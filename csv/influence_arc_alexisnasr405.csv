1997.mtsummit-workshop.12,J94-4004,0,0.436237,"ant strides towards understanding why interlingua-based analyses are successful. • There are practical advantages to tying machine translation to surface-oriented representations as much as possible: the availability of large bilingual corpora has made the exploitation of stochastic approaches a crucial element in the practical success of MT, and such approaches are by nature oriented towards the surface form. This paper is structured as follows. In Section 2, we introduce some the standard interlingua-based analysis for a well-known case of “structural divergence”, a difficult MT challenges (Dorr, 1994). In Section 3, we present our MT system and its lexico-structural transfer formalism in particular. In Section 4, we discuss the semantic analysis that underlies our approach. In Section 5, we present a simple transposition of the interlingua approach to lexico-structural transfer. In Section 6, we show how we can eliminate the most unmotivated features of this analysis by using lexical functions, a language-internal device for relating lexemes. We conclude in Section 7. 91 2 Structural Divergences A classic problem in machine translation is the translation of motion verbs from English to Fre"
1997.mtsummit-workshop.12,J87-3006,0,\N,Missing
2004.jeptalnrecital-long.10,P03-1006,0,0.0226818,"age, car des trigrammes apparaissant dans les textes à étiqueter peuvent n’avoir jamais été observés dans le corpus d’apprentissage. C’est la raison pour laquelle on a recours à des méthodes de lissage des probabilités, telles que les méthodes de repli (10) qui consistent à se replier sur la probabilité du bigramme b c lorsque le trigramme a b c n’a pas été observé dans le corpus et, lorsque le bigramme b c n’a pas été observé, à se replier sur l’unigramme c. Un modèle de repli peut être directement représenté sous la forme d’un automate comportant des transitions par défaut comme décrit dans (4). Etant donné un symbole , une transition par défaut émanant d’un état est empruntée lorsqu’il n’existe pas de transition émanant de étiquetée par . Dans le cas du modèle de repli, une transition par défaut est empruntée lorsqu’un trigramme ou un bigramme n’a jamais été observé. Il ne nous est pas possible ici de décrire plus en détail la structure de tels automates. Pour plus de détails, le lecteur est invité à se référer à l’article cité ci-desssus. ¡ ¢ ¢ ¡ Plusieurs approches dans la littérature (14; 11; 9) utilisent les automates finis pondérés afin de simuler le fonctionnement d’un MMC. D"
2004.jeptalnrecital-long.10,P94-1032,0,0.0424499,"s pour objectif de favoriser un découpage en chunks d’une même suite de catégories plutôt qu’un autre (l’analyse en chunks est unique !). Son objectif est de fournir un moyen de comparer entre elles différentes séquences de catégories possibles pour une même phrase. Pour cela, l’analyseur partiel associe à toute séquence de catégories une probabilité qui est d’autant plus élevée que la séquence de catégories correspond à des séquences de chunks bien formés, agencés dans un ordre linéaire observé sur un corpus d’apprentissage. Cette approche partage plusieurs points communs avec les travaux de (6) qui utilisent eux aussi des transducteurs pondérés pour réaliser un analyseur partiel probabiliste. Cependant, dans leur cas, plusieurs découpages de la phrase en chunks sont possibles et l’objectif de l’analyseur est de fournir le découpage le plus probable. De plus, leur analyseur prend en entrée une séquence unique de catégories. ? @   & | &   & !   La probabilité d’une suite de catégories découpée en chunks est calculée à partir de deux types de probabilités : des probabilités intra chunk et des probabilités inter chunks. Une probabilité intra chunk est la probabilité qu’une suite d"
2004.jeptalnrecital-long.10,P97-1059,0,0.172067,"présenté sous la forme d’un automate comportant des transitions par défaut comme décrit dans (4). Etant donné un symbole , une transition par défaut émanant d’un état est empruntée lorsqu’il n’existe pas de transition émanant de étiquetée par . Dans le cas du modèle de repli, une transition par défaut est empruntée lorsqu’un trigramme ou un bigramme n’a jamais été observé. Il ne nous est pas possible ici de décrire plus en détail la structure de tels automates. Pour plus de détails, le lecteur est invité à se référer à l’article cité ci-desssus. ¡ ¢ ¢ ¡ Plusieurs approches dans la littérature (14; 11; 9) utilisent les automates finis pondérés afin de simuler le fonctionnement d’un MMC. Dans les trois cas, les n-grammes sont représentés sous la forme d’automates, de manière proche de la notre. Cependant, ces travaux se distinguent du notre en ne modélisant pas directement les probablilités d’émission ( ) estimées sur un corpus d’apprentissage, mais en recourant à des classes d’ambiguïtés, qui sont des ensembles de catégories associées à un mot. K  ? M @  4 Analyse syntaxique partielle L’analyse syntaxique partielle désigne un ensemble de techniques dont le but est de mettre au jour une parti"
2004.jeptalnrecital-long.10,J97-2003,0,0.0291913,"les formels différents. Un autre avantage de l’homogénéité de ce cadre est la facilité de mise en œuvre : plus de formats spécifiques à concevoir pour différents types de données, plus d’algorithmes à adapter, à programmer et à optimiser. La réalisation de tels traitements dépend de manière cruciale de l’existence de bibliothèques logicielles de manipulation d’automates. Dans le cadre de ce travail, nous avons utilisé les outils FSM et GRM de ATT (8). Notre travail se situe dans la mouvance du traitement probabiliste de la langue à l’aide d’automates pondérés, dont on trouvera un apperçu dans (12). Il se distingue dans son esprit d’autres approches fondées sur les automates finis non probabilistes, telles qu’INTEX (7), dans lesquelles des règles sont construites manuellement pour être ensuite utilisées dans le cadre de traitements automatiques. L’organisation de l’article est la suivante : dans la partie 2, on reprend quelques définitions concernant les automates pondérés et on introduit quelques notations. Les sections 3 et 4 décrivent respectivement les principes d’un étiqueteur probabiliste et d’un analyseur partiel et leur implémentation sous la forme d’automates pondérés. Dans la"
2009.jeptalnrecital-long.3,P98-1013,0,0.0221491,"Missing"
2009.jeptalnrecital-long.3,C96-2120,0,0.108306,"Missing"
2009.jeptalnrecital-long.3,sagot-etal-2006-lefff,0,0.069707,"Missing"
2009.jeptalnrecital-long.3,J92-1004,0,0.212364,"Missing"
2011.jeptalnrecital-court.5,2007.jeptalnrecital-long.34,0,0.0895264,"Missing"
2011.jeptalnrecital-court.5,2008.jeptalnrecital-court.10,1,0.829059,"Missing"
2011.jeptalnrecital-court.5,2009.jeptalnrecital-court.14,1,0.844763,"Missing"
2011.jeptalnrecital-court.5,W99-0904,0,0.129856,"Missing"
2011.jeptalnrecital-court.5,E09-1056,0,0.0206157,"Missing"
2011.jeptalnrecital-court.5,2010.jeptalnrecital-demonstration.16,1,0.820922,"Missing"
2011.jeptalnrecital-court.5,2003.jeptalnrecital-long.27,0,0.120239,"Missing"
2011.jeptalnrecital-long.26,W10-1408,1,0.877026,"Missing"
2011.jeptalnrecital-long.26,C10-1011,0,0.0269882,"Missing"
2011.jeptalnrecital-long.26,candito-etal-2010-statistical,0,0.0312059,"Missing"
2011.jeptalnrecital-long.26,W09-3821,0,0.0436454,"Missing"
2011.jeptalnrecital-long.26,2009.jeptalnrecital-long.4,0,0.0966482,"Missing"
2011.jeptalnrecital-long.26,C10-2013,0,0.0302856,"Missing"
2011.jeptalnrecital-long.26,P05-1022,0,0.145446,"Missing"
2011.jeptalnrecital-long.26,P97-1003,0,0.220523,"Missing"
2011.jeptalnrecital-long.26,2010.jeptalnrecital-long.3,0,0.0504872,"Missing"
2011.jeptalnrecital-long.26,N10-1095,0,0.0377103,"Missing"
2011.jeptalnrecital-long.26,P05-1010,0,0.0473543,"Missing"
2011.jeptalnrecital-long.26,C08-1071,0,0.0408272,"Missing"
2011.jeptalnrecital-long.26,P05-1012,0,0.152191,"Missing"
2011.jeptalnrecital-long.26,P06-1055,0,0.0763483,"Missing"
2011.jeptalnrecital-long.26,N07-1051,0,0.0986944,"Missing"
2011.jeptalnrecital-long.26,N10-1049,0,0.0288354,"Missing"
2011.jeptalnrecital-long.8,esteve-etal-2010-epac,1,0.88325,"Missing"
2011.jeptalnrecital-long.8,J00-3003,0,0.247225,"Missing"
2013.mtsummit-papers.16,al-sabbagh-girju-2010-mining,0,0.257071,"Missing"
2013.mtsummit-papers.16,altantawy-etal-2010-morphological,1,0.88472,"ition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) com"
2013.mtsummit-papers.16,W11-4416,1,0.855594,"t al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that"
2013.mtsummit-papers.16,E06-1047,1,0.8586,"; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Eg"
2013.mtsummit-papers.16,N13-1066,1,0.827322,"e authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. design principles, development tools and guidelines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers h"
2013.mtsummit-papers.16,P05-1071,1,0.761472,"ar, dual and plural are reduced to singular and plural. Masculine and feminine values of gender feature are not distinguished in TUN except for the third person singular. Patterns carry a general meaning, the MSA pattern Ai12a33, for example, denotes the change of state. This pattern is not used in TUN and Tunisians express the state change by using the pattern 12A3 which not exists in MSA. Furthermore, some MSA patterns are not defined in TUN and vice versa. 4 Tools and Resources Our architecture relies on the morphological processing tool MAGEAD and on a transfer lexicon. 4.1 MAGEAD MAGEAD (Habash and Rambow, 2005) is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). MAGEAD relates (bidirectionally) a lexeme and a set of linguistic features to a surface word form through a sequence of transformations. In a generation perspective, the features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. The concrete templatic morphemes are interdigitated and affixes added, finally morphological and phonological rewrite rules are applied. 4.1.1 Lexeme and Features Morphological analyses are represented in terms of a lexeme"
2013.mtsummit-papers.16,P06-1086,1,0.951348,"delines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic,"
2013.mtsummit-papers.16,W05-0703,1,0.894943,"lopment tools and guidelines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to"
2013.mtsummit-papers.16,habash-etal-2012-conventional,1,0.925187,"independence of mapping roots and patterns is optimal in reducing overall ambiguity and increasing recall. 1 Introduction The Arabic language has many variants. Modern Standard Arabic (MSA) is one of them. It is the official language of all Arab countries. However, MSA is the native language of no Arabic speakers. It is used for education, printed and spoken media. There exists also a variety of Arabic dialects which are the native languages of Arabic speakers. Unlike MSA, Dialectal Arabic (DA) varieties are only spoken. Therefore, there is no standard orthographic conventions (Habash, 2010; Habash et al., 2012b). Most of the Arabic natural language processing (NLP) resources are built in order to process MSA. Very few works on processing dialects have been established, and mainly for Egyptian, Iraqi and Levantine Arabic. In this work, we focus on the Tunisian Arabic dialect (TUN), an important yet less studied Arabic dialect. We propose to transform it into a form that is close to MSA by using morphological analysis and generation in order to take advantage of MSA NLP tools. Our approach relies on modeling the translation process over the deep morphological representations of roots and patterns, co"
2013.mtsummit-papers.16,N13-1044,1,0.842075,"chine Translation Summit (Nice, September 2–6, 2013), p. 125–134. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. design principles, development tools and guidelines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to"
2013.mtsummit-papers.16,J00-1006,0,0.400564,"(3) &lt;zhr,V1tV2V3,iaa> + at Simple interdigitation of root, pattern and vocalism then yields the form iztahar+at. 4.1.4 MAGEAD Rules MAGEAD uses two types of rules. Morphophonemic/phonological rules map from the morphemic representation to the phonological and orthographic representations. Orthographic rules rewrite only the orthographic representation. For our example, we get /izdaharat/ at the phonological level (as opposed to /iztaharat/). Using standard MSA diacritized orthography, our example becomes Aizdaharat. Removing the diacritics turns this into the more familiar Azdhrt. We follow (Kiraz, 2000) in using a multi-tape representation. MAGEAD extend the analysis of Kiraz by introducing a fifth tier. The five tiers are used as follows: Tier 1: pattern and affixational morphemes; Tier 2: root; Tier 3: vocalism; Tier 4: phonological representation; Tier 5: orthographic representation. In the generation direction, tiers 1 through 3 are always input tiers. Tier 4 is first an output tier, and subsequently an input tier. Tier 5 is always an output tier. 4.1.5 From MSA to Tunisian We adapted MAGEAD to process TUN verbs. Our effort concentrated on the orthographic representation. Changes concern"
2013.mtsummit-papers.16,P12-2035,0,0.0237282,"e, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al., 2012; Salloum and Habash, 2013) but using a well-motivated deep morphological representation based on the MAGEAD approach (Habash and Rambow, 2006). Our solution is bi-directional unlike previous efforts and we demonstrate our approach on Tunisian Arabic. 3 Morphology: MSA vs Tunisian Arabic Many similarities and differences exist between MSA"
2013.mtsummit-papers.16,2006.amta-papers.21,0,0.0163821,"s of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence fr"
2013.mtsummit-papers.16,W11-2602,1,0.878992,"e morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al., 2012; Salloum and Habash"
2013.mtsummit-papers.16,N13-1036,1,0.796057,"that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al., 2012; Salloum and Habash, 2013) but using a well-motiv"
2013.mtsummit-papers.16,2010.amta-papers.5,0,0.416846,"ithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al"
2013.mtsummit-papers.16,N12-1006,0,0.11258,"ystem for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analy"
2013.mtsummit-papers.16,W05-0909,0,0.192592,"Missing"
2013.mtsummit-papers.16,E06-1032,0,0.0212101,"Missing"
2013.mtsummit-papers.16,fishel-etal-2012-terra,0,0.0320987,"Missing"
2013.mtsummit-papers.16,2005.mtsummit-papers.11,0,0.016339,"Missing"
2013.mtsummit-papers.16,max-etal-2010-contrastive,0,0.0225119,"Missing"
2013.mtsummit-papers.16,W03-0301,0,0.0575504,"Missing"
2013.mtsummit-papers.16,C00-2163,0,0.162528,"Missing"
2013.mtsummit-papers.16,2011.eamt-1.36,0,0.0293463,"Missing"
2013.mtsummit-papers.16,W06-3101,0,0.0604473,"Missing"
2013.mtsummit-papers.16,2006.amta-papers.25,0,0.0798075,"Missing"
2013.mtsummit-papers.16,C08-1141,0,0.0294622,"Missing"
2013.mtsummit-papers.16,J03-1002,0,0.00754575,"Missing"
2013.mtsummit-papers.16,P02-1040,0,0.086357,"Missing"
2013.mtsummit-papers.16,W12-2301,1,\N,Missing
2018.jeptalnrecital-court.42,L16-1319,0,0.0628307,"Missing"
2018.jeptalnrecital-court.42,P05-2014,0,0.0804368,"Missing"
2018.jeptalnrecital-court.42,W04-2319,0,0.232274,"Missing"
2018.jeptalnrecital-court.42,N16-1174,0,0.0218811,"Missing"
2018.jeptalnrecital-long.13,P08-1037,0,0.0567262,"Missing"
2018.jeptalnrecital-long.13,P15-1006,0,0.0589067,"Missing"
2018.jeptalnrecital-long.13,D16-1156,0,0.0311152,"Missing"
2018.jeptalnrecital-long.13,P17-1191,0,0.0198975,"Missing"
2018.jeptalnrecital-long.13,E17-2050,0,0.0304591,"Missing"
2018.jeptalnrecital-long.13,W17-6311,1,0.661114,"Missing"
2018.jeptalnrecital-long.13,J93-2004,0,0.0615618,"Missing"
2018.jeptalnrecital-long.13,J16-1002,1,0.87007,"Missing"
2018.jeptalnrecital-long.13,Q14-1006,0,0.100825,"Missing"
2019.jeptalnrecital-court.4,P98-1013,0,0.0571271,"Missing"
2019.jeptalnrecital-court.4,S17-2051,1,0.890372,"Missing"
2019.jeptalnrecital-court.4,W18-0530,0,0.0380174,"Missing"
2019.jeptalnrecital-court.4,P14-2053,0,0.0606828,"Missing"
2019.jeptalnrecital-court.4,D16-1264,0,0.11831,"Missing"
2019.jeptalnrecital-court.4,D17-1090,0,0.029907,"Missing"
2019.jeptalnrecital-court.4,W17-2603,0,0.0497315,"Missing"
2020.coling-main.298,P11-2123,0,0.0126922,"SemCor for English Wordnet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns are annotated using Wordnet supersenses as semantic tags (Barque et al., 2020). Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs. inanimate nouns (Øvrelid, 2006). We understand supersenses as general coarse semantic distinctions. Our"
2020.coling-main.298,2020.lrec-1.724,1,0.874407,"Missing"
2020.coling-main.298,Q17-1010,0,0.0487418,"ngs have become commonplace in NLP, as they naturally represent input (words) in state-of-the-art neural models. Although they can be randomly initialised and learned, unsupervised pre-training on raw corpora is common (Turian et al., 2010). Embeddings can be pre-trained as by-products of predictive neural language models (Mikolov et al., 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al., 2014), etc. Sub-lexical units (character n-grams) address linguistic variability, e.g., due to rich morphology, non-standard text, and out-of-vocabulary forms (Bojanowski et al., 2017). Most of the models prior to 2018 are static, assuming a single vector per word. These models suffer from meaning conflation, i.e., a single vector is created for ambiguous units, ignoring polysemous and multi-facet words. Advances in neural networks triggered the development of contextual embeddings, with representations conditioned on the surrounding words. They can be obtained using stacked recurrent layers as in ELMo (Peters et al., 2018), or attention-based transformers as in BERT (Devlin et al., 2018) and GPT-2 (Radford et al., 2018). In addition to their outstanding performances, these"
2020.coling-main.298,S12-1023,0,0.0459254,"Missing"
2020.coling-main.298,F12-2024,0,0.0332991,"Missing"
2020.coling-main.298,W03-1022,0,0.180902,"performing WSD in languages other than English (Moro et al., 2014). Supervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.g., SemCor for English Wordnet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns are annotated using Wordnet supersenses as semantic tags (Barque et al., 2020). Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream"
2020.coling-main.298,P17-2094,0,0.0229623,"nymy, synonymy). For many years, the English Wordnet has been the basis of 3358 sense-annotated corpora (Landes et al., 1998) and WSD research (Navigli, 2009). Babelnet (Navigli and Ponzetto, 2012) is a semi-automatic multilingual lexicon similar to Wordnet and also quite popular for performing WSD in languages other than English (Moro et al., 2014). Supervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.g., SemCor for English Wordnet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we em"
2020.coling-main.298,N15-1184,0,0.0730725,"Missing"
2020.coling-main.298,D15-1208,0,0.0255752,") and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns are annotated using Wordnet supersenses as semantic tags (Barque et al., 2020). Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs. inanimate nouns (Øvrelid, 2006). We understand supersenses as general coarse semantic distinctions. Our set of six semantic labels is related to Wordnet supers"
2020.coling-main.298,P16-1191,0,0.194906,"which a lexical unit is associated to several vectors (as in contextual models), but with some generalisation across occurrences (as in static models). Unsupervised sense (multi-prototype) embeddings can be obtained by adapting the objective of the learning procedure (Neelakantan et al., 2014), or with word sense induction methods based on clustering, e.g., Panchenko et al. (2017). For interpretability, resources such as Wordnet can be used to semantically enhance static embeddings (Faruqui et al., 2015) or to learn representations for Wordnet synsets (Rothe and Sch¨utze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al., 2016). Contextual models such as BERT can be enriched with supersenses, predicted jointly with masked words during training, with observed improvements in tasks requiring lexical semantics (Levine et al., 2020). Interpretable semantic representations One of the most popular sense inventories in NLP is Wordnet (Miller et al., 1990), in which words are grouped into synsets and linked to each other via lexical-semantic relations (e.g., hypernymy, synonymy). For many years, the English Wordnet has been the basis of 3358 sense-annotated corpora (Landes"
2020.coling-main.298,C18-1001,0,0.0144746,"al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns are annotated using Wordnet supersenses as semantic tags (Barque et al., 2020). Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs. inanimate nouns (Øvrelid, 2006). We understand supersenses as general coarse semantic distinctions. Our set of six semantic labels is related to Wordnet supersenses, but there is not a 1:1 relation between our supersenses and Wordnet’s ones. Weakly supervised semantic classification Many models have been proposed to induce lexical semantics from raw corpora without supervision, e.g., (Lin, 1998), usually performing unsupervised WSD as a by-product. Most methods rely on distributional clustering algorithms, e"
2020.coling-main.298,S17-1025,0,0.0193502,"ted corpora, such as Semcor (Flekova and Gurevych, 2016) or sense inventories such as Wordnet (Levine et al., 2020). Our embedding learning procedure is not fully unsupervised, but uses weak supervision to bootstrap semantic classes from corpora. Typical or non-ambiguous words can be used to produce sense-annotated data, which in turn enable training classifiers for inducing lexical knowledge. This has been proposed in several studies, e.g., Mihalcea (2003), especially for polysemy pattern detection (Boleda et al., 2012), and adapted to semantic frame induction using predicate-argument pairs (Jauhar and Hovy, 2017). The method of Thelen and Riloff (2002) is similar to ours. They learn representations for six coarse supersenses using pattern-based bootstrapping based on a small list of seed words. The features used to learn senses are based on lexical patterns, syntactic co-occurrence, web queries, etc. (Qadir and Riloff, 2012). Instead of focusing on the features, our approach is more in line with current neural methods, with features learned from the data jointly with the supersense classifiers. 3 Contextual and Lexical Signatures The heart of SLICE consists in a series of binary classifiers, one per s"
2020.coling-main.298,P19-1356,0,0.215452,"c embedding per lexical unit, contextual This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 3357 Proceedings of the 28th International Conference on Computational Linguistics, pages 3357–3370 Barcelona, Spain (Online), December 8-13, 2020 models provide a fine-grained distinct representation for each occurrence. Both models, but especially the latter, are increasingly complex and opaque (Rogers et al., 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al., 2019; Serrano and Smith, 2019). Given this landscape, we introduce SLICE: an alternative semantic model which constitutes a trade-off between static, interpretable symbolic senses and contextual word embeddings. We propose a weakly supervised technique to build dense low-dimensional embeddings whose dimensions represent coarsegrained semantic classes i.e., supersenses such as ANIMATE ENTITY and NATURAL OBJECT (Sec. 3). Our lightweight model embeds both lexical units and their contexts into the same semantic space. Thus, words and their contexts are represented as two compact vectors of directly in"
2020.coling-main.298,2020.lrec-1.302,0,0.0592296,"Missing"
2020.coling-main.298,2020.acl-main.423,0,0.16561,"dure (Neelakantan et al., 2014), or with word sense induction methods based on clustering, e.g., Panchenko et al. (2017). For interpretability, resources such as Wordnet can be used to semantically enhance static embeddings (Faruqui et al., 2015) or to learn representations for Wordnet synsets (Rothe and Sch¨utze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al., 2016). Contextual models such as BERT can be enriched with supersenses, predicted jointly with masked words during training, with observed improvements in tasks requiring lexical semantics (Levine et al., 2020). Interpretable semantic representations One of the most popular sense inventories in NLP is Wordnet (Miller et al., 1990), in which words are grouped into synsets and linked to each other via lexical-semantic relations (e.g., hypernymy, synonymy). For many years, the English Wordnet has been the basis of 3358 sense-annotated corpora (Landes et al., 1998) and WSD research (Navigli, 2009). Babelnet (Navigli and Ponzetto, 2012) is a semi-automatic multilingual lexicon similar to Wordnet and also quite popular for performing WSD in languages other than English (Moro et al., 2014). Supervised WSD"
2020.coling-main.298,P98-2127,0,0.339672,"lar, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs. inanimate nouns (Øvrelid, 2006). We understand supersenses as general coarse semantic distinctions. Our set of six semantic labels is related to Wordnet supersenses, but there is not a 1:1 relation between our supersenses and Wordnet’s ones. Weakly supervised semantic classification Many models have been proposed to induce lexical semantics from raw corpora without supervision, e.g., (Lin, 1998), usually performing unsupervised WSD as a by-product. Most methods rely on distributional clustering algorithms, e.g., (Biemann and Riedl, 2013). While automatically induced word senses are hard to interpret, they may be automatically labeled, for example, using hypernym-induction patterns (Ustalov et al., 2019). There have been several proposals to integrate interpretable representations such as supersenses with continuous (unsupervised) representations, but they often rely on annotated corpora, such as Semcor (Flekova and Gurevych, 2016) or sense inventories such as Wordnet (Levine et al.,"
2020.coling-main.298,Q14-1019,0,0.0404694,"cal semantics (Levine et al., 2020). Interpretable semantic representations One of the most popular sense inventories in NLP is Wordnet (Miller et al., 1990), in which words are grouped into synsets and linked to each other via lexical-semantic relations (e.g., hypernymy, synonymy). For many years, the English Wordnet has been the basis of 3358 sense-annotated corpora (Landes et al., 1998) and WSD research (Navigli, 2009). Babelnet (Navigli and Ponzetto, 2012) is a semi-automatic multilingual lexicon similar to Wordnet and also quite popular for performing WSD in languages other than English (Moro et al., 2014). Supervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.g., SemCor for English Wordnet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces"
2020.coling-main.298,D14-1113,0,0.0358788,"t senses and are modelled with a custom embeddings. On the downside, they are computationally heavy and opaque (Rogers et al., 2020), requiring sophisticated techniques such as probing to interpret predictions (Jawahar et al., 2019). Particularly relevant to our work are sense embeddings (Camacho-Collados and Pilehvar, 2018), in which a lexical unit is associated to several vectors (as in contextual models), but with some generalisation across occurrences (as in static models). Unsupervised sense (multi-prototype) embeddings can be obtained by adapting the objective of the learning procedure (Neelakantan et al., 2014), or with word sense induction methods based on clustering, e.g., Panchenko et al. (2017). For interpretability, resources such as Wordnet can be used to semantically enhance static embeddings (Faruqui et al., 2015) or to learn representations for Wordnet synsets (Rothe and Sch¨utze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al., 2016). Contextual models such as BERT can be enriched with supersenses, predicted jointly with masked words during training, with observed improvements in tasks requiring lexical semantics (Levine et al., 2020). Interpret"
2020.coling-main.298,L16-1262,0,0.0179717,"Missing"
2020.coling-main.298,E06-3008,0,0.0699912,"tive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns are annotated using Wordnet supersenses as semantic tags (Barque et al., 2020). Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs. inanimate nouns (Øvrelid, 2006). We understand supersenses as general coarse semantic distinctions. Our set of six semantic labels is related to Wordnet supersenses, but there is not a 1:1 relation between our supersenses and Wordnet’s ones. Weakly supervised semantic classification Many models have been proposed to induce lexical semantics from raw corpora without supervision, e.g., (Lin, 1998), usually performing unsupervised WSD as a by-product. Most methods rely on distributional clustering algorithms, e.g., (Biemann and Riedl, 2013). While automatically induced word senses are hard to interpret, they may be automatical"
2020.coling-main.298,E17-1009,0,0.0177933,"ly heavy and opaque (Rogers et al., 2020), requiring sophisticated techniques such as probing to interpret predictions (Jawahar et al., 2019). Particularly relevant to our work are sense embeddings (Camacho-Collados and Pilehvar, 2018), in which a lexical unit is associated to several vectors (as in contextual models), but with some generalisation across occurrences (as in static models). Unsupervised sense (multi-prototype) embeddings can be obtained by adapting the objective of the learning procedure (Neelakantan et al., 2014), or with word sense induction methods based on clustering, e.g., Panchenko et al. (2017). For interpretability, resources such as Wordnet can be used to semantically enhance static embeddings (Faruqui et al., 2015) or to learn representations for Wordnet synsets (Rothe and Sch¨utze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al., 2016). Contextual models such as BERT can be enriched with supersenses, predicted jointly with masked words during training, with observed improvements in tasks requiring lexical semantics (Levine et al., 2020). Interpretable semantic representations One of the most popular sense inventories in NLP is Wordnet"
2020.coling-main.298,2020.lrec-1.706,0,0.019867,"r et al., 1990), in which words are grouped into synsets and linked to each other via lexical-semantic relations (e.g., hypernymy, synonymy). For many years, the English Wordnet has been the basis of 3358 sense-annotated corpora (Landes et al., 1998) and WSD research (Navigli, 2009). Babelnet (Navigli and Ponzetto, 2012) is a semi-automatic multilingual lexicon similar to Wordnet and also quite popular for performing WSD in languages other than English (Moro et al., 2014). Supervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.g., SemCor for English Wordnet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency pa"
2020.coling-main.298,D14-1162,0,0.0834123,"e being constantly improved, the main principle is stable across models: vectors represent a word’s usage (and meaning) based on its distributional context (Harris, 1954). Embeddings have become commonplace in NLP, as they naturally represent input (words) in state-of-the-art neural models. Although they can be randomly initialised and learned, unsupervised pre-training on raw corpora is common (Turian et al., 2010). Embeddings can be pre-trained as by-products of predictive neural language models (Mikolov et al., 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al., 2014), etc. Sub-lexical units (character n-grams) address linguistic variability, e.g., due to rich morphology, non-standard text, and out-of-vocabulary forms (Bojanowski et al., 2017). Most of the models prior to 2018 are static, assuming a single vector per word. These models suffer from meaning conflation, i.e., a single vector is created for ambiguous units, ignoring polysemous and multi-facet words. Advances in neural networks triggered the development of contextual embeddings, with representations conditioned on the surrounding words. They can be obtained using stacked recurrent layers as in"
2020.coling-main.298,N18-1202,0,0.0419497,"Sub-lexical units (character n-grams) address linguistic variability, e.g., due to rich morphology, non-standard text, and out-of-vocabulary forms (Bojanowski et al., 2017). Most of the models prior to 2018 are static, assuming a single vector per word. These models suffer from meaning conflation, i.e., a single vector is created for ambiguous units, ignoring polysemous and multi-facet words. Advances in neural networks triggered the development of contextual embeddings, with representations conditioned on the surrounding words. They can be obtained using stacked recurrent layers as in ELMo (Peters et al., 2018), or attention-based transformers as in BERT (Devlin et al., 2018) and GPT-2 (Radford et al., 2018). In addition to their outstanding performances, these models address meaning conflation: contexts correspond to (slightly) different senses and are modelled with a custom embeddings. On the downside, they are computationally heavy and opaque (Rogers et al., 2020), requiring sophisticated techniques such as probing to interpret predictions (Jawahar et al., 2019). Particularly relevant to our work are sense embeddings (Camacho-Collados and Pilehvar, 2018), in which a lexical unit is associated to"
2020.coling-main.298,S12-1028,0,0.0279669,"data, which in turn enable training classifiers for inducing lexical knowledge. This has been proposed in several studies, e.g., Mihalcea (2003), especially for polysemy pattern detection (Boleda et al., 2012), and adapted to semantic frame induction using predicate-argument pairs (Jauhar and Hovy, 2017). The method of Thelen and Riloff (2002) is similar to ours. They learn representations for six coarse supersenses using pattern-based bootstrapping based on a small list of seed words. The features used to learn senses are based on lexical patterns, syntactic co-occurrence, web queries, etc. (Qadir and Riloff, 2012). Instead of focusing on the features, our approach is more in line with current neural methods, with features learned from the data jointly with the supersense classifiers. 3 Contextual and Lexical Signatures The heart of SLICE consists in a series of binary classifiers, one per supersense. Each classifier takes as input a context C and produces a score that indicates how likely C could be associated to a given supersense si . This score, noted csi (C), is called a context score. A context C can be associated to a d-dimensional vector, called its signature CS(C) = (cs1 (C), . . . , csd (C))T"
2020.coling-main.298,2020.tacl-1.54,0,0.0458401,"each context corresponds to a different sense (Yarowsky, 1993). In short, while static models create one generic embedding per lexical unit, contextual This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 3357 Proceedings of the 28th International Conference on Computational Linguistics, pages 3357–3370 Barcelona, Spain (Online), December 8-13, 2020 models provide a fine-grained distinct representation for each occurrence. Both models, but especially the latter, are increasingly complex and opaque (Rogers et al., 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al., 2019; Serrano and Smith, 2019). Given this landscape, we introduce SLICE: an alternative semantic model which constitutes a trade-off between static, interpretable symbolic senses and contextual word embeddings. We propose a weakly supervised technique to build dense low-dimensional embeddings whose dimensions represent coarsegrained semantic classes i.e., supersenses such as ANIMATE ENTITY and NATURAL OBJECT (Sec. 3). Our lightweight model embeds both lexical units and their contexts int"
2020.coling-main.298,P15-1173,0,0.051392,"Missing"
2020.coling-main.298,S16-1084,0,0.0224397,"ther than English (Moro et al., 2014). Supervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.g., SemCor for English Wordnet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy (e.g., A NIMAL, E VENT), referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions, often with positive impact on downstream applications such as dependency parsing (Agirre et al., 2011) and personality profiling (Flekova and Gurevych, 2015).1 In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns are annotated using Wordnet supersenses as semantic tags (Barque et al., 2020). Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al"
2020.coling-main.298,P19-1282,0,0.0279069,"l unit, contextual This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 3357 Proceedings of the 28th International Conference on Computational Linguistics, pages 3357–3370 Barcelona, Spain (Online), December 8-13, 2020 models provide a fine-grained distinct representation for each occurrence. Both models, but especially the latter, are increasingly complex and opaque (Rogers et al., 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al., 2019; Serrano and Smith, 2019). Given this landscape, we introduce SLICE: an alternative semantic model which constitutes a trade-off between static, interpretable symbolic senses and contextual word embeddings. We propose a weakly supervised technique to build dense low-dimensional embeddings whose dimensions represent coarsegrained semantic classes i.e., supersenses such as ANIMATE ENTITY and NATURAL OBJECT (Sec. 3). Our lightweight model embeds both lexical units and their contexts into the same semantic space. Thus, words and their contexts are represented as two compact vectors of directly interpretable scores, one pe"
2020.coling-main.298,W02-1028,0,0.32498,"nd Gurevych, 2016) or sense inventories such as Wordnet (Levine et al., 2020). Our embedding learning procedure is not fully unsupervised, but uses weak supervision to bootstrap semantic classes from corpora. Typical or non-ambiguous words can be used to produce sense-annotated data, which in turn enable training classifiers for inducing lexical knowledge. This has been proposed in several studies, e.g., Mihalcea (2003), especially for polysemy pattern detection (Boleda et al., 2012), and adapted to semantic frame induction using predicate-argument pairs (Jauhar and Hovy, 2017). The method of Thelen and Riloff (2002) is similar to ours. They learn representations for six coarse supersenses using pattern-based bootstrapping based on a small list of seed words. The features used to learn senses are based on lexical patterns, syntactic co-occurrence, web queries, etc. (Qadir and Riloff, 2012). Instead of focusing on the features, our approach is more in line with current neural methods, with features learned from the data jointly with the supersense classifiers. 3 Contextual and Lexical Signatures The heart of SLICE consists in a series of binary classifiers, one per supersense. Each classifier takes as inpu"
2020.coling-main.298,P10-1040,0,0.110797,"entations is enormous, ranging from traditional models such as LSA (Landauer and Dumais, 1997) to sophisticated deep contextualised embeddings such as BERT (Devlin et al., 2018). Although techniques are being constantly improved, the main principle is stable across models: vectors represent a word’s usage (and meaning) based on its distributional context (Harris, 1954). Embeddings have become commonplace in NLP, as they naturally represent input (words) in state-of-the-art neural models. Although they can be randomly initialised and learned, unsupervised pre-training on raw corpora is common (Turian et al., 2010). Embeddings can be pre-trained as by-products of predictive neural language models (Mikolov et al., 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al., 2014), etc. Sub-lexical units (character n-grams) address linguistic variability, e.g., due to rich morphology, non-standard text, and out-of-vocabulary forms (Bojanowski et al., 2017). Most of the models prior to 2018 are static, assuming a single vector per word. These models suffer from meaning conflation, i.e., a single vector is created for ambiguous units, ignoring polysemous and multi-facet"
2020.coling-main.298,J19-3002,0,0.0113555,"nctions. Our set of six semantic labels is related to Wordnet supersenses, but there is not a 1:1 relation between our supersenses and Wordnet’s ones. Weakly supervised semantic classification Many models have been proposed to induce lexical semantics from raw corpora without supervision, e.g., (Lin, 1998), usually performing unsupervised WSD as a by-product. Most methods rely on distributional clustering algorithms, e.g., (Biemann and Riedl, 2013). While automatically induced word senses are hard to interpret, they may be automatically labeled, for example, using hypernym-induction patterns (Ustalov et al., 2019). There have been several proposals to integrate interpretable representations such as supersenses with continuous (unsupervised) representations, but they often rely on annotated corpora, such as Semcor (Flekova and Gurevych, 2016) or sense inventories such as Wordnet (Levine et al., 2020). Our embedding learning procedure is not fully unsupervised, but uses weak supervision to bootstrap semantic classes from corpora. Typical or non-ambiguous words can be used to produce sense-annotated data, which in turn enable training classifiers for inducing lexical knowledge. This has been proposed in s"
2021.cmcl-1.13,2021.cmcl-1.7,0,0.0888806,"Missing"
2021.cmcl-1.13,P11-4015,1,0.695876,"Missing"
2021.cmcl-1.13,W03-3017,0,0.178156,"ers that 108 Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, pages 108–113 Online Event, June 10, 2021. ©2021 Association for Computational Linguistics take as input features about current word and its context and produce as output a probability distribution over a set of actions. Such actions posit word boundaries on the raw text, associate part of speech and morphological tags to words or link words of a sentence with syntactic dependencies. The actions that perform the prediction of syntactic dependencies are based on the transition based parsing framework (Nivre, 2003), which makes use of a stack that stores words that should be connected to words not yet discovered. The stack allows to connect words that are not adjacent in the sentence. The classifiers are organized in an incremental architecture, i.e., once the tokenizer detected a word boundary, control jumps to the part of speech tagger, then to the morphological tagger and eventually to the syntactic parser, before going back to the tokenizer. The behaviour of the whole system is greedy, at every step, a single action is selected and performed. The action selected is the one that maximizes the probabi"
2021.iwpt-1.3,D15-1159,0,0.0166852,"f Configurations and Actions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointly predict POS tags and"
2021.iwpt-1.3,D12-1133,0,0.0167993,"BP the two key notions of Configurations and Actions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointl"
2021.iwpt-1.3,P16-1016,0,0.0165502,"eedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointly predict POS tags and the dependency tree, improving both the accuracy of tagging and parsing. T"
2021.iwpt-1.3,2021.cmcl-1.13,1,0.719176,"tics man sentence processing (see Hale (2017) for a review). Various “linking hypotheses” have been proposed to relate the models’ intermediate states when parsing a given sentence to the behavior of human subjects trying to understand that same sentence. The RM offers a framework to investigate such linking hypotheses by defining machines that implement them and observe their behaviour on human data. In this perspective, the RM has already been used for predicting eye-movements during reading: different RM architectures have been compared on their ability to accurately predict fixation time (Dary et al., 2021a,b). In order to illustrate the kind of experiments that can be conducted in such a perspective, we will define and compare machines that model different perceptual fields and measure their influence on an incremental parsing process. Technically, RM is an extension of the transitionbased parsing algorithm (TBP) (Yamada and Matsumoto, 2003; Nivre, 2003). The reason for this choice is mainly that TBP implements an incremental parsing strategy (Nivre, 2008). We propose to extend this model to define a complete incremental NLP parser that integrates six tasks: tokenization, POS tagging, morpholo"
2021.iwpt-1.3,C12-1059,0,0.0337806,"tape. 4 The training process of a RM is close to TBP training. It starts with a dependency tree that is decomposed into a sequence of (state, configuration, action) triples, by a static oracle. The difference with TBP is that the set of actions is considerably larger since it encompasses actions for all six tasks. This sequence is used to train the classifiers: every classifier receives examples corresponding to the states it is related to. The RM is trained using only correct examples, predicted by the oracle. In order to increase the robustness to error propagation, we use a dynamic oracle (Goldberg and Nivre, 2012) to extract a new set of training examples where the actions applied were the one predicted by the network.3 The RM is therefore trained to predict the next action given potentially incorrect configurations. Four epochs are devoted to the first part of the training process, followed by 26 more epochs in dynamic oracle regime.4 At each epoch, the machine is used to decode the development set, and is saved if its score (mean score across all 6 levels) is the best so far. We used cross entropy as a loss function and Adagrad (Duchi et al., 2011) for optimization. The classifiers used to predict th"
2021.iwpt-1.3,P15-1108,1,0.90889,"owing modules: a parser, for example, does not have to consider different tokenization hypotheses nor different POS tags for a word. Considering all such decisions can lead to a combinatorial explosion problem and yields huge search spaces. The pipe-line architecture nevertheless has its limits. It is well known that some low level decisions (made by early modules of the pipe-line) can benefit from high level ones (made by late modules). Some tokenization decisions, for example, can depend on the syntactic structure of the sentence to parse, such as complex prepositions in French, as noted by Nasr et al. (2015). Likewise, sentence segmentation can depend on syntactic structures, especially when punctuation is absent or unreliable, such as in speech transcriptions. Such top down dependencies cannot be taken into account in a strict pipe-line architecture. But they are arguably less numerous than bottom up dependencies and this is the reason why the pipeline architecture usually yields good results. One aim of this paper is to propose a framework, called the Reading Machine (RM), that is flexible enough to define several patterns for combining different NLP modules and explore different ways to link d"
2021.iwpt-1.3,P12-1110,0,0.0349411,"ctions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointly predict POS tags and the dependency tree,"
2021.iwpt-1.3,K18-2008,0,0.0122697,"ges (what the shared task was mainly about), and did not test whether or not the joint prediction of multiple tasks was improving the performances. Related Work Solving the circular dependencies that exist between parsing and other pre-processing steps, is an active area of research in the parsing literature. The solution that has been mainly investigated consists in jointly performing syntactic parsing and other pre-parsing steps. If we restrict ourselves to recent approaches to dependency parsing, solutions have been proposed both for graph-based parsing (Yan et al., 2020; Lee et al., 2011; Nguyen and Verspoor, 2018; Nasr et al., 2015; Li et al., 2011; Zhang et al., 2015) and transition-based pars27 Our model has the following characteristics that distinguishes it form the approaches cited above. The RM performs simultaneously six NLP tasks with the notable inclusion of sentence segmentation which is almost always pre-processed in parsing systems. The RM allows us to build a machine that is strictly incremental across the six tasks it realizes. There are two reasons for this choice. The first is theoretical, we are interested to know how much information is present in top-down dependencies and whether th"
2021.iwpt-1.3,Q14-1011,0,0.0247891,"ransitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointly predict POS tags and the dependency tree, improving both the accuracy"
2021.iwpt-1.3,W03-3017,0,0.265614,"and observe their behaviour on human data. In this perspective, the RM has already been used for predicting eye-movements during reading: different RM architectures have been compared on their ability to accurately predict fixation time (Dary et al., 2021a,b). In order to illustrate the kind of experiments that can be conducted in such a perspective, we will define and compare machines that model different perceptual fields and measure their influence on an incremental parsing process. Technically, RM is an extension of the transitionbased parsing algorithm (TBP) (Yamada and Matsumoto, 2003; Nivre, 2003). The reason for this choice is mainly that TBP implements an incremental parsing strategy (Nivre, 2008). We propose to extend this model to define a complete incremental NLP parser that integrates six tasks: tokenization, POS tagging, morphological analysis, lemmatization, syntactic parsing and sentence segmentation. RM borrows from TBP the two key notions of Configurations and Actions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic d"
2021.iwpt-1.3,P10-2012,0,0.0155253,"Reading Machine (RM), that is flexible enough to define several patterns for combining different NLP modules and explore different ways to link decisions made by these modules. We use in this paper the RM framework to define and compare several non sequential machines that model top down dependencies. There is another, less immediate, reason for studying non sequential architectures, in link with human cognition. Psycholinguistic studies have shown that human language processing is incremental, i.e., people do not wait to see the entire sentence before they start trying to understand it (see Keller (2010) for more details). Such findings have developed interest in using NLP tools to implement cognitively-plausible models of huThe Reading Machine, is a parsing framework that takes as input raw text and performs six standard NLP tasks: tokenization, POS tagging, morphological analysis, lemmatization, dependency parsing and sentence segmentation. It is built upon Transition Based Parsing, and allows implementing a large number of parsing configurations, among which a fully incremental one. Three case studies are presented to highlight the versatility of the framework. The first one explores wheth"
2021.iwpt-1.3,J08-4003,0,0.0314372,"ting eye-movements during reading: different RM architectures have been compared on their ability to accurately predict fixation time (Dary et al., 2021a,b). In order to illustrate the kind of experiments that can be conducted in such a perspective, we will define and compare machines that model different perceptual fields and measure their influence on an incremental parsing process. Technically, RM is an extension of the transitionbased parsing algorithm (TBP) (Yamada and Matsumoto, 2003; Nivre, 2003). The reason for this choice is mainly that TBP implements an incremental parsing strategy (Nivre, 2008). We propose to extend this model to define a complete incremental NLP parser that integrates six tasks: tokenization, POS tagging, morphological analysis, lemmatization, syntactic parsing and sentence segmentation. RM borrows from TBP the two key notions of Configurations and Actions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syn"
2021.iwpt-1.3,Q16-1023,0,0.0267281,"t describe the four high-level features then give a description of the machines. 5.1 Figure 1. The most complex part of the classifier is the transformation of the configuration into a vector: the input of the MLP. Depending of its feature function, the classifier extracts from the configuration elements that can be of different natures: the current state of the RM, tags or words read from the tapes, characters read from the input tape, previous action present in the history and words from the stack. All these elements are fed to specific Bi-LSTM that produce contextual representations, as in Kiperwasser and Goldberg (2016), that are in turn concatenated in the MLP input layer. All feature values are represented by trainable embeddings of size 128. These embeddings are randomly initialized, except for word embeddings that are pretrained5 exclusively on the train set, in order to produce an embedding for unknown words (using words occurring only once in the train set). The Bi-LSTM that take sequences of these embeddings as input are made of only one layer of size 64. 5 TOK POS Input BLSTM LEM Strategy As mentioned in section 3, the strategy of a RM is the structure of the underlying automaton: its number of state"
2021.iwpt-1.3,P09-1040,0,0.0169927,"ne symbol at a time. They conducted their experiments on Chinese, and were the first to use a neural network architecture using both word and character based embeddings to achieve fully joint prediction of these three tasks. They showed that their joint architecture was competitive with a pipeline architecture for word segmentation and POS tagging, but fell short on parsing. For their participation in the 2018 CoNLL Shared Task (Zeman et al., 2018), Wan et al. (2018) also defined an extension of TBP that is close to ours. It is based on the arc-standard system enriched with a swap transition (Nivre, 2009), and is able to jointly perform word segmentation, POS tagging, morphological tagging and dependency parsing. They showed that such a system could get better scores than the shared task’s baseline, while still being quite far from the top scoring systems. Their paper focuses on low or even zero resources languages (what the shared task was mainly about), and did not test whether or not the joint prediction of multiple tasks was improving the performances. Related Work Solving the circular dependencies that exist between parsing and other pre-processing steps, is an active area of research in"
2021.iwpt-1.3,W04-3250,0,0.190243,"Missing"
2021.iwpt-1.3,D14-1162,0,0.0840264,"Missing"
2021.iwpt-1.3,W17-0412,0,0.0221565,"Missing"
2021.iwpt-1.3,P17-1111,0,0.0121872,"ms syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointly predict POS tags and the dependency tree, improving both the accuracy of tagging and parsing. These systems are not"
2021.iwpt-1.3,K18-2009,0,0.0908929,"We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extended and trained to jointly predict POS tags and the dependency tree, improving both the accuracy of tagging and parsing. These systems are not strictly incrementa"
2021.iwpt-1.3,P11-1089,0,0.0418261,"o resources languages (what the shared task was mainly about), and did not test whether or not the joint prediction of multiple tasks was improving the performances. Related Work Solving the circular dependencies that exist between parsing and other pre-processing steps, is an active area of research in the parsing literature. The solution that has been mainly investigated consists in jointly performing syntactic parsing and other pre-parsing steps. If we restrict ourselves to recent approaches to dependency parsing, solutions have been proposed both for graph-based parsing (Yan et al., 2020; Lee et al., 2011; Nguyen and Verspoor, 2018; Nasr et al., 2015; Li et al., 2011; Zhang et al., 2015) and transition-based pars27 Our model has the following characteristics that distinguishes it form the approaches cited above. The RM performs simultaneously six NLP tasks with the notable inclusion of sentence segmentation which is almost always pre-processed in parsing systems. The RM allows us to build a machine that is strictly incremental across the six tasks it realizes. There are two reasons for this choice. The first is theoretical, we are interested to know how much information is present in top-down"
2021.iwpt-1.3,W03-3023,0,0.101387,"machines that implement them and observe their behaviour on human data. In this perspective, the RM has already been used for predicting eye-movements during reading: different RM architectures have been compared on their ability to accurately predict fixation time (Dary et al., 2021a,b). In order to illustrate the kind of experiments that can be conducted in such a perspective, we will define and compare machines that model different perceptual fields and measure their influence on an incremental parsing process. Technically, RM is an extension of the transitionbased parsing algorithm (TBP) (Yamada and Matsumoto, 2003; Nivre, 2003). The reason for this choice is mainly that TBP implements an incremental parsing strategy (Nivre, 2008). We propose to extend this model to define a complete incremental NLP parser that integrates six tasks: tokenization, POS tagging, morphological analysis, lemmatization, syntactic parsing and sentence segmentation. RM borrows from TBP the two key notions of Configurations and Actions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. Al"
2021.iwpt-1.3,D11-1109,0,0.0266166,"nd did not test whether or not the joint prediction of multiple tasks was improving the performances. Related Work Solving the circular dependencies that exist between parsing and other pre-processing steps, is an active area of research in the parsing literature. The solution that has been mainly investigated consists in jointly performing syntactic parsing and other pre-parsing steps. If we restrict ourselves to recent approaches to dependency parsing, solutions have been proposed both for graph-based parsing (Yan et al., 2020; Lee et al., 2011; Nguyen and Verspoor, 2018; Nasr et al., 2015; Li et al., 2011; Zhang et al., 2015) and transition-based pars27 Our model has the following characteristics that distinguishes it form the approaches cited above. The RM performs simultaneously six NLP tasks with the notable inclusion of sentence segmentation which is almost always pre-processed in parsing systems. The RM allows us to build a machine that is strictly incremental across the six tasks it realizes. There are two reasons for this choice. The first is theoretical, we are interested to know how much information is present in top-down dependencies and whether they can be captured in an incremental"
2021.iwpt-1.3,2020.tacl-1.6,0,0.0209772,"on low or even zero resources languages (what the shared task was mainly about), and did not test whether or not the joint prediction of multiple tasks was improving the performances. Related Work Solving the circular dependencies that exist between parsing and other pre-processing steps, is an active area of research in the parsing literature. The solution that has been mainly investigated consists in jointly performing syntactic parsing and other pre-parsing steps. If we restrict ourselves to recent approaches to dependency parsing, solutions have been proposed both for graph-based parsing (Yan et al., 2020; Lee et al., 2011; Nguyen and Verspoor, 2018; Nasr et al., 2015; Li et al., 2011; Zhang et al., 2015) and transition-based pars27 Our model has the following characteristics that distinguishes it form the approaches cited above. The RM performs simultaneously six NLP tasks with the notable inclusion of sentence segmentation which is almost always pre-processed in parsing systems. The RM allows us to build a machine that is strictly incremental across the six tasks it realizes. There are two reasons for this choice. The first is theoretical, we are interested to know how much information is pr"
2021.iwpt-1.3,D16-1109,0,0.017839,"ation. RM borrows from TBP the two key notions of Configurations and Actions (also called Transitions), as well as a greedy algorithm that performs syntactic parsing. We extend these notions by defining an enriched version of a configuration and a richer set of actions. All linguistic decisions, such as word and sentence boundaries detection, POS tagging, lemmatization and, of course, syntactic parsing are realized by actions that are predicted based on configurations. The RM takes as input raw text and greedily predicts a sequence of actions that perform the six tasks mentioned above. 2 ing (Yoshikawa et al., 2016; Bohnet and Nivre, 2012; Alberti et al., 2015; Hatori et al., 2012; Honnibal and Johnson, 2014; Constant and Nivre, 2016; Kurita et al., 2017; Wan et al., 2018). Solutions to this problem differ vastly for these two approaches, mainly because of the different parsing strategies they adopt. This is why we have decided to restrict ourselves to TBP based papers in the remainder of this section. There have been many propositions to realize simultaneously several linguistic tasks in TBP. Both Bohnet and Nivre (2012) and Alberti et al. (2015), for example, show how a transition system can be extend"
2021.iwpt-1.3,K18-2001,0,0.0341341,"Missing"
2021.iwpt-1.3,N15-1005,0,0.0182411,"hether or not the joint prediction of multiple tasks was improving the performances. Related Work Solving the circular dependencies that exist between parsing and other pre-processing steps, is an active area of research in the parsing literature. The solution that has been mainly investigated consists in jointly performing syntactic parsing and other pre-parsing steps. If we restrict ourselves to recent approaches to dependency parsing, solutions have been proposed both for graph-based parsing (Yan et al., 2020; Lee et al., 2011; Nguyen and Verspoor, 2018; Nasr et al., 2015; Li et al., 2011; Zhang et al., 2015) and transition-based pars27 Our model has the following characteristics that distinguishes it form the approaches cited above. The RM performs simultaneously six NLP tasks with the notable inclusion of sentence segmentation which is almost always pre-processed in parsing systems. The RM allows us to build a machine that is strictly incremental across the six tasks it realizes. There are two reasons for this choice. The first is theoretical, we are interested to know how much information is present in top-down dependencies and whether they can be captured in an incremental setup. The second is"
bazillon-etal-2012-syntactic,N07-1051,0,\N,Missing
bazillon-etal-2012-syntactic,C10-1011,0,\N,Missing
bazillon-etal-2012-syntactic,P05-1012,0,\N,Missing
bazillon-etal-2012-syntactic,D07-1101,0,\N,Missing
bazillon-etal-2012-syntactic,W03-3017,0,\N,Missing
C02-2026,P97-1003,0,0.0133068,"antics One type of Natural Language Understanding (NLU) application is exemplified by the database access problem: the user may type in free source language text, but the NLU component must map this text to a fixed set of actions dictated by the underlying application program. We will call such NLU applications “applicationsemantic NLU”. Other examples of applicationsemantic NLU include interfaces to commandbased applications (such as airline reservation systems), often in the guise of dialog systems. Several general-purpose off-the-shelf (OTS) parsers have become widely available (Lin, 1994; Collins, 1997). For application-semantic NLU, it is possible to use such an OTS parser in conjunction with a post-processor which transfers the output of the parser (be it phrase structure or dependency) to the domain semantics. In addition to mapping the parser output to application semantics, the post-processor often must also “correct” the output of the parser: the parser may be tailored for a particular domain (such as main presents linguistic constructions not found in the original domain (such as questions). It may also be the case that the OTS parser consistently misanalyzes certain lexemes because t"
C02-2026,C94-1079,0,0.0338234,"pecific Semantics One type of Natural Language Understanding (NLU) application is exemplified by the database access problem: the user may type in free source language text, but the NLU component must map this text to a fixed set of actions dictated by the underlying application program. We will call such NLU applications “applicationsemantic NLU”. Other examples of applicationsemantic NLU include interfaces to commandbased applications (such as airline reservation systems), often in the guise of dialog systems. Several general-purpose off-the-shelf (OTS) parsers have become widely available (Lin, 1994; Collins, 1997). For application-semantic NLU, it is possible to use such an OTS parser in conjunction with a post-processor which transfers the output of the parser (be it phrase structure or dependency) to the domain semantics. In addition to mapping the parser output to application semantics, the post-processor often must also “correct” the output of the parser: the parser may be tailored for a particular domain (such as main presents linguistic constructions not found in the original domain (such as questions). It may also be the case that the OTS parser consistently misanalyzes certain l"
C02-2026,W02-2214,1,0.870509,"Missing"
C02-2026,J00-1003,0,0.0131956,"beled by the name of an elementary tree machine by the lexicalized version of that tree machine. Of course, in each iteration, there are many more replacements than in the previous iteration. We use 5 rounds of iteration; obviously, the number of iterations restrict the syntactic complexity (but not the length) of recognized input. However, because we output brackets in the FSTs, we obtain a parse with full syntactic/lexical semantic (i.e., dependency) structure, not a “shallow parse”. This construction is in many ways similar to similar constructions proposed for CFGs, in particular that of (Nederhof, 2000). One difference is that, since we start from TAG, recursion is already factored, and we need not find cycles in the rules of the grammar. 5 Experimental Results We present results in which our classes are defined entirely with respect to syntactic behavior. This is because we do not have available an important corpus annotated with semantics. We train on the Wall Street Journal (WSJ) corpus. We evaluate by taking a list of 205 sentences which are chosen at random from entries to W ORDS E YE made by the developers (who were testing the graphical component using a different parser). Their avera"
C04-1082,J99-2004,0,0.0799316,"Missing"
C04-1082,P95-1039,0,0.060758,"Missing"
C04-1082,A00-1031,0,0.0428662,"hen they do not lead to a complete analysis of the sentence. The parser itself acts, in a sense, as a tagger since, while parsing the sentence, it chooses the right tag among a set of possible tags for each word. The reason why we still need a tagger and don’t let the parser do the job is time and space complexity. Parsers are usually more time and space consuming than taggers and highly ambiguous tags assignments can lead to prohibitive processing time and memory requirements. The tagger described in this paper is based on the standard Hidden Markov Model architecture (Charniak et al., 1993; Brants, 2000). Such taggers assign to a sequence of words W = w1 . . . wn , the part of speech tag sequence Tˆ = tˆ1 . . . tˆn which maximizes the joint probability P (T, W ) where T ranges over all possible tag sequences of length n. The probability P (T, W ) is itself decomposed into a product of 2n probabilities, n lexical probabilities P (wi |ti ) (emission probabilities of the HMM) and n syntactic probabilites (transition probabilities of the HMM). Syntactic probabilities model the probability of the occurrence of tag ti given a history which is the knowledge of the h preceding tags (ti−1 . . . ti−h )"
C04-1082,J93-2004,0,0.0234941,"Missing"
C04-1082,2004.jeptalnrecital-long.10,1,0.820729,"Missing"
C04-1082,tufis-etal-2000-principled,0,0.0505436,"Missing"
C16-1040,abeille-barrier-2004-enriching,0,0.127213,"Missing"
C16-1040,P98-1013,0,0.401614,"ic phenomena such as alternations, control and raising tend to obfuscate the relation between syntax and semantics. In this paper we predict the semantic structure of a sentence using a deeper syntax than what is usually done. This deep syntactic representation abstracts away from purely syntactic phenomena and proposes a structural organization of the sentence that is closer to the semantic representation. Experiments conducted on a French corpus annotated with semantic frames showed that a semantic parser reaches better performances with such a deep syntactic input. 1 Introduction FrameNet (Baker et al., 1998) is an English resource containing a set of inter-related semantic frames, each frame containing a set of semantic roles (frame elements in FrameNet’s terminology). Frames offer semantic generalizations over individual predicates, since different lexical units can evoke the same frame, and semantic roles offer generalizations over syntactic arguments. Hence FrameNet parsing can be viewed as mixing predicate disambiguation and semantic role labelling.1 Although FrameNet is more semantically-oriented than other semantic role labeling resources such as PropBank (Palmer et al., 2005), syntactic in"
C16-1040,W13-4916,0,0.0644053,"Missing"
C16-1040,burchardt-etal-2006-salsa,0,0.0709356,"Missing"
C16-1040,P04-1041,0,0.257367,"Missing"
C16-1040,F12-2024,1,0.849637,"Missing"
C16-1040,candito-etal-2014-developing,1,0.868508,"Missing"
C16-1040,candito-etal-2014-deep,1,0.904832,"Missing"
C16-1040,J14-1002,0,0.278828,"y (Gildea and Hockenmaier, 2003) work shows that using CCG-derived predicate-argument features predicted by a CCG parser improves the identification of core PropBank arguments. Vickrey and Koller (2008) investigate the use of simplified syntactic paths and report a slight improvement when applying transformation rules to simplify phrase-structure parses. As far as FrameNet parsing is concerned, we don’t know of any work using more abstract syntactic input than plain “surface” syntactic trees, whether phrase-structure (Gildea and Jurafsky, 2002) or dependency trees (Johansson and Nugues, 2007; Das et al., 2014). We focus on French, first because of the availability of the afore-mentioned DSR, and second because in the French FrameNet corpus (Djemaa et al., 2016) the annotated semantic roles are restricted to essential arguments. On the contrary, both essential (“core”) and non essential participants are annotated in the English FrameNet, including modifiers such as time, location, purpose etc... But syntactic variation such as syntactic alternations, VP coordination, control etc... does concern primarily the most salient grammatical functions (subject, direct object, indirect object etc...), which a"
C16-1040,L16-1601,1,0.883433,"core PropBank arguments. Vickrey and Koller (2008) investigate the use of simplified syntactic paths and report a slight improvement when applying transformation rules to simplify phrase-structure parses. As far as FrameNet parsing is concerned, we don’t know of any work using more abstract syntactic input than plain “surface” syntactic trees, whether phrase-structure (Gildea and Jurafsky, 2002) or dependency trees (Johansson and Nugues, 2007; Das et al., 2014). We focus on French, first because of the availability of the afore-mentioned DSR, and second because in the French FrameNet corpus (Djemaa et al., 2016) the annotated semantic roles are restricted to essential arguments. On the contrary, both essential (“core”) and non essential participants are annotated in the English FrameNet, including modifiers such as time, location, purpose etc... But syntactic variation such as syntactic alternations, VP coordination, control etc... does concern primarily the most salient grammatical functions (subject, direct object, indirect object etc...), which are typically the ones that essential arguments bear. Hence, neutralizing syntactic variation is expected to have an impact primarily on essential semantic"
C16-1040,W03-1008,0,0.0542579,"ntations (DSR) to refer to surface syntactic trees and deep syntactic graphs. Using abstract syntactic representations as an intermediate representation level between syntax and semantics has been proposed in different theoretical frameworks, such as derived trees of Tree Adjoining Grammars (Joshi and Schabes, 1997) or deep syntactic structures of the Meaning Text Theory (Mel’ˇcuk, 1988). But we only found few works showing, empirically, that using such representations can effectively help predict the semantic roles of predicates.Two of them concern PropBank semantic role labeling. The early (Gildea and Hockenmaier, 2003) work shows that using CCG-derived predicate-argument features predicted by a CCG parser improves the identification of core PropBank arguments. Vickrey and Koller (2008) investigate the use of simplified syntactic paths and report a slight improvement when applying transformation rules to simplify phrase-structure parses. As far as FrameNet parsing is concerned, we don’t know of any work using more abstract syntactic input than plain “surface” syntactic trees, whether phrase-structure (Gildea and Jurafsky, 2002) or dependency trees (Johansson and Nugues, 2007; Das et al., 2014). We focus on F"
C16-1040,J02-3001,0,0.750944,"roles (frame elements in FrameNet’s terminology). Frames offer semantic generalizations over individual predicates, since different lexical units can evoke the same frame, and semantic roles offer generalizations over syntactic arguments. Hence FrameNet parsing can be viewed as mixing predicate disambiguation and semantic role labelling.1 Although FrameNet is more semantically-oriented than other semantic role labeling resources such as PropBank (Palmer et al., 2005), syntactic information has been shown to be decisive for predicting (FrameNet) semantic roles since the early days of the task (Gildea and Jurafsky, 2002). Linking regularities provide the theoretical justification of this result: there exist regularities in how semantic arguments are realized in syntax. Yet it is well known that the mapping from syntactic arguments to semantic ones is not straightforward. First, lexical idiosyncrasies can come into play, for instance the Addressee of communication verbs may correspond to the indirect object for verbs like to say and to the direct object for a verb like to inform. Second, it is also well known that surface syntax exhibits variation that can obfuscate regularities. For instance though the Speake"
C16-1040,hajic-etal-2012-announcing,0,0.071915,"Missing"
C16-1040,J07-3004,0,0.0194536,"additional information is sometimes viewed as pertaining to semantic representations, sometimes retained as still syntactic. English has been the first focus language, along with Czech thanks to the Prague Dependency Treebank (Hajiˇc et al., 2006). For English, several works automatically convert Penn Treebank constituency trees into deeper representations, based on lexicalized grammar formalisms such as LFG, CCG or HPSG. Cahill et al. (2004) automatically construct LFG f-structures from PTB trees, a work adapted for various other languages including French (Schluter and van Genabith, 2008). Hockenmaier and Steedman (2007) extracted a corpus of CCG derivations and dependency structures from the Penn Treebank. These two kinds of deeper representations do capture long distance dependencies, subjects of non finite verbs, argument sharing between coordinated verbs. When compared to the DSRs we use though, the main missing trait is the neutralization of syntactic alternations, which we believe is a major source for the syntactic path normalization effect described in section 2.38 . The Stanford dependencies (SD, De Marneffe and Manning (2008)) constitute another proposal for obtaining dependencies not directly prese"
C16-1040,S07-1048,0,0.0380114,"ntic role labeling. The early (Gildea and Hockenmaier, 2003) work shows that using CCG-derived predicate-argument features predicted by a CCG parser improves the identification of core PropBank arguments. Vickrey and Koller (2008) investigate the use of simplified syntactic paths and report a slight improvement when applying transformation rules to simplify phrase-structure parses. As far as FrameNet parsing is concerned, we don’t know of any work using more abstract syntactic input than plain “surface” syntactic trees, whether phrase-structure (Gildea and Jurafsky, 2002) or dependency trees (Johansson and Nugues, 2007; Das et al., 2014). We focus on French, first because of the availability of the afore-mentioned DSR, and second because in the French FrameNet corpus (Djemaa et al., 2016) the annotated semantic roles are restricted to essential arguments. On the contrary, both essential (“core”) and non essential participants are annotated in the English FrameNet, including modifiers such as time, location, purpose etc... But syntactic variation such as syntactic alternations, VP coordination, control etc... does concern primarily the most salient grammatical functions (subject, direct object, indirect obje"
C16-1040,P11-4015,1,0.84752,"Missing"
C16-1040,S14-2008,0,0.0709768,"Missing"
C16-1040,J05-1004,0,0.168366,"tion FrameNet (Baker et al., 1998) is an English resource containing a set of inter-related semantic frames, each frame containing a set of semantic roles (frame elements in FrameNet’s terminology). Frames offer semantic generalizations over individual predicates, since different lexical units can evoke the same frame, and semantic roles offer generalizations over syntactic arguments. Hence FrameNet parsing can be viewed as mixing predicate disambiguation and semantic role labelling.1 Although FrameNet is more semantically-oriented than other semantic role labeling resources such as PropBank (Palmer et al., 2005), syntactic information has been shown to be decisive for predicting (FrameNet) semantic roles since the early days of the task (Gildea and Jurafsky, 2002). Linking regularities provide the theoretical justification of this result: there exist regularities in how semantic arguments are realized in syntax. Yet it is well known that the mapping from syntactic arguments to semantic ones is not straightforward. First, lexical idiosyncrasies can come into play, for instance the Addressee of communication verbs may correspond to the indirect object for verbs like to say and to the direct object for"
C16-1040,W12-4625,1,0.848471,"Missing"
C16-1040,schluter-van-genabith-2008-treebank,0,0.0725663,"Missing"
C16-1040,P08-1040,0,0.0330744,"and semantics has been proposed in different theoretical frameworks, such as derived trees of Tree Adjoining Grammars (Joshi and Schabes, 1997) or deep syntactic structures of the Meaning Text Theory (Mel’ˇcuk, 1988). But we only found few works showing, empirically, that using such representations can effectively help predict the semantic roles of predicates.Two of them concern PropBank semantic role labeling. The early (Gildea and Hockenmaier, 2003) work shows that using CCG-derived predicate-argument features predicted by a CCG parser improves the identification of core PropBank arguments. Vickrey and Koller (2008) investigate the use of simplified syntactic paths and report a slight improvement when applying transformation rules to simplify phrase-structure parses. As far as FrameNet parsing is concerned, we don’t know of any work using more abstract syntactic input than plain “surface” syntactic trees, whether phrase-structure (Gildea and Jurafsky, 2002) or dependency trees (Johansson and Nugues, 2007; Das et al., 2014). We focus on French, first because of the availability of the afore-mentioned DSR, and second because in the French FrameNet corpus (Djemaa et al., 2016) the annotated semantic roles a"
C16-1040,C98-1013,0,\N,Missing
C98-1102,C96-1058,0,0.0831199,"ime complexity of the algorithm is O(nalalQm~×), where G is the number of ruleFSMs derived from the dependency and LP rules in the g r a m m a r and Qmax is the m a x i m u m number of states in any of the rule-FSMs. 4 A F o r m a l i z a t i o n of PP-Dependency Grammars Recall that in a pseudo-projective tree, we make a distinction between a syntactic governor and a linear governor. A node can bc &quot;lifted&quot; along a lifting path from being a dependent of its syntactic governor to being a dependent of its linear ~This type of parser has been proposed previously. See for example (Lombardi, 1996; Eisner, 1996), who also discuss Early-style parsers for projective dependency grammars. 6We can use pre-computed top-down prediction to limit the number of pairs added. 649 governor, which nmst be an ancestor of the governor. In defining a formal rewriting system for pseudo-projective trees, we will not attempt to model the &quot;lifting&quot; as a transformational step in the derivation. Rather, we will directly derive the &quot;lifted&quot; version of the tree, where a node is dependent of its linear governor. Thus, the derived structure resembles more a unistratal dependency representation like those used by (Hudson, 1990)"
C98-1102,1995.iwpt-1.23,1,0.317064,"Missing"
C98-1102,P97-1043,0,0.102938,"Missing"
C98-1102,P97-1003,0,0.0349333,"sable Non-Projective Dependency Grammar Sylvain Kahane* and Alexis Nasr t and Owen Rambow ~ • T A L A N A Universitfi Paris 7 (sk(~ccr. j u s s i e u . f r ) LIA Universit~ d &apos; A v i g n o n ( a l e x i s . n a s r O l i a , u n i v - a v i g n o n , f r ) ~cCoGenTex, Inc. ( o w e n @ c o g e n t e x . c o m ) 1 Introduction Dependency g r a m m a r has a long tradition in syntactic theory, dating back to at least TesniSre&apos;s work from the thirties. 1 Recently, it has gained renewed attention as empirical methods in parsing are discovering the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly do, but context-free phrasestructure grammars do not. One problem that has posed an impediment to more wide-spread acceptance of dependency grammars is the fact that there is no computationally tractable version of dependency g r a m m a r which is not restricted to projective analyses. However, it is well known that there are some syntactic phenomena (such as wh-movement in English or clitic climbing in Romance) that require nonprojective analyses. In this paper, we present a form of projectivity which we call pseudoprojectivity, and we pr"
C98-1102,C96-2122,0,\N,Missing
D17-1180,P16-1231,0,0.145344,"of 0.826. Table 2 compares this result to past work. The supertagger outperforms all other models besides the Word Vector model. Since this Word Vector model (like the MaxEnt model) is specifically trained for this task, and given that our supertagger is not trained for this particular task, the accuracy is reasonably encouraging. This result suggests that TAG supertagging is a reasonable intermediate level between only resolving PP attachment and conducting full parsing. System Malt (Nivre et al., 2006) MaxEnt (Ratnaparkhi et al., 1994) Word Vector (Belinkov et al., 2014) Parsey McParseface (Andor et al., 2016) BLSTM Supertagger PP Attachment Accuracy 79.7* 81.6* 88.7* 82.3 82.6 Table 2: Various PP attachment results. * denotes the results on a different dataset. 5.3 Parsing Results Parsing results and comparison with prior models are summarized in Tables 3, 4 (Section 00), and 5 (Section 23). From Table 4, we see that the combination of the BLSTM supertagger, MICA chart parser, and the neural network parser achieves state-of-the-art performance, even compared to parsers that make use of lexical information, POS tags, and hand-engineered features. With gold supertags, the neural network parser with"
D17-1180,N09-2047,1,0.730968,"se given a sequence of lexical units motivated Bangalore and Joshi (1999) to decompose the parsing problem into two phases: supertagging, where elementary objects, or supertags, are assigned to each word, and stapling, where these supertags are combined together. They claim that given a perfect supertagger, a parse of a sentence follows from syntactic features provided by the supertags, and therefore, supertagging is “almost parsing.” This claim has been confirmed in subsequent work: it has been shown that the task of parsing given a gold sequence of supertags can achieve high accuracy (TAG: (Bangalore et al., 2009; Chung et al., 2016), CCG: (Lewis et al., 2016)). However, it has also been revealed that the difficulty of supertagging, because of the large set of possible supertags, re1712 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1712–1722 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics sults in inaccuracies that prevent us from effectively utilizing syntactic information provided by the imperfect set of supertags that are assigned. This problem is even more severe for TAG parsing. TAG differs from CCG in hav"
D17-1180,J99-2004,0,0.901854,"n of these units in a derivation could be even more informative for subsequent tasks involving semantic interpretation, translation and the like, which have been the focus of CCG-based work. The elementary units of CCG and TAG (categories for CCG, and elementary trees for TAG) determine a word’s combinatory potential, in a way that is not the case for the usual part-ofspeech tags used in parsing. Indeed, the assignment of elementary objects to the words in a sentence almost determines the possible parse for a sentence. The near uniqueness of a parse given a sequence of lexical units motivated Bangalore and Joshi (1999) to decompose the parsing problem into two phases: supertagging, where elementary objects, or supertags, are assigned to each word, and stapling, where these supertags are combined together. They claim that given a perfect supertagger, a parse of a sentence follows from syntactic features provided by the supertags, and therefore, supertagging is “almost parsing.” This claim has been confirmed in subsequent work: it has been shown that the task of parsing given a gold sequence of supertags can achieve high accuracy (TAG: (Bangalore et al., 2009; Chung et al., 2016), CCG: (Lewis et al., 2016))."
D17-1180,C00-1007,1,0.469077,"G grammar from the WSJ part of the Penn Treebank corpus, resulting in a grammar and derivation trees labeled with the grammar Chen (2001). For example, in Figure 1, t27 is the basic tree for a transitive verb (regulate), while t722 is the tree for a transitive verb which forms an object relative clause with an overt relative pronoun but an empty subject (Figure 2).2 The corpus and grammar were iteratively refined to obtain linguistically plausible derivation trees which could serve 2 Our full grammar is shown at http://mica.lif. univ-mrs.fr/d6.clean2-backup.pdf as input for a generation task (Bangalore and Rambow, 2000). As a result, the dependency structure is similar to Universal Dependency (Nivre et al., 2016), apart from the different treatment of long-distance wh-movement noted above: the primary dependencies are between the core meaningbearing lexical words, while function words (auxiliaries, determiners, complementizers) depend on their lexical head and have no dependents.3 We label verbal argument arcs with deep dependency labels: Subject, Object, and Indirect Object normalized for passive and dative shift. All other arcs are labeled as Adjuncts. This means that our label set is small, but determinin"
D17-1180,Q14-1043,0,0.0502821,"Missing"
D17-1180,D14-1082,0,0.0783022,"1 Figure 4: Shift-Reduce Parser Neural Network Architecture. one supertag into another, allowing the generalization across these contexts. Indeed, as we will show in a later section, the substitution memory embeddings and supertag embeddings turn out to yield interpretable and linguistically sensible structures. Finally, we concatenate the vectors associated with the relevant elements from the stack and buffer into a 2dk dimensional vector and feed it to the network to obtain a probability distribution over the possible transition actions. The architecture is visualized in Figure 4. Following Chen and Manning (2014), we use the cube activation function for the first layer, which could better capture interactions. We, again, optimize the negative loglikelihood in a mini-batch stochastic fashion with the Adam optimization algorithm with l = 0.001 (Kingma and Ba, 2015). With regards to decoding, we consider both greedy parsing as well as a beam search algorithm, where we keep transition action hypotheses at each time step, in the experiments we report below. 4.3 Supertag Input to the Parser We consider three types of supertag inputs to the neural network parser: gold supertags, 1-best supertags from the BLS"
D17-1180,W03-1006,1,0.730571,"d the neural network parser achieves state-of-the-art performance, even compared to parsers that make use of lexical information, POS tags, and hand-engineered features. With gold supertags, the neural network parser with beam size 16 performs slightly better than the chart parser. As shown in Table 5, our supertag-based parser outperforms SyntaxNet (Andor et al., 2016) with the computationally expensive global normalization. This suggests that, besides providing the grammars and linguistic features that can be used in downstream tasks in addition to derivation trees (Semantic Role Labeling: (Chen and Rambow, 2003), Textual Entailments: (Xu et al., 2017)), supertagging also improves parsing performance. 5.4 Learned Vector Representation We motivated the use of embeddings in the parser to encode properties of the supertags and the substitution operations performed on them. We can examine their structure in a way similar to what Mikolov et al. (2013) did for word embeddings by performing analogy tests on the learned supertag embeddings. Consider, for example, the analogy that an elementary tree representing a clause headed by a transitive verb (t27) is to a clause headed by an intransitive verb (t81) as a"
D17-1180,W16-3309,1,0.503636,"exical units motivated Bangalore and Joshi (1999) to decompose the parsing problem into two phases: supertagging, where elementary objects, or supertags, are assigned to each word, and stapling, where these supertags are combined together. They claim that given a perfect supertagger, a parse of a sentence follows from syntactic features provided by the supertags, and therefore, supertagging is “almost parsing.” This claim has been confirmed in subsequent work: it has been shown that the task of parsing given a gold sequence of supertags can achieve high accuracy (TAG: (Bangalore et al., 2009; Chung et al., 2016), CCG: (Lewis et al., 2016)). However, it has also been revealed that the difficulty of supertagging, because of the large set of possible supertags, re1712 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1712–1722 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics sults in inaccuracies that prevent us from effectively utilizing syntactic information provided by the imperfect set of supertags that are assigned. This problem is even more severe for TAG parsing. TAG differs from CCG in having a smaller set of"
D17-1180,P82-1020,0,0.860511,"Missing"
D17-1180,J07-3004,0,0.050816,"anguage Processing, pages 1712–1722 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics sults in inaccuracies that prevent us from effectively utilizing syntactic information provided by the imperfect set of supertags that are assigned. This problem is even more severe for TAG parsing. TAG differs from CCG in having a smaller set of combinatory operations, but a more varied set of elementary objects: the TAG-annotated version of the Penn Treebank that we use (Chen, 2001) includes 4727 distinct supertags (2165 occur once) while the CCG-annotated version (Hockenmaier and Steedman, 2007) includes 1286 distinct supertags (439 occur once). As a result, building a robust, broad-coverage TAG parser has proven difficult. In this work, we show that robust supertaggingbased parsing of TAG is indeed possible by using a dense representation of supertags that is induced using neural networks. In the first half of the paper, we present a neural network supertagger based on a bi-directional LSTM (BLSTM) architecture, inspired by the work of Xu (2015) and Lewis et al. (2016) in CCG, and we make crucial use of synchronized dropout (Gal and Ghahramani, 2016). This supertagger achieves the s"
D17-1180,D15-1169,0,0.109483,"vercomes the drawbacks for statistical models of TAG as compared to CCG parsing, raising the possibility that TAG is a viable alternative for NLP tasks that require the assignment of richer structural descriptions to sentences. 1 R. Thomas McCoy Dept. of Linguistics Yale University richard.mccoy@yale.edu Introduction Recent work has applied Combinatory Categorial Grammar (CCG, Steedman and Baldridge (2011)) to the problem of broad-coverage parsing in order to derive grammatical representations that are sufficiently rich to support tasks requiring deeper representation of a sentence’s meaning (Lewis et al., 2015; Reddy et al., 2016; Nadejde et al., 2017). Yet CCG is only one of a number of mildly context-sensitive grammar formalisms that can provide such rich representations, and each has distinct advantages. In this paper we explore the applicability of another formalism, Tree Adjoining Grammar (TAG, Joshi and Schabes (1997)), to the task of broad-coverage parsing. TAG and CCG share the property of lexicalization: words are associated with elementary units of grammatical structure which are composed during a derivation using one of a small set of operations to produce a parse tree. The task of parsi"
D17-1180,nivre-etal-2006-maltparser,0,0.106193,"our test set of 1951 sentences, 1616 had supertags modifying the correct part of speech, to give an accuracy of 0.826. Table 2 compares this result to past work. The supertagger outperforms all other models besides the Word Vector model. Since this Word Vector model (like the MaxEnt model) is specifically trained for this task, and given that our supertagger is not trained for this particular task, the accuracy is reasonably encouraging. This result suggests that TAG supertagging is a reasonable intermediate level between only resolving PP attachment and conducting full parsing. System Malt (Nivre et al., 2006) MaxEnt (Ratnaparkhi et al., 1994) Word Vector (Belinkov et al., 2014) Parsey McParseface (Andor et al., 2016) BLSTM Supertagger PP Attachment Accuracy 79.7* 81.6* 88.7* 82.3 82.6 Table 2: Various PP attachment results. * denotes the results on a different dataset. 5.3 Parsing Results Parsing results and comparison with prior models are summarized in Tables 3, 4 (Section 00), and 5 (Section 23). From Table 4, we see that the combination of the BLSTM supertagger, MICA chart parser, and the neural network parser achieves state-of-the-art performance, even compared to parsers that make use of lex"
D17-1180,D14-1162,0,0.0808709,"Missing"
D17-1180,W17-6214,1,0.705078,"the-art performance, even compared to parsers that make use of lexical information, POS tags, and hand-engineered features. With gold supertags, the neural network parser with beam size 16 performs slightly better than the chart parser. As shown in Table 5, our supertag-based parser outperforms SyntaxNet (Andor et al., 2016) with the computationally expensive global normalization. This suggests that, besides providing the grammars and linguistic features that can be used in downstream tasks in addition to derivation trees (Semantic Role Labeling: (Chen and Rambow, 2003), Textual Entailments: (Xu et al., 2017)), supertagging also improves parsing performance. 5.4 Learned Vector Representation We motivated the use of embeddings in the parser to encode properties of the supertags and the substitution operations performed on them. We can examine their structure in a way similar to what Mikolov et al. (2013) did for word embeddings by performing analogy tests on the learned supertag embeddings. Consider, for example, the analogy that an elementary tree representing a clause headed by a transitive verb (t27) is to a clause headed by an intransitive verb (t81) as a subject relative clause headed by a tra"
D17-1180,P11-1069,0,0.02522,"l. (2016) in CCG, and we make crucial use of synchronized dropout (Gal and Ghahramani, 2016). This supertagger achieves the stateof-the-art accuracy on the WSJ Penn Treebank. When combined with an existing TAG chart parser (Bangalore et al., 2009), the LSTM-based supertagger already yields state-of-the-art unlabeled and labeled attachment scores. In the second half of the work, we present a shift-reduce parsing model based on a feedforward neural network that makes use of dense supertag embeddings. Although this approach has much in common with the approach to shiftreduce CCG parsing taken by Zhang and Clark (2011), it differs in its additive structures in supertag embeddings. When a CCG operation combines two supertags (categories), it yields a resulting category that is typically distinct from the two that are combined, and CCG shift-reduce parsers (e.g. Xu (2015)) make use of this result to guide subsequent actions. When the resulting category is the same as some lexical category assignment (for example when function application over (SN P )/N P N P yields SN P , the same as an intransitive verb), the parser will benefit from sharing statistics across these contexts. For TAG however, substitution o"
D17-1180,N10-1049,1,0.806749,"sponds to the obligatory addition of an argument, and adjunction is used to add adjuncts, as well as function words to a lexical head. The one exception is the treatment of long distance whmovement in TAG. Here, a matrix clause is represented by a predicative auxiliary tree which is adjoined into the embedded clause, so that the whelement moved from the embedded clause can still be substituted locally into the tree headed by its verb. As a result, the dependency between the matrix and embedded verbs is inverted relative to the 1 For the difference between formal and linguistic dependency, see Rambow (2010). 1713 regulate t27 SUBJ ADJ bill t3 the t1 OBJ which t100 ADJ ADJ pass t722 PREDAUX OBJ SUBJ would t45 emissions t3 ADJ the ADJ failed t119 to t31 bill SUBJ they SUBJ they t29 regulate ADJ ADJ failed OBJ OBJ would emissions OBJ pass ADJ which to Figure 1: TAG derivation tree (left) and closely related dependency tree (right) for The bill, which they failed to pass, would regulate emissions. Substitution edges are labeled SUBJ or OBJ, predicative auxiliary edges are labeled PREDAUX, while all other adjoining edges are labeled ADJ. We use the same edge labels in the dependency tree. The derivat"
D17-1180,H94-1048,0,0.551047,"e in the context of prepositional phrase (PP) attachment ambiguity. Normally, in dependency parsing, PP attachment is resolved by the parser. However, in our case, it can be resolved before parsing, during the supertagging step. This is because the supertags for prepositions vary depending on the type of constituent modified by the PP containing the preposition; for example, t4 is the supertag for a preposition whose PP modifies an NP, while t13 is the supertag for a preposition whose PP modifies a VP. To test how well our supertagger resolves PP attachment ambiguity, we used the dataset from Ratnaparkhi et al. (1994) (derived from the PTB WSJ) to extract a test set of sentences with PPs that are ambiguous between attaching to a VP or to an NP.7 7 We were unable to use the full test set because, in order to run the supertagger on the test set, we had to map the test examples back to their full sentences, but some of those original sentences are no longer available in PTB3. 1718 We then supertagged these sentences and checked whether the supertag for the preposition in the ambiguous PP is a VP modifier or an NP modifier. Of our test set of 1951 sentences, 1616 had supertags modifying the correct part of spe"
D17-1180,Q16-1010,0,0.0921511,"Missing"
D17-1180,W04-2407,0,\N,Missing
D17-1180,D16-1181,0,\N,Missing
D17-1180,L16-1262,0,\N,Missing
D19-5803,D17-1219,0,0.0586191,"Missing"
D19-5803,P18-1177,0,0.0329458,"Missing"
D19-5803,D17-1090,0,0.0502955,"Missing"
D19-5803,W18-0530,0,0.0377572,"Missing"
D19-5803,P98-1013,0,0.564217,"Missing"
D19-5803,W17-2603,0,0.0578148,"Missing"
D19-5803,W18-2605,0,0.203005,"n2 (1) Aix-Marseille Univ, Université de Toulon, CNRS, LIS, Marseille, France (2) Orange Labs, Lannion (1) {first.last}@lis-lab.fr (2) {first.last}@orange.com Abstract previous methods based on linguistic analysis or similarity metrics between questions and segments (Hermann et al., 2015). Recently the use of contextual word embeddings such as BERT (Devlin et al., 2018) or XLNet (Yang et al., 2019) lead to obtain another great increase in performance, reaching human-level performance according to some benchmarks 1 . These large corpora are only available in English, and more recently Chinese (He et al., 2018) but for other languages, such as French, there is no comparable resources and the effort required to collect such a large amount of data is very important, limiting the use of these methods to other languages or other application frameworks. To address this problem, several studies have proposed to generate automatically questions and answers directly from a text document such as Wikipedia pages (Du and Cardie, 2018) in order to build a training corpus for MRC models. One of the issues of such methods is the semantic errors that can occur between questions and answers due to the automatic gen"
D19-5803,L18-1159,1,0.509096,"rame, E is one Frame Element of f and C (for Context) is the set of the other Frame Elements. Given a triplet (F, E, C), questions can be produced for which the answer is E. In the case of the Losing Frame of Figure 1, which has three Frame Elements, three triplets (F, E, C) can be produced : corpus of question/answer pairs to train a question generation model, we will rely on simple patterns based on the semantic annotations of our target corpus. The main originality of this work is to use a large encyclopedic corpus in French annotated with a FrameNet semantic model, the CALOR FRAME corpus (Marzinotto et al., 2018), in order to automatically produce a large amount of semantically-valid pairs of questions and answerspans, the CALOR - QUEST corpus. Using FrameNet annotations for generating an MRC training corpus has a major drawback : the human effort needed to build such resources is arguably bigger than building directly a question/answer corpus such as SQuAD. However we believe this method has several advantages : — firstly corpora with frame-based annotations are available for many languages, even if often of limited sizes ; — secondly frame-based annotation is not linked to a single task such as MRC,"
D19-5803,P14-2053,0,0.0685118,"Missing"
D19-5803,D16-1264,0,0.0910622,"ge corpora. The collect of natural questions is reduced to a validation/test set. We applied this method on the French CALOR - FRAME corpus to develop the CALOR - QUEST resource presented in this paper. 1 Introduction Machine Reading Comprehension (MRC) is a Natural Language Understanding task consisting in retrieving text segments from a document thanks to a set of questions, each segment being an answer to a particular question. This task received a lot of attention in the past few years thanks to the availability of very large corpora of triplets (document, question, answer) such as SQuAD (Rajpurkar et al., 2016) or MS MARCO (Nguyen et al., 2016), each containing more than 100k triplets. In these corpora each question has been manually produced, either through crowd-sourcing or by collecting query logs from a search engine. These large corpora opened the door to the development of supervised machine learning approaches for MRC, mostly based on Deep Neural Network (Wang and Jiang, 2016; Seo et al., 2016), improving greatly the state-of-the-art over 1. https ://rajpurkar.github.io/SQuAD-explorer/ 19 Proceedings of the Second Workshop on Machine Reading for Question Answering, pages 19–26 c Hong Kong, Ch"
D19-5803,P16-1056,0,0.048778,"Missing"
F13-1029,P06-1086,1,0.854793,"Missing"
F13-1029,W05-0703,1,0.865443,"Missing"
F13-1029,J00-1006,0,0.0708705,"Missing"
F13-1029,W07-0801,0,0.0371678,"Missing"
I11-1007,P08-2045,0,0.0237054,"Data will issue (event2 ) about 3.6 million shares; last Monday (time1 ), the company had (event3 ) nearly 73 million shares outstanding.”, taken from document wsj 0541 of TimeBank (Pustejovsky et al., 2003), there are two temporal relations between pairs (event1 , event2 ) and (time1 , event3 ). The task of a temporal relation extraction system is to automatically tag these pairs with relations BEFORE and INCLUDES, respectively. Several researchers have focused on temporal relation learning (Chklovski and Pantel, 2005; Lapata and Lascarides, 2006; Bethard et al., 2007; Chambers et al., 2007; Bethard and Martin, 2008; Mirroshandel and Ghassem-Sani, 2010; Puscasu, 2007) among which SVM has shown good performances. In this section, we describe two of the most successful SVM-based methods. Inderjeet Mani was the first to propose an SVMbased temporal relation classification model which is based on a linear kernel (Mani et al., 2006). His system (referred to as (kM ani )) uses five temporal attributes that have been tagged in the standard corpora (Pustejovsky et al., 2003) plus the string of words that constitute the events, as well as their part of part of speech tags. The other successful SVM-based temporal"
I11-1007,P07-2044,0,0.0991669,") to common, Automatic Data will issue (event2 ) about 3.6 million shares; last Monday (time1 ), the company had (event3 ) nearly 73 million shares outstanding.”, taken from document wsj 0541 of TimeBank (Pustejovsky et al., 2003), there are two temporal relations between pairs (event1 , event2 ) and (time1 , event3 ). The task of a temporal relation extraction system is to automatically tag these pairs with relations BEFORE and INCLUDES, respectively. Several researchers have focused on temporal relation learning (Chklovski and Pantel, 2005; Lapata and Lascarides, 2006; Bethard et al., 2007; Chambers et al., 2007; Bethard and Martin, 2008; Mirroshandel and Ghassem-Sani, 2010; Puscasu, 2007) among which SVM has shown good performances. In this section, we describe two of the most successful SVM-based methods. Inderjeet Mani was the first to propose an SVMbased temporal relation classification model which is based on a linear kernel (Mani et al., 2006). His system (referred to as (kM ani )) uses five temporal attributes that have been tagged in the standard corpora (Pustejovsky et al., 2003) plus the string of words that constitute the events, as well as their part of part of speech tags. The other succ"
I11-1007,I05-1069,0,0.0248059,"mporally links x1 to x2 . For example in “If all the debt is converted (event1 ) to common, Automatic Data will issue (event2 ) about 3.6 million shares; last Monday (time1 ), the company had (event3 ) nearly 73 million shares outstanding.”, taken from document wsj 0541 of TimeBank (Pustejovsky et al., 2003), there are two temporal relations between pairs (event1 , event2 ) and (time1 , event3 ). The task of a temporal relation extraction system is to automatically tag these pairs with relations BEFORE and INCLUDES, respectively. Several researchers have focused on temporal relation learning (Chklovski and Pantel, 2005; Lapata and Lascarides, 2006; Bethard et al., 2007; Chambers et al., 2007; Bethard and Martin, 2008; Mirroshandel and Ghassem-Sani, 2010; Puscasu, 2007) among which SVM has shown good performances. In this section, we describe two of the most successful SVM-based methods. Inderjeet Mani was the first to propose an SVMbased temporal relation classification model which is based on a linear kernel (Mani et al., 2006). His system (referred to as (kM ani )) uses five temporal attributes that have been tagged in the standard corpora (Pustejovsky et al., 2003) plus the string of words that constitut"
I11-1007,P06-1095,0,0.365838,"r example in “If all the debt is converted (event1 ) to common, Automatic Data will issue (event2 ) about 3.6 million shares; last Monday (time1 ), the company had (event3 ) nearly 73 million shares outstanding.”, taken from document wsj 0541 of TimeBank (Pustejovsky et al., 2003), there are two temporal relations between pairs (event1 , event2 ) and (time1 , event3 ). The task of a temporal relation extraction system is to automatically tag these pairs with relations BEFORE and INCLUDES, respectively. Several researchers have focused on temporal relation learning (Chklovski and Pantel, 2005; Lapata and Lascarides, 2006; Bethard et al., 2007; Chambers et al., 2007; Bethard and Martin, 2008; Mirroshandel and Ghassem-Sani, 2010; Puscasu, 2007) among which SVM has shown good performances. In this section, we describe two of the most successful SVM-based methods. Inderjeet Mani was the first to propose an SVMbased temporal relation classification model which is based on a linear kernel (Mani et al., 2006). His system (referred to as (kM ani )) uses five temporal attributes that have been tagged in the standard corpora (Pustejovsky et al., 2003) plus the string of words that constitute the events, as well as thei"
I11-1007,S07-1108,0,0.0278743,"(time1 ), the company had (event3 ) nearly 73 million shares outstanding.”, taken from document wsj 0541 of TimeBank (Pustejovsky et al., 2003), there are two temporal relations between pairs (event1 , event2 ) and (time1 , event3 ). The task of a temporal relation extraction system is to automatically tag these pairs with relations BEFORE and INCLUDES, respectively. Several researchers have focused on temporal relation learning (Chklovski and Pantel, 2005; Lapata and Lascarides, 2006; Bethard et al., 2007; Chambers et al., 2007; Bethard and Martin, 2008; Mirroshandel and Ghassem-Sani, 2010; Puscasu, 2007) among which SVM has shown good performances. In this section, we describe two of the most successful SVM-based methods. Inderjeet Mani was the first to propose an SVMbased temporal relation classification model which is based on a linear kernel (Mani et al., 2006). His system (referred to as (kM ani )) uses five temporal attributes that have been tagged in the standard corpora (Pustejovsky et al., 2003) plus the string of words that constitute the events, as well as their part of part of speech tags. The other successful SVM-based temporal classification method uses a polynomial convolution t"
I11-1007,D08-1112,0,0.207908,"In the active learning framework, the learner has control over choosing the instances that will constitute the training set. A typical active learning algorithm begins with a small number of annotated data, and selects one or more informative instances from a large set of unlabeled instances, named the pool. The chosen instance(s) are then labeled and added to other annotated data, and the model is updated with this new information. These steps are repeated until at least one termination condition is satisfied. While there have been numerous applications of active learning to NLP researches (Settles and Craven, 2008; Xu et al., 2007), it has not been applied, to our knowledge, to temporal relation classification. This paper presents a novel active learning strategy for SVM-based classification algorithm. The proposed algorithm considers three measures: uncertainty, representativeness, and diversity to select the instances that will be annotated. The method we propose is generic, it could be applied to any SVM based classification problem. Temporal relation classification has been selected, in this paper, for illustration purpose. Our experiments show that state-of-the-art results can be reproduced with a"
J16-1002,N07-1049,0,0.19655,"of speech tags and lemmas. Bechet and Nasr (2009), for example, represent LSCs as finite-state automata that are matched on S. This method has a tendency to over-generate and proposes some very unlikely instantiations. In order to constrain the instantiation process, some syntax can be used. For example, LSCs can be matched on a set T of possible parses of S in order to produce I. The set T itself can be the k-best parses produced by a parser, as in parse reranking (Collins and Koo 2005; Charniak and Johnson 2005). It can also be built using parse correction techniques (Hall and Nov´ak 2005; Attardi and Ciaramita 2007; Henestroza and Candito 2011). In the latter approach, a parse tree T of S is first built, using a parser, and parse correction rules are applied on it in order to build other parses that might correct errors of T. The solution that we propose uses a parser to produce a list T = {T1 , . . . , Tk } of kbest parses, such as in parse reranking. But this list is merged into a set of dependencies Dk that is the union of all the dependencies appearing in the k-best trees. The set Dk is not a tree because a single word can have several governors. This set can be seen as a superset of the k-best pars"
J16-1002,P11-1070,0,0.0180803,"y beyond the aim of this article. The dominant approach for extracting lexical cooccurrences, as described, for example, in Volk (2001), Nakov and Hearst (2005), Pitler et al. (2010), and Zhou et al. (2011) directly model word co-occurrences on word strings. Co-occurrences of pairs of words are first collected on raw corpora or n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of word co-occurrences is generally very simple: It is either based on the direct adjacency of the words in the string or their co-occurrence in a window of a few words. Bansal and Klein (2011) and Nakov and Hearst (2005) rely on the same sort of techniques but use more sophisticated patterns, based on simple paraphrase rules, for identifying co-occurrences. Our work departs from these approaches by extracting co-occurences in specific lexicosyntactic contexts that correspond to our SC patterns. Our approach allows us to extract more fine-grained phenomena but, being based on automatically parsed data, it is more error-prone. Extracting SFs for verbs from raw data has also been an active direction of research for a long time, dating back at least to the work of Brent (1991) and Mann"
J16-1002,J04-4004,0,0.0650612,"tructures of different sizes. 56 Mirroshandel and Nasr Integrating Selection and Subcategorization in a Dependency Parser The second difference between parsing and patching is the data sets that were used to train them. The parser is trained on a standard treebank whereas the patching model is trained on a raw corpus that is several orders of magnitude larger. The reason for this difference comes from the fact that high-order factors used to model SFs and SCs contain up to three lexical elements and cannot be accurately modeled using available treebanks. It has been shown by Gildea (2001) and Bikel (2004) that bilexical dependencies of the Collins parser (Collins 1997) have a very limited impact on the performances of the parser, although they were supposed to play a key role for some important ambiguous syntactic attachments. The reason for this is that treebanks are not large enough to correctly model bilexical dependencies. We show in Sections 7.2 and 8.2 that current treebanks are much too limited in size to accurately model SCs and SFs. Other solutions have been proposed in the literature in order to combine local and global syntactic phenomena in a parser. Parse reranking is one of them."
J16-1002,C10-1011,0,0.0308948,"constraint because this element only occurs in the set Ui0 and will not conflict with any element of another set Uk0 with k 6= i. 70 Mirroshandel and Nasr Integrating Selection and Subcategorization in a Dependency Parser We have decided not to devote specific sections to the processes of patching and parsing under constraints. Patching has been described in full in Section 3. The ILP solver we have used is SCIP (Achterberg 2009). Parsing under constraints has been described in section 2.2. 6.1 Parser The parser used for our experiments is the second-order graph-based parser implementation of Bohnet (2010). We have extended the decoding part of the parser in order to implement constrained parsing and k-best parses generation. The first-order extension is based on algorithm 3 of Huang and Chiang (2005), and the second-order extension relies on a non-optimal greedy search algorithm. The parser uses the 101 feature templates, described in Table 4 of Bohnet (2010). Each feature template describes the governor and dependent of a labeled dependency, called the target dependency, as well as some features of its neighborhood. Every feature is associated with a score, computed on a treebank. A parse tre"
J16-1002,W09-3818,1,0.892166,"Missing"
J16-1002,P91-1027,0,0.344759,"nsal and Klein (2011) and Nakov and Hearst (2005) rely on the same sort of techniques but use more sophisticated patterns, based on simple paraphrase rules, for identifying co-occurrences. Our work departs from these approaches by extracting co-occurences in specific lexicosyntactic contexts that correspond to our SC patterns. Our approach allows us to extract more fine-grained phenomena but, being based on automatically parsed data, it is more error-prone. Extracting SFs for verbs from raw data has also been an active direction of research for a long time, dating back at least to the work of Brent (1991) and Manning (1993). More recently, Messiant et al. (2008) proposed such a system for French verbs. The method we use for extracting SF is not novel with respect to such work. Our aim was not to devise new extraction techniques, but merely to evaluate the resource produced by such techniques for statistical parsing. 6.3 Candidate Generation The candidate generation process has as input a sentence S and a set L of SCs and SFs. It produces the set I made of instantiations of elements of L on S. This set constitues ˆ The candidate generation the input of the ILP solver that will produce the solut"
J16-1002,2009.jeptalnrecital-long.4,0,0.123097,"Missing"
J16-1002,P05-1022,0,0.576729,"y were supposed to play a key role for some important ambiguous syntactic attachments. The reason for this is that treebanks are not large enough to correctly model bilexical dependencies. We show in Sections 7.2 and 8.2 that current treebanks are much too limited in size to accurately model SCs and SFs. Other solutions have been proposed in the literature in order to combine local and global syntactic phenomena in a parser. Parse reranking is one of them. The idea is to produce the n-best parses for a sentence and rerank them using higher order features, such as in Collins and Koo (2005) and Charniak and Johnson (2005). This solution has the advantage of drastically limiting the search space of the high-order search algorithm to the k best parses. Although the parsing architecture we propose in this article does use k-best parse lists, our solution allows us to combine dependencies that appear in any of the parses of the list. We show in Section 6.3 that combining dependencies that appear in any parse of a k-best list can yield parses that are more accurate than the best parse of this k-best list. Our method is closer to forest rescoring (Huang and Chiang 2007) or forest reranking (Huang 2008). Another solu"
J16-1002,J90-1003,0,0.089217,"ing: sSC (C, lr , ll ) = 1 2  C(C, lr , ll ) C(C, lr , ll ) + C(C, lr , ∗ ) C(C, ∗, ll )  where C(C, l, ∗ ) (respectively, C(C, ∗, l)) is the number of occurrences of configuration C with lemma l as a root (respectively, leaf) and C(C, lr , ll ) is the number of occurrences of configuration C with lemma lr as a root and lemma ll as a leaf, simultaneously. 64 Mirroshandel and Nasr Integrating Selection and Subcategorization in a Dependency Parser This function takes its values between 0 (lr and ll never co-occur) and 1 (lr and ll always co-occur). It is close to pointwise mutual information (Church and Hanks 1990) but takes its values between 0 and 1. 3.4.1 Selecting the Optimal Set of Selectional Constraints. Given a sentence S of length N and the set I 0 of Instantiated Selectional Constraints (ISCs) over S, the selection of the optimal set Iˆ0 ⊆ I 0 is framed as the following ILP program. r – – r – Definition of the variables j j γi = 1 if word number i is the root of ISC number j, and γi = 0 otherwise. j j δi if word number i is the leaf of ISC number j, and δi = 0 otherwise. Definition of the constraints a word cannot be the leaf of more than one ISC ∀i ∈ {1, . . . N} X j δi ≤ 1 j ∈I 0 – for an IS"
J16-1002,P97-1003,0,0.572184,"ng Selection and Subcategorization in a Dependency Parser The second difference between parsing and patching is the data sets that were used to train them. The parser is trained on a standard treebank whereas the patching model is trained on a raw corpus that is several orders of magnitude larger. The reason for this difference comes from the fact that high-order factors used to model SFs and SCs contain up to three lexical elements and cannot be accurately modeled using available treebanks. It has been shown by Gildea (2001) and Bikel (2004) that bilexical dependencies of the Collins parser (Collins 1997) have a very limited impact on the performances of the parser, although they were supposed to play a key role for some important ambiguous syntactic attachments. The reason for this is that treebanks are not large enough to correctly model bilexical dependencies. We show in Sections 7.2 and 8.2 that current treebanks are much too limited in size to accurately model SCs and SFs. Other solutions have been proposed in the literature in order to combine local and global syntactic phenomena in a parser. Parse reranking is one of them. The idea is to produce the n-best parses for a sentence and rera"
J16-1002,J05-1003,0,0.372921,"of the parser, although they were supposed to play a key role for some important ambiguous syntactic attachments. The reason for this is that treebanks are not large enough to correctly model bilexical dependencies. We show in Sections 7.2 and 8.2 that current treebanks are much too limited in size to accurately model SCs and SFs. Other solutions have been proposed in the literature in order to combine local and global syntactic phenomena in a parser. Parse reranking is one of them. The idea is to produce the n-best parses for a sentence and rerank them using higher order features, such as in Collins and Koo (2005) and Charniak and Johnson (2005). This solution has the advantage of drastically limiting the search space of the high-order search algorithm to the k best parses. Although the parsing architecture we propose in this article does use k-best parse lists, our solution allows us to combine dependencies that appear in any of the parses of the list. We show in Section 6.3 that combining dependencies that appear in any parse of a k-best list can yield parses that are more accurate than the best parse of this k-best list. Our method is closer to forest rescoring (Huang and Chiang 2007) or forest rera"
J16-1002,C96-1058,0,0.0864957,"Missing"
J16-1002,W01-0521,0,0.139429,"aints defined on structures of different sizes. 56 Mirroshandel and Nasr Integrating Selection and Subcategorization in a Dependency Parser The second difference between parsing and patching is the data sets that were used to train them. The parser is trained on a standard treebank whereas the patching model is trained on a raw corpus that is several orders of magnitude larger. The reason for this difference comes from the fact that high-order factors used to model SFs and SCs contain up to three lexical elements and cannot be accurately modeled using available treebanks. It has been shown by Gildea (2001) and Bikel (2004) that bilexical dependencies of the Collins parser (Collins 1997) have a very limited impact on the performances of the parser, although they were supposed to play a key role for some important ambiguous syntactic attachments. The reason for this is that treebanks are not large enough to correctly model bilexical dependencies. We show in Sections 7.2 and 8.2 that current treebanks are much too limited in size to accurately model SCs and SFs. Other solutions have been proposed in the literature in order to combine local and global syntactic phenomena in a parser. Parse rerankin"
J16-1002,W05-1505,0,0.456675,"Missing"
J16-1002,D11-1113,0,0.295452,"Bechet and Nasr (2009), for example, represent LSCs as finite-state automata that are matched on S. This method has a tendency to over-generate and proposes some very unlikely instantiations. In order to constrain the instantiation process, some syntax can be used. For example, LSCs can be matched on a set T of possible parses of S in order to produce I. The set T itself can be the k-best parses produced by a parser, as in parse reranking (Collins and Koo 2005; Charniak and Johnson 2005). It can also be built using parse correction techniques (Hall and Nov´ak 2005; Attardi and Ciaramita 2007; Henestroza and Candito 2011). In the latter approach, a parse tree T of S is first built, using a parser, and parse correction rules are applied on it in order to build other parses that might correct errors of T. The solution that we propose uses a parser to produce a list T = {T1 , . . . , Tk } of kbest parses, such as in parse reranking. But this list is merged into a set of dependencies Dk that is the union of all the dependencies appearing in the k-best trees. The set Dk is not a tree because a single word can have several governors. This set can be seen as a superset of the k-best parses. We will call this method s"
J16-1002,W05-1506,0,0.0438603,"orization in a Dependency Parser We have decided not to devote specific sections to the processes of patching and parsing under constraints. Patching has been described in full in Section 3. The ILP solver we have used is SCIP (Achterberg 2009). Parsing under constraints has been described in section 2.2. 6.1 Parser The parser used for our experiments is the second-order graph-based parser implementation of Bohnet (2010). We have extended the decoding part of the parser in order to implement constrained parsing and k-best parses generation. The first-order extension is based on algorithm 3 of Huang and Chiang (2005), and the second-order extension relies on a non-optimal greedy search algorithm. The parser uses the 101 feature templates, described in Table 4 of Bohnet (2010). Each feature template describes the governor and dependent of a labeled dependency, called the target dependency, as well as some features of its neighborhood. Every feature is associated with a score, computed on a treebank. A parse tree score is defined as the sum of the features it contains and the parser looks for the parse tree with the highest score. Feature templates are divided into six sets: Standard Feature Templates are t"
J16-1002,P08-1067,0,0.0358564,"arniak and Johnson (2005). This solution has the advantage of drastically limiting the search space of the high-order search algorithm to the k best parses. Although the parsing architecture we propose in this article does use k-best parse lists, our solution allows us to combine dependencies that appear in any of the parses of the list. We show in Section 6.3 that combining dependencies that appear in any parse of a k-best list can yield parses that are more accurate than the best parse of this k-best list. Our method is closer to forest rescoring (Huang and Chiang 2007) or forest reranking (Huang 2008). Another solution to combine local and global decisions is to represent the local and the global constraints as a single ILP program. This solution is possible because dependency parsing can be framed as an ILP program. Riedel and Clarke (2006) propose a formulation of nonprojective dependency parsing as an ILP program. This program, however, requires an exponential number of variables. Martins, Smith, and Xing (2009) propose a more concise formulation that only requires a polynomial number of variables and constraints. Martins, Almeida, and Smith (2013) propose extending the model to third-o"
J16-1002,P07-1019,0,0.0307599,"es, such as in Collins and Koo (2005) and Charniak and Johnson (2005). This solution has the advantage of drastically limiting the search space of the high-order search algorithm to the k best parses. Although the parsing architecture we propose in this article does use k-best parse lists, our solution allows us to combine dependencies that appear in any of the parses of the list. We show in Section 6.3 that combining dependencies that appear in any parse of a k-best list can yield parses that are more accurate than the best parse of this k-best list. Our method is closer to forest rescoring (Huang and Chiang 2007) or forest reranking (Huang 2008). Another solution to combine local and global decisions is to represent the local and the global constraints as a single ILP program. This solution is possible because dependency parsing can be framed as an ILP program. Riedel and Clarke (2006) propose a formulation of nonprojective dependency parsing as an ILP program. This program, however, requires an exponential number of variables. Martins, Smith, and Xing (2009) propose a more concise formulation that only requires a polynomial number of variables and constraints. Martins, Almeida, and Smith (2013) propo"
J16-1002,D10-1002,0,0.0345377,"Missing"
J16-1002,J04-3001,0,0.0379395,"tain threshold and by Rush and Petrov (2012) in their multi-pass, coarse-to-fine approach. 2.3 Confidence Measure The other extension of graph-based parsers that we use in this work is the computation of confidence measures on the output of the parser. The confidence measure used is based on the estimation of posterior probability of a subtree, computed on the k-best list of parses of a sentence. It is very close to confidence measures used for speech recognition (Wessel et al. 2001) and differs from confidence measures used for parsing, such as S´anchez-S´aez, S´anchez, and Bened´ı (2009) or Hwa (2004), which compute confidence measures for complete parses of a sentence. Given the k-best parses of a sentence and a subtree ∆ present in at least one of the k-best parses, let C(∆ ) be the number of occurrences of ∆ in the k-best parse set. Then CM(∆ ), the confidence measure associated with ∆, is computed as: CM(∆ ) = C(∆ ) k 59 Computational Linguistics Volume 42, Number 1 Mirroshandel and Nasr (2011) and Mirroshandel, Nasr, and Roux (2012) provide more detail on the performance of this measure. Other confidence measures could be used, such as the edge expectation described in McDonald and Sa"
J16-1002,P10-1001,0,0.135158,"1996; McDonald and Pereira 2006), in which our study takes place. The basic first-order model makes an extreme choice with respect to the domain of locality by limiting it to one dependency (the score of a tree is the sum of the scores of its dependencies). Second-order models slightly extend the factor sizes to second-order patterns that include a dependency adjacent to the target dependency. It has been shown experimentally that second-order models perform better than first-order ones, which tends to prove that second-order factors do capture important syntactic regularities. More recently, Koo and Collins (2010) proposed extending factor size to three dependencies and showed that such models yield better accuracy than second-order models on the same data. However, extending the order of the models has a high computational cost because the number of factors to be considered in a sentence grows exponentially with the order of the model. Using such models in a Dynamic Programming framework, such as Eisner (1996), becomes quickly intractable in terms of processing time and memory requirements. Additionally, by reliably estimating the scores of such factors we are quickly confronted with the problem of da"
J16-1002,J93-2004,0,0.055019,"Missing"
J16-1002,P13-2109,0,0.046441,"Missing"
J16-1002,P09-1039,0,0.0763554,"Missing"
J16-1002,P05-1012,0,0.190303,"Missing"
J16-1002,W07-2216,0,0.0304145,") or Hwa (2004), which compute confidence measures for complete parses of a sentence. Given the k-best parses of a sentence and a subtree ∆ present in at least one of the k-best parses, let C(∆ ) be the number of occurrences of ∆ in the k-best parse set. Then CM(∆ ), the confidence measure associated with ∆, is computed as: CM(∆ ) = C(∆ ) k 59 Computational Linguistics Volume 42, Number 1 Mirroshandel and Nasr (2011) and Mirroshandel, Nasr, and Roux (2012) provide more detail on the performance of this measure. Other confidence measures could be used, such as the edge expectation described in McDonald and Satta (2007), or insideoutside probabilities. 3. Patching In this section, we introduce the process of patching a sentence. The general idea of patching sentence S is to detect in S the occurrences of predefined configurations. In section 3.1 we introduce Lexico-Syntactic Configurations, which correspond to the patches. We describe in section 3.2 the process of selecting an optimal set of patches on a sentence (finding an optimal solution is not trivial since patches have scores and some patches are incompatible). Sections 3.3 and 3.4, respectively, describe two instances of the patching problem, namely,"
J16-1002,E06-1011,0,0.113783,"Missing"
J16-1002,messiant-etal-2008-lexschem,0,0.0306632,") rely on the same sort of techniques but use more sophisticated patterns, based on simple paraphrase rules, for identifying co-occurrences. Our work departs from these approaches by extracting co-occurences in specific lexicosyntactic contexts that correspond to our SC patterns. Our approach allows us to extract more fine-grained phenomena but, being based on automatically parsed data, it is more error-prone. Extracting SFs for verbs from raw data has also been an active direction of research for a long time, dating back at least to the work of Brent (1991) and Manning (1993). More recently, Messiant et al. (2008) proposed such a system for French verbs. The method we use for extracting SF is not novel with respect to such work. Our aim was not to devise new extraction techniques, but merely to evaluate the resource produced by such techniques for statistical parsing. 6.3 Candidate Generation The candidate generation process has as input a sentence S and a set L of SCs and SFs. It produces the set I made of instantiations of elements of L on S. This set constitues ˆ The candidate generation the input of the ILP solver that will produce the solution I. 72 Mirroshandel and Nasr Integrating Selection and"
J16-1002,W11-2917,1,0.844652,"a sentence. It is very close to confidence measures used for speech recognition (Wessel et al. 2001) and differs from confidence measures used for parsing, such as S´anchez-S´aez, S´anchez, and Bened´ı (2009) or Hwa (2004), which compute confidence measures for complete parses of a sentence. Given the k-best parses of a sentence and a subtree ∆ present in at least one of the k-best parses, let C(∆ ) be the number of occurrences of ∆ in the k-best parse set. Then CM(∆ ), the confidence measure associated with ∆, is computed as: CM(∆ ) = C(∆ ) k 59 Computational Linguistics Volume 42, Number 1 Mirroshandel and Nasr (2011) and Mirroshandel, Nasr, and Roux (2012) provide more detail on the performance of this measure. Other confidence measures could be used, such as the edge expectation described in McDonald and Satta (2007), or insideoutside probabilities. 3. Patching In this section, we introduce the process of patching a sentence. The general idea of patching sentence S is to detect in S the occurrences of predefined configurations. In section 3.1 we introduce Lexico-Syntactic Configurations, which correspond to the patches. We describe in section 3.2 the process of selecting an optimal set of patches on a se"
J16-1002,P12-1082,1,0.932083,"Missing"
J16-1002,N13-1024,1,0.92541,"Missing"
J16-1002,H05-1105,0,0.0335314,"pplied on the parses, using unification, in order to produce SCs and SFs along with their number of occurrences. These numbers are used to compute selectional constraints scores (sSC ), as defined in Section 3.4, and subcategorization frame scores (sSF ) as described in Section 3.3. The extraction of lexical co-occurrences from raw data has been a very active direction of research for many years. Giving an exhaustive description of this body of work is clearly beyond the aim of this article. The dominant approach for extracting lexical cooccurrences, as described, for example, in Volk (2001), Nakov and Hearst (2005), Pitler et al. (2010), and Zhou et al. (2011) directly model word co-occurrences on word strings. Co-occurrences of pairs of words are first collected on raw corpora or n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of word co-occurrences is generally very simple: It is either based on the direct adjacency of the words in the string or their co-occurrence in a window of a few words. Bansal and Klein (2011) and Nakov and Hearst (2005) rely on the same sort of techniques but use more sophisticated patterns, based on simple paraphrase rules, f"
J16-1002,W12-3018,0,0.0225987,"Missing"
J16-1002,P11-4015,1,0.858638,"Missing"
J16-1002,C10-1100,0,0.0241441,"ng unification, in order to produce SCs and SFs along with their number of occurrences. These numbers are used to compute selectional constraints scores (sSC ), as defined in Section 3.4, and subcategorization frame scores (sSF ) as described in Section 3.3. The extraction of lexical co-occurrences from raw data has been a very active direction of research for many years. Giving an exhaustive description of this body of work is clearly beyond the aim of this article. The dominant approach for extracting lexical cooccurrences, as described, for example, in Volk (2001), Nakov and Hearst (2005), Pitler et al. (2010), and Zhou et al. (2011) directly model word co-occurrences on word strings. Co-occurrences of pairs of words are first collected on raw corpora or n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of word co-occurrences is generally very simple: It is either based on the direct adjacency of the words in the string or their co-occurrence in a window of a few words. Bansal and Klein (2011) and Nakov and Hearst (2005) rely on the same sort of techniques but use more sophisticated patterns, based on simple paraphrase rules, for identifying co-occu"
J16-1002,W06-1616,0,0.0985108,"Missing"
J16-1002,N12-1054,0,0.053926,"Missing"
J16-1002,R09-1070,0,0.0586346,"Missing"
J16-1002,P11-1156,0,0.0414482,"Missing"
J16-1002,H91-1067,0,\N,Missing
J16-1002,P08-3010,0,\N,Missing
J16-1002,P93-1032,0,\N,Missing
L16-1363,P14-1070,0,0.0147402,"ation of DeQue takes place in the context of the development of a statistical dependency parser for French (Nasr et al., 2011). The need to quantify ambiguity has a practical consequence: unambiguous constructions can be included in the lexicon as frozen multiword tokens, while ambiguous ones need to be annotated and dealt with at parsing time. One way of disambiguating ambiguous multiword units is to keep the tokens as individual lexical units during tokenisation and POS tagging, and then use special syntactic dependencies to indicate the presence of a CPRE or a CCONJ (McDonald et al., 2013; Candito and Constant, 2014; Green et al., 2013). In previous experiments, we demonstrated that this approach is superior to treating all units systematically as words with spaces (Nasr et al., 2015). However, this was only demonstrated for a small set of 8 CCONJs and 4 determiners in French. The present work substantially extends the coverage of the list of potentially ambiguous constructions that can be modelled using that approach. In the remainder of this paper, we discuss the general properties and syntactic behaviour of prepositions and constructions in French (§ 2.). Then, we present the criteria (§ 3.) and metho"
L16-1363,J13-1009,0,0.0691578,"Missing"
L16-1363,P13-2017,0,0.0245369,"wrong analysis. The creation of DeQue takes place in the context of the development of a statistical dependency parser for French (Nasr et al., 2011). The need to quantify ambiguity has a practical consequence: unambiguous constructions can be included in the lexicon as frozen multiword tokens, while ambiguous ones need to be annotated and dealt with at parsing time. One way of disambiguating ambiguous multiword units is to keep the tokens as individual lexical units during tokenisation and POS tagging, and then use special syntactic dependencies to indicate the presence of a CPRE or a CCONJ (McDonald et al., 2013; Candito and Constant, 2014; Green et al., 2013). In previous experiments, we demonstrated that this approach is superior to treating all units systematically as words with spaces (Nasr et al., 2015). However, this was only demonstrated for a small set of 8 CCONJs and 4 determiners in French. The present work substantially extends the coverage of the list of potentially ambiguous constructions that can be modelled using that approach. In the remainder of this paper, we discuss the general properties and syntactic behaviour of prepositions and constructions in French (§ 2.). Then, we present t"
L16-1363,P11-4015,1,0.75139,"ches in French. A simplistic approach such as treating all occurrences of bien que as a single word with spaces inside would introduce an error for sentences like example 2. Conversely, ignoring it in example 1 would mean that both words are treated independently, not capturing the fact that the whole behaves like a conjunction. And what is more, these errors would be propagated to the following processing steps like POS tagging and parsing, certainly generating a wrong analysis. The creation of DeQue takes place in the context of the development of a statistical dependency parser for French (Nasr et al., 2011). The need to quantify ambiguity has a practical consequence: unambiguous constructions can be included in the lexicon as frozen multiword tokens, while ambiguous ones need to be annotated and dealt with at parsing time. One way of disambiguating ambiguous multiword units is to keep the tokens as individual lexical units during tokenisation and POS tagging, and then use special syntactic dependencies to indicate the presence of a CPRE or a CCONJ (McDonald et al., 2013; Candito and Constant, 2014; Green et al., 2013). In previous experiments, we demonstrated that this approach is superior to tr"
L16-1363,P15-1108,1,0.900374,"Missing"
L16-1363,sagot-2010-lefff,0,0.198248,"and complex conjunctions (CCONJ) are two types of function words that consist of more than one orthographic word (Piot, 1993). They can be considered as fixed multiword expressions that allow little or no variability. Examples in English include CCONJs even though, as well as and CPREs up to and in front of. Examples in French are shown in Table 1 along with their English (EN) meaningful and literal translations. CPRE and CCONJ constructions are quite frequent in French. Their linguistic description in the literature is generally limited to building comprehensive lists of such constructions (Sagot, 2010). Most authors assume that these constructions allow no or very little variability (inflection, insertion). Therefore, they would not require a very sophisticated description and representation in machine-readable lexicons and NLP systems, such as the ones required for verbs, for instance (Dubois and Dubois-Charlier, 2004). An aspect which is often neglected is the segmentation and structural ambiguity that arises when the words composing the complex function word co-occur by pure chance. Consider examples 1 and 2 containing the French CCONJ bien que. It is composed by the words bien (well) an"
L18-1014,W15-4319,0,0.0354559,"Missing"
L18-1014,W16-3916,0,0.0119843,"ng Error Correction 1. Introduction is commonly expected. The typology of errors is slightly different and most recent works focus on one-to-one lexical errors (replacing one word by another). The availability of large corpora has led to the design of normalization lexicons (Han et al., 2012) that directly map correct words to there common ill-formed variants. (Sridhar, 2015) learns a normalization lexicon and converts it into a Finite State Transducer. More recently, the construction of normalization dictionaries using word embeddings on Twitter texts were performed for Brazilian Portuguese (Bertaglia and Nunes, 2016). In this paper, we focus on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text, several approaches have proposed to use word clusters provided by hierarchical clustering approaches such as the Brown algorithm. (Owoputi et al., 2013) use word clusters along with dedicated lexical features to enrich their tagger in the context"
L18-1014,W14-4012,0,0.0307382,"Missing"
L18-1014,R13-1026,0,0.0263471,"on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text, several approaches have proposed to use word clusters provided by hierarchical clustering approaches such as the Brown algorithm. (Owoputi et al., 2013) use word clusters along with dedicated lexical features to enrich their tagger in the context of online conversations. (Derczynski et al., 2013) use clustering approaches to handle linguistic noise, and train their system from a mixture of hand-annotated tweets and existing POS-labeled data. (Nasr et al., 2016) address the issue of training data mismatch in the context of online conversations and show that equivalent performance can be obtained by training on a small in domain corpus rather than using generic POS-labeled resources. Contact Center chat conversation is a particular type of noisy user generated text in the sense that it is a formal Computer Mediated Communication (CMC) interaction mode. It shares some normalization issue"
L18-1014,D12-1039,0,0.0312327,"es the remaining errors. Word embeddings are trained on a large corpus in order to address both normalization and POS tagging. Experiments are run on Contact Center chat conversations, a particular type of formal Computer Mediated Communication data. Keywords: Part of Speech Tagging, Computer Mediated Communication, Spelling Error Correction 1. Introduction is commonly expected. The typology of errors is slightly different and most recent works focus on one-to-one lexical errors (replacing one word by another). The availability of large corpora has led to the design of normalization lexicons (Han et al., 2012) that directly map correct words to there common ill-formed variants. (Sridhar, 2015) learns a normalization lexicon and converts it into a Finite State Transducer. More recently, the construction of normalization dictionaries using word embeddings on Twitter texts were performed for Brazilian Portuguese (Bertaglia and Nunes, 2016). In this paper, we focus on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to"
L18-1014,D12-1000,0,0.199842,"Missing"
L18-1014,P13-1155,0,0.0229557,"plying the corrector with the lower case lexicon described in 3.1. The original case is reintroduced before applying the POS tagger. The lexical corrector provides a list of candidates for correction, until a maximum cost is reach. This upper bound is proportional to the word length n in terms of number of letters and is computed as follows: max cost = n × γ In these experiments γ is set to 0.3. Here again contrastive experiments can be provided showing the impact of the γ parameter. As we are dealing with formal interactions,we did not apply the modification on the edit distance proposed by (Hassan and Menezes, 2013) where edit distance is computed on consonant skeletons, nor do we use Longest Common Subsequence Ratio (LCSR) as it didn’t reveal to be helpful in our case. 3.3. Cemb (w, αi (w)) = C(w, αi (w)) × demb (w, αi (w)) 4. The part of speech tagger used in our experiment is based on Gated Recurrent Units (GRU). GRUs, introduced by (Cho et al., 2014), are recurrent neural networks that work in a similar fashion than LSTMs. GRUs are simpler than LSTMs: they do not have an output gate, and the input and forget gates are merged into an update gate. This property allows GRUs to be computationally more ef"
L18-1014,C08-1056,1,0.761051,"deviations in the design of the tagger. We will show that a good compromise is to handle some of the errors through lexical normalization but also to design a robust POS tagger that handles orthographic errors. We propose to use word embeddings at both levels: for text normalization and for POS tagging. 2. Related work Text normalization has been studied for several years now, with different perspectives over time. When studying SMS style language, researchers tried to handle new phenomena including voluntary slang shortcuts through phonetic models of pronunciation (Toutanova and Moore, 2002; Kobus et al., 2008). Recently, the effort has been more particularly set on Social Media text normalization with specific challenges on Twitter texts (Baldwin et al., 2015), which has been shown to be more formal (Hu et al., 2013) that what 3. Text normalization Our text normalization process operates in two steps, the first one produces in-lexicon variants for an out of lexicon form. The second one reranks the forms produced by the first step, using a distributional distance. The first step is based on a lexicon and an edit distance while the second relies on word embeddings. We focus on one-to-one normalizatio"
L18-1014,W16-3621,1,0.929075,"ted representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text, several approaches have proposed to use word clusters provided by hierarchical clustering approaches such as the Brown algorithm. (Owoputi et al., 2013) use word clusters along with dedicated lexical features to enrich their tagger in the context of online conversations. (Derczynski et al., 2013) use clustering approaches to handle linguistic noise, and train their system from a mixture of hand-annotated tweets and existing POS-labeled data. (Nasr et al., 2016) address the issue of training data mismatch in the context of online conversations and show that equivalent performance can be obtained by training on a small in domain corpus rather than using generic POS-labeled resources. Contact Center chat conversation is a particular type of noisy user generated text in the sense that it is a formal Computer Mediated Communication (CMC) interaction mode. It shares some normalization issues with other CMC texts such as chatroom conversations or social media interactions but unlike the aforementioned cases, the professional context implies some specificit"
L18-1014,N13-1039,0,0.0795164,"Missing"
L18-1014,sagot-2010-lefff,0,0.0253431,"ir associated morphological and lexical features. The words are encoded using a lookup table which associates each word with its word embedding representation. These word embeddings can be initialized with pretrained embeddings and/or learned when training the model. For the morphological and typographic features, we use a boolean value for the presence of an uppercase character as the first letter of the word as well as the word suffixes of length 3 and 4 represented as onehot vectors. Finally, we also input as onehot vectors external lexicon information, constructed using the Lefff lexicon (Sagot, 2010). Such vectors represent the possible part-of-speech labels of a word. On the output layer, we use a softmax activation. During training, categorical Rescoring with word embeddings The edit distance based variant generation process described above does not take into account the context of a word when generating variants. In order to take it into 1 Part of speech tagging https://github.com/Orange-OpenSource/lexical-corrector 89 cross-entropy is used as the loss function and the Adam optimiser (Kingma and Ba, 2014) is used for the gradient descent optimisation. 5. # of correctable err. # of non"
L18-1014,W15-1502,0,0.014803,"ss both normalization and POS tagging. Experiments are run on Contact Center chat conversations, a particular type of formal Computer Mediated Communication data. Keywords: Part of Speech Tagging, Computer Mediated Communication, Spelling Error Correction 1. Introduction is commonly expected. The typology of errors is slightly different and most recent works focus on one-to-one lexical errors (replacing one word by another). The availability of large corpora has led to the design of normalization lexicons (Han et al., 2012) that directly map correct words to there common ill-formed variants. (Sridhar, 2015) learns a normalization lexicon and converts it into a Finite State Transducer. More recently, the construction of normalization dictionaries using word embeddings on Twitter texts were performed for Brazilian Portuguese (Bertaglia and Nunes, 2016). In this paper, we focus on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text,"
L18-1014,P02-1019,0,0.072417,"directly handling language deviations in the design of the tagger. We will show that a good compromise is to handle some of the errors through lexical normalization but also to design a robust POS tagger that handles orthographic errors. We propose to use word embeddings at both levels: for text normalization and for POS tagging. 2. Related work Text normalization has been studied for several years now, with different perspectives over time. When studying SMS style language, researchers tried to handle new phenomena including voluntary slang shortcuts through phonetic models of pronunciation (Toutanova and Moore, 2002; Kobus et al., 2008). Recently, the effort has been more particularly set on Social Media text normalization with specific challenges on Twitter texts (Baldwin et al., 2015), which has been shown to be more formal (Hu et al., 2013) that what 3. Text normalization Our text normalization process operates in two steps, the first one produces in-lexicon variants for an out of lexicon form. The second one reranks the forms produced by the first step, using a distributional distance. The first step is based on a lexicon and an edit distance while the second relies on word embeddings. We focus on on"
L18-1159,P98-1013,0,0.900593,"rated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The models compared are CRFs and multitasks bi-LSTMs. Keywords: Frame Semantic Parsing, LSTM, CRF 1. Introduction Semantic Frame parsing is a Natural Language Understanding task that involves detecting in a sentence an event or a scenario, called Frame, as well as all the elements or roles that can be associated to this event in the sentence, called Frame Elements. One of the most popular semantic frame model is the Berkeley FrameNet project developed by ICSI Berkeley (Baker et al., 1998). This model is composed of an inventory of Frames with, for each of them, a list of words, called Lexical Units (or LU), that can trigger a frame in a sentence. Besides, for each frame, a list of Frame Elements (FE), core or optional, is defined. LUs are pairings of a word with a sense; Frame Elements are the components of a frame, represented by sequences of words in a sentence. Two kinds of parsing can be done with a Semantic Frame model: full text parsing where each word in a sentence is analyzed to check if it can trigger a frame; and partial parsing where only a subset of frames and LUs"
L18-1159,candito-etal-2014-developing,0,0.0449117,"Missing"
L18-1159,P14-1136,0,0.159427,"CRF relatively small, limited to the frames that can be triggered by the word considered. Therefore the ambiguity is limited and CRFs can be trained efficiently even with a large number of features. However the drawback is that the training data is split across words in the LU lexicon, therefore similarities among LU are not exploited. This situation is acceptable if enough training examples are provided for each LUs, which is the case for the CALOR corpus. 4.2. Multi-task LSTM approach Deep Neural Networks (DNN) with word embedding is the state of the art approach for semantic frame parsing (Hermann et al., 2014). More recently recurrent neural networks (RNN) with Long Short Memory (LSTM) cells have been applied to several semantic tagging tasks such as slot filling (Mesnil et al., 2015) or even frame parsing (Hakkani-T¨ur et al., 2016; Tafforeau et al., 2016) for Spoken Language Understanding. Following these previous works, we propose in this study a single-layered bidirectional LSTM sequence to sequence architecture to perform frame tagging. To deal with the multi-label issue we could train a biLSTM model per LU, using the same approach as for the CRF, however, the number of examples per LU is redu"
L18-1159,W03-0430,0,0.0251963,"he absolute value of these links is not meaningful and cannot be predicted the same way as the semantic labels are. In this study we compare two different strategies in order to deal with the multi-label issue, one based on CRF with a multi-model approach (each LU has its own prediction model) and one based on a bi-LSTM model following a multi-task approach. They are described in the next section. 4. 4.1. Sequence labeling models Multi-model CRF approach CRF-based approaches have been used in many NLP tasks involving sequence labeling such as POS tagging, chunking or named entity recognition (McCallum and Li, 2003). In order to apply CRF to frame parsing, as described in section 3., we need to address the multi-label issue. Since we want to perform frame disambiguation and semantic role detection in one step, and because each word in a sentence cannot trigger more than one frame, we chose a multimodel approach where a CRF-model is trained for each word belonging to the LU lexicon. This approach is described in Figure 3. At training time, the corpus is split according to the LU lexicon: to each word Wi belonging to this lexicon is attached a sub-corpus containing all the sentences CWi where Wi occurs. Fo"
L18-1159,P11-4015,1,0.681968,"Missing"
L18-1716,D11-1113,0,0.0240604,"Missing"
L18-1716,N07-1049,0,0.0621939,"Missing"
L18-1716,W16-3210,0,0.0493476,"Missing"
L18-1716,W05-1505,0,0.0831543,"Missing"
L18-1716,P11-4015,1,0.873913,"Missing"
L18-1716,Q14-1006,0,0.0432872,"age is described with five captions, each annotated with entities. Entities that corefer with a visual element in the image are linked to the corresponding bounding box. Finally, for every preposition manually attached, a set of possible attachment alternatives for use in a reranking system is produced. 2. Enriching the Flickr30k Entities Corpus with PP-Attachment Annotations Corpora with joint annotation of image and text has recently become widely available. The corpus used in this work is the Flickr30k Entities (F30kE) (Plummer et al., 2017), an extension of the original Flickr30k dataset (Young et al., 2014). This corpus is composed of almost 32K images and, for each image, five captions describing the image have been produced. Besides, every object in the image that corresponds to a mention in the captions has been manually identified with a bounding box. 4520 Preposition in with for near through on next to from into over by at of around in front of under behind along during across down against outside towards out of beside above in the middle of onto outside of inside between past toward on top of like among after away from off up up to before atop about along with underneath without out at the"
N09-2047,J99-2004,1,0.793606,"A returns n-best parses for arbitrary n; parse trees are associated with probabilities. A packed forest can also be returned. • MICA is freely available2 , easy to install under Linux, and easy to use. (Input is one sentence per line with no special tokenization required.) There is an enormous amount of related work, and we can mention only the most salient, given space constraints. Our parser is very similar to the work of (Shen and Joshi, 2005). They do not employ a supertagging step, and we do not restrict our trees to spinal projections. Other parsers using supertagging include the LDA of Bangalore and Joshi (1999), the CCG-based parser of Clark and Curran (2004), and the constraint-based approach of Wang 2 http://www1.ccls.columbia.edu/˜rambow/mica.html Proceedings of NAACL HLT 2009: Short Papers, pages 185–188, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics and Harper (2004). Widely used dependency parsers which generate deep dependency representations include Minipar (Lin, 1994), which uses a declarative grammar, and the Stanford parser (Levy and Manning, 2004), which performs a conversion from a standard phrase-structure parse. All of these systems generate dependency"
N09-2047,W07-2213,1,0.853249,"d by a dependency extractor that relies on the TIG structure of the CFG. The Earley-like parser relies on Earley’s algorithm (Earley, 1970). However, several optimizations have been applied, including guiding techniques (Boullier, 2003), extensive static (offline) computations over the grammar, and efficient data structures. Moreover, Earley’s algorithm has been extended so as to handle input DAGs (and not only sequences of forms). A particular effort has been made to handle huge grammars (over 1 million symbol occurrences in the grammar), thanks to advanced dynamic lexicalization techniques (Boullier and Sagot, 2007). The resulting efficiency is satisfying: with standard ambiguous NLP grammars, huge shared parse forest (over 1010 trees) are often generated in a few dozens of milliseconds. Within MICA, the first module that is applied on top of the shared parse forest is S YNTAX’s n-best module. This module adapts and implements the algorithm of (Huang and Chiang, 2005) for efficient n-best trees extraction from a shared parse forest. In practice, and within the current version of MICA, this module is usually used with n = 1, which identifies the optimal tree w.r.t. the probabilistic model embedded in the"
N09-2047,W03-3005,1,0.86506,"et of the symbols are specialized. 4 Parser S YNTAX (Boullier and Deschamp, 1988) is a system used to generate lexical and syntactic analyzers (parsers) (both deterministic and non-deterministic) for all kind of context-free grammars (CFGs) as well as some classes of contextual grammars. It has been under development at INRIA for several decades. S YNTAX handles most classes of deterministic (unambiguous) grammars (LR, LALR, RLR) as well as general context-free grammars. The non-deterministic features include, among others, an Earley-like parser generator used for natural language processing (Boullier, 2003). Like most S YNTAX Earley-like parsers, the architecture of MICA’s PCFG-based parser is the following: • The Earley-like parser proper computes a shared parse forest that represents in a factorized (polynomial) way all possible parse trees according to the underlying (non-probabilistic) CFG that represents the TIG; • Filtering and/or decoration modules are applied on the shared parse forest; in MICA’s case, an nbest module is applied, followed by a dependency extractor that relies on the TIG structure of the CFG. The Earley-like parser relies on Earley’s algorithm (Earley, 1970). However, sev"
N09-2047,P04-1014,0,0.0349589,"are associated with probabilities. A packed forest can also be returned. • MICA is freely available2 , easy to install under Linux, and easy to use. (Input is one sentence per line with no special tokenization required.) There is an enormous amount of related work, and we can mention only the most salient, given space constraints. Our parser is very similar to the work of (Shen and Joshi, 2005). They do not employ a supertagging step, and we do not restrict our trees to spinal projections. Other parsers using supertagging include the LDA of Bangalore and Joshi (1999), the CCG-based parser of Clark and Curran (2004), and the constraint-based approach of Wang 2 http://www1.ccls.columbia.edu/˜rambow/mica.html Proceedings of NAACL HLT 2009: Short Papers, pages 185–188, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics and Harper (2004). Widely used dependency parsers which generate deep dependency representations include Minipar (Lin, 1994), which uses a declarative grammar, and the Stanford parser (Levy and Manning, 2004), which performs a conversion from a standard phrase-structure parse. All of these systems generate dependency structures which are slightly different from MIC"
N09-2047,P81-1022,0,0.788449,"processing (Boullier, 2003). Like most S YNTAX Earley-like parsers, the architecture of MICA’s PCFG-based parser is the following: • The Earley-like parser proper computes a shared parse forest that represents in a factorized (polynomial) way all possible parse trees according to the underlying (non-probabilistic) CFG that represents the TIG; • Filtering and/or decoration modules are applied on the shared parse forest; in MICA’s case, an nbest module is applied, followed by a dependency extractor that relies on the TIG structure of the CFG. The Earley-like parser relies on Earley’s algorithm (Earley, 1970). However, several optimizations have been applied, including guiding techniques (Boullier, 2003), extensive static (offline) computations over the grammar, and efficient data structures. Moreover, Earley’s algorithm has been extended so as to handle input DAGs (and not only sequences of forms). A particular effort has been made to handle huge grammars (over 1 million symbol occurrences in the grammar), thanks to advanced dynamic lexicalization techniques (Boullier and Sagot, 2007). The resulting efficiency is satisfying: with standard ambiguous NLP grammars, huge shared parse forest (over 101"
N09-2047,W05-1506,0,0.0313205,"een extended so as to handle input DAGs (and not only sequences of forms). A particular effort has been made to handle huge grammars (over 1 million symbol occurrences in the grammar), thanks to advanced dynamic lexicalization techniques (Boullier and Sagot, 2007). The resulting efficiency is satisfying: with standard ambiguous NLP grammars, huge shared parse forest (over 1010 trees) are often generated in a few dozens of milliseconds. Within MICA, the first module that is applied on top of the shared parse forest is S YNTAX’s n-best module. This module adapts and implements the algorithm of (Huang and Chiang, 2005) for efficient n-best trees extraction from a shared parse forest. In practice, and within the current version of MICA, this module is usually used with n = 1, which identifies the optimal tree w.r.t. the probabilistic model embedded in the original PCFG; other values can also be used. Once the n-best trees have been extracted, the dependency extractor module transforms each of these trees into a dependency tree, by exploiting the fact that the CFG used for parsing has been built from a TIG. 5 Evaluation We compare MICA to the MALT parser. Both parsers are trained on sections 02-21 of our depe"
N09-2047,P04-1042,0,0.0251422,"nd we do not restrict our trees to spinal projections. Other parsers using supertagging include the LDA of Bangalore and Joshi (1999), the CCG-based parser of Clark and Curran (2004), and the constraint-based approach of Wang 2 http://www1.ccls.columbia.edu/˜rambow/mica.html Proceedings of NAACL HLT 2009: Short Papers, pages 185–188, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics and Harper (2004). Widely used dependency parsers which generate deep dependency representations include Minipar (Lin, 1994), which uses a declarative grammar, and the Stanford parser (Levy and Manning, 2004), which performs a conversion from a standard phrase-structure parse. All of these systems generate dependency structures which are slightly different from MICA’s, so that direct comparison is difficult. For comparison purposes, we therefore use the MALT parser generator (Nivre et al., 2004), which allows us to train a dependency parser on our own dependency structures. MALT has been among the top performers in the CoNLL dependency parsing competitions. 2 Supertags and Supertagging Supertags are elementary trees of a lexicalized tree grammar such as a Tree-Adjoining Grammar (TAG) (Joshi, 1987)"
N09-2047,C94-1079,0,0.0973378,"rk of (Shen and Joshi, 2005). They do not employ a supertagging step, and we do not restrict our trees to spinal projections. Other parsers using supertagging include the LDA of Bangalore and Joshi (1999), the CCG-based parser of Clark and Curran (2004), and the constraint-based approach of Wang 2 http://www1.ccls.columbia.edu/˜rambow/mica.html Proceedings of NAACL HLT 2009: Short Papers, pages 185–188, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics and Harper (2004). Widely used dependency parsers which generate deep dependency representations include Minipar (Lin, 1994), which uses a declarative grammar, and the Stanford parser (Levy and Manning, 2004), which performs a conversion from a standard phrase-structure parse. All of these systems generate dependency structures which are slightly different from MICA’s, so that direct comparison is difficult. For comparison purposes, we therefore use the MALT parser generator (Nivre et al., 2004), which allows us to train a dependency parser on our own dependency structures. MALT has been among the top performers in the CoNLL dependency parsing competitions. 2 Supertags and Supertagging Supertags are elementary tree"
N09-2047,W04-2407,0,0.102365,"Missing"
N09-2047,J94-1004,0,0.118342,"es anchored by Xl from the symbol Xl∗ . No adjunction, the first adjunction, and the second adjunction are modeled explicitly in the grammar and the associated probabilistic model, while the third and all subsequent adjunctions are modeled together. This conversion method is basically the same as that presented in (Schabes and Waters, 1995), except that our PCFG models multiple adjunctions at the same node by positions (a concern Schabes and Waters (1995) do not share, of course). Our PCFG construction differs from that of Hwa (2001) in that she does not allow multiple adjunction at one node (Schabes and Shieber, 1994) (which we do since we are interested in the derivation structure as a representation of linguistic dependency). For more information about the positional model of adjunction and a discussion of an alternate model, the “bigram model”, see (Nasr and Rambow, 2006). Tree tdi from Section 2 gives rise to the following rule (where tdi and tCO are terminal symbols and the rest are nonterminals): S → S∗l NP VP∗l Vl∗ tdi Vr∗ NP PP∗l P∗l tCO P∗r NP PP∗r VP∗r S∗r The probabilities of the PCFG rules are estimated using maximum likelihood. The probabilistic model refers only to supertag names, not to word"
N09-2047,H05-1102,0,0.0299565,"which derives the syntactic structure from the n-best chosen supertags. Only the supertagger uses lexical information, the parser only sees the supertag hypotheses. • MICA returns n-best parses for arbitrary n; parse trees are associated with probabilities. A packed forest can also be returned. • MICA is freely available2 , easy to install under Linux, and easy to use. (Input is one sentence per line with no special tokenization required.) There is an enormous amount of related work, and we can mention only the most salient, given space constraints. Our parser is very similar to the work of (Shen and Joshi, 2005). They do not employ a supertagging step, and we do not restrict our trees to spinal projections. Other parsers using supertagging include the LDA of Bangalore and Joshi (1999), the CCG-based parser of Clark and Curran (2004), and the constraint-based approach of Wang 2 http://www1.ccls.columbia.edu/˜rambow/mica.html Proceedings of NAACL HLT 2009: Short Papers, pages 185–188, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics and Harper (2004). Widely used dependency parsers which generate deep dependency representations include Minipar (Lin, 1994), which uses a dec"
N09-2047,W04-0307,0,0.115845,"Missing"
N13-1024,P05-1038,0,0.0275125,"a major issue in the design of syntactic formalisms in the eighties and nineties. Unification grammars, such as Lexical Functional Grammars (Bresnan, 1982), Generalized Phrase Structure Grammars (Gazdar et al., 1985) and Head-driven Phrase Structure Grammars (Pollard and Sag, 1994), made SF part of the grammar. Tree Adjoining Grammars (Joshi et al., 1975) proposed to extend the domain of locality of Context Free Grammars partly in order to be able to represent SF in a generative grammar. More recently, (Collins, 1997) proposed a way to introduce SF in a probabilistic context free grammar and (Arun and Keller, 2005) used the same technique for French. (Carroll et al., 1998), used subcategorization probabilities for ranking trees generated by unification-based phrasal grammar and (Zeman, 2002) showed that using frame frequency in a dependency parser can lead to a significant improvement of the performance of the parser. The main novelties of the work presented here is (1) the way a new parse is built by combining subparses that appear in the n best parse list and (2) the use of three very different resources that list the possible SF for verbs. 240 The organization of the paper is the following: in sectio"
N13-1024,P91-1027,0,0.756275,"Missing"
N13-1024,2009.jeptalnrecital-long.4,0,0.376303,"Missing"
N13-1024,W98-1114,0,0.490937,"ighties and nineties. Unification grammars, such as Lexical Functional Grammars (Bresnan, 1982), Generalized Phrase Structure Grammars (Gazdar et al., 1985) and Head-driven Phrase Structure Grammars (Pollard and Sag, 1994), made SF part of the grammar. Tree Adjoining Grammars (Joshi et al., 1975) proposed to extend the domain of locality of Context Free Grammars partly in order to be able to represent SF in a generative grammar. More recently, (Collins, 1997) proposed a way to introduce SF in a probabilistic context free grammar and (Arun and Keller, 2005) used the same technique for French. (Carroll et al., 1998), used subcategorization probabilities for ranking trees generated by unification-based phrasal grammar and (Zeman, 2002) showed that using frame frequency in a dependency parser can lead to a significant improvement of the performance of the parser. The main novelties of the work presented here is (1) the way a new parse is built by combining subparses that appear in the n best parse list and (2) the use of three very different resources that list the possible SF for verbs. 240 The organization of the paper is the following: in section 2, we will briefly describe the parsing model that we wil"
N13-1024,P05-1022,0,0.64006,"the nature of the task itself. The first one is the availability of treebanks such as the Penn Treebank (Marcus et al., 1993) or the French Treebank (Abeill´e et al., 2003), which have been used in the parsing community to train stochastic parsers, such as (Collins, 1997; Petrov and Klein, 2008). Such work remained rooted in the classical language theoretic tradition of parsing, generally based on variants of generative context free grammars. The second change occurred with the use of discriminative machine learning techniques, first to rerank the output of a stochastic parser (Collins, 2000; Charniak and Johnson, 2005) and then in the parser itself (Ratnaparkhi, 1999; Nivre et al., 2007; McDonald et al., 2005a). Such parsers clearly depart from classical parsers in the sense that they do not rely anymore on a generative grammar: given a sentence S, all possible parses for S 1 are considered as possible parses of S. A parse tree is seen as a set of lexico-syntactic features which are associated to weights. The score of a parse is computed as the sum of the weights of its features. This new generation of parsers allows to reach high accuracy but possess their own limitations. We will focus in this paper on on"
N13-1024,P97-1003,0,0.538724,"an n best list in order to build a new parse. Taking into account SF in a parser has been a major issue in the design of syntactic formalisms in the eighties and nineties. Unification grammars, such as Lexical Functional Grammars (Bresnan, 1982), Generalized Phrase Structure Grammars (Gazdar et al., 1985) and Head-driven Phrase Structure Grammars (Pollard and Sag, 1994), made SF part of the grammar. Tree Adjoining Grammars (Joshi et al., 1975) proposed to extend the domain of locality of Context Free Grammars partly in order to be able to represent SF in a generative grammar. More recently, (Collins, 1997) proposed a way to introduce SF in a probabilistic context free grammar and (Arun and Keller, 2005) used the same technique for French. (Carroll et al., 1998), used subcategorization probabilities for ranking trees generated by unification-based phrasal grammar and (Zeman, 2002) showed that using frame frequency in a dependency parser can lead to a significant improvement of the performance of the parser. The main novelties of the work presented here is (1) the way a new parse is built by combining subparses that appear in the n best parse list and (2) the use of three very different resources"
N13-1024,2010.jeptalnrecital-long.3,1,0.734837,"atically computed Subcat Frames The extraction procedure described above has been used to extract ASF from an automatically parsed corpus. The corpus is actually a collection of three corpora of slightly different genres. The first one is a collection of news reports of the French press agency Agence France Presse, the second is a collection of newspaper articles from a local French newspaper : l’Est R´epublicain. The third one is a collection of articles from the French Wikipedia. The size of the different corpora are detailed in table 4. The corpus was first POS tagged with the MELT tagger (Denis and Sagot, 2010), lemmatized with the MACAON tool suite (Nasr et al., 2011) and parsed in order to get the best parse for every sentence. Then the ASF have been extracted. The number of verbs, number of SF and average number of SF per verb are represented in table 3, in column A0 (A stands for Automatic). As one can see, the number of verbs and SF are unrealistic. This is due to the fact that the data that we extract SF from is noisy: it consists of automatically produced syntactic trees which contain errors (recall CORPUS AFP EST REP WIKI TOTAL Sent. nb. 2 041 146 2 998 261 1 592 035 5 198 642 Tokens nb. 59"
N13-1024,J93-2004,0,0.0441011,"Missing"
N13-1024,P05-1012,0,0.419757,"ebank (Marcus et al., 1993) or the French Treebank (Abeill´e et al., 2003), which have been used in the parsing community to train stochastic parsers, such as (Collins, 1997; Petrov and Klein, 2008). Such work remained rooted in the classical language theoretic tradition of parsing, generally based on variants of generative context free grammars. The second change occurred with the use of discriminative machine learning techniques, first to rerank the output of a stochastic parser (Collins, 2000; Charniak and Johnson, 2005) and then in the parser itself (Ratnaparkhi, 1999; Nivre et al., 2007; McDonald et al., 2005a). Such parsers clearly depart from classical parsers in the sense that they do not rely anymore on a generative grammar: given a sentence S, all possible parses for S 1 are considered as possible parses of S. A parse tree is seen as a set of lexico-syntactic features which are associated to weights. The score of a parse is computed as the sum of the weights of its features. This new generation of parsers allows to reach high accuracy but possess their own limitations. We will focus in this paper on one kind of weakness of such parser which is their inability to properly take into account sub"
N13-1024,H05-1066,0,0.0332134,"Missing"
N13-1024,messiant-etal-2008-lexschem,0,0.138044,"Missing"
N13-1024,W11-2917,1,0.936423,"troduced this quantity in order to measure more accurately the impact of the methods described in this paper on the selection of a SF for the verbs of a sentence. SAS LAS UAS TEST 80.84 88.88 90.71 DEV 79.88 88.53 90.37 Table 2: Subcategorization Frame Accuracy, Labeled and Unlabeled Accuracy Score on TEST and DEV. We have chosen a second order graph parser in this work for two reasons. The first is that it is the parsing model that obtained the best results on the French Treebank. The second is that it allows us to impose structural constraints in the solution of the parser, as described in (Mirroshandel and Nasr, 2011), a feature that will reveal itself precious when enforcing SF in the parser output. 3 The Resources Three resources have been used in this work in order to correct SF errors. The first one has been extracted from a treebank, the second has been extracted from an automatically parsed corpus that is several order of magnitude bigger than the treebank. The third one has been extracted from an existing lexico-syntactic resource. The three resources are respectively described in sections 3.2, 3.3 and 3.4. Before describing the resources, we describe in details, in section 3.1 our definition of SF."
N13-1024,P11-4015,1,0.843682,"Missing"
N13-1024,sagot-2010-lefff,1,0.929954,"omputed Subcat Frames The extraction procedure described above has been used to extract ASF from an automatically parsed corpus. The corpus is actually a collection of three corpora of slightly different genres. The first one is a collection of news reports of the French press agency Agence France Presse, the second is a collection of newspaper articles from a local French newspaper : l’Est R´epublicain. The third one is a collection of articles from the French Wikipedia. The size of the different corpora are detailed in table 4. The corpus was first POS tagged with the MELT tagger (Denis and Sagot, 2010), lemmatized with the MACAON tool suite (Nasr et al., 2011) and parsed in order to get the best parse for every sentence. Then the ASF have been extracted. The number of verbs, number of SF and average number of SF per verb are represented in table 3, in column A0 (A stands for Automatic). As one can see, the number of verbs and SF are unrealistic. This is due to the fact that the data that we extract SF from is noisy: it consists of automatically produced syntactic trees which contain errors (recall CORPUS AFP EST REP WIKI TOTAL Sent. nb. 2 041 146 2 998 261 1 592 035 5 198 642 Tokens nb. 59"
N13-1024,C02-1118,0,0.715298,"mars (Gazdar et al., 1985) and Head-driven Phrase Structure Grammars (Pollard and Sag, 1994), made SF part of the grammar. Tree Adjoining Grammars (Joshi et al., 1975) proposed to extend the domain of locality of Context Free Grammars partly in order to be able to represent SF in a generative grammar. More recently, (Collins, 1997) proposed a way to introduce SF in a probabilistic context free grammar and (Arun and Keller, 2005) used the same technique for French. (Carroll et al., 1998), used subcategorization probabilities for ranking trees generated by unification-based phrasal grammar and (Zeman, 2002) showed that using frame frequency in a dependency parser can lead to a significant improvement of the performance of the parser. The main novelties of the work presented here is (1) the way a new parse is built by combining subparses that appear in the n best parse list and (2) the use of three very different resources that list the possible SF for verbs. 240 The organization of the paper is the following: in section 2, we will briefly describe the parsing model that we will be using for this work and give accuracy results on a French corpus. Section 3 will describe three different resources"
N13-1024,H91-1067,0,\N,Missing
N13-1024,P93-1032,0,\N,Missing
N19-1393,J19-2006,0,0.0420386,"Missing"
N19-1393,D14-1082,0,0.0401592,"that are difficult to assess and would have prevented 1 2 https://wals.info/ http://universaldependencies.org 3919 Proceedings of NAACL-HLT 2019, pages 3919–3930 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics to measure the precise influence of the typological features on the behaviour of the parser. The fourth issue concerns the parser, which must be language independent and produce syntactic trees based on combinations of parameter values and sentential configurations. We use a transition-based parser with a multi-layer perceptron classifier (Chen and Manning, 2014), responsible for proposing how parameter values match observable patterns in the data. Our research hypotheses are: (a) features derived from the WALS enable cross-lingual sharing in multilingual parsing, and (b) these features do more than acting as mere language identifiers. Our main contributions are to reassess the utility of the WALS as informant of typological features of parsed languages, to evaluate their benefit in a controlled multilingual setting with full supervision, and to perform a set of analyses to better understand how they interact with the parser model. In addition to mult"
N19-1393,C12-1059,0,0.0406222,"Missing"
N19-1393,2016.jeptalnrecital-invite.2,0,0.0666192,"for multilingual dependency parsing. Our experiments on multilingual parsing for 40 languages show that typological information can indeed guide parsers to share information between similar languages beyond simple language identification. 1 Introduction Human languages may share some syntactic features, but differ on others. For example, some languages tend to place the subject before the verb (e.g., English) whereas others favour the reverse order (e.g., Arabic), and some do not exhibit a clear preference (e.g., Polish). These features can be viewed as the parameters of a language’s syntax (Greenberg, 1963; Chomsky, 1995). When training a multilingual parser, it could be interesting to explicitly represent these parameters, and to integrate them into the parsing model. If a successful strategy to do so was found, then, a parser could be trained simultaneously on several languages whose syntactic parameters have been explicitly represented. Such parser could then use a single model to parse texts in any language with known syntactic parameters. In theory, if we had at our disposal a set of parameters that completely describes the syntax of languages as well as treebanks that explore the whole sp"
N19-1393,P15-1119,0,0.0526325,": (a) features derived from the WALS enable cross-lingual sharing in multilingual parsing, and (b) these features do more than acting as mere language identifiers. Our main contributions are to reassess the utility of the WALS as informant of typological features of parsed languages, to evaluate their benefit in a controlled multilingual setting with full supervision, and to perform a set of analyses to better understand how they interact with the parser model. In addition to multilingual parsing, our method is suitable for zero-shot learning for under-resourced languages (Ammar et al., 2016; Guo et al., 2015). After discussing related work (Sec. 2), we describe UD (Sec. 3), the WALS (Sec. 4) and our parser (Sec. 5). The experimental setup (Sec. 6) precedes our results (Sec. 7), analyses (Sec. 8) and conclusions (Sec. 9). 2 Related Work Our work is at the intersection of three trends in the multilingual dependency parsing literature. The first is transfer parsing, when a parser is trained on a language (or a collection of languages) and tested on another one. The second is delexicalised parsing, which aims at abstracting away from the lexicon in order to neutralise genre, domain and topic biases wh"
N19-1393,N16-1121,0,0.0901739,"’ vocabulary. The third trend is the use of a handcrafted typological resources, such as the WALS, in multilingual NLP methods. Transfer parsing is often a suitable solution when dealing with low-resource languages (McDonald et al., 2011). Projected transfer relies on parallel corpora in which one of the languages does not have labelled training data to learn a parser, but the other does. One commonly employed solution is to use word alignments to project parsed sentences from one side onto the low-resource side of the parallel text, using heuristics (Hwa et al., 2005) or partial annotations (Lacroix et al., 2016). Agi´c et al. (2016) parse the resource-rich languages in a multi-parallel corpus, proposing a projection method to obtain POS tags and dependency trees for low-resource languages from multiple-language word alignments. The parsing model for the target language can also be obtained in an unsupervised fashion, by optimising a function that combines the likelihood of parallel data and the likelihood of the transferred model on non-annotated data in the low-resource language (Ma and Xia, 2014). Instead of assuming the availability of parallel corpora, direct transfer approaches capitalize on lan"
N19-1393,W14-4606,0,0.0214781,"source-rich languages in a multi-parallel corpus, proposing a projection method to obtain POS tags and dependency trees for low-resource languages from multiple-language word alignments. The parsing model for the target language can also be obtained in an unsupervised fashion, by optimising a function that combines the likelihood of parallel data and the likelihood of the transferred model on non-annotated data in the low-resource language (Ma and Xia, 2014). Instead of assuming the availability of parallel corpora, direct transfer approaches capitalize on language similarities. For instance, Lynn et al. (2014) build parser for Irish by first training a delexicalised parser on another language, and then applying it on Irish. They surprisingly found out that Indonesian was the language providing the best parsing results for Irish, even if they do not belong to the same language family, because longdistance dependencies are better represented in Indonesian than in the other languages tested. Low-resource languages may have some (insufficient) amount of training material available. One can employ bilingual parsing, concatenating training corpora in two languages, to verify if there is an improvement in"
N19-1393,P14-1126,0,0.0930726,"low-resource side of the parallel text, using heuristics (Hwa et al., 2005) or partial annotations (Lacroix et al., 2016). Agi´c et al. (2016) parse the resource-rich languages in a multi-parallel corpus, proposing a projection method to obtain POS tags and dependency trees for low-resource languages from multiple-language word alignments. The parsing model for the target language can also be obtained in an unsupervised fashion, by optimising a function that combines the likelihood of parallel data and the likelihood of the transferred model on non-annotated data in the low-resource language (Ma and Xia, 2014). Instead of assuming the availability of parallel corpora, direct transfer approaches capitalize on language similarities. For instance, Lynn et al. (2014) build parser for Irish by first training a delexicalised parser on another language, and then applying it on Irish. They surprisingly found out that Indonesian was the language providing the best parsing results for Irish, even if they do not belong to the same language family, because longdistance dependencies are better represented in Indonesian than in the other languages tested. Low-resource languages may have some (insufficient) amoun"
N19-1393,D11-1006,0,0.166397,"Missing"
N19-1393,P12-1066,0,0.589557,"then use a single model to parse texts in any language with known syntactic parameters. In theory, if we had at our disposal a set of parameters that completely describes the syntax of languages as well as treebanks that explore the whole space of parameters and their values, then such a universal parser could be designed. To make such a program realistic, though, several issues have to be addressed. In this paper, we propose to study the feasibility of learning such multilingual parser by addressing some of these issues. The first one is the choice of syntactic parameters that will be used (Naseem et al., 2012; T¨ackstr¨om et al., 2013; Zhang and Barzilay, 2015). In our work, we approximate these parameters by extracting syntactic information from the World Atlas of Language Structures (WALS) (Dryer and Haspelmath, 2013). 1 A language is represented by a vector containing the values it selects in the WALS. This vector plays the role of the parameters mentioned above. The second issue is the design of a unified scheme for representing syntax. Our natural choice is the Universal Dependencies (UD) initiative. 2 UD specifically proposes a set of universal dependency relations, part-of-speech tags and m"
N19-1393,J08-4003,0,0.0903223,"Missing"
N19-1393,P05-1013,0,0.103528,"Missing"
N19-1393,E17-2102,0,0.0315184,"the WALS provide information about the structure of languages (Dryer and Haspelmath, 2013). These could be useful to guide multilingual parsers, informing them about the model parameters that can be shared among languages with similar characteristics. Naseem et al. (2012) and Zhang and Barzilay (2015) use word-order features available for all their languages, while Ponti et al. (2018) used features they judged relevant in many categories (not only word order). The parameters proposed in the WALS are not the only way to represent properties of languages. Meth¨ ods based on language embeddings (Ostling and Tiedemann, 2017; Bjerva et al., 2019) also constitute interesting language representation. T¨ackstr¨om et al. (2013) use a multilingual delexicalised transfer method, showing how selective parameter sharing, based on typological features and language family membership, can be incorporated in a discriminative graph-based dependency parser. They select the typological features based on those used by Naseem et al. (2012), removing two features not considered useful. The work closest to ours experimented with concatenating treebanks to train a multilingual parser (Ammar et al., 2016). The authors use an S-LSTM t"
N19-1393,P18-1142,0,0.133767,"Missing"
N19-1393,P17-1049,0,0.0583782,"Missing"
N19-1393,N13-1126,0,0.187912,"Missing"
N19-1393,W15-2137,0,0.094949,"te training corpora. However, in our case, we combine treebanks from many more sources (around 40 languages) and include typological features. The combination of corpora in multiple languages for parser training is facilitated by the recent advent of multilingual standards and resources, in particular in Universal Dependencies for dependency syntax (Nivre et al., 2016). This initiative enables the annotation of POS, morphology and syntactic dependencies for all languages with the same guidelines and label sets. The availability of such corpora favours the development of cross-lingual methods (Tiedemann, 2015). Multilingual parsing research is also encouraged by initiatives such as the CoNLL 2017 and 2018 shared tasks, on highly multilingual dependency parsing from raw text (Zeman et al., 2017, 2018). Delexicalised parsers ignore the word forms and lemmas when analysing a sentence, usually relying on more abstract features such as word classes 3920 and POS tags. The use of delexicalised parsers is especially relevant when learning multilingual parsers, since languages generally share only a limited amount of lexical units. The approach proposed by Zeman and Resnik (2008) consists in adapting a pars"
N19-1393,K17-3001,0,0.157189,"guages for parser training is facilitated by the recent advent of multilingual standards and resources, in particular in Universal Dependencies for dependency syntax (Nivre et al., 2016). This initiative enables the annotation of POS, morphology and syntactic dependencies for all languages with the same guidelines and label sets. The availability of such corpora favours the development of cross-lingual methods (Tiedemann, 2015). Multilingual parsing research is also encouraged by initiatives such as the CoNLL 2017 and 2018 shared tasks, on highly multilingual dependency parsing from raw text (Zeman et al., 2017, 2018). Delexicalised parsers ignore the word forms and lemmas when analysing a sentence, usually relying on more abstract features such as word classes 3920 and POS tags. The use of delexicalised parsers is especially relevant when learning multilingual parsers, since languages generally share only a limited amount of lexical units. The approach proposed by Zeman and Resnik (2008) consists in adapting a parser for a new related language using either parallel corpora or delexicalised parsing. This method can be used to quickly construct a parser if the source and target languages are sufficie"
nasr-etal-2014-automatically,H05-1066,0,\N,Missing
nasr-etal-2014-automatically,bazillon-etal-2012-syntactic,1,\N,Missing
nasr-etal-2014-automatically,bechet-etal-2012-decoda,1,\N,Missing
P00-1011,J93-2006,0,\N,Missing
P00-1011,A97-1030,0,\N,Missing
P00-1011,W99-0613,0,\N,Missing
P11-4015,W10-1408,1,0.44138,"Missing"
P11-4015,2006.jeptalnrecital-long.5,0,0.0461776,"rk has been funded by the French Agence Nationale pour la Recherche, through the projects SEQUOIA (ANR-08EMER-013) and DECODA (2009-CORD-005-01) 1 Annotation must be taken here in a general sense which includes tagging, segmentation or the construction of more complex objets as syntagmatic or dependencies trees. 86 Proceedings of the ACL-HLT 2011 System Demonstrations, pages 86–91, c Portland, Oregon, USA, 21 June 2011. 2011 Association for Computational Linguistics of processing. 2 Several processing tools suites alread exist for French among which SXPIPE (Sagot and Boullier, 2008), OUTILEX (Blanc et al., 2006), NOOJ2 or UNI TEX 3 . A general comparison of MACAON with these tools is beyond the scope of this paper. Let us just mention that MACAON shares with most of them the use of finite state machines as core data representation. Some modules are implemented as standard operations on finite state machines. The MACAON exchange format is based on four concepts: segment, attribute, annotation level and segmentation. A segment refers to a segment of the text or speech signal that is to be processed, as a sentence, a clause, a syntactic constituent, a lexical unit, a named entity . . . A segment can be"
P11-4015,P06-1055,0,0.0181302,"ace that allows to inspect MACAON XML files and run the components. 3.3 sentation of many NLP tools input and output in the MACAON format. MACAON has been interfaced with the SPEERAL Automatic Speech Recognition System (Nocera et al., 2006). The word lattices produced by SPEERAL can be converted to pre-lexical MACAON automata. MACAON does not provide any native module for parsing yet but it can be interfaced with any already existing parser. For the purpose of this demonstration we have chosen the LORG parser developed at NCLT, Dublin14 . This parser is based on PCFGs with latent annotations (Petrov et al., 2006), a formalism that showed state-of-the-art parsing accuracy for a wide range of languages. In addition it offers a sophisticated handling of unknown words relying on automatically learned morphological clues, especially for French (Attia et al., 2010). Moreover, this parser accepts input that can be tokenized, postagged or pre-bracketed. This possibility allows for different settings when interfacing it with MACAON. 4 Applications MACAON has been used in several projects, two of which are briefly described here, the D EFINIENS project and the L UNA project. D EFINIENS (Barque et al., 2010) is"
P11-4015,W05-0618,0,\N,Missing
P11-4015,J08-2002,0,\N,Missing
P11-4015,sagot-etal-2006-lefff,0,\N,Missing
P12-1082,D11-1113,0,0.0592684,"e initial treebank and a new parser is trained. The main difference between these approaches and ours is that we do not directly add the output of the parser to the training corpus, but extract precise lexical information that is then re-injected in the parser. In the self training approach, (Chen et al., 2009) is quite close to our work: instead of adding new parses to the treebank, the occurrence of simple interesting subtrees are detected in the parses and introduced as new features in the parser. The way we introduce lexical affinity measures in the parser, in 5.1, shares some ideas with (Anguiano and Candito, 2011), who modify some attachments in the parser output, based on lexical information. The main difference is that we only take attachments that appear in an n-best parse list into account, while 778 they consider the first best parse and compute all potential alternative attachments, that may not actually occur in the n-best forests. 3 The Parser The parser used in this work is the second order graph based parser (McDonald et al., 2005; K¨ubler et al., 2009) implementation of (Bohnet, 2010). The parser was trained on the French Treebank (Abeill´e et al., 2003) which was transformed into dependency"
P12-1082,P11-1070,0,0.0752681,"et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or internet n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of words co-occurrences is generally very simple, it is either based on the direct adjacency of the words in the string or their cooccurrence in a window of a few words. (Bansal and Klein, 2011; Nakov and Hearst, 2005) rely on the same sort of techniques but use more sophisticated patterns, based on simple paraphrase rules, for identifying co-occurrences. Our work departs from those approaches by the fact that we do not extract the lexical information directly on a raw corpus, but we first parse it and then extract the co-occurrences on the parse trees, based on some predetermined lexico-syntactic patterns. The first reason for this choice is that the linguistic phenomena that we are interested in, such as as PP attachment, coordination, verb subject and object can range over long d"
P12-1082,W09-3821,0,0.0626406,"Missing"
P12-1082,W10-1409,0,0.0210375,"ted from this procedure, the first Previous Work Coping with lexical sparsity of treebanks using raw corpora has been an active direction of research for many years. One simple and effective way to tackle this problem is to put together words that share, in a large raw corpus, similar linear contexts, into word clusters. The word occurrences of the training treebank are then replaced by their cluster identifier and a new parser is trained on the transformed treebank. Using such techniques (Koo et al., 2008) report significative improvement on the Penn Treebank (Marcus et al., 1993) and so do (Candito and Seddah, 2010; Candito and Crabb´e, 2009) on the French Treebank (Abeill´e et al., 2003). Another series of papers (Volk, 2001; Nakov and Hearst, 2005; Pitler et al., 2010; Zhou et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or internet n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of word"
P12-1082,2009.jeptalnrecital-long.4,0,0.35731,"Missing"
P12-1082,D09-1060,0,0.020148,"ated corpora. Our work can also be compared with self training approaches to parsing (McClosky et al., 2006; Suzuki et al., 2009; Steedman et al., 2003; Sagae and Tsujii, 2007) where a parser is first trained on a treebank and then used to parse a large raw corpus. The parses produced are then added to the initial treebank and a new parser is trained. The main difference between these approaches and ours is that we do not directly add the output of the parser to the training corpus, but extract precise lexical information that is then re-injected in the parser. In the self training approach, (Chen et al., 2009) is quite close to our work: instead of adding new parses to the treebank, the occurrence of simple interesting subtrees are detected in the parses and introduced as new features in the parser. The way we introduce lexical affinity measures in the parser, in 5.1, shares some ideas with (Anguiano and Candito, 2011), who modify some attachments in the parser output, based on lexical information. The main difference is that we only take attachments that appear in an n-best parse list into account, while 778 they consider the first best parse and compute all potential alternative attachments, that"
P12-1082,J90-1003,0,0.123387,"flect the tendency of lg and ld to appear together in configuration C. It should be maximal if whenever lg occurs as the governor of configuration C, the dependent position is occupied by ld and, symmetrically, if whenever ld occurs as the dependent of configuration C, the governor position is occupied by lg . A function that conforms such a behavior is the following: s(C, lg , ld ) = 1 2  C(C, lg , ld ) C(C, lg , ld ) + C(C, lg , ∗) C(C, ∗, ld )  it takes its values between 0 (lg and ld never co-occur) and 1 (g and d always co-occur). This function is close to pointwise mutual information (Church and Hanks, 1990) but takes its values between 0 and 1. Description (V, g) CORPUS AFP EST REP WIKI TOTAL (N, d) (N, d) ADJ (N, d) (N, d) (N, d) (N, d) (N, d) (V, d) 4.2 Evaluation Table 4: List of the 9 configurations. The computation of the number of occurrences of an instantiated configuration in the corpus is quite straightforward, it consists in traversing the dependency trees produced by the parser and detect the occurrences of this configuration. At the end of the counts collection, we have gath780 Lexical affinities were computed on three corpora of slightly different genres. The first one, is a collect"
P12-1082,2010.jeptalnrecital-long.3,0,0.0258924,"d in this work is the second order graph based parser (McDonald et al., 2005; K¨ubler et al., 2009) implementation of (Bohnet, 2010). The parser was trained on the French Treebank (Abeill´e et al., 2003) which was transformed into dependency trees by (Candito et al., 2009). The size of the treebank and its decomposition into train, development and test sets is represented in table 1. FTB TRAIN FTB DEV FTB TEST nb of sentences 9 881 1 239 1 235 nb of words 278 083 36 508 36 340 Table 1: Size and decomposition of the French Treebank The part of speech tagging was performed with the MELT tagger (Denis and Sagot, 2010) and lemmatized with the MACAON tool suite (Nasr et al., 2011). The parser gave state of the art results for parsing of French, reported in table 2. LAS UAS pred. POS tags punct no punct 88.02 90.24 90.02 92.50 gold POS tags punct no punct 88.88 91.12 90.71 93.20 Table 2: Labeled and unlabeled accuracy score for automatically predicted and gold POS tags with and without taking into account punctuation on FTB TEST. Figure 1 shows the distribution of the 100 most common error types made by the parser. In this figure, x axis shows the error types and y axis shows the error ratio of the related er"
P12-1082,J04-3001,0,0.172645,"Missing"
P12-1082,P08-1068,0,0.0501283,"in specific lexico-syntactic configurations, are then injected back in the parser. Two outcomes are expected from this procedure, the first Previous Work Coping with lexical sparsity of treebanks using raw corpora has been an active direction of research for many years. One simple and effective way to tackle this problem is to put together words that share, in a large raw corpus, similar linear contexts, into word clusters. The word occurrences of the training treebank are then replaced by their cluster identifier and a new parser is trained on the transformed treebank. Using such techniques (Koo et al., 2008) report significative improvement on the Penn Treebank (Marcus et al., 1993) and so do (Candito and Seddah, 2010; Candito and Crabb´e, 2009) on the French Treebank (Abeill´e et al., 2003). Another series of papers (Volk, 2001; Nakov and Hearst, 2005; Pitler et al., 2010; Zhou et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or inte"
P12-1082,J93-2004,0,0.0408799,"e parser. Two outcomes are expected from this procedure, the first Previous Work Coping with lexical sparsity of treebanks using raw corpora has been an active direction of research for many years. One simple and effective way to tackle this problem is to put together words that share, in a large raw corpus, similar linear contexts, into word clusters. The word occurrences of the training treebank are then replaced by their cluster identifier and a new parser is trained on the transformed treebank. Using such techniques (Koo et al., 2008) report significative improvement on the Penn Treebank (Marcus et al., 1993) and so do (Candito and Seddah, 2010; Candito and Crabb´e, 2009) on the French Treebank (Abeill´e et al., 2003). Another series of papers (Volk, 2001; Nakov and Hearst, 2005; Pitler et al., 2010; Zhou et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or internet n-grams. Based on the counts produced, lexical affinity scores are comp"
P12-1082,N06-1020,0,0.0601272,"is choice is that the linguistic phenomena that we are interested in, such as as PP attachment, coordination, verb subject and object can range over long distances, beyond what is generally taken into account when working on limited windows. The second reason for this choice was to show that the performances that the NLP community has reached on parsing, combined with the use of confidence measures allow to use parsers to extract accurate lexico-syntactic information, beyond what can be found in limited annotated corpora. Our work can also be compared with self training approaches to parsing (McClosky et al., 2006; Suzuki et al., 2009; Steedman et al., 2003; Sagae and Tsujii, 2007) where a parser is first trained on a treebank and then used to parse a large raw corpus. The parses produced are then added to the initial treebank and a new parser is trained. The main difference between these approaches and ours is that we do not directly add the output of the parser to the training corpus, but extract precise lexical information that is then re-injected in the parser. In the self training approach, (Chen et al., 2009) is quite close to our work: instead of adding new parses to the treebank, the occurrence"
P12-1082,H05-1066,0,0.218273,"Missing"
P12-1082,W11-2917,1,0.81381,"ve strategy that was used in 4.2.2. But it has an important drawback: it creates inconsistent parses. Recall that the parser we are using is based on a second order model, which means that the score of a dependency depends on some neighboring ones. Since with the post processing method only a subset of the dependencies are modified, the resulting parse is inconsistent: the score of some dependencies is computed on the basis of other dependencies that have been modified. In order to compute a new optimal parse tree that preserves the modified dependencies, we have used a technique proposed in (Mirroshandel and Nasr, 2011) that modifies the scoring function of the parser in such a way that the dependencies that we want to keep in the parser output get better scores than all competing dependencies. The double parsing method is therefore a three stage method. First, sentence S is parsed, producing the n-best parses. Then, the post processing method is used, modifying the first best parse. Let’s note D the set of dependencies that were changed in this process. In the last stage, a new parse is produced, that preserves D. 5.3 Feature Based Method In the feature based method, new features are added to the parser tha"
P12-1082,H05-1105,0,0.090773,"f research for many years. One simple and effective way to tackle this problem is to put together words that share, in a large raw corpus, similar linear contexts, into word clusters. The word occurrences of the training treebank are then replaced by their cluster identifier and a new parser is trained on the transformed treebank. Using such techniques (Koo et al., 2008) report significative improvement on the Penn Treebank (Marcus et al., 1993) and so do (Candito and Seddah, 2010; Candito and Crabb´e, 2009) on the French Treebank (Abeill´e et al., 2003). Another series of papers (Volk, 2001; Nakov and Hearst, 2005; Pitler et al., 2010; Zhou et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or internet n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of words co-occurrences is generally very simple, it is either based on the direct adjacency of the words in the string or their cooccurrence in"
P12-1082,P11-4015,1,0.877849,"Missing"
P12-1082,C10-1100,0,0.0472971,"s. One simple and effective way to tackle this problem is to put together words that share, in a large raw corpus, similar linear contexts, into word clusters. The word occurrences of the training treebank are then replaced by their cluster identifier and a new parser is trained on the transformed treebank. Using such techniques (Koo et al., 2008) report significative improvement on the Penn Treebank (Marcus et al., 1993) and so do (Candito and Seddah, 2010; Candito and Crabb´e, 2009) on the French Treebank (Abeill´e et al., 2003). Another series of papers (Volk, 2001; Nakov and Hearst, 2005; Pitler et al., 2010; Zhou et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or internet n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of words co-occurrences is generally very simple, it is either based on the direct adjacency of the words in the string or their cooccurrence in a window of a few wo"
P12-1082,D07-1111,0,0.0991287,"n, such as as PP attachment, coordination, verb subject and object can range over long distances, beyond what is generally taken into account when working on limited windows. The second reason for this choice was to show that the performances that the NLP community has reached on parsing, combined with the use of confidence measures allow to use parsers to extract accurate lexico-syntactic information, beyond what can be found in limited annotated corpora. Our work can also be compared with self training approaches to parsing (McClosky et al., 2006; Suzuki et al., 2009; Steedman et al., 2003; Sagae and Tsujii, 2007) where a parser is first trained on a treebank and then used to parse a large raw corpus. The parses produced are then added to the initial treebank and a new parser is trained. The main difference between these approaches and ours is that we do not directly add the output of the parser to the training corpus, but extract precise lexical information that is then re-injected in the parser. In the self training approach, (Chen et al., 2009) is quite close to our work: instead of adding new parses to the treebank, the occurrence of simple interesting subtrees are detected in the parses and introd"
P12-1082,R09-1070,0,0.252787,"Missing"
P12-1082,E03-1008,0,0.0230249,"hat we are interested in, such as as PP attachment, coordination, verb subject and object can range over long distances, beyond what is generally taken into account when working on limited windows. The second reason for this choice was to show that the performances that the NLP community has reached on parsing, combined with the use of confidence measures allow to use parsers to extract accurate lexico-syntactic information, beyond what can be found in limited annotated corpora. Our work can also be compared with self training approaches to parsing (McClosky et al., 2006; Suzuki et al., 2009; Steedman et al., 2003; Sagae and Tsujii, 2007) where a parser is first trained on a treebank and then used to parse a large raw corpus. The parses produced are then added to the initial treebank and a new parser is trained. The main difference between these approaches and ours is that we do not directly add the output of the parser to the training corpus, but extract precise lexical information that is then re-injected in the parser. In the self training approach, (Chen et al., 2009) is quite close to our work: instead of adding new parses to the treebank, the occurrence of simple interesting subtrees are detected"
P12-1082,D09-1058,0,0.0352758,"inguistic phenomena that we are interested in, such as as PP attachment, coordination, verb subject and object can range over long distances, beyond what is generally taken into account when working on limited windows. The second reason for this choice was to show that the performances that the NLP community has reached on parsing, combined with the use of confidence measures allow to use parsers to extract accurate lexico-syntactic information, beyond what can be found in limited annotated corpora. Our work can also be compared with self training approaches to parsing (McClosky et al., 2006; Suzuki et al., 2009; Steedman et al., 2003; Sagae and Tsujii, 2007) where a parser is first trained on a treebank and then used to parse a large raw corpus. The parses produced are then added to the initial treebank and a new parser is trained. The main difference between these approaches and ours is that we do not directly add the output of the parser to the training corpus, but extract precise lexical information that is then re-injected in the parser. In the self training approach, (Chen et al., 2009) is quite close to our work: instead of adding new parses to the treebank, the occurrence of simple interestin"
P12-1082,P11-1156,0,0.0326054,"ective way to tackle this problem is to put together words that share, in a large raw corpus, similar linear contexts, into word clusters. The word occurrences of the training treebank are then replaced by their cluster identifier and a new parser is trained on the transformed treebank. Using such techniques (Koo et al., 2008) report significative improvement on the Penn Treebank (Marcus et al., 1993) and so do (Candito and Seddah, 2010; Candito and Crabb´e, 2009) on the French Treebank (Abeill´e et al., 2003). Another series of papers (Volk, 2001; Nakov and Hearst, 2005; Pitler et al., 2010; Zhou et al., 2011) directly model word co-occurrences. Cooccurrences of pairs of words are first collected in a 777 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 777–785, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics raw corpus or internet n-grams. Based on the counts produced, lexical affinity scores are computed. The detection of pairs of words co-occurrences is generally very simple, it is either based on the direct adjacency of the words in the string or their cooccurrence in a window of a few words. (Bansal and Kle"
P12-1082,J04-4004,0,\N,Missing
P15-1108,C10-1011,0,0.0338988,"ost simple one is the arcfactored or first-order model, which simply decomposes a tree into single dependencies and assigns them a score, independently of their context. We used a second-order parser which decomposes a tree into factors of three types: 1. first-order factors, made of one dependency; 2. sibling factors, made of two dependencies sharing a common governor; 3. grandchildren factors, made of two dependencies where the dependent of one of them is the governor of the other one. 5 Integration with a Syntactic Lexicon Although this kind of parsers achieve state-of-theart performances (Bohnet, 2010), their predictions are limited to the phenomena that occur in the treebanks they are trained on. In particular, they often fail at correctly distinguishing elements that are subcategorized by a verb (henceforth complements) from others (modifiers). This is due to the fact that the nature and number of the complements is specific to each verb. If the verb did not occur, or did not occur often enough, in the treebank, the nature and number of its complements will not be correctly modeled by the parser. A precise description of verb complements plays an important role in the task of predicting t"
P15-1108,P14-1070,0,0.338931,"our model on ADV+que and de+DET constructions. 3 The MORPH Dependency In order to let the parser take the tokenization decisions, we propose not to group sequences of tokens of the form ADV+que and de+DET at tokenization time. Instead, we transform the task of segmentation decision into a parsing decision task. We associate a syntactic structure to ADV+que and de+DET constructions by introducing a new type of dependency that we call MORPH. It is not a standard syntactic dependency, but a reminiscent of the morphological dependencies of Mel’ˇcuk (1988), similar to the DEP CPD label proposed by Candito and Constant (2014) or the ID dependency of Nivre and Nilsson (2004), except that we focus on syntactically-motivated MWEs, proposing a regular structure for them. The syntactic structures of examples 1 and 2, introduced in Section 1, are represented below4 . Example 1. MOD SUJ CLS Je OBJ MORPH VRB ADV mange bien CSU que ... ... VRB ... ... VRB ... ... aie Example 2. OBJ SUJ CLS Je 4 OBJ MOD VRB pense ADV bien CSU que ... ... ai In the examples, parts of speech CLS, VRB, ADV and CSU respectively stand for subject clitic pronoun, verb, adverb and subordinating conjunction. Syntactic labels SUJ, MOD, OBJ, DE - OBJ"
P15-1108,2009.jeptalnrecital-long.4,0,0.132562,"Missing"
P15-1108,W11-0809,0,0.233442,"Missing"
P15-1108,W13-4905,0,0.184526,"Missing"
P15-1108,W13-4906,0,0.0305705,"oices are difficult to make without 1 This paper considers dependency syntactic structures. taking syntax into account. To avoid the pitfall of premature decisions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees associated to sequences of different lengths (De La Clergerie, 2013). This problem is particularly hard when parsing multiword expressions (MWEs), that is, groups of tokens that must be treated as single units (Baldwin and Kim, 2010). The solution we present in this paper is different from the usual pipeline. We propose to jointly parse and tokenize MWEs, transforming segmentation decisions into linking decisions. Our experiments concentrate on two difficult tokenization cases. Hence, it is the parser that will choose, in such cases, whether to group or not several tokens. Our first target phenomenon is the family of ADV+que constructions, a type of complex co"
P15-1108,P11-2124,0,0.0242174,"entation into linguistically relevant units (words), tagging the words with POS tags and linking the (word, POS) pairs by means of syntactic dependencies. This setup is clearly not ideal, as some decisions are made too early in the pipeline (Branco and Silva, 2003). More specifically, some tokenization and tagging choices are difficult to make without 1 This paper considers dependency syntactic structures. taking syntax into account. To avoid the pitfall of premature decisions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees associated to sequences of different lengths (De La Clergerie, 2013). This problem is particularly hard when parsing multiword expressions (MWEs), that is, groups of tokens that must be treated as single units (Baldwin and Kim, 2010). The solution we present in this paper is different from the usual pipeline. We propose to jointly parse and tokenize MWEs, tra"
P15-1108,C10-1045,0,0.0851174,"Missing"
P15-1108,J13-1009,0,0.204866,"Missing"
P15-1108,W11-0818,0,0.117479,"Missing"
P15-1108,Q14-1016,0,0.201312,"Missing"
P15-1108,D07-1110,1,0.726501,"Missing"
P15-1108,P13-2046,0,0.0386249,", while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous"
P15-1108,I13-1024,0,0.528563,", while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous"
P15-1108,W10-3705,0,0.543959,"Missing"
P15-1108,N10-1089,0,\N,Missing
P98-1106,1995.iwpt-1.23,1,0.308224,"ependents. (4) • The order of the newly introduced dependents is consistent with the LP rule associated with the governor. • The introduced terminal string (head) is m a p p e d to the rewritten category. (5) 3We follow (Gaifman, 1965) throughout this paper by modeling a dependency grammar with a string-rewriting system. However, we will identify a derivation with its representation as a tree, and we will sometimes refer to symbols introduced in a rewrite step as ""dependent nodes"". For a model of a DG based on tree-rewriting (in the spirit of Tree Adjoining Grammar (Joshi et al., 1975)), see (Nasr, 1995). 4In this paper, we will allow finite feature structures on categories, which we will notate using subscripts; e.g., Vtrans. Since the feature structures are finite, this is simply a notational variant of a system defined only with simple category labels. N o b j Adv f J Figure 3: A sample GDG derivation LP rules are represented as regular expressions (actually, only a limited form of regular expressions) associated with each category. We use the hash sign ( # ) to denote the position of the governor (head). For example: pl:Yt. . . . Nnom I Here is a sample m-rule. d3 : V Adv Carlos ) gnom, N"
P98-1106,P97-1043,0,0.0606835,"overed by ~2"" ((Nasr, 1996)). The resulting pseudo-projectivity is a fairly weak extension to projectivity, which nevertheless covers major nonprojective linguistic structures. However, we do not pursue a purely structural definition of pseudo-projectivity in this paper. In order to define pseudo-projectivity, we in647 linguistic example of lifting rule is given in Section 4. The idea of building a projective tree by means of lifting appears in (Kunze, 1968) and is used by (Hudson, 1990) and (Hudson, unpublished). This idea can also be compared to the notion of word order domain (Reape, 1990; BrSker and Neuhaus, 1997), to the Slash feature of G P S G and HPSG, to the functional uncertainty of LFG, and to the Move-a of GB theory. 3 Projective Revisited Dependency Vclause (2) ~ gnom, Y (3) ~ Adv = (Adv)Nnom(Aux)Adv*#YobjAdv*Yt . . . . yesterday Fernando thought Vtrans Nnom eats beans slowly We will call this system g e n e r a t i v e depend e n c y g r a m m a r or GDG for short. Derivations in GDG are defined as follows. In a rewrite step, we choose a multiset of dependency rules (i.e., a set of instances of dependency rules) which contains exactly one srule and zero or more m-rules. The left-hand side non"
P98-1106,P97-1003,0,0.0396601,"e e is a tree enriched with a linear order over the set of its nodes. Finally, if l is an arc of an ordered tree T, then Supp(1) represents the s u p p o r t of l, i.e. the set of the nodes of T situated between the extremities of l, extremities included. We will say that the elements of Supp(1) are c o v e r e d by I. Introduction Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesni~re's work from the thirties3 Recently, it has gained renewed attention as empirical methods in parsing are discovering the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly do, but context-free phrasestructure grammars do not. One problem that has posed an impediment to more wide-spread acceptance of dependency grammars is the fact that there is no computationally tractable version of dependency grammar which is not restricted to projective analyses. However, it is well known that there are some syntactic phenomena (such as wh-movement in English or clitic climbing in Romance) that require nonprojective analyses. In this paper, we present a form of projectivity which we call pseudoprojectivity, and we present"
P98-1106,C96-2122,0,\N,Missing
P98-1106,C96-1058,0,\N,Missing
palmer-etal-1998-rapid,W97-0311,0,\N,Missing
palmer-etal-1998-rapid,A97-1050,0,\N,Missing
palmer-etal-1998-rapid,C94-1024,0,\N,Missing
palmer-etal-1998-rapid,1997.mtsummit-workshop.12,1,\N,Missing
palmer-etal-1998-rapid,P96-1025,0,\N,Missing
palmer-etal-1998-rapid,A97-1039,0,\N,Missing
S12-1024,A00-2006,0,0.053697,"tly related through antonymy (heavy– light); synsets of relational adjectives are linked to a related noun by a pointer (fraternal–brother). Fellbaum et al. (1993:36) acknowledge the existence of more diverse relations to nominal synsets, but, to our knowledge, these are not accounted for in WordNet. This limitation is also present in the open access French version of the Princeton WordNet, WOLF (Sagot and Fiˇser, 2012). This limitation has led projects extending WordNet to other languages, like EuroWordNet, ItalWordNet or WordNet.PT, to add a few more relations to account for this diversity (Alonge et al., 2000; Marrafa and Mendes, 2006; Vossen, 2002). The number of new relations is however limited. As can be seen, WordNet-type approaches focus on relating adjectival synsets using a few semantic relations, mostly antonymy and plain related to relations. Our goal is to achieve a finer, and thus richer, semantic characterization of the relations holding between French adjectives and other words from all syntactic categories using the formalism of lexical functions. We assume that the type of the adjective is reflected in the structure of its lexicographic definition. Thus, to extract semantically rele"
S12-1024,P06-2072,0,0.0191947,"ntonymy (heavy– light); synsets of relational adjectives are linked to a related noun by a pointer (fraternal–brother). Fellbaum et al. (1993:36) acknowledge the existence of more diverse relations to nominal synsets, but, to our knowledge, these are not accounted for in WordNet. This limitation is also present in the open access French version of the Princeton WordNet, WOLF (Sagot and Fiˇser, 2012). This limitation has led projects extending WordNet to other languages, like EuroWordNet, ItalWordNet or WordNet.PT, to add a few more relations to account for this diversity (Alonge et al., 2000; Marrafa and Mendes, 2006; Vossen, 2002). The number of new relations is however limited. As can be seen, WordNet-type approaches focus on relating adjectival synsets using a few semantic relations, mostly antonymy and plain related to relations. Our goal is to achieve a finer, and thus richer, semantic characterization of the relations holding between French adjectives and other words from all syntactic categories using the formalism of lexical functions. We assume that the type of the adjective is reflected in the structure of its lexicographic definition. Thus, to extract semantically relevant information from adje"
S12-1024,P11-4015,1,0.880706,"Missing"
S12-1024,C96-2142,0,0.0937881,"do have a large coverage and present a reliable content. They lack nevertheless the sufficient formalization. In this paper, we present a rule-based method to automatically create a large-coverage semantic lexicon of French adjectives by extracting paradigmatic relations from lexicographic definitions using lexico-syntactic patterns. Formalized adRelated Work It is well established that there are different types of adjectives distinguished by properties, such as gradation and markedness, and by their semantic and syntactic behaviors (antonymy, selectional preferences) (Fellbaum et al., 1993; Raskin and Nirenburg, 1996). WordNet, for example, distinguishes different types of adjectives according to their semantic and syntactic behaviors: descriptive, reference-modifying, color and relational adjectives (Fellbaum et al., 1993). However, it mainly accounts for the first and the last types of adjectives. Descrip1 For other possible NLP applications of lexicons encoded with the lexical function formalism, see Schwab and Lafourcade (2007). 161 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 161–169, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics tiv"
S12-1024,2011.jeptalnrecital-court.12,0,0.106835,"Missing"
W02-2214,W02-2236,1,\N,Missing
W02-2214,J99-2004,1,\N,Missing
W02-2214,J95-4002,0,\N,Missing
W02-2214,1997.iwpt-1.11,0,\N,Missing
W02-2214,P00-1058,0,\N,Missing
W02-2214,P98-1106,1,\N,Missing
W02-2214,C98-1102,1,\N,Missing
W02-2214,P95-1037,0,\N,Missing
W02-2214,P98-1061,0,\N,Missing
W02-2214,C98-1059,0,\N,Missing
W02-2214,P98-2190,0,\N,Missing
W02-2214,C98-2185,0,\N,Missing
W02-2214,J94-1004,0,\N,Missing
W04-1503,J00-1004,0,0.0239731,"or the recovery of the dependency structure both from the derivation tree and from a parse forest represented in polynomial space. (In fact, our parsing algorithm draws on this work.) However, the approach of course requires the introduction of additional nonterminal nodes. Finally, we observe that Recursive Transition Networks (Woods, 1970) can be used to encode a grammar whose derivation trees are dependency trees. However, they are more a general framework for encoding grammars than a specific type of grammar (for example, we can also use them to encode CFGs). In a somewhat related manner, Alshawi et al. (2000) use cascaded head automata to derive dependency trees, but leave the nature of the cascading under-formalized. Eisner (2000) provides a formalization of a system that uses two different automata to generate left and right children of a head. His formalism is very close to the one we present, but it is not a string-rewriting formalism (and not really generative at all). We are looking for a precise formulation of a generative dependency grammar, and the question has remained open whether there is an alternate formalism which allows for an unbounded number of adjuncts, introduces all daughter n"
W04-1503,J99-2004,0,0.0901481,"Missing"
W04-1503,P00-1058,0,0.0564617,"Missing"
W04-1503,P97-1003,0,0.061391,"act parse forest in a straightforward manner. In this paper, we present a simple generative formalism for dependency grammars based on Extended Context-Free Grammar, along with a parser; the formalism captures the intuitions of previous formalizations while deviating minimally from the much-used Context-Free Grammar. 1 Introduction Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesni`ere’s work from the thirties. Recently, it has gained renewed attention as empirical methods in parsing have emphasized the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly, but context-free phrase-structure grammars do not. In this paper, we address an important issue in using grammar formalisms: the compact representation of the parse forest. Why is this an important issue? It is well known that for non-toy grammars and non-toy examples, a sentence can have a staggeringly large number of analyses (for example, using a contextfree grammar (CFG) extracted from the Penn Treebank, a sentence of 25 words may easily have 1,000,000 or more analyses). By way of an example of an ambiguous sentence (though with only t"
W04-1503,W98-0503,0,0.0418103,"tic sense as a type of syntactic dependency (another type being argument). We use head (or mother) and dependent (or daughter) to refer to nodes in a tree. Sometimes, in the formal and parsing literature, modifier is used to designate any dependent node, but we consider that usage confusing because of the related but different meaning of the term modifier that is well-established in the linguistic literature. 4 In fact, much of our formalism is very similar to (Lombardo, 1996), who however does not discuss parsing (only recognition), nor the representation of the parse forest. 5 Kahane et al. (1998) present three different types of rules, for subcategorization, modification, and linear precedence. In the formalism presented in this paper, they have been collapsed into one. 6 We leave aside here work on tree rewriting systems such as Tree Adjoining Grammar, which, when lexicalized, have derivation structures which are very similar to dependency trees. See (Rambow and Joshi, 1997) for a discussion related to TAG, and see (Rambow et al., 2001) for the definition of a tree-rewriting system which can be used to develop grammars whose derivations faithfully mirror syntactic dependency. 2 Previ"
W04-1503,P98-1106,1,0.547588,"n and easy-to-use generative formalism with a straightforward notion of parse forest. In particular, our formalism, Generative Dependency Grammar, allows for an unbounded number of daughter nodes in the derivation tree through the use of regular expressions in its rules. The parser uses the corresponding finite-state machines which straightforwardly allows for a binary-branching representation of the derivation structure for the purpose of parsing, and thus for a compact (polynomial and not exponential) representation of the parse forest. This formalism is based on previous work presented in (Kahane et al., 1998), which has been substantially reformulated in order to simplify it. 5 In particular, we do not address non-projectivity here, but acknowledge that for certain languages it is a crucial issue. We will extend our basic approach in the spirit of (Kahane et al., 1998) in future work. The paper is structured as follows. We start out by surveying previous formalizations of dependency grammar in Section 2. In Section 3, we introduce several formalisms, including Generative Dependency Grammar. We present a parsing algorithm in Section 4, and mention empirical results in Section 5. We then conclude. 3"
W04-1503,W04-3308,1,0.831117,"Missing"
W04-1503,J01-1004,1,0.796959,"formalism is very similar to (Lombardo, 1996), who however does not discuss parsing (only recognition), nor the representation of the parse forest. 5 Kahane et al. (1998) present three different types of rules, for subcategorization, modification, and linear precedence. In the formalism presented in this paper, they have been collapsed into one. 6 We leave aside here work on tree rewriting systems such as Tree Adjoining Grammar, which, when lexicalized, have derivation structures which are very similar to dependency trees. See (Rambow and Joshi, 1997) for a discussion related to TAG, and see (Rambow et al., 2001) for the definition of a tree-rewriting system which can be used to develop grammars whose derivations faithfully mirror syntactic dependency. 2 Previous Formalizations of Dependency Grammar We start out by observing that “dependency grammar” should be contrasted with “phrase structure grammar”, not “CFG”, which is a particular formalization of phrase structure grammar. Thus, just as it only makes sense to study the formal properties of a particular formalization of phrase structure grammar, the question about the formal properties of dependency grammar in general is not well defined, nor the"
W04-1503,1993.iwpt-1.22,0,0.0201459,"es make reference to other strucsaw saw H  HH man Pilar  HH a Pilar with telescope H  HH HH man with a telescope a a Figure 1: Two dependency trees V N Pilar V saw N D man a N P with saw Pilar N D P man with N a D N D telesope telesope a a Figure 2: Two dependency trees with lexical categories tures, these approaches cannot be formalized in a straightforward manner as context-free rewriting formalisms. In the third approach, which includes formalizations of dependency structure such as Dependency Tree Grammar of Modina (see (Dikovsky and Modina, 2000) for an overview), Link Grammar (Sleator and Temperley, 1993) or the tree-composition approach of Nasr (1996), rules construct the dependency tree incrementally; in these approaches, the grammar licenses dependency relations which, in a derivation, are added to the tree one by one, or in groups. In contrast, we are interested in a stringrewriting system; in such a system, we cannot add dependency relations incrementally: all daughters of a node must be added at once to represent a single rewrite step. In the fourth approach, the dependency grammar is converted into a headed context-free grammar (Abney, 1996; Holan et al., 1998), also the Basic Dependenc"
W04-1503,W04-3313,0,0.0284371,"Missing"
W04-1503,W00-1307,0,0.0605429,"Missing"
W04-3308,J00-1004,0,0.0316841,"aselines on the test corpus (Section 23) the active valency of the lexical head in the FSM. A result, in retrieving the derivation tree, each item in the parse tree corresponds to an attachment of one word to another, and there are fewer items. Furthermore, our FSMs are built left-to-right, while Evans and Weir only explore FSMs constructed bottom-up from the lexical anchor of the tree (not unlike (Eisner, 2000)). As a result, we can perform a strict left-to-right parse, which is not straightforwardly possible in standard TAG parsing using FSMs. Our parsing algorithm is similar to the work of Alshawi et al. (2000). They use cascaded head automata to derive dependency trees, but leave the nature of the cascading under-formalized. Eisner (2000) provides a formalization of a system that uses two different automata to generate left and right children of a head. His formalism is very close to the one we present, but we use a single automaton. Also, the relation to an independently proposed syntactic formalism such as TAG is less obvious. In related work (Rambow et al., 2002), we have used the same automata constructed from an extracted TAG for parsing, but instead of using them in a chart parser, we have us"
W04-3308,J99-2004,0,0.26168,"ntary trees, we distinguish passive transitives without byphrase from active intransitives, and we include strongly governed prepositions (as determined in the PTB annotation, including passive by-phrases) in elementary verbal trees. Generally, function words such as auxiliaries or determiners are dependents of the lexical head,1 conjunctions (including punctuation functioning as conjunction) are dependent on the first conjunct and take the second conjunct as their argument, and conjunction chains are represented as right-branching rather than flat. 2.2 But Is Supertag-Based Parsing Feasible? Bangalore and Joshi (1999) claim that supertagging is “almost parsing”. What this means is that the syntactic information provided by supertags is so rich that there is little structural ambiguity left and the parse is almost 1 This is a linguistic choice and not forced by the formalism or the PTB. We prefer this representation as the resulting dependency tree is closer to predicate-argument structure. 57 In the second step, we directly compile a set of FSMs which are used by the parser. To derive a set of FSMs from a TAG, we do a depth-first traversal of each elementary tree in the grammar (but excluding the root and"
W04-3308,P00-1058,0,0.295422,"om bilexical information that they use (Gildea, 2001; Klein and Manning, 2003). 3 Representing a TAG as a Set of FSMs For the purpose of our parser, we represent a Tree Adjoining Grammar as a set of finite-state machines (FSMs). The FSMs form a (lexicalized) Recursive Transition Network (RTN). To extract an RTN from the Penn Treebank (PTB), we first extract a TAG, and then convert it to an RTN. This first step does not represent the research reported in this paper, and we describe it only for the sake of clarity. We use the approach of (Chen, 2001) (which is similar to (Xia et al., 2000) and (Chiang, 2000)). We use sections 02 to 21 of the Penn Treebank. However, we optimize the head percolation in the grammar extraction module to create meaningful dependency structures, rather than (for example) maximally simple elementary tree structures. For example, we include long-distance dependencies (wh-movement, relativization) in elementary trees, we distinguish passive transitives without byphrase from active intransitives, and we include strongly governed prepositions (as determined in the PTB annotation, including passive by-phrases) in elementary verbal trees. Generally, function words such as aux"
W04-3308,P02-1042,0,0.128533,"Missing"
W04-3308,P97-1003,0,0.163256,"a new domain, a nonlexical structural model can be reused from a previous domain, and only a supertagged corpus in the new domain is needed (to train the supertagger), not a structurally annotated corpus. Furthermore, this approach uses an explicit lexicalized grammar. As a consequence, when porting a parser to a new domain, learned parser preferences in the supertagger can be overridden explicitly for domain-idiosyncratic words before the parse happens. This overriding can happen through manually written or learned rules. By way of anecdotal example, in a recent application of the parser of Collins (1997) in which the WSJ-trained parser was applied to rather different text, sentences such as John put the book on the table were mostly analyzed with the PP attached to the noun, not the verb (as was always required in that domain). In the application, this had to be fixed by writing special post-processing code to rearrange the output of the parser; in our approach, we could simply state that put should always have a PP argument before the parse, and correct any output of the supertagger using simple hand-written rules. And finally, we point out that is is a different approach from the dominant b"
W04-3308,W01-0521,0,0.0271495,"by writing special post-processing code to rearrange the output of the parser; in our approach, we could simply state that put should always have a PP argument before the parse, and correct any output of the supertagger using simple hand-written rules. And finally, we point out that is is a different approach from the dominant bilexical one, and it is always worthwhile to pursue new approaches, especially as the performance of the bilexical parsers seems to be plateauing. In fact recent work has questioned to what extent bilexical parsers even profit from bilexical information that they use (Gildea, 2001; Klein and Manning, 2003). 3 Representing a TAG as a Set of FSMs For the purpose of our parser, we represent a Tree Adjoining Grammar as a set of finite-state machines (FSMs). The FSMs form a (lexicalized) Recursive Transition Network (RTN). To extract an RTN from the Penn Treebank (PTB), we first extract a TAG, and then convert it to an RTN. This first step does not represent the research reported in this paper, and we describe it only for the sake of clarity. We use the approach of (Chen, 2001) (which is similar to (Xia et al., 2000) and (Chiang, 2000)). We use sections 02 to 21 of the Penn"
W04-3308,P02-1043,0,0.104902,"Missing"
W04-3308,P03-1054,0,0.0166784,"ecial post-processing code to rearrange the output of the parser; in our approach, we could simply state that put should always have a PP argument before the parse, and correct any output of the supertagger using simple hand-written rules. And finally, we point out that is is a different approach from the dominant bilexical one, and it is always worthwhile to pursue new approaches, especially as the performance of the bilexical parsers seems to be plateauing. In fact recent work has questioned to what extent bilexical parsers even profit from bilexical information that they use (Gildea, 2001; Klein and Manning, 2003). 3 Representing a TAG as a Set of FSMs For the purpose of our parser, we represent a Tree Adjoining Grammar as a set of finite-state machines (FSMs). The FSMs form a (lexicalized) Recursive Transition Network (RTN). To extract an RTN from the Penn Treebank (PTB), we first extract a TAG, and then convert it to an RTN. This first step does not represent the research reported in this paper, and we describe it only for the sake of clarity. We use the approach of (Chen, 2001) (which is similar to (Xia et al., 2000) and (Chiang, 2000)). We use sections 02 to 21 of the Penn Treebank. However, we opt"
W04-3308,C02-2026,1,0.839924,"ht parse, which is not straightforwardly possible in standard TAG parsing using FSMs. Our parsing algorithm is similar to the work of Alshawi et al. (2000). They use cascaded head automata to derive dependency trees, but leave the nature of the cascading under-formalized. Eisner (2000) provides a formalization of a system that uses two different automata to generate left and right children of a head. His formalism is very close to the one we present, but we use a single automaton. Also, the relation to an independently proposed syntactic formalism such as TAG is less obvious. In related work (Rambow et al., 2002), we have used the same automata constructed from an extracted TAG for parsing, but instead of using them in a chart parser, we have used them to construct a single large FSM that produces a dependency tree. Needless to say, the number of embeddings allowed by such an approach is limited. in a first pass before structure is constructed, and structure is constructed only in a second pass in which no lexical information is used (other than the lexical emit probability for supertags). This result motivates further research into supertagging accuracy. If supertagging accuracy is improved, a lightw"
W04-3308,C92-2065,0,0.0324549,"e joint event A1 , . . . , An . A large range of different models can be used to compute such a joint probability, from the simplest which considers that all events are independent to the model that considers that they are all dependent. The three models that we descibe in this section vary in the way they model multi-adjunction (when several auxiliary trees are attached to a single node from the same direction). The reason to focus on this phenomenon comes P (A) = P (Root) Y × P (A) A∈A|O(A)=subst × Y P (LEF T (s, i)) s∈S,i∈nodes(s) × Y P (RIGHT (s, i)) s∈S,i∈nodes(s) This basically follows (Resnik, 1992; Schabes, 1992). The models we discuss here differ in how to compute the terms P (RIGHT (s, i)) and P (LEF T (s, i)). The probability of each attachment is estimated by maximum likelihood (the counts are obtained in the same step as the grammar extraction), and are added to the corresponding transition in the governor’s automaton as its weight. When the probabilistic model associates different 59 a,P(a|a) P(pos=0) p, P(b) ) 0 P(E T AR ND ST (a| a,P b,P(b,pos>2) 1 |a) a,P(a,pos=1) 0 a,P(a|b) b,P (b| b,P(b|a) 3 0 b,P(b,pos=1) |b) ST 2 P(pos>2) 3 b,P(b,pos=2) ND AR T) a,P(a,pos=2) 1 2 P(E b,P(b,"
W04-3308,P94-1022,0,0.010494,"he LDA are obtained by using the LDA as developed previously by Bangalore Srinivas, but using the same grammar we used for the full parser. Note that none of the numbers reported in this section can be directly compared to any numbers reported elsewhere, as 7 Related Work We are not aware of any other work that directly investigates the extent to which supertagging determines parsing. Chiang (2000) also parses with an automatically extracted TIG, but unlike our approach, he uses standard TAG/TIG parsing techniques (i.e., he reconstructs the derived tree in the chart, not the derivation tree). Rogers (1994) proposes a different context-free variant, “regular-form TAG”. The set of regular-form TAGs is a superset of the set of TIGs, and our construction cannot capture the added expressive power of regular-form TAG. Our conversion to FSMs is very similar to that of Evans and Weir (1997). One important difference is that they model TAG, while we model TIG. Another difference is that they use FSMs to encode the sequence of actions that need to be taken during a standard TAG parse (i.e., reconstructing the derived tree), while we encode 61 Method Baseline: LDA Baseline: full parse with random choice M"
W04-3308,J94-1004,0,0.0189536,"closer to predicate-argument structure. 57 In the second step, we directly compile a set of FSMs which are used by the parser. To derive a set of FSMs from a TAG, we do a depth-first traversal of each elementary tree in the grammar (but excluding the root and foot nodes of adjunct auxiliary trees) to obtain a sequence of nonterminal nodes. As usual, the elementary trees are tree schemas, with positions for the lexical heads. Substitution nodes are represented by obligatory transitions, adjunction by optional transitions (selfloops). (Note that in this paper, we assume adjunction as defined by Schabes and Shieber (1994).) Each node becomes two states of the FSM, one state representing the node on the downward traversal on the left side (the left node state), the other representing the state on the upward traversal, on the right side (the right node state). For leaf nodes, the two states immediately follow one another. The states are linearly connected with -transitions, with the left node state of the root node the start state, and its right node state the final state (except for predicative auxiliary trees – see below). We give a sample grammar in Figure 1 and the result of converting one of its trees to a"
W04-3308,J95-4002,0,0.210292,"onnected with -transitions, with the left node state of the root node the start state, and its right node state the final state (except for predicative auxiliary trees – see below). We give a sample grammar in Figure 1 and the result of converting one of its trees to an FSM in Figure 2. For each pair of adjacent states representing a substitution node, we add transitions between them labeled with the names of the trees that can substitute there. For the lexical head, we add a transition on that head. For footnodes of predicative auxiliary trees which are left auxiliary trees (in the sense of Schabes and Waters (1995), i.e., all nonempty frontier nodes are to the left of the footnode), we take the left node state as the final state. Finally, in the basic model in which adjunctions are modeled as independent, we proceed as follows for non-leaf nodes. (In Section 5, we will see two other models that treat non-leaf nodes in a more complex manner.) To each nonleaf state, we add one self loop transition for each tree in the grammar that can adjoin at that state from the specified direction (i.e., for a state representing a node on the downward traversal, the auxiliary tree must adjoin from the left), labeled wi"
W04-3308,C92-2066,0,0.0607005,"A1 , . . . , An . A large range of different models can be used to compute such a joint probability, from the simplest which considers that all events are independent to the model that considers that they are all dependent. The three models that we descibe in this section vary in the way they model multi-adjunction (when several auxiliary trees are attached to a single node from the same direction). The reason to focus on this phenomenon comes P (A) = P (Root) Y × P (A) A∈A|O(A)=subst × Y P (LEF T (s, i)) s∈S,i∈nodes(s) × Y P (RIGHT (s, i)) s∈S,i∈nodes(s) This basically follows (Resnik, 1992; Schabes, 1992). The models we discuss here differ in how to compute the terms P (RIGHT (s, i)) and P (LEF T (s, i)). The probability of each attachment is estimated by maximum likelihood (the counts are obtained in the same step as the grammar extraction), and are added to the corresponding transition in the governor’s automaton as its weight. When the probabilistic model associates different 59 a,P(a|a) P(pos=0) p, P(b) ) 0 P(E T AR ND ST (a| a,P b,P(b,pos>2) 1 |a) a,P(a,pos=1) 0 a,P(a|b) b,P (b| b,P(b|a) 3 0 b,P(b,pos=1) |b) ST 2 P(pos>2) 3 b,P(b,pos=2) ND AR T) a,P(a,pos=2) 1 2 P(E b,P(b,pos>2) a,P(a) P("
W04-3308,W00-1307,0,0.0509159,"parsers even profit from bilexical information that they use (Gildea, 2001; Klein and Manning, 2003). 3 Representing a TAG as a Set of FSMs For the purpose of our parser, we represent a Tree Adjoining Grammar as a set of finite-state machines (FSMs). The FSMs form a (lexicalized) Recursive Transition Network (RTN). To extract an RTN from the Penn Treebank (PTB), we first extract a TAG, and then convert it to an RTN. This first step does not represent the research reported in this paper, and we describe it only for the sake of clarity. We use the approach of (Chen, 2001) (which is similar to (Xia et al., 2000) and (Chiang, 2000)). We use sections 02 to 21 of the Penn Treebank. However, we optimize the head percolation in the grammar extraction module to create meaningful dependency structures, rather than (for example) maximally simple elementary tree structures. For example, we include long-distance dependencies (wh-movement, relativization) in elementary trees, we distinguish passive transitives without byphrase from active intransitives, and we include strongly governed prepositions (as determined in the PTB annotation, including passive by-phrases) in elementary verbal trees. Generally, functio"
W04-3308,1997.iwpt-1.11,0,\N,Missing
W09-3818,W05-1501,1,0.861787,"the number of trees in the forest, such as LFG f-structures construction or some advanced reranking techniques. The experiments detailed in the last part of this paper show that the overgeneration factor of pruned sub-forest is more or less constant (see 6): after pruning the forest so as to keep the n best trees, the resulting forest contains approximately 103 n trees. At least for some post-parsing processes, this overhead is highly problematic. For example, although LFG parsing can be achieved by computing LFG f-structures on top of a c-structure parse forest with a reasonable efficiency (Boullier and Sagot, 2005), it is clear that a 103 factor drastically affects the overall speed of the LFG parser. Therefore, simply pruning the forest is not an adequate solution. However, it will prove useful for comparison purposes. The new direction that we explore in this paper is the production of shared forests that contain exactly the n most likely trees, avoiding both the explicit construction of n different trees and the over-generation of pruning techniques. This can be seen as a transduction which is applied on a forest and produces another forest. The transduction applies some local transformations on the"
W09-3818,P81-1022,0,0.635558,"st and produce shared forests that contain exactly the n most likely trees of the initial forest. Such forests are suitable for subsequent processing, such as (some types of) reranking or LFG fstructure computation, that can be performed ontop of a shared forest, but that may have a high (e.g., exponential) complexity w.r.t. the number of trees contained in the forest. We evaluate the performances of both algorithms on real-scale NLP forests generated with a PCFG extracted from the Penn Treebank. 1 Introduction The output of a CFG parser based on dynamic programming, such as an Earley parser (Earley, 1970), is a compact representation of all syntactic parses of the parsed sentence, called a shared parse forest (Lang, 1974; Lang, 1994). It can represent an exponential number of parses (with respect to the length of the sentence) in a cubic size structure. This forest can be used for further processing, as reranking (Huang, 2008) or machine translation (Mi et al., 2008). When a CFG is associated with probabilistic information, as in a Probabilistic CFG (PCFG), it can be interesting to process only the n most likely trees of the forest. Standard state-of-the-art algorithms that extract the n best"
W09-3818,W05-1506,0,0.594224,"ompact representation of all syntactic parses of the parsed sentence, called a shared parse forest (Lang, 1974; Lang, 1994). It can represent an exponential number of parses (with respect to the length of the sentence) in a cubic size structure. This forest can be used for further processing, as reranking (Huang, 2008) or machine translation (Mi et al., 2008). When a CFG is associated with probabilistic information, as in a Probabilistic CFG (PCFG), it can be interesting to process only the n most likely trees of the forest. Standard state-of-the-art algorithms that extract the n best parses (Huang and Chiang, 2005) produce a collection of trees, losing the factorization that has been achieved by the parser, and reproduce some identical sub-trees in several parses. This situation is not satisfactory since postparsing processes, such as reranking algorithms or attribute computation, cannot take advantage 117 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 117–128, c Paris, October 2009. 2009 Association for Computational Linguistics (resp. upper bound), and can be extracted by the operator lb() (resp. ub()). An instantiated production (or instantiated rule) is a cont"
W09-3818,P08-1067,0,0.0708541,"e number of trees contained in the forest. We evaluate the performances of both algorithms on real-scale NLP forests generated with a PCFG extracted from the Penn Treebank. 1 Introduction The output of a CFG parser based on dynamic programming, such as an Earley parser (Earley, 1970), is a compact representation of all syntactic parses of the parsed sentence, called a shared parse forest (Lang, 1974; Lang, 1994). It can represent an exponential number of parses (with respect to the length of the sentence) in a cubic size structure. This forest can be used for further processing, as reranking (Huang, 2008) or machine translation (Mi et al., 2008). When a CFG is associated with probabilistic information, as in a Probabilistic CFG (PCFG), it can be interesting to process only the n most likely trees of the forest. Standard state-of-the-art algorithms that extract the n best parses (Huang and Chiang, 2005) produce a collection of trees, losing the factorization that has been achieved by the parser, and reproduce some identical sub-trees in several parses. This situation is not satisfactory since postparsing processes, such as reranking algorithms or attribute computation, cannot take advantage 117"
W09-3818,W01-1812,0,0.069726,"Missing"
W09-3818,J93-2004,0,0.031559,"ectangles algorithm to this example, we can now give its final result, in which the axiom’s (unnecessary) decorations have been removed: {1,1} 1,2 S1..3 → A1..2 B2..3 {2,2} 1,1 S1..3 → A1..2 B2..3 → A21..2 A21..2 → a1..2 → B12..3 B12..3 → b2..3 → B22..3 B22..3 → b2..3 Compared to the forest built by the ranksets algorithm, this forest has one less production and one less non-terminal symbol. It has only one more production than the over-generating pruned forest. 4 Experiments on the Penn Treebank The methods described in section 3 have been tested on a PCFG G extracted from the Penn Treebank (Marcus et al., 1993). G has been extracted naively: the trees have been decomposed into binary context free rules, and the probability of every rule has been estimated by its relative frequency (number of occurrences of the rule divided by the number of occurrences of its left hand side). Rules occurring less than 3 times and rules with probabilities lower than 3 × 10−4 have been eliminated. The grammar produced contains 932 non terminals and 3, 439 rules.7 The parsing has been realized using the S YN TAX system which implements, and optimizes, the Earley algorithm (Boullier, 2003). The evaluation has been conduc"
W09-3818,P08-1023,0,0.0155304,"rest. We evaluate the performances of both algorithms on real-scale NLP forests generated with a PCFG extracted from the Penn Treebank. 1 Introduction The output of a CFG parser based on dynamic programming, such as an Earley parser (Earley, 1970), is a compact representation of all syntactic parses of the parsed sentence, called a shared parse forest (Lang, 1974; Lang, 1994). It can represent an exponential number of parses (with respect to the length of the sentence) in a cubic size structure. This forest can be used for further processing, as reranking (Huang, 2008) or machine translation (Mi et al., 2008). When a CFG is associated with probabilistic information, as in a Probabilistic CFG (PCFG), it can be interesting to process only the n most likely trees of the forest. Standard state-of-the-art algorithms that extract the n best parses (Huang and Chiang, 2005) produce a collection of trees, losing the factorization that has been achieved by the parser, and reproduce some identical sub-trees in several parses. This situation is not satisfactory since postparsing processes, such as reranking algorithms or attribute computation, cannot take advantage 117 Proceedings of the 11th International Co"
W09-3818,W03-3005,1,\N,Missing
W11-2917,P10-1001,0,0.0267249,"endent and the governor ... Different Machine Learning techniques can be used in order to learn the weight vector. In our experiment, we used the implementation of (Bohnet, 2010) that is based on MIRA (Crammer et al., 2006), an on-line large margin classifier. The arc factored model, described here, achieves good performances, but it relies on a very strong independence assumption which is that the score of a dependency is independent of its context. Such an independence assumption is linguistically unappealing and more elaborate models, known as second order (Carreras, 2007) and third order (Koo and Collins, 2010) models, which associate a score with pairs of adjacent dependencies in a tree or chains of two or three dependencies, have shown to give better results. Although we have used second order models in our experiments, we will consider in the next two subsections, only first order models, which are conceptually and computationally simpler. dependencies and assigns a score to a dependency, independently of its context. The score of tree T , noted s(T ) in this model is therefore : s(T ) = X λ(i, r, j) (wi ,r,wj ) where (i, r, j) is the dependency that has wi as governor, wj as dependent and r as l"
W11-2917,C10-1011,0,0.0467266,"dependency tree for sentence W = w1 . . . wl and the dependency relation set R is a directed labelled tree (V, A) such that V = {w1 , . . . wn } and A ⊆ V × R × V . 141 with every feature of the model. In first order models, features describe different aspects of a dependency, such as the part of speech of the governor and the dependent, their lexical value, the length of the dependency, the part of speech of tokens between the dependent and the governor ... Different Machine Learning techniques can be used in order to learn the weight vector. In our experiment, we used the implementation of (Bohnet, 2010) that is based on MIRA (Crammer et al., 2006), an on-line large margin classifier. The arc factored model, described here, achieves good performances, but it relies on a very strong independence assumption which is that the score of a dependency is independent of its context. Such an independence assumption is linguistically unappealing and more elaborate models, known as second order (Carreras, 2007) and third order (Koo and Collins, 2010) models, which associate a score with pairs of adjacent dependencies in a tree or chains of two or three dependencies, have shown to give better results. Al"
W11-2917,candito-etal-2010-statistical,0,0.0486859,"Missing"
W11-2917,W07-2216,0,0.0359895,"fficult attachments. Active Learning Strategy The token based active learning algorithm is straightforward. For every iteration of the algorithm, the most uncertain tokens are selected, hand annotated and their sentences are parsed in such a way that the partial annotation is preserved. The new parses are then added to the labeled set 5 As suggested by one of the reviewers, for first order models, the confidence measure can be computed without producing the n-best parses, using marginal probability of an arc existing in any tree, which can be efficiently computed, via the matrix tree theorem (McDonald and Satta, 2007). 147 Labeled Accuracy Score Labeled Accuracy Score 89 88 87 86 85 84 Most Uncertain Dependencies in Pool Uncertain Dependencies of Each Sentence Full Sentence Entropy Random Selection 83 82 89 88 87 86 85 84 Most Uncertain Dependencies in Pool Combined Method Full Sentence Entropy Random Selection 83 82 0 50 100 150 200 250 300 0 Number of manually annotated tokens in the train set (in thousands) 50 100 150 200 250 Number of manually annotated tokens in the train set (in thousands) Figure 5: Learning curves with token selection strategy. Comparison with full sentence strategy and random selec"
W11-2917,D07-1101,0,0.0325064,"speech of tokens between the dependent and the governor ... Different Machine Learning techniques can be used in order to learn the weight vector. In our experiment, we used the implementation of (Bohnet, 2010) that is based on MIRA (Crammer et al., 2006), an on-line large margin classifier. The arc factored model, described here, achieves good performances, but it relies on a very strong independence assumption which is that the score of a dependency is independent of its context. Such an independence assumption is linguistically unappealing and more elaborate models, known as second order (Carreras, 2007) and third order (Koo and Collins, 2010) models, which associate a score with pairs of adjacent dependencies in a tree or chains of two or three dependencies, have shown to give better results. Although we have used second order models in our experiments, we will consider in the next two subsections, only first order models, which are conceptually and computationally simpler. dependencies and assigns a score to a dependency, independently of its context. The score of tree T , noted s(T ) in this model is therefore : s(T ) = X λ(i, r, j) (wi ,r,wj ) where (i, r, j) is the dependency that has wi"
W11-2917,P05-1012,0,0.149293,"the sentence would be a waste of effort. The main novelty of the work reported here is that we explore the other extreme position: instead of considering uncertain sentences, we consider single uncertain word tokens in a sentence. More precisely, we consider the attachment of single word tokens. In the framework of dependency parsing, which is used here, this boils down to selecting, for a token w, its governor and the label of the dependency between w and its governor. The task is therefore to select, in a sentence, the most uncertain dependencies. 2 Graph-Based Parsing Graph-Based parsing (McDonald et al., 2005; K¨ubler et al., 2009) defines a framework for parsing that does not make use of a generative grammar. In such a framework, given a sentence W = w1 . . . wl , any dependency tree1 for W is a valid syntactic representation of W . The heart of a graph-based parser is the scoring function that assigns a score to every tree T ∈ TW , where TW denotes the set of all dependency trees of sentence W . Such scores are usually a weighted sum of the scores of subparts of W . Active learning for parsing using sub-sentential units has already been explored by (Sassano and Kurohashi, 2010). In their work th"
W11-2917,J82-3004,0,0.145175,"uite far from the perfect confidence measure that would achieve a precision and recall of 1. High recall values can be obtained at the cost of very low precision, and inversely, high precision yields very low recall. On average, lower values of n achieve better precision recall tradeoffs but do not allow to reach high recall values. The inability for low values of n to reach high values of recall opens the door for a discussion about the influence of the sentence length on precision recall curves. The number of parses of a sentence is, in the worse case, an exponential function of its length (Church and Patil, 1982). Computing entropy attachment on fixed length n-best parses lists only allow to consider a very limited number of possible governors of a token for longer sentences. A natural solution in order to cope with this problem is to compute variable length n-best lists, where the value of n is a function of the length (l) of the sentence being parsed. It would make sense to let n be an exponential function of l. This approach is in practice impossible since (at least in our implementation of the n best algorithm) the production of the n-best list will take an exponential time. Furthermore, our exper"
W11-2917,R09-1070,0,0.230898,"Missing"
W11-2917,P10-1037,0,0.135403,"ing Graph-Based parsing (McDonald et al., 2005; K¨ubler et al., 2009) defines a framework for parsing that does not make use of a generative grammar. In such a framework, given a sentence W = w1 . . . wl , any dependency tree1 for W is a valid syntactic representation of W . The heart of a graph-based parser is the scoring function that assigns a score to every tree T ∈ TW , where TW denotes the set of all dependency trees of sentence W . Such scores are usually a weighted sum of the scores of subparts of W . Active learning for parsing using sub-sentential units has already been explored by (Sassano and Kurohashi, 2010). In their work they select unreliable dependencies predicted by a parser (a simple shift-reduce parser where dependencies are weighted using an averaged perceptron with polynomial kernels), based on the score the parser assigns to the dependencies. Such dependencies are hand labeled and, based on syntactic characteristics of Japanese syntax (dependencies are projective and oriented from left to right (the governor is always to the right of the dependent)) other dependencies are deduced and this set of dependencies are added to the training set. Our work departs from their in the uncertainty m"
W11-2917,P07-1050,0,0.0195289,"fined as follows: Tˆ3 = arg max s(T ) if j 0 = j and i0 = i and r0 = r =  λ(i, r, j) otherwise   −∞ T ∈L1 The process is iterated until a tree Tˆn has been produced, for a given value of n. The process, as described is not computationnaly optimal since the parser is run n × l times on the same sentence and many operations are duplicated. Much of the redundant work could be avoided using dynamic programming. We are not aware of a general method for efficiently computing n-best parses for graphbased parsing, as it is the case with context-free parsing (Huang and Chiang, 2005). Nevertheless, (Hall, 2007) describes an efficient n-best method for graph-based parsing which is unfortunately limited to first order models. The effect of this new scoring function when parsing sentence W is that the solution produced by the parser will not contain dependency d. Functions λ+ and λ− can be extended in order to force the presence or the absence of any set of dependencies in the output of the parser. Suppose D is a set of dependencies, we define λ+ D the following way: λ+ D (i, r, j) =  +  λd (i, r, j) if (·, ·, j) ∈ D  2.2 λ(i, r, j) otherwise Producing N -Best Parses 3 Given scoring functions λ− D ,"
W11-2917,P02-1016,0,0.383377,"earner. The performances of such methods heavily rely on the definition of a good confidence measure, which measures the confidence the model, in our case the parser, has in the solution it proposes. Active learning has been used for many NLP applications, such as automatic speech recognition, information extraction, part of speech tagging or syntactic parsing. We will not detail the way active learning has been applied to those tasks, the interested reader can find two reasonably recent surveys in (Settles, 2010) and (Olsson, 2009), and concentrate on its application to statistical parsing. (Tang et al., 2002) and (Hwa, 2004) proposed active learning techniques for training probabilistic parsers. They both used uncertainty sampling and suggested a measure of uncertainty based on the entropy of the probability distribution of the parses of a sentence. The idea being that the higher this entropy is, the more uncertain the Current successful probabilistic parsers require large treebanks which are difficult, time consuming, and expensive to produce. Some parts of these data do not contain any useful information for training a parser. Active learning strategies allow to select the most informative sampl"
W11-2917,W05-1506,0,0.0519465,"nd the third best scoring tree Tˆ3 is defined as follows: Tˆ3 = arg max s(T ) if j 0 = j and i0 = i and r0 = r =  λ(i, r, j) otherwise   −∞ T ∈L1 The process is iterated until a tree Tˆn has been produced, for a given value of n. The process, as described is not computationnaly optimal since the parser is run n × l times on the same sentence and many operations are duplicated. Much of the redundant work could be avoided using dynamic programming. We are not aware of a general method for efficiently computing n-best parses for graphbased parsing, as it is the case with context-free parsing (Huang and Chiang, 2005). Nevertheless, (Hall, 2007) describes an efficient n-best method for graph-based parsing which is unfortunately limited to first order models. The effect of this new scoring function when parsing sentence W is that the solution produced by the parser will not contain dependency d. Functions λ+ and λ− can be extended in order to force the presence or the absence of any set of dependencies in the output of the parser. Suppose D is a set of dependencies, we define λ+ D the following way: λ+ D (i, r, j) =  +  λd (i, r, j) if (·, ·, j) ∈ D  2.2 λ(i, r, j) otherwise Producing N -Best Parses 3 Gi"
W11-2917,J04-3001,0,\N,Missing
W12-3412,W09-3821,0,0.0545879,"Missing"
W12-3412,C10-2013,0,0.219842,"ith a linear model (5). The parse with the best score is considered as final. The structure of the paper is the following: in Section 2 we describe the details of our generative parser and in Section 3 our reranking model together with the features templates. Section 4 reports the results of the experiments conducted on the Penn Treebank (Marcus et al., 1994) as well as on the Paris 7 Treebank (Abeillé et al., 2003) and Section 5 concludes the paper. 2 Generative Model The first part of our system, the syntactic analysis itself, generates surface dependency structures in a sequential fashion (Candito et al., 2010b; Candito et al., 2010a). A phrase structure parser based on Latent Variable PCFGs (P CFG -L As) produces tree structures that are enriched with functions and then converted to labelled dependency structures, which will be processed by the parse reranker. 2.1 P CFG -L As Probabilistic Context Free Grammars with Latent Annotations, introduced in (Matsuzaki et al., 2005) can be seen as automatically specialised PCFGs learnt from treebanks. Each symbol of the grammar is enriched with annotation symbols behaving as subclasses of this symbol. More formally, the probability of an unannotated tree i"
W12-3412,candito-etal-2010-statistical,0,0.196867,"ith a linear model (5). The parse with the best score is considered as final. The structure of the paper is the following: in Section 2 we describe the details of our generative parser and in Section 3 our reranking model together with the features templates. Section 4 reports the results of the experiments conducted on the Penn Treebank (Marcus et al., 1994) as well as on the Paris 7 Treebank (Abeillé et al., 2003) and Section 5 concludes the paper. 2 Generative Model The first part of our system, the syntactic analysis itself, generates surface dependency structures in a sequential fashion (Candito et al., 2010b; Candito et al., 2010a). A phrase structure parser based on Latent Variable PCFGs (P CFG -L As) produces tree structures that are enriched with functions and then converted to labelled dependency structures, which will be processed by the parse reranker. 2.1 P CFG -L As Probabilistic Context Free Grammars with Latent Annotations, introduced in (Matsuzaki et al., 2005) can be seen as automatically specialised PCFGs learnt from treebanks. Each symbol of the grammar is enriched with annotation symbols behaving as subclasses of this symbol. More formally, the probability of an unannotated tree i"
W12-3412,W10-1408,1,0.890534,"Missing"
W12-3412,W08-2102,0,0.107256,"for Computational Linguistics, pages 89–99, c Jeju, Republic of Korea, 12 July 2012. 2012 Association for Computational Linguistics pendents of a predicate. On the other hand, dependencies extracted from constituent parses are known to be more accurate than dependencies obtained from dependency parsers. Therefore the solution we choose is an indirect one: we use a phrase-based parser to generate n-best lists and convert them to lists of dependency structures that are reranked. This approach can be seen as trade-off between phrasebased reranking experiments (Collins, 2000) and the approach of Carreras et al. (2008) where a discriminative model is used to score lexical features representing unlabelled dependencies in the Tree Adjoining Grammar formalism. Our architecture, illustrated in Figure 1, is based on two steps. During the first step, a syntagmatic parser processes the input sentence and produces nbest parses as well as their probabilities. They are annotated with a functional tagger which tags syntagms with standard syntactic functions subject, object, indirect object . . . and converted to dependency structures by application of percolation rules. In the second step, we extract a set of features"
W12-3412,P05-1022,0,0.610797,"ect of some recent work thanks to progresses achieved in the field of Machine Learning. A parse tree is represented as a vector of features and its accuracy is measured as the distance between this vector and the reference. One way to take advantage of both approaches is to combine them sequentially, as initially proposed by Collins (2000). A generative parser produces a set of candidates structures that constitute the input of a second, discriminative module, whose search space is limited to this set of candidates. Such an approach, parsing followed by reranking, is used in the Brown parser (Charniak and Johnson, 2005). The approach can be extended in order to feed the reranker with the output of different parsers, as shown by (Johnson and Ural, 2010; Zhang et al., 2009). In this paper we are interested in applying reranking to dependency structures. The main reason is that many linguistic constraints are straightforward to implement on dependency structures, as, for example, subcategorization frames or selectional constraints that are closely linked to the notion of deProceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 89–99, c Jeju, Republic of Korea, 12 July 201"
W12-3412,P97-1003,0,0.249871,"his can be implemented efficiently using two weight vectors as for the averaged perceptron. parses as possible, but specific enough to characterize good and bad configurations in the parse tree. We extended the feature set from (McDonald, 2006) which showed to be effective for a range of languages. Our feature templates can be categorized in 5 classes according to their domain of locality. In the following, we describe and exemplify these templates on the following sentence from the Penn treebank, in which we target the PMOD dependency between “at” and “watch.” like bilexical dependencies in (Collins, 1997). l Given dependency xi → xj , the feature created is (word xi , lemma xi , pos-tag xi , word xj , lemma xj , pos-tag xj , distance3 from i to j, direction, type). The previous example generates the following feature: [at, at, IN, watch, watch, NN, 2, R, PMOD] Where 2 is the distance between “at” and “watch”. Probability Three features are derived from the P CFG -L A parser, namely the posterior probability of the parse (eq. 1), its normalized probability relative to the 1-best, and its rank in the n-best list. Unigram Unigram features are the most simple as they only involve one word. Given a"
W12-3412,Y09-1013,0,0.0423233,"odel, namely Tree Adjoining Grammars, and the system of Suzuki et al. (2009) that makes use of external data (unannotated text). Huang, 2008 Bohnet, 2010 Zhang et al, 2008 Huang and Sagae, 2010 Charniak et al, 2005 Carreras et al. 2008 Suzuki et al. 2009 This work F 91.7 – 91.4 – 91.5 – – 91.1 LAS – 90.3 – – 90.0 – – 89.8 UAS – – 93.2 92.1 94.0 93.5 93.8 93.9 Table 3: Comparison on PTB Test set For French, see Table 4, we compare our system with the M ATE parser (Bohnet, 2010), an improvement over the MST parser (McDonald et al., 2005) with hash kernels, using the ME LT part-of-speech tagger (Denis and Sagot, 2009) and our own lemmatiser. We also compare the French system with results drawn from the benchmark performed by Candito et al. (2010a). The first system (BKY-FR) is close to ours without the reranking module, using the Berkeley parser adapted to French. The second (MSTFR) is based on MSTParser (McDonald et al., 2005). These two system use word clusters as well. The next section takes a close look at the models 96 This work M ATE + ME LT B KY-F R M ST-F R F < 40 89.2 – 88.2 – LAS 89.2 89.2 86.8 88.2 UAS 92.1 91.8 91.0 90.9 Table 4: Comparison on FTB Test set 4.3.4 Model Analysis It is interesting"
W12-3412,P08-1067,0,0.164776,"k + MElt 87.4 89.2 89.2 92.1 7 The model is always trained with 100 candidates. F < 40 is the parseval F-score for sentences with less than 40 words. 8 95 Table 2: System results on FTB Test set 4.3.3 Comparison with Related Work of the reranker and its impact on performance. We compare our results with related parsing results on English and French. For English, the main results are shown in Table 3. From the presented data, we can see that indirect reranking on LAS may not seem as good as direct reranking on phrase-structures compared to F-scores obtained in (Charniak and Johnson, 2005) and (Huang, 2008) with one parser or (Zhang et al., 2009) with several parsers. However, our system does not rely on any language specific feature and can be applied to other languages/treebanks. It is difficult to compare our system for LAS because most systems evaluate on gold data (part-of-speech, lemmas and morphological information) like Bohnet (2010). Our system also compares favourably with the system of Carreras et al. (2008) that relies on a more complex generative model, namely Tree Adjoining Grammars, and the system of Suzuki et al. (2009) that makes use of external data (unannotated text). Huang, 2"
W12-3412,W07-2416,0,0.0538469,"Missing"
W12-3412,H94-1020,0,0.383534,"tion w (5) MIRA reranking Final constituency & dependency parse Figure 1: The parsing architecture: production of the nbest syntagmatic trees (1) tagged with functional labels (2), conversion to a dependency structure (3) and feature extraction (4), scoring with a linear model (5). The parse with the best score is considered as final. The structure of the paper is the following: in Section 2 we describe the details of our generative parser and in Section 3 our reranking model together with the features templates. Section 4 reports the results of the experiments conducted on the Penn Treebank (Marcus et al., 1994) as well as on the Paris 7 Treebank (Abeillé et al., 2003) and Section 5 concludes the paper. 2 Generative Model The first part of our system, the syntactic analysis itself, generates surface dependency structures in a sequential fashion (Candito et al., 2010b; Candito et al., 2010a). A phrase structure parser based on Latent Variable PCFGs (P CFG -L As) produces tree structures that are enriched with functions and then converted to labelled dependency structures, which will be processed by the parse reranker. 2.1 P CFG -L As Probabilistic Context Free Grammars with Latent Annotations, introdu"
W12-3412,P05-1010,0,0.0421253,"as on the Paris 7 Treebank (Abeillé et al., 2003) and Section 5 concludes the paper. 2 Generative Model The first part of our system, the syntactic analysis itself, generates surface dependency structures in a sequential fashion (Candito et al., 2010b; Candito et al., 2010a). A phrase structure parser based on Latent Variable PCFGs (P CFG -L As) produces tree structures that are enriched with functions and then converted to labelled dependency structures, which will be processed by the parse reranker. 2.1 P CFG -L As Probabilistic Context Free Grammars with Latent Annotations, introduced in (Matsuzaki et al., 2005) can be seen as automatically specialised PCFGs learnt from treebanks. Each symbol of the grammar is enriched with annotation symbols behaving as subclasses of this symbol. More formally, the probability of an unannotated tree is the sum of the probabilities of its annotated counterparts. For a P CFG -L A G, R is the set of annotated rules, D(t) is the set of (annotated) derivations of an unannotated tree t, and R(d) is the set of rules used in a derivation d. Then the probability assigned by G to t is: PG (t) = X d∈D(t) PG (d) = X Y PG (r) (1) 3 Discriminative model d∈D(t) r∈R(d) Because of t"
W12-3412,P05-1012,0,0.0505025,"h the system of Carreras et al. (2008) that relies on a more complex generative model, namely Tree Adjoining Grammars, and the system of Suzuki et al. (2009) that makes use of external data (unannotated text). Huang, 2008 Bohnet, 2010 Zhang et al, 2008 Huang and Sagae, 2010 Charniak et al, 2005 Carreras et al. 2008 Suzuki et al. 2009 This work F 91.7 – 91.4 – 91.5 – – 91.1 LAS – 90.3 – – 90.0 – – 89.8 UAS – – 93.2 92.1 94.0 93.5 93.8 93.9 Table 3: Comparison on PTB Test set For French, see Table 4, we compare our system with the M ATE parser (Bohnet, 2010), an improvement over the MST parser (McDonald et al., 2005) with hash kernels, using the ME LT part-of-speech tagger (Denis and Sagot, 2009) and our own lemmatiser. We also compare the French system with results drawn from the benchmark performed by Candito et al. (2010a). The first system (BKY-FR) is close to ours without the reranking module, using the Berkeley parser adapted to French. The second (MSTFR) is based on MSTParser (McDonald et al., 2005). These two system use word clusters as well. The next section takes a close look at the models 96 This work M ATE + ME LT B KY-F R M ST-F R F < 40 89.2 – 88.2 – LAS 89.2 89.2 86.8 88.2 UAS 92.1 91.8 91."
W12-3412,P08-1108,0,0.0159804,"al linguistic knowledge (lexical preferences, subcategorisation frames, copula verbs, coordination symmetry . . . ). Integrating features from the phrase-structure trees is also an option that needs to be explored. Third this architecture enables the integration of several systems. We experimented on French using a part-of-speech tagger but we could also use another parser and either use the methodology of (Johnson and Ural, 2010) or (Zhang et al., 2009) which fusion n-best lists form different parsers, or use stacking methods where an additional parser is used as a guide for the main parser (Nivre and McDonald, 2008). Finally it should be noted that this system does not rely on any language specific feature, and thus can be applied to languages other that French or English S NP VP NP syntagmatic parses S NP PP QP VP NP PP NP PP QP NP NNP May PP NP NP CD 31 NNS VBD CD CD IN NNS Stocks were 698 million bushels on IN DT NN . of this year . NNP May CD 31 IN DT NN . of this year . dependency parses IN NNS VBD CD CD NNS Stocks were 698 million bushels on NP Before reranking After reranking Figure 3: English sentence from the WSJ test set for which the reranker selected the correct tree while the first candidate"
W12-3412,N07-1051,0,0.0129372,"ore formally, the probability of an unannotated tree is the sum of the probabilities of its annotated counterparts. For a P CFG -L A G, R is the set of annotated rules, D(t) is the set of (annotated) derivations of an unannotated tree t, and R(d) is the set of rules used in a derivation d. Then the probability assigned by G to t is: PG (t) = X d∈D(t) PG (d) = X Y PG (r) (1) 3 Discriminative model d∈D(t) r∈R(d) Because of this alternation of sums and products that cannot be optimally factorised, there is no exact polynomial dynamic programming algorithm for parsing. Matsuzaki et al. (2005) and Petrov and Klein (2007) discuss approximations of the decoding step based on a Bayesian variational approach. This enables cubic time decoding that can be further enhanced with coarse-to-fine methods (Charniak and Johnson, 2005). This type of grammars has already been tested on a variety of languages, in particular English and French, giving state-of-the-art results. Let us stress that this phrase-structure formalism is not lexicalised as opposed to grammars previously used in reranking experiments (Collins, 2000; Charniak and Johnson, 2005). The notion of lexical head is therefore absent at parsing time and will be"
W12-3412,P06-1055,0,0.0101291,"entence and produces nbest parses as well as their probabilities. They are annotated with a functional tagger which tags syntagms with standard syntactic functions subject, object, indirect object . . . and converted to dependency structures by application of percolation rules. In the second step, we extract a set of features from the dependency parses and the associated probabilities. These features are used to reorder the n-best list and select a potentially more accurate parse. Syntagmatic parses are produced by the implementation of a P CFG - LA parser of (Attia et al., 2010), similar to (Petrov et al., 2006), a functional tagger and dependency converter for the target language. The reranking model is a linear model trained with an implementation of the M IRA algorithm (Crammer et al., 2006)1 . Charniak and Johnson (2005) and Collins (2000) rerank phrase-structure parses and they also include head-dependent information, in other words unlabelled dependencies. In our approach we take into account grammatical functions or labelled dependencies. It should be noted that the features we use are very generic and do not depend on the linguistic knowledge of the authors. We applied our method to English,"
W12-3412,N10-1049,0,0.020729,"(Candito et al., 2010b) showed that a sequential approach is better than an integrated one for contextfree grammars, because the strong independence hypothesis of this formalism implies a restricted domain of locality which cannot express the context needed to properly assign functions. Most functional taggers, such as the ones used in the following experiments, rely on classifiers whose feature sets can describe the whole context of a node in order to make a decision. Dependency Structures A syntactic theory can either be expressed with phrase structures or dependencies, as advocated for in (Rambow, 2010). However, some information may be simpler to describe in one of the representations. This equivalence between the modes of representations only stands if the informational contents are the same. Unfortunately, this is not the case here because the phrase structures that we use do not contain functional annotations and lexical heads, whereas labelled dependencies do. 91 Our discriminative model is a linear model trained with the Margin-Infused Relaxed Algorithm (M IRA) (Crammer et al., 2006). This model computes the score of a parse tree as the inner product of a feature vector and a weight ve"
W12-3412,sagot-2010-lefff,0,0.0216271,"r as in (Candito and Crabbé, 2009). For both languages we constructed 10-fold training data from train sets in order to avoid overfitting the training data. The trees from training sets were divided into 10 subsets and the parses for each subset were generated by a parser trained on the other 4 Functions are omitted. 94 9 subsets. Development and test parses are given by a parser using the whole training set. Development sets were used to choose the best reranking model. For lemmatisation, we use the MATE lemmatiser for English and a home-made lemmatiser for French based on the lefff lexicon (Sagot, 2010). 4.2 Generative Model The performances of our parser are summarised in Figure 2, (a) and (b), where F-score denotes the Parseval F-score5 , and LAS and UAS are respectively the Labelled and Unlabelled Attachment Score of the converted dependency structures6 . We give oracle scores (the score that our system would get if it selected the best parse from the n-best lists) when the parser generates n-best lists of depth 10, 20, 50 and 100 in order to get an idea of the effectiveness of the reranking process. One of the issues we face with this approach is the use of an imperfect functional annota"
W12-3412,D09-1058,0,0.0661606,"Missing"
W12-3412,D09-1161,0,0.19433,"sured as the distance between this vector and the reference. One way to take advantage of both approaches is to combine them sequentially, as initially proposed by Collins (2000). A generative parser produces a set of candidates structures that constitute the input of a second, discriminative module, whose search space is limited to this set of candidates. Such an approach, parsing followed by reranking, is used in the Brown parser (Charniak and Johnson, 2005). The approach can be extended in order to feed the reranker with the output of different parsers, as shown by (Johnson and Ural, 2010; Zhang et al., 2009). In this paper we are interested in applying reranking to dependency structures. The main reason is that many linguistic constraints are straightforward to implement on dependency structures, as, for example, subcategorization frames or selectional constraints that are closely linked to the notion of deProceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 89–99, c Jeju, Republic of Korea, 12 July 2012. 2012 Association for Computational Linguistics pendents of a predicate. On the other hand, dependencies extracted from constituent parses are known to b"
W12-3412,C10-1011,0,\N,Missing
W12-3412,N10-1095,0,\N,Missing
W12-5107,P85-1037,0,0.348154,"ach with its own definition which is examined separately. Hence, the hierarchy actually detects académie-6 → école-1 → établissement After a successful connection attempt, the pairs of unique senses immediately connected to each other (like académie-6 → école-1) are recorded and a frequentation counter associated with the sense pair is incremented. The result of the process allows us to tell which sense of école is expressed in the definition of académie that we considered. 2 Several studies proposed automatic or semi-automatic methods to develop lexical hierarchies from dictionary data, e.g. [2, 10]. 82 2 Resources 2.1 TLFi The Trésor de la Langue française informatisé (TLFi) [11] is the digital version of the Trésor de la Langue française, a large reference dictionary for French. The two main reasons why we have chosen the TLFi is that it is available in electronic form for research purpose and that most of its definitions belong to so-called definitions by genus and differentiæ allowing us to extract genus (or hypernym of the defined unit). The TLFi has also a wide coverage with around 270,000 definitions. This study is restricted to nouns, for which the TLFi provide 100,493 definition"
W12-5107,hanoka-sagot-2012-wordnet,1,0.806801,"om the Princeton WordNet (PWN) and various other resources [12]. Monosemous literals in the PWN 2.0 were translated using a bilingual French-English lexicon built from various multilingual resources. Polysemous PWN literals were handled by an alignment approach based on a multilingual parallel corpus. The synsets obtained from both approaches were then merged. The resulting resource, WOLF, preserves the hierarchy and structure of PWN 2.0 and contains the definitions and usage examples provided in PWN for each synset. Although new approaches are currently being used for increasing its coverage [5], WOLF is rather sparse, as information was not found for all PWN synsets by these automatic methods. Indeed, one of the difficulties in completing WOLF is to disambiguate the words contained in its synsets as to 4 http://alpage.inria.fr/~sagot/wolf.html 85 allow a correct translation, since the level of polysemy is high. In this work, we used the version 0.2.0 of the WOLF, in which 46,449 out of the 115,424 PWN 2.0 synsets are filled with at least one French literal. WOLF 0.2.0 contains 50,968 unique literals which take part in 86,235 (literal, synset) pairs, i.e., lexical entries (to be comp"
W12-5107,P11-4015,1,0.82167,"e Definiens project, TLFi definitions of nouns were POS-tagged and processed to determine the genus of a given definition, that is, the noun or noun phrase that corresponds to the hypernym of the defined noun [1]. The Definiens heuristic relies on lexicosyntactic patterns that recognise nouns or noun phrases as possible genus candidates. More precisely, around fifty rules have been manually elaborated to identify geni in the TLFi definitions. Represented as finite-state transducers, the rules have been run on definitions previously labeled with part of speech tags by the NLP tool suite MACAON [8]. The rule presented in figure 1 identifies nominal definitions that begin with a common noun (nc for nom commun in French), followed by a preposition and then another noun (left hand side of the rule). The right hand side of the rule proposes two possible geni for this kind definition: the first noun or a more specific phrasal genus constituted by the three elements (noun, preposition, noun) detected in the left hand side of the rule. This rule matches for example the definition of JODHPURS presented below since it begins with a noun (pantalon) followed by a preposition (de) followed by a nou"
W12-5107,E09-1068,0,0.0233717,"with a set of word sense pairs that TLFi puts in direct hypernymy relation. We can then use these pairs to populate WOLF: if two words w and W are deemed to have definitions d and D in direct hypernymy according to TLFi, and belong to synsets s and S in WOLF, these synsets also being in the hypernymy relation, then we can safely identify d to s and D to S. To disambiguate the hyponyms of an (h, H) pair, we explore the graph by hypernymic ascent: we consider the different senses h1 , . . . , hn that TLFi provides for h, and attempt to connect each of them to any of the senses of H. Inspired by [9], we propose a connection scheme whereby we jump from one word to a word of its definition, iteratively, until we reach the target H. In our implementation of the hypernymic ascent scheme, we select the genus of the 86 action action attaque assaut abordage abordage Figure 3: TLFi ambiguous structure (left) WOLF structure (right) definition of a word (that can also be considered as its hypernym) to carry on the next iteration step, taking advantage of the preprocessing performed in the Definiens project [1]. This process is illustrated in figure 3. In the left hand part of the figure, we have r"
W14-5311,E06-1047,0,0.0770861,"eated a Levantine annotated corpus (oral transcriptions) for speech recognition research. (Habash et al., 2005; Habash and Rambow, 2006) proposed a system including a morphological analyzer and a generator for Arabic dialects (MAGEAD) used for MSA and Levantine Arabic. (Habash et al., 2012) also built a morphological analyzer for Egyptian Arabic that extends an existing resource, the Egyptian Colloquial Arabic Lexicon. Other approaches take advantage of the special relation (closeness) that exists betweeen MSA and dialects in order to adapt MSA resources and tools to dialects. To name a few, (Chiang et al., 2006) used MSA treebanks to parse Levantine Arabic. (Sawaf, 2010) presented a translation system for handling dialectal Arabic, using an algorithm to normalize spontaneous and dialectal Arabic into MSA. (Salloum and Habash, 2013) developped a translation system pivoting through MSA from some Arabic dialects (Levantine, Egyptian, Iraqi, and Gulf Arabic) to English. (Hamdi et al., 2013) proposed a translation system between Tunisian (TUN) and MSA verbs using an analyser and a generator for both variants. Yet if the first kind of approach is more linguistically accurate because it takes into account s"
W14-5311,P06-1086,0,0.382042,"unication on the web (social networks, blogs and forums). Such unstandardized varieties differ from MSA with respect to phonology, morphology, syntax and the lexicon. Linguistic resources (lexica, corpora) and natural language processing (NLP) tools for such dialects (parsers) are very rare. Different approaches are discussed in the litterature to cope with Arabic dialects processing. A general solution is to build specific resources and tools. For example, (Maamouri et al., 2004) created a Levantine annotated corpus (oral transcriptions) for speech recognition research. (Habash et al., 2005; Habash and Rambow, 2006) proposed a system including a morphological analyzer and a generator for Arabic dialects (MAGEAD) used for MSA and Levantine Arabic. (Habash et al., 2012) also built a morphological analyzer for Egyptian Arabic that extends an existing resource, the Egyptian Colloquial Arabic Lexicon. Other approaches take advantage of the special relation (closeness) that exists betweeen MSA and dialects in order to adapt MSA resources and tools to dialects. To name a few, (Chiang et al., 2006) used MSA treebanks to parse Levantine Arabic. (Sawaf, 2010) presented a translation system for handling dialectal A"
W14-5311,W05-0703,0,0.331399,"informal written communication on the web (social networks, blogs and forums). Such unstandardized varieties differ from MSA with respect to phonology, morphology, syntax and the lexicon. Linguistic resources (lexica, corpora) and natural language processing (NLP) tools for such dialects (parsers) are very rare. Different approaches are discussed in the litterature to cope with Arabic dialects processing. A general solution is to build specific resources and tools. For example, (Maamouri et al., 2004) created a Levantine annotated corpus (oral transcriptions) for speech recognition research. (Habash et al., 2005; Habash and Rambow, 2006) proposed a system including a morphological analyzer and a generator for Arabic dialects (MAGEAD) used for MSA and Levantine Arabic. (Habash et al., 2012) also built a morphological analyzer for Egyptian Arabic that extends an existing resource, the Egyptian Colloquial Arabic Lexicon. Other approaches take advantage of the special relation (closeness) that exists betweeen MSA and dialects in order to adapt MSA resources and tools to dialects. To name a few, (Chiang et al., 2006) used MSA treebanks to parse Levantine Arabic. (Sawaf, 2010) presented a translation syste"
W14-5311,W12-2301,0,0.0465374,"exicon. Linguistic resources (lexica, corpora) and natural language processing (NLP) tools for such dialects (parsers) are very rare. Different approaches are discussed in the litterature to cope with Arabic dialects processing. A general solution is to build specific resources and tools. For example, (Maamouri et al., 2004) created a Levantine annotated corpus (oral transcriptions) for speech recognition research. (Habash et al., 2005; Habash and Rambow, 2006) proposed a system including a morphological analyzer and a generator for Arabic dialects (MAGEAD) used for MSA and Levantine Arabic. (Habash et al., 2012) also built a morphological analyzer for Egyptian Arabic that extends an existing resource, the Egyptian Colloquial Arabic Lexicon. Other approaches take advantage of the special relation (closeness) that exists betweeen MSA and dialects in order to adapt MSA resources and tools to dialects. To name a few, (Chiang et al., 2006) used MSA treebanks to parse Levantine Arabic. (Sawaf, 2010) presented a translation system for handling dialectal Arabic, using an algorithm to normalize spontaneous and dialectal Arabic into MSA. (Salloum and Habash, 2013) developped a translation system pivoting throu"
W14-5311,N13-1036,0,0.0600667,"alects (MAGEAD) used for MSA and Levantine Arabic. (Habash et al., 2012) also built a morphological analyzer for Egyptian Arabic that extends an existing resource, the Egyptian Colloquial Arabic Lexicon. Other approaches take advantage of the special relation (closeness) that exists betweeen MSA and dialects in order to adapt MSA resources and tools to dialects. To name a few, (Chiang et al., 2006) used MSA treebanks to parse Levantine Arabic. (Sawaf, 2010) presented a translation system for handling dialectal Arabic, using an algorithm to normalize spontaneous and dialectal Arabic into MSA. (Salloum and Habash, 2013) developped a translation system pivoting through MSA from some Arabic dialects (Levantine, Egyptian, Iraqi, and Gulf Arabic) to English. (Hamdi et al., 2013) proposed a translation system between Tunisian (TUN) and MSA verbs using an analyser and a generator for both variants. Yet if the first kind of approach is more linguistically accurate because it takes into account specificities of each dialect, building resources from scratch is costly and extremely time consuming. In this paper we will thus adopt the second approach: we will present a method to automatically build a lexicon for Tunisi"
W14-5311,2010.amta-papers.5,0,0.481334,"recognition research. (Habash et al., 2005; Habash and Rambow, 2006) proposed a system including a morphological analyzer and a generator for Arabic dialects (MAGEAD) used for MSA and Levantine Arabic. (Habash et al., 2012) also built a morphological analyzer for Egyptian Arabic that extends an existing resource, the Egyptian Colloquial Arabic Lexicon. Other approaches take advantage of the special relation (closeness) that exists betweeen MSA and dialects in order to adapt MSA resources and tools to dialects. To name a few, (Chiang et al., 2006) used MSA treebanks to parse Levantine Arabic. (Sawaf, 2010) presented a translation system for handling dialectal Arabic, using an algorithm to normalize spontaneous and dialectal Arabic into MSA. (Salloum and Habash, 2013) developped a translation system pivoting through MSA from some Arabic dialects (Levantine, Egyptian, Iraqi, and Gulf Arabic) to English. (Hamdi et al., 2013) proposed a translation system between Tunisian (TUN) and MSA verbs using an analyser and a generator for both variants. Yet if the first kind of approach is more linguistically accurate because it takes into account specificities of each dialect, building resources from scratc"
W14-5311,I13-1048,0,\N,Missing
W15-0212,N09-2022,0,\N,Missing
W15-0212,J14-1002,0,\N,Missing
W15-0212,P11-4015,1,\N,Missing
W15-0212,J02-3001,0,\N,Missing
W15-0212,bazillon-etal-2012-syntactic,1,\N,Missing
W15-0212,bechet-etal-2012-decoda,1,\N,Missing
W15-3207,P13-2081,0,0.0194228,"Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot; become in TUN respectively +« ς+ and +Ó m+ proclitics when the word following is definite (marked by the determinant 1 In Arabic orthography, short vowels are represented with optional diacritics which makes the language ambiguous. 2 Arabic orthographic trans"
W15-3207,al-sabbagh-girju-2010-mining,0,0.0234652,"erived from the root Ð h. h H j m and the patterns 1a22i3 and 1a22A3 respectively. • lexical variations: from a lexical point of view, the differences between MSA and TUN are significant. They are mainly due to the influence of other languages. Such TUN words still generally follow MSA morphology, sharing the same inflectional and derivational rules. Table 1 gives some examples of words of different origins. 3 Related work Processing Arabic dialects Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are someti"
W15-3207,feldman-etal-2006-cross,0,0.0816915,"Missing"
W15-3207,altantawy-etal-2010-morphological,1,0.844358,"phic representations. In our example, two rules are applied. First, the gemination3 rule, which allows to delete the vowel between the second and the third radical if it is followed by a suffix starting with a vowel. Then, a phonological rule that transforms the /t/ of the pattern i1ta2a3 to /T/.4 We get, at this step: /wa+iDTar∼+uwA/. Morphological analysis and generation of Arabic and its dialect MAGEAD is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). It processes Arabic verbs (Habash and Rambow, 2006; Habash et al., 2005) and Arabic nouns (Altantawy et al., 2010). MAGEAD relates a deep representation of a word with its surface form through a sequence of transformations. It can be used bidirectionally, to generate, as well as to analyze, surface forms. At a deep representation level, MAGEAD represents a word as a root, a pattern and a set of feature-value pairs. The features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. Finally, morphological and phonological rewrite rules are applied. To describe the different processes made by MAGEAD, we use  @ ð waAiDTar∼uwA &quot;and the surface form @ð Q¢ they were"
W15-3207,P05-1071,1,0.680538,"trigram model is used to give the first best path while the unigram allowed to filter and score the lattice. Three different inputs can be handled by the POS tagger: an unscored lattice derived from the conversion, a scored lattice produced by the disambiguation based on the unigram language model and the first best path generated by the 3gram language model. 5.3 Table 4 gives the results of POS tagging of a MSA corpus using our different HMM taggers. These results are comparable to state-of-the-art MSA POS tagging systems: Habash and Roth (2009) report a higher result using the MADA system (Habash and Rambow, 2005). However, we cannot use the MADA system because it does not support POS tagging over a lattice, which we need for TUN POS tagging. It should be noted that the results in the table are for forms (real task), but also for gold lemmas and lmms. We present the lemma and lmm results only for comparative reasons as the starting point is artificial, and the performance numbers should be seen as upper bounds. bigram trigram Pos-Tagging forms 94.52 94.72 gold lemmas 97.61 97.63 gold lmms 96.84 96.94 Table 4: Accuracy of POS tagging of MSA corpus The taggers used in this work are based on Hidden Markov"
W15-3207,W13-2813,0,0.0208615,"re details, see (Hamdi et al., 2013). Due to the lexical differences between MSA and TUN, the conversion process cannot be limited to morphological transformations and requires some lexical transformations. We used three lexica to map from TUN to MSA: a lexicon of verbs, a lexicon of deverbal nouns and a lexicon of particles. 4.2.3 Lexicon of particles Arabic particles cover many categories: conjunctions, prepositions, clitics . . . Our lexicon, made of about 200 pairs (MSA particle, TUN particle), includes all of them. The MSA particles are extracted from the PATB and then translated to TUN (Boujelbane et al., 2013). In its current version, the lexicon matches 262 Tunisian particles to 143 MSA particles. 4.2.1 5 4.2 Lexica Lexicon of verbs Architecture and experiments Our system consists of three step: conversion, disambiguation and POS tagging. The TUN input sentence t1 t2 t3 . . . tn , is converted to a MSA lattice. The lattice is then disambiguated to produce a pseudo MSA target sentence m1 m2 m3 . . . mn . Next, a MSA tagger assign to The verbal lexicon consists of pairs of the form (PM SA , PT U N ) where PM SA and PT U N are themselves pairs made of a root and a pattern. Its development was based o"
W15-3207,P06-1086,1,0.882041,"ap the morphemic representation to the phonological and orthographic representations. In our example, two rules are applied. First, the gemination3 rule, which allows to delete the vowel between the second and the third radical if it is followed by a suffix starting with a vowel. Then, a phonological rule that transforms the /t/ of the pattern i1ta2a3 to /T/.4 We get, at this step: /wa+iDTar∼+uwA/. Morphological analysis and generation of Arabic and its dialect MAGEAD is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). It processes Arabic verbs (Habash and Rambow, 2006; Habash et al., 2005) and Arabic nouns (Altantawy et al., 2010). MAGEAD relates a deep representation of a word with its surface form through a sequence of transformations. It can be used bidirectionally, to generate, as well as to analyze, surface forms. At a deep representation level, MAGEAD represents a word as a root, a pattern and a set of feature-value pairs. The features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. Finally, morphological and phonological rewrite rules are applied. To describe the different processes made by MAGEAD, w"
W15-3207,P09-2056,1,0.929017,"n corpus, it is a collection of political debates transcriptions. The trigram model is used to give the first best path while the unigram allowed to filter and score the lattice. Three different inputs can be handled by the POS tagger: an unscored lattice derived from the conversion, a scored lattice produced by the disambiguation based on the unigram language model and the first best path generated by the 3gram language model. 5.3 Table 4 gives the results of POS tagging of a MSA corpus using our different HMM taggers. These results are comparable to state-of-the-art MSA POS tagging systems: Habash and Roth (2009) report a higher result using the MADA system (Habash and Rambow, 2005). However, we cannot use the MADA system because it does not support POS tagging over a lattice, which we need for TUN POS tagging. It should be noted that the results in the table are for forms (real task), but also for gold lemmas and lmms. We present the lemma and lmm results only for comparative reasons as the starting point is artificial, and the performance numbers should be seen as upper bounds. bigram trigram Pos-Tagging forms 94.52 94.72 gold lemmas 97.61 97.63 gold lmms 96.84 96.94 Table 4: Accuracy of POS tagging"
W15-3207,E06-1047,1,0.908066,"Missing"
W15-3207,W05-0703,1,0.756785,"tation to the phonological and orthographic representations. In our example, two rules are applied. First, the gemination3 rule, which allows to delete the vowel between the second and the third radical if it is followed by a suffix starting with a vowel. Then, a phonological rule that transforms the /t/ of the pattern i1ta2a3 to /T/.4 We get, at this step: /wa+iDTar∼+uwA/. Morphological analysis and generation of Arabic and its dialect MAGEAD is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). It processes Arabic verbs (Habash and Rambow, 2006; Habash et al., 2005) and Arabic nouns (Altantawy et al., 2010). MAGEAD relates a deep representation of a word with its surface form through a sequence of transformations. It can be used bidirectionally, to generate, as well as to analyze, surface forms. At a deep representation level, MAGEAD represents a word as a root, a pattern and a set of feature-value pairs. The features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. Finally, morphological and phonological rewrite rules are applied. To describe the different processes made by MAGEAD, we use  @ ð waAiDTar∼"
W15-3207,P11-1061,0,0.0825298,"Missing"
W15-3207,W05-0708,0,0.325435,"Missing"
W15-3207,habash-etal-2012-conventional,1,0.844173,"s all phonemes that exist in MSA. However, TUN has three extra phonemes /p/, /v/ and /g/. To a lesser extent, variations appear in some common words, that consist in dropping some short vowels1 on  the TUN side. For instance, H . AJ» ktAb2  &quot;book&quot; and I . J» ktb &quot;to write&quot; which exist in both languages but are pronounced differently: /kitAb/, /katab/ in MSA and /ktAb/, /ktib/ in Tunisian dialect. Concerning orthography, unlike MSA, which already has a standard orthography, Tunisian dialect is unstandardized. Zribi et al. (2014) proposes orthographic standards for TUN, following the works of Habash et al. (2012), that aim to establish a common orthographic convention for all Arabic dialects. marker +Ë@ Al+). Furthermore, indirect object pronouns are realized as enclitics in TUN verbs and not in MSA. On the other hand, some MSA clitics are detached in TUN. The MSA future particle proclitic + sa+ is real . bAš with ized as the autonomous particle AK TUN verbs. As for inflectional morphology, MSA has a richer system than TUN. In fact, MSA nominal case and verbal mood do not exist in TUN. The three MSA number values (singular, dual and plural) are reduced to singular and plural. On TUN side, the mascu"
W15-3207,P13-2112,0,0.0514903,"Missing"
W15-3207,N13-1044,1,0.924233,"Missing"
W15-3207,elfardy-diab-2012-simplified,0,0.0297093,"morphology, sharing the same inflectional and derivational rules. Table 1 gives some examples of words of different origins. 3 Related work Processing Arabic dialects Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot; become in TUN respectively +« ς+ and +Ó m+ proclitics when the word following is definite (ma"
W15-3207,2013.mtsummit-papers.16,1,0.829942,"s. This method overgenerates and can produce wrong pairs. In order to face this problem, we filtered the MSA part using the MSA large-scale lexicon SAMA (Graff et al., 2009). At the end of the process, a lexicon made of 33, 271 entries is created (Hamdi et al., 2014). ( É¿ AK yÂkl becomes É¿AK yAkl ’he/it eats’). Finally, TUN verbs whose root ends with Z ’, behave the same way as verbs whose final root radical ø y in the perfective aspect. For example, roots of TUN verbs AJK YK. bdiynA &quot;we started&quot; and AJJ ÓP rmiynA &quot;we threw&quot; are respectively Z X H . bd’ and ø Ð P rmy. For more details, see (Hamdi et al., 2013). Due to the lexical differences between MSA and TUN, the conversion process cannot be limited to morphological transformations and requires some lexical transformations. We used three lexica to map from TUN to MSA: a lexicon of verbs, a lexicon of deverbal nouns and a lexicon of particles. 4.2.3 Lexicon of particles Arabic particles cover many categories: conjunctions, prepositions, clitics . . . Our lexicon, made of about 200 pairs (MSA particle, TUN particle), includes all of them. The MSA particles are extracted from the PATB and then translated to TUN (Boujelbane et al., 2013). In its cur"
W15-3207,Q13-1001,0,0.0473055,"Missing"
W15-3207,W14-5311,1,0.785537,"between TUN and MSA • phonological and orthographic variations: TUN has all phonemes that exist in MSA. However, TUN has three extra phonemes /p/, /v/ and /g/. To a lesser extent, variations appear in some common words, that consist in dropping some short vowels1 on  the TUN side. For instance, H . AJ» ktAb2  &quot;book&quot; and I . J» ktb &quot;to write&quot; which exist in both languages but are pronounced differently: /kitAb/, /katab/ in MSA and /ktAb/, /ktib/ in Tunisian dialect. Concerning orthography, unlike MSA, which already has a standard orthography, Tunisian dialect is unstandardized. Zribi et al. (2014) proposes orthographic standards for TUN, following the works of Habash et al. (2012), that aim to establish a common orthographic convention for all Arabic dialects. marker +Ë@ Al+). Furthermore, indirect object pronouns are realized as enclitics in TUN verbs and not in MSA. On the other hand, some MSA clitics are detached in TUN. The MSA future particle proclitic + sa+ is real . bAš with ized as the autonomous particle AK TUN verbs. As for inflectional morphology, MSA has a richer system than TUN. In fact, MSA nominal case and verbal mood do not exist in TUN. The three MSA number values ("
W15-3207,J00-1006,0,0.103881,"ue pairs to sets of abstract morphemes (AMs). In our example, the MBC verb-III maps asp:p and vox:a to the AM [PAT_PV:VIII][VOC_PV:VIIIact]. The feature value cnj:w is simply mapped to the AM [CNJ:W] while the features values per:3 gen:m num:prl asp:p is mapped to the AM [SUBJ_SUFF:3MP]. AMs are then ordered. At this point our example is represented as: (2) [CNJ:W] + [ROOT:Drr] [PAT_PV:VIII] [VOC_PV:VIII-act] + [SUBJ_SUFF:3MP] • Orthographic rules rewrite the orthographic representation. Using standard MSA diacritized orthography, our example becomes  @ ð waAiDTar∼uwA. @ð Q¢ MAGEAD follows (Kiraz, 2000) in using a multi-tape representation. It extends the analysis of Kiraz by introducing a fifth tier. The five tiers are the following : • Tier 1: pattern and affixational morphemes • Tier 2: root • Tier 3: vocalism • Tier 4: phonological representation • Tier 5: orthographic representation In the generation direction, tiers 1 through 3 are input tiers. Tier 4 is an output tier, and an input tier for the orthographic representation. MAGEAD handles Arabic nouns in the same way. Specific CMs, AMs and morpheme order are defined for nouns. The MBC hierarchy specifies relevant morphosyntactic featur"
W15-3207,H01-1035,0,0.191545,"Missing"
W15-3207,D12-1127,0,0.0661705,"Missing"
W15-3207,J14-1006,0,0.0185027,"Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot; become in TUN respectively +« ς+ and +Ó m+ proclitics when the word following is definite (marked by the determinant 1 In Arabic orthography, short vowels are represented with optional diacritics which makes the language ambiguous. 2 Arabic orthographic transliteration is presented in the Hab"
W15-3207,N12-1006,0,0.0182278,"inly due to the influence of other languages. Such TUN words still generally follow MSA morphology, sharing the same inflectional and derivational rules. Table 1 gives some examples of words of different origins. 3 Related work Processing Arabic dialects Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot;"
W15-3207,mohamed-etal-2012-annotating,0,0.0605098,"Missing"
W15-3207,pasha-etal-2014-madamira,1,0.917159,"Missing"
W15-3207,zribi-etal-2014-conventional,1,0.845685,"al variations between TUN and MSA • phonological and orthographic variations: TUN has all phonemes that exist in MSA. However, TUN has three extra phonemes /p/, /v/ and /g/. To a lesser extent, variations appear in some common words, that consist in dropping some short vowels1 on  the TUN side. For instance, H . AJ» ktAb2  &quot;book&quot; and I . J» ktb &quot;to write&quot; which exist in both languages but are pronounced differently: /kitAb/, /katab/ in MSA and /ktAb/, /ktib/ in Tunisian dialect. Concerning orthography, unlike MSA, which already has a standard orthography, Tunisian dialect is unstandardized. Zribi et al. (2014) proposes orthographic standards for TUN, following the works of Habash et al. (2012), that aim to establish a common orthographic convention for all Arabic dialects. marker +Ë@ Al+). Furthermore, indirect object pronouns are realized as enclitics in TUN verbs and not in MSA. On the other hand, some MSA clitics are detached in TUN. The MSA future particle proclitic + sa+ is real . bAš with ized as the autonomous particle AK TUN verbs. As for inflectional morphology, MSA has a richer system than TUN. In fact, MSA nominal case and verbal mood do not exist in TUN. The three MSA number values ("
W15-3207,P08-2030,1,0.912901,"Missing"
W15-3207,P13-2001,0,0.0321949,"Missing"
W15-3207,W11-2602,1,0.899147,"Missing"
W15-3207,2010.amta-papers.5,0,0.0386245,"Missing"
W15-3207,I13-1133,0,\N,Missing
W15-3207,bouamor-etal-2014-multidialectal,1,\N,Missing
W16-3309,J99-2004,1,\N,Missing
W16-3621,bazillon-etal-2012-syntactic,1,0.849545,"d to tweets and that adaptation with in-domain data helps increasing these performances. More recently (Kong et al., 2014) described a dependency parser for tweets. However, to the best of our knowledge, no such study has been published on social media data from formal on line web conversations. We believe that the current models used in the fields of syntactic and semantic parsing are mature enough to go beyond normative data that we find in benchmark corpora and process text that comes from CRM chat. The experience we gathered on parsing speech transcriptions in the framework of the DECODA (Bazillon et al., 2012) and ORFEO (Nasr et al., 2014) projects showed that current parsing techniques can be successfully used to parse disfluent speech transcriptions. Syntactic parsing of non canonical textual input in the context of human-human conversations has been mainly studied in the context of textual transcription of spontaneous speech. In such data, the variation with respect to canonical written text comes mainly from syntactic structures that are specific to spontaneous speech, as well as disfluencies, such as filled pauses, repetitions and false starts. Our input has some of the specificities of sponta"
W16-3621,D13-1035,0,0.0134229,"ra Guerraz2 , Frederic Bechet1 (1) Aix Marseille Universite - CNRS-LIF, Marseille, France (2) Orange Labs - Lannion, France Abstract Recent projects in Europe, such as the CoMeRe (Chanier et al., 2014) or the STAC (Asher, 2011) project gathered collections of CMC data in several languages in order to study this new kind of language. Most of the effort has been dedicated to ”chat room” data as it is the kind of data which is the most accessible on the WEB. (Achille, 2005) constituted a corpus in French. (Forsyth and Martell, 2007) and (Shaikh et al., 2010) describe similar corpora in English. (Cadilhac et al., 2013) have studied the relational structure of such conversations through a deep discursive analysis of chat sessions in an online video game. This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers. This study is realized in the context of the DATCHA project, a collaborative project funded by the French National Research Agency, which aims at performing unsupervised knowledge extraction from very large databases of WEB chat conversations between operators and clients in"
W16-3621,L16-1319,1,0.841476,"here are no repetitions nor false starts. Orthographic errors are numerous and some of them are challenging for a syntactic parser. We present in this paper a detailed analysis of the impact of all these phenomena on syntactic parsing. Other types of social media data have been studied in the literature. In particular tweets have received lately more attention. (Ritter et al., 2011) for example provide a detailed evaluation of a pos tagger on tweets, with the final objec4 A study on orthographic errors in agent/customer chat dialogs Chat conversations are unique from several perspectives. In (Damnati et al., 2016), we conducted a study comparing contact center chat conversations and phone conversations, both in the domain of technical assistance for Orange customers. The comparative analysis showed significant differences in terms of interaction flow. If chat conversations were on average twice as long in terms of effective duration, phone conversations contain on average four times more turns than chat conversations. This can be explained by several factors: chat is not an exclusive activity and latencies are more easily accepted than in an oral conversation. Chat utterances are formulated in a more d"
W16-3621,D14-1108,0,0.0569385,"rd. ok fine within 48h maximum 72h for the card You will receive it according to delivery time at the address in your record. ok fine thank you You’re welcome Before you go, do you any other question? no thank you Figure 1: Example of conversation in the TV assistance domain, in its original forme (above) and a translation without errors (below) 177 tive of performing Named Entity detection. They showed that the performances of a classical tagger trained on generic news data drop when applied to tweets and that adaptation with in-domain data helps increasing these performances. More recently (Kong et al., 2014) described a dependency parser for tweets. However, to the best of our knowledge, no such study has been published on social media data from formal on line web conversations. We believe that the current models used in the fields of syntactic and semantic parsing are mature enough to go beyond normative data that we find in benchmark corpora and process text that comes from CRM chat. The experience we gathered on parsing speech transcriptions in the framework of the DECODA (Bazillon et al., 2012) and ORFEO (Nasr et al., 2014) projects showed that current parsing techniques can be successfully u"
W16-3621,2005.jeptalnrecital-recital.10,0,0.11855,"Missing"
W16-3621,nasr-etal-2014-automatically,1,0.860161,"th in-domain data helps increasing these performances. More recently (Kong et al., 2014) described a dependency parser for tweets. However, to the best of our knowledge, no such study has been published on social media data from formal on line web conversations. We believe that the current models used in the fields of syntactic and semantic parsing are mature enough to go beyond normative data that we find in benchmark corpora and process text that comes from CRM chat. The experience we gathered on parsing speech transcriptions in the framework of the DECODA (Bazillon et al., 2012) and ORFEO (Nasr et al., 2014) projects showed that current parsing techniques can be successfully used to parse disfluent speech transcriptions. Syntactic parsing of non canonical textual input in the context of human-human conversations has been mainly studied in the context of textual transcription of spontaneous speech. In such data, the variation with respect to canonical written text comes mainly from syntactic structures that are specific to spontaneous speech, as well as disfluencies, such as filled pauses, repetitions and false starts. Our input has some of the specificities of spontaneous speech but adds new ones"
W16-3621,W03-3017,0,0.0902461,"ine of the table corresponds to the status of a token. If the token is correct, the status is CORR, otherwise it corresponds to one label of the split REF HYP tok tag tok tag AB TAB A TA B TB Table 5: Conventions defined when computing the accuracy of the tagger for a token. Tags in bold face are compared 181 status CORR DIACR AGGLU SUB1C INFL DEL1C OTHER INS1C APOST SPLIT SWITCH occ. 5916 201 76 46 67 43 40 20 47 6 2 corr. 5547 120 23 13 45 22 23 12 40 3 2 acc. 93.76 59.70 30.26 28.26 67.16 51.16 57.50 60.00 85.11 50.00 100.00 contrib. 59.23 13.00 8.51 5.30 3.53 3.37 2.73 1.28 1.12 0.48 0.00 Nivre, 2003). It is a dependency parser that takes as input tokens with their pos tag and selects for every token a syntactic governor (which is another token of the sentence) and a syntactic label. The prediction is based on several features that combine lexical information and pos tags. Orthographic errors have therefore a double impact on the parsing process: through the errors they provoke on the pos tagging process and the errors they provoke directly on the parsing process. The parser was trained on the French Treebank. Contrary to taggers, a single parser was used for our experiments since we do no"
W16-3621,D11-1141,0,0.0851138,"Missing"
W16-3621,shaikh-etal-2010-mpc,0,0.0320112,"rsation corpus Alexis Nasr1 , Geraldine Damnati2 , Aleksandra Guerraz2 , Frederic Bechet1 (1) Aix Marseille Universite - CNRS-LIF, Marseille, France (2) Orange Labs - Lannion, France Abstract Recent projects in Europe, such as the CoMeRe (Chanier et al., 2014) or the STAC (Asher, 2011) project gathered collections of CMC data in several languages in order to study this new kind of language. Most of the effort has been dedicated to ”chat room” data as it is the kind of data which is the most accessible on the WEB. (Achille, 2005) constituted a corpus in French. (Forsyth and Martell, 2007) and (Shaikh et al., 2010) describe similar corpora in English. (Cadilhac et al., 2013) have studied the relational structure of such conversations through a deep discursive analysis of chat sessions in an online video game. This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers. This study is realized in the context of the DATCHA project, a collaborative project funded by the French National Research Agency, which aims at performing unsupervised knowledge extraction from very large database"
W16-3621,W03-3023,0,0.127109,"Missing"
W17-6311,J16-1002,1,0.539863,"-end process a text directly from an image, without an explicit representation (syntactic or semantic) of the text generated. For syntactic parsing, the problem of PPattachment has a long history in Natural Language Processing and a wealth of different methods and sources of information have been used to alleviate it. Giving a overview of this vast body of literature is well beyond the scope of this paper. Traditionally, two types of resources have been used to help resolving PP-attachment, semantic knowledge bases (Agirre et al., 2008; Dasigi et al., 2017), and corpora (Rakshit et al., 2016; Mirroshandel and Nasr, 2016; Belinkov et al., 2014; de Kok et al., 2017). We are not aware of much work using multimodal information for PP-attachment. In the most relevant work that we have found (Christie et al., 2016), a parser is used to predict the k best parses for a sentence and this set is re-ranked using visual information. The main difference with their work is, in our case, the combined use of lexical, semantic and visual cues as well as the method used (k best parses v/s parse correction). 73 a development set, made of 2271 captions (2907 annotated prepositions) and a test set, made of 2288 captions (2907 pr"
W17-6311,P11-4015,1,0.883412,"Missing"
W17-6311,P08-1037,0,0.100252,"representation for both image and language features and generate in an end-to-end process a text directly from an image, without an explicit representation (syntactic or semantic) of the text generated. For syntactic parsing, the problem of PPattachment has a long history in Natural Language Processing and a wealth of different methods and sources of information have been used to alleviate it. Giving a overview of this vast body of literature is well beyond the scope of this paper. Traditionally, two types of resources have been used to help resolving PP-attachment, semantic knowledge bases (Agirre et al., 2008; Dasigi et al., 2017), and corpora (Rakshit et al., 2016; Mirroshandel and Nasr, 2016; Belinkov et al., 2014; de Kok et al., 2017). We are not aware of much work using multimodal information for PP-attachment. In the most relevant work that we have found (Christie et al., 2016), a parser is used to predict the k best parses for a sentence and this set is re-ranked using visual information. The main difference with their work is, in our case, the combined use of lexical, semantic and visual cues as well as the method used (k best parses v/s parse correction). 73 a development set, made of 2271"
W17-6311,W03-3017,0,0.11765,"or a sentence and this set is re-ranked using visual information. The main difference with their work is, in our case, the combined use of lexical, semantic and visual cues as well as the method used (k best parses v/s parse correction). 73 a development set, made of 2271 captions (2907 annotated prepositions) and a test set, made of 2288 captions (2907 prepositions). 4 Error Prediction The train part of the PP-corpus has been used to train a classifier that predicts whether a PPattachment proposed by a parser is correct or not. The parser used is a standard arc-eager transition based parser (Nivre, 2003), trained on sections 0 − 18 of the Penn Treebank (Marcus et al., 1993). The parser was run on the train set of the corpus and, for each occurrence of a manually attached preposition, a negative or a positive example has been produced depending on whether the parser has predicted the correct attachment or not. This data set is composed of 17643 positive and 5611 negative examples. It has been used to train a classifier that predicts whether the attachment made by the parser is correct or not. The classifier used for this task is the Icsiboost classifier (Favre et al., 2007). This Adaboost clas"
W17-6311,D11-1113,0,0.0220038,"f these prepositions, column two displays its number of occurrences, column three (BL) shows the attachment accuracy for this preposition in the output the parser. Columns four (T), five (C), six (V) and seven (TCV) show the attachment accuracy for the corrected output for four different configurations The classifier developed in the previous section only checked if a PP-attachment proposed by the parser is correct or not. In this section we integrate this classifier in a correction strategy in order to improve the accuracy of our parser. This correction strategy is inspired from the ideas of Anguiano and Candito (2011); Attardi and Ciaramita (2007); Hall and Nov´ak (2005): given a sentence S, a parse T for S and a target preposition p, a set 75 Prep into with through behind under down in in front of outside on around for at along across against near towards next to by of over during from TOTAL Occ 116 310 145 35 58 41 369 51 35 143 59 168 63 50 49 31 159 30 137 76 72 111 41 140 2907 BL 0.89 0.65 0.95 0.74 0.84 0.63 0.76 0.90 0.63 0.85 0.73 0.73 0.84 0.52 0.88 0.77 0.33 0.90 0.89 0.84 0.93 0.66 0.71 0.76 0.75 T 0.93 0.78 0.96 0.86 0.84 0.73 0.84 0.88 0.74 0.90 0.81 0.82 0.86 0.86 0.96 0.94 0.84 0.93 0.89 0.8"
W17-6311,N07-1049,0,0.0243527,"two displays its number of occurrences, column three (BL) shows the attachment accuracy for this preposition in the output the parser. Columns four (T), five (C), six (V) and seven (TCV) show the attachment accuracy for the corrected output for four different configurations The classifier developed in the previous section only checked if a PP-attachment proposed by the parser is correct or not. In this section we integrate this classifier in a correction strategy in order to improve the accuracy of our parser. This correction strategy is inspired from the ideas of Anguiano and Candito (2011); Attardi and Ciaramita (2007); Hall and Nov´ak (2005): given a sentence S, a parse T for S and a target preposition p, a set 75 Prep into with through behind under down in in front of outside on around for at along across against near towards next to by of over during from TOTAL Occ 116 310 145 35 58 41 369 51 35 143 59 168 63 50 49 31 159 30 137 76 72 111 41 140 2907 BL 0.89 0.65 0.95 0.74 0.84 0.63 0.76 0.90 0.63 0.85 0.73 0.73 0.84 0.52 0.88 0.77 0.33 0.90 0.89 0.84 0.93 0.66 0.71 0.76 0.75 T 0.93 0.78 0.96 0.86 0.84 0.73 0.84 0.88 0.74 0.90 0.81 0.82 0.86 0.86 0.96 0.94 0.84 0.93 0.89 0.86 0.93 0.85 0.76 0.86 0.85 C 0"
W17-6311,Q14-1043,0,0.021789,"from an image, without an explicit representation (syntactic or semantic) of the text generated. For syntactic parsing, the problem of PPattachment has a long history in Natural Language Processing and a wealth of different methods and sources of information have been used to alleviate it. Giving a overview of this vast body of literature is well beyond the scope of this paper. Traditionally, two types of resources have been used to help resolving PP-attachment, semantic knowledge bases (Agirre et al., 2008; Dasigi et al., 2017), and corpora (Rakshit et al., 2016; Mirroshandel and Nasr, 2016; Belinkov et al., 2014; de Kok et al., 2017). We are not aware of much work using multimodal information for PP-attachment. In the most relevant work that we have found (Christie et al., 2016), a parser is used to predict the k best parses for a sentence and this set is re-ranked using visual information. The main difference with their work is, in our case, the combined use of lexical, semantic and visual cues as well as the method used (k best parses v/s parse correction). 73 a development set, made of 2271 captions (2907 annotated prepositions) and a test set, made of 2288 captions (2907 prepositions). 4 Error Pr"
W17-6311,D16-1156,0,0.234932,"Natural Language Processing and a wealth of different methods and sources of information have been used to alleviate it. Giving a overview of this vast body of literature is well beyond the scope of this paper. Traditionally, two types of resources have been used to help resolving PP-attachment, semantic knowledge bases (Agirre et al., 2008; Dasigi et al., 2017), and corpora (Rakshit et al., 2016; Mirroshandel and Nasr, 2016; Belinkov et al., 2014; de Kok et al., 2017). We are not aware of much work using multimodal information for PP-attachment. In the most relevant work that we have found (Christie et al., 2016), a parser is used to predict the k best parses for a sentence and this set is re-ranked using visual information. The main difference with their work is, in our case, the combined use of lexical, semantic and visual cues as well as the method used (k best parses v/s parse correction). 73 a development set, made of 2271 captions (2907 annotated prepositions) and a test set, made of 2288 captions (2907 prepositions). 4 Error Prediction The train part of the PP-corpus has been used to train a classifier that predicts whether a PPattachment proposed by a parser is correct or not. The parser used"
W17-6311,Q14-1006,0,0.0483338,"ki, 1994) computes first spatial relations among objects detected in images with knowledge-based language generation model in order to generate short descriptions of videos in limited domains (traffic scenes, soccer matches). Recently open-domain language generation from 72 Proceedings of the 15th International Conference on Parsing Technologies, pages 72–77, c Pisa, Italy; September 20–22, 2017. 2017 Association for Computational Linguistics 3 Data The multimodal corpus used in this work is the Flickr30k Entities (F30kE) (Plummer et al., 2017), an extension of the original Flickr30k dataset (Young et al., 2014). This corpus is composed of almost 32K images and, for each image, five captions describing the image have been produced. Besides, every object in the image that corresponds to a mention in the captions has been manually identified with a bounding box. Bounding boxes and the mentions in the captions have been paired together via co-reference links. A total of 244K such links have been annotated. Furthermore, each mention in the captions has been categorized into eight coarse-grained conceptual types using manually constructed dictionaries. The types are: people, body parts, animals, clothing,"
W17-6311,P17-1191,0,0.150617,"oth image and language features and generate in an end-to-end process a text directly from an image, without an explicit representation (syntactic or semantic) of the text generated. For syntactic parsing, the problem of PPattachment has a long history in Natural Language Processing and a wealth of different methods and sources of information have been used to alleviate it. Giving a overview of this vast body of literature is well beyond the scope of this paper. Traditionally, two types of resources have been used to help resolving PP-attachment, semantic knowledge bases (Agirre et al., 2008; Dasigi et al., 2017), and corpora (Rakshit et al., 2016; Mirroshandel and Nasr, 2016; Belinkov et al., 2014; de Kok et al., 2017). We are not aware of much work using multimodal information for PP-attachment. In the most relevant work that we have found (Christie et al., 2016), a parser is used to predict the k best parses for a sentence and this set is re-ranked using visual information. The main difference with their work is, in our case, the combined use of lexical, semantic and visual cues as well as the method used (k best parses v/s parse correction). 73 a development set, made of 2271 captions (2907 annota"
W17-6311,E17-2050,0,0.162099,"Missing"
W17-6311,W05-1505,0,0.122245,"Missing"
W17-6311,J93-2004,0,\N,Missing
