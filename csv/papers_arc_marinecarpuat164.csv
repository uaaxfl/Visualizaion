2021.hcinlp-1.14,Machine Translation Believability,2021,-1,-1,3,1,6057,marianna martindale,Proceedings of the First Workshop on Bridging Human{--}Computer Interaction and Natural Language Processing,0,"Successful Machine Translation (MT) deployment requires understanding not only the intrinsic qualities of MT output, such as fluency and adequacy, but also user perceptions. Users who do not understand the source language respond to MT output based on their perception of the likelihood that the meaning of the MT output matches the meaning of the source text. We refer to this as believability. Output that is not believable may be off-putting to users, but believable MT output with incorrect meaning may mislead them. In this work, we study the relationship of believability to fluency and adequacy by applying traditional MT direct assessment protocols to annotate all three features on the output of neural MT systems. Quantitative analysis of these annotations shows that believability is closely related to but distinct from fluency, and initial qualitative analysis suggests that semantic features may account for the difference."
2021.gem-1.6,A Review of Human Evaluation for Style Transfer,2021,-1,-1,5,1,4011,eleftheria briakou,"Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",0,"This paper reviews and summarizes human evaluation practices described in 97 style transfer papers with respect to three main evaluation aspects: style transfer, meaning preservation, and fluency. In principle, evaluations by human raters should be the most reliable. However, in style transfer papers, we find that protocols for human evaluations are often underspecified and not standardized, which hampers the reproducibility of research in this field and progress toward better human and automatic evaluation methods."
2021.findings-acl.330,A Non-Autoregressive Edit-Based Approach to Controllable Text Simplification,2021,-1,-1,3,1,3517,sweta agrawal,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.385,How Does Distilled Data Complexity Impact the Quality and Confidence of Non-Autoregressive Machine Translation?,2021,-1,-1,4,1,5273,weijia xu,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.eval4nlp-1.22,The {UMD} Submission to the Explainable {MT} Quality Estimation Shared Task: Combining Explanation Models with Sequence Labeling,2021,-1,-1,2,0,8619,tasnim kabir,Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems,0,None
2021.emnlp-main.100,Evaluating the Evaluation Metrics for Style Transfer: A Case Study in Multilingual Formality Transfer,2021,-1,-1,4,1,4011,eleftheria briakou,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"While the field of style transfer (ST) has been growing rapidly, it has been hampered by a lack of standardized practices for automatic evaluation. In this paper, we evaluate leading automatic metrics on the oft-researched task of formality style transfer. Unlike previous evaluations, which focus solely on English, we expand our focus to Brazilian-Portuguese, French, and Italian, making this work the first multilingual evaluation of metrics in ST. We outline best practices for automatic evaluation in (formality) style transfer and identify several models that correlate well with human judgments and are robust across languages. We hope that this work will help accelerate development in ST, where human evaluation is often challenging to collect."
2021.emnlp-main.477,Rule-based Morphological Inflection Improves Neural Terminology Translation,2021,-1,-1,2,1,5273,weijia xu,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Current approaches to incorporating terminology constraints in machine translation (MT) typically assume that the constraint terms are provided in their correct morphological forms. This limits their application to real-world scenarios where constraint terms are provided as lemmas. In this paper, we introduce a modular framework for incorporating lemma constraints in neural MT (NMT) in which linguistic knowledge and diverse types of NMT models can be flexibly applied. It is based on a novel cross-lingual inflection module that inflects the target lemma constraints based on the source context. We explore linguistically motivated rule-based and data-driven neural-based inflection modules and design English-German health and English-Lithuanian news test suites to evaluate them in domain adaptation and low-resource MT settings. Results show that our rule-based inflection module helps NMT models incorporate lemma constraints more accurately than a neural module and outperforms the existing end-to-end approach with lower training costs."
2021.acl-long.562,Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation,2021,-1,-1,2,1,4011,eleftheria briakou,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"While it has been shown that Neural Machine Translation (NMT) is highly sensitive to noisy parallel training samples, prior work treats all types of mismatches between source and target as noise. As a result, it remains unclear how samples that are mostly equivalent but contain a small number of semantically divergent tokens impact NMT training. To close this gap, we analyze the impact of different types of fine-grained semantic divergences on Transformer models. We show that models trained on synthetic divergences output degenerated text more frequently and are less confident in their predictions. Based on these findings, we introduce a divergent-aware NMT framework that uses factors to help NMT recover from the degradation caused by naturally occurring divergences, improving both translation quality and model calibration on EN-FR tasks."
2020.wmt-1.56,The {U}niversity of {M}aryland{'}s Submissions to the {WMT}20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation,2020,-1,-1,5,0,13882,calvin bao,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes the University of Maryland{'}s submissions to the WMT20 Shared Task on Chat Translation. We focus on translating agent-side utterances from English to German. We started from an off-the-shelf BPE-based standard transformer model trained with WMT17 news and fine-tuned it with the provided in-domain training data. In addition, we augment the training set with its best matches in the WMT19 news dataset. Our primary submission uses a standard Transformer, while our contrastive submissions use multi-encoder Transformers to attend to previous utterances. Our primary submission achieves 56.7 BLEU on the agent side (enâde), outperforming a baseline system provided by the task organizers by more than 13 BLEU points. Moreover, according to an evaluation on a set of carefully-designed examples, the multi-encoder architecture is able to generate more coherent translations."
2020.wmt-1.141,Incorporating Terminology Constraints in Automatic Post-Editing,2020,-1,-1,4,0,10874,david wan,Proceedings of the Fifth Conference on Machine Translation,0,"Users of machine translation (MT) may want to ensure the use of specific lexical terminologies. While there exist techniques for incorporating terminology constraints during inference for MT, current APE approaches cannot ensure that they will appear in the final translation. In this paper, we present both autoregressive and non-autoregressive models for lexically constrained APE, demonstrating that our approach enables preservation of 95{\%} of the terminologies and also improves translation quality on English-German benchmarks. Even when applied to lexically constrained MT output, our approach is able to improve preservation of the terminologies. However, we show that our models do not learn to copy constraints systematically and suggest a simple data augmentation technique that leads to improved performance and robustness."
2020.winlp-1.36,Multitask Models for Controlling the Complexity of Neural Machine Translation,2020,-1,-1,2,1,3517,sweta agrawal,Proceedings of the The Fourth Widening Natural Language Processing Workshop,0,We introduce a machine translation task where the output is aimed at audiences of different levels of target language proficiency. We collect a novel dataset of news articles available in English and Spanish and written for diverse reading grade levels. We leverage this dataset to train multitask sequence to sequence models that translate Spanish into English targeted at an easier reading grade level than the original Spanish. We show that multitask models outperform pipeline approaches that translate and simplify text independently.
2020.winlp-1.40,An Evaluation of Subword Segmentation Strategies for Neural Machine Translation of Morphologically Rich Languages,2020,-1,-1,4,0,14031,aquia richburg,Proceedings of the The Fourth Widening Natural Language Processing Workshop,0,"Byte-Pair Encoding (BPE) (Sennrich et al., 2016) has become a standard pre-processing step when building neural machine translation systems. However, it is not clear whether this is an optimal strategy in all settings. We conduct a controlled comparison of subword segmentation strategies for translating two low-resource morphologically rich languages (Swahili and Turkish) into English. We show that segmentations based on a unigram language model (Kudo, 2018) yield comparable BLEU and better recall for translating rare source words than BPE."
2020.ngt-1.21,Generating Diverse Translations via Weighted Fine-tuning and Hypotheses Filtering for the {D}uolingo {STAPLE} Task,2020,-1,-1,2,1,3517,sweta agrawal,Proceedings of the Fourth Workshop on Neural Generation and Translation,0,"This paper describes the University of Maryland{'}s submission to the Duolingo Shared Task on Simultaneous Translation And Paraphrase for Language Education (STAPLE). Unlike the standard machine translation task, STAPLE requires generating a set of outputs for a given input sequence, aiming to cover the space of translations produced by language learners. We adapt neural machine translation models to this requirement by (a) generating n-best translation hypotheses from a model fine-tuned on learner translations, oversampled to reflect the distribution of learner responses, and (b) filtering hypotheses using a feature-rich binary classifier that directly optimizes a close approximation of the official evaluation metric. Combination of systems that use these two strategies achieves F1 scores of 53.9{\%} and 52.5{\%} on Vietnamese and Portuguese, respectively ranking 2nd and 4th on the leaderboard."
2020.findings-emnlp.182,Dual Reconstruction: a Unifying Objective for Semi-Supervised Neural Machine Translation,2020,-1,-1,3,1,5273,weijia xu,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"While Iterative Back-Translation and Dual Learning effectively incorporate monolingual training data in neural machine translation, they use different objectives and heuristic gradient approximation strategies, and have not been extensively compared. We introduce a novel dual reconstruction objective that provides a unified view of Iterative Back-Translation and Dual Learning. It motivates a theoretical analysis and controlled empirical study on German-English and Turkish-English tasks, which both suggest that Iterative Back-Translation is more effective than Dual Learning despite its relative simplicity."
2020.figlang-1.26,Evaluating a {B}i-{LSTM} Model for Metaphor Detection in {TOEFL} Essays,2020,-1,-1,2,0,20021,kevin kuo,Proceedings of the Second Workshop on Figurative Language Processing,0,"This paper describes systems submitted to the Metaphor Shared Task at the Second Workshop on Figurative Language Processing. In this submission, we replicate the evaluation of the Bi-LSTM model introduced by Gao et al.(2018) on the VUA corpus in a new setting: TOEFL essays written by non-native English speakers. Our results show that Bi-LSTM models outperform feature-rich linear models on this challenging task, which is consistent with prior findings on the VUA dataset. However, the Bi-LSTM models lag behind the best performing systems in the shared task."
2020.emnlp-main.121,{D}etecting {F}ine-{G}rained {C}ross-{L}ingual {S}emantic {D}ivergences without {S}upervision by {L}earning to {R}ank,2020,-1,-1,2,1,4011,eleftheria briakou,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Detecting fine-grained differences in content conveyed in different languages matters for cross-lingual NLP and multilingual corpora analysis, but it is a challenging machine learning problem since annotation is expensive and hard to scale. This work improves the prediction and annotation of fine-grained semantic divergences. We introduce a training strategy for multilingual BERT models by learning to rank synthetic divergent examples of varying granularity. We evaluate our models on the Rationalized English-French Semantic Divergences, a new dataset released with this work, consisting of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales. Learning to rank helps detect fine-grained sentence-level divergences more accurately than a strong sentence-level similarity model, while token-level predictions have the potential of further distinguishing between coarse and fine-grained divergences."
W19-6623,Identifying Fluently Inadequate Output in Neural and Statistical Machine Translation,2019,0,0,2,1,6057,marianna martindale,Proceedings of Machine Translation Summit XVII: Research Track,0,None
W19-5308,The {U}niversity of {M}aryland{'}s {K}azakh-{E}nglish Neural Machine Translation System at {WMT}19,2019,0,0,2,1,4011,eleftheria briakou,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper describes the University of Maryland{'}s submission to the WMT 2019 Kazakh-English news translation task. We study the impact of transfer learning from another low-resource but related language. We experiment with different ways of encoding lexical units to maximize lexical overlap between the two language pairs, as well as back-translation and ensembling. The submitted system improves over a Kazakh-only baseline by +5.45 BLEU on newstest2019."
N19-1043,Bi-Directional Differentiable Input Reconstruction for Low-Resource Neural Machine Translation,2019,0,4,3,1,19625,xing niu,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We aim to better exploit the limited amounts of parallel text available in low-resource settings by introducing a differentiable reconstruction loss for neural machine translation (NMT). This loss compares original inputs to reconstructed inputs, obtained by back-translating translation hypotheses into the input language. We leverage differentiable sampling and bi-directional NMT to train models end-to-end, without introducing additional parameters. This approach achieves small but consistent BLEU improvements on four language pairs in both translation directions, and outperforms an alternative differentiable reconstruction strategy based on hidden states."
N19-1189,Curriculum Learning for Domain Adaptation in Neural Machine Translation,2019,0,6,5,0,5135,xuan zhang,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We introduce a curriculum learning approach to adapt generic neural machine translation models to a specific domain. Samples are grouped by their similarities to the domain of interest and each group is fed to the training algorithm with a particular schedule. This approach is simple to implement on top of any neural framework or architecture, and consistently outperforms both unadapted and adapted baselines in experiments with two distinct domains and two language pairs."
N19-1207,Differentiable Sampling with Flexible Reference Word Order for Neural Machine Translation,2019,0,1,3,1,5273,weijia xu,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Despite some empirical success at correcting exposure bias in machine translation, scheduled sampling algorithms suffer from a major drawback: they incorrectly assume that words in the reference translations and in sampled sequences are aligned at each time step. Our new differentiable sampling algorithm addresses this issue by optimizing the probability that the reference can be aligned with the sampled output, based on a soft alignment predicted by the model itself. As a result, the output distribution at each time step is evaluated with respect to the whole predicted sequence. Experiments on IWSLT translation tasks show that our approach improves BLEU compared to maximum likelihood and scheduled sampling baselines. In addition, our approach is simpler to train with no need for sampling schedule and yields models that achieve larger improvements with smaller beam sizes."
D19-1166,Controlling Text Complexity in Neural Machine Translation,2019,0,1,2,1,3517,sweta agrawal,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"This work introduces a machine translation task where the output is aimed at audiences of different levels of target language proficiency. We collect a high quality dataset of news articles available in English and Spanish, written for diverse grade levels and propose a method to align segments across comparable bilingual articles. The resulting dataset makes it possible to train multi-task sequence to sequence models that can translate and simplify text jointly. We show that these multi-task models outperform pipeline approaches that translate and simplify text independently."
D19-1532,Weakly Supervised Cross-lingual Semantic Relation Classification via Knowledge Distillation,2019,0,1,2,1,3434,yogarshi vyas,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Words in different languages rarely cover the exact same semantic space. This work characterizes differences in meaning between words across languages using semantic relations that have been used to relate the meaning of English words. However, because of translation ambiguity, semantic relations are not always preserved by translation. We introduce a cross-lingual relation classifier trained only with English examples and a bilingual dictionary. Our classifier relies on a novel attention-based distillation approach to account for translation ambiguity when transferring knowledge from English to cross-lingual settings. On new English-Chinese and English-Hindi test sets, the resulting models largely outperform baselines that more naively rely on bilingual embeddings or dictionaries for cross-lingual transfer, and approach the performance of fully supervised systems on English tasks."
W18-6431,The {U}niversity of {M}aryland{'}s {C}hinese-{E}nglish Neural Machine Translation Systems at {WMT}18,2018,0,1,2,1,5273,weijia xu,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper describes the University of Maryland{'}s submission to the WMT 2018 ChineseâEnglish news translation tasks. Our systems are BPE-based self-attentional Transformer networks with parallel and backtranslated monolingual training data. Using ensembling and reranking, we improve over the Transformer baseline by +1.4 BLEU for ChineseâEnglish and +3.97 BLEU for EnglishâChinese on \textit{newstest2017}. Our best systems reach BLEU scores of 24.4 for ChineseâEnglish and 39.0 for EnglishâChinese on \textit{newstest2018}."
W18-2710,Bi-Directional Neural Machine Translation with Synthetic Parallel Data,2018,0,8,3,1,19625,xing niu,Proceedings of the 2nd Workshop on Neural Machine Translation and Generation,0,"Despite impressive progress in high-resource settings, Neural Machine Translation (NMT) still struggles in low-resource and out-of-domain scenarios, often failing to match the quality of phrase-based translation. We propose a novel technique that combines back-translation and multilingual NMT to improve performance in these difficult cases. Our technique trains a single model for both directions of a language pair, allowing us to back-translate source or target monolingual data without requiring an auxiliary model. We then continue training on the augmented parallel data, enabling a cycle of improvement for a single model that can incorporate any source, target, or parallel data to improve both translation directions. As a byproduct, these models can reduce training and deployment costs significantly compared to uni-directional models. Extensive experiments show that our technique outperforms standard back-translation in low-resource scenarios, improves quality on cross-domain tasks, and effectively reduces costs across the board."
W18-1803,Fluency Over Adequacy: A Pilot Study in Measuring User Trust in Imperfect {MT},2018,20,1,2,1,6057,marianna martindale,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,"Although measuring intrinsic quality has been a key factor in the advancement of Machine Translation (MT), successfully deploying MT requires considering not just intrinsic quality but also the user experience, including aspects such as trust. This work introduces a method of studying how users modulate their trust in an MT system after seeing errorful (disfluent or inadequate) output amidst good (fluent and adequate) output. We conduct a survey to determine how users respond to good translations compared to translations that are either adequate but not fluent, or fluent but not adequate. In this pilot study, users responded strongly to disfluent translations, but were, surprisingly, much less concerned with adequacy."
S18-1170,{UMD} at {S}em{E}val-2018 Task 10: Can Word Embeddings Capture Discriminative Attributes?,2018,0,0,2,0,28909,alexander zhang,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"We describe the University of Maryland{'}s submission to SemEval-018 Task 10, {``}Capturing Discriminative Attributes{''}: given word triples (w1, w2, d), the goal is to determine whether d is a discriminating attribute belonging to w1 but not w2. Our study aims to determine whether word embeddings can address this challenging task. Our submission casts this problem as supervised binary classification using only word embedding features. Using a gaussian SVM model trained only on validation data results in an F-score of 60{\%}. We also show that cosine similarity features are more effective, both in unsupervised systems (F-score of 65{\%}) and supervised systems (F-score of 67{\%})."
N18-1056,Robust Cross-Lingual Hypernymy Detection Using Dependency Context,2018,35,0,3,0,8203,shyam upadhyay,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Cross-lingual Hypernymy Detection involves determining if a word in one language ({``}fruit{''}) is a hypernym of a word in another language ({``}pomme{''} i.e. apple in French). The ability to detect hypernymy cross-lingually can aid in solving cross-lingual versions of tasks such as textual entailment and event coreference. We propose BiSparse-Dep, a family of unsupervised approaches for cross-lingual hypernymy detection, which learns sparse, bilingual word embeddings based on dependency contexts. We show that BiSparse-Dep can significantly improve performance on this task, compared to approaches based only on lexical context. Our approach is also robust, showing promise for low-resource settings: our dependency-based embeddings can be learned using a parser trained on related languages, with negligible loss in performance. We also crowd-source a challenging dataset for this task on four languages {--} Russian, French, Arabic, and Chinese. Our embeddings and datasets are publicly available."
N18-1136,Identifying Semantic Divergences in Parallel Text without Annotations,2018,40,2,3,1,3434,yogarshi vyas,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Recognizing that even correct translations are not always semantically equivalent, we automatically detect meaning divergences in parallel sentence pairs with a deep neural model of bilingual semantic similarity which can be trained for any parallel corpus without any manual annotation. We show that our semantic model detects divergences more accurately than models based on surface features derived from word alignments, and that these divergences matter for neural machine translation."
C18-1086,Multi-Task Neural Models for Translating Between Styles Within and Across Languages,2018,36,2,3,1,19625,xing niu,Proceedings of the 27th International Conference on Computational Linguistics,0,"Generating natural language requires conveying content in an appropriate style. We explore two related tasks on generating text of varying formality: monolingual formality transfer and formality-sensitive machine translation. We propose to solve these tasks jointly using multi-task learning, and show that our models achieve state-of-the-art performance for formality transfer and are able to perform formality-sensitive translation without being explicitly trained on style-annotated translation examples."
W17-4903,Discovering Stylistic Variations in Distributional Vector Space Models via Lexical Paraphrases,2017,15,4,2,1,19625,xing niu,Proceedings of the Workshop on Stylistic Variation,0,"Detecting and analyzing stylistic variation in language is relevant to diverse Natural Language Processing applications. In this work, we investigate whether salient dimensions of style variations are embedded in standard distributional vector spaces of word meaning. We hypothesizes that distances between embeddings of lexical paraphrases can help isolate style from meaning variations and help identify latent style dimensions. We conduct a qualitative analysis of latent style dimensions, and show the effectiveness of identified style subspaces on a lexical formality prediction task."
W17-3209,Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation,2017,30,7,1,1,6058,marine carpuat,Proceedings of the First Workshop on Neural Machine Translation,0,"Parallel corpora are often not as parallel as one might assume: non-literal translations and noisy translations abound, even in curated corpora routinely used for training and evaluation. We use a cross-lingual textual entailment system to distinguish sentence pairs that are parallel in meaning from those that are not, and show that filtering out divergent examples from training improves translation quality."
S17-1004,Detecting Asymmetric Semantic Relations in Context: A Case-Study on Hypernymy Detection,2017,22,2,2,1,3434,yogarshi vyas,Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*{SEM} 2017),0,"We introduce WHiC, a challenging testbed for detecting hypernymy, an asymmetric relation between words. While previous work has focused on detecting hypernymy between word types, we ground the meaning of words in specific contexts drawn from WordNet examples, and require predictions to be sensitive to changes in contexts. WHiC lets us analyze complementary properties of two approaches of inducing vector representations of word meaning in context. We show that such contextualized word representations also improve detection of a wider range of semantic relations in context."
D17-1299,A Study of Style in Machine Translation: Controlling the Formality of Machine Translation Output,2017,22,11,3,1,19625,xing niu,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Stylistic variations of language, such as formality, carry speakers{'} intention beyond literal meaning and should be conveyed adequately in translation. We propose to use lexical formality models to control the formality level of machine translation output. We demonstrate the effectiveness of our approach in empirical evaluations, as measured by automatic metrics and human assessments."
S16-1084,{S}em{E}val-2016 Task 10: Detecting Minimal Semantic Units and their Meanings ({D}i{MSUM}),2016,38,15,4,0,794,nathan schneider,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
P16-2059,Learning Monolingual Compositional Representations via Bilingual Supervision,2016,27,1,2,0,4554,ahmed elgohary,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Bilingual models that capture the semantics of sentences are typically only evaluated on cross-lingual transfer tasks such as cross-lingual document categorization or machine translation. In this work, we evaluate the quality of the monolingual representations learned with a variant of the bilingual compositional model of Hermann and Blunsom (2014), when viewing translations in a second language as a semantic annotation as the original language text. We show that compositional objectives based on phrase translation pairs outperform compositional objectives based on bilingual sentences and on monolingual paraphrases."
N16-1142,Sparse Bilingual Word Representations for Cross-lingual Lexical Entailment,2016,50,10,2,1,3434,yogarshi vyas,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We introduce the task of cross-lingual lexical entailment, which aims to detect whether the meaning of a word in one language can be inferred from the meaning of a word in another language. We construct a gold standard for this task, and propose an unsupervised solution based on distributional word representations. As commonly done in the monolingual setting, we assume a worde entails a wordf if the prominent context features of e are a subset of those of f . To address the challenge of comparing contexts across languages, we propose a novel method for inducing sparse bilingual word representations from monolingual and parallel texts. Our approach yields an Fscore of 70%, and significantly outperforms strong baselines based on translation and on existing word representations."
N16-1163,Retrofitting Sense-Specific Word Vectors Using Parallel Text,2016,16,4,3,0,8001,allyson ettinger,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W15-2903,Connotation in Translation,2015,20,4,1,1,6058,marine carpuat,"Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"We present a pilot study analyzing the connotative language found in a bilingual corpus of French and English headlines. We find that (1) manual annotation of connotation at the word-level is more reliable than using segment-level judgments, (2) connotation polarity is often, but not always, preserved in reference translations produced by humans, (3) machine translated text does not preserve the connotative language identified by an English connotation lexicon. These lessons will helps us build new resources to learn better models of connotation and translation."
2015.iwslt-papers.9,Class-based N-gram language difference models for data selection,2015,-1,-1,4,0,18812,amittai axelrod,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
2015.iwslt-evaluation.8,The {UMD} machine translation systems at {IWSLT} 2015,2015,-1,-1,2,0,18812,amittai axelrod,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
W14-5316,The {NRC} System for Discriminating Similar Languages,2014,13,20,3,0.64122,653,cyril goutte,"Proceedings of the First Workshop on Applying {NLP} Tools to Similar Languages, Varieties and Dialects",0,"We describe the system built by the National Research Council Canada for the xe2x80x9dDiscriminating between similar languagesxe2x80x9d (DSL) shared task. Our system uses various statistical classifiers and makes predictions based on a two-stage process: we first predict the language group, then discriminate between languages or variants within the group. Language groups are predicted using a generative classifier with 99.99% accuracy on the five target groups. Within each group (except English), we use a voting combination of discriminative classifiers trained on a variety of feature spaces, achieving an average accuracy of 95.71%, with per-group accuracy between 90.95% and 100% depending on the group. This approach turns out to reach the best performance among all systems submitted to the open and closed tasks."
W14-3913,Mixed Language and Code-Switching in the {C}anadian {H}ansard,2014,16,9,1,1,6058,marine carpuat,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"While there has been lots of interest in code-switching in informal text such as tweets and online content, we ask whether code-switching occurs in the proceedings of multilingual institutions. We focus on the Canadian Hansard, and automatically detect mixed language segments based on simple corpus-based rules and an existing word-level language tagger. Manual evaluation shows that the performance of automatic detection varies significantly depending on the primary language. While 95% precision can be achieved when the original language is French, common words generate many false positives which hurt precision in English. Furthermore, we found that codeswitching does occur within the mixed languages examples detected in the Canadian Hansard, and it might be used differently by French and English speakers. This analysis suggests that parallel corpora such as the Hansard can provide interesting test beds for studying multilingual practices, including code-switching and its translation, and encourages us to collect more gold annotations to improve the characterization and detection of mixed language and code-switching in parallel corpora."
W14-3363,Linear Mixture Models for Robust Machine Translation,2014,18,6,1,1,6058,marine carpuat,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"As larger and more diverse parallel texts become available, how can we leverage heterogeneous data to train robust machine translation systems that achieve good translation quality on various test domains? This challenge has been addressed so far by repurposing techniques developed for domain adaptation, such as linear mixture models which combine estimates learned on homogeneous subdomains. However, learning from large heterogeneous corpora is quite different from standard adaptation tasks with clear domain distinctions. In this paper, we show that linear mixture models can reliably improve translation quality in very heterogeneous training conditions, even if the mixtures do not use any domain knowledge and attempt to learn generic models rather than adapt them to the target domain. This surprising finding opens new perspectives for using mixture models in machine translation beyond clear cut domain adaptation tasks."
S14-2030,{CNRC}-{TMT}: Second Language Writing Assistant System Description,2014,14,1,3,0.64122,653,cyril goutte,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"We describe the system entered by the National Research Council Canada in the SemEval-2014 L2 writing assistant task. Our system relies on a standard Phrase-Based Statistical Machine Translation trained on generic, publicly available data. Translations are produced by taking the already translated part of the sentence as fixed context. We show that translation systems can address the L2 writing assistant task, reaching out-of-five word-based accuracy above 80 percent for 3 out of 4 language pairs. We also present a brief analysis of remaining errors."
P14-2047,Assessing the Discourse Factors that Influence the Quality of Machine Translation,2014,21,11,2,0,1538,junyi li,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We present a study of aspects of discourse structure xe2x80x94 specifically discourse devices used to organize information in a sentence xe2x80x94 that significantly impact the quality of machine translation. Our analysis is based on manual evaluations of translations of news from Chinese and Arabic to English. We find that there is a particularly strong mismatch in the notion of what constitutes a sentence in Chinese and English, which occurs often and is associated with significant degradation in translation quality. Also related to lower translation quality is the need to employ multiple explicit discourse connectives (because, but, etc.), as well as the presence of ambiguous discourse connectives in the English translation. Furthermore, the mismatches between discourse expressions across languages significantly impact translation quality."
C14-1055,Cross-lingual Discourse Relation Analysis: A corpus study and a semi-supervised classification system,2014,42,4,2,0,1538,junyi li,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We present a cross-lingual discourse relation analysis based on a parallel corpus with discourse information available only for one language. First, we conduct a corpus study to explore differences in discourse organization between Chinese and English, including differences in information packaging, implicit/explicit discourse expression divergence, and discourse connective ambiguities. Second, we introduce a novel approach to learning to recognize discourse relations, using the parallel corpus instead of discourse annotation in the language of interest. Our resulting semi-supervised system reaches state-of-art performance on the task of discourse relation detection, and outperforms a supervised system on discourse relation classification."
W13-1712,Feature Space Selection and Combination for Native Language Identification,2013,10,6,3,0.753307,653,cyril goutte,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We decribe the submissions made by the National Research Council Canada to the Native Language Identification (NLI) shared task. Our submissions rely on a Support Vector Machine classifier, various feature spaces using a variety of lexical, spelling, and syntactic features, and on a simple model combination strategy relying on a majority vote between classifiers. Somewhat surprisingly, a classifier relying on purely lexical features performed very well and proved difficult to outperform significantly using various combinations of feature spaces. However, the combination of multiple predictors allowed to exploit their different strengths and provided a significant boost in performance."
W13-0801,A Semantic Evaluation of Machine Translation Lexical Choice,2013,43,3,1,1,6058,marine carpuat,"Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"While automatic metrics of translation quality are invaluable for machine translation research, deeper understanding of translation errors require more focused evaluations designed to target specific aspects of translation quality. We show that Word Sense Disambiguation (WSD) can be used to evaluate the quality of machine translation lexical choice, by applying a standard phrase-based SMT system on the SemEval2010 Cross-Lingual WSD task. This case study reveals that the SMT system does not perform as well as a WSD system trained on the exact same parallel data, and that local context models based on source phrases and target n-grams are much weaker representations of context than the simple templates used by the WSD system."
S13-2034,{NRC}: A Machine Translation Approach to Cross-Lingual Word Sense Disambiguation ({S}em{E}val-2013 Task 10),2013,18,11,1,1,6058,marine carpuat,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes the NRC submission to the Spanish Cross-Lingual Word Sense Disambiguation task at SemEval-2013. Since this word sense disambiguation task uses Spanish translations of English words as gold annotation, it can be cast as a machine translation problem. We therefore submitted the output of a standard phrase-based system as a baseline, and investigated ways to improve its sense disambiguation performance. Using only local context information and no linguistic analysis beyond lemmatization, our machine translation system surprisingly yields top precision score based on the best predictions. However, its top 5 predictions are weaker than those from other systems."
Q13-1035,Measuring Machine Translation Errors in New Domains,2013,38,34,3,0,32782,ann irvine,Transactions of the Association for Computational Linguistics,0,"We develop two techniques for analyzing the effect of porting a machine translation system to a new domain. One is a macro-level analysis that measures how domain shift affects corpus-level evaluation; the second is a micro-level analysis for word-level errors. We apply these methods to understand what happens when a Parliament-trained phrase-based machine translation system is applied in four very different domains: news, medical texts, scientific articles and movie subtitles. We present quantitative and qualitative experiments that highlight opportunities for future research in domain adaptation for machine translation."
P13-1141,{S}ense{S}potting: Never let your parallel data tie you to an old domain,2013,28,22,1,1,6058,marine carpuat,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Words often gain new senses in new domains. Being able to automatically identify, from a corpus of monolingual text, which word tokens are being used in a previously unseen sense has applications to machine translation and other tasks sensitive to lexical semantics. We define a task, SENSESPOTTING, in which we build systems to spot tokens that have new senses in new domain text. Instead of difficult and expensive annotation, we build a goldstandard by leveraging cheaply available parallel corpora, targeting our approach to the problem of domain adaptation for machine translation. Our system is able to achieve F-measures of as much as 80%, when applied to word types it has never seen before. Our approach is based on a large set of novel features that capture varied aspects of how words change when used in new domains."
W12-3156,The Trouble with {SMT} Consistency,2012,13,30,1,1,6058,marine carpuat,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"SMT typically models translation at the sentence level, ignoring wider document context. Does this hurt the consistency of translated documents? Using a phrase-based SMT system in various data conditions, we show that SMT translates documents remarkably consistently, even without document knowledge. Nevertheless, translation inconsistencies often indicate translation errors. However, unlike in human translation, these errors are rarely due to terminology inconsistency. They are more often symptoms of deeper issues with SMT models instead."
2012.amta-papers.7,The Impact of Sentence Alignment Errors on Phrase-Based Machine Translation Performance,2012,-1,-1,2,0.753307,653,cyril goutte,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"When parallel or comparable corpora are harvested from the web, there is typically a tradeoff between the size and quality of the data. In order to improve quality, corpus collection efforts often attempt to fix or remove misaligned sentence pairs. But, at the same time, Statistical Machine Translation (SMT) systems are widely assumed to be relatively robust to sentence alignment errors. However, there is little empirical evidence to support and characterize this robustness. This contribution investigates the impact of sentence alignment errors on a typical phrase-based SMT system. We confirm that SMT systems are highly tolerant to noise, and that performance only degrades seriously at very high noise levels. Our findings suggest that when collecting larger, noisy parallel data for training phrase-based SMT, cleaning up by trying to detect and remove incorrect alignments can actually degrade performance. Although fixing errors, when applicable, is a preferable strategy to removal, its benefits only become apparent for fairly high misalignment rates. We provide several explanations to support these findings."
2012.amta-keynotes.1,Domain Adaptation in Machine Translation: Findings from the 2012 {J}ohns {H}opkins Summer Workshop,2012,-1,-1,2,0,4346,hal iii,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Keynote Presentations,0,None
P10-2033,Improving {A}rabic-to-{E}nglish Statistical Machine Translation by Reordering Post-Verbal Subjects for Alignment,2010,44,37,1,1,6058,marine carpuat,Proceedings of the {ACL} 2010 Conference Short Papers,0,"We study the challenges raised by Arabic verb and subject detection and reordering in Statistical Machine Translation (SMT). We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to English. In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately, even with a state-of-the-art Arabic dependency parser. We therefore propose to reorder VS constructions into SV order for SMT word alignment only. This strategy significantly improves BLEU and TER scores, even on a strong large-scale baseline and despite noisy parses."
N10-1029,Task-based Evaluation of Multiword Expressions: a Pilot Study in Statistical Machine Translation,2010,12,60,1,1,6058,marine carpuat,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We conduct a pilot study for task-oriented evaluation of Multiword Expression (MWE) in Statistical Machine Translation (SMT). We propose two different integration strategies for MWE in SMT, which take advantage of different degrees of MWE semantic compositionality and yield complementary improvements in SMT quality on a large-scale translation task."
2010.jeptalnrecital-long.30,Reordering Matrix Post-verbal Subjects for {A}rabic-to-{E}nglish {SMT},2010,-1,-1,1,1,6058,marine carpuat,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"We improve our recently proposed technique for integrating Arabic verb-subject constructions in SMT word alignment (Carpuat et al., 2010) by distinguishing between matrix (or main clause) and non-matrix Arabic verb-subject constructions. In gold translations, most matrix VS (main clause verb-subject) constructions are translated in inverted SV order, while non-matrix (subordinate clause) VS constructions are inverted in only half the cases. In addition, while detecting verbs and their subjects is a hard task, our syntactic parser detects VS constructions better in matrix than in non-matrix clauses. As a result, reordering only matrix VS for word alignment consistently improves translation quality over a phrase-based SMT baseline, and over reordering all VS constructions, in both medium- and large-scale settings. In fact, the improvements obtained by reordering matrix VS on the medium-scale setting remarkably represent 44{\%} of the gain in BLEU and 51{\%} of the gain in TER obtained with a word alignment training bitext that is 5 times larger."
W09-2404,One Translation Per Discourse,2009,26,37,1,1,6058,marine carpuat,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We revisit the one sense per discourse hypothesis of Gale et al. in the context of machine translation. Since a given sense can be lexicalized differently in translation, do we observe one translation per discourse? Analysis of manual translations reveals that the hypothesis still holds when using translations in parallel text as sense annotation, thus confirming that translational differences represent useful sense distinctions. Analysis of Statistical Machine Translation (SMT) output showed that despite ignoring document structure, the one translation per discourse hypothesis is strongly supported in part because of the low variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors. A preliminary study showed that enforcing the one translation per discourse constraint in SMT can potentially improve translation quality, and that SMT systems might benefit from translating sentences within their entire document context."
W09-0427,Toward Using Morphology in {F}rench-{E}nglish Phrase-Based {SMT},2009,13,5,1,1,6058,marine carpuat,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"We describe the system used in our submission to the WMT-2009 French-English translation task. We use the Moses phrase-based Statistical Machine Translation system with two simple modications of the decoding input and word-alignment strategy based on morphology, and analyze their impact on translation quality."
carpuat-wu-2008-evaluation,Evaluation of Context-Dependent Phrasal Translation Lexicons for Statistical Machine Translation,2008,20,13,1,1,6058,marine carpuat,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present new direct data analysis showing that dynamically-built context-dependent phrasal translation lexicons are more useful resources for phrase-based statistical machine translation (SMT) than conventional static phrasal translation lexicons, which ignore all contextual information. After several years of surprising negative results, recent work suggests that context-dependent phrasal translation lexicons are an appropriate framework to successfully incorporate Word Sense Disambiguation (WSD) modeling into SMT. However, this approach has so far only been evaluated using automatic translation quality metrics, which are important, but aggregate many different factors. A direct analysis is still needed to understand how context-dependent phrasal translation lexicons impact translation quality, and whether the additional complexity they introduce is really necessary. In this paper, we focus on the impact of context-dependent translation lexicons on lexical choice in phrase-based SMT and show that context-dependent lexicons are more useful to a phrase-based SMT system than a conventional lexicon. A typical phrase-based SMT system makes use of more and longer phrases with context modeling, including phrases that were not seen very frequently in training. Even when the segmentation is identical, the context-dependent lexicons yield translations that match references more often than conventional lexicons."
D07-1007,Improving Statistical Machine Translation Using Word Sense Disambiguation,2007,44,294,1,1,6058,marine carpuat,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We show for the first time that incorporating the predictions of a word sense disambiguation system within a typical phrase-based statistical machine translation (SMT) model consistently improves translation quality across all three different IWSLT ChineseEnglish test sets, as well as producing statistically significant improvements on the larger NIST Chinese-English MT taskxe2x80x94 and moreover never hurts performance on any test set, according not only to BLEU but to all eight most commonly used automatic evaluation metrics. Recent work has challenged the assumption that word sense disambiguation (WSD) systems are useful for SMT. Yet SMT translation quality still obviously suffers from inaccurate lexical choice. In this paper, we address this problem by investigating a new strategy for integrating WSD into an SMT system, that performs fully phrasal multi-word disambiguation. Instead of directly incorporating a Senseval-style WSD system, we redefine the WSD task to match the exact same phrasal translation disambiguation task faced by phrase-based SMT systems. Our results provide the first known empirical evidence that lexical semantics are indeed useful for SMT, despite claims to the contrary."
2007.tmi-papers.6,How phrase sense disambiguation outperforms word sense disambiguation for statistical machine translation,2007,23,52,1,1,6058,marine carpuat,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"We present comparative empirical evidence arguing that a generalized phrase sense disambiguation approach better improves statistical machine translation than ordinary word sense disambiguation, along with a data analysis suggesting the reasons for this. Standalone word sense disambiguation, as exemplified by the Senseval series of evaluations, typically defines the target of disambiguation as a single word. But in order to be useful in statistical machine translation, our studies indicate that word sense disambiguation should be redefined to move beyond the particular case of single word targets, and instead to generalize to multi-word phrase targets. We investigate how and why the phrase sense disambiguation approachxe2x80x94in contrast to recent efforts to apply traditional word sense disambiguation to SMTxe2x80x94is able to yield statistically significant yimprovements in translation quality even under large data conditions, and consistently improve SMT across both IWSLT and NIST Chinese-English text translation tasks. We discuss architectural issues raised by this change of perspective, and consider the new model architecture necessitated by the phrase sense disambiguation approach. This material is based upon work supported in part by"
2007.mtsummit-papers.11,Context-dependent phrasal translation lexicons for statistical machine translation,2007,25,27,1,1,6058,marine carpuat,Proceedings of Machine Translation Summit XI: Papers,0,"Most current statistical machine translation (SMT) systems make very little use of contextual information to select a translation candidate for a given input language phrase. However, despite evidence that rich context features are useful in stand-alone translation disambiguation tasks, recent studies reported that incorporating context-rich approaches from Word Sense Disambiguation (WSD) methods directly into classic word-based SMT systems, surprisingly, did not yield the expected improvements in translation quality. We argue here that, instead, it is necessary to design a contextdependent lexicon that is specifically matched to a given phrase-based SMT model, rather than simply incorporating an independently built and tested WSD module. In this approach, the baseline SMT phrasal lexicon, which uses translation probabilities that are independent of context, is augmented with a context-dependent score, defined using insights from standalone translation disambiguation evaluations. This approach reliably improves performance on both IWSLT and NIST ChineseEnglish test sets, producing consistent gains on all eight of the most commonly used automated evaluation metrics. We analyze the behavior of the model along a number of dimensons, including an analysis confirming that the most important context features are not available in conventional phrase-based SMT models."
2007.iwslt-1.12,{HKUST} statistical machine translation experiments for {IWSLT} 2007,2007,19,3,3,0,49487,yihai shen,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper describes the HKUST experiments in the IWSLT 2007 evaluation campaign on spoken language translation. Our primary objective was to compare the open-source phrase-based statistical machine translation toolkit Moses against Pharaoh. We focused on Chinese to English translation, but we also report results on the Arabic to English, Italian to English, and Japanese to English tasks."
W06-0124,Boosting for {C}hinese Named Entity Recognition,2006,12,7,2,0,40250,xiaofeng yu,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,"We report an experiment in which a highperformance boosting based NER model originally designed for multiple European languages is instead applied to the Chinese named entity recognition task of the third SIGHAN Chinese language processing bakeoff. Using a simple characterbased model along with a set of features that are easily obtained from the Chinese input strings, the system described employs boosting, a promising and theoretically well-founded machine learning method to combine a set of weak classifiers together into a final system. Even though we did no other Chinese-specific tuning, and used only one-third of the MSRA and CityU corpora to train the system, reasonable results are obtained. Our evaluation results show that 75.07 and 80.51 overall F-measures were obtained on MSRA and CityU test sets respectively."
2006.iwslt-evaluation.5,Toward integrating word sense and entity disambiguation into statistical machine translation,2006,29,14,1,1,6058,marine carpuat,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We describe a machine translation approach being designed at HKUST to integrate semantic processing into statistical machine translation, beginning with entity and word sense disambiguation. We show how integrating the semantic modules consistently improves translation quality across several data sets. We report results on five different IWSLT 2006 speech translation tasks, representing HKUSTxe2x80x99s first participation in the IWSLT spoken language translation evaluation campaign. We translated both read and spontaneous speech transcriptions fromChinese to English, achieving reasonable performance despite the fact that our system is essentially text-based and therefore not designed and tuned to tackle the challenges of speech translation. We also find that the system achieves reasonable results on a wide range of languages, by evaluating on read speech transcriptions from Arabic, Italian, and Japanese into English."
P05-1048,Word Sense Disambiguation vs. Statistical Machine Translation,2005,22,114,1,1,6058,marine carpuat,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"We directly investigate a subject of much recent debate: do word sense disambiguation models help statistical machine translation quality? We present empirical results casting doubt on this common, but unproved, assumption. Using a state-of-the-art Chinese word sense disambiguation model to choose translation candidates for a typical IBM statistical MT system, we find that word sense disambiguation does not yield significantly better translation quality than the statistical machine translation system alone. Error analysis suggests several key factors behind this surprising finding, including inherent limitations of current statistical MT architectures."
I05-2021,Evaluating the Word Sense Disambiguation Performance of Statistical Machine Translation,2005,17,28,1,1,6058,marine carpuat,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We present the first known empirical test of an increasingly common speculative claim, by evaluating a representative Chinese-toEnglish SMT model directly on word sense disambiguation performance, using standard WSD evaluation methodology and datasets from the Senseval-3 Chinese lexical sample task. Much effort has been put in designing and evaluating dedicated word sense disambiguation (WSD) models, in particular with the Senseval series of workshops. At the same time, the recent improvements in the BLEU scores of statistical machine translation (SMT) suggests that SMT models are good at predicting the right translation of the words in source language sentences. Surprisingly however, the WSD accuracy of SMT models has never been evaluated and compared with that of the dedicated WSD models. We present controlled experiments showing the WSD accuracy of current typical SMT models to be significantly lower than that of all the dedicated WSD models considered. This tends to support the view that despite recent speculative claims to the contrary, current SMT models do have limitations in comparison with dedicated WSD models, and that SMT should benefit from the better predictions made by the WSD models. The authors would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through grants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09."
W04-0822,Augmenting ensemble classification for Word Sense Disambiguation with a kernel {PCA} model,2004,12,17,1,1,6058,marine carpuat,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"The HKUST word sense disambiguation systems benefit from a new nonlinear Kernel Principal Component Analysis (KPCA) based disambiguation technique. We discuss and analyze results from the Senseval-3 English, Chinese, and Multilingual Lexical Sample data sets. Among an ensemble of four different kinds of voted models, the KPCA-based model, along with the maximum entropy model, outperforms the boosting model and"
W04-0845,"Semantic role labeling with Boosting, {SVM}s, Maximum Entropy, {SNOW}, and Decision Lists",2004,9,11,3,0,49223,grace ngai,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper describes the HKPolyU-HKUST systems which were entered into the Semantic Role Labeling task in Senseval-3. Results show that these systems, which are based upon common machine learning algorithms, all manage to achieve good performances on the non-restricted Semantic Role Labeling task."
W04-0863,Joining forces to resolve lexical ambiguity: East meets West in {B}arcelona,2004,3,1,4,0,824,richard wicentowski,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
P04-1081,A Kernel {PCA} Method for Superior Word Sense Disambiguation,2004,21,24,3,0,33578,dekai wu,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"We introduce a new method for disambiguating word senses that exploits a nonlinear Kernel Principal Component Analysis (KPCA) technique to achieve accuracy superior to the best published individual models. We present empirical results demonstrating significantly better accuracy compared to the state-of-the-art achieved by either naive Bayes or maximum entropy models, on Senseval-2 data. We also contrast against another type of kernel method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions."
N04-4010,Using N-best lists for Named Entity Recognition from {C}hinese Speech,2004,10,27,4,0,51822,lufeng zhai,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"We present the first known result for named entity recognition (NER) in realistic large-vocabulary spoken Chinese. We establish this result by applying a maximum entropy model, currently the single best known approach for textual Chinese NER, to the recognition output of the BBN LVCSR system on Chinese Broadcast News utterances. Our results support the claim that transferring NER approaches from text to spoken language is a significantly more difficult task for Chinese than for English. We propose re-segmenting the ASR hypotheses as well as applying post-classification to improve the performance. Finally, we introduce a method of using n-best hypotheses that yields a small but nevertheless useful improvement NER accuracy. We use acoustic, phonetic, language model, NER and other scores as confidence measure. Experimental results show an average of 6.7% relative improvement in precision and 1.7% relative improvement in F-measure."
wu-etal-2004-raising,Raising the Bar: Stacked Conservative Error Correction Beyond Boosting,2004,12,4,3,0,33578,dekai wu,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We introduce a conservative error correcting model, Stacked TBL, that is designed to improve the performance of even high-performing models like boosting, with little risk of accidentally degrading performance. Stacked TBL is particularly well suited for corpus-based natural language applications involving high-dimensional feature spaces, since it leverages the characteristics of the TBL paradigm that we appropriate. We consider here the task of automatically annonating named entities in text corpora. The task does pose a number of challenges for TBL, to which there are some simple yet effective solutions. We discuss the empirical behavior of Stacked TBL, and consider evidence that despite its simplicity, more complex and time-consuming variants are not generally required. 1. Setting the Bar: Introduction In this paper we develop a general stacking-based method called Stacked TBL (STBL) that error-corrects the output of a boosting model that is already highly tuned. We deploy TBL in an unconventional fashion, and discuss motivation and evidence to support its use. Several modifications to the traditional TBL procedure are required, but the revised procedure remains relatively simple. To demonstrate the applicability of STBL, we construct a base model trained using the AdaBoost boosting algorithm (Freund and Schapire, 1997). Boosting has acquired a superior reputation for error driven learning of ensemble models and, when used in corpus-based NLP systems, typically finds a place as the ultimate stage. Two of the best-performing three teams in the CoNLL-2002 Named Entity Recognition shared task evaluation used boosting as their base system (Carreras et al., 2002; Wu et al., 2002). However, we have found that, like all learning models, even boosting models can and do reach certain limits that other models are less susceptible to. This holds even after careful feature engineering to compensate is carried out. We are thus driven to investigate the problem of correcting errors after boosting has done its best. This establishes a high bar for any model stacked on the boosting base model, because it is difficult to correct the few remaining errors without also accidentally undoing correct classifications at the same time. In the following sections, we first define the particular stacking approach we will use. Subsequently we describe our model in detail, and analyze issues that arise from repurposing TBL for this task. We discuss the principles behind our proposed solutions, and demonstrate the The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through research grants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09. The author would like to thank the Hong Kong Polytechnic University for supporting this research in part through research grants A-PE37 and 4-Z03S. methodxe2x80x99s empirical behavior. Finally, we consider evidence that more complicated and time-consuming alternative variants of STBL are unnecessary in practice. 2. Piping versus Stacking Stacking has become widely used since its introduction a decade ago (Wolpert, 1992). However, a few words of clarification on stacking are in order since it is an extremely general concept, that is often confusingly used to lump together various approaches that are in fact methodologically quite different. The major division of stacking approaches is between (1) those employing multiple heterogenous base learning models, and (2) those employing a single base learning model. The former case is a general alternative to simple voting among heterogenous base models. To avoid confusion we will use the term piping for the latter case, i.e., stacking with a single base learning model. In this paper we will restrict our attention to piping, specifically using a boosting base model. Usage of piping has two common subcases. First, piping provides a kind of arcing framework (Breiman, 1998), and as such is an alternative to simple bagging models. As an arcing procedure, however, its use appears to have been eclipsed in recent years by boosting. Second, for some tasks, piping is effective as a sequentially chained error correcting ensemble. The investigation in this paper falls in this category. Piped classifiers differ from cascaded classifiers (e.g., Alpaydin (1998)) in several important respects, one of which is that in cascading, confidence scores are not assigned to the predictions of the earlier classifiers. A cascaded classifier only attempts to classify examples that earlier stages have voluntarily passed on; it does not identify where errors are likely to have occurred and therefore is not an error corrector per se. Piping can, however, be viewed as a combination of cascading and confidence prediction. In this view, the error correcting stage is responsible for both predicting the confidence on each example that was output by the previous stage, as well as performing corrections on low-confidence examples. In fact, to be more precise, it is not actually necessary for the error correcting stage to predict an absolute confidence score for the base modelxe2x80x99s output. It merely needs to predict with high confidence when the error correctorxe2x80x99s confidence score is relatively higher than the base modelxe2x80x99s. Piping, broadly interpreted, is widespread in corpusbased NLP. An example of piping in an NER application very similar to the experiments described later in this paper is Florian (2002), who used a TBL base model piped to a forward-backward decoder model. However, narrowly interpreted piping, which employs correct and sound stacking training procedures, is rather less common, perhaps especially in NLP work. 3. Raising the Bar: Repurposing TBL for Error Correction Certain kinds of models are better suited to error correction than others. This is particularly true when the performance of the base model is already high. The error corrector model must (1) have characteristics that vary sufficiently from the base model so that the corrector will make a significant difference, and (2) be excellent at xe2x80x9cleaving well enough alonexe2x80x9d so as not to miscorrect the already highly accurate predictions from the boosting model. We consider transformation-based learning to be a reasonable candidate for error correction, and we call this model Stacked TBL (STBL). The odd thing is that although it is inherently an error-correcting paradigm, TBL has not received much attention as an error-corrector for models that already achieve high performance. Instead, TBL is traditionally used by itself, trained by correcting the output of relatively xe2x80x9cdumbxe2x80x9d base models. Even less attention has been given to using TBL as an error corrector for highperformance models.1 Nevertheless, TBL appeared to fit the bill since (1) its sequential processing characteristics are very different from the boosting modelxe2x80x99s, and (2) it can be modified to leave well enough alone, as we shall see in the subsequent section. Transformation-based learning was first introduced by Brill (1995) for part-of-speech tagging, and it has since been applied to a wide range of corpus-based NLP tasks, including parsing (Brill, 1996), noun phrase chunking (Ramshaw and Marcus, 1999), phrase chunking (Florian et al., 2000), and dialog act tagging (Samuel et al., 1998). It is a flexible model which is easily extensible to various tasks, and it has the advantage of being able to achieve state-ofthe-art performance with a small set of perspicious rules. In some ways, TBL is similar to boosting in that it is an iterative process in which each iteration targets the residual error from previous iterations. A traditional TBL system is trained using the following algorithm: 1. Create an initial assignment of classifi cations using simple"
C04-1058,Why Nitpicking Works: Evidence for Occam{'}s Razor in Error Correctors,2004,15,4,3,0,33578,dekai wu,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Empirical experience and observations have shown us when powerful and highly tunable classifiers such as maximum entropy classifiers, boosting and SVMs are applied to language processing tasks, it is possible to achieve high accuracies, but eventually their performances all tend to plateau out at around the same point. To further improve performance, various error correction mechanisms have been developed, but in practice, most of them cannot be relied on to predictably improve performance on unseen data; indeed, depending upon the test set, they are as likely to degrade accuracy as to improve it. This problem is especially severe if the base classifier has already been finely tuned.In recent work, we introduced N-fold Templated Piped Correction, or NTPC (nitpick), an intriguing error corrector that is designed to work in these extreme operating conditions. Despite its simplicity, it consistently and robustly improves the accuracy of existing highly accurate base models. This paper investigates some of the more surprising claims made by NTPC, and presents experiments supporting an Occam's Razor argument that more complex models are damaging or unnecessary in practice."
C04-1190,Semi-supervised training of a Kernel {PCA}-Based Model for Word Sense Disambiguation,2004,15,9,2,0,7570,weifeng su,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper, we introduce a new semi-supervised learning model for word sense disambiguation based on Kernel Principal Component Analysis (KPCA), with experiments showing that it can further improve accuracy over supervised KPCA models that have achieved WSD accuracy superior to the best published individual models. Although empirical results with supervised KPCA models demonstrate significantly better accuracy compared to the state-of-the-art achieved by either naive Bayes or maximum entropy models on Senseval-2 data, we identify specific sparse data conditions under which supervised KPCA models deteriorate to essentially a most-frequent-sense predictor. We discuss the potential of KPCA for leveraging unannotated data for partially-unsupervised training to address these issues, leading to a composite model that combines both the supervised and semi-supervised models."
W03-0433,"A Stacked, Voted, Stacked Model for Named Entity Recognition",2003,14,57,3,0.385505,33578,dekai wu,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"This paper investigates stacking and voting methods for combining strong classifiers like boosting, SVM, and TBL, on the named-entity recognition task. We demonstrate several effective approaches, culminating in a model that achieves error rate reductions on the development and test sets of 63.6% and 55.0% (English) and 47.0% and 51.7% (German) over the CoNLL-2003 standard baseline respectively, and 19.7% over a strong AdaBoost baseline model from CoNLL-2002."
W02-2035,Boosting for Named Entity Recognition,2002,9,38,3,0,33578,dekai wu,{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002),0,"This paper presents a system that applies boosting to the task of named-entity identification. The CoNLL-2002 shared task, for which the system is designed, is language-independent named-entity recognition. Using a set of features which are easily obtainable for almost any language, the presented system uses boosting to combine a set of weak classifiers into a final system that performs significantly better than that of an off-the-shelf maximum entropy classifier."
C02-1162,Identifying Concepts Across Languages: A First Step towards a Corpus-based Approach to Automatic Ontology Alignment,2002,18,22,2,0,49223,grace ngai,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"The growing importance of multilingual information retrieval and machine translation has made multilingual ontologies an extremely valuable resource. Since the construction of an ontology from scratch is a very expensive and time consuming undertaking, it is attractive to consider ways of automatically aligning monolingual ontologies, which already exist for many of the world's major languages."
