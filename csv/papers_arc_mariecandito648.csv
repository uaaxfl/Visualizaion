2020.mwe-1.14,Edition 1.2 of the {PARSEME} Shared Task on Semi-supervised Identification of Verbal Multiword Expressions,2020,-1,-1,5,0,12002,carlos ramisch,Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons,0,"We present edition 1.2 of the PARSEME shared task on identification of verbal multiword expressions (VMWEs). Lessons learned from previous editions indicate that VMWEs have low ambiguity, and that the major challenge lies in identifying test instances never seen in the training data. Therefore, this edition focuses on unseen VMWEs. We have split annotated corpora so that the test corpora contain around 300 unseen VMWEs, and we provide non-annotated raw corpora to be used by complementary discovery methods. We released annotated and raw corpora in 14 languages, and this semi-supervised challenge attracted 7 teams who submitted 9 system results. This paper describes the effort of corpus creation, the task design, and the results obtained by the participating systems, especially their performance on unseen expressions."
2020.lrec-1.724,{F}r{S}em{C}or: Annotating a {F}rench Corpus with Supersenses,2020,0,0,5,0,18073,lucie barque,Proceedings of the 12th Language Resources and Evaluation Conference,0,"French, as many languages, lacks semantically annotated corpus data. Our aim is to provide the linguistic and NLP research communities with a gold standard sense-annotated corpus of French, using WordNet Unique Beginners as semantic tags, thus allowing for interoperability. In this paper, we report on the first phase of the project, which focused on the annotation of common nouns. The resulting dataset consists of more than 12,000 French noun occurrences which were annotated in double blind and adjudicated according to a carefully redefined set of supersenses. The resource is released online under a Creative Commons Licence."
W19-6109,Comparing linear and neural models for competitive {MWE} identification,2019,0,0,2,0,23677,hazem saied,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"In this paper, we compare the use of linear versus neural classifiers in a greedy transition system for MWE identification. Both our linear and neural models achieve a new state-of-the-art on the PARSEME 1.1 shared task data sets, comprising 20 languages. Surprisingly, our best model is a simple feed-forward network with one hidden layer, although more sophisticated (recurrent) architectures were tested. The feedback from this study is that tuning a SVM is rather straightforward, whereas tuning our neural system revealed more challenging. Given the number of languages and the variety of linguistic phenomena to handle for the MWE identification task, we have designed an accurate tuning procedure, and we show that hyperparameters are better selected by using a majority-vote within random search configurations rather than a simple best configuration selection. Although the performance is rather good (better than both the best shared task system and the average of the best per-language results), further work is needed to improve the generalization power, especially on unseen MWEs."
W19-6110,Syntax-based identification of light-verb constructions,2019,0,0,2,0.833333,23678,silvio cordeiro,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"This paper analyzes results on light-verb construction identification from the PARSEME shared-task, distinguishing between simple cases that could be directly learned from training data from more complex cases that require an extra level of semantic processing. We propose a simple baseline that beats the state of the art for the simple cases, and couple it with another simple baseline to handle the complex cases. We additionally present two other classifiers based on a richer set of features, with results surpassing the state of the art by 8 percentage points."
W19-0422,Using {W}iktionary as a resource for {WSD} : the case of {F}rench verbs,2019,0,1,2,0,17270,vincent segonne,Proceedings of the 13th International Conference on Computational Semantics - Long Papers,0,"As opposed to word sense induction, word sense disambiguation (WSD) has the advantage of us-ing interpretable senses, but requires annotated data, which are quite rare for most languages except English (Miller et al. 1993; Fellbaum, 1998). In this paper, we investigate which strategy to adopt to achieve WSD for languages lacking data that was annotated specifically for the task, focusing on the particular case of verb disambiguation in French. We first study the usability of Eurosense (Bovi et al. 2017) , a multilingual corpus extracted from Europarl (Kohen, 2005) and automatically annotated with BabelNet (Navigli and Ponzetto, 2010) senses. Such a resource opened up the way to supervised and semi-supervised WSD for resourceless languages like French. While this perspective looked promising, our evaluation on French verbs was inconclusive and showed the annotated senses{'} quality was not sufficient for supervised WSD on French verbs. Instead, we propose to use Wiktionary, a collaboratively edited, multilingual online dictionary, as a resource for WSD. Wiktionary provides both sense inventory and manually sense tagged examples which can be used to train supervised and semi-supervised WSD systems. Yet, because senses{'} distribution differ in lexicographic examples found in Wiktionary with respect to natural text, we then focus on studying the impact on WSD of the training data size and senses{'} distribution. Using state-of-the art semi-supervised systems, we report experiments of Wiktionary-based WSD for French verbs, evaluated on FrenchSemEval (FSE), a new dataset of French verbs manually annotated with wiktionary senses."
S19-2003,{S}em{E}val-2019 Task 2: Unsupervised Lexical Frame Induction,2019,0,3,5,0,18354,behrang qasemizadeh,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"This paper presents Unsupervised Lexical Frame Induction, Task 2 of the International Workshop on Semantic Evaluation in 2019. Given a set of prespecified syntactic forms in context, the task requires that verbs and their arguments be clustered to resemble semantic frame structures. Results are useful in identifying polysemous words, i.e., those whose frame structures are not easily distinguished, as well as discerning semantic relations of the arguments. Evaluation of unsupervised frame induction methods fell into two tracks: Task A) Verb Clustering based on FrameNet 1.7; and B) Argument Clustering, with B.1) based on FrameNet{'}s core frame elements, and B.2) on VerbNet 3.2 semantic roles. The shared task attracted nine teams, of whom three reported promising results. This paper describes the task and its data, reports on methods and resources that these systems used, and offers a comparison to human annotation."
W18-4925,Edition 1.1 of the {PARSEME} Shared Task on Automatic Identification of Verbal Multiword Expressions,2018,0,2,8,0.213919,12002,carlos ramisch,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"This paper describes the PARSEME Shared Task 1.1 on automatic identification of verbal multiword expressions. We present the annotation methodology, focusing on changes from last year{'}s shared task. Novel aspects include enhanced annotation guidelines, additional annotated data for most languages, corpora for some new languages, and new evaluation settings. Corpora were created for 20 languages, which are also briefly discussed. We report organizational principles behind the shared task and the evaluation metrics employed for ranking. The 17 participating systems, their methods and obtained results are also presented and analysed."
L18-1718,Cheating a Parser to Death: Data-driven Cross-Treebank Annotation Transfer,2018,0,0,5,0,167,djame seddah,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"We present an efficient and accurate method for transferring annotations between two different treebanks of the same language. This method led to the creation of a new instance of the French Treebank (Abeille et al., 2003), which follows the Universal Dependency annotation scheme and which was proposed to the participants of the CoNLL 2017 Universal Dependency parsing shared task (Zeman et al., 2017). Strong results from an evaluation on our gold standard (94.75% of LAS, 99.40% UAS on the test set) demonstrate the quality of this new annotated data set and validate our approach."
W17-7601,Annotating and parsing to semantic frames: feedback from the {F}rench {F}rame{N}et project,2017,-1,-1,1,1,16504,marie candito,Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories,0,None
W17-6507,Enhanced {UD} Dependencies with Neutralized Diathesis Alternation,2017,19,3,1,1,16504,marie candito,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,"The 2.0 release of the Universal Dependency treebanks demonstrates the effectiveness of the UD scheme to cope with very diverse languages. The next step would be to get more of syntactic analysis , and the  enhanced dependencies  sketched in the UD 2.0 guidelines is a promising attempt in that direction. In this work we propose to go further and enrich the enhanced dependency scheme along two axis: extending the cases of recovered arguments of non-finite verbs, and neutralizing syntactic alternations. Doing so leads to both richer and more uniform structures, while remaining at the syntactic level, and thus rather neutral with respect to the type of semantic representation that can be further obtained. We implemented this proposal in two UD treebanks of French, using deterministic graph-rewriting rules. Evaluation on a 200 sentence gold standard shows that deep syntactic graphs can be obtained from surface syntax annotations with a high accuracy. Among all arguments of verbs in the gold standard, 13.91% are impacted by syntactic alternation normalization, and 18.93% are additional deep edges."
W17-1704,The {PARSEME} Shared Task on Automatic Identification of Verbal Multiword Expressions,2017,5,8,7,0.407925,16493,agata savary,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"Multiword expressions (MWEs) are known as a {``}pain in the neck{''} for NLP due to their idiosyncratic behaviour. While some categories of MWEs have been addressed by many studies, verbal MWEs (VMWEs), such as to take a decision, to break one{'}s heart or to turn off, have been rarely modelled. This is notably due to their syntactic variability, which hinders treating them as {``}words with spaces{''}. We describe an initiative meant to bring about substantial progress in understanding, modelling and processing VMWEs. It is a joint effort, carried out within a European research network, to elaborate universal terminologies and annotation guidelines for 18 languages. Its main outcome is a multilingual 5-million-word annotated corpus which underlies a shared task on automatic identification of VMWEs. This paper presents the corpus annotation methodology and outcome, the shared task organisation and the results of the participating systems."
W17-1717,The {ATILF}-{LLF} System for Parseme Shared Task: a Transition-based Verbal Multiword Expression Tagger,2017,7,3,3,0,23677,hazem saied,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"We describe the ATILF-LLF system built for the MWE 2017 Shared Task on automatic identification of verbal multiword expressions. We participated in the closed track only, for all the 18 available languages. Our system is a robust greedy transition-based system, in which MWE are identified through a MERGE transition. The system was meant to accommodate the variety of linguistic resources provided for each language, in terms of accompanying morphological and syntactic information. Using per-MWE Fscore, the system was ranked first for all but two languages (Hungarian and Romanian)."
2017.jeptalnrecital-court.1,Annotation d{'}expressions polylexicales verbales en fran{\\c{c}}ais (Annotation of verbal multiword expressions in {F}rench),2017,-1,-1,1,1,16504,marie candito,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"Nous d{\'e}crivons la partie fran{\c{c}}aise des donn{\'e}es produites dans le cadre de la campagne multilingue PARSEME sur l{'}identification d{'}expressions polylexicales verbales (Savary et al., 2017). Les expressions couvertes pour le fran{\c{c}}ais sont les expressions verbales idiomatiques, les verbes intrins{\`e}quement pronominaux et une g{\'e}n{\'e}ralisation des constructions {\`a} verbe support. Ces ph{\'e}nom{\`e}nes ont {\'e}t{\'e} annot{\'e}s sur le corpus French-UD (Nivre et al., 2016) et le corpus Sequoia (Candito {\&} Seddah, 2012), soit un corpus de 22 645 phrases, pour un total de 4 962 expressions annot{\'e}es. On obtient un ratio d{'}une expression annot{\'e}e tous les 100 tokens environ, avec un fort taux d{'}expressions discontinues (40{\%})."
L16-1375,Hard Time Parsing Questions: Building a {Q}uestion{B}ank for {F}rench,2016,13,1,2,0,167,djame seddah,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present the French Question Bank, a treebank of 2600 questions. We show that classical parsing model performance drop while the inclusion of this data set is highly beneficial without harming the parsing of non-question data. when facing out-of- domain data with strong structural diver- gences. Two thirds being aligned with the QB (Judge et al., 2006) and being freely available, this treebank will prove useful to build robust NLP systems."
L16-1601,Corpus Annotation within the {F}rench {F}rame{N}et: a Domain-by-domain Methodology,2016,13,2,2,0,35314,marianne djemaa,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper reports on the development of a French FrameNet, within the ASFALDA project. While the first phase of the project focused on the development of a French set of frames and corresponding lexicon (Candito et al., 2014), this paper concentrates on the subsequent corpus annotation phase, which focused on four notional domains (commercial transactions, cognitive stances, causality and verbal communication). Given full coverage is not reachable for a relatively {``}new{''} FrameNet project, we advocate that focusing on specific notional domains allowed us to obtain full lexical coverage for the frames of these domains, while partially reflecting word sense ambiguities. Furthermore, as frames and roles were annotated on two French Treebanks (the French Treebank (Abeill{\'e} and Barrier, 2004) and the Sequoia Treebank (Candito and Seddah, 2012), we were able to extract a syntactico-semantic lexicon from the annotated frames. In the resource{'}s current status, there are 98 frames, 662 frame evoking words, 872 senses, and about 13000 annotated frames, with their semantic roles assigned to portions of text. The French FrameNet is freely available at alpage.inria.fr/asfalda."
L16-1603,A General Framework for the Annotation of Causality Based on {F}rame{N}et,2016,31,4,3,0,35315,laure vieu,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present here a general set of semantic frames to annotate causal expressions, with a rich lexicon in French and an annotated corpus of about 5000 instances of causal lexical items with their corresponding semantic frames. The aim of our project is to have both the largest possible coverage of causal phenomena in French, across all parts of speech, and have it linked to a general semantic framework such as FN, to benefit in particular from the relations between other semantic frames, e.g., temporal ones or intentional ones, and the underlying upper lexical ontology that enable some forms of reasoning. This is part of the larger ASFALDA French FrameNet project, which focuses on a few different notional domains which are interesting in their own right (Djemma et al., 2016), including cognitive positions and communication frames. In the process of building the French lexicon and preparing the annotation of the corpus, we had to remodel some of the frames proposed in FN based on English data, with hopefully more precise frame definitions to facilitate human annotation. This includes semantic clarifications of frames and frame elements, redundancy elimination, and added coverage. The result is arguably a significant improvement of the treatment of causality in FN itself."
C16-1040,Deeper syntax for better semantic parsing,2016,21,4,3,0,35700,olivier michalon,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Syntax plays an important role in the task of predicting the semantic structure of a sentence. But syntactic phenomena such as alternations, control and raising tend to obfuscate the relation between syntax and semantics. In this paper we predict the semantic structure of a sentence using a deeper syntax than what is usually done. This deep syntactic representation abstracts away from purely syntactic phenomena and proposes a structural organization of the sentence that is closer to the semantic representation. Experiments conducted on a French corpus annotated with semantic frames showed that a semantic parser reaches better performances with such a deep syntactic input."
P14-1070,Strategies for Contiguous Multiword Expression Analysis and Dependency Parsing,2014,21,18,1,1,16504,marie candito,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper, we investigate various strate- gies to predict both syntactic dependency parsing and contiguous multiword expres- sion (MWE) recognition, testing them on the dependency version of French Tree- bank (Abeille and Barrier, 2004), as in- stantiated in the SPMRL Shared Task (Seddah et al., 2013). Our work focuses on using an alternative representation of syntactically regular MWEs, which cap- tures their syntactic internal structure. We obtain a system with comparable perfor- mance to that of previous works on this dataset, but which predicts both syntactic dependencies and the internal structure of MWEs. This can be useful for capturing the various degrees of semantic composi- tionality of MWEs."
candito-etal-2014-deep,Deep Syntax Annotation of the Sequoia {F}rench Treebank,2014,27,7,1,1,16504,marie candito,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We define a deep syntactic representation scheme for French, which abstracts away from surface syntactic variation and diathesis alternations, and describe the annotation of deep syntactic representations on top of the surface dependency trees of the Sequoia corpus. The resulting deep-annotated corpus, named deep-sequoia, is freely available, and hopefully useful for corpus linguistics studies and for training deep analyzers to prepare semantic analysis."
candito-etal-2014-developing,Developing a {F}rench {F}rame{N}et: Methodology and First results,2014,23,6,1,1,16504,marie candito,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Asfalda project aims to develop a French corpus with frame-based semantic annotations and automatic tools for shallow semantic analysis. We present the first part of the project: focusing on a set of notional domains, we delimited a subset of English frames, adapted them to French data when necessary, and developed the corresponding French lexicon. We believe that working domain by domain helped us to enforce the coherence of the resulting resource, and also has the advantage that, though the number of frames is limited (around a hundred), we obtain full coverage within a given domain."
F14-2031,Annotation scheme for deep dependency syntax of {F}rench (Un sch{\\'e}ma d{'}annotation en d{\\'e}pendances syntaxiques profondes pour le fran{\\c{c}}ais) [in {F}rench],2014,0,0,2,0,5832,guy perrier,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
W13-4905,The {LIGM}-{A}lpage architecture for the {SPMRL} 2013 Shared Task: Multiword Expression Analysis and Dependency Parsing,2013,20,8,2,0,23668,matthieu constant,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper describes the LIGM-Alpage system for the SPMRL 2013 Shared Task. We only participated to the French part of the dependency parsing track, focusing on the realistic setting where the system is informed neither with gold tagging and morphology nor (more importantly) with gold grouping of tokens into multi-word expressions (MWEs). While the realistic scenario of predicting both MWEs and syntax has already been investigated for constituency parsing, the SPMRL 2013 shared task datasets offer the possibility to investigate it in the dependency framework. We obtain the best results for French, both for overall parsing and for MWE recognition, using a reparsing architecture that combines several parsers, with both pipeline architecture (MWE recognition followed by parsing), and joint architecture (MWE recognition performed by the parser)."
W13-4917,Overview of the {SPMRL} 2013 Shared Task: A Cross-Framework Evaluation of Parsing Morphologically Rich Languages,2013,110,38,4,0.51282,167,djame seddah,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper reports on the first shared task on statistical parsing of morphologically rich languages (MRLs). The task features data sets from nine languages, each available both in constituency and dependency annotation. We report on the preparation of the data sets, on the proposed parsing scenarios, and on the evaluation metrics for parsing MRLs given different representation types. We present and analyze parsing results obtained by the task participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios."
W12-3401,Probabilistic Lexical Generalization for {F}rench Dependency Parsing,2012,30,5,2,0.952381,42227,enrique anguiano,Proceedings of the {ACL} 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,0,"This paper investigates the impact on French dependency parsing of lexical generalization methods beyond lemmatization and morphological analysis. A distributional thesaurus is created from a large text corpus and used for distributional clustering and WordNet automatic sense ranking. The standard approach for lexical generalization in parsing is to map a word to a single generalized class, either replacing the word with the class or adding a new feature for the class. We use a richer framework that allows for probabilistic generalization, with a word represented as a probability distribution over a space of generalized classes: lemmas, clusters, or synsets. Probabilistic lexical information is introduced into parser feature vectors by modifying the weights of lexical features. We obtain improvements in parsing accuracy with some lexical generalization configurations in experiments run on the French Treebank and two out-of-domain treebanks, with slightly better performance for the probabilistic lexical generalization approach compared to the standard single-mapping approach."
seddah-etal-2012-ubiquitous,Ubiquitous Usage of a Broad Coverage {F}rench Corpus: Processing the {E}st {R}epublicain corpus,2012,0,1,2,0.55434,167,djame seddah,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we introduce a set of resources that we have derived from the EST R{\'E}PUBLICAIN CORPUS, a large, freely-available collection of regional newspaper articles in French, totaling 150 million words. Our resources are the result of a full NLP treatment of the EST R{\'E}PUBLICAIN CORPUS: handling of multi-word expressions, lemmatization, part-of-speech tagging, and syntactic parsing. Processing of the corpus is carried out using statistical machine-learning approaches - joint model of data driven lemmatization and part- of-speech tagging, PCFG-LA and dependency based models for parsing - that have been shown to achieve state-of-the-art performance when evaluated on the French Treebank. Our derived resources are made freely available, and released according to the original Creative Common license for the EST R{\'E}PUBLICAIN CORPUS. We additionally provide an overview of the use of these resources in various applications, in particular the use of generated word clusters from the corpus to alleviate lexical data sparseness for statistical parsing."
F12-2024,Le corpus Sequoia : annotation syntaxique et exploitation pour l{'}adaptation d{'}analyseur par pont lexical (The Sequoia Corpus : Syntactic Annotation and Use for a Parser Lexical Domain Adaptation Method) [in {F}rench],2012,0,3,1,1,16504,marie candito,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
C12-1149,The {F}rench {S}ocial {M}edia {B}ank: a Treebank of Noisy User Generated Content,2012,34,19,3,0.55434,167,djame seddah,Proceedings of {COLING} 2012,0,"In recent years, statistical parsers have reached high performance levels on well-edited texts. Domain adaptation techniques have improved parsing results on text genres differing from the journalistic data most parsers are trained on. However, such corpora usually comply with standard linguistic, spelling and typographic conventions. In the meantime, the emergence of Web 2.0 communication media has caused the apparition of new types of online textual data. Although valuable, e.g., in terms of data mining and sentiment analysis, such user-generated content rarely complies with standard conventions: they are noisy. This prevents most NLP tools, especially treebank based parsers, from performing well on such data. For this reason, we have developed the French Social Media Bank, the first user-generated content treebank for French, a morphologically rich language (MRL). The first release of this resource contains 1,700 sentences from various Web 2.0 sources, including data specifically chosen for their high noisiness. We describe here how we created this treebank and expose the methodology we used for fully annotating it. We also provide baseline POS tagging and statistical constituency parsing results, which are lower by far than usual results on edited texts. This highlights the high difficulty of automatically processing such noisy data in a MRL."
W11-2905,A Word Clustering Approach to Domain Adaptation: Effective Parsing of Biomedical Texts,2011,22,20,1,1,16504,marie candito,Proceedings of the 12th International Conference on Parsing Technologies,0,"We present a simple and effective way to perform out-of-domain statistical parsing by drastically reducing lexical data sparseness in a PCFG-LA architecture. We replace terminal symbols with unsupervised word clusters acquired from a large newspaper corpus augmented with biomedical targetdomain data. The resulting clusters are effective in bridging the lexical gap between source-domain and target-domain vocabularies. Our experiments combine known self-training techniques with unsupervised word clustering and produce promising results, achieving an error reduction of 21% on a new evaluation set for biomedical text with manual bracketing annotations."
D11-1113,Parse Correction with Specialized Models for Difficult Attachment Types,2011,33,9,2,0.952381,42227,enrique anguiano,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"This paper develops a framework for syntactic dependency parse correction. Dependencies in an input parse tree are revised by selecting, for a given dependent, the best governor from within a small set of candidates. We use a discriminative linear ranking model to select the best governor from a group of candidates for a dependent, and our model includes a rich feature set that encodes syntactic structure in the input parse tree. The parse correction framework is parser-agnostic, and can correct attachments using either a generic model or specialized models tailored to difficult attachment types like coordination and pp-attachment. Our experiments show that parse correction, combining a generic model with specialized models for difficult attachment types, can successfully improve the quality of predicted parse trees output by several representative state-of-the-art dependency parsers for French."
W10-1401,"Statistical Parsing of Morphologically Rich Languages ({SPMRL}) What, How and Whither",2010,60,61,6,0.273954,5249,reut tsarfaty,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"The term Morphologically Rich Languages (MRLs) refers to languages in which significant information concerning syntactic units and relations is expressed at word-level. There is ample evidence that the application of readily available statistical parsing models to such languages is susceptible to serious performance degradation. The first workshop on statistical parsing of MRLs hosts a variety of contributions which show that despite language-specific idiosyncrasies, the problems associated with parsing MRLs cut across languages and parsing frameworks. In this paper we review the current state-of-affairs with respect to parsing MRLs and point out central challenges. We synthesize the contributions of researchers working on parsing Arabic, Basque, French, German, Hebrew, Hindi and Korean to point out shared solutions across languages. The overarching analysis suggests itself as a source of directions for future investigations."
W10-1409,Parsing Word Clusters,2010,22,37,1,1,16504,marie candito,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"We present and discuss experiments in statistical parsing of French, where terminal forms used during training and parsing are replaced by more general symbols, particularly clusters of words obtained through un-supervised linear clustering. We build on the work of Candito and Crabbe (2009) who proposed to use clusters built over slightly coarsened French inflected forms. We investigate the alternative method of building clusters over lemma/part-of-speech pairs, using a raw corpus automatically tagged and lemmatized. We find that both methods lead to comparable improvement over the baseline (we obtain F1=86.20% and F1=86.21% respectively, compared to a baseline of F1=84.10%). Yet, when we replace gold lemma/POS pairs with their corresponding cluster, we obtain an upper bound (F1=87.80) that suggests room for improvement for this technique, should tag-ging/lemmatisation performance increase for French.n n We also analyze the improvement in performance for both techniques with respect to word frequency. We find that replacing word forms with clusters improves attachment performance for words that are originally either unknown or low-frequency, since these words are replaced by cluster symbols that tend to have higher frequencies. Furthermore, clustering also helps significantly for medium to high frequency words, suggesting that training on word clusters leads to better probability estimates for these words."
W10-1410,Lemmatization and Lexicalized Statistical Parsing of Morphologically-Rich Languages: the Case of {F}rench,2010,22,15,5,0.666406,167,djame seddah,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper shows that training a lexicalized parser on a lemmatized morphologically-rich treebank such as the French Treebank slightly improves parsing results. We also show that lemmatizing a similar in size subset of the English Penn Treebank has almost no effect on parsing performance with gold lemmas and leads to a small drop of performance when automatically assigned lemmas and POS tags are used. This highlights two facts: (i) lemmatization helps to reduce lexicon data-sparseness issues for French, (ii) it also makes the parsing process sensitive to correct assignment of POS tags to unknown words."
candito-etal-2010-statistical,Statistical {F}rench Dependency Parsing: Treebank Conversion and First Results,2010,23,85,1,1,16504,marie candito,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We first describe the automatic conversion of the French Treebank (Abeill{\'e} and Barrier, 2004), a constituency treebank, into typed projective dependency trees. In order to evaluate the overall quality of the resulting dependency treebank, and to quantify the cases where the projectivity constraint leads to wrong dependencies, we compare a subset of the converted treebank to manually validated dependency trees. We then compare the performance of two treebank-trained parsers that output typed dependency parses. The first parser is the MST parser (Mcdonald et al., 2006), which we directly train on dependency trees. The second parser is a combination of the Berkeley parser (Petrov et al., 2006) and a functional role labeler: trained on the original constituency treebank, the Berkeley parser first outputs constituency trees, which are then labeled with functional roles, and then converted into dependency trees. We found that used in combination with a high-accuracy French POS tagger, the MST parser performs a little better for unlabeled dependencies (UAS=90.3{\%} versus 89.6{\%}), and better for labeled dependencies (LAS=87.6{\%} versus 85.6{\%})."
C10-2013,Benchmarking of Statistical Dependency Parsers for {F}rench,2010,41,59,1,1,16504,marie candito,Coling 2010: Posters,0,"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French. The architectures are based on PCFGs with latent variables, graph-based dependency parsing and transition-based dependency parsing, respectively. We also study the influence of three types of lexical information: lemmas, morphological features, and word clusters. The results show that all three systems achieve competitive performance, with a best labeled attachment score over 88%. All three parsers benefit from the use of automatically derived lemmas, while morphological features seem to be less important. Word clusters have a positive effect primarily on the latent variable parser."
W09-3821,Improving generative statistical parsing with semi-supervised word clustering,2009,12,68,1,1,16504,marie candito,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We present a semi-supervised method to improve statistical parsing performance. We focus on the well-known problem of lexical data sparseness and present experiments of word clustering prior to parsing. We use a combination of lexicon-aided morphological clustering that preserves tagging ambiguity, and unsupervised word clustering, trained on a large unannotated corpus. We apply these clusterings to the French Treebank, and we train a parser with the PCFG-LA unlexicalized algorithm of (Petrov et al., 2006). We find a gain in French parsing performance: from a baseline of F1=86.76% to F1=87.37% using morphological clustering, and up to F1=88.29% using further unsupervised clustering. This is the best known score for French probabilistic parsing. These preliminary results are encouraging for statistically parsing morphologically rich languages, and languages with small amount of annotated data."
W09-3824,Cross parser evaluation : a {F}rench Treebanks study,2009,13,8,2,0.666406,167,djame seddah,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,None
W09-1008,On Statistical Parsing of {F}rench with Supervised and Semi-Supervised Strategies,2009,19,19,1,1,16504,marie candito,Proceedings of the {EACL} 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference,0,"This paper reports results on grammatical induction for French. We investigate how to best train a parser on the French Treebank (Abeille et al., 2003), viewing the task as a trade-off between generaliz-ability and interpretability. We compare, for French, a supervised lexicalized parsing algorithm with a semi-supervised un-lexicalized algorithm (Petrov et al., 2006) along the lines of (Crabbe and Candito, 2008). We report the best results known to us on French statistical parsing, that we obtained with the semi-supervised learning algorithm. The reported experiments can give insights for the task of grammatical learning for a morphologically-rich language, with a relatively limited amount of training data, annotated with a rather flat structure."
2009.jeptalnrecital-long.4,Analyse syntaxique du fran{\\c{c}}ais : des constituants aux d{\\'e}pendances,2009,-1,-1,1,1,16504,marie candito,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente une technique d{'}analyse syntaxique statistique {\`a} la fois en constituants et en d{\'e}pendances. L{'}analyse proc{\`e}de en ajoutant des {\'e}tiquettes fonctionnelles aux sorties d{'}un analyseur en constituants, entra{\^\i}n{\'e} sur le French Treebank, pour permettre l{'}extraction de d{\'e}pendances typ{\'e}es. D{'}une part, nous sp{\'e}cifions d{'}un point de vue formel et linguistique les structures de d{\'e}pendances {\`a} produire, ainsi que la proc{\'e}dure de conversion du corpus en constituants (le French Treebank) vers un corpus cible annot{\'e} en d{\'e}pendances, et partiellement valid{\'e}. D{'}autre part, nous d{\'e}crivons l{'}approche algorithmique qui permet de r{\'e}aliser automatiquement le typage des d{\'e}pendances. En particulier, nous nous focalisons sur les m{\'e}thodes d{'}apprentissage discriminantes d{'}{\'e}tiquetage en fonctions grammaticales."
2009.jeptalnrecital-court.1,Adaptation de parsers statistiques lexicalis{\\'e}s pour le fran{\\c{c}}ais : Une {\\'e}valuation compl{\\`e}te sur corpus arbor{\\'e}s,2009,-1,-1,2,0.666406,167,djame seddah,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Cet article pr{\'e}sente les r{\'e}sultats d{'}une {\'e}valuation exhaustive des principaux analyseurs syntaxiques probabilistes dit {``}lexicalis{\'e}s{''} initialement con{\c{c}}us pour l{'}anglais, adapt{\'e}s pour le fran{\c{c}}ais et {\'e}valu{\'e}s sur le CORPUS ARBOR{\'E} DU FRAN{\c{C}}AIS (Abeill{\'e} et al., 2003) et le MODIFIED FRENCH TREEBANK (Schluter {\&} van Genabith, 2007). Confirmant les r{\'e}sultats de (Crabb{\'e} {\&} Candito, 2008), nous montrons que les mod{\`e}les lexicalis{\'e}s, {\`a} travers les mod{\`e}les de Charniak (Charniak, 2000), ceux de Collins (Collins, 1999) et le mod{\`e}le des TIG Stochastiques (Chiang, 2000), pr{\'e}sentent des performances moindres face {\`a} un analyseur PCFG {\`a} Annotation Latente (Petrov et al., 2006). De plus, nous montrons que le choix d{'}un jeu d{'}annotations issus de tel ou tel treebank oriente fortement les r{\'e}sultats d{'}{\'e}valuations tant en constituance qu{'}en d{\'e}pendance non typ{\'e}e. Compar{\'e}s {\`a} (Schluter {\&} van Genabith, 2008; Arun {\&} Keller, 2005), tous nos r{\'e}sultats sont state-of-the-art et infirment l{'}hypoth{\`e}se d{'}une difficult{\'e} particuli{\`e}re qu{'}aurait le fran{\c{c}}ais en terme d{'}analyse syntaxique probabiliste et de sources de donn{\'e}es."
2008.jeptalnrecital-long.17,Exp{\\'e}riences d{'}analyse syntaxique statistique du fran{\\c{c}}ais,2008,-1,-1,2,0,5601,benoit crabbe,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous montrons qu{'}il est possible d{'}obtenir une analyse syntaxique statistique satisfaisante pour le fran{\c{c}}ais sur du corpus journalistique, {\`a} partir des donn{\'e}es issues du French Treebank du laboratoire LLF, {\`a} l{'}aide d{'}un algorithme d{'}analyse non lexicalis{\'e}."
