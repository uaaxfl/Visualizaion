2007.jeptalnrecital-poster.6,P97-1023,0,0.0380874,"Missing"
2007.jeptalnrecital-poster.6,H05-1043,0,0.100577,"Missing"
2007.jeptalnrecital-poster.6,W03-1014,0,0.0815478,"Missing"
2008.jeptalnrecital-long.13,P06-2005,0,0.138809,"Missing"
2008.jeptalnrecital-long.13,J94-3001,0,0.124636,"Missing"
2008.jeptalnrecital-long.13,N03-1017,0,0.00990468,"Missing"
2008.jeptalnrecital-long.13,P96-1031,0,0.435683,"Missing"
2008.jeptalnrecital-long.13,J03-1002,0,0.00433238,"Missing"
2008.jeptalnrecital-long.13,P02-1040,0,0.0741734,"Missing"
2015.jeptalnrecital-court.26,bechet-etal-2012-decoda,0,0.0275817,"Missing"
2015.jeptalnrecital-court.26,D13-1035,0,0.0394255,"Missing"
2015.jeptalnrecital-court.26,garnier-rizet-etal-2008-callsurf,0,0.0612481,"Missing"
2015.jeptalnrecital-court.33,A00-2004,0,0.172421,"Missing"
2015.jeptalnrecital-court.33,W02-0908,0,0.0427818,"Missing"
2015.jeptalnrecital-court.33,J97-1003,0,0.648522,"Missing"
2015.jeptalnrecital-court.33,P11-1154,0,0.057336,"Missing"
2015.jeptalnrecital-court.33,P06-1004,0,0.0855874,"Missing"
2015.jeptalnrecital-court.33,J02-1002,0,0.115371,"Missing"
2017.jeptalnrecital-court.16,S16-1081,0,0.0683389,"Missing"
2017.jeptalnrecital-court.16,S17-2051,1,0.600812,"Missing"
2017.jeptalnrecital-court.16,S16-1126,0,0.0620442,"Missing"
2017.jeptalnrecital-court.16,S16-1136,0,0.0306689,"Missing"
2017.jeptalnrecital-court.6,P98-1013,0,0.0815769,"Missing"
2017.jeptalnrecital-court.6,J14-1002,0,0.042123,"Missing"
2017.jeptalnrecital-court.6,L16-1601,0,0.0200449,"Missing"
2017.jeptalnrecital-court.6,johansson-etal-2012-semantic,0,0.0517494,"Missing"
2017.jeptalnrecital-court.6,C16-1040,0,0.0213593,"Missing"
2018.jeptalnrecital-court.23,L16-1319,1,0.890242,"Missing"
2018.jeptalnrecital-court.23,H92-1003,0,0.312653,"Missing"
2018.jeptalnrecital-court.23,P17-1103,0,0.0359151,"Missing"
2018.jeptalnrecital-court.23,D14-1162,0,0.0812105,"Missing"
2018.jeptalnrecital-court.4,hara-etal-2010-estimation,0,0.0818392,"Missing"
2018.jeptalnrecital-court.4,D14-1181,0,0.00513954,"Missing"
2018.jeptalnrecital-court.4,N13-1064,0,0.0306075,"Missing"
2019.jeptalnrecital-court.4,P98-1013,0,0.0571271,"Missing"
2019.jeptalnrecital-court.4,S17-2051,1,0.890372,"Missing"
2019.jeptalnrecital-court.4,W18-0530,0,0.0380174,"Missing"
2019.jeptalnrecital-court.4,P14-2053,0,0.0606828,"Missing"
2019.jeptalnrecital-court.4,D16-1264,0,0.11831,"Missing"
2019.jeptalnrecital-court.4,D17-1090,0,0.029907,"Missing"
2019.jeptalnrecital-court.4,W17-2603,0,0.0497315,"Missing"
2020.jeptalnrecital-taln.28,D19-5803,1,0.892204,"Missing"
2020.jeptalnrecital-taln.28,N19-1423,0,0.0470817,"Missing"
2020.jeptalnrecital-taln.28,fillmore-etal-2004-framenet,0,0.070679,"Missing"
2020.jeptalnrecital-taln.28,P17-1044,0,0.0497604,"Missing"
2020.jeptalnrecital-taln.28,L18-1159,1,0.891341,"Missing"
2020.jeptalnrecital-taln.28,N18-1202,0,0.076873,"Missing"
2020.jeptalnrecital-taln.28,D16-1264,0,0.115656,"Missing"
2020.jeptalnrecital-taln.28,D07-1002,0,0.161947,"Missing"
2020.jeptalnrecital-taln.28,K17-3009,0,0.0558784,"Missing"
2020.lrec-1.529,auer-etal-2010-elan,0,0.0931201,"Missing"
2020.lrec-1.529,bazillon-etal-2008-manual,1,0.695665,"iption (Section 3.1.), thematic segmentation (Section 3.2.), and in-domain words annotation (Section 3.3.), established for annotating the PASTEL corpus. 3.1. Manual transcription This manual transcription was carried out in two passes. The first pass consists in automatically transcribing the course through a generic speech recognition system (i.e. not adapted to the targeted courses). The human expert intervenes during the second pass to manually correct the errors made by the automatic transcription. This two-step approach proved to be a faster way than a manual from scratch transcription (Bazillon et al., 2008). The conventions used for the evaluation of transcription campaigns (Gravier et al., 2004) served as a guide for manually transcribing registered lectures. The speech recognition system is based on the Kaldi toolkit (Povey et al., 2011). Acoustic models were trained on about 300 hours of speech from French broadcast news with manual transcriptions, and are based on a chain-TDNN approach (Povey et al., 2016). The generic n-gram language models were trained on these manual transcriptions of speech, but also on newspaper articles, for a total of 1.6 billions of words. The vocabulary of the gener"
2020.lrec-1.529,gravier-etal-2004-ester,0,0.126641,"(Section 3.3.), established for annotating the PASTEL corpus. 3.1. Manual transcription This manual transcription was carried out in two passes. The first pass consists in automatically transcribing the course through a generic speech recognition system (i.e. not adapted to the targeted courses). The human expert intervenes during the second pass to manually correct the errors made by the automatic transcription. This two-step approach proved to be a faster way than a manual from scratch transcription (Bazillon et al., 2008). The conventions used for the evaluation of transcription campaigns (Gravier et al., 2004) served as a guide for manually transcribing registered lectures. The speech recognition system is based on the Kaldi toolkit (Povey et al., 2011). Acoustic models were trained on about 300 hours of speech from French broadcast news with manual transcriptions, and are based on a chain-TDNN approach (Povey et al., 2016). The generic n-gram language models were trained on these manual transcriptions of speech, but also on newspaper articles, for a total of 1.6 billions of words. The vocabulary of the generic language model contains around 160k words. More details about language models can be fou"
2020.lrec-1.529,J97-1003,0,0.803763,"dvances in ASR allow us to imagine new applications for enhancing learning. Lectures can automatically be transcribed in text which, in turn, can be used by learners to read the courses. But, unlike handouts or any written educational resources, transcribed lecture audio can be tedious to browse, making it difficult for learners to retrieve relevant information in the absence of structural information such as topic boundaries. We present in this section our work on the thematic segmentation of oral lectures. Our thematic segmentation baseline system consists in using the TextTiling algorithm (Hearst, 1997) which is based on analysis of lexical distribution between adjacent blocs. The main reasons of choosing TextTiling is related to its simplicity and that it is an unsupervised algorithm that does not require training data (note that our corpus only contains 388 segments). In TextTiling, a block is constituted of k sentences, while a sentence is constituted of w words. Similarity is computed using a sliding window between adjacent blocks. The similarity values allow us to draw a lexical cohesion curve. Topic boundaries are detected based on the valley depth of the lexical cohesion curve. Otherw"
2020.lrec-1.529,P11-4015,0,0.0181479,"Missing"
2020.lrec-1.529,trancoso-etal-2008-lectra,0,0.0544874,"scientific fields from both speech and text processing, with language model adaptation, thematic segmentation and transcription to slide alignment. Keywords: Multimodal corpus, Educational context, Thematic segmentation, Alignment, Language model adaptation 1. Introduction With the increasing number of applications handling spontaneous speech, lecture processing has becoming an active field of research. In this particular educational context, a large number of projects have been developed, coming with different datasets. Among them, we can first quote the LECTRA corpus (Trancoso et al., 2006; Trancoso et al., 2008) dealing with classroom lectures in European Portuguese. This corpus provides the audio of lectures and their manual transcription. In addition to the oral modality, the “Spontaneous Speech Corpus and Processing Technology”(Furui et al., 2000; Furui et al., 2001) and the CHIL projects (Lamel et al., 2005) include, in addition to the audio and the transcription, the video recording of lectures. Finally, the LMELectures corpus (Riedhammer et al., 2013) is the most complete one with various modalities (audio, video and text), including the annotation of speech transcription, a segmentation in spe"
2020.lrec-1.674,D19-5803,1,0.856783,"Missing"
2020.lrec-1.674,D19-1169,0,0.0192657,"thods, is the alignment between the source and target language when generating a text span answering a given question, as described in (Cui 5491 et al., 2019). To overcome this problem several studies have proposed to take advantage of multilingual training of word representation in order to capture cross-lingual lexical representations. When training a machine reading model on a large source language corpus, and a much smaller target language corpus, this cross-lingual space allows the target model to benefit from the large source language training examples. Such approaches were proposed in (Cui et al., 2019; Kumar et al., 2019; Lee and Lee, 2019). Another line of research consists in considering only multilingual lexical representations in a zero-shot cross-lingual setting where a machine reading model trained exclusively on a source language is applied to a target language for which no task-related data is available, an approach studied in (Siblini et al., 2019) and (Artetxe et al., 2019). In this study we will investigate this zero-shot cross-lingual paradigm by applying a BERT multilingual model finetuned for an MRC task on a source language to an evaluation dataset on a target language. More"
2020.lrec-1.674,W18-2605,0,0.0186037,"estion-Answering where questions are not generic in scope but are related to a particular document. Recently very large corpora (SQuAD (Rajpurkar et al., 2016), MS MARCO (Nguyen et al., 2016)) containing triplets (document, question, answer) were made available to the scientific community allowing to develop supervised methods based on deep neural networks with promising results. These methods need very large training corpora to be efficient, however such kind of data only exists for English at the moment. Developing such resources for a new language requires a lot of effort, as presented in (He et al., 2018) for Chinese. Many methods have been proposed to help reducing this cost based on an automatic translation process between MRC resources in English and the target language (Asai et al., 2018; Lee and Lee, 2019). In addition to methods performing a full translation of English corpora into a target language, methods have been proposed to directly perform online translation with a multilingual alignment process (Asai et al., 2018). One of the key issues with translation based methods, is the alignment between the source and target language when generating a text span answering a given question, a"
2020.lrec-1.674,P19-1481,0,0.0119573,"nment between the source and target language when generating a text span answering a given question, as described in (Cui 5491 et al., 2019). To overcome this problem several studies have proposed to take advantage of multilingual training of word representation in order to capture cross-lingual lexical representations. When training a machine reading model on a large source language corpus, and a much smaller target language corpus, this cross-lingual space allows the target model to benefit from the large source language training examples. Such approaches were proposed in (Cui et al., 2019; Kumar et al., 2019; Lee and Lee, 2019). Another line of research consists in considering only multilingual lexical representations in a zero-shot cross-lingual setting where a machine reading model trained exclusively on a source language is applied to a target language for which no task-related data is available, an approach studied in (Siblini et al., 2019) and (Artetxe et al., 2019). In this study we will investigate this zero-shot cross-lingual paradigm by applying a BERT multilingual model finetuned for an MRC task on a source language to an evaluation dataset on a target language. Moreover, we will compar"
2020.lrec-1.674,L18-1159,1,0.826003,"nswer, paragraph-question pairs over 48 articles. Thanks to the paragraph and question identifiers, we generated the same subset from the original English SQUAD corpus, allowing comparisons to be drawn from the same subset in two different languages. 3.2. CALOR-QUEST a machine reading corpus with semantic annotations 3.2.1. Dataset collection One of the contributions of this work is to use a new French MRC corpus called C ALOR -Q UEST , developed from a corpus of encyclopedic documents annotated with semantic information (C ALOR -F RAME ) following the Berkeley Framenet paradigm described in (Marzinotto et al., 2018). The C ALOR -F RAME corpus was initially built in order to alleviate Semantic Frame detection for the French language with two main purposes. The first one was to have a large amount of annotated examples for each Frame with all their possible frame Elements, with the deliberate choice to annotate only the most frequent Frames. As a result, the corpus contains 53 different Frames but around 26k occurrences of them along with around 57k Frame Element occurrences. The second purpose was to study the impact of domain change and style change. To this end the corpus was built by gathering encyclop"
2020.lrec-1.674,D16-1264,0,0.110361,"Missing"
2021.wnut-1.27,D08-1014,0,0.0837202,"erall polarity of a sen- proaches are complementary : MT can be used tence by assigning it a polarity label (Pang and Lee, to generate synthetic data in languages for which 2008). no annotated data is available. Accordingly, MT Aspect-based sentiment analysis (ABSA) (Hu can improve cross-lingual transfer in two ways : and Liu, 2004; Popescu and Etzioni, 2005; Pontiki (i) By translating the training data into the target et al., 2014, 2015, 2016) is a more fine-grained languages and fine-tuning on all languages, e.g. opinion mining task with several sub-tasks associa- for subjectivity analysis (Banea et al., 2008), sentited with it. For example, opinion target extraction ment classification (Duh et al., 2011) or semantic (OTE) retrieves the entity on which an opinion is role labeling (Fei et al., 2020). (ii) Or by applying expressed in a review, and aspect sentiment classi- a model fine-tuned on the source language to a fication (ASC) identifies the polarity of an opinion test set translated from target to source language. expressed on a given target entity. Some works fo- (Conneau et al., 2020) refers to the former approach cus on one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to"
2021.wnut-1.27,2020.emnlp-main.42,0,0.0178535,"he word level for sequence tagging. This requires an important additional step of annotation projection as no word-to-word correspondence is available. One approach to annotation projection for sequence tagging tasks relies on obtaining word alignments to project labels from source to target utterances. Several statistical word alignment tools are available such as fast_align (Dyer et al., 2013) which constitutes the usual baseline for this approach. Starting from the assumption that neural machine translation (NMT) models capture word alignment through their attention mechanism, other works (Chen et al., 2020; Zouhar and Pylypenko, 2021) focus on using attention weights for word alignment. In an attempt to alleviate the need for parallel corpora, (Jalili Sabet et al., 2020) leveraged modern multilingual pre-trained models and released SimAlign, a tool for unsupervised word alignment based on the similarity of multilingual word representations. In order to project sequence annotations, one has to leverage word-level alignment towards span alignment. Marzinotto (2020) used attention-based word alignments to project FrameNet annotations (targets and Frame Elements) into a target language. Others have"
2021.wnut-1.27,2020.acl-main.747,0,0.15467,"aptation yields superior performance comguages such as multilingual BERT (mBERT) and pared to zero-shot cross-lingual transfer, provided XLM-R provide an alternative. They have been the right annotation projection method is used. shown to yield on par, if not better performance on various tasks compared to monolingual models We propose to apply this method in the context and perform particularly well for low-resource lan- of opinion mining, and specifically to aspect-based guages provided similar languages are represented sentiment analysis (ABSA) (Pontiki et al., 2014). in the training data (Conneau et al., 2020). What’s Nowadays, people increasingly rely on reviews and more, they have shown surprising capacities for ge- comments, e.g. on social media and review webneralization with zero-shot cross-lingual transfer, in sites, to select which products to buy or which serwhich a model is fine-tuned for a task using annota- vices to use. Companies can also make use of these 238 Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 238–248 November 11, 2021. ©2021 Association for Computational Linguistics data which provide insightful feedback from their cu"
2021.wnut-1.27,D18-1269,0,0.0205247,"one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we focus on the former approach. (OWE) (Fan et al., 2019; Pouran Ben Veyseh et al., This approach naturally applies to sentence classi2020). But this division of subtasks is ill-suited fication tasks and previous work has shown that for real-world scenarios as both ASC and OWE translation-based adaptation is superior to zero239 shot cross-lingual transfer for text classification (Schwenk and Li, 2018) and text pair classification (Conneau et al., 2018; Yang et al., 2019). However, little work focuses on adapting datasets annotated at the word level for sequence tagging. This requires an important additional step of annotation projection as no word-to-word correspondence is available. One approach to annotation projection for sequence tagging tasks relies on obtaining word alignments to project labels from source to target utterances. Several statistical word alignment tools are available such as fast_align (Dyer et al., 2013) which constitutes the usual baseline for this approach. Starting from the assumption that neural machine translatio"
2021.wnut-1.27,P11-2075,0,0.0325625,"ty label (Pang and Lee, to generate synthetic data in languages for which 2008). no annotated data is available. Accordingly, MT Aspect-based sentiment analysis (ABSA) (Hu can improve cross-lingual transfer in two ways : and Liu, 2004; Popescu and Etzioni, 2005; Pontiki (i) By translating the training data into the target et al., 2014, 2015, 2016) is a more fine-grained languages and fine-tuning on all languages, e.g. opinion mining task with several sub-tasks associa- for subjectivity analysis (Banea et al., 2008), sentited with it. For example, opinion target extraction ment classification (Duh et al., 2011) or semantic (OTE) retrieves the entity on which an opinion is role labeling (Fei et al., 2020). (ii) Or by applying expressed in a review, and aspect sentiment classi- a model fine-tuned on the source language to a fication (ASC) identifies the polarity of an opinion test set translated from target to source language. expressed on a given target entity. Some works fo- (Conneau et al., 2020) refers to the former approach cus on one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we"
2021.wnut-1.27,N13-1073,0,0.189354,"zero239 shot cross-lingual transfer for text classification (Schwenk and Li, 2018) and text pair classification (Conneau et al., 2018; Yang et al., 2019). However, little work focuses on adapting datasets annotated at the word level for sequence tagging. This requires an important additional step of annotation projection as no word-to-word correspondence is available. One approach to annotation projection for sequence tagging tasks relies on obtaining word alignments to project labels from source to target utterances. Several statistical word alignment tools are available such as fast_align (Dyer et al., 2013) which constitutes the usual baseline for this approach. Starting from the assumption that neural machine translation (NMT) models capture word alignment through their attention mechanism, other works (Chen et al., 2020; Zouhar and Pylypenko, 2021) focus on using attention weights for word alignment. In an attempt to alleviate the need for parallel corpora, (Jalili Sabet et al., 2020) leveraged modern multilingual pre-trained models and released SimAlign, a tool for unsupervised word alignment based on the similarity of multilingual word representations. In order to project sequence annotation"
2021.wnut-1.27,N19-1259,0,0.0136468,"ty on which an opinion is role labeling (Fei et al., 2020). (ii) Or by applying expressed in a review, and aspect sentiment classi- a model fine-tuned on the source language to a fication (ASC) identifies the polarity of an opinion test set translated from target to source language. expressed on a given target entity. Some works fo- (Conneau et al., 2020) refers to the former approach cus on one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we focus on the former approach. (OWE) (Fan et al., 2019; Pouran Ben Veyseh et al., This approach naturally applies to sentence classi2020). But this division of subtasks is ill-suited fication tasks and previous work has shown that for real-world scenarios as both ASC and OWE translation-based adaptation is superior to zero239 shot cross-lingual transfer for text classification (Schwenk and Li, 2018) and text pair classification (Conneau et al., 2018; Yang et al., 2019). However, little work focuses on adapting datasets annotated at the word level for sequence tagging. This requires an important additional step of annotation projection as no word-"
2021.wnut-1.27,2020.acl-main.627,0,0.0190282,"ata is available. Accordingly, MT Aspect-based sentiment analysis (ABSA) (Hu can improve cross-lingual transfer in two ways : and Liu, 2004; Popescu and Etzioni, 2005; Pontiki (i) By translating the training data into the target et al., 2014, 2015, 2016) is a more fine-grained languages and fine-tuning on all languages, e.g. opinion mining task with several sub-tasks associa- for subjectivity analysis (Banea et al., 2008), sentited with it. For example, opinion target extraction ment classification (Duh et al., 2011) or semantic (OTE) retrieves the entity on which an opinion is role labeling (Fei et al., 2020). (ii) Or by applying expressed in a review, and aspect sentiment classi- a model fine-tuned on the source language to a fication (ASC) identifies the polarity of an opinion test set translated from target to source language. expressed on a given target entity. Some works fo- (Conneau et al., 2020) refers to the former approach cus on one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we focus on the former approach. (OWE) (Fan et al., 2019; Pouran Ben Veyseh et al., This approach"
2021.wnut-1.27,D19-1100,0,0.0186851,"word alignment. In an attempt to alleviate the need for parallel corpora, (Jalili Sabet et al., 2020) leveraged modern multilingual pre-trained models and released SimAlign, a tool for unsupervised word alignment based on the similarity of multilingual word representations. In order to project sequence annotations, one has to leverage word-level alignment towards span alignment. Marzinotto (2020) used attention-based word alignments to project FrameNet annotations (targets and Frame Elements) into a target language. Others have sought to improve label projection through different approaches. Jain et al. (2019) proposed an entity projection method for named entity recognition, in which they obtain potential translations of an entity in the target language and select the best match with the source entity. To make use of task-related information, Xu et al. (2020) proposed an end-to-end model to jointly align and predict target slot labels for cross-lingual NLU. (Li et al., 2020) propose an approach called span-tospan mapping which derives span alignment from word alignments. They applied it to several tasks (Opinion Mining, Semantic Role Labeling, Named Entities) but didn’t obtain satisfactory results"
2021.wnut-1.27,2020.findings-emnlp.147,0,0.119903,"o annotation projection for sequence tagging tasks relies on obtaining word alignments to project labels from source to target utterances. Several statistical word alignment tools are available such as fast_align (Dyer et al., 2013) which constitutes the usual baseline for this approach. Starting from the assumption that neural machine translation (NMT) models capture word alignment through their attention mechanism, other works (Chen et al., 2020; Zouhar and Pylypenko, 2021) focus on using attention weights for word alignment. In an attempt to alleviate the need for parallel corpora, (Jalili Sabet et al., 2020) leveraged modern multilingual pre-trained models and released SimAlign, a tool for unsupervised word alignment based on the similarity of multilingual word representations. In order to project sequence annotations, one has to leverage word-level alignment towards span alignment. Marzinotto (2020) used attention-based word alignments to project FrameNet annotations (targets and Frame Elements) into a target language. Others have sought to improve label projection through different approaches. Jain et al. (2019) proposed an entity projection method for named entity recognition, in which they ob"
2021.wnut-1.27,N19-1257,0,0.0227179,"orks address OTE and ASC simultaneously (Li et al., 2019a,b). The problem can be formulated as a sequence tagging task with unified labels to simultaneously detect opinion targets and the corresponding aspect sentiments. Some works went even further by addressing OTE, ASC, and OWE simultaneously, a task dubbed as aspect sentiment triplet extraction (Peng et al., 2020; Wang et al., 2021). Most works in the state of the art focus on SemEval datasets from 2014 to 2016, with data from the restaurant, hotel or laptop domain in English. However, SemEval data are also available in several languages. Jebbara and Cimiano (2019), for instance, evaluated CNN models for OTE with multilingual word embeddings in a zero-shot crosslingual framework. 2.2 Cross-lingual transfer Multilingual pre-trained models have shown strong capacities for generalization and have been successfully applied for zero-shot cross-lingual transfer on a variety of natural language understanding tasks (Wu and Dredze, 2019). This enables the application of such models to low-resource languages for which little or no labelled data is avai2 Related Work lable. 2.1 Aspect-based Sentiment Analysis Machine Translation (MT) can help learning Due to the d"
2021.wnut-1.27,D19-5505,0,0.0441508,"our translation-based adaptation approach, and show its relevance in two scenarios : cross-lingual adaptation where annotated data is only available in the source language, and data augmentation where annotated data is available for both source and target languages. Lastly, we turn to an analysis of noisy user-generated text and propose a heuristic to filter out noisy utterances before translation. assume that the opinion target is given. Moreover, these subtasks aim to extract related information. To facilitate practical applications of ABSA, recent works address OTE and ASC simultaneously (Li et al., 2019a,b). The problem can be formulated as a sequence tagging task with unified labels to simultaneously detect opinion targets and the corresponding aspect sentiments. Some works went even further by addressing OTE, ASC, and OWE simultaneously, a task dubbed as aspect sentiment triplet extraction (Peng et al., 2020; Wang et al., 2021). Most works in the state of the art focus on SemEval datasets from 2014 to 2016, with data from the restaurant, hotel or laptop domain in English. However, SemEval data are also available in several languages. Jebbara and Cimiano (2019), for instance, evaluated CNN"
2021.wnut-1.27,D17-1310,0,0.0213051,"Missing"
2021.wnut-1.27,2020.framenet-1.6,1,0.718968,"om the assumption that neural machine translation (NMT) models capture word alignment through their attention mechanism, other works (Chen et al., 2020; Zouhar and Pylypenko, 2021) focus on using attention weights for word alignment. In an attempt to alleviate the need for parallel corpora, (Jalili Sabet et al., 2020) leveraged modern multilingual pre-trained models and released SimAlign, a tool for unsupervised word alignment based on the similarity of multilingual word representations. In order to project sequence annotations, one has to leverage word-level alignment towards span alignment. Marzinotto (2020) used attention-based word alignments to project FrameNet annotations (targets and Frame Elements) into a target language. Others have sought to improve label projection through different approaches. Jain et al. (2019) proposed an entity projection method for named entity recognition, in which they obtain potential translations of an entity in the target language and select the best match with the source entity. To make use of task-related information, Xu et al. (2020) proposed an end-to-end model to jointly align and predict target slot labels for cross-lingual NLU. (Li et al., 2020) propose"
2021.wnut-1.27,P19-1493,0,0.0294473,"vailable for ral machine translation systems, the paracertain languages, this technique of cross-lingual digm of using automatically translated data for transfer can be harnessed to process low-resource cross-lingual adaptation is now studied in several applicative domains. The capacity to aclanguages, therefore bypassing the need for a costly curately project annotations remains however annotation process. Some research effort has been an issue for sequence tagging tasks where andone in grasping to what extent these models are notation must be projected with correct spans. language agnostic (Pires et al., 2019), though more Additionally, when the task implies noisy userprobing is necessary in order to fully understand generated text, the quality of translation and and measure how multilingual these models are. annotation projection can be affected. In this paper we propose to tackle multilingual seAnother approach to cross-lingual transfer quence tagging with a new span alignment consists in using machine translation (MT) to adapt method and apply it to opinion target extracthe annotated training data available in a source lantion from customer reviews. We show that guage to the target language. The"
2021.wnut-1.27,S15-2082,0,0.038394,"Missing"
2021.wnut-1.27,S14-2004,0,0.02396,"In contrast, we show that translationbased adaptation yields superior performance comguages such as multilingual BERT (mBERT) and pared to zero-shot cross-lingual transfer, provided XLM-R provide an alternative. They have been the right annotation projection method is used. shown to yield on par, if not better performance on various tasks compared to monolingual models We propose to apply this method in the context and perform particularly well for low-resource lan- of opinion mining, and specifically to aspect-based guages provided similar languages are represented sentiment analysis (ABSA) (Pontiki et al., 2014). in the training data (Conneau et al., 2020). What’s Nowadays, people increasingly rely on reviews and more, they have shown surprising capacities for ge- comments, e.g. on social media and review webneralization with zero-shot cross-lingual transfer, in sites, to select which products to buy or which serwhich a model is fine-tuned for a task using annota- vices to use. Companies can also make use of these 238 Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 238–248 November 11, 2021. ©2021 Association for Computational Linguistics data wh"
2021.wnut-1.27,H05-1043,0,0.0202948,"representations and transfering inforuser-generated text, opinion mining is commonly mation across languages. Rather than being at odds, formulated as a text classification task concerned zero-shot cross-lingual transfer and MT-based apwith e.g. classifying the overall polarity of a sen- proaches are complementary : MT can be used tence by assigning it a polarity label (Pang and Lee, to generate synthetic data in languages for which 2008). no annotated data is available. Accordingly, MT Aspect-based sentiment analysis (ABSA) (Hu can improve cross-lingual transfer in two ways : and Liu, 2004; Popescu and Etzioni, 2005; Pontiki (i) By translating the training data into the target et al., 2014, 2015, 2016) is a more fine-grained languages and fine-tuning on all languages, e.g. opinion mining task with several sub-tasks associa- for subjectivity analysis (Banea et al., 2008), sentited with it. For example, opinion target extraction ment classification (Duh et al., 2011) or semantic (OTE) retrieves the entity on which an opinion is role labeling (Fei et al., 2020). (ii) Or by applying expressed in a review, and aspect sentiment classi- a model fine-tuned on the source language to a fication (ASC) identifies th"
2021.wnut-1.27,2020.emnlp-main.719,0,0.0208325,"Missing"
2021.wnut-1.27,L18-1560,0,0.0282515,"et al., 2020) refers to the former approach cus on one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we focus on the former approach. (OWE) (Fan et al., 2019; Pouran Ben Veyseh et al., This approach naturally applies to sentence classi2020). But this division of subtasks is ill-suited fication tasks and previous work has shown that for real-world scenarios as both ASC and OWE translation-based adaptation is superior to zero239 shot cross-lingual transfer for text classification (Schwenk and Li, 2018) and text pair classification (Conneau et al., 2018; Yang et al., 2019). However, little work focuses on adapting datasets annotated at the word level for sequence tagging. This requires an important additional step of annotation projection as no word-to-word correspondence is available. One approach to annotation projection for sequence tagging tasks relies on obtaining word alignments to project labels from source to target utterances. Several statistical word alignment tools are available such as fast_align (Dyer et al., 2013) which constitutes the usual baseline for this approach. Starting"
2021.wnut-1.27,2020.eamt-1.61,0,0.0142467,"ristic to filter out pseudo-labeled utterances that are likely to be ill-formed. See Figure 2 for an example. Translation-based Adaptation Modern neural machine translation (NMT) provides satisfactory results thanks to Transformer models and has become increasingly available. As a result, such models can be used effectively to create synthetic data by translating a source language reference corpus. We use Marian NMT 1 to translate the source language corpora into the other languages, and viceversa. Marian NMT is open source and allows the use of pre-trained NMT models from the OPUSMT project (Tiedemann and Thottingal, 2020) available on this framework. A description of each model and its evaluation on benchmarks can be found online. 2 To obtain word alignments, we use both off-the-shelf fast_align (Dyer et al., 2013) and SimAlign (Jalili Sabet et al., 2020). For the latter, which doesn’t need any parallel data for training but relies on multilingual word representations, we use the Itermax variant, which was shown to outperform other word alignment approaches. Note that we did not adapt the translation models nor the alignment approaches to our specific domains. 4.1 F IGURE 2: In this case, ""bourguignon"" which i"
2021.wnut-1.27,D19-1077,0,0.0119457,"t al., 2021). Most works in the state of the art focus on SemEval datasets from 2014 to 2016, with data from the restaurant, hotel or laptop domain in English. However, SemEval data are also available in several languages. Jebbara and Cimiano (2019), for instance, evaluated CNN models for OTE with multilingual word embeddings in a zero-shot crosslingual framework. 2.2 Cross-lingual transfer Multilingual pre-trained models have shown strong capacities for generalization and have been successfully applied for zero-shot cross-lingual transfer on a variety of natural language understanding tasks (Wu and Dredze, 2019). This enables the application of such models to low-resource languages for which little or no labelled data is avai2 Related Work lable. 2.1 Aspect-based Sentiment Analysis Machine Translation (MT) can help learning Due to the difficulties associated with processing cross-lingual representations and transfering inforuser-generated text, opinion mining is commonly mation across languages. Rather than being at odds, formulated as a text classification task concerned zero-shot cross-lingual transfer and MT-based apwith e.g. classifying the overall polarity of a sen- proaches are complementary :"
2021.wnut-1.27,P18-2094,0,0.0142057,"nion target extraction ment classification (Duh et al., 2011) or semantic (OTE) retrieves the entity on which an opinion is role labeling (Fei et al., 2020). (ii) Or by applying expressed in a review, and aspect sentiment classi- a model fine-tuned on the source language to a fication (ASC) identifies the polarity of an opinion test set translated from target to source language. expressed on a given target entity. Some works fo- (Conneau et al., 2020) refers to the former approach cus on one subtask at a time, e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we focus on the former approach. (OWE) (Fan et al., 2019; Pouran Ben Veyseh et al., This approach naturally applies to sentence classi2020). But this division of subtasks is ill-suited fication tasks and previous work has shown that for real-world scenarios as both ASC and OWE translation-based adaptation is superior to zero239 shot cross-lingual transfer for text classification (Schwenk and Li, 2018) and text pair classification (Conneau et al., 2018; Yang et al., 2019). However, little work focuses on adapting datasets annotated at the word level for"
2021.wnut-1.27,2020.emnlp-main.410,0,0.0425345,"Missing"
2021.wnut-1.27,D19-1382,0,0.0188832,"e.g. OTE (Li and Lam, as translate-train and to the latter as translate-test. 2017; Xu et al., 2018) or opinion word extraction In this work, we focus on the former approach. (OWE) (Fan et al., 2019; Pouran Ben Veyseh et al., This approach naturally applies to sentence classi2020). But this division of subtasks is ill-suited fication tasks and previous work has shown that for real-world scenarios as both ASC and OWE translation-based adaptation is superior to zero239 shot cross-lingual transfer for text classification (Schwenk and Li, 2018) and text pair classification (Conneau et al., 2018; Yang et al., 2019). However, little work focuses on adapting datasets annotated at the word level for sequence tagging. This requires an important additional step of annotation projection as no word-to-word correspondence is available. One approach to annotation projection for sequence tagging tasks relies on obtaining word alignments to project labels from source to target utterances. Several statistical word alignment tools are available such as fast_align (Dyer et al., 2013) which constitutes the usual baseline for this approach. Starting from the assumption that neural machine translation (NMT) models captu"
C08-1056,P06-2005,0,0.765033,"ng (NLP) point of view, these messages contain an abnormally high rate of out-of-vocabulary forms, and the ambiguity of existing word forms is aggravated, two factors that contribute to degrade the performance of natural language processing tools. Recovering a normalized orthography seems thus to be a necessary preprocessing step for many real-world NLP applications, such as text-to-speech, translation, or text mining applications (filtering, routing, information retrieval, etc). These short messages have so far received relatively little attention from the NLP community2 : see, for English, (Aw et al., 2006; Choudhury et al., 2007), which both address the problem with statistical learning techniques, and, for French, (Guimier de Neef et al., 2007), which details a complete pipe-line of hand-crafted, symbolic, modules. In fact, the problem of normalizing SMS shares a lot of commonalities with other NLP applications, and can be addressed from several viewpoints. The first, maybe the most natural angle, is to make an analogy with the spelling correction problem. This problem has been extensively studied in the past and a variety of statistical approaches are readily available, most notably the “noi"
C08-1056,P00-1037,0,0.335755,"lem with statistical learning techniques, and, for French, (Guimier de Neef et al., 2007), which details a complete pipe-line of hand-crafted, symbolic, modules. In fact, the problem of normalizing SMS shares a lot of commonalities with other NLP applications, and can be addressed from several viewpoints. The first, maybe the most natural angle, is to make an analogy with the spelling correction problem. This problem has been extensively studied in the past and a variety of statistical approaches are readily available, most notably the “noisy channel” approach (see eg. (Church and Gale, 1991; Brill and Moore, 2000; Toutanova and Moore, 2002)). An alternative metaphor is the translation metaphor: under this view, the normalization task is accomplished by taking the SMS 2 A couple of on-line SMS-to-English translation systems are accessible on the Internet, see notably http://www. transl8it.com/ and http://www.lingo2word. com/; “Netspeak” dictionaries, again for English, also abound. The situation is more or less comparable for French, see eg http://www.traducteur-sms.com/. language as a foreign language, and using standard (statistical) translation techniques. Both views have their own merit, and their"
C08-1056,J90-2002,0,0.532128,", the case for common abbreviations (eg. btw for by the way) and for instances of “consonantic” spellings. The dictionnary used in the experiments reported above contains about 4,200 entries. This module is implemented as a finitestate transducer E which transduces letter sequences in Λ∗ into mixed grapheme and phoneme sequences (in (Λ ∪ Π)∗ ). Two normalization systems 3.1 The MT-like system Our first normalization system is entirely based on open-source, public domain packages for statistical machine translation. Giza++ (Och and Ney, 2003) is used to induce, based on statistical principles (Brown et al., 1990), an automatic word alignment of SMS tokens with their normalized counterparts; Moses (Koehn et al., 2007) is used to learn the various parameters of the phrase-based model, to optimize the weight combination and to perform the translation using a multi-stack search algorithm; the SRI language model toolkit (Stolcke, 2002) is finally used to estimate statistical language models. For this system, the training set has been split in a learning set3 (approximately 25000 messages) and a development set (about 11700 messages), which is used to tune parameters. As suggested in the previous sections,"
C08-1056,fairon-paumier-2006-translated,0,0.0864503,"Ol/ (for Paul). Upon recognition of any such sequence, two transitions loop back to the initial state: one carries the input symbol ’#’, which is used whenever a word separator is encountered; the other is an ε transition, which allows to re-segment the input stream. 4 4.1 Experiments Experimental protocol The experiments reported below use two corpora. The first one has been collected at the University of Aix-en-Provence (Hocq, 2006); it contains approximately 9700 messages. The second corpus has been gathered in Belgium by the Catholic University of Louvain, and totals about 30000 messages (Fairon and Paumier, 2006). Both corpora contain, for each message, a reference normalization which has been produced and validated by human annotators. Both corpora were merged, lowercased, stripped from punctuation signs and standardized (in particular with respect to the anonymization conventions). This database was split in a training set (about 36700 messages) and a distinct test set of about 3000 messages. The training set was used both to train and tune the MT-like system and to estimate a 3-gram language model required in both approaches, using standard back-off procedures. Some relevant statistics regarding th"
C08-1056,2008.jeptalnrecital-long.13,1,0.776365,"Mohri and Riley, 1998). In addition to these four main modules, the preprocessing module of the ASR-like system contains a number of small enhancements that improve the normalization of dates and hours. We furthermore had to modify the processing of outof-vocabulary words: in the architecture sketched above, any word that does not belong to the vocabulary has to be decomposed into smaller, known, words, causing systematic errors. Our final ASRlike system allows these forms to be either decomposed phonetically or copied verbatim in the output. A complete description of this system is given in (Kobus et al., 2008). &lt;eps&gt;:&lt;eps&gt; O:&lt;eps&gt; 1 2 p:paul l:&lt;eps&gt; 3 _#:&lt;eps&gt; 0/0 _#:&lt;eps&gt; l:louis 4 w:&lt;eps&gt; 5 i:&lt;eps&gt; 6 &lt;eps&gt;:&lt;eps&gt; Figure 1: Transducing phone sequences into word sequences with a dictionary This simplistic inverted dictionary recognizes two phonemic sequences: /lwi/ (for Louis) and /pOl/ (for Paul). Upon recognition of any such sequence, two transitions loop back to the initial state: one carries the input symbol ’#’, which is used whenever a word separator is encountered; the other is an ε transition, which allows to re-segment the input stream. 4 4.1 Experiments Experimental protocol The experiment"
C08-1056,J03-1002,0,0.00184899,"mic content of the corresponding lexical item(s). This is, for instance, the case for common abbreviations (eg. btw for by the way) and for instances of “consonantic” spellings. The dictionnary used in the experiments reported above contains about 4,200 entries. This module is implemented as a finitestate transducer E which transduces letter sequences in Λ∗ into mixed grapheme and phoneme sequences (in (Λ ∪ Π)∗ ). Two normalization systems 3.1 The MT-like system Our first normalization system is entirely based on open-source, public domain packages for statistical machine translation. Giza++ (Och and Ney, 2003) is used to induce, based on statistical principles (Brown et al., 1990), an automatic word alignment of SMS tokens with their normalized counterparts; Moses (Koehn et al., 2007) is used to learn the various parameters of the phrase-based model, to optimize the weight combination and to perform the translation using a multi-stack search algorithm; the SRI language model toolkit (Stolcke, 2002) is finally used to estimate statistical language models. For this system, the training set has been split in a learning set3 (approximately 25000 messages) and a development set (about 11700 messages), w"
C08-1056,2001.mtsummit-papers.68,0,0.0259089,"translation tools incorporate mechanisms to model the possible mismatch in word order between source and target, which are virtually nonexisting when it comes to translating SMS. This metaphor is, nonetheless, the one resorted to in (Aw et al., 2006), which uses a statistical phrase-based machine translation tool to convert English SMS texts into standardized English. This system incorporates some of the peculiarities of this translation task, which both simplifies the construction of the phrase-table and the decoding search algorithm. Using this system, (Aw et al., 2006) reports a 0.81 BLEU (Papineni et al., 2001) score on a set of 5,000 English SMS. Normalization as translation is certainly a natural, and simple to implement, idea. Using phrase-based systems, it becomes possible to model (context-dependant) one-to-many relationships that are out-of-reach of the spell checking approach. We feel that it still overlooks some aspects of the task, notably the fact that the lexical creativity attested in SMS messages can hardly be captured in a static phrase table, where correspondences between SMS phrases and normalized phrases are learned by rote, rather than modeled. 2.3 The &quot;speech recognition&quot; metaphor"
C08-1056,P02-1019,0,0.707037,"arning techniques, and, for French, (Guimier de Neef et al., 2007), which details a complete pipe-line of hand-crafted, symbolic, modules. In fact, the problem of normalizing SMS shares a lot of commonalities with other NLP applications, and can be addressed from several viewpoints. The first, maybe the most natural angle, is to make an analogy with the spelling correction problem. This problem has been extensively studied in the past and a variety of statistical approaches are readily available, most notably the “noisy channel” approach (see eg. (Church and Gale, 1991; Brill and Moore, 2000; Toutanova and Moore, 2002)). An alternative metaphor is the translation metaphor: under this view, the normalization task is accomplished by taking the SMS 2 A couple of on-line SMS-to-English translation systems are accessible on the Internet, see notably http://www. transl8it.com/ and http://www.lingo2word. com/; “Netspeak” dictionaries, again for English, also abound. The situation is more or less comparable for French, see eg http://www.traducteur-sms.com/. language as a foreign language, and using standard (statistical) translation techniques. Both views have their own merit, and their limitations, which we shall"
C08-1056,P02-1040,0,\N,Missing
C08-1056,P07-2045,0,\N,Missing
D19-5803,D17-1219,0,0.0586191,"Missing"
D19-5803,P18-1177,0,0.0329458,"Missing"
D19-5803,D17-1090,0,0.0502955,"Missing"
D19-5803,W18-0530,0,0.0377572,"Missing"
D19-5803,P98-1013,0,0.564217,"Missing"
D19-5803,W17-2603,0,0.0578148,"Missing"
D19-5803,W18-2605,0,0.203005,"n2 (1) Aix-Marseille Univ, Université de Toulon, CNRS, LIS, Marseille, France (2) Orange Labs, Lannion (1) {first.last}@lis-lab.fr (2) {first.last}@orange.com Abstract previous methods based on linguistic analysis or similarity metrics between questions and segments (Hermann et al., 2015). Recently the use of contextual word embeddings such as BERT (Devlin et al., 2018) or XLNet (Yang et al., 2019) lead to obtain another great increase in performance, reaching human-level performance according to some benchmarks 1 . These large corpora are only available in English, and more recently Chinese (He et al., 2018) but for other languages, such as French, there is no comparable resources and the effort required to collect such a large amount of data is very important, limiting the use of these methods to other languages or other application frameworks. To address this problem, several studies have proposed to generate automatically questions and answers directly from a text document such as Wikipedia pages (Du and Cardie, 2018) in order to build a training corpus for MRC models. One of the issues of such methods is the semantic errors that can occur between questions and answers due to the automatic gen"
D19-5803,L18-1159,1,0.509096,"rame, E is one Frame Element of f and C (for Context) is the set of the other Frame Elements. Given a triplet (F, E, C), questions can be produced for which the answer is E. In the case of the Losing Frame of Figure 1, which has three Frame Elements, three triplets (F, E, C) can be produced : corpus of question/answer pairs to train a question generation model, we will rely on simple patterns based on the semantic annotations of our target corpus. The main originality of this work is to use a large encyclopedic corpus in French annotated with a FrameNet semantic model, the CALOR FRAME corpus (Marzinotto et al., 2018), in order to automatically produce a large amount of semantically-valid pairs of questions and answerspans, the CALOR - QUEST corpus. Using FrameNet annotations for generating an MRC training corpus has a major drawback : the human effort needed to build such resources is arguably bigger than building directly a question/answer corpus such as SQuAD. However we believe this method has several advantages : — firstly corpora with frame-based annotations are available for many languages, even if often of limited sizes ; — secondly frame-based annotation is not linked to a single task such as MRC,"
D19-5803,P14-2053,0,0.0685118,"Missing"
D19-5803,D16-1264,0,0.0910622,"ge corpora. The collect of natural questions is reduced to a validation/test set. We applied this method on the French CALOR - FRAME corpus to develop the CALOR - QUEST resource presented in this paper. 1 Introduction Machine Reading Comprehension (MRC) is a Natural Language Understanding task consisting in retrieving text segments from a document thanks to a set of questions, each segment being an answer to a particular question. This task received a lot of attention in the past few years thanks to the availability of very large corpora of triplets (document, question, answer) such as SQuAD (Rajpurkar et al., 2016) or MS MARCO (Nguyen et al., 2016), each containing more than 100k triplets. In these corpora each question has been manually produced, either through crowd-sourcing or by collecting query logs from a search engine. These large corpora opened the door to the development of supervised machine learning approaches for MRC, mostly based on Deep Neural Network (Wang and Jiang, 2016; Seo et al., 2016), improving greatly the state-of-the-art over 1. https ://rajpurkar.github.io/SQuAD-explorer/ 19 Proceedings of the Second Workshop on Machine Reading for Question Answering, pages 19–26 c Hong Kong, Ch"
D19-5803,P16-1056,0,0.048778,"Missing"
F12-1102,N10-1025,0,0.0610677,"Missing"
L16-1319,garnier-rizet-etal-2008-callsurf,0,0.0798392,"Missing"
L16-1319,shaikh-etal-2010-mpc,0,0.364037,"Missing"
L16-1319,bechet-etal-2012-decoda,0,0.0276519,"Missing"
L16-1319,D13-1035,0,0.076969,"able wealth of information in order to better understand customers’ needs. From a language processing perspective, they constitute a new area of study which has been only very little explored. In this article we propose a descriptive analysis of such a chat conversation corpus. Some aspects are described through a contrastive analysis with a phone call-center conversation corpus. Most studies in the literature refer to multiparty chat conversations from chatrooms. (Falaise, 2005) constituted a corpus in French. (Martel & al., 2007) and (Shaikh & al. 2010) describe similar corpora in English. (Cadilhac et al., 2013) have studied the relational structure of such conversations through a deep discursive analysis of chat sessions in an online video game. Among the few works that have been published on contact centers chat conversations, (Dickey et al., 2007) propose a study from the perspective of the strategies adopted by agents in favor of mutual comprehension, with a focus on discontinuity phenomena, trying to understand the reasons why miscomprehension can arise. (Wu et al., 2012) propose a typography of communication modes between customers and agents through a study on a conversation interface. The med"
L18-1014,W15-4319,0,0.0354559,"Missing"
L18-1014,W16-3916,0,0.0119843,"ng Error Correction 1. Introduction is commonly expected. The typology of errors is slightly different and most recent works focus on one-to-one lexical errors (replacing one word by another). The availability of large corpora has led to the design of normalization lexicons (Han et al., 2012) that directly map correct words to there common ill-formed variants. (Sridhar, 2015) learns a normalization lexicon and converts it into a Finite State Transducer. More recently, the construction of normalization dictionaries using word embeddings on Twitter texts were performed for Brazilian Portuguese (Bertaglia and Nunes, 2016). In this paper, we focus on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text, several approaches have proposed to use word clusters provided by hierarchical clustering approaches such as the Brown algorithm. (Owoputi et al., 2013) use word clusters along with dedicated lexical features to enrich their tagger in the context"
L18-1014,W14-4012,0,0.0307382,"Missing"
L18-1014,R13-1026,0,0.0263471,"on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text, several approaches have proposed to use word clusters provided by hierarchical clustering approaches such as the Brown algorithm. (Owoputi et al., 2013) use word clusters along with dedicated lexical features to enrich their tagger in the context of online conversations. (Derczynski et al., 2013) use clustering approaches to handle linguistic noise, and train their system from a mixture of hand-annotated tweets and existing POS-labeled data. (Nasr et al., 2016) address the issue of training data mismatch in the context of online conversations and show that equivalent performance can be obtained by training on a small in domain corpus rather than using generic POS-labeled resources. Contact Center chat conversation is a particular type of noisy user generated text in the sense that it is a formal Computer Mediated Communication (CMC) interaction mode. It shares some normalization issue"
L18-1014,D12-1039,0,0.0312327,"es the remaining errors. Word embeddings are trained on a large corpus in order to address both normalization and POS tagging. Experiments are run on Contact Center chat conversations, a particular type of formal Computer Mediated Communication data. Keywords: Part of Speech Tagging, Computer Mediated Communication, Spelling Error Correction 1. Introduction is commonly expected. The typology of errors is slightly different and most recent works focus on one-to-one lexical errors (replacing one word by another). The availability of large corpora has led to the design of normalization lexicons (Han et al., 2012) that directly map correct words to there common ill-formed variants. (Sridhar, 2015) learns a normalization lexicon and converts it into a Finite State Transducer. More recently, the construction of normalization dictionaries using word embeddings on Twitter texts were performed for Brazilian Portuguese (Bertaglia and Nunes, 2016). In this paper, we focus on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to"
L18-1014,D12-1000,0,0.199842,"Missing"
L18-1014,P13-1155,0,0.0229557,"plying the corrector with the lower case lexicon described in 3.1. The original case is reintroduced before applying the POS tagger. The lexical corrector provides a list of candidates for correction, until a maximum cost is reach. This upper bound is proportional to the word length n in terms of number of letters and is computed as follows: max cost = n × γ In these experiments γ is set to 0.3. Here again contrastive experiments can be provided showing the impact of the γ parameter. As we are dealing with formal interactions,we did not apply the modification on the edit distance proposed by (Hassan and Menezes, 2013) where edit distance is computed on consonant skeletons, nor do we use Longest Common Subsequence Ratio (LCSR) as it didn’t reveal to be helpful in our case. 3.3. Cemb (w, αi (w)) = C(w, αi (w)) × demb (w, αi (w)) 4. The part of speech tagger used in our experiment is based on Gated Recurrent Units (GRU). GRUs, introduced by (Cho et al., 2014), are recurrent neural networks that work in a similar fashion than LSTMs. GRUs are simpler than LSTMs: they do not have an output gate, and the input and forget gates are merged into an update gate. This property allows GRUs to be computationally more ef"
L18-1014,C08-1056,1,0.761051,"deviations in the design of the tagger. We will show that a good compromise is to handle some of the errors through lexical normalization but also to design a robust POS tagger that handles orthographic errors. We propose to use word embeddings at both levels: for text normalization and for POS tagging. 2. Related work Text normalization has been studied for several years now, with different perspectives over time. When studying SMS style language, researchers tried to handle new phenomena including voluntary slang shortcuts through phonetic models of pronunciation (Toutanova and Moore, 2002; Kobus et al., 2008). Recently, the effort has been more particularly set on Social Media text normalization with specific challenges on Twitter texts (Baldwin et al., 2015), which has been shown to be more formal (Hu et al., 2013) that what 3. Text normalization Our text normalization process operates in two steps, the first one produces in-lexicon variants for an out of lexicon form. The second one reranks the forms produced by the first step, using a distributional distance. The first step is based on a lexicon and an edit distance while the second relies on word embeddings. We focus on one-to-one normalizatio"
L18-1014,W16-3621,1,0.929075,"ted representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text, several approaches have proposed to use word clusters provided by hierarchical clustering approaches such as the Brown algorithm. (Owoputi et al., 2013) use word clusters along with dedicated lexical features to enrich their tagger in the context of online conversations. (Derczynski et al., 2013) use clustering approaches to handle linguistic noise, and train their system from a mixture of hand-annotated tweets and existing POS-labeled data. (Nasr et al., 2016) address the issue of training data mismatch in the context of online conversations and show that equivalent performance can be obtained by training on a small in domain corpus rather than using generic POS-labeled resources. Contact Center chat conversation is a particular type of noisy user generated text in the sense that it is a formal Computer Mediated Communication (CMC) interaction mode. It shares some normalization issues with other CMC texts such as chatroom conversations or social media interactions but unlike the aforementioned cases, the professional context implies some specificit"
L18-1014,N13-1039,0,0.0795164,"Missing"
L18-1014,sagot-2010-lefff,0,0.0253431,"ir associated morphological and lexical features. The words are encoded using a lookup table which associates each word with its word embedding representation. These word embeddings can be initialized with pretrained embeddings and/or learned when training the model. For the morphological and typographic features, we use a boolean value for the presence of an uppercase character as the first letter of the word as well as the word suffixes of length 3 and 4 represented as onehot vectors. Finally, we also input as onehot vectors external lexicon information, constructed using the Lefff lexicon (Sagot, 2010). Such vectors represent the possible part-of-speech labels of a word. On the output layer, we use a softmax activation. During training, categorical Rescoring with word embeddings The edit distance based variant generation process described above does not take into account the context of a word when generating variants. In order to take it into 1 Part of speech tagging https://github.com/Orange-OpenSource/lexical-corrector 89 cross-entropy is used as the loss function and the Adam optimiser (Kingma and Ba, 2014) is used for the gradient descent optimisation. 5. # of correctable err. # of non"
L18-1014,W15-1502,0,0.014803,"ss both normalization and POS tagging. Experiments are run on Contact Center chat conversations, a particular type of formal Computer Mediated Communication data. Keywords: Part of Speech Tagging, Computer Mediated Communication, Spelling Error Correction 1. Introduction is commonly expected. The typology of errors is slightly different and most recent works focus on one-to-one lexical errors (replacing one word by another). The availability of large corpora has led to the design of normalization lexicons (Han et al., 2012) that directly map correct words to there common ill-formed variants. (Sridhar, 2015) learns a normalization lexicon and converts it into a Finite State Transducer. More recently, the construction of normalization dictionaries using word embeddings on Twitter texts were performed for Brazilian Portuguese (Bertaglia and Nunes, 2016). In this paper, we focus on out-of-vocabulary words. We propose to generate variants of such words using a lexical corrector based on a customized edit distance and to use word embeddings as distributed representations of words to re-rank these hypotheses thanks to contextual distance estimation. In order to adapt POS tagging systems for noisy text,"
L18-1014,P02-1019,0,0.072417,"directly handling language deviations in the design of the tagger. We will show that a good compromise is to handle some of the errors through lexical normalization but also to design a robust POS tagger that handles orthographic errors. We propose to use word embeddings at both levels: for text normalization and for POS tagging. 2. Related work Text normalization has been studied for several years now, with different perspectives over time. When studying SMS style language, researchers tried to handle new phenomena including voluntary slang shortcuts through phonetic models of pronunciation (Toutanova and Moore, 2002; Kobus et al., 2008). Recently, the effort has been more particularly set on Social Media text normalization with specific challenges on Twitter texts (Baldwin et al., 2015), which has been shown to be more formal (Hu et al., 2013) that what 3. Text normalization Our text normalization process operates in two steps, the first one produces in-lexicon variants for an out of lexicon form. The second one reranks the forms produced by the first step, using a distributional distance. The first step is based on a lexicon and an edit distance while the second relies on word embeddings. We focus on on"
L18-1159,P98-1013,0,0.900593,"rated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The models compared are CRFs and multitasks bi-LSTMs. Keywords: Frame Semantic Parsing, LSTM, CRF 1. Introduction Semantic Frame parsing is a Natural Language Understanding task that involves detecting in a sentence an event or a scenario, called Frame, as well as all the elements or roles that can be associated to this event in the sentence, called Frame Elements. One of the most popular semantic frame model is the Berkeley FrameNet project developed by ICSI Berkeley (Baker et al., 1998). This model is composed of an inventory of Frames with, for each of them, a list of words, called Lexical Units (or LU), that can trigger a frame in a sentence. Besides, for each frame, a list of Frame Elements (FE), core or optional, is defined. LUs are pairings of a word with a sense; Frame Elements are the components of a frame, represented by sequences of words in a sentence. Two kinds of parsing can be done with a Semantic Frame model: full text parsing where each word in a sentence is analyzed to check if it can trigger a frame; and partial parsing where only a subset of frames and LUs"
L18-1159,candito-etal-2014-developing,0,0.0449117,"Missing"
L18-1159,P14-1136,0,0.159427,"CRF relatively small, limited to the frames that can be triggered by the word considered. Therefore the ambiguity is limited and CRFs can be trained efficiently even with a large number of features. However the drawback is that the training data is split across words in the LU lexicon, therefore similarities among LU are not exploited. This situation is acceptable if enough training examples are provided for each LUs, which is the case for the CALOR corpus. 4.2. Multi-task LSTM approach Deep Neural Networks (DNN) with word embedding is the state of the art approach for semantic frame parsing (Hermann et al., 2014). More recently recurrent neural networks (RNN) with Long Short Memory (LSTM) cells have been applied to several semantic tagging tasks such as slot filling (Mesnil et al., 2015) or even frame parsing (Hakkani-T¨ur et al., 2016; Tafforeau et al., 2016) for Spoken Language Understanding. Following these previous works, we propose in this study a single-layered bidirectional LSTM sequence to sequence architecture to perform frame tagging. To deal with the multi-label issue we could train a biLSTM model per LU, using the same approach as for the CRF, however, the number of examples per LU is redu"
L18-1159,W03-0430,0,0.0251963,"he absolute value of these links is not meaningful and cannot be predicted the same way as the semantic labels are. In this study we compare two different strategies in order to deal with the multi-label issue, one based on CRF with a multi-model approach (each LU has its own prediction model) and one based on a bi-LSTM model following a multi-task approach. They are described in the next section. 4. 4.1. Sequence labeling models Multi-model CRF approach CRF-based approaches have been used in many NLP tasks involving sequence labeling such as POS tagging, chunking or named entity recognition (McCallum and Li, 2003). In order to apply CRF to frame parsing, as described in section 3., we need to address the multi-label issue. Since we want to perform frame disambiguation and semantic role detection in one step, and because each word in a sentence cannot trigger more than one frame, we chose a multimodel approach where a CRF-model is trained for each word belonging to the LU lexicon. This approach is described in Figure 3. At training time, the corpus is split according to the LU lexicon: to each word Wi belonging to this lexicon is attached a sub-corpus containing all the sentences CWi where Wi occurs. Fo"
L18-1159,P11-4015,1,0.681968,"Missing"
L18-1329,W15-4635,0,0.0332707,"Missing"
L18-1329,S17-2001,0,0.0131291,"domly selected from articles of the Brown corpus. These segments are grouped into 700 documents where each document is the concatenation of 10 segments. A segment is composed of the first n sentences of the original article. The ICSI corpus (Shriberg et al., 2004) (Shriberg et al., 2000) contains 75 documents transcribed automatically 1 https://lium.univ-lemans.fr/frnewslink/ Corpora for semantic textual similarity Semantic textual similarity measures the meaning similarity of texts, beyond lexical similarity. It has been treated in several evaluation campaigns in SemEval in the recent years (Cer et al., 2017). Available corpora are mainly in English, even though some have been introduced in Spanish and Arabic. In the semantic textual similarity task of SemEval, similarity is measured between short sentences, according to a scale of 5 levels, ranging from ”no relation at all” to ”paraphrase”. Another task of the SemEval campaign deals with semantic similarity in the context of Community Questions Answering (Nakov et al., 2017). In particular: one subtask addresses ”question-question” similarity, where the questions are questions posted on an english2087 speaking forum (Qatar Living Forum) which dea"
L18-1329,A00-2004,0,0.135092,"sics course recordings. In (Eisenstein and Barzilay, 2008), the authors have made available a medical book in which each section is considered as a new topic segment. In the domain of French TVBN topic segmentation (Guinaudeau, 2011) created a corpus of 57 news programs broadcasted in February and March 2007 on the French television channel France 2. It contained 1180 topic boundaries. As will be developed in section 5.1. the particularity of our corpus lies in the diversity of TVBN shows sources and formats. 2.2. 2. 2.1. Related work Corpora for topic segmentation The C99 corpus designed by (Choi, 2000) has been widely used for evaluating topic segmentation of written text. It is an artificial corpus composed of 7000 segments randomly selected from articles of the Brown corpus. These segments are grouped into 700 documents where each document is the concatenation of 10 segments. A segment is composed of the first n sentences of the original article. The ICSI corpus (Shriberg et al., 2004) (Shriberg et al., 2000) contains 75 documents transcribed automatically 1 https://lium.univ-lemans.fr/frnewslink/ Corpora for semantic textual similarity Semantic textual similarity measures the meaning sim"
L18-1329,D08-1035,0,0.0375718,"king annotations between topic segments and press articles. Therefore, this corpus is very useful for many tasks such as topic segmentation, topic titling, video linking, semantic similarity, events follow-up and topic modeling (grouping documents addressing similar topics). Section 6. presents several tasks that can be addressed with our corpus, along with evaluations of theses tasks performed on it. from meeting records (approximately one hour each). For each conversation turn the speaker, start time, end time, and word content are marked. This corpus has been exploited in several works as (Eisenstein and Barzilay, 2008) and (Galley et al., 2003). The TDT (Topic Detection and Tracking) corpus has become a standard for topic segmentation. This corpus contains English, Arabic and Chinese (Mandarin) documents. The corpus with its different versions (from TDT1 to TDT5) is used to evaluate many topic segmentation systems as (Rosenberg and Hirschberg, 2006) and (Xie et al., 2010). It is important to note that several works dedicated to topic segmentation use their own corpus (Malioutov and Barzilay, 2006), (Eisenstein and Barzilay, 2008). In (Malioutov and Barzilay, 2006), the authors have created their corpus from"
L18-1329,P03-1071,0,0.0764755,"nts and press articles. Therefore, this corpus is very useful for many tasks such as topic segmentation, topic titling, video linking, semantic similarity, events follow-up and topic modeling (grouping documents addressing similar topics). Section 6. presents several tasks that can be addressed with our corpus, along with evaluations of theses tasks performed on it. from meeting records (approximately one hour each). For each conversation turn the speaker, start time, end time, and word content are marked. This corpus has been exploited in several works as (Eisenstein and Barzilay, 2008) and (Galley et al., 2003). The TDT (Topic Detection and Tracking) corpus has become a standard for topic segmentation. This corpus contains English, Arabic and Chinese (Mandarin) documents. The corpus with its different versions (from TDT1 to TDT5) is used to evaluate many topic segmentation systems as (Rosenberg and Hirschberg, 2006) and (Xie et al., 2010). It is important to note that several works dedicated to topic segmentation use their own corpus (Malioutov and Barzilay, 2006), (Eisenstein and Barzilay, 2008). In (Malioutov and Barzilay, 2006), the authors have created their corpus from physics course recordings"
L18-1329,P13-1024,0,0.0203889,"data: the objective is to link a fragment to another fragment from the same source. Some other works attempt to link heterogeneous sources but from an alignment perspective (e.g. books and movies (Zhu et al., 2015) or video lectures and scientific papers (Mougard et al., 2015)). In the News domain there has been several studies about linking press articles with other information sources. (Aker et al., 2015) explore linking press articles and comments on the AT corpus (Das et al., 2014) which has been built from article of The Guardian. Linking press articles and Tweets have also been studied (Guo et al., 2013). Closer to our purpose is the work of (Bois et al., 2017a) who attempt to build graph representations for News browsing. The authors have collected over a 3 week period (May 20−Jun 8, 2015) a corpus of documents in French including press articles, videos (e.g. daily news from France 2, political news), and radio podcasts (e.g. news programs from France Inter, political interviews from RMC). This corpus is not distributed so far. The FrNewsLink corpus allows addressing several multi-modal linking tasks, with heterogeneous data from various sources and of various length. 3. 3.2. Press articles"
L18-1329,J97-1003,0,0.511183,"Missing"
L18-1329,P06-1004,0,0.0599047,"peaker, start time, end time, and word content are marked. This corpus has been exploited in several works as (Eisenstein and Barzilay, 2008) and (Galley et al., 2003). The TDT (Topic Detection and Tracking) corpus has become a standard for topic segmentation. This corpus contains English, Arabic and Chinese (Mandarin) documents. The corpus with its different versions (from TDT1 to TDT5) is used to evaluate many topic segmentation systems as (Rosenberg and Hirschberg, 2006) and (Xie et al., 2010). It is important to note that several works dedicated to topic segmentation use their own corpus (Malioutov and Barzilay, 2006), (Eisenstein and Barzilay, 2008). In (Malioutov and Barzilay, 2006), the authors have created their corpus from physics course recordings. In (Eisenstein and Barzilay, 2008), the authors have made available a medical book in which each section is considered as a new topic segment. In the domain of French TVBN topic segmentation (Guinaudeau, 2011) created a corpus of 57 news programs broadcasted in February and March 2007 on the French television channel France 2. It contained 1180 topic boundaries. As will be developed in section 5.1. the particularity of our corpus lies in the diversity of T"
L18-1329,N06-2032,0,0.0486759,"our corpus, along with evaluations of theses tasks performed on it. from meeting records (approximately one hour each). For each conversation turn the speaker, start time, end time, and word content are marked. This corpus has been exploited in several works as (Eisenstein and Barzilay, 2008) and (Galley et al., 2003). The TDT (Topic Detection and Tracking) corpus has become a standard for topic segmentation. This corpus contains English, Arabic and Chinese (Mandarin) documents. The corpus with its different versions (from TDT1 to TDT5) is used to evaluate many topic segmentation systems as (Rosenberg and Hirschberg, 2006) and (Xie et al., 2010). It is important to note that several works dedicated to topic segmentation use their own corpus (Malioutov and Barzilay, 2006), (Eisenstein and Barzilay, 2008). In (Malioutov and Barzilay, 2006), the authors have created their corpus from physics course recordings. In (Eisenstein and Barzilay, 2008), the authors have made available a medical book in which each section is considered as a new topic segment. In the domain of French TVBN topic segmentation (Guinaudeau, 2011) created a corpus of 57 news programs broadcasted in February and March 2007 on the French televisio"
L18-1329,W04-2319,0,0.0989752,"aries. As will be developed in section 5.1. the particularity of our corpus lies in the diversity of TVBN shows sources and formats. 2.2. 2. 2.1. Related work Corpora for topic segmentation The C99 corpus designed by (Choi, 2000) has been widely used for evaluating topic segmentation of written text. It is an artificial corpus composed of 7000 segments randomly selected from articles of the Brown corpus. These segments are grouped into 700 documents where each document is the concatenation of 10 segments. A segment is composed of the first n sentences of the original article. The ICSI corpus (Shriberg et al., 2004) (Shriberg et al., 2000) contains 75 documents transcribed automatically 1 https://lium.univ-lemans.fr/frnewslink/ Corpora for semantic textual similarity Semantic textual similarity measures the meaning similarity of texts, beyond lexical similarity. It has been treated in several evaluation campaigns in SemEval in the recent years (Cer et al., 2017). Available corpora are mainly in English, even though some have been introduced in Spanish and Arabic. In the semantic textual similarity task of SemEval, similarity is measured between short sentences, according to a scale of 5 levels, ranging f"
L18-1329,D15-1237,0,0.0626871,"Missing"
N19-2021,P98-1013,0,0.0871379,"Missing"
N19-2021,D18-1002,0,0.0267427,"nguage classifiers with an adversarial objective to train task-specific but language agnostic representations. Besides the cross-lingual transfer problem, there are few studies of the impact of domain-adversarial training in a monolingual setup. For instance, (Liu et al., 2017) successfully uses this technique to improve generalization in a document classification task. It has also been used recently for varied tasks such as transfer learning on Q&A systems (Yu et al., 2018) or duplicate question detection (Shah et al., 2018) and removal of protected attributes from social media textual data (Elazar and Goldberg, 2018). 2.2 Semantic parsing model with an adversarial training scheme 3.2 Sequence encoding/decoding For all experiments we use a BIO label encoding. To ensure that output sequences respect the BIO constrains we implement an A∗ decoding strategy similar to the one proposed by (He et al., 2017). We further apply a coherence filter to the output of the tagging process. This filter ensures that the predicted semantic structure is acceptable. Given a sentence and a word w that is a Lexical Unit (LU) trigger, we select the frame F as being the most probable frame among the ones that can have w as a trig"
N19-2021,D15-1112,0,0.0293163,"Missing"
N19-2021,passonneau-etal-2012-masc,0,0.0148032,"null hypothesis is selected if its probability is higher than P (yt = O). Varying δ > 0 (resp. δ < 0) is equivalent to being more strict (resp. less strict) on the highest non-null hypothesis. By doing so we can study the precision/recall (P/R) trade-off of our models. This δ parameter is tuned on a validation set and we either provide the P/R curve or report scores for the F max setting. Robustness in Semantic Frame Parsing In Frame Semantic Parsing, data is scarce and classic evaluation settings seldom propose outof-domain test data. Despite the existence of out-of-domain corpora such MASC (Passonneau et al., 2012) and YAGS (Hartmann et al., 2017) the domain adaptation problem has been widely reported (Johansson and Nugues, 2008; Søgaard et al., 2015) but not extensively studied. Recently, (Hartmann et al., 2017) presented the first in depth study of the domain adaptation problem using the YAGS frame corpus. They show that the main problem in domain adaptation for frame semantic parsing is the frame identification step and propose a more robust classifier using predicate and context embeddings to perform frame identification. This approach is suitable for cascade systems such as SEMAFOR (Das et al., 201"
N19-2021,D18-1131,0,0.0229096,"et al., 2017) and sentiment analysis (Chen et al., 2016). These approaches introduce language classifiers with an adversarial objective to train task-specific but language agnostic representations. Besides the cross-lingual transfer problem, there are few studies of the impact of domain-adversarial training in a monolingual setup. For instance, (Liu et al., 2017) successfully uses this technique to improve generalization in a document classification task. It has also been used recently for varied tasks such as transfer learning on Q&A systems (Yu et al., 2018) or duplicate question detection (Shah et al., 2018) and removal of protected attributes from social media textual data (Elazar and Goldberg, 2018). 2.2 Semantic parsing model with an adversarial training scheme 3.2 Sequence encoding/decoding For all experiments we use a BIO label encoding. To ensure that output sequences respect the BIO constrains we implement an A∗ decoding strategy similar to the one proposed by (He et al., 2017). We further apply a coherence filter to the output of the tagging process. This filter ensures that the predicted semantic structure is acceptable. Given a sentence and a word w that is a Lexical Unit (LU) trigger,"
N19-2021,E17-1045,0,0.0149287,"probability is higher than P (yt = O). Varying δ > 0 (resp. δ < 0) is equivalent to being more strict (resp. less strict) on the highest non-null hypothesis. By doing so we can study the precision/recall (P/R) trade-off of our models. This δ parameter is tuned on a validation set and we either provide the P/R curve or report scores for the F max setting. Robustness in Semantic Frame Parsing In Frame Semantic Parsing, data is scarce and classic evaluation settings seldom propose outof-domain test data. Despite the existence of out-of-domain corpora such MASC (Passonneau et al., 2012) and YAGS (Hartmann et al., 2017) the domain adaptation problem has been widely reported (Johansson and Nugues, 2008; Søgaard et al., 2015) but not extensively studied. Recently, (Hartmann et al., 2017) presented the first in depth study of the domain adaptation problem using the YAGS frame corpus. They show that the main problem in domain adaptation for frame semantic parsing is the frame identification step and propose a more robust classifier using predicate and context embeddings to perform frame identification. This approach is suitable for cascade systems such as SEMAFOR (Das et al., 2014), (Hermann et al., 2014) and (Y"
N19-2021,D18-1548,0,0.0502383,"Missing"
N19-2021,P17-1044,0,0.254675,"e to obtain labels for the classification task. Firstly we perform experiments on a large multi-domain frame corpus (Marzinotto et al., 2018a) where only a relatively small number of frames where annotated, corresponding to possible targets in an Information Extraction applicative framework. We evaluate our adversarial framework with a semantic frame parser we developed on this corpus and presented in (Marzinotto et al., 2018b). Secondly we checked the genericity of our approach on the standard PropBank Semantic Role Labeling task on the CoNLL-2005 benchmark, with a tagging model proposed by (He et al., 2017). We show that in both cases adversarial learning increases all models generalization capabilities both on in and out-of-domain data. This paper addresses the issue of generalization for Semantic Parsing in an adversarial framework. Building models that are more robust to inter-document variability is crucial for the integration of Semantic Parsing technologies in real applications. The underlying question throughout this study is whether adversarial learning can be used to train models on a higher level of abstraction in order to increase their robustness to lexical and stylistic variations."
N19-2021,D17-1128,0,0.638184,"s searched where the taskspecific classifier is good and the domain classifier is bad. It has been shown in (Ganin and Lempitsky, 2015) that this implicitly optimizes the hidden representation towards domain independence. 3.1 Semantic parsing model: biGRU We use in this study a sequence tagging semantic frame parser that performs frame selection and argument classification in one step based on a deep bi-directional GRU tagger (biGRU ). The advantage of this architecture is its flexibility as it can be applied to several semantic parsing schemes such as PropBank (He et al., 2017) and FrameNet (Yang and Mitchell, 2017). More precisely, the model consists of a 4 layer bi-directional Gated Recurrent Unit (GRU) with highway connections (Srivastava et al., 2015). This model does not rely solely on word embeddings as input. Instead, it has a richer set of features including syntactic, morphological and surface features. (see (Marzinotto et al., 2018b) for more details). Except for words where we use pre-trained embeddings, we use randomly initialized embedding layers for categorical features. In NLP problems this approach has successfully been used to train cross-lingual word representations (Conneau et al., 201"
N19-2021,P14-1136,0,0.0166367,"YAGS (Hartmann et al., 2017) the domain adaptation problem has been widely reported (Johansson and Nugues, 2008; Søgaard et al., 2015) but not extensively studied. Recently, (Hartmann et al., 2017) presented the first in depth study of the domain adaptation problem using the YAGS frame corpus. They show that the main problem in domain adaptation for frame semantic parsing is the frame identification step and propose a more robust classifier using predicate and context embeddings to perform frame identification. This approach is suitable for cascade systems such as SEMAFOR (Das et al., 2014), (Hermann et al., 2014) and (Yang and Mitchell, 2017). In this paper we propose to study the generalization issue within the framework of a sequence tagging semantic frame parser that performs frame selection and argument classification in one step. 167 3.3 Adversarial Domain Classifier In order to design an efficient adversarial task, several criteria have to be met. The task has to be related to the biases it is supposed to alleviate. And furthermore, the adversarial task should not be correlated to the main task (i.e semantic parsing here), otherwise it may harm the model’s performances. Determining where these b"
N19-2021,Q15-1020,0,0.0307751,"words surrounding the LU. 6 Generalization to PropBank Parsing We further show that this adversarial learning technique can be used on other semantic frameworks such as Propbank. In PropBank Semantic Role Labeling, CoNLL-2005 uses Wall Street Journal (WSJ) for training and two test corpora. The in-domain (ID) test set is derived from WSJ and the out-of-domain (OOD) test set contains ’general fiction’ from the Brown corpus. In published works, there is always an important gap in performances between ID and OOD. Several studies have tried to develop models with better generalization capacities (Yang et al., 2015), (FitzGerald et al., 2015). In recent works, PropBank SRL systems have evolved and span classifier approaches have been replaced by current state of the art sequence tagging models that use recurrent neural networks (He et al., 2017) and neural atten171 biGRU biGRU +AC Target Identification in-domain out-of-domain D1 D2 D3 97.6 95.5 93.3 97.6 95.6 94.3 Frame Identification in-domain out-of-domain D1 D2 D3 93.8 93.4 90.9 95.3 94.5 91.2 Argument Identification in-domain out-of-domain D1 D2 D3 58.2 46.1 43.6 60.0 47.1 45.2 Table 3: Frame semantic parsing performances (Fmax). Models trained on D1"
N19-2021,C08-1050,0,0.0327132,"t to being more strict (resp. less strict) on the highest non-null hypothesis. By doing so we can study the precision/recall (P/R) trade-off of our models. This δ parameter is tuned on a validation set and we either provide the P/R curve or report scores for the F max setting. Robustness in Semantic Frame Parsing In Frame Semantic Parsing, data is scarce and classic evaluation settings seldom propose outof-domain test data. Despite the existence of out-of-domain corpora such MASC (Passonneau et al., 2012) and YAGS (Hartmann et al., 2017) the domain adaptation problem has been widely reported (Johansson and Nugues, 2008; Søgaard et al., 2015) but not extensively studied. Recently, (Hartmann et al., 2017) presented the first in depth study of the domain adaptation problem using the YAGS frame corpus. They show that the main problem in domain adaptation for frame semantic parsing is the frame identification step and propose a more robust classifier using predicate and context embeddings to perform frame identification. This approach is suitable for cascade systems such as SEMAFOR (Das et al., 2014), (Hermann et al., 2014) and (Yang and Mitchell, 2017). In this paper we propose to study the generalization issue"
N19-2021,D17-1302,0,0.0504865,"t (GRU) with highway connections (Srivastava et al., 2015). This model does not rely solely on word embeddings as input. Instead, it has a richer set of features including syntactic, morphological and surface features. (see (Marzinotto et al., 2018b) for more details). Except for words where we use pre-trained embeddings, we use randomly initialized embedding layers for categorical features. In NLP problems this approach has successfully been used to train cross-lingual word representations (Conneau et al., 2017) and to transfer learning from English to low resource languages for POS tagging (Kim et al., 2017) and sentiment analysis (Chen et al., 2016). These approaches introduce language classifiers with an adversarial objective to train task-specific but language agnostic representations. Besides the cross-lingual transfer problem, there are few studies of the impact of domain-adversarial training in a monolingual setup. For instance, (Liu et al., 2017) successfully uses this technique to improve generalization in a document classification task. It has also been used recently for varied tasks such as transfer learning on Q&A systems (Yu et al., 2018) or duplicate question detection (Shah et al.,"
N19-2021,P17-1001,0,0.06826,"Missing"
N19-2021,L18-1159,1,0.864948,"Missing"
N19-2021,C98-1013,0,\N,Missing
N19-2021,Q18-1039,0,\N,Missing
S17-2051,S16-1081,0,0.110665,"Missing"
S17-2051,S16-1172,0,0.0288908,"ed fusion of different similarity measures, some being unsupervised, others supervised. Among the unsupervised measures, many were based on overlap count between components (from n-grams of words or characters to knowledge-based components such as named entities, frame representations, knowledge graphs, e.g. (Franco-Salvador et al., 2016)...). Much attention was also paid for the use of word embeddings (e.g. (Mihaylov and Nakov, 2016)), with question-level averaged vectors used directly with a cosine similarity or as input of a neural classifier. Finally, fusion was often performed with SVMs (Filice et al., 2016) Our motivation in this work was slightly different: we considered that forum data were too noisy to get reliable outputs from linguistic analysis and we wanted to focus on core textual semantic similarity. Hence, we avoided using any metadata analysis (such as user profile...) to get results that could easily generalize to other similarity tasks.Thus, we explore unsupervised similarity measures, with no external resources, hardly any linguistic processing (except a list of stopwords), relying only on the availability of sufficient unannotated corpora representative of the data. And we fuse th"
S17-2051,S16-1126,0,0.243704,"focus on subtaskB, with the purpose of developing semantic textual similarity measures for such noisy texts. Questionquestion similarity appeared in SemEval2016 (Nakov et al., 2016), and is pursued in SemEval2017 (Nakov et al., 2017). The approaches explored last year were mostly supervised fusion of different similarity measures, some being unsupervised, others supervised. Among the unsupervised measures, many were based on overlap count between components (from n-grams of words or characters to knowledge-based components such as named entities, frame representations, knowledge graphs, e.g. (Franco-Salvador et al., 2016)...). Much attention was also paid for the use of word embeddings (e.g. (Mihaylov and Nakov, 2016)), with question-level averaged vectors used directly with a cosine similarity or as input of a neural classifier. Finally, fusion was often performed with SVMs (Filice et al., 2016) Our motivation in this work was slightly different: we considered that forum data were too noisy to get reliable outputs from linguistic analysis and we wanted to focus on core textual semantic similarity. Hence, we avoided using any metadata analysis (such as user profile...) to get results that could easily generali"
S17-2051,S16-1136,0,0.0343159,"texts. Questionquestion similarity appeared in SemEval2016 (Nakov et al., 2016), and is pursued in SemEval2017 (Nakov et al., 2017). The approaches explored last year were mostly supervised fusion of different similarity measures, some being unsupervised, others supervised. Among the unsupervised measures, many were based on overlap count between components (from n-grams of words or characters to knowledge-based components such as named entities, frame representations, knowledge graphs, e.g. (Franco-Salvador et al., 2016)...). Much attention was also paid for the use of word embeddings (e.g. (Mihaylov and Nakov, 2016)), with question-level averaged vectors used directly with a cosine similarity or as input of a neural classifier. Finally, fusion was often performed with SVMs (Filice et al., 2016) Our motivation in this work was slightly different: we considered that forum data were too noisy to get reliable outputs from linguistic analysis and we wanted to focus on core textual semantic similarity. Hence, we avoided using any metadata analysis (such as user profile...) to get results that could easily generalize to other similarity tasks.Thus, we explore unsupervised similarity measures, with no external r"
S17-2051,S17-2003,0,0.0636249,"Missing"
S19-2015,D17-1302,0,0.0458613,"Missing"
S19-2015,P13-1023,0,0.193631,"tagger and we focused on our recursive parsing strategy and on the cross lingual transfer problem to develop a robust model for the French language, using only few training samples. 1 Introduction Semantic representation is an essential part of NLP. For this reason, several semantic representation paradigms have been proposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual semantic representation scheme, has demonstrated applicability in En2 Model Our system consists of a sequence tagger that is first applied on the sentence to extract the main scenes and links and then it is"
S19-2015,C10-1081,0,0.0319072,"2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual semantic representation scheme, has demonstrated applicability in En2 Model Our system consists of a sequence tagger that is first applied on the sentence to extract the main scenes and links and then it is recursively applied on the extracted element to build the semantic graph. At each step of the recursion we use a masking mechanism to feed information about the previous stages into the model. In order to convert the sequence labels into nodes of the UCCA graph we also apply a decoding policy at each stage. Our tagger is implemented using deep bi107 Proceedings of"
S19-2015,P98-1013,0,0.11685,"vely apply our model on the sentence using a masking feature that reflects the decisions made in previous steps. Process continues until the terminal nodes are reached. We choose a standard neural tagger and we focused on our recursive parsing strategy and on the cross lingual transfer problem to develop a robust model for the French language, using only few training samples. 1 Introduction Semantic representation is an essential part of NLP. For this reason, several semantic representation paradigms have been proposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual sem"
S19-2015,L18-1159,1,0.901723,"Missing"
S19-2015,W13-2322,0,0.0398789,"that reflects the decisions made in previous steps. Process continues until the terminal nodes are reached. We choose a standard neural tagger and we focused on our recursive parsing strategy and on the cross lingual transfer problem to develop a robust model for the French language, using only few training samples. 1 Introduction Semantic representation is an essential part of NLP. For this reason, several semantic representation paradigms have been proposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual semantic representation scheme, has demonstrated applicability in E"
S19-2015,W13-3820,0,0.0141242,"oposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual semantic representation scheme, has demonstrated applicability in En2 Model Our system consists of a sequence tagger that is first applied on the sentence to extract the main scenes and links and then it is recursively applied on the extracted element to build the semantic graph. At each step of the recursion we use a masking mechanism to feed information about the previous stages into the model. In order to convert the sequence labels into nodes of the UCCA graph we also apply a decoding policy at each stage. Our tagger"
S19-2015,N19-2021,1,0.857199,"Missing"
S19-2015,J05-1004,0,0.167269,"the main scenes and links and then we recursively apply our model on the sentence using a masking feature that reflects the decisions made in previous steps. Process continues until the terminal nodes are reached. We choose a standard neural tagger and we focused on our recursive parsing strategy and on the cross lingual transfer problem to develop a robust model for the French language, using only few training samples. 1 Introduction Semantic representation is an essential part of NLP. For this reason, several semantic representation paradigms have been proposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu an"
S19-2015,D16-1134,0,0.275857,"Missing"
S19-2015,D07-1002,0,0.0616599,"ction Semantic representation is an essential part of NLP. For this reason, several semantic representation paradigms have been proposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual semantic representation scheme, has demonstrated applicability in En2 Model Our system consists of a sequence tagger that is first applied on the sentence to extract the main scenes and links and then it is recursively applied on the extracted element to build the semantic graph. At each step of the recursion we use a masking mechanism to feed information about the previous stages into the m"
S19-2015,Q17-1010,0,0.0344421,"Missing"
S19-2015,W11-1608,0,0.03239,"l part of NLP. For this reason, several semantic representation paradigms have been proposed. Among them we find PropBank (Palmer et al., 2005) and FrameNet Semantics (Baker et al., 1998), Abstract Meaning Representation (AMR) (Banarescu et al., 2013), Universal Decompositional Semantics (White et al., 2016) and Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013). These constantly improving representations, along with the advances in semantic parsing, have proven to be beneficial in many NLU tasks such as Question Answering (Shen and Lapata, 2007), text summarization (Genest and Lapalme, 2011), dialog systems (Tur et al., 2005), information extraction (Bastianelli et al., 2013) and machine translation (Liu and Gildea, 2010). UCCA is a cross-lingual semantic representation scheme, has demonstrated applicability in En2 Model Our system consists of a sequence tagger that is first applied on the sentence to extract the main scenes and links and then it is recursively applied on the extracted element to build the semantic graph. At each step of the recursion we use a masking mechanism to feed information about the previous stages into the model. In order to convert the sequence labels i"
S19-2015,K17-3009,0,0.0384453,"Missing"
S19-2015,P17-1044,0,0.0319668,"odel. In order to convert the sequence labels into nodes of the UCCA graph we also apply a decoding policy at each stage. Our tagger is implemented using deep bi107 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 107–112 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics directional GRU (biGRU). This simple architecture is frequently used in semantic parsers across different representation paradigms. Besides its flexibility, it is a powerful model, with close to state of the art performance on both PropBank (He et al., 2017) and FrameNet semantic parsing (Yang and Mitchell, 2017; Marzinotto et al., 2018b). More precisely, the model consists of a 4 layer bi-directional Gated Recurrent Unit (GRU) with highway connections (Srivastava et al., 2015). Our model uses has a rich set of features including syntactic, morphological, lexical and surface features, which have shown to be useful in language abstracted representations. The list is given below: To train such a model, we build a new training corpus in which the sentences are repeated several times. More precisely, a sentence appears N times (N being the number of"
S19-2015,P17-1104,0,0.0603676,"seful for defining semantic evaluation measures in textto-text generation and machine translation (Birch et al., 2016). UCCA represents the semantics of a sentence using directed acyclic graphs (DAGs), where terminal nodes correspond to text tokens, and non-terminal nodes to higher level semantic units. Edges are labelled, indicating the role of a child in the relation to its parent. UCCA parsing is a recent task and since UCCA has several unique properties, adapting syntactic parsers or parsers from other semantic representations is not straight-forward. Current state of the art parser TUPA (Hershcovich et al., 2017) uses a transition based parsing to build UCCA representations. Building over previous work on FrameNet Semantic Parsing (Marzinotto et al., 2018a,b) we chose to perform UCCA parsing using sequence tagging methods along with a graph decoding policy. To do this we propose a recursive strategy in which we perform a first inference on the sentence to extract the main scenes and links and then we recursively apply our model on the sentence with a masking mechanism at the input in order to feed information about the previous parsing decisions. This paper describes our recursive system for SemEval-2"
S19-2015,D17-1128,0,0.0163775,"to nodes of the UCCA graph we also apply a decoding policy at each stage. Our tagger is implemented using deep bi107 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 107–112 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics directional GRU (biGRU). This simple architecture is frequently used in semantic parsers across different representation paradigms. Besides its flexibility, it is a powerful model, with close to state of the art performance on both PropBank (He et al., 2017) and FrameNet semantic parsing (Yang and Mitchell, 2017; Marzinotto et al., 2018b). More precisely, the model consists of a 4 layer bi-directional Gated Recurrent Unit (GRU) with highway connections (Srivastava et al., 2015). Our model uses has a rich set of features including syntactic, morphological, lexical and surface features, which have shown to be useful in language abstracted representations. The list is given below: To train such a model, we build a new training corpus in which the sentences are repeated several times. More precisely, a sentence appears N times (N being the number of non terminal nodes in the UCCA graph) each one a with d"
W04-2321,P00-1011,1,\N,Missing
W04-2321,P03-1006,0,\N,Missing
W07-0307,P03-1006,0,0.014449,"Rate (WER), Concept Error Rate (CER) and Interpretation Error Rate (IER) according to the SLU strategy γˆ = argmaxP (γ|C)P (C|W )P (W |Y ) W,C,γ The stochastic models proposed are implemented with a Finite State Machine (FSM) paradigm thanks to the AT&T FSM toolkit (Mohri et al., 2002). Following the approach described in (Raymond et al., 2006), the SLU first stage is implemented by means of a word-to-concept transducer that translates a word lattice into a concept lattice. This concept lattice is rescored with a Language Model on the concepts (also encoded as FSMs with the AT&T GRM toolkit (Allauzen et al., 2003)). The rule database of the SLU second stage is encoded as a transducer that takes as input concepts and output semantic interpretations γ. By applying this transducer to an FSM representing a concept lattice, we directly obtain a lattice of interpretations. 53 The comparison among the two strategies is given in table 4. As we can see a small improvement is obtained for the interpretation error rate (IER) with the integrated strategy (strat2). This gain is small; however it is interesting to look at the Oracle IER that can be obtained on an n-best list of interpretations produced by each strat"
W07-0307,H90-1021,0,0.384908,"Missing"
W16-3621,bazillon-etal-2012-syntactic,1,0.849545,"d to tweets and that adaptation with in-domain data helps increasing these performances. More recently (Kong et al., 2014) described a dependency parser for tweets. However, to the best of our knowledge, no such study has been published on social media data from formal on line web conversations. We believe that the current models used in the fields of syntactic and semantic parsing are mature enough to go beyond normative data that we find in benchmark corpora and process text that comes from CRM chat. The experience we gathered on parsing speech transcriptions in the framework of the DECODA (Bazillon et al., 2012) and ORFEO (Nasr et al., 2014) projects showed that current parsing techniques can be successfully used to parse disfluent speech transcriptions. Syntactic parsing of non canonical textual input in the context of human-human conversations has been mainly studied in the context of textual transcription of spontaneous speech. In such data, the variation with respect to canonical written text comes mainly from syntactic structures that are specific to spontaneous speech, as well as disfluencies, such as filled pauses, repetitions and false starts. Our input has some of the specificities of sponta"
W16-3621,D13-1035,0,0.0134229,"ra Guerraz2 , Frederic Bechet1 (1) Aix Marseille Universite - CNRS-LIF, Marseille, France (2) Orange Labs - Lannion, France Abstract Recent projects in Europe, such as the CoMeRe (Chanier et al., 2014) or the STAC (Asher, 2011) project gathered collections of CMC data in several languages in order to study this new kind of language. Most of the effort has been dedicated to ”chat room” data as it is the kind of data which is the most accessible on the WEB. (Achille, 2005) constituted a corpus in French. (Forsyth and Martell, 2007) and (Shaikh et al., 2010) describe similar corpora in English. (Cadilhac et al., 2013) have studied the relational structure of such conversations through a deep discursive analysis of chat sessions in an online video game. This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers. This study is realized in the context of the DATCHA project, a collaborative project funded by the French National Research Agency, which aims at performing unsupervised knowledge extraction from very large databases of WEB chat conversations between operators and clients in"
W16-3621,L16-1319,1,0.841476,"here are no repetitions nor false starts. Orthographic errors are numerous and some of them are challenging for a syntactic parser. We present in this paper a detailed analysis of the impact of all these phenomena on syntactic parsing. Other types of social media data have been studied in the literature. In particular tweets have received lately more attention. (Ritter et al., 2011) for example provide a detailed evaluation of a pos tagger on tweets, with the final objec4 A study on orthographic errors in agent/customer chat dialogs Chat conversations are unique from several perspectives. In (Damnati et al., 2016), we conducted a study comparing contact center chat conversations and phone conversations, both in the domain of technical assistance for Orange customers. The comparative analysis showed significant differences in terms of interaction flow. If chat conversations were on average twice as long in terms of effective duration, phone conversations contain on average four times more turns than chat conversations. This can be explained by several factors: chat is not an exclusive activity and latencies are more easily accepted than in an oral conversation. Chat utterances are formulated in a more d"
W16-3621,D14-1108,0,0.0569385,"rd. ok fine within 48h maximum 72h for the card You will receive it according to delivery time at the address in your record. ok fine thank you You’re welcome Before you go, do you any other question? no thank you Figure 1: Example of conversation in the TV assistance domain, in its original forme (above) and a translation without errors (below) 177 tive of performing Named Entity detection. They showed that the performances of a classical tagger trained on generic news data drop when applied to tweets and that adaptation with in-domain data helps increasing these performances. More recently (Kong et al., 2014) described a dependency parser for tweets. However, to the best of our knowledge, no such study has been published on social media data from formal on line web conversations. We believe that the current models used in the fields of syntactic and semantic parsing are mature enough to go beyond normative data that we find in benchmark corpora and process text that comes from CRM chat. The experience we gathered on parsing speech transcriptions in the framework of the DECODA (Bazillon et al., 2012) and ORFEO (Nasr et al., 2014) projects showed that current parsing techniques can be successfully u"
W16-3621,2005.jeptalnrecital-recital.10,0,0.11855,"Missing"
W16-3621,nasr-etal-2014-automatically,1,0.860161,"th in-domain data helps increasing these performances. More recently (Kong et al., 2014) described a dependency parser for tweets. However, to the best of our knowledge, no such study has been published on social media data from formal on line web conversations. We believe that the current models used in the fields of syntactic and semantic parsing are mature enough to go beyond normative data that we find in benchmark corpora and process text that comes from CRM chat. The experience we gathered on parsing speech transcriptions in the framework of the DECODA (Bazillon et al., 2012) and ORFEO (Nasr et al., 2014) projects showed that current parsing techniques can be successfully used to parse disfluent speech transcriptions. Syntactic parsing of non canonical textual input in the context of human-human conversations has been mainly studied in the context of textual transcription of spontaneous speech. In such data, the variation with respect to canonical written text comes mainly from syntactic structures that are specific to spontaneous speech, as well as disfluencies, such as filled pauses, repetitions and false starts. Our input has some of the specificities of spontaneous speech but adds new ones"
W16-3621,W03-3017,0,0.0902461,"ine of the table corresponds to the status of a token. If the token is correct, the status is CORR, otherwise it corresponds to one label of the split REF HYP tok tag tok tag AB TAB A TA B TB Table 5: Conventions defined when computing the accuracy of the tagger for a token. Tags in bold face are compared 181 status CORR DIACR AGGLU SUB1C INFL DEL1C OTHER INS1C APOST SPLIT SWITCH occ. 5916 201 76 46 67 43 40 20 47 6 2 corr. 5547 120 23 13 45 22 23 12 40 3 2 acc. 93.76 59.70 30.26 28.26 67.16 51.16 57.50 60.00 85.11 50.00 100.00 contrib. 59.23 13.00 8.51 5.30 3.53 3.37 2.73 1.28 1.12 0.48 0.00 Nivre, 2003). It is a dependency parser that takes as input tokens with their pos tag and selects for every token a syntactic governor (which is another token of the sentence) and a syntactic label. The prediction is based on several features that combine lexical information and pos tags. Orthographic errors have therefore a double impact on the parsing process: through the errors they provoke on the pos tagging process and the errors they provoke directly on the parsing process. The parser was trained on the French Treebank. Contrary to taggers, a single parser was used for our experiments since we do no"
W16-3621,D11-1141,0,0.0851138,"Missing"
W16-3621,shaikh-etal-2010-mpc,0,0.0320112,"rsation corpus Alexis Nasr1 , Geraldine Damnati2 , Aleksandra Guerraz2 , Frederic Bechet1 (1) Aix Marseille Universite - CNRS-LIF, Marseille, France (2) Orange Labs - Lannion, France Abstract Recent projects in Europe, such as the CoMeRe (Chanier et al., 2014) or the STAC (Asher, 2011) project gathered collections of CMC data in several languages in order to study this new kind of language. Most of the effort has been dedicated to ”chat room” data as it is the kind of data which is the most accessible on the WEB. (Achille, 2005) constituted a corpus in French. (Forsyth and Martell, 2007) and (Shaikh et al., 2010) describe similar corpora in English. (Cadilhac et al., 2013) have studied the relational structure of such conversations through a deep discursive analysis of chat sessions in an online video game. This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers. This study is realized in the context of the DATCHA project, a collaborative project funded by the French National Research Agency, which aims at performing unsupervised knowledge extraction from very large database"
W16-3621,W03-3023,0,0.127109,"Missing"
W19-5121,S17-1006,0,0.196115,"Missing"
W19-5121,J13-1009,0,0.062952,"Missing"
W19-5121,W18-4920,0,0.033138,"Missing"
W19-5121,C18-1139,0,0.0277841,"ation, we used the gensim library7 to train 256-dimensional vectors for both forms and lemmas on the training corpus of the shared task for 10 epochs. Furthermore, all embeddings use the CBOW algorithm with the same hyper-parameter values of 5 for the window size (left/right context of words) and 1 for min-count (minimum number of occurrences of words). For FastText, we set the size of character n-grams to 1 to combine the whole word’s embedding with the embeddings of its characters. We did not use contextual representations, like BERT, Elmo or Flair (Devlin et al., 2018; Peters et al., 2018; Akbik et al., 2018), because they have to be pre-trained on large corpora and we wanted to have an experimental setup compatible with the closed track of the PARSEME shared task. tal setup implies that it is difficult for a system to predict a VMWE without a reliable representation for a verb, learned from the training data. MWE Identification System We use our inhouse MWE identification system Veyn (Zampieri et al., 2018), based on sequence tagging using recurrent neural networks.5 The system takes as input the concatenation of the embeddings of the words’ features (e.g. lemmas and POS). It uses a CRF output la"
W19-5121,W17-1707,0,0.122077,"Missing"
W19-5121,Q17-1010,0,0.27521,"gical and syntactic variability (Savary et al., 2018). Our goal is to study the impact of word representations on verbal MWE (VMWE) identification, comparing lemmas, surface forms, traditional word embeddings and subword representations. We compare the performance of an off-the-shelf MWE identification system based on neural sequence tagging (Zampieri et al., 2018) using lemmas and surface forms as input features, encoded in the form of classical pre-initialised word2vec embeddings (Mikolov et al., 2013) or, alternatively, using new-generation FastText embeddings built from character n-grams (Bojanowski et al., 2017). Our main hypothesis is that the latter can model morphological variability, representing an alternative for lemmatisation. We carry out experiments in 3 languages with varying morphological complexity: French, Polish and Basque. Recent initiatives such as the PARSEME shared task have allowed the rapid development of MWE identification systems. Many of those are based on recent NLP advances, using neural sequence models that take continuous word representations as input. We study two related questions in neural verbal MWE identification: (a) the use of lemmas and/or surface forms as input fea"
W19-5121,P16-1101,0,0.0908242,"Missing"
W19-5121,J17-4005,1,0.906443,"Missing"
W19-5121,N18-1202,0,0.0419821,"). For each representation, we used the gensim library7 to train 256-dimensional vectors for both forms and lemmas on the training corpus of the shared task for 10 epochs. Furthermore, all embeddings use the CBOW algorithm with the same hyper-parameter values of 5 for the window size (left/right context of words) and 1 for min-count (minimum number of occurrences of words). For FastText, we set the size of character n-grams to 1 to combine the whole word’s embedding with the embeddings of its characters. We did not use contextual representations, like BERT, Elmo or Flair (Devlin et al., 2018; Peters et al., 2018; Akbik et al., 2018), because they have to be pre-trained on large corpora and we wanted to have an experimental setup compatible with the closed track of the PARSEME shared task. tal setup implies that it is difficult for a system to predict a VMWE without a reliable representation for a verb, learned from the training data. MWE Identification System We use our inhouse MWE identification system Veyn (Zampieri et al., 2018), based on sequence tagging using recurrent neural networks.5 The system takes as input the concatenation of the embeddings of the words’ features (e.g. lemmas and POS). It"
W19-5121,Q14-1016,0,0.121795,"ons and WordNet (MWE-WN 2019), pages 169–175 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics 3 popular models for MWE identification (Constant et al., 2017). Parsing-based methods take the (recursive) structure of language into account, trying to identify MWEs as a by-product of parsing (Green et al., 2013; Constant et al., 2013), or jointly (Constant and Nivre, 2016). Sequence tagging models, on the other hand, consider only linear context, using models such as CRFs (Vincze et al., 2011; Shigeto et al., 2013; Riedl and Biemann, 2016) and averaged perceptron (Schneider et al., 2014) combined with some variant of begin-inside-outside (BIO) encoding (Ramshaw and Marcus, 1995). Experimental Setup Corpora The PARSEME shared task 1.1 released freely available VMWE-annotated corpora in 20 languages.1 Each language’s corpus is split into training, development and test parts. To choose our target languages, we analysed the PARSEME corpora, choosing 3 languages with varying morphological richness: Basque (EU), French (FR) and Polish (PL), shown in Table 1.2 The FR training corpus has more than 420K tokens, whereas the PL and EU training corpora have around 220K and 117K tokens. E"
W19-5121,S16-1084,0,0.0197434,"many years, MWE identification was considered unrealistic, with most MWE research focusing on out-of-context MWE discovery (Ramisch et al., 2013). Indeed, the availability of MWE-annotated corpora was limited to some treebanks with partial annotations, often a by-product of syntax trees (Green et al., 2013; Constant et al., 2013). This prevented the widespread development and evaluation of MWE identification systems, as compared to other tasks such as POS tagging and named entity recognition. This landscape has drastically changed in the last few years, thanks to shared tasks such as DiMSUM (Schneider et al., 2016) and PARSEME 1.0 and 1.1 (Savary et al., 2017; Ramisch et al., 2018) and to the release of open corpora annotated for MWEs in ∼20 languages. These initiatives provide a unified framework for MWE identifi2 Related Work Rule-based matching, supervised classification, sequence tagging, and parsing are among the most 169 Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019), pages 169–175 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics 3 popular models for MWE identification (Constant et al., 2017). Parsing-based methods take the (re"
W19-5121,W95-0107,0,0.136505,"ation for Computational Linguistics 3 popular models for MWE identification (Constant et al., 2017). Parsing-based methods take the (recursive) structure of language into account, trying to identify MWEs as a by-product of parsing (Green et al., 2013; Constant et al., 2013), or jointly (Constant and Nivre, 2016). Sequence tagging models, on the other hand, consider only linear context, using models such as CRFs (Vincze et al., 2011; Shigeto et al., 2013; Riedl and Biemann, 2016) and averaged perceptron (Schneider et al., 2014) combined with some variant of begin-inside-outside (BIO) encoding (Ramshaw and Marcus, 1995). Experimental Setup Corpora The PARSEME shared task 1.1 released freely available VMWE-annotated corpora in 20 languages.1 Each language’s corpus is split into training, development and test parts. To choose our target languages, we analysed the PARSEME corpora, choosing 3 languages with varying morphological richness: Basque (EU), French (FR) and Polish (PL), shown in Table 1.2 The FR training corpus has more than 420K tokens, whereas the PL and EU training corpora have around 220K and 117K tokens. EU contains less annotated VMWE occurrences than both FR and PL. The average length of annotat"
W19-5121,W13-1021,0,0.0269041,"ong the most 169 Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019), pages 169–175 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics 3 popular models for MWE identification (Constant et al., 2017). Parsing-based methods take the (recursive) structure of language into account, trying to identify MWEs as a by-product of parsing (Green et al., 2013; Constant et al., 2013), or jointly (Constant and Nivre, 2016). Sequence tagging models, on the other hand, consider only linear context, using models such as CRFs (Vincze et al., 2011; Shigeto et al., 2013; Riedl and Biemann, 2016) and averaged perceptron (Schneider et al., 2014) combined with some variant of begin-inside-outside (BIO) encoding (Ramshaw and Marcus, 1995). Experimental Setup Corpora The PARSEME shared task 1.1 released freely available VMWE-annotated corpora in 20 languages.1 Each language’s corpus is split into training, development and test parts. To choose our target languages, we analysed the PARSEME corpora, choosing 3 languages with varying morphological richness: Basque (EU), French (FR) and Polish (PL), shown in Table 1.2 The FR training corpus has more than 420K tokens,"
W19-5121,W16-1816,0,0.10689,"edings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019), pages 169–175 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics 3 popular models for MWE identification (Constant et al., 2017). Parsing-based methods take the (recursive) structure of language into account, trying to identify MWEs as a by-product of parsing (Green et al., 2013; Constant et al., 2013), or jointly (Constant and Nivre, 2016). Sequence tagging models, on the other hand, consider only linear context, using models such as CRFs (Vincze et al., 2011; Shigeto et al., 2013; Riedl and Biemann, 2016) and averaged perceptron (Schneider et al., 2014) combined with some variant of begin-inside-outside (BIO) encoding (Ramshaw and Marcus, 1995). Experimental Setup Corpora The PARSEME shared task 1.1 released freely available VMWE-annotated corpora in 20 languages.1 Each language’s corpus is split into training, development and test parts. To choose our target languages, we analysed the PARSEME corpora, choosing 3 languages with varying morphological richness: Basque (EU), French (FR) and Polish (PL), shown in Table 1.2 The FR training corpus has more than 420K tokens, whereas the PL and EU tra"
W19-5121,N19-1275,0,0.376069,"Missing"
W19-5121,W18-4933,1,0.891813,"words than a system based on lemmas, especially for morphologically-rich languages in which a single lemma may correspond to dozens of surface forms (Seddah et al., 2013). This problem is particularly relevant for verbal MWEs, which present high morphological and syntactic variability (Savary et al., 2018). Our goal is to study the impact of word representations on verbal MWE (VMWE) identification, comparing lemmas, surface forms, traditional word embeddings and subword representations. We compare the performance of an off-the-shelf MWE identification system based on neural sequence tagging (Zampieri et al., 2018) using lemmas and surface forms as input features, encoded in the form of classical pre-initialised word2vec embeddings (Mikolov et al., 2013) or, alternatively, using new-generation FastText embeddings built from character n-grams (Bojanowski et al., 2017). Our main hypothesis is that the latter can model morphological variability, representing an alternative for lemmatisation. We carry out experiments in 3 languages with varying morphological complexity: French, Polish and Basque. Recent initiatives such as the PARSEME shared task have allowed the rapid development of MWE identification syst"
W19-5914,D18-1241,0,0.0321279,"dialogue components and several question answering back-ends, which rely on data provided by Wikidata1 . Interaction with a human user is achieved through a graphical user interface (GUI). Figure 1 depicts the components together with their interactions. Introduction Conversational question answering is an open research problem. It studies the integration of question answering (QA) systems in a dialogue system(DS). Not long ago, each of these research subjects were studied separately; only very recently has studying the intersection between them gained increasing interest (Reddy et al., 2018; Choi et al., 2018). We present a spoken conversational question answering system that is able to answer questions about general knowledge in French by calling two distinct QA systems. It solves coreference and ellipsis by modelling context. Furthermore, it is extensible, thus other components such as neural approaches for question-answering can be easily integrated. It is also possible to collect a dialogue corpus from its iterations. In contrast to most conversational systems which support only speech, two input and output modalities are supported speech and text. Thus it is possible to let the user check the"
W19-5914,D17-1018,0,0.0467956,"Missing"
W19-5914,L18-1159,1,0.800452,"Missing"
W19-5914,Q19-1016,0,0.0457819,"Missing"
W19-5914,K17-3009,0,0.0308447,"Missing"
W19-5914,Q17-1010,0,\N,Missing
