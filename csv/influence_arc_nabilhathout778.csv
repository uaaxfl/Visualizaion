2002.jeptalnrecital-long.22,P99-1068,0,0.0159567,"GoogleTM et autre AltaVistaTM. Notre approche n’échappe pas à ce filtre, et nous ne travaillons, comme tous les autres « webolinguistes », que sur la partie du Web (dont la proportion est d’ailleurs inconnue) indexée par ces moteurs, et donc sur un sous-ensemble des pages accessible qui varie avec le temps, et sur lequel aucun critère de sélection fiable n’est applicable. La question se pose alors du type d’études sur corpus pour lesquelles le recours au Web est justifié. Les études actuelles vont du repérage d’entités nommées (Jacquemin et Bush 2000) à l’étude de textes parallèles bilingues (Resnik 1999), et en règle générale se limitent à l’étude d’unités lexicales en utilisant des extracteurs de contextes et des mesures de cooccurrence. Il paraît en effet plus délicat de mener des études relevant de la syntaxe ou de la sémantique sur un corpus aussi « incontrôlable », et pour lequel on dispose de si peu d’informations. Nous nous situons ici dans le cadre de la morphologie, avec comme but affiché de constituer des ressources facilement réutilisables. Nous proposons une méthode permettant de construire des bases de données lexicales, dont la couverture va croissante, et dont le contenu peut ê"
2004.jeptalnrecital-long.6,E93-1028,0,0.0435506,"Missing"
2004.jeptalnrecital-long.6,J98-1001,0,0.152324,"Missing"
2009.jeptalnrecital-long.1,W02-0603,0,0.0594547,"Missing"
2009.jeptalnrecital-long.1,W98-1239,0,0.0915732,"Missing"
2009.jeptalnrecital-long.1,W99-0904,0,0.0812516,"Missing"
2009.jeptalnrecital-long.1,J01-2001,0,0.0403763,"Missing"
2009.jeptalnrecital-long.1,hathout-2002-wordnet,1,0.763972,"Missing"
2009.jeptalnrecital-long.1,D07-1092,0,0.364246,"Missing"
2009.jeptalnrecital-long.1,P98-1120,0,0.0885404,"Missing"
2009.jeptalnrecital-long.1,W06-3811,1,0.874575,"Missing"
2009.jeptalnrecital-long.1,W02-0604,0,0.0605547,"Missing"
2009.jeptalnrecital-long.1,W00-0712,0,0.0616698,"Missing"
2009.jeptalnrecital-long.1,W05-0616,0,0.261032,"Missing"
2009.jeptalnrecital-long.1,P00-1027,0,0.0478729,"Missing"
2011.jeptalnrecital-court.35,P98-1120,0,0.0219407,"tué des 100 mots qui sont morphologiquement les plus proches de l&apos;entrée. Ces voisinages sont définis par une mesure qui rapproche les mots qui partagent le plus grand nombre possible de propriétés formelles (n-grammes de lettres ou de phonèmes) les plus spécifiques possible (Hathout, 2009). La mesure est calculée au moyen d&apos;un algorithme de propagation d&apos;activation inspiré des travaux de Gaume (2004). Cette mesure est différente de la distance d&apos;édition de Levenshtein. (b) la découverte de l&apos;ensemble des analogies formelles qui s&apos;établissent entre les entrées et les mots de leurs voisinages (Lepage, 1998; Stroppa et Yvon, 2006). Afin de réduire la complexité de cette exploration, ces analogies sont identifiées sur la base de signatures d&apos;édition (séquence d&apos;opérations d&apos;édition) calculées pour chaque couple (m, v) où m est une entrée et v un de ses voisins. Les couples qui partagent les mêmes signatures forment des analogies (Hathout, 2009). (c) l&apos;utilisation de trois critères pour séparer les familles des séries et pour sélectionner les paradigmes qui comportent le moins d&apos;erreurs possible. Le premier est un critère catégoriel qui permet de séparer les relations familiales des relations séri"
2011.jeptalnrecital-court.5,2007.jeptalnrecital-long.34,0,0.0895264,"Missing"
2011.jeptalnrecital-court.5,2008.jeptalnrecital-court.10,1,0.829059,"Missing"
2011.jeptalnrecital-court.5,2009.jeptalnrecital-court.14,1,0.844763,"Missing"
2011.jeptalnrecital-court.5,W99-0904,0,0.129856,"Missing"
2011.jeptalnrecital-court.5,E09-1056,0,0.0206157,"Missing"
2011.jeptalnrecital-court.5,2010.jeptalnrecital-demonstration.16,1,0.820922,"Missing"
2011.jeptalnrecital-court.5,2003.jeptalnrecital-long.27,0,0.120239,"Missing"
2014.lilt-11.6,W08-2205,0,0.0167697,"h other through multiple relations: a base word is connected to many derivatives, and derived words from the same family and series are related to each other. Second, each word is semantically typed, and its meaning is paraphrased via several definitions, one for each of the word’s relations with other words. Third, these features are also available for morphologically simple words, as all relations are bi-oriented. These three properties can be exploited for various tasks in language technol´monette, a French derivational morpho-semantic network / 161 De ogy and NLP applications. As noted in Clark et al. (2008), the analysis of textual content can be improved through the enrichment of lexical resources with semantic annotations. Furthermore, word-to-word relations and their associated definitions facilitate word selection and the identification of lexical meaning. Similar to WordNet and Wolf, these capabilities can be advantageous for natural language processing applications (e.g., word-sense disambiguation, information retrieval). Moreover, they can be used in tools designed for content production: the ability to choose between words based on the relations between them, their semantic types and the"
2014.lilt-11.6,P03-1036,0,0.10268,"any have been developed over the past two decades to meet the needs of morphological analysis in NLP and to overcome the limitations of the lexicons. Such parsers split words into morphemes. Some of them add labels to identify morpheme variants. They are usually based on the Harrisian model (Harris 1955) and on a variety of machine learning methods. Therefore, they are relatively language independent, although many are designed to yield better results for Western European concatenative languages such as English, German and French. These systems include Linguistica (Goldsmith 2001), Morfessor (Creutz 2003; Creutz and Lagus 2005) and Bernhard’s (2006) parser. In this respect, this trend is similar to 128 / LiLT volume 11, issue 5 December 2014 that observed in POS-tagging and syntactic parsing. Other systems, grounded in more recent morphological theories have also been developed, such as D´eriF (Namer 2009), which is presented in Section 2.2 (for a general overview, see (Bernhard et al. 2011; Namer 2013b)). Morphological descriptions may also be found in certain general lexical semantic resources, such as wordnets (Fellbaum 1999) or Jeux de Mots (Lafourcade and Joubert 2013). Princeton WordNet"
2014.lilt-11.6,J01-2001,0,0.131782,"orin 2011) for a summary). Many have been developed over the past two decades to meet the needs of morphological analysis in NLP and to overcome the limitations of the lexicons. Such parsers split words into morphemes. Some of them add labels to identify morpheme variants. They are usually based on the Harrisian model (Harris 1955) and on a variety of machine learning methods. Therefore, they are relatively language independent, although many are designed to yield better results for Western European concatenative languages such as English, German and French. These systems include Linguistica (Goldsmith 2001), Morfessor (Creutz 2003; Creutz and Lagus 2005) and Bernhard’s (2006) parser. In this respect, this trend is similar to 128 / LiLT volume 11, issue 5 December 2014 that observed in POS-tagging and syntactic parsing. Other systems, grounded in more recent morphological theories have also been developed, such as D´eriF (Namer 2009), which is presented in Section 2.2 (for a general overview, see (Bernhard et al. 2011; Namer 2013b)). Morphological descriptions may also be found in certain general lexical semantic resources, such as wordnets (Fellbaum 1999) or Jeux de Mots (Lafourcade and Joubert"
2014.lilt-11.6,N03-1013,0,0.0527152,"prehensive description of these three lexicons that includes phonology, inflectional and derivational morphology, syntactic categories and corpus frequency. CELEX adopts a conventional model of derivational morphology: lexemes have morphological structures that are represented as morpheme decompositions, as in (16) for the noun occupation. CELEX contains no lexical semantic relations and provides no characterization of word meaning. (16) ((occupy)[V],(ation)[N|V.])[N] There are also more modest derivational resources that essentially provide morphologically related word pairs, such as CatVar (Habash and Dorr 2003) for English or DerivBase for German (Zeller et al. 2013). A more sophisticated resource, Morphonette (Hathout 2011), is described in detail in Section 2.3. Note that more specialized resources have also been created for French, such as Verbaction (Tanguy and Hathout 2002; see Section 5). Work related to the construction of derivational morphological resources is relatively scarce. Most efforts in computer morphology have focused on the development of morphological analyzers (see (Hammarstr¨ om and Borin 2011) for a summary). Many have been developed over the past two decades to meet the needs"
2014.lilt-11.6,J11-2002,0,0.0601032,"Missing"
2014.lilt-11.6,hathout-etal-2014-glaff,1,0.857749,"ces and tools share ´monette, a French derivational morpho-semantic network / 127 De some of these characteristics. The most common morphological resources are inflectional lexicons. Several large inflectional lexicons exist for French, such as Lefff (Sagot et al. 2006), which also includes syntactic subcategorization frames; Morphalou (Romary et al. 2004) or TLFnome, which were created from ` the Tr´esor de la Langue Fran¸caise word list, and GLAFF, which was extracted from the French Wiktionary and is notable for its significantly larger size and phonemic transcriptions (Sajous et al. 2013; Hathout et al. 2014). In addition to these inflectional resources, some derivational morphological resources are available, though much fewer in number. The best known is certainly CELEX, which addresses English, German and Dutch (Baayen et al. 1995). It provides a comprehensive description of these three lexicons that includes phonology, inflectional and derivational morphology, syntactic categories and corpus frequency. CELEX adopts a conventional model of derivational morphology: lexemes have morphological structures that are represented as morpheme decompositions, as in (16) for the noun occupation. CELEX con"
2014.lilt-11.6,P98-1120,0,0.194235,"represent all derivational relations between TLFnome entries (Hathout 2011). Their identification is conducted in three steps. (a) Select, for each entry, a neighborhood consisting of the 100 most morphologically similar words. This neighborhood is defined by the Proxinette measure (Hathout 2009, 2014). The similarity of two words is estimated with respect to the number and specificity of the formal features (n-grams of characters) they share. Proxinette is comparable to the distance of De Pauw and Wagacha (2007). (b) Collect all formal analogies that exist between an entry and its neighbors (Lepage 1998; Stroppa and Yvon 2005). Analogies are identified on the basis of editing signatures calculated for each pair (w, u), ´monette, a French derivational morpho-semantic network / 135 De where w is an entry and u is one of its neighbors (Lepage 2004; Gosme and Lepage 2009). Pairs that share the same signature form analogies. (c) Apply three criteria to separate families from series and to select the quadruplets that are more likely to be morphologically valid. . The first is a categorical criterion that separates relations between family members from relations between series members in analogies"
2014.lilt-11.6,P04-1036,0,0.0129145,"these capabilities can be advantageous for natural language processing applications (e.g., word-sense disambiguation, information retrieval). Moreover, they can be used in tools designed for content production: the ability to choose between words based on the relations between them, their semantic types and their bases and to replace them with paraphrases is of significant benefit to computer-aided translation, text summarization, standardization and generation. In association with other distributional bases (Turney and Pantel 2010), D´emonette can also be used for lexical substitution tasks (McCarthy et al. 2004) and semantic categorization (Tsatsaronis and Panagiotopoulou 2009). Conclusion In this paper, we have presented the first version of D´emonette, a lexical resource that currently contains 31,204 morphologically annotated entries and was constructed automatically from the results produced by two systems that implement two different approaches to Word Formation theories: Morphonette, which is based on formal analogies between lexemes and implements theoretical principles of relational and paradigmatic morphology, and D´eriF, which exploits oriented linguistic rules that have been manually desig"
2014.lilt-11.6,2002.jeptalnrecital-long.21,1,0.705543,"Missing"
2014.lilt-11.6,W07-1710,0,0.0797997,"Missing"
2014.lilt-11.6,W05-0616,0,0.0858594,"derivational relations between TLFnome entries (Hathout 2011). Their identification is conducted in three steps. (a) Select, for each entry, a neighborhood consisting of the 100 most morphologically similar words. This neighborhood is defined by the Proxinette measure (Hathout 2009, 2014). The similarity of two words is estimated with respect to the number and specificity of the formal features (n-grams of characters) they share. Proxinette is comparable to the distance of De Pauw and Wagacha (2007). (b) Collect all formal analogies that exist between an entry and its neighbors (Lepage 1998; Stroppa and Yvon 2005). Analogies are identified on the basis of editing signatures calculated for each pair (w, u), ´monette, a French derivational morpho-semantic network / 135 De where w is an entry and u is one of its neighbors (Lepage 2004; Gosme and Lepage 2009). Pairs that share the same signature form analogies. (c) Apply three criteria to separate families from series and to select the quadruplets that are more likely to be morphologically valid. . The first is a categorical criterion that separates relations between family members from relations between series members in analogies in which the four words"
2014.lilt-11.6,2002.jeptalnrecital-long.22,1,0.561448,"esented as morpheme decompositions, as in (16) for the noun occupation. CELEX contains no lexical semantic relations and provides no characterization of word meaning. (16) ((occupy)[V],(ation)[N|V.])[N] There are also more modest derivational resources that essentially provide morphologically related word pairs, such as CatVar (Habash and Dorr 2003) for English or DerivBase for German (Zeller et al. 2013). A more sophisticated resource, Morphonette (Hathout 2011), is described in detail in Section 2.3. Note that more specialized resources have also been created for French, such as Verbaction (Tanguy and Hathout 2002; see Section 5). Work related to the construction of derivational morphological resources is relatively scarce. Most efforts in computer morphology have focused on the development of morphological analyzers (see (Hammarstr¨ om and Borin 2011) for a summary). Many have been developed over the past two decades to meet the needs of morphological analysis in NLP and to overcome the limitations of the lexicons. Such parsers split words into morphemes. Some of them add labels to identify morpheme variants. They are usually based on the Harrisian model (Harris 1955) and on a variety of machine learn"
2014.lilt-11.6,E09-3009,0,0.0224448,"language processing applications (e.g., word-sense disambiguation, information retrieval). Moreover, they can be used in tools designed for content production: the ability to choose between words based on the relations between them, their semantic types and their bases and to replace them with paraphrases is of significant benefit to computer-aided translation, text summarization, standardization and generation. In association with other distributional bases (Turney and Pantel 2010), D´emonette can also be used for lexical substitution tasks (McCarthy et al. 2004) and semantic categorization (Tsatsaronis and Panagiotopoulou 2009). Conclusion In this paper, we have presented the first version of D´emonette, a lexical resource that currently contains 31,204 morphologically annotated entries and was constructed automatically from the results produced by two systems that implement two different approaches to Word Formation theories: Morphonette, which is based on formal analogies between lexemes and implements theoretical principles of relational and paradigmatic morphology, and D´eriF, which exploits oriented linguistic rules that have been manually designed and validated by linguists. Words in D´emonette that belong to"
2014.lilt-11.6,W04-2104,0,\N,Missing
2014.lilt-11.6,2003.mtsummit-systems.9,0,\N,Missing
2014.lilt-11.6,C98-1116,0,\N,Missing
2014.lilt-11.6,P13-1118,0,\N,Missing
2014.lilt-11.6,sagot-etal-2006-lefff,0,\N,Missing
2019.jeptalnrecital-court.9,N15-1140,0,0.0439651,"Missing"
2019.jeptalnrecital-court.9,D17-1074,0,0.0203074,". Le contenu de Démonette2 ne se résume pas aux seules relations héritées de ces ressources. L'ambition du projet est de constituer (semi-)automatiquement les familles dérivationnelles des lexèmes codés au cours de l'étape de migration et décrire, comme autant de nouvelles entrées, les relations entre les membres de ces familles. Plusieurs approches sont envisagées : l’extension des régularités 4 Échantillon de la toile, pour le domaine français, totalisant 1,6 milliard d'occurrences, cf. (Baroni et al., 2009) paradigmatiques encodées lors de la première phase, l’usage de réseaux de neurones (Cotterell et al., 2017) ou l'application de l'analyse des concepts formels (Leeuwenberg et al., 2015). 4 Premiers résultats 4.1 Un échantillon de Démonette2 BUVEUSENf ACTEURNm ACTIONNm BOIREV IMBUVABLEA FOIEN HEPATIQUEA exp2 BOIREV Const.2 Mot2 exp1 Mot1 Const.1 Chaque entrée de Démonette2 décrit une relation dérivationnelle qui s’établit entre deux lexèmes (Mot1, Mot2) de la même famille dérivationnelle où Mot1 est considéré comme morphologiquement motivé par Mot2. En général, la motivation de Mot2 par Mot1 est également possible, ce qui fait que l'entrée symétrique (Mot2, Mot1) est aussi présente dans la base. Nou"
2019.jeptalnrecital-court.9,P03-1036,0,0.131463,"ition, etc. Le résultat sera accessible grâce une plateforme offrant un accès adapté à différents publics. La BDM sera distribuée sous licence libre via l'EQUIPEX Ortolang (https://www.ortolang.fr/) et la plateforme REDAC (http://redac.univ-tlse2.fr/). 2 Etat de l'art L’analyse morphologique constitue l’une des étapes initiales centrales des systèmes de TAL. Les analyseurs, le plus souvent basés sur des méthodes d’apprentissage automatique, réalisent un découpage morphématique des mots et permettent de compenser les limitations des lexiques. On citera Linguistica (Goldsmith, 2001), Morfessor (Creutz, 2003 ; Creutz, Lagus, 2005), l’analyseur de Bernhard (2009) ou plus récemment les modèles de Cotterell et al. (2015, 2017). Applicables à n’importe quelle langue, ces systèmes sont plus efficaces pour les langues à morphologie concaténative comme l’anglais, l’allemand et le français. Parallèlement, des analyseurs symboliques ont été développés par des linguistes ; pour un panorama, voir Bernhard et al. (2011), ou Namer (2013). Les analyseurs morphologiques peuvent être complétés par des ressources lexicales munies d’annotations dérivationnelles, ayant une couverture lexicale assez importante et un"
2019.jeptalnrecital-court.9,J01-2001,0,0.202956,"indications de l’âge d'acquisition, etc. Le résultat sera accessible grâce une plateforme offrant un accès adapté à différents publics. La BDM sera distribuée sous licence libre via l'EQUIPEX Ortolang (https://www.ortolang.fr/) et la plateforme REDAC (http://redac.univ-tlse2.fr/). 2 Etat de l'art L’analyse morphologique constitue l’une des étapes initiales centrales des systèmes de TAL. Les analyseurs, le plus souvent basés sur des méthodes d’apprentissage automatique, réalisent un découpage morphématique des mots et permettent de compenser les limitations des lexiques. On citera Linguistica (Goldsmith, 2001), Morfessor (Creutz, 2003 ; Creutz, Lagus, 2005), l’analyseur de Bernhard (2009) ou plus récemment les modèles de Cotterell et al. (2015, 2017). Applicables à n’importe quelle langue, ces systèmes sont plus efficaces pour les langues à morphologie concaténative comme l’anglais, l’allemand et le français. Parallèlement, des analyseurs symboliques ont été développés par des linguistes ; pour un panorama, voir Bernhard et al. (2011), ou Namer (2013). Les analyseurs morphologiques peuvent être complétés par des ressources lexicales munies d’annotations dérivationnelles, ayant une couverture lexica"
2019.jeptalnrecital-court.9,P98-1013,0,0.256154,"mantiques Les décisions à prendre en termes de codage des propriétés (morpho-)sémantiques sont cruciales, car elles conditionnent la structure et l'homogénéité du contenu de la base. Pour chaque entrée, l'information sémantique à définir est le produit de trois annotations qui se complètent, et que l'on ne trouve à notre connaissance dans aucune autre BDM : la classe ontologique de Mot1 et Mot2, la catégorie sémantique de la relation morphologique entre Mot1 et Mot2, et la motivation réciproque de Mot1 et Mot2, sous forme d'une paraphrase inspirées du modèle des frame definitions de Framenet (Fillmore et al., 1998). Codage des unités du lexique : Actuellement, par défaut, les verbes s'interprètent comme des situations et les adjectifs comme des propriétés. Pour le codage des noms, un jeu d’étiquettes a été adapté des WordNet Unique Beginners, désormais UB (Miller et al. 1990, Fellbaum 1998), ce qui permet de couvrir l’ensemble du spectre lexical et d’offrir un degré de généralité qui convient a priori à la description morphologique. La liste des UB (en gras), complétée par l'étiquette sousspécifiée Top s'organise comme indiqué Fig.1. Nous avons établi des tableaux de correspondance entre les UB (ou leur"
2019.jeptalnrecital-court.9,2014.lilt-11.6,1,0.89144,"Missing"
2019.jeptalnrecital-court.9,L16-1173,1,0.87256,"Missing"
2019.jeptalnrecital-court.9,P13-1118,0,0.0278525,"ur les langues romanes, comme le constataient déjà Dal et al. (1999). La plus connues de ces ressources est CELEX (Baayen et al., 1995), qui décrit pour l’allemand, l’anglais et le néerlandais, les propriétés phonétiques, flexionnelles, morpho-syntaxiques, dérivationnelles et statistiques d’un peu moins de 250 000 mots non fléchis issus de dictionnaires et de corpus littéraires et journalistiques. Sinon, citons CatVar (Habash, Dorr, 2003) qui est un système lexical de 100 000 lexèmes de l'anglais réunis en sous-familles dérivationnelles organisées en graphes ; sur le même principe, DerivBase (Zeller et al., 2013) contient 215 000 unités lexicales de l'allemand dont les regroupements en familles dérivationnelles sont motivés sémantiquement ; la version 3.0 de WordNet (Fellbaum et al., 2007) est enrichie de relations dérivationnelles annotées sémantiquement entre les verbes et une partie de leurs dérivés nominaux (par exemple, la relation EMPLOYV/EMPLOYERN est étiquetée agent). Pour le français, on peut citer deux initiatives récentes visant le développement de réseaux lexicaux à large couverture. Le RL-fr (Lux-Pogadalla, Polguère, 2014) décrit 1 million d'entrées au moyen de relations sémantiques inspi"
2020.coling-main.109,N19-1423,0,0.225431,"k is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creative commons.org/licenses/by/4.0/. 1266 Proceedings of the 28th International Conference on Computational Linguistics, pages 1266–1278 Barcelona, Spain (Online), December 8-13, 2020 annotations; all the linguistic knowledge—that the neural network might exploit for its final decisions—is modeled implicitly throughout the neural network’s hidden layers. This line of research has culminated in the recent contextual embedding language architectures, such as ELMo (Peters et al., 2018), B ERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), which adapt the individual word embeddings in order to yield a fine-grained representation of the meaning within the context of a specific text fragment, and these embeddings can subsequently be exploited for language prediction tasks. The implicit nature of the linguistic knowledge contained within these recent approaches opens up a number of questions with regard to the relevance of selectional preferences in the neural network paradigm. Whereas previous NLP approaches generally considered selectional preferences as a standalone module that may be easily eval"
2020.coling-main.109,J10-4007,0,0.0875983,"Missing"
2020.coling-main.109,P07-1028,0,0.122544,"gorithm for selectional preference acquisition based on a probabilistic latent variable model. In their model, both predicate and argument are generated from a latent variable, where the latent variables represent clusters of tight verb–argument interactions. p(v, o) = ∑ p(c, v, o) = ∑ p(c)p(v∣c)p(o∣c) c∈C (3) c∈C The use of latent variables allows the model to generalize to predicate–argument tuples that have not been seen during training. The latent variable distribution—and the probabilities of predicates and argument given the latent variables—are automatically induced from data using EM. Erk (2007) and Erk et al. (2010) describe a method that uses corpus-driven distributional similarity metrics for the induction of selectional preferences. The key idea is that a predicate-argument tuple ′ (v, o) is felicitous if the predicate v appears in the training corpus with arguments o similar to o, i.e. wt(v, o ) ′ ⋅ sim(o, o ) S(v, o) = ∑ Z(v) ′ ′ (4) o ∈Ov where Ov represents the set of arguments that have been attested with predicate v, wt(⋅) represents ′ an appropriate weighting function (in its simplest form the frequency of the (v, o ) tuple), and Z is a normalization factor. Van de Cruys ("
2020.coling-main.109,2020.tacl-1.3,0,0.0204862,"learns more sophisticated relations in higher layers (Jawahar et al., 2019). Coenen et al. (2019) found that the attention matrices output by bert-base-uncased contain syntactic representations, with certain directions in space representing specific relations, and they were also able to locate similar sub-spaces for semantic relations. Petroni et al. (2019) report that B ERT contains enough relational knowledge to compete with knowledge-based methods on tasks such as open-type questions, which leads them to the conclusion that the model has acquired a certain level of semantic knowledge. And Ettinger (2020) presents a number of experiments in which in many cases B ERT makes good predictions with regard to semantic fit, such as hypernyms and subject-object nouns. However, McCoy et al. (2019) question the ability of B ERT—and similar pretrained models—to truly capture deep linguistic structures and semantic information, as past bibliography has suggested. Tenney et al. (2019) also investigated pretrained models on their performance on both syntactic and semantic phenomena, and concluded that simple syntactic phenomena were successfully identified, but phenomena which mostly relied on semantic rela"
2020.coling-main.109,J02-3001,0,0.175779,"hing that can be run), while the second example is semantically infelicitous (both a bassoon and a banana are inanimate entities without a literal capability of motion). This preference of predicates for particular arguments is known as selectional preference (Katz and Fodor, 1963). A proper understanding of this phenomenon is important within various natural language processing (NLP) applications, and selectional preferences have indeed been used as an additional knowledge source for various NLP tasks, such as word sense disambiguation (McCarthy and Carroll, 2003) and semantic role labeling (Gildea and Jurafsky, 2002). While language processing architectures prior to the neural network paradigm primarily made use of a sequential NLP pipeline, where designated modules sequentially provide increasingly complex linguistic annotations (such as part of speech tagging and syntactic parsing), more recent approaches tend to tackle NLP problems with a single, overarching neural network architecture: words are modeled as multidimensional embeddings that are fed to the neural network architecture, without any additional linguistic This work is licensed under a Creative Commons Attribution 4.0 International License. L"
2020.coling-main.109,W15-1106,0,0.215521,"B ERT, and report that it is uncertain whether the embeddings are able to properly represent semantic similarities on a word-base level (as the theory of distributional semantics would suggest), due to the influence of the context sentence on the distributional semantics space (even without meaning correlates). 3 Methodology 3.1 Selectional Preference Corpus Out of the several datasets of syntactic-semantic relations which have been released throughout the years for linguistics and NLP research, such as MST98 (McRae et al., 1998), F-Inst (Ferretti et al., 2001), P07 (Pad´o, 2007) and GDS-all (Greenberg et al., 2015), we decided to use SP-10K (Zhang et al., 2019b). SP-10K is the largest dataset available to date for evaluating the selectional preference abilities of natural 1 language processing tasks. It is composed of slightly over 10K pairs of words, evenly split into five different types of syntactic relations: nsubj (verb and noun as verb + subject), dobj (verb and noun as verb + direct object), amod (noun and adjective where the adjective is a modifier to the noun), nsubj amod 1 The authors had initially created 2,000 word pairs for each category, and later they added 124 more word pairs for the nsu"
2020.coling-main.109,P19-1356,0,0.0232524,"Transformer model) is more robust in syntactic tasks than a simple LSTM architecture (a Recurrent Neural Network), and with a series of probing tasks on different datasets he proved that there is some syntactic knowledge beyond semantic and contextual relations. B ERT was especially more successful in such tasks compared to other contextual embedding models, because of its bi-directional architecture (Wolf, 2019). Further research on learned syntactic information showed that B ERT captures phrase-level information in the lower layers, and learns more sophisticated relations in higher layers (Jawahar et al., 2019). Coenen et al. (2019) found that the attention matrices output by bert-base-uncased contain syntactic representations, with certain directions in space representing specific relations, and they were also able to locate similar sub-spaces for semantic relations. Petroni et al. (2019) report that B ERT contains enough relational knowledge to compete with knowledge-based methods on tasks such as open-type questions, which leads them to the conclusion that the model has acquired a certain level of semantic knowledge. And Ettinger (2020) presents a number of experiments in which in many cases B ER"
2020.coling-main.109,2020.tacl-1.28,0,0.0344737,"c positions. We want grammatical sentences, with varied contexts, in order to examine in which cases selectional preferences have an influence on the prediction of the masked word. We decided not to compose our own prompt sentences, as this would be a very large-scale effort and could have introduced some unwanted biases. On the other hand, existing datasets of prompt sentences were either too small to include a sufficient amount of the SP-10K word pairs (such as the Corpus of Linguistic Acceptability, Warstadt et al. (2018)) or too specialized on semantic relations (such as the LPAQA corpus, Jiang et al. (2020)). Thus, we decided to use a large corpus and extract sample sentences for each word pair. The ukWaC corpus was created by crawling websites in the .uk domain, and it includes a variety of texts in English (articles, titles, user reviews, etc.) and over 2 billion words (Ferraresi et al., 2008). In order to find the SP-10K word pairs in the ukWaC sentences in the correct syntactic positions and relations, we used a syntactically annotated version of the corpus, which was parsed using the Malt parser (Nivre et al., 2006). Out of the 85 million sentences in the ukWaC corpus, we looked for short s"
2020.coling-main.109,D19-1445,0,0.0231733,"ository . As for future work, a further exploration of the attention output would be quite beneficial in understanding the attention weights during prediction, in each scenario, and how they differ per layer and attention head. Researchers who have attempted to thoroughly analyze B ERT’s attention behavior in syntactic probing tasks have noted that the attention maps have “a fairly thorough representation of English syntax” [sic] (Clark et al., 2019), and have noticed that specific attention heads and layers specialize on learning specific linguistic knowledge, such as syntactic dependencies (Kovaleva et al., 2019). Visualizing attention for 12 layers and 12 attention heads, over 145K sentences, is a complicated task which we intend to tackle soon, with the help of visualization libraries (Vig, 2019). Acknowledgements This work has been funded by CNRS (80∣PRIME-2019 project MoDiCLI). Experiments presented in 5 this paper were carried out using the OSIRIM platform that is administered by IRIT and supported by CNRS, the Region Midi-Pyr´en´ees, the French Government, and ERDF. We would like to thank our reviewers for their insightful comments and suggestions. References Stephen Clark and David Weir. 2001."
2020.coling-main.109,J98-2002,0,0.136793,"k–Leibler 1267 divergence between the posterior cluster distribution of the verb and the prior cluster distribution: SR(v) = ∑ p(c∣v) log c p(c∣v) p(c) (1) where c stands for a noun cluster, and R stands for a given predicate-argument relation. The selectional association of a particular noun cluster is the contribution of that cluster to the verb’s preference strength. p(c∣v) log AR(v,c) = p(c∣v) p(c) SR(v) (2) The model’s generalization relies entirely on WordNet, and there is no generalization among the verbs. A number of other researchers have equally exploited WordNet for generalization (Li and Abe, 1998; ´ S´eaghdha and Korhonen, 2012). Most researchers, however, acknowledge the Clark and Weir, 2001; O shortcomings of hand-crafted resources, and focus on the acquisition of selectional preferences from corpus data. Rooth et al. (1999) propose an Expectation–Maximization (EM) clustering algorithm for selectional preference acquisition based on a probabilistic latent variable model. In their model, both predicate and argument are generated from a latent variable, where the latent variables represent clusters of tight verb–argument interactions. p(v, o) = ∑ p(c, v, o) = ∑ p(c)p(v∣c)p(o∣c) c∈C (3"
2020.coling-main.109,J03-4004,0,0.0756675,"ctly normal for athletes to run, and a marathon is something that can be run), while the second example is semantically infelicitous (both a bassoon and a banana are inanimate entities without a literal capability of motion). This preference of predicates for particular arguments is known as selectional preference (Katz and Fodor, 1963). A proper understanding of this phenomenon is important within various natural language processing (NLP) applications, and selectional preferences have indeed been used as an additional knowledge source for various NLP tasks, such as word sense disambiguation (McCarthy and Carroll, 2003) and semantic role labeling (Gildea and Jurafsky, 2002). While language processing architectures prior to the neural network paradigm primarily made use of a sequential NLP pipeline, where designated modules sequentially provide increasingly complex linguistic annotations (such as part of speech tagging and syntactic parsing), more recent approaches tend to tackle NLP problems with a single, overarching neural network architecture: words are modeled as multidimensional embeddings that are fed to the neural network architecture, without any additional linguistic This work is licensed under a Cr"
2020.coling-main.109,P19-1334,0,0.112606,"esentations, with certain directions in space representing specific relations, and they were also able to locate similar sub-spaces for semantic relations. Petroni et al. (2019) report that B ERT contains enough relational knowledge to compete with knowledge-based methods on tasks such as open-type questions, which leads them to the conclusion that the model has acquired a certain level of semantic knowledge. And Ettinger (2020) presents a number of experiments in which in many cases B ERT makes good predictions with regard to semantic fit, such as hypernyms and subject-object nouns. However, McCoy et al. (2019) question the ability of B ERT—and similar pretrained models—to truly capture deep linguistic structures and semantic information, as past bibliography has suggested. Tenney et al. (2019) also investigated pretrained models on their performance on both syntactic and semantic phenomena, and concluded that simple syntactic phenomena were successfully identified, but phenomena which mostly relied on semantic relations were not as easily learned. Ettinger (2020) has also pointed out that B ERT performance on predictions dropped in cases of true/false statements and negations. Zhang et al. (2019c)"
2020.coling-main.109,nivre-etal-2006-maltparser,0,0.0781106,"(2018)) or too specialized on semantic relations (such as the LPAQA corpus, Jiang et al. (2020)). Thus, we decided to use a large corpus and extract sample sentences for each word pair. The ukWaC corpus was created by crawling websites in the .uk domain, and it includes a variety of texts in English (articles, titles, user reviews, etc.) and over 2 billion words (Ferraresi et al., 2008). In order to find the SP-10K word pairs in the ukWaC sentences in the correct syntactic positions and relations, we used a syntactically annotated version of the corpus, which was parsed using the Malt parser (Nivre et al., 2006). Out of the 85 million sentences in the ukWaC corpus, we looked for short sentences (4 to 15 tokens), in order to stay well under B ERT’s limit of 512 tokens per sequence, but also in order to ensure that the sentences would not be erroneously composed of multiple sentences (due to segmentation errors), or be composed of multiple clauses, or include complex and distant dependencies. In an effort to eliminate syntactic complexity as an extraneous factor of prediction difficulty, we considered excluding some specific dependency labels, such as xcomp (open clausal complement) and acl:rel (for re"
2020.coling-main.109,S12-1025,0,0.0482264,"Missing"
2020.coling-main.109,P10-1045,0,0.0687978,"Missing"
2020.coling-main.109,N18-1202,0,0.0215985,"dditional linguistic This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creative commons.org/licenses/by/4.0/. 1266 Proceedings of the 28th International Conference on Computational Linguistics, pages 1266–1278 Barcelona, Spain (Online), December 8-13, 2020 annotations; all the linguistic knowledge—that the neural network might exploit for its final decisions—is modeled implicitly throughout the neural network’s hidden layers. This line of research has culminated in the recent contextual embedding language architectures, such as ELMo (Peters et al., 2018), B ERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), which adapt the individual word embeddings in order to yield a fine-grained representation of the meaning within the context of a specific text fragment, and these embeddings can subsequently be exploited for language prediction tasks. The implicit nature of the linguistic knowledge contained within these recent approaches opens up a number of questions with regard to the relevance of selectional preferences in the neural network paradigm. Whereas previous NLP approaches generally considered selectional preferences as a standalone m"
2020.coling-main.109,D19-1250,0,0.0491867,"Missing"
2020.coling-main.109,P10-1044,0,0.0163361,"ased on tensor factorization, which is able to model multi-way selectional preferences. Three-way co-occurrences of subjects, verbs, and objects are represented as a three-way tensor (the generalization of a matrix), and a latent tensor factorization model is applied in order to generalize to unseen instances. ´ A number of researchers presented models that are based on the framework of topic modeling. O S´eaghdha (2010) describes three models for selectional preference induction based on Latent Dirichlet Allocation, which model the selectional preference of a predicate and a single argument. Ritter et al. (2010) equally present a selectional preference model based on topic modeling, but they tackle multiway selectional preferences (of transitive predicates, which take two arguments) instead. More recently, neural network based approaches have equally been used. Van de Cruys (2014) presents an approach based on feed-forward neural networks; predicates and arguments are represented as embeddings, and serve as input to a simple feed-forward neural network architecture, which yields a single selectional preference value. And Zhang et al. (2019a) present multiplex word embeddings for selectional preferenc"
2020.coling-main.109,P99-1014,0,0.298355,"nt relation. The selectional association of a particular noun cluster is the contribution of that cluster to the verb’s preference strength. p(c∣v) log AR(v,c) = p(c∣v) p(c) SR(v) (2) The model’s generalization relies entirely on WordNet, and there is no generalization among the verbs. A number of other researchers have equally exploited WordNet for generalization (Li and Abe, 1998; ´ S´eaghdha and Korhonen, 2012). Most researchers, however, acknowledge the Clark and Weir, 2001; O shortcomings of hand-crafted resources, and focus on the acquisition of selectional preferences from corpus data. Rooth et al. (1999) propose an Expectation–Maximization (EM) clustering algorithm for selectional preference acquisition based on a probabilistic latent variable model. In their model, both predicate and argument are generated from a latent variable, where the latent variables represent clusters of tight verb–argument interactions. p(v, o) = ∑ p(c, v, o) = ∑ p(c)p(v∣c)p(o∣c) c∈C (3) c∈C The use of latent variables allows the model to generalize to predicate–argument tuples that have not been seen during training. The latent variable distribution—and the probabilities of predicates and argument given the latent v"
2020.coling-main.109,W09-0211,1,0.702534,"Missing"
2020.coling-main.109,D14-1004,1,0.794166,"Missing"
2020.coling-main.109,P19-3007,0,0.0288465,"layer and attention head. Researchers who have attempted to thoroughly analyze B ERT’s attention behavior in syntactic probing tasks have noted that the attention maps have “a fairly thorough representation of English syntax” [sic] (Clark et al., 2019), and have noticed that specific attention heads and layers specialize on learning specific linguistic knowledge, such as syntactic dependencies (Kovaleva et al., 2019). Visualizing attention for 12 layers and 12 attention heads, over 145K sentences, is a complicated task which we intend to tackle soon, with the help of visualization libraries (Vig, 2019). Acknowledgements This work has been funded by CNRS (80∣PRIME-2019 project MoDiCLI). Experiments presented in 5 this paper were carried out using the OSIRIM platform that is administered by IRIT and supported by CNRS, the Region Midi-Pyr´en´ees, the French Government, and ERDF. We would like to thank our reviewers for their insightful comments and suggestions. References Stephen Clark and David Weir. 2001. Class-based probability estimation using a semantic hierarchy. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Languag"
2020.coling-main.109,W19-2304,0,0.0293691,"ce) and [SEP] (to indicate the end of it). We make use of the model’s built-in tokenizer, BertTokenizer, and we do not perform any finetuning of the encoder weights, but make use of the pretrained model as it is made available. 3.4 Correlation of SP-10K score and B ERT probability For each example sentence in our corpus, we mask the dependent word of the word pair using a [MASK] token, and we retrieve the probability that is assigned to the target word in the focal position. The probability is computed by passing the last hidden state through a softmax function, a feature that is also used by Wang and Cho (2019) in the context of language modeling. We are making the assumption that this result is to be treated as the conditional probability of a bi-directional language model (similar to what a traditional language model would return) even though we are aware that B ERT’s bi-directional nature means that this assumption is not self-evident. Next, we compute the correlation of the masked word’s probability and the plausibility score of the word pair, using the Kendall rank correlation coefficient as implemented by the scipy Python library. Kendall τ (tau) correlation is a non-parametric measure of the"
2020.coling-main.109,D19-1528,0,0.0224831,"Missing"
2020.coling-main.109,P19-1071,0,0.108639,"g or implausible meanings. The stellar success of contextual word embedding models such as B ERT in NLP tasks has led many to question whether these models have learned linguistic information, but up till now, most research has focused on syntactic information. We investigate whether B ERT contains information on the selectional preferences of words, by examining the probability it assigns to the dependent word given the presence of a head word in a sentence. We are using word pairs of head-dependent words in five different syntactic relations from the SP-10K corpus of selectional preference (Zhang et al., 2019b), in sentences from the ukWaC corpus, and we are calculating the correlation of the plausibility score (from SP-10K) and the model probabilities. Our results show that overall, there is no strong positive or negative correlation in any syntactic relation, but we do find that certain head words have a strong correlation, and that masking all words but the head word yields the most positive correlations in most scenarios—which indicates that the semantics of the predicate is indeed an integral and influential factor for the selection of the argument. 1 Introduction Motivated by their semantics"
2020.computerm-1.7,P99-1050,0,0.320176,"Missing"
2020.computerm-1.7,S17-1002,0,0.0638067,"Missing"
2020.computerm-1.7,P02-1006,0,0.030563,"Missing"
2020.computerm-1.7,Q19-1027,0,0.0279449,"Missing"
2020.computerm-1.7,P16-4003,1,0.813413,"ojection of lexicalsemantic relations, we did not use the 259 DRV pairs and excluded them from RefCD. We also excluded the 225 pairs of verbs because TermSuite only extracts noun phrases. Since RefCD does not contain information between simple terms describing other relations, like co-hyponyms, our study on semantic relations between MWTs concentrates on QSYN, HYP, and ANTI. The distribution of the three relation categories is imbalanced, as shown in table 2. TermSuite The MWT candidates were extracted from the PANACEA corpus through TermSuit, a terminology extraction tool developed at LS2N2 (Cram and Daille, 2016). TermSuit only extracts noun phrases; the candidates are provided with their part of speech, specificity, and frequency. Table 1 illustrates the extracted candidates. For this study, we only consider the candidates composed of two lexical words (e.g. milieu naturel ‘natural environment’). Pairs Terms ANTI HYP QSYN 116 107 191 122 523 415 total 830 429 Table 2: Number of terms and semantic relations in RefCD 5. 5.1. 1 http://www.panacea-lr.eu/en/info-for-researchers/datasets/monolingual-corpora 2 https://www.ls2n.fr Generation of semantically-linked MWTs Raw projection We extracted all the MWT"
2020.computerm-1.7,daille-hazem-2014-semi,1,0.790075,"Missing"
2020.computerm-1.7,N19-1423,0,0.0112122,"Missing"
2020.computerm-1.7,P98-1082,0,0.515765,"Missing"
2020.computerm-1.7,L18-1045,1,0.866609,"Missing"
2020.jeptalnrecital-taln.34,2020.lrec-1.724,0,0.0529014,"Missing"
2020.jeptalnrecital-taln.34,candito-etal-2014-developing,0,0.0675992,"Missing"
2020.jeptalnrecital-taln.34,2014.lilt-11.6,1,0.880199,"Missing"
2020.jeptalnrecital-taln.34,L16-1173,1,0.891171,"Missing"
2020.jeptalnrecital-taln.34,2020.lrec-1.478,1,0.833955,"Missing"
2020.jeptalnrecital-taln.34,W19-8502,1,0.790208,"Missing"
2020.lrec-1.369,acs-2014-pivot,0,0.542137,"Missing"
2020.lrec-1.369,Q17-1010,0,0.0751759,"Missing"
2020.lrec-1.369,D18-1181,0,0.148165,"r than semantic similarity and that their ability to properly distinguish different semantic relations is limited. DSM are generally trained on large corpora and evaluated on standard data sets. Most studies usually compare different architectures of some systems and assess their respective performances. The other factor that we can change is the training data: one could compare different systems trained on different inputs. Instead of training the DSM on large corpora, one could use lexicographic definitions as input. DSM trained on definitions have been proposed by Noraset et al. (2016) and Bosc and Vincent (2018). In spite of the reduced size of the data, the performance of these models are comparable to the performance of models trained on (very) large corpora. These “lexicographic word embeddings” can be created by standard tools such as Word2Vec (Mikolov et al., 2013), FastText (Bojanowski et al., 2017) or LSTM architectures (Hochreiter and Schmidhuber, 1997). In the following, we compare 3 models: a classical FastText model trained on the Common Crawl, a 600 billion words corpus (Grave et al., 2018), a FastText model trained on ENGLAWI’s definitions and a model created by means of an LSTM, also tr"
2020.lrec-1.369,L18-1550,0,0.0315503,"Missing"
2020.lrec-1.369,2014.lilt-11.6,1,0.806008,"2. Diachronic information may be provided: etymons and languages, as well as relations between etymons (cognate, borrowing, derivation, inheritance and calque). Morphological information on word formations (affixes, compounds, derivations, etc.) also occurs in etymologies, as illustrated in Figure 3. This data is usually more reliable than underspecified relations (derived and related, that contributors use inconsistently) found in Wiktionary’s sections entitled derived terms (cf. Section 4.6.2.). Such information provides material to be included in morphological resources such as Démonette (Hathout and Namer, 2014). &lt;etymology nb=&quot;1&quot;> &lt;wiki>From {{inh|en|enm|cat}}, {{m|enm|catte}}, from {{inh|en|ang|catt||male cat}}... &lt;xml>From &lt;etym type=&quot;inherited&quot;>&lt;lang langCode=&quot;enm&quot;> Middle English&lt;/lang> &lt;etymon>cat&lt;/etymon>&lt;/etym>, &lt;etymon langCode=&quot;enm&quot; langName=&quot;Middle English&quot;> catte&lt;/etymon>, from &lt;etym type=&quot;inherited&quot;> &lt;lang langCode=&quot;ang&quot;>Old English&lt;/lang> &lt;etymon gloss=&quot;male cat&quot;>catt&lt;/etymon>&lt;/etym>...&lt;/xml> &lt;txt>From Middle English cat, catte, from Old English catt ...&lt;/txt> &lt;parsed> &lt;!-- ... --> &lt;/parsed> &lt;/etymology> Figure 2: One shortened etymology (out of six) for cat POS sections &lt;definition lev"
2020.lrec-1.369,L16-1218,1,0.91151,"tion This paper introduces ENGLAWI, a structured and normalized version of the English Wiktionary encoded into a workable XML format. ENGLAWI is freely available for download,1 fully documented, and is supplied with G-PeTo (GLAWI Perl Tools), a set of scripts that helps extract specific information from GLAWI dictionaries. Contrary to other approaches designed to extract particular data from Wiktionary, ENGLAWI is part of a series of works aiming to provide the full body of information encoded in the collaborative dictionaries. In previous papers, we presented GLAWI (Sajous and Hathout, 2015; Hathout and Sajous, 2016), extracted from the French Wiktionnaire and GLAWIT (Calderone et al., 2016), extracted from the Italian Wikizionario. In these papers, we described the conversion and the standardization of the heterogeneous data extracted from the dictionaries’ dumps and we illustrated how specific lexicons can be easily tailored on demand. We did adopt an identical approach to develop ENGLAWI. The current paper describes the content of ENGLAWI, illustrates how it is structured and suggests possible uses for linguistic studies and NLP applications. The remainder of the article is organized as follows. In Sec"
2020.lrec-1.369,W14-5809,1,0.819028,"ed on the analysis of HTML pages of different language editions of Wiktionary to extract morphological paradigms in various languages, with minimal language-specific tuning. According to the authors, their approach achieved – for 3 tested languages – results comparable in quality and quantity to that obtained with previous, fine-tuned methods. Extracting data in 350 languages, the authors concluded their method contributes a uniquely large morphological resource, they called UniMorph. ENGLAWI did not exist by that time. Resources existed however for French, namely GLÀFF (Sajous et al., 2013a; Hathout et al., 2014b) and GLAWI (Sajous and Hathout, 2015; Hathout and Sajous, 2016), that achieved a better coverage (cf. Section 4.2.), but were not taken into account in the comparison led by Kirov et al. (2016). What we propose in the current paper is a resource for a single language – English – containing the full body of information encoded in Wiktionary, including notably definitions and etymologies, as clean as possible and as conform as possible to Wiktionary’s original content. ENGLAWI, we hope, will help conduct further research without the need of wikicode parsing. 4. Resource description The general"
2020.lrec-1.369,hathout-etal-2014-glaff,1,0.89161,"Missing"
2020.lrec-1.369,L16-1498,0,0.455859,"urpose was “to obtain a coherent and consistent lexical resource that contains as much information as possible about words and their relations”. Liebeck and Conrad developed a lemmatizer for German and focused on the extraction of inflections for this language. They insisted on the importance of templates reimplementation for that purpose. Both papers 3017 compared the extracted data to that obtained with JWKTL and revealed lacks in the latter. Unlike IWNLP, whose both source code and data are made available for download, knoWitiary is not publicly released. Another original method is that of Kirov et al. (2016), who relied on the analysis of HTML pages of different language editions of Wiktionary to extract morphological paradigms in various languages, with minimal language-specific tuning. According to the authors, their approach achieved – for 3 tested languages – results comparable in quality and quantity to that obtained with previous, fine-tuned methods. Extracting data in 350 languages, the authors concluded their method contributes a uniquely large morphological resource, they called UniMorph. ENGLAWI did not exist by that time. Resources existed however for French, namely GLÀFF (Sajous et al"
2020.lrec-1.369,P15-2068,0,0.406694,"Missing"
2020.lrec-1.369,P10-1023,0,0.145602,"Missing"
2020.lrec-1.369,S18-2019,0,0.023733,"Missing"
2020.lrec-1.369,W19-0422,0,0.0187042,"synthesis process. The authors assessed the good coverage and quality of the extracted transcriptions. De Smedt et al. 3016 (2014), noting that basic resources (especially free ones) were still missing for many languages, including Italian, developed a weakly-supervised, fast, free and reasonably accurate tagger for Italian, created by mining words and their part-of-speech from Wiktionary. Ács (2014) applied a triangulation method to Wiktionary to create a pivot-based multilingual dictionary. Metheniti and Neumann (2018) produced inflectional paradigms for over 150 languages from Wiktionary. Segonne et al. (2019) investigated which strategy to adopt to achieve WSD for languages lacking annotated sense disambiguated corpora (i.e. languages other than English). Focusing on verb disambiguation in French, they resorted to the sense inventory and to the manually sense tagged examples extracted from the French Wiktionnaire to train WSD systems. All these works, like other successful use of data extracted from Wiktionary, presented in Section 6, confirm that Wiktionary-based MRD may benefit NLP tools and linguistic studies. 3. Related works on information extraction from Wiktionary Ide and Veronis (1993) que"
2020.lrec-1.369,serasset-2012-dbnary,0,0.0645476,"Missing"
2020.lrec-1.369,zesch-etal-2008-extracting,0,0.0593736,"ry’s content. We also noted in these papers that the syntax highly differs from a language edition to another. Several authors focus on the extraction of specific information from Wiktionary. Because partial and noisy data meet their needs, they do not report such difficulties. Most of them use the English dump to extract information in another target language and purely ignore the edition of Wiktionary in the language they are working on. We analyze below the pros and cons of different approaches to extracting data from Wiktionary. First pioneering work on using Wiktionary for NLP was led by Zesch et al. (2008) for semantic relatedness computation. The authors released JWKTL, an API giving access to the data of the English and German wiktionaries. Navarro et al. (2009) worked on synonymy mining and made available the first versions of the English and the French wiktionaries as MRD, called WiktionaryX. An advantage of JWKTL is that a user can download a recent dump of Wiktionary and access its current data. A drawback is that it handles regular wiki markups such as hyperlinks, bold and italic, but do not adequately process all the MediaWiki templates. For example, the linguistic labels found in defin"
2020.lrec-1.478,Q17-1010,0,0.0193812,"form’, ‘reformist:reformism’ The second projection Glawinette provides is the deriva3878 3. Related work The supply in morphological resources has increased significantly in recent years, for inflection and derivation. Inflectional lexicons have become available for many languages because they are required in important NLP tasks such as syntactic parsing, spell checking or to develop predictive keyboards. On the other hand, modern NLP systems do not make use of derivational resources. Often, derivation is summarily taken into account and dealt with at the level of tokenization as in FastText (Bojanowski et al., 2017) or BERT (Devlin et al., 2018). Derivational databases are mainly used in psycho-linguistics to create experimental material, in speech and language remediation to setup exercises or to teach vocabulary at primary schools. One way, derivational databases can be created is by running a morphological analyzer on a lexicon or a large corpus. Many of these systems are based on machine learning and trained to decompose words into morphemes, like Linguistica (Goldsmith, 2001), Morfessor (Creutz and Lagus, 2005) or, more recently, the model of (Cotterell and Schütze, 2018); for a panorama, see (Bernh"
2020.lrec-1.478,Q18-1003,0,0.0160709,"of tokenization as in FastText (Bojanowski et al., 2017) or BERT (Devlin et al., 2018). Derivational databases are mainly used in psycho-linguistics to create experimental material, in speech and language remediation to setup exercises or to teach vocabulary at primary schools. One way, derivational databases can be created is by running a morphological analyzer on a lexicon or a large corpus. Many of these systems are based on machine learning and trained to decompose words into morphemes, like Linguistica (Goldsmith, 2001), Morfessor (Creutz and Lagus, 2005) or, more recently, the model of (Cotterell and Schütze, 2018); for a panorama, see (Bernhard et al., 2011). The other way to create derivational databases is to annotate lexicons semi-automatically. This annotation can take multiple forms: in CELEX (Baayen et al., 1995), the words are decomposed into morphemes; DeriNet (Vidra et al., 2019) describes the morphological relations between derived words and their bases; in CATVAR (Habash and Dorr, 2003) or DErivBase (Zeller et al., 2013) the lexicon is clustered into derivational families; for an exhaustive presentation of the derivational databases available for Romance, Germanic and Slavic languages, see ("
2020.lrec-1.478,L18-1171,0,0.0161787,"ut a more complete semantic analysis. For instance, the -ment series contains pairs that instantiate various patterns: ^(.+)er$:^(.+)ement$ développer:développement ^(.+)ir$:^(.+)issement$ investir:investissement ‘invest:investment’ ^(.+)eler$:^(.+)ellement$ ruisseler:ruissellement ‘flowV :flowN ’ ^(.+)re$:^(.+)ement$ rendre:rendement ‘returnV :yieldN ’ For this reason, we use the formal subseries as approximations of the derivational series. In other words, the previous hypothesis is reframed as: derivational relations form formal series, that is series that do not contain formal variations. Fam and Lepage (2018) make use of the same hypothesis to create analogical grids from text corpora. The hypothesis is stated as in (1). P11 :P12 :· · ·:P1n ∀(i, k) ∈ {1, . . . , n}2 , P21 :P22 :· · ·:P2n 2 .. .. .. .. ⇐⇒ ∀(j, l) ∈ {1, . . . , m} , j j l l . . . . Pi : Pi = Pk : Pk n 2 1 :· · ·:Pm :Pm Pm (1) In our case, we focus only on series of derivational relations. In other words, n = 2. Globally, Glawinette could be seen as an analogical grid with at least three differences: we only consider derivational relations; Glawinette identifies the linguistic exponents involved in the derivational relations it conta"
2020.lrec-1.478,J01-2001,0,0.492289,"ources. Often, derivation is summarily taken into account and dealt with at the level of tokenization as in FastText (Bojanowski et al., 2017) or BERT (Devlin et al., 2018). Derivational databases are mainly used in psycho-linguistics to create experimental material, in speech and language remediation to setup exercises or to teach vocabulary at primary schools. One way, derivational databases can be created is by running a morphological analyzer on a lexicon or a large corpus. Many of these systems are based on machine learning and trained to decompose words into morphemes, like Linguistica (Goldsmith, 2001), Morfessor (Creutz and Lagus, 2005) or, more recently, the model of (Cotterell and Schütze, 2018); for a panorama, see (Bernhard et al., 2011). The other way to create derivational databases is to annotate lexicons semi-automatically. This annotation can take multiple forms: in CELEX (Baayen et al., 1995), the words are decomposed into morphemes; DeriNet (Vidra et al., 2019) describes the morphological relations between derived words and their bases; in CATVAR (Habash and Dorr, 2003) or DErivBase (Zeller et al., 2013) the lexicon is clustered into derivational families; for an exhaustive pres"
2020.lrec-1.478,N03-1013,0,0.150972,"Many of these systems are based on machine learning and trained to decompose words into morphemes, like Linguistica (Goldsmith, 2001), Morfessor (Creutz and Lagus, 2005) or, more recently, the model of (Cotterell and Schütze, 2018); for a panorama, see (Bernhard et al., 2011). The other way to create derivational databases is to annotate lexicons semi-automatically. This annotation can take multiple forms: in CELEX (Baayen et al., 1995), the words are decomposed into morphemes; DeriNet (Vidra et al., 2019) describes the morphological relations between derived words and their bases; in CATVAR (Habash and Dorr, 2003) or DErivBase (Zeller et al., 2013) the lexicon is clustered into derivational families; for an exhaustive presentation of the derivational databases available for Romance, Germanic and Slavic languages, see (Kyjánek, 2018). The main contributions of Glawinette with respect to these resources are (i) the combination of the derivational families with the derivational series, and (ii) the description of the morphological relations by means of linguistically relevant exponents. For many year, French lacked a large-scale derivational resources similar to CELEX. The first derivational databases aim"
2020.lrec-1.478,2014.lilt-11.6,1,0.963274,"es that form regular formal analogies and that instantiate frequent enough formal patterns. The graph structure of the morphological families has then been used to identify for each pair of lexemes derivational patterns that are close to the intuition of the morphologists. Keywords: derivational database, French, paradigmatic morphology, derivational family, derivational series 1. Introduction The aim of this work is to create a derivational lexicon of French that could be used to feed Démonette, a large coverage morphological database which combines the results of various linguistic studies (Hathout and Namer, 2014a; Hathout and Namer, 2014b; Hathout and Namer, 2016; Namer et al., 2019). The idea behind the creation of this lexicon, named Glawinette, is to take advantage of the availability of GLAWI (Sajous and Hathout, 2015; Hathout and Sajous, 2016), a large French machine readable dictionary derived from Wiktionnaire, the French edition of Wiktionary. The task addressed in this article is to discover the derivational relations that hold in a subset of the French lexicon. Because these relations cannot be identified only from the formal properties of words (Hathout, 2002), some semantic knowledge must"
2020.lrec-1.478,L16-1173,1,0.925463,"ntiate frequent enough formal patterns. The graph structure of the morphological families has then been used to identify for each pair of lexemes derivational patterns that are close to the intuition of the morphologists. Keywords: derivational database, French, paradigmatic morphology, derivational family, derivational series 1. Introduction The aim of this work is to create a derivational lexicon of French that could be used to feed Démonette, a large coverage morphological database which combines the results of various linguistic studies (Hathout and Namer, 2014a; Hathout and Namer, 2014b; Hathout and Namer, 2016; Namer et al., 2019). The idea behind the creation of this lexicon, named Glawinette, is to take advantage of the availability of GLAWI (Sajous and Hathout, 2015; Hathout and Sajous, 2016), a large French machine readable dictionary derived from Wiktionnaire, the French edition of Wiktionary. The task addressed in this article is to discover the derivational relations that hold in a subset of the French lexicon. Because these relations cannot be identified only from the formal properties of words (Hathout, 2002), some semantic knowledge must be used in order for instance to exclude the numero"
2020.lrec-1.478,L16-1218,1,0.865795,"he intuition of the morphologists. Keywords: derivational database, French, paradigmatic morphology, derivational family, derivational series 1. Introduction The aim of this work is to create a derivational lexicon of French that could be used to feed Démonette, a large coverage morphological database which combines the results of various linguistic studies (Hathout and Namer, 2014a; Hathout and Namer, 2014b; Hathout and Namer, 2016; Namer et al., 2019). The idea behind the creation of this lexicon, named Glawinette, is to take advantage of the availability of GLAWI (Sajous and Hathout, 2015; Hathout and Sajous, 2016), a large French machine readable dictionary derived from Wiktionnaire, the French edition of Wiktionary. The task addressed in this article is to discover the derivational relations that hold in a subset of the French lexicon. Because these relations cannot be identified only from the formal properties of words (Hathout, 2002), some semantic knowledge must be used in order for instance to exclude the numerous cases where the formal relation between a pair of morphologically unrelated words (such as poisse:poisson ‘unluck:fish’) is the same as the relation between morphologically related words"
2020.lrec-1.478,W14-5809,1,0.69832,"ed only from the formal properties of words (Hathout, 2002), some semantic knowledge must be used in order for instance to exclude the numerous cases where the formal relation between a pair of morphologically unrelated words (such as poisse:poisson ‘unluck:fish’) is the same as the relation between morphologically related words such as corde:cordon ‘rope:string’, poche:pochon ‘bag:small bag’, glace:glaçon ‘ice:ice cube’, etc. Lexicographic definitions provide precise descriptions of word meanings that could help us perform more accurate morphological analysis (Hathout, 2009a; Hathout, 2011a; Hathout et al., 2014). However, we cannot automatically extract from the definitions all the morphosemantic properties of the derivational relations between derived headwords and their bases. For instance, we cannot abstract from the definitions of -on suffixed words such as in (1) that these words denote an entity that belongs to the category of the base and that is small in this category (Plénat, 2005). (1) a. clocheton: petit bâtiment en forme de clocher, de tourelle, dont on orne les angles ou le sommet d’une construction ‘small building in the shape of a bell tower, that decorate buildings corners or tops’ b."
2020.lrec-1.478,hathout-2002-wordnet,1,0.619646,"linguistic studies (Hathout and Namer, 2014a; Hathout and Namer, 2014b; Hathout and Namer, 2016; Namer et al., 2019). The idea behind the creation of this lexicon, named Glawinette, is to take advantage of the availability of GLAWI (Sajous and Hathout, 2015; Hathout and Sajous, 2016), a large French machine readable dictionary derived from Wiktionnaire, the French edition of Wiktionary. The task addressed in this article is to discover the derivational relations that hold in a subset of the French lexicon. Because these relations cannot be identified only from the formal properties of words (Hathout, 2002), some semantic knowledge must be used in order for instance to exclude the numerous cases where the formal relation between a pair of morphologically unrelated words (such as poisse:poisson ‘unluck:fish’) is the same as the relation between morphologically related words such as corde:cordon ‘rope:string’, poche:pochon ‘bag:small bag’, glace:glaçon ‘ice:ice cube’, etc. Lexicographic definitions provide precise descriptions of word meanings that could help us perform more accurate morphological analysis (Hathout, 2009a; Hathout, 2011a; Hathout et al., 2014). However, we cannot automatically ext"
2020.lrec-1.478,W08-2001,1,0.697252,"n objectif premier, système qui prône le sacrifice de toute autre considération pour maximiser la productivité ‘doctrine which states that production is a primary objective, system that advocates the sacrifice of all other considerations to maximize productivity’. The extraction of derivational relations from the definitions is circular, to some extent. In order to find the morphological relations, we must know which words are derivatives but this is precisely the information we want to extract from the dictionary. One effective solution to this problem could be to use the Proxinette measure (Hathout, 2008; Hathout, 2014) in order to identify the possible members of their derivational families and series. The idea would be to only consider the very first neighbors of the headword that occur in the definition. However, some derivatives may be missed because Proxinette is not categorical. Moreover, we would still have to exclude the pairs of words where the neighborhoods returned by Proxinette belong to the derivational series of the entry. We therefore opted for a different and more simple solution. We made use of the hypothesis that derivational relations connect forms that display regular alte"
2020.lrec-1.478,C08-2013,0,0.528332,"hese pairs are merged with the ones yielded by the definitions (as detailed in Section 4.). We then select the valid pairs from this set of candidates as detailed in Sections 6. and 7. 6. Analogical selection of the derivational relations When two words such as développer and développement are in the same morphological relation as two others such as classer ‘order’ and classement ‘ordering’, they form a proportional analogy and could be noted développer:développement=classer:classement. In this particular case, the analogy is called formal (Lepage, 1998; Lepage, 2004b; Stroppa and Yvon, 2005; Langlais and Yvon, 2008) because it holds between the strings that realize the four lemma. In other words, the formal difference between développer and développement is exactly the same as the one that exists between classer and classement. This difference could be described by the following regex substitution that transforms the first string into the second one /^(.+)er$/^1ement$/ or by a non oriented pair of patterns ^(.+)er$:^(.+)ement$ where the variable parts (.+) represent the identical substrings in the two patterns. Note that these patterns are not minimal in that they take into account that the first two st"
2020.lrec-1.478,P98-1120,0,0.738579,"f GLAWI yielded 125,002 candidate pairs of lexemes. These pairs are merged with the ones yielded by the definitions (as detailed in Section 4.). We then select the valid pairs from this set of candidates as detailed in Sections 6. and 7. 6. Analogical selection of the derivational relations When two words such as développer and développement are in the same morphological relation as two others such as classer ‘order’ and classement ‘ordering’, they form a proportional analogy and could be noted développer:développement=classer:classement. In this particular case, the analogy is called formal (Lepage, 1998; Lepage, 2004b; Stroppa and Yvon, 2005; Langlais and Yvon, 2008) because it holds between the strings that realize the four lemma. In other words, the formal difference between développer and développement is exactly the same as the one that exists between classer and classement. This difference could be described by the following regex substitution that transforms the first string into the second one /^(.+)er$/^1ement$/ or by a non oriented pair of patterns ^(.+)er$:^(.+)ement$ where the variable parts (.+) represent the identical substrings in the two patterns. Note that these patterns are"
2020.lrec-1.478,C04-1106,0,0.71649,"d 125,002 candidate pairs of lexemes. These pairs are merged with the ones yielded by the definitions (as detailed in Section 4.). We then select the valid pairs from this set of candidates as detailed in Sections 6. and 7. 6. Analogical selection of the derivational relations When two words such as développer and développement are in the same morphological relation as two others such as classer ‘order’ and classement ‘ordering’, they form a proportional analogy and could be noted développer:développement=classer:classement. In this particular case, the analogy is called formal (Lepage, 1998; Lepage, 2004b; Stroppa and Yvon, 2005; Langlais and Yvon, 2008) because it holds between the strings that realize the four lemma. In other words, the formal difference between développer and développement is exactly the same as the one that exists between classer and classement. This difference could be described by the following regex substitution that transforms the first string into the second one /^(.+)er$/^1ement$/ or by a non oriented pair of patterns ^(.+)er$:^(.+)ement$ where the variable parts (.+) represent the identical substrings in the two patterns. Note that these patterns are not minimal i"
2020.lrec-1.478,W05-0616,0,0.701232,"date pairs of lexemes. These pairs are merged with the ones yielded by the definitions (as detailed in Section 4.). We then select the valid pairs from this set of candidates as detailed in Sections 6. and 7. 6. Analogical selection of the derivational relations When two words such as développer and développement are in the same morphological relation as two others such as classer ‘order’ and classement ‘ordering’, they form a proportional analogy and could be noted développer:développement=classer:classement. In this particular case, the analogy is called formal (Lepage, 1998; Lepage, 2004b; Stroppa and Yvon, 2005; Langlais and Yvon, 2008) because it holds between the strings that realize the four lemma. In other words, the formal difference between développer and développement is exactly the same as the one that exists between classer and classement. This difference could be described by the following regex substitution that transforms the first string into the second one /^(.+)er$/^1ement$/ or by a non oriented pair of patterns ^(.+)er$:^(.+)ement$ where the variable parts (.+) represent the identical substrings in the two patterns. Note that these patterns are not minimal in that they take into acc"
2020.lrec-1.478,W19-8510,0,0.0271207,"Missing"
2020.lrec-1.478,P13-1118,0,0.0195407,"chine learning and trained to decompose words into morphemes, like Linguistica (Goldsmith, 2001), Morfessor (Creutz and Lagus, 2005) or, more recently, the model of (Cotterell and Schütze, 2018); for a panorama, see (Bernhard et al., 2011). The other way to create derivational databases is to annotate lexicons semi-automatically. This annotation can take multiple forms: in CELEX (Baayen et al., 1995), the words are decomposed into morphemes; DeriNet (Vidra et al., 2019) describes the morphological relations between derived words and their bases; in CATVAR (Habash and Dorr, 2003) or DErivBase (Zeller et al., 2013) the lexicon is clustered into derivational families; for an exhaustive presentation of the derivational databases available for Romance, Germanic and Slavic languages, see (Kyjánek, 2018). The main contributions of Glawinette with respect to these resources are (i) the combination of the derivational families with the derivational series, and (ii) the description of the morphological relations by means of linguistically relevant exponents. For many year, French lacked a large-scale derivational resources similar to CELEX. The first derivational databases aimed at closing the gap is Démonette"
2021.jeptalnrecital-taln.10,P98-1120,0,0.63144,"Missing"
2021.jeptalnrecital-taln.10,C96-2121,0,0.247437,"Missing"
2021.jeptalnrecital-taln.10,W14-1618,0,0.064754,"Missing"
2021.jeptalnrecital-taln.10,Q15-1016,0,0.0726251,"Missing"
2021.jeptalnrecital-taln.10,N13-1090,0,0.115129,"Missing"
2021.jeptalnrecital-taln.10,L18-1228,0,0.0333152,"Missing"
2021.jeptalnrecital-taln.10,radev-etal-2002-evaluating,0,0.0153727,"Missing"
2021.jeptalnrecital-taln.10,2007.jeptalnrecital-long.37,0,0.157858,"Missing"
2021.jeptalnrecital-taln.10,C08-1114,0,0.156047,"Missing"
2021.jeptalnrecital-taln.10,R19-1147,0,0.0206954,"Missing"
2021.jeptalnrecital-taln.10,P16-1158,0,0.022487,"Missing"
2021.jeptalnrecital-taln.20,Q14-1022,0,0.0264206,"Missing"
2021.jeptalnrecital-taln.20,E12-1027,0,0.0772706,"Missing"
2021.jeptalnrecital-taln.20,N19-1423,0,0.0742582,"Missing"
2021.jeptalnrecital-taln.20,S16-2002,0,0.0272269,"Missing"
2021.jeptalnrecital-taln.20,D17-1271,0,0.0301046,"Missing"
2021.jeptalnrecital-taln.20,P14-2085,0,0.0376093,"Missing"
2021.jeptalnrecital-taln.20,P16-1166,0,0.0307235,"Missing"
2021.jeptalnrecital-taln.20,D15-1294,0,0.0401697,"Missing"
2021.jeptalnrecital-taln.20,Q18-1048,0,0.0287551,"Missing"
2021.jeptalnrecital-taln.20,ide-etal-2008-masc,0,0.0137302,"Missing"
2021.jeptalnrecital-taln.20,D14-1181,0,0.00576178,"Missing"
2021.jeptalnrecital-taln.20,2020.coling-main.401,0,0.0349433,"Missing"
2021.jeptalnrecital-taln.20,W19-0409,0,0.055761,"Missing"
2021.jeptalnrecital-taln.20,2016.lilt-13.3,0,0.109764,"Missing"
2021.jeptalnrecital-taln.20,2020.coling-main.109,1,0.810761,"Missing"
2021.jeptalnrecital-taln.20,J00-4004,0,0.542683,"Missing"
2021.jeptalnrecital-taln.20,J81-4005,0,0.616075,"Missing"
2021.sigmorphon-1.28,N15-1107,0,0.0246514,"form and an inflected one. Generalizations over similar mappings (e.g. love-loved,walk-walked vs. sing-sang, ringrang) are learned from the dependences between the phonemes in sequences. The APs presented in Section 3 provide a description complementary to the lemma-form mapping in which analogical regularities may be locally to a single pair of forms (BAPs) or globally from the entire lexicon (FAPs). These paradigmatic analogies emerge when the forms are contrasted with all other forms of their lexeme and the other forms that occupy the same cell in the paradigm (Bonami and Beniamine, 2016; Ahlberg et al., 2015; Albright, 2002). The models we designed for the task combine the capacity of the sequence-to-sequence models to learn the regularities present in strings of phonemes with the alternation patterns acquired from the paradigms, in order to predict native speaker responses in a wug test. 4.1 Models We designed four models for the shared task. 4.1.1 Model 1 In the first model, M1, we consider morphological inflection as a mapping over sequences. The mapping is implemented by bidirectional LSTMs with dropouts (Hochreiter and Schmidhuber, 1997; Gal and Ghahramani, 2016). The hidden states of the en"
2021.sigmorphon-1.28,2021.scil-1.20,0,0.0480167,"Missing"
2021.sigmorphon-1.28,P19-1376,0,0.0264591,"erell (2018) argue that a neural encoder-decoder network (ED) can perform morphological inflection tasks in a cognitively valid manner. In particular, the authors claim that, in a wug test protocol, ED’s outputs significantly correlate with human judgements for nonce verbs supporting the assumption that the model learns representations of specific knowledge and involves cognitive mechanisms that are known to underlie language processing in the speakers. However, whether and how such models are able to mimic the human behaviour of subjects exposed to the same stimuli is still an open question (Corkery et al., 2019). Part 2 of Shared Task 0 addresses this same issue. More specifically, it adopts the experimental approach of Albright and Hayes (2003). The task is to design models which predict the inflected forms of a set of nonce verbs in a given language and that have output scores of the predictions that correlate with human judgements. In this paper we report on a series of experiments that address the shared task by exploring whether pre-learned formal analogies between strings can be usefully combined with an ED architecture to alleviate some limitations of the application of an ED architecture to r"
2021.sigmorphon-1.28,N16-1077,0,0.0144511,"e a simulation of how English past tense is learned. They focus on pairs of verb forms like go-went and walk-walked and consider that morphological learning is a gradual process which includes an intermediate phases of “over-regularization” (where the past form of go is goed instead of went). This yields the wellknown“U-shape” curves observed in the developmental phases of morphological competence in children. More recently, models based on deep learning architectures have been used (Malouf, 2017) and in particular sequence-to-sequence models able to predict one form of a lexeme from another (Faruqui et al., 2016; Kirov and Cotterell, 2018). These approaches are based on the assumption that the morphological learning can reduce to a simple mapping between a base form and an inflected one. Generalizations over similar mappings (e.g. love-loved,walk-walked vs. sing-sang, ringrang) are learned from the dependences between the phonemes in sequences. The APs presented in Section 3 provide a description complementary to the lemma-form mapping in which analogical regularities may be locally to a single pair of forms (BAPs) or globally from the entire lexicon (FAPs). These paradigmatic analogies emerge when t"
2021.sigmorphon-1.28,L16-1218,1,0.754656,"tari:fi:r@n tari:fi:r@nt V.PTCP;PRS ‘to tariff’ tari:fi:r@n tari:fi:rt@n V;SBJV;PST;3;PL ast@n ast@nt V.PTCP;PRS ‘to lug’ ast@n ast@t@t V;SBJV;PST;2;PL vain@n vain@nt V.PTCP;PRS “ “ ‘to cry’ vain@n vaint V;IND;PRS;3;SG “ “ tsErStrait@n tsErStrait@nt V.PTCP;PRS “ “ ‘to disagree’ tsErStrait@n tsErStrait@st V;SBJV;PST;2;SG “ “ In this paper, we rely on an algorithm for inferring BAPs and FAPs initially developed to create Glawinette (Hathout et al., 2020). Glawinette is a French derivational lexicon created from the definitions of the GLAWI machine readable dictionary (Sajous and Hathout, 2015; Hathout and Sajous, 2016). Glawinette provides a description of derivational morphology by means of morphological families and derivational series; it is part of an effort aiming at the design of derivational paradigms. BAPs and FAPs have been adapted to the datasets of the current task, analogizing inflectional paradigms to derivational families and pairs of inflectional paradigm cells to derivational series. For instance, (4) presents an excerpt of an inflectional series in the inflectional paradigm of the verb anspielen that realizes the features V;NFIN and V.PTCP;PST. In turn, this series yields two series of word"
2021.sigmorphon-1.28,2020.lrec-1.478,1,0.723847,"Spi:l@n anSpi:l@n Spi:l@t+an Spi:lt@+an Spi:lt+an Spi:l@+an anSpi:l@st anSpi:lst V;IND;PST;2;PL V;SBJV;PST;1;SG V;IMP;2;PL V;IMP;2;SG V;SBJV;PST;2;SG V;IND;PRS;2;SG tari:fi:r@n tari:fi:r@nt V.PTCP;PRS ‘to tariff’ tari:fi:r@n tari:fi:rt@n V;SBJV;PST;3;PL ast@n ast@nt V.PTCP;PRS ‘to lug’ ast@n ast@t@t V;SBJV;PST;2;PL vain@n vain@nt V.PTCP;PRS “ “ ‘to cry’ vain@n vaint V;IND;PRS;3;SG “ “ tsErStrait@n tsErStrait@nt V.PTCP;PRS “ “ ‘to disagree’ tsErStrait@n tsErStrait@st V;SBJV;PST;2;SG “ “ In this paper, we rely on an algorithm for inferring BAPs and FAPs initially developed to create Glawinette (Hathout et al., 2020). Glawinette is a French derivational lexicon created from the definitions of the GLAWI machine readable dictionary (Sajous and Hathout, 2015; Hathout and Sajous, 2016). Glawinette provides a description of derivational morphology by means of morphological families and derivational series; it is part of an effort aiming at the design of derivational paradigms. BAPs and FAPs have been adapted to the datasets of the current task, analogizing inflectional paradigms to derivational families and pairs of inflectional paradigm cells to derivational series. For instance, (4) presents an excerpt of an"
2021.sigmorphon-1.28,P82-1020,0,0.667734,"Missing"
2021.sigmorphon-1.28,W14-2804,0,0.0505973,"the two forms. (5) word-form1 word-form2 BAP1 BAP2 ap ap + + g@ g@ tail tai“l “ + + @n t @n t Note that a BAP can also be seen as a characterization of an analogical series. For instance, the pairs of forms in (4) can all be aligned in exactly the same way as in (5), they all have the same BAP ++@n/+g@+t and they form formal analogies (Lepage, 1998, 2004b,a; Stroppa and Yvon, 2005; Langlais and Yvon, 2008). More specifically, if two pairs of forms (F1 , F2 ) and (F3 , F4 ) have the same BAP, then F1 : F2 :: F3 : F4 . BAPs could also be computed for entire inflectional paradigms as proposed by Hulden (2014). Also note that BAPs are not specific to an inflection class, as two classes may exhibit common behavior in one part of their paradigm but not in another. For instance, the BAP +/+s describes the formal relation that connects the infinitive and the V;PRS;3;SG form of both regular (work) and irregular English verbs (eat). Fine alternation patterns. Unlike BAPs which are derived solely from the examination of pairwise alternations, FAPs rely on the place of the two word-forms in the overall morphological system to identify more stable recurrent partials corresponding to traditional exponents. F"
2021.sigmorphon-1.28,L18-1293,0,0.0203353,"Missing"
2021.sigmorphon-1.28,C08-2013,0,0.0394651,"heir respective patterns. For example, SequenceMatcher aligns the forms aptail@n and apg@tailt as in (5) “ “ BAPs are which yields the ++en/+ge+t BAP. therefore calculated separately for each entry considering only the two forms. (5) word-form1 word-form2 BAP1 BAP2 ap ap + + g@ g@ tail tai“l “ + + @n t @n t Note that a BAP can also be seen as a characterization of an analogical series. For instance, the pairs of forms in (4) can all be aligned in exactly the same way as in (5), they all have the same BAP ++@n/+g@+t and they form formal analogies (Lepage, 1998, 2004b,a; Stroppa and Yvon, 2005; Langlais and Yvon, 2008). More specifically, if two pairs of forms (F1 , F2 ) and (F3 , F4 ) have the same BAP, then F1 : F2 :: F3 : F4 . BAPs could also be computed for entire inflectional paradigms as proposed by Hulden (2014). Also note that BAPs are not specific to an inflection class, as two classes may exhibit common behavior in one part of their paradigm but not in another. For instance, the BAP +/+s describes the formal relation that connects the infinitive and the V;PRS;3;SG form of both regular (work) and irregular English verbs (eat). Fine alternation patterns. Unlike BAPs which are derived solely from the"
2021.sigmorphon-1.28,P98-1120,0,0.100249,"mon parts by + and copying the differences in their respective patterns. For example, SequenceMatcher aligns the forms aptail@n and apg@tailt as in (5) “ “ BAPs are which yields the ++en/+ge+t BAP. therefore calculated separately for each entry considering only the two forms. (5) word-form1 word-form2 BAP1 BAP2 ap ap + + g@ g@ tail tai“l “ + + @n t @n t Note that a BAP can also be seen as a characterization of an analogical series. For instance, the pairs of forms in (4) can all be aligned in exactly the same way as in (5), they all have the same BAP ++@n/+g@+t and they form formal analogies (Lepage, 1998, 2004b,a; Stroppa and Yvon, 2005; Langlais and Yvon, 2008). More specifically, if two pairs of forms (F1 , F2 ) and (F3 , F4 ) have the same BAP, then F1 : F2 :: F3 : F4 . BAPs could also be computed for entire inflectional paradigms as proposed by Hulden (2014). Also note that BAPs are not specific to an inflection class, as two classes may exhibit common behavior in one part of their paradigm but not in another. For instance, the BAP +/+s describes the formal relation that connects the infinitive and the V;PRS;3;SG form of both regular (work) and irregular English verbs (eat). Fine alternat"
2021.sigmorphon-1.28,C04-1106,0,0.244635,"Missing"
2021.sigmorphon-1.28,W05-0616,0,0.12621,"ing the differences in their respective patterns. For example, SequenceMatcher aligns the forms aptail@n and apg@tailt as in (5) “ “ BAPs are which yields the ++en/+ge+t BAP. therefore calculated separately for each entry considering only the two forms. (5) word-form1 word-form2 BAP1 BAP2 ap ap + + g@ g@ tail tai“l “ + + @n t @n t Note that a BAP can also be seen as a characterization of an analogical series. For instance, the pairs of forms in (4) can all be aligned in exactly the same way as in (5), they all have the same BAP ++@n/+g@+t and they form formal analogies (Lepage, 1998, 2004b,a; Stroppa and Yvon, 2005; Langlais and Yvon, 2008). More specifically, if two pairs of forms (F1 , F2 ) and (F3 , F4 ) have the same BAP, then F1 : F2 :: F3 : F4 . BAPs could also be computed for entire inflectional paradigms as proposed by Hulden (2014). Also note that BAPs are not specific to an inflection class, as two classes may exhibit common behavior in one part of their paradigm but not in another. For instance, the BAP +/+s describes the formal relation that connects the infinitive and the V;PRS;3;SG form of both regular (work) and irregular English verbs (eat). Fine alternation patterns. Unlike BAPs which a"
C04-1173,W99-0901,0,0.0762723,"Missing"
C04-1173,C96-1005,0,0.135258,"Missing"
C04-1173,J98-1001,0,0.0631318,"Missing"
C04-1173,C90-2067,0,0.182568,"thin those entries. The basic idea is to consider the dictionary as an undirected graph whose nodes are noun entries, and an edge exists between two nodes whenever one of them occur in the definition of the other. More precisely, the graph of the dictionary encodes two types of lexicographical informations: (1) the definitions of the entries sub-senses and (2) the structure of the entries that is the hierarchical organisation of their subsenses. The graph then includes two types of nodes: w-nodes used for the words that occur 2 With the exceptions of the methods of (Kozima and Furugori, 1993; Ide and Véronis, 1990), both based on models of activation of lexical relations, but who present no quantified results. in the definitions and ∆-nodes used for the definitions of the sub-senses of the entries. The graph is created in three phases: 1. For each dictionary entry, there is a ∆node for the entry as a whole and there is one ∆-node for each of the sub-senses of the entry. Then an edge is added between each ∆-node and the ∆-nodes which represent the sub-senses of the next lower level. In other words, the graph includes a tree of ∆-nodes which encodes the hierarchical structure of each entry. 2. A w-node is"
C04-1173,E93-1028,0,0.269738,"nd verb lemmas occurring within those entries. The basic idea is to consider the dictionary as an undirected graph whose nodes are noun entries, and an edge exists between two nodes whenever one of them occur in the definition of the other. More precisely, the graph of the dictionary encodes two types of lexicographical informations: (1) the definitions of the entries sub-senses and (2) the structure of the entries that is the hierarchical organisation of their subsenses. The graph then includes two types of nodes: w-nodes used for the words that occur 2 With the exceptions of the methods of (Kozima and Furugori, 1993; Ide and Véronis, 1990), both based on models of activation of lexical relations, but who present no quantified results. in the definitions and ∆-nodes used for the definitions of the sub-senses of the entries. The graph is created in three phases: 1. For each dictionary entry, there is a ∆node for the entry as a whole and there is one ∆-node for each of the sub-senses of the entry. Then an edge is added between each ∆-node and the ∆-nodes which represent the sub-senses of the next lower level. In other words, the graph includes a tree of ∆-nodes which encodes the hierarchical structure of ea"
F13-1021,de-mareuil-etal-2000-french,0,0.106464,"Missing"
F13-1021,W12-0909,1,0.884989,"Missing"
F13-1021,clement-etal-2004-morphology,0,0.0603535,"Missing"
F13-1021,E12-1059,0,0.0681223,"Missing"
F13-1021,C94-1097,0,0.326,"Missing"
F13-1021,W04-2104,0,0.0912097,"Missing"
F13-1021,serasset-2012-dbnary,0,0.03081,"Missing"
F13-1021,zesch-etal-2008-extracting,0,0.0979201,"Missing"
F14-1019,W08-2205,0,0.0613093,"Missing"
F14-1019,J01-2001,0,0.141254,"Missing"
F14-1019,P98-1120,0,0.217427,"Missing"
F14-1019,P04-1036,0,0.0713969,"Missing"
F14-1019,W04-2104,0,0.0926649,"Missing"
F14-1019,fillmore-etal-2002-framenet,0,0.121236,"Missing"
F14-1019,2008.jeptalnrecital-long.18,0,0.0832624,"Missing"
F14-1019,2002.jeptalnrecital-long.22,1,0.736819,"Missing"
F14-1019,E09-3009,0,0.0584142,"Missing"
hathout-2002-wordnet,N01-1024,0,\N,Missing
hathout-2002-wordnet,W98-1239,0,\N,Missing
hathout-2002-wordnet,J01-2001,0,\N,Missing
hathout-2002-wordnet,W00-0712,0,\N,Missing
hathout-2002-wordnet,P98-1120,0,\N,Missing
hathout-2002-wordnet,C98-1116,0,\N,Missing
hathout-2002-wordnet,namer-dal-2000-gederif,0,\N,Missing
hathout-2002-wordnet,W99-0904,0,\N,Missing
hathout-etal-2014-glaff,serasset-2012-dbnary,0,\N,Missing
hathout-etal-2014-glaff,clement-etal-2004-morphology,0,\N,Missing
hathout-etal-2014-glaff,W04-2104,0,\N,Missing
hathout-etal-2014-glaff,E12-1059,0,\N,Missing
hathout-etal-2014-glaff,zesch-etal-2008-extracting,0,\N,Missing
hathout-etal-2014-glaff,de-mareuil-etal-2000-french,0,\N,Missing
L16-1173,2014.lilt-11.6,1,0.51401,"f new resources into Démonette and illustrate them with the incorporation of two lexicons: Verbaction and Lexeur. The remainder of the article is organized as follows: Section 2. introduces Démonette’s main features. Section 3. presents the resources used to create the current version of Démonette: DériF, Morphonette, Verbaction and Lexeur. We then discuss some aspects of the integration of the two last into Démonette (Section 4.). Finally, in Section 5., we review the adaptability of Démonette with the descriptive requirements of the derivational morphology of French. 2. Démonette Démonette (Hathout and Namer, 2014) is a general resource designed for the description of word formation (WF) of French. It is eventually intended to partially fill the lack of broad-coverage morphological resources of French as they exist for other languages such as DerivBase for German (Zeller et al., 2013) or CELEX (Baayen et al., 1995) for English, German and Dutch. Démonette has an original structure since it is a directed graph, where vertices represent lexemes and edges represent derivational relations. In its current version (1.3), it only contains relations between members of the same family. As illustrated in Figure 1"
L16-1173,2001.jeptalnrecital-tutoriel.0,0,0.305908,"Missing"
L16-1173,P13-1118,0,0.275058,"ere already validated. The harmonization of their content into a unified format offers them a second life. Moreover, they are enriched with new properties provided these can be deduced from their content. Démonette is released under a Creative Commons license. It is usable for theoretical and descriptive research in morphology, as a source of experimental material for psycholinguistics, natural language processing (NLP) and information retrieval (IR), where it fills a gap, since French lacks a large-coverage derivational resources database, similar to CELEX (Baayen et al., 1995) or DerivBase (Zeller et al., 2013). In its current state, Démonette consists of information coming from four different sources. They have been added in three successive stages. Overall, Démonette contains 108 888 entries. The entries are a morphological relations, that is pairs of morphologically related words (W1 , W2 ). W1 and W2 belong to the same derivational family and one of them at least is a derived word. Each entry associates a set of structural, morpho-semantic and morphophonological descriptions to a morphological relationship. Derived words described in Démonette include deverbal action nouns (essorage ‘spin’N ), a"
L16-1218,I13-1041,0,0.0574588,"Missing"
L16-1218,2014.lilt-11.6,1,0.836431,"near-synonym 196 antonym 494 Table 4: Semantic relations The number of morphological sections per POS and the total number of morphological relations are given in Table 6. In addition to the morphological sections, information about derivational or compositional coinage of words may be found in the etymology sections (cf. section 2.3.). GLAWI’s morphological relations may be used for research in computational morphology and to build morphological resources like Morphonette,3 a paradigm-based morphological network (Hathout, 2011) and D´emonette,4 a French derivational morpho-semantic network (Hathout and Namer, 2014). They could also be leveraged in NLP applications. For example, Pad´o et al. (2013) use derivative words to overcome data sparseness in distributional analysis. &lt;translations> &lt;trans lang=""de"">Radweg&lt;/trans> &lt;trans lang=""en"">bicycle path&lt;/trans> &lt;trans lang=""it"">pista ciclabile&lt;/trans> &lt;trans lang=""it"">ciclopista&lt;/trans> &lt;trans lang=""nl"">fietspad&lt;/trans> &lt;trans lang=""no_nb"">sykkelvei&lt;/trans> &lt;trans lang=""no_nn"">sykkelveg&lt;/trans> &lt;trans lang=""pt"">ciclovia&lt;/trans> &lt;trans lang=""sv"">cykelv¨ ag&lt;/trans> &lt;/translations> Figure 6: Translations for piste cyclable ‘bicycle path’ POS nouns adjectives ve"
L16-1218,W14-5809,1,0.634797,"ue material opens way to the renewal of MRD-based methods, notably the automated extraction and acquisition of semantic relations. Keywords: French, Machine-Readable Dictionary, Free Lexical Resource, Wiktionary, Wiktionnaire 1. Introduction POS noun proper noun adjective verb adverb total 1 GLAWI is a large Machine-Readable Dictionary (MRD) extracted from Wiktionnaire, the French language edition of Wiktionary, and converted into a workable XML format. In a previous work, Sajous et al. (2010) introduced WiktionaryX, an electronic lexicon including lemmas, semantic relations and translations. Hathout et al. (2014b) described ` how GLAFF, a large inflectional and phonological lexicon, has been extracted from the same source. The assessment ` of GLAFF’s lexical coverage and the quality of its phonemic transcriptions has shown that Wiktionnaire is a valuable starting point to build lexical resources of good quality. Sajous and Hathout (2015) introduced GLAWI, a dictionary built from an updated version of Wiktionnaire that ` merges the information stored in WiktionaryX and GLAFF into a single resource. New information, such as etymology and morphological relations, has also been added. Sajous and Hathout"
L16-1218,hathout-etal-2014-glaff,1,0.753071,"Missing"
L16-1218,E12-1014,0,0.0127549,"pound 1,118 derivative 50,506 related 22,874 adjectives 4,939 compound 309 derivative 9,481 related 6,767 verbs 5,443 compound 109 derivative 10,684 related 5,170 adverbs 899 derivative 488 related 1,284 Translations # sections # translations 71,133 383,612 16,797 60,360 11,484 70,615 3,014 14,478 102,428 529,065 POS nouns Table 5: Translations Many applications may benefit from these translations. Statistical machine translation algorithms tend to disregard lexicons. However, when no parallel corpora are available, algorithms may resort to monolingual corpora and bilingual lexicon induction (Klementiev et al., 2012). The induction process requires a seed dictionary that GLAWI could provide for many language pairs. GLAWI’s translations could also be used to complement existing multilingual resources such as PanDictionary (Mausam et al., 2009), a multilingual translation graphs which compiles numerous dictionaries. Translations may even help infer monolingual information. For example, they can be used to compute semantic relatedness: two words of a given language translating to the same words in different languages are likely to have close meanings (Sajous et al., 2013). 2.6. Morphological relations GLAWI"
L16-1218,P09-1030,0,0.0225969,"slations 71,133 383,612 16,797 60,360 11,484 70,615 3,014 14,478 102,428 529,065 POS nouns Table 5: Translations Many applications may benefit from these translations. Statistical machine translation algorithms tend to disregard lexicons. However, when no parallel corpora are available, algorithms may resort to monolingual corpora and bilingual lexicon induction (Klementiev et al., 2012). The induction process requires a seed dictionary that GLAWI could provide for many language pairs. GLAWI’s translations could also be used to complement existing multilingual resources such as PanDictionary (Mausam et al., 2009), a multilingual translation graphs which compiles numerous dictionaries. Translations may even help infer monolingual information. For example, they can be used to compute semantic relatedness: two words of a given language translating to the same words in different languages are likely to have close meanings (Sajous et al., 2013). 2.6. Morphological relations GLAWI contains compounds, derivative and “related” words that correspond to Wiktionnaire’s sections entitled Compos´es, D´eriv´es and Apparent´es e´ tymologiques. Examples of such morphological relations are presented for the noun nom ‘"
L16-1218,melero-etal-2012-holaaa,0,0.0220577,"Missing"
L16-1218,P13-2128,0,0.0709883,"Missing"
L16-1218,C12-1160,0,0.0206169,"Missing"
L16-1218,W09-3304,0,0.062039,"Missing"
L18-1619,N13-1014,0,0.0243344,"nguages considered. Then, a tagset has to be created or adapted to the language, which requires linguistic expertise. Finally, the annotation also requires annotators with linguistic expertise. Crowdsourcing can be used for part-of-speech annotation (Hovy et al., 2014), and was even used for Alsatian (Millour et al., 2017). Yet, crowdsourcing necessitates an adapted platform, and communication to possible speakers, who for example in the case of Picard, are rare. A possible direction for POS tagging could be to create a minimum tag dictionary for the most frequent word types, such as used by (Garrette and Baldridge, 2013). This kind of approach still requires a test corpus to evaluate the tagger; and the performance remains low compared to more resourced languages. 6. Conclusion We have presented our methodology for producing corpora with POS annotations for three regional languages of France, namely Alsatian, Occitan and Picard. The tagsets are based on an extended version of the Universal POS tags, with some language-specific additions to account for particular linguistic phenomena. The annotation guidelines as well as the manually annotated corpora are freely available. We plan to use these corpora to devel"
L18-1619,P14-2062,0,0.0289724,"difficulties. First, it requires assembling a large textual corpus, which can be a challenge for these languages which have few electronic resources. Work on part-of-speech tagging for under-resourced languages is often based on parallel corpora, following (Yarowsky et al., 2001), but there are no such existing electronic corpora for the three languages considered. Then, a tagset has to be created or adapted to the language, which requires linguistic expertise. Finally, the annotation also requires annotators with linguistic expertise. Crowdsourcing can be used for part-of-speech annotation (Hovy et al., 2014), and was even used for Alsatian (Millour et al., 2017). Yet, crowdsourcing necessitates an adapted platform, and communication to possible speakers, who for example in the case of Picard, are rare. A possible direction for POS tagging could be to create a minimum tag dictionary for the most frequent word types, such as used by (Garrette and Baldridge, 2013). This kind of approach still requires a test corpus to evaluate the tagger; and the performance remains low compared to more resourced languages. 6. Conclusion We have presented our methodology for producing corpora with POS annotations fo"
L18-1619,C94-1097,0,0.819681,"Missing"
L18-1619,L16-1262,0,0.116016,"Missing"
L18-1619,W14-5303,1,0.882391,"Missing"
L18-1619,H01-1035,0,0.160961,"potlights that they lit the pit . Table 10: Annotation example for Picard The annotation guidelines and the corpora are available for all three languages on the Zenodo platform, in the RESTAURE project community (see Section 9. for the corpus list).17 5. Related Work Creating annotated corpora for under-resourced languages presents several difficulties. First, it requires assembling a large textual corpus, which can be a challenge for these languages which have few electronic resources. Work on part-of-speech tagging for under-resourced languages is often based on parallel corpora, following (Yarowsky et al., 2001), but there are no such existing electronic corpora for the three languages considered. Then, a tagset has to be created or adapted to the language, which requires linguistic expertise. Finally, the annotation also requires annotators with linguistic expertise. Crowdsourcing can be used for part-of-speech annotation (Hovy et al., 2014), and was even used for Alsatian (Millour et al., 2017). Yet, crowdsourcing necessitates an adapted platform, and communication to possible speakers, who for example in the case of Picard, are rare. A possible direction for POS tagging could be to create a minimu"
W06-3811,J02-2001,0,0.03705,"coverage, and the availability of such resources, in general and also in specialised domains. We present here a method exploiting such a graph structure to compute a distance between words. This distance is used to isolate candidate synonyms for a given word. We present an evaluation of the relevance of the candidates on a sample of the lexicon. 1 Introduction Thesaurus are an important resource in many natural language processing tasks. They are used to help information retrieval (Zukerman et al., 2003), machine or semi-automated translation, (Ploux and Ji, 2003; Barzilay and McKeown, 2001; Edmonds and Hirst, 2002) or generation (Langkilde and Knight, 1998). Since the gathering of such lexical information is a delicate and time-consuming endeavour, some effort has been devoted to the automatic building of sets of synonyms words or expressions. Synonym extraction suffers from a variety of methodological problems, however. Synonymy itself is not an easily definable notion. Totally equivalent words (in meaning and use) arguably do not exist, and some people prefer to talk about nearsynonyms (Edmonds and Hirst, 2002). A nearsynonym is a word that can be used instead of another one, in some contexts, without"
W06-3811,W05-0604,0,0.0906816,"equency of words in a corpus of ten years of the journal ""Le Monde"". The 50 words picked out in our sample have an average frequency of 2000 occurrences, while when we consider all our about 430 candidates for synonymy, the average frequency is 5300. Among the methods proposed to collect synonymy information, two families can be distinguished according to the input they consider. Either a general dictionary is used (or more than one (Wu and Zhou, 2003)), or a corpus of unconstrained texts from which lexical distributions are computed (simple collocations or syntactic dependencies) (Lin, 1998; Freitag et al., 2005) . The approach of (Barzilay and McKeown, 2001) uses a related kind of resource: multiple translations of the same text, with additional constraints on availability, and problems of text alignment, for only a third of the results being synonyms (when compared to Wordnet). The main conclusion to draw here is that our method is able to recover a lot of synonyms that are in the definition of words, and some in definitions not directly related, which seems to be an improvement on previous attempts from dictionaries. There is some arbitrariness in the method that should be further investigated (the"
W06-3811,C04-1173,1,0.863464,"Missing"
W06-3811,E93-1028,0,0.0606376,"at is hopefully not too noisy. A few studies have tried to use the lexical information available in a general dictionary and find patterns that would indicate synonymy relations (Blon65 Workshop on TextGraphs, at HLT-NAACL 2006, pages 65–72, c New York City, June 2006. 2006 Association for Computational Linguistics del et al., 2004; Ho and Cédrick, 2004). The general idea is that words are related by the definition they appear in, in a complex network that must be semantic in nature (this has been also applied to word sense disambiguation, albeit with limited success (Veronis and Ide, 1990; H.Kozima and Furugori, 1993)). We present here a method exploiting the graph structure of a dictionary, where words are related by the definition they appear in, to compute a distance between words. This distance is used to isolate candidate synonyms for a given word. We present an evaluation of the relevance of the candidates on a sample of the lexicon. 2 Semantic distance on a dictionary graph We describe here our method (dubbed Prox) to compute a distance between nodes in a graph. Basically, nodes are derived from entries in the dictionary or words appearing in definitions, and there are edges between an entry and the"
W06-3811,P98-1116,0,0.0208124,"resources, in general and also in specialised domains. We present here a method exploiting such a graph structure to compute a distance between words. This distance is used to isolate candidate synonyms for a given word. We present an evaluation of the relevance of the candidates on a sample of the lexicon. 1 Introduction Thesaurus are an important resource in many natural language processing tasks. They are used to help information retrieval (Zukerman et al., 2003), machine or semi-automated translation, (Ploux and Ji, 2003; Barzilay and McKeown, 2001; Edmonds and Hirst, 2002) or generation (Langkilde and Knight, 1998). Since the gathering of such lexical information is a delicate and time-consuming endeavour, some effort has been devoted to the automatic building of sets of synonyms words or expressions. Synonym extraction suffers from a variety of methodological problems, however. Synonymy itself is not an easily definable notion. Totally equivalent words (in meaning and use) arguably do not exist, and some people prefer to talk about nearsynonyms (Edmonds and Hirst, 2002). A nearsynonym is a word that can be used instead of another one, in some contexts, without too much change in meaning. This leaves of"
W06-3811,P98-2127,0,0.425462,"average frequency of words in a corpus of ten years of the journal ""Le Monde"". The 50 words picked out in our sample have an average frequency of 2000 occurrences, while when we consider all our about 430 candidates for synonymy, the average frequency is 5300. Among the methods proposed to collect synonymy information, two families can be distinguished according to the input they consider. Either a general dictionary is used (or more than one (Wu and Zhou, 2003)), or a corpus of unconstrained texts from which lexical distributions are computed (simple collocations or syntactic dependencies) (Lin, 1998; Freitag et al., 2005) . The approach of (Barzilay and McKeown, 2001) uses a related kind of resource: multiple translations of the same text, with additional constraints on availability, and problems of text alignment, for only a third of the results being synonyms (when compared to Wordnet). The main conclusion to draw here is that our method is able to recover a lot of synonyms that are in the definition of words, and some in definitions not directly related, which seems to be an improvement on previous attempts from dictionaries. There is some arbitrariness in the method that should be fu"
W06-3811,C04-1162,0,0.0592964,"Missing"
W06-3811,C94-1049,0,0.0783861,"Missing"
W06-3811,J03-2001,0,0.0156665,"antage of using a general dictionary lies in the coverage, and the availability of such resources, in general and also in specialised domains. We present here a method exploiting such a graph structure to compute a distance between words. This distance is used to isolate candidate synonyms for a given word. We present an evaluation of the relevance of the candidates on a sample of the lexicon. 1 Introduction Thesaurus are an important resource in many natural language processing tasks. They are used to help information retrieval (Zukerman et al., 2003), machine or semi-automated translation, (Ploux and Ji, 2003; Barzilay and McKeown, 2001; Edmonds and Hirst, 2002) or generation (Langkilde and Knight, 1998). Since the gathering of such lexical information is a delicate and time-consuming endeavour, some effort has been devoted to the automatic building of sets of synonyms words or expressions. Synonym extraction suffers from a variety of methodological problems, however. Synonymy itself is not an easily definable notion. Totally equivalent words (in meaning and use) arguably do not exist, and some people prefer to talk about nearsynonyms (Edmonds and Hirst, 2002). A nearsynonym is a word that can be"
W06-3811,C90-2067,0,0.123005,"in a set of proposals that is hopefully not too noisy. A few studies have tried to use the lexical information available in a general dictionary and find patterns that would indicate synonymy relations (Blon65 Workshop on TextGraphs, at HLT-NAACL 2006, pages 65–72, c New York City, June 2006. 2006 Association for Computational Linguistics del et al., 2004; Ho and Cédrick, 2004). The general idea is that words are related by the definition they appear in, in a complex network that must be semantic in nature (this has been also applied to word sense disambiguation, albeit with limited success (Veronis and Ide, 1990; H.Kozima and Furugori, 1993)). We present here a method exploiting the graph structure of a dictionary, where words are related by the definition they appear in, to compute a distance between words. This distance is used to isolate candidate synonyms for a given word. We present an evaluation of the relevance of the candidates on a sample of the lexicon. 2 Semantic distance on a dictionary graph We describe here our method (dubbed Prox) to compute a distance between nodes in a graph. Basically, nodes are derived from entries in the dictionary or words appearing in definitions, and there are"
W06-3811,C04-1146,0,0.05164,"Missing"
W06-3811,W03-1613,0,0.0117086,"in, in a complex network of an arguably semantic nature. The advantage of using a general dictionary lies in the coverage, and the availability of such resources, in general and also in specialised domains. We present here a method exploiting such a graph structure to compute a distance between words. This distance is used to isolate candidate synonyms for a given word. We present an evaluation of the relevance of the candidates on a sample of the lexicon. 1 Introduction Thesaurus are an important resource in many natural language processing tasks. They are used to help information retrieval (Zukerman et al., 2003), machine or semi-automated translation, (Ploux and Ji, 2003; Barzilay and McKeown, 2001; Edmonds and Hirst, 2002) or generation (Langkilde and Knight, 1998). Since the gathering of such lexical information is a delicate and time-consuming endeavour, some effort has been devoted to the automatic building of sets of synonyms words or expressions. Synonym extraction suffers from a variety of methodological problems, however. Synonymy itself is not an easily definable notion. Totally equivalent words (in meaning and use) arguably do not exist, and some people prefer to talk about nearsynonyms (Ed"
W06-3811,P01-1008,0,\N,Missing
W06-3811,C98-1112,0,\N,Missing
W06-3811,W03-1610,0,\N,Missing
W06-3811,C98-2122,0,\N,Missing
W08-2001,P98-1120,0,0.508246,"nbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact that dériveur is morphologically and semantically closer to dérive"
W08-2001,W02-0606,0,0.0784643,"m a fine-grained filtering. Technically, our model joins: (graphemic, phonological, etc.) can be used. They can be cumulated easily in spite of the differences in nature and origin. The model takes advantage of the redundancy of the features and is fairly insensitive to variation and exceptions. 3 Many works in the field of computational morphology aim at the discovery of relations between lexical units. All of them rely primarily on finding similarities between the word graphemic forms. These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity. As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automati"
W08-2001,W06-3811,1,0.924143,"currence in an n-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact that dériveur is mo"
W08-2001,W02-0604,0,0.0623678,"antage of the redundancy of the features and is fairly insensitive to variation and exceptions. 3 Many works in the field of computational morphology aim at the discovery of relations between lexical units. All of them rely primarily on finding similarities between the word graphemic forms. These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity. As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Cr"
W08-2001,W00-0712,0,0.178764,"Missing"
W08-2001,W02-0603,0,0.0546786,"Missing"
W08-2001,W05-0616,0,0.485568,"ar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact that dériveur is morphologically and semantically closer to dérive than to dérivationnelleme"
W08-2001,W98-1239,0,0.0953843,"Missing"
W08-2001,P00-1027,0,0.121745,"Missing"
W08-2001,J01-2001,0,0.0946318,"icates the lexical relatedness of the words. The members of the morphological family and the derivational series of each word are then identified among its lexical neighbors by means of formal analogies. This is work in progress and we still have to separate the members of the families from the members of the series. We also intend to conduct a similar experiment on the English lexicon and to evaluate our results in a more classical manner by using the CELEX database (Baayen et al., 1995) as gold standard. The evaluation should also be done with respect to well known systems like Linguistica (Goldsmith, 2001) or the morphological analyzer of Bernhard (2006). • N.fructification:N.identification:: V.fructifier:V.identifier • N.fruiterie:N.fruitier::N.laiterie:N.laitier • * N.fruit:N.bruit::V.frusquer:V.brusquer The first example is particularly interesting because it involves on one side suffixed words and on the other prefixed ones. The performance of the method strongly depends on the length of the headwords. Table 3 presents the number of analogies and the error rate for 13 groups of 5 words. The words of each group are of the same length. Lengths range from 4 to 16 letters. 8 analogies 29 22 8 1"
W08-2001,hathout-2002-wordnet,1,0.869085,"c cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lex"
W08-2001,C98-1116,0,\N,Missing
W14-5809,W02-0606,0,0.131976,"arable to those obtained with resources designed by professionals, when used to compute semantic relatedness of words. In Sajous et al. (2013a), we created an inflectional and phonological lexicon from Wiktionary and showed that its quality is comparable to those of reference lexicons, while the coverage is much wider. Comparatively little effort has been reported in literature on the exploitation of semantic relations to automatically identify morphological relations. Schone and Jurafsky (2000) learn morphology with a method based on semantic similarity extracted by latent semantic analysis. Baroni et al. (2002) combine orthographic (string edit distances) and semantic similarity (words’ contextual information) in order to discover morphologically related words. Along the same line, Zweigenbaum and Grabar (2003) acquire semantic information from a medical corpus and use it to detect morphologically derived words. More recently, Hathout (2008) uses the TLFi to discover morphologically related words by combining orthographic and semantic similarity with formal analogy. I another work, Pentheroudakis and Vanderwende (1993) present a method to automatically extract morphological relations from the defini"
W14-5809,2011.jeptalnrecital-long.17,0,0.0197551,"by the verb (e.g. verrouiller:verrouillage).6 It has been 5 Unfortunately, these results could not have been compared with those of Pentheroudakis and Vanderwende (1993) because their system makes use of a number of lexical and semantic resources that are not available for French. However, a comparison with Baroni et al. (2002) is underway although their method is corpus-based (and not MRD-based). 6 Verbaction is freely available at: http://redac.univ-tlse2.fr/lexiques/verbaction.html. 71 used in syntactic dependency parsing by Bourigault (2007), in the construction of the French TimeBank by Bittar et al. (2011), in question answering systems by Bernhard et al. (2011), etc. (6) verrouillageN ‘locking’ = Action de verrouiller. ‘the act of locking.’ (7) nous v´erouillons la porte rapidement le verrouillage de la porte est rapide ‘we quickly lock the gate’ ‘gate locking is quick’ In our experiment, we used the linear SVM classifier liblinear of Fan et al. (2008) to assign a semantic type to the definitions that have a nominal definiendum and where the morphosemantic head of the definiens is a verb as in (4) or (6). Verbaction was used to select a corpus of 1,198 of such definitions. Three judges annotat"
W14-5809,C73-2005,0,0.471748,"Missing"
W14-5809,P85-1037,0,0.731276,"Missing"
W14-5809,W02-0908,0,0.0433907,"ed MRD which contains, among other things, definitions and morphological relations. In Section 4, we explain how we used Wiktionnaire’s morphological sections to create a lexicon of morphologically related words. The notion of morphological definitions and their automatic identification are introduced in Section 5. In Section 6, we show how these definitions enable us to acquire new derived words and enrich the initial lexicon. Finally, Section 7 describes an experiment where we semantically typed process nouns definitions. 2 Related work Semantic relations are usually acquired using corpora (Curran and Moens, 2002; van der Plas and Bouma, 2005; Heylen et al., 2008) but may also be acquired from MRDs. MRDs-based approaches are bound to the availability of such resources. However, for some languages including French, no such resource exists. Recent years have seen the development of large resources built automatically by aggregating and/or translating data originating from different sources. For example, Sagot and Fiˇser (2008) have built WOLF, “a free French Wordnet” and Navigli and Ponzetto (2010) BabelNet, a large multilingual semantic network. Such resources tend to favor coverage over reliability an"
W14-5809,W08-2001,1,0.958116,"ffort has been reported in literature on the exploitation of semantic relations to automatically identify morphological relations. Schone and Jurafsky (2000) learn morphology with a method based on semantic similarity extracted by latent semantic analysis. Baroni et al. (2002) combine orthographic (string edit distances) and semantic similarity (words’ contextual information) in order to discover morphologically related words. Along the same line, Zweigenbaum and Grabar (2003) acquire semantic information from a medical corpus and use it to detect morphologically derived words. More recently, Hathout (2008) uses the TLFi to discover morphologically related words by combining orthographic and semantic similarity with formal analogy. I another work, Pentheroudakis and Vanderwende (1993) present a method to automatically extract morphological relations from the definitions of MRDs. The authors automatically identify classes of morphologically related words by comparing the semantic information in the entry of the derivative with the information stored in the candidate base form. This effort shows the crucial importance and the potential of the MRDs’ definitions to acquire and discover morphological"
W14-5809,heylen-etal-2008-modelling,0,0.0302569,"and morphological relations. In Section 4, we explain how we used Wiktionnaire’s morphological sections to create a lexicon of morphologically related words. The notion of morphological definitions and their automatic identification are introduced in Section 5. In Section 6, we show how these definitions enable us to acquire new derived words and enrich the initial lexicon. Finally, Section 7 describes an experiment where we semantically typed process nouns definitions. 2 Related work Semantic relations are usually acquired using corpora (Curran and Moens, 2002; van der Plas and Bouma, 2005; Heylen et al., 2008) but may also be acquired from MRDs. MRDs-based approaches are bound to the availability of such resources. However, for some languages including French, no such resource exists. Recent years have seen the development of large resources built automatically by aggregating and/or translating data originating from different sources. For example, Sagot and Fiˇser (2008) have built WOLF, “a free French Wordnet” and Navigli and Ponzetto (2010) BabelNet, a large multilingual semantic network. Such resources tend to favor coverage over reliability and may contain errors and This work is licenced under"
W14-5809,P86-1018,0,0.691876,"Missing"
W14-5809,P10-1023,0,0.0608567,"ntically typed process nouns definitions. 2 Related work Semantic relations are usually acquired using corpora (Curran and Moens, 2002; van der Plas and Bouma, 2005; Heylen et al., 2008) but may also be acquired from MRDs. MRDs-based approaches are bound to the availability of such resources. However, for some languages including French, no such resource exists. Recent years have seen the development of large resources built automatically by aggregating and/or translating data originating from different sources. For example, Sagot and Fiˇser (2008) have built WOLF, “a free French Wordnet” and Navigli and Ponzetto (2010) BabelNet, a large multilingual semantic network. Such resources tend to favor coverage over reliability and may contain errors and This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 65 Proceedings of the Workshop on Lexical and Grammatical Resources for Language Processing, pages 65–74, Coling 2014, Dublin, Ireland, August 24 2014. inaccuracy, or be incomplete. Pierrel (2013), while criticizing these resources, describes the digitizat"
W14-5809,W00-0712,0,0.0877052,"f view has not been done yet, Zesch and Gurevych (2010) have shown that lexical resources built by crowds lead to results comparable to those obtained with resources designed by professionals, when used to compute semantic relatedness of words. In Sajous et al. (2013a), we created an inflectional and phonological lexicon from Wiktionary and showed that its quality is comparable to those of reference lexicons, while the coverage is much wider. Comparatively little effort has been reported in literature on the exploitation of semantic relations to automatically identify morphological relations. Schone and Jurafsky (2000) learn morphology with a method based on semantic similarity extracted by latent semantic analysis. Baroni et al. (2002) combine orthographic (string edit distances) and semantic similarity (words’ contextual information) in order to discover morphologically related words. Along the same line, Zweigenbaum and Grabar (2003) acquire semantic information from a medical corpus and use it to detect morphologically derived words. More recently, Hathout (2008) uses the TLFi to discover morphologically related words by combining orthographic and semantic similarity with formal analogy. I another work,"
W14-5809,serasset-2012-dbnary,0,0.189363,"Missing"
W14-5809,W05-0616,0,0.405686,"Missing"
W14-5809,zesch-etal-2008-extracting,0,0.231497,"Missing"
W14-6601,J10-4006,0,0.0993487,"Missing"
W14-6601,W11-2501,0,0.0343859,"Missing"
W14-6601,D11-1094,1,0.899938,"Missing"
W19-2908,J10-4006,0,0.266917,"2013). Even if the performance of these systems is impressive for some specific tasks (analogy resolution, lexical substitution, etc.), they usually fail to provide a fine grained characterisation of the relation between two words. Current distributional semantic models tend to aggregate all the classical lexical relations (e.g. synonymy, hypo/hypernymy, meronymy) and to confuse relations between similar words (e.g. couch - sofa) and relations between associated words (e.g. couch - nap). There is also a need for evaluation data when comparing and assessing these techniques (Hill et al., 2015; Baroni and Lenci, 2010). This paper proposes a step toward the satisfaction of both needs. We use data gathered in psycholinguistics experiments to compare different similarity measures and at the same time investigate how using complementary computational semantic techniques can help characterising lexical relations between stimuli and responses provided by subjects in a word association task. Section 2 describes the Evolex protocol from which data was collected as well as the manual annotation of the lexical relations in the collected dataset. We present the computational measures of semantic similarity in Section"
W19-2908,W11-2501,0,0.0189754,"s. 2nd-order similarity can be computed in a number of ways (Baroni and Lenci, 2010; Baroni et al., 2009), and for a few years most of the work and research has focused on word embeddings. For this experiment, we used Word2vec (Mikolov et al., 2013) on the same FrWac corpus to obtain a dense matrix in which each word is represented by a numeric vector. The cosine distance was then computed to measure the similarity between two words. In the absence of benchmark test sets for French (while many exist for English, including BLESS that can be used to tune a model for specific semantic relations (Baroni and Lenci, 2011), we relied on the default parameters3 . 3.2 Dictionary-Based Similarity TLF.1st similarity is based on the principle that two words are considered similar if one appears in the definition of the other. We computed this similarity by building an undirected and unweighted graph with words as vertices (V ) and relations between words as edges (E). The TLF.1st measure relies on the graph GT LF = (VT LF , ET LF ) where ∀x, y ∈ VT LF , {x, y} ∈ ET LF iff x appears in the TLF’s definition of y or vice-versa (or both). This similarity measure is therefore binary: the similarity between x and y is 1 i"
W19-2908,J90-1003,0,0.585343,"tational Linguistics co-hyponym:balanoire(swing)/toboggan(slide) hypernym:balancoire(swing)/jeu(game) meronym:balancoire(swing)/corde(rope) hyponym:animal(animal)/chat(cat holonym:doigt(finger)/main(hand) synonym:canap(couch)/sofa(sofa) antonym:aube(dawn)/crpuscule(dusk) is to obtain such data through the analysis of reference language data with NLP techniques. The use of data-based inductive methods for automatically measuring the similarity between words is one of the key task in computational semantics. If the first methods were based on the collocation frequency of words in large corpora (Church and Hanks, 1990; Evert, 2009), newer techniques rely on the principles of distributional semantics (Lenci, 2008; Mikolov et al., 2013). Even if the performance of these systems is impressive for some specific tasks (analogy resolution, lexical substitution, etc.), they usually fail to provide a fine grained characterisation of the relation between two words. Current distributional semantic models tend to aggregate all the classical lexical relations (e.g. synonymy, hypo/hypernymy, meronymy) and to confuse relations between similar words (e.g. couch - sofa) and relations between associated words (e.g. couch -"
W19-2908,J15-4004,0,0.0425412,"8; Mikolov et al., 2013). Even if the performance of these systems is impressive for some specific tasks (analogy resolution, lexical substitution, etc.), they usually fail to provide a fine grained characterisation of the relation between two words. Current distributional semantic models tend to aggregate all the classical lexical relations (e.g. synonymy, hypo/hypernymy, meronymy) and to confuse relations between similar words (e.g. couch - sofa) and relations between associated words (e.g. couch - nap). There is also a need for evaluation data when comparing and assessing these techniques (Hill et al., 2015; Baroni and Lenci, 2010). This paper proposes a step toward the satisfaction of both needs. We use data gathered in psycholinguistics experiments to compare different similarity measures and at the same time investigate how using complementary computational semantic techniques can help characterising lexical relations between stimuli and responses provided by subjects in a word association task. Section 2 describes the Evolex protocol from which data was collected as well as the manual annotation of the lexical relations in the collected dataset. We present the computational measures of seman"
W19-8502,J01-2001,0,0.248512,"gular processes or presenting discrepancies between form and meaning. The article focuses on the principles of morphological, structural and semantic encoding that reflect the methodological choices that have been made in Démonettev2 . Our proposal will be illustrated with various examples of non-canonical word formations. 1 Introduction Morphological analysis is one of the initial steps in many NLP systems. Analyzers, most often based on machine learning and statistical methods, decompose words into morphemes in order to compensate for the limitations of lexicons. Let us mention Linguistica (Goldsmith 2001), Morfessor (Creutz and Lagus 2005), or, more recently, Cotterell and Schütze (2017)’s models. These systems are applicable to any language, however they are more effective for languages with concatenative morphology such as English, German and French. Morphological analysis can also be carried out by symbolic parsers, most of them developed by linguists; for a panorama, see (Bernhard et al. 2011). Lexical resources with derivational annotations can replace or supplement morphological parsers in the NLP pipeline if their lexical coverage is large enough and if their features are sufficiently r"
W19-8502,2014.lilt-11.6,1,0.8936,"P pipeline if their lexical coverage is large enough and if their features are sufficiently rich and varied. In its meticulous and exhaustive report, Kyjánek (2018) produces a typology describing the structure and coverage of 30 recent derivational resources for Romance (including Latin), Germanic and Slavic languages. The reader should refer to this work to get a clear idea of the existing derivational databases (DDBs) and lexicons with derivational annotations. The lack of large-scale derivational resources of French motivated the development, from 2011, of a prototype database Démonettev1 (Hathout and Namer 2014a, 2016). Démonettev1 describes derivational families made up of verbs, agent and action nouns and modality adjectives. Three objectives were pursued: (1) use DériF’s analyses (Namer 2009, 2013) to produce a resource whose inputs are derivational relations between two words W1 and W2 , labelled with linguistically grounded fetures, including semantic annotations; (2) complete these W1 → W2 derivations by relations between derivational family members provided by the analogic model implemented in Morphonette (Hathout 2009); (3) define an extensible and redundant architecture, which can be fed by"
W19-8502,L16-1173,1,0.836314,"Missing"
W19-8503,P98-1013,0,0.519891,"ent in the derivational lexicon. In this paper, we address this issue in the framework of paradigmatic morphology. The objective is to describe the morphosemantic relations contained in the lexicon and design semantic representations compatible with morphological resources that could be used in NLP and experimental linguistics. Starting from what has already been done with Démonette (Hathout and Namer, 2014, 2016), we propose a representation of paradigmatic regularities in the lexicon by using structures inspired by Frame Semantics (Fillmore et al., 2006) and used in resources like FrameNet (Baker et al., 1998). Although differences exist between the objectives of FrameNet (document the range of semantic and syntactic combinatory possibilities of each word in each of its senses through objects called &quot;frames&quot;) and Démonette (representing morphological regularities in the lexicon) frame-like structures could help us achieve our objective. 2 Definitions Derivational families. A derivational family is a set of lexemes connected by morphological derivational relations (Hathout, 2009). This extensive definition includes also forms with suppletive stems (hippodrome ‘racecourse’ in the family of cheval ‘ho"
W19-8503,2014.lilt-11.6,1,0.926473,"form and meaning of words (Haspelmath and Sims, 2013), one problem that remains unsolved in the context of derivational morphology is finding an efficient way to represent morphosemantic regularities that are present in the derivational lexicon. In this paper, we address this issue in the framework of paradigmatic morphology. The objective is to describe the morphosemantic relations contained in the lexicon and design semantic representations compatible with morphological resources that could be used in NLP and experimental linguistics. Starting from what has already been done with Démonette (Hathout and Namer, 2014, 2016), we propose a representation of paradigmatic regularities in the lexicon by using structures inspired by Frame Semantics (Fillmore et al., 2006) and used in resources like FrameNet (Baker et al., 1998). Although differences exist between the objectives of FrameNet (document the range of semantic and syntactic combinatory possibilities of each word in each of its senses through objects called &quot;frames&quot;) and Démonette (representing morphological regularities in the lexicon) frame-like structures could help us achieve our objective. 2 Definitions Derivational families. A derivational famil"
W19-8503,L16-1173,1,0.820404,"nt from the others. For this reason, entries in the Démonette database do not describe the properties of the derivatives, they describe instead properties of the derivational relations connecting two lexemes. Entries are thus pairs of morphologically related words (w1 ,w2 ) belonging to the same derivational family, such as laver → laveur. Relations in Démonette are characterized by their orientation. Démonette is a directed graph where a relation (w1 ← w2 ) describes the morphological motivation of w1 with respect to w2 . Most of the lexemes are connected with each other in both directions. (Hathout and Namer, 2016). Direct relations in Démonette may be descending or ascending: the first connect a derived lexeme to its base or to a more distant ascendant (laver ← laveur ) while the latter connect a lexeme to its derivative or to a more distant descendant (laveur ← laver ). Among the existing fields used to describe derivational relations in the Démonette database, an important role is played by the four fields used for the semantic description. Currently, there are two fields expressing the semantic type of w1 and w2 , one for the concrete definition giving 16 the meaning of w1 with respect to w2 and one"
