2021.jeptalnrecital-taln.5,Open Information Extraction: Approche Supervis{\\'e}e et Syntaxique pour le Fran{\\c{c}}ais (Supervised Syntactic Approach for {F}rench Open Information Extraction),2021,-1,-1,2,0,5593,massinissa atmani,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\\'e}rence principale,0,"L{'} Open Information Extraction, est un paradigme d{'}extraction con{\c{c}}u pour g{\'e}rer l{'}adaptation de domaine, la principale difficult{\'e} des approches traditionnelles pour l{'}extraction d{'}informations. Cependant, la plupart des approches se concentrent sur l{'}anglais. Ainsi, nous proposons une approche supervis{\'e}e pour l{'}OpenIE pour le fran{\c{c}}ais, nous d{\'e}veloppons {\'e}galement un corpus d{'}entra{\^\i}nement et un r{\'e}f{\'e}rentiel d{'}{\'e}valuation. Nous proposons un nouveau mod{\`e}le bas{\'e} en deux {\'e}tapes pour l{'}{\'e}tiquetage de s{\'e}quence, qui identifie d{'}abord tous les arguments de la relation avant de les {\'e}tiqueter. Les exp{\'e}rimentations montrent non seulement que l{'}approche que nous proposons obtient les meilleurs r{\'e}sultats, mais aussi que l{'}{\'e}tat de l{'}art actuel n{'}est pas assez robuste pour s{'}adapter {\`a} un domaine diff{\'e}rent du domaine du corpus d{'}entra{\^\i}nement."
2021.jeptalnrecital-taln.15,Extraction automatique de relations s{\\'e}mantiques d{'}hyperonymie et d{'}hyponymie dans un corpus m{\\'e}tier (Automatic extraction of hypernym and hyponym relations in a professional corpus),2021,-1,-1,3,0,5619,camille gosset,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\\'e}rence principale,0,Nous nous int{\'e}ressons dans cet article {\`a} l{'}extraction automatique de relations s{\'e}mantiques d{'}hyperonymie et d{'}hyponymie {\`a} partir d{'}un corpus de sp{\'e}cialit{\'e}s m{\'e}tier. Le corpus regroupe des ouvrages et articles en fran{\c{c}}ais d{'}expertise juridique et a {\'e}t{\'e} partiellement annot{\'e} en termes-cl{\'e}s par des experts. Nous pr{\'e}traitons ces annotations afin de pouvoir les retrouver dans ce corpus et obtenir un concept g{\'e}n{\'e}ral pour extraire les relations entre ces termes. Nous d{\'e}crivons une {\'e}tude exp{\'e}rimentale qui compare plusieurs m{\'e}thodes de classification appliqu{\'e}es sur des vecteurs de relations construits {\`a} partir d{'}un mod{\`e}le Word2Vec. Nous comparons les r{\'e}sultats obtenus gr{\^a}ce {\`a} un jeu de donn{\'e}es construit {\`a} partir de relations d{'}hyperonymie tir{\'e}es d{'}un r{\'e}seau lexico-s{\'e}mantique fran{\c{c}}ais que nous inversons pour obtenir les relations d{'}hyponymie. Nos r{\'e}sultats montrent que nous obtenons une classification pouvant atteindre un taux d{'}exactitude de 92 {\%}.
2020.lrec-1.280,Inferences for Lexical Semantic Resource Building with Less Supervision,2020,-1,-1,2,0,17223,nadia bebeshina,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Lexical semantic resources may be built using various approaches such as extraction from corpora, integration of the relevant pieces of knowledge from the pre-existing knowledge resources, and endogenous inference. Each of these techniques needs human supervision in order to deal with the potential errors, mapping difficulties or inferred candidate validation. We detail how various inference processes can be employed for the less supervised lexical semantic resource building. Our experience is based on the combination of different inference techniques for multilingual resource building and evaluation."
2020.jeptalnrecital-taln.12,R{\\'e}duire l{'}effort humain d{'}am{\\'e}lioration des ressources lexicales gr{\\^a}ce aux inf{\\'e}rences (Reducing the Knowledge Resource Enhancement Human Effort through Inferences),2020,-1,-1,2,0,17223,nadia bebeshina,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Les inf{\'e}rences translingues repr{\'e}sentent une piste int{\'e}ressante pour la construction des ressources lexico-s{\'e}mantiques multilingues. Cependant, la validation des {\'e}l{\'e}ments candidats n{\'e}cessite un effort humain consid{\'e}rable. Nous d{\'e}crivons une fa{\c{c}}on de construire des ressources lexico-s{\'e}mantiques via des inf{\'e}rences monolingue et translingue. Son int{\'e}r{\^e}t principal consiste {\`a} impl{\'e}menter dans le contexte d{'}une ressource lexico-s{\'e}mantique multilingue une approche o{\`u} le processus de construction est un processus auto-apprenant car l{'}{\'e}valuation participe {\`a} la construction de celle-ci."
2020.jeptalnrecital-taln.25,Recherche de similarit{\\'e} th{\\'e}matique en temps r{\\'e}el au sein d{'}un d{\\'e}bat en ligne (Thematic similarity real-time computation during an online debate),2020,-1,-1,1,1,5594,mathieu lafourcade,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Cet article se focalise sur l{'}utilisation d{'}un large r{\'e}seau lexico-s{\'e}mantique fran{\c{c}}ais pour le calcul de similarit{\'e} th{\'e}matique d{'}interventions au cours d{'}un d{\'e}bat en ligne dans les lyc{\'e}es, proche du temps r{\'e}el. Pour cela, notre syst{\`e}me extrait des informations s{\'e}mantiques du r{\'e}seau et cr{\'e}e {\`a} la vol{\'e}e des vecteurs enrichis pour chaque fragment de texte. Les donn{\'e}es r{\'e}cup{\'e}r{\'e}es sont contextualis{\'e}es via un algorithme de propagation. Les vecteurs r{\'e}sultat permettent aux fragments de texte d{'}{\^e}tre compar{\'e}s. Notre m{\'e}thode aide {\`a} trouver les th{\'e}matiques {\'e}mergentes des d{\'e}bats et {\`a} identifier des clusters d{'}opinion. La contrainte temps r{\'e}el nous force {\`a} s{\'e}lectionner pr{\'e}cis{\'e}ment les informations que nous incluons, aussi bien pour les temps de calcul des vecteurs cr{\'e}{\'e}s que la qualit{\'e} de ceux-ci."
2020.jeptalnrecital-deft.6,{DEFT} 2020 - Extraction d{'}information fine dans les donn{\\'e}es cliniques : terminologies sp{\\'e}cialis{\\'e}es et graphes de connaissance (Fine-grained Information Extraction in Clinical Data : Dedicated Terminologies and Knowledge Graphs ),2020,-1,-1,3,0,18801,thomas lemaitre,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Atelier D{\\'E}fi Fouille de Textes",0,"Nous pr{\'e}sentons dans cet article notre approche {\`a} base de r{\`e}gles con{\c{c}}ue pour r{\'e}pondre {\`a} la t{\^a}che 3 de la campagne d{'}{\'e}valuation DEFT 2020. Selon le type d{'}information {\`a} extraire, nous construisons (1) une terminologie sp{\'e}cialis{\'e}e {\`a} partir de ressources m{\'e}dicales et (2) un graphe orient{\'e} bas{\'e} sur les informations extraites de la base de connaissances g{\'e}n{\'e}raliste et de grande taille - JeuxDeMots."
2020.gamnlp-1.4,Game Design Evaluation of {GWAP}s for Collecting Word Associations,2020,-1,-1,1,1,5594,mathieu lafourcade,Workshop on Games and Natural Language Processing,0,"GWAP design might have a tremendous effect on its popularity of course but also on the quality of the data collected. In this paper, a comparison is undertaken between two GWAPs for building term association lists, namely JeuxDeMots and Quicky Goose. After comparing both game designs, the Cohen kappa of associative lists in various configurations is computed in order to assess likeness and differences of the data they provide."
2020.crac-1.17,A Dataset for Anaphora Analysis in {F}rench Emails,2020,-1,-1,3,0,20943,hani guenoune,"Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference",0,"In 2019, about 293 billion emails were sent worldwide every day. They are a valuable source of information and knowledge for professionals. Since the 90{'}s, many studies have been done on emails and have highlighted the need for resources regarding numerous NLP tasks. Due to the lack of available resources for French, very few studies on emails have been conducted. Anaphora resolution in emails is an unexplored area, annotated resources are needed, at least to answer a first question: Does email communication have specifics that must be addressed to tackle the anaphora resolution task? In order to answer this question 1) we build a French emails corpus composed of 100 anonymized professional threads and make it available freely for scientific exploitation. 2) we provide annotations of anaphoric links in the email collection."
R19-1012,Using a Lexical Semantic Network for the Ontology Building,2019,0,0,3,0,25270,nadia bebeshinaclairet,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Building multilingual ontologies is a hard task as ontologies are often data-rich resources. We introduce an approach which allows exploiting structured lexical semantic knowledge for the ontology building. Given a multilingual lexical semantic (non ontological) resource and an ontology model, it allows mining relevant semantic knowledge and make the ontology building and enhancement process faster."
2019.jeptalnrecital-court.18,Inf{\\'e}rence des relations s{\\'e}mantiques dans un r{\\'e}seau lexico-s{\\'e}mantique multilingue (Inferring semantic relations in a multilingual lexical semantic network),2019,-1,-1,2,0,25270,nadia bebeshinaclairet,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"Les m{\'e}thodes endog{\`e}nes se trouvent au coeur de la construction des ressources de connaissance telles que les r{\'e}seaux lexico-s{\'e}mantiques. Dans le cadre de l{'}exp{\'e}rience d{\'e}crite dans le pr{\'e}sent article, nous nous focalisons sur les m{\'e}thodes d{'}inf{\'e}rence des relations. Nous consid{\'e}rons, en particulier, les cas d{'}inf{\'e}rence des relations s{\'e}mantiques et des raffinements de sens. Les diff{\'e}rents m{\'e}canismes d{'}inf{\'e}rence des relations s{\'e}mantiques y compris dans le contexte de polys{\'e}mie de termes ont {\'e}t{\'e} d{\'e}crits par Zarrouk (2015) pour le contexte monolingue. {\`A} notre connaissance, il n{'}existe pas de travaux concernant l{'}inf{\'e}rence des relations s{\'e}mantiques et des raffinements dans le contexte d{'}am{\'e}lioration d{'}une ressource multilingue."
2018.jeptalnrecital-court.28,Utilisation d{'}une base de connaissances de sp{\\'e}cialit{\\'e} et de sens commun pour la simplification de comptes-rendus radiologiques (Radiological text simplification using a general knowledge base),2018,-1,-1,2,1,30999,lionel ramadier,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Dans le domaine m{\'e}dical, la simplification des textes est {\`a} la fois une t{\^a}che souhaitable pour les patients et scientifiquement stimulante pour le domaine du traitement automatique du langage naturel. En effet, les comptes rendus m{\'e}dicaux peuvent {\^e}tre difficile {\`a} comprendre pour les non sp{\'e}cialistes, essentiellement {\`a} cause de termes m{\'e}dicaux sp{\'e}cifiques (prurit, par exemple). La substitution de ces termes par des mots du langage courant peut aider le patient {\`a} une meilleure compr{\'e}hension. Dans cet article, nous pr{\'e}sentons une m{\'e}thode de simplification dans le domaine m{\'e}dical (en fran{\c{c}}ais) bas{\'e}e sur un r{\'e}seau lexico-s{\'e}mantique. Nous traitons cette difficult{\'e} s{\'e}mantique par le remplacement du terme m{\'e}dical difficile par un synonyme ou terme qui lui est li{\'e} s{\'e}mantiquement {\`a} l{'}aide d{'}un r{\'e}seau lexico-s{\'e}mantique fran{\c{c}}ais. Nous pr{\'e}sentons dans ce papier, une telle m{\'e}thode ainsi que son {\'e}valuation."
2018.jeptalnrecital-court.37,{J}eux{D}e{L}iens: Word Embeddings and Path-Based Similarity for Entity Linking using the {F}rench {J}eux{D}e{M}ots Lexical Semantic Network,2018,0,0,3,0,10343,julien plu,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Entity linking systems typically rely on encyclopedic knowledge bases such as DBpedia or Freebase. In this paper, we use, instead, a French lexical-semantic network named JeuxDeMots to jointly type and link entities. Our approach combines word embeddings and a path-based similarity resulting in encouraging results over a set of documents from the French Le Monde newspaper."
W17-7204,Explicative Path Finding in a Semantic Network,2017,0,0,2,0,20944,kevin cousot,Proceedings of the Computing Natural Language Inference Workshop,0,None
W17-7206,Identifying Polysemous Words and Inferring Sense Glosses in a Semantic Network,2017,0,0,2,0,31283,maxime chapuis,Proceedings of the Computing Natural Language Inference Workshop,0,None
W17-6920,"Ambiguss, a game for building a Sense Annotated Corpus for {F}rench",2017,16,1,1,1,5594,mathieu lafourcade,{IWCS} 2017 {---} 12th International Conference on Computational Semantics {---} Short papers,0,"This paper presents Ambiguss, a Game With A Purpose designed both to collect ambiguous sentences and build a Sense Annotated Corpus. It also generates a lexicon of polysemous words associated with the glosses that illustrate the different meanings. Early evaluations indicate that the approach is relevant and efficient."
lafourcade-le-brun-2017-extracting,"Extracting semantic relations via the combination of inferences, schemas and cooccurrences",2017,0,0,1,1,5594,mathieu lafourcade,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Extracting semantic relations from texts is a good way to build and supply a knowledge base, an indispensable resource for text analysis. We propose and evaluate the combination of three ways of producing lexical-semantic relations."
lafourcade-etal-2017-mice,"If mice were reptiles, then reptiles could be mammals or How to detect errors in the {J}eux{D}e{M}ots lexical network?",2017,0,0,1,1,5594,mathieu lafourcade,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Correcting errors in a data set is a critical issue. This task can be either hand-made by experts, or by crowdsourcing methods, or automatically done using algorithms. Although the rate of errors present in the JeuxDeMots network is rather low, it is important to reduce it. We present here automatic methods for detecting potential secondary errors that would result from automatic inference mechanisms when they rely on an initial error manually detected. Encouraging results also invite us to consider strategies that would automatically detect {``}erroneous{''} initial relations, which could lead to the automatic detection of the majority of errors in the network."
2017.jeptalnrecital-court.19,"Parcourir, reconna{\\^\\i}tre et r{\\'e}fl{\\'e}chir. Combinaison de m{\\'e}thodes l{\\'e}g{\\`e}res pour l{'}extraction de relations s{\\'e}mantiques (Browse, recognize and think)",2017,-1,-1,1,1,5594,mathieu lafourcade,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"La capture de relations s{\'e}mantiques entre termes {\`a} partir de textes est un moyen privil{\'e}gi{\'e} de constituer/alimenter une base de connaissances, ressource indispensable pour l{'}analyse de textes. Nous proposons et {\'e}valuons la combinaison de trois m{\'e}thodes de production de relations lexicos{\'e}mantiques."
2017.jeptalnrecital-court.20,"Si les souris {\\'e}taient des reptiles, alors les reptiles pourraient {\\^e}tre des mammif{\\`e}res ou Comment d{\\'e}tecter les anomalies dans le r{\\'e}seau {JDM} ? (If mice were reptiles, then the reptiles could be mammals, or How to detect errors in a lexical network?)",2017,-1,-1,2,0.743962,32452,alain joubert,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"La correction des erreurs dans une collection de donn{\'e}es est un probl{\`e}me d{\'e}licat. Elle peut {\^e}tre r{\'e}alis{\'e}e manuellement par un expert, ou en utilisant des m{\'e}thodes de crowdsourcing, ou encore automatiquement au moyen d{'}algorithmes. Nous pr{\'e}sentons ici des m{\'e}thodes automatiques permettant de d{\'e}tecter les erreurs potentielles Â« secondaires Â» induites par les m{\'e}canismes automatiques d{'}inf{\'e}rences de relations, lorsqu{'}ils s{'}appuient sur des relations erron{\'e}es Â« initiales Â» d{\'e}tect{\'e}es manuellement. Des r{\'e}sultats encourageants, mesur{\'e}s sur le r{\'e}seau JeuxDeMots, nous invitent {\`a} envisager {\'e}galement des strat{\'e}gies qui permettraient de d{\'e}tecter automatiquement les relations erron{\'e}es Â« initiales Â», ce qui pourrait conduire {\`a} une d{\'e}tection automatique de la majorit{\'e} des erreurs pr{\'e}sentes dans le r{\'e}seau."
L16-1725,Semantic Relation Extraction with Semantic Patterns Experiment on Radiology Reports,2016,19,2,1,1,5594,mathieu lafourcade,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This work presents a practical system for indexing terms and relations from French radiology reports, called IMAIOS. In this paper, we present how semantic relations (causes, consequences, symptoms, locations, parts...) between medical terms can be extracted. For this purpose, we handcrafted some linguistic patterns from on a subset of our radiology report corpora. As semantic patterns (de (of)) may be too general or ambiguous, semantic constraints have been added. For instance, in the sentence n{\'e}oplasie du sein (neoplasm of breast) the system knowing neoplasm as a disease and breast as an anatomical location, identify the relation as being a location: neoplasm r-lieu breast. An evaluation of the effect of semantic constraints is proposed."
2016.jeptalnrecital-poster.26,Patrons s{\\'e}mantiques pour l{'}extraction de relations entre termes - Application aux comptes rendus radiologiques (Here the title in {E}nglish),2016,-1,-1,2,1,30999,lionel ramadier,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,"Dans cet article nous nous int{\'e}ressons {\`a} la t{\^a}che d{'}extraction de relations s{\'e}mantiques dans les textes m{\'e}dicaux et plus particuli{\`e}rement dans les comptes rendus radiologiques. L{'}identification de relations s{\'e}mantiques est une t{\^a}che importante pour plusieurs applications (recherche d{'}information, g{\'e}n{\'e}ration de r{\'e}sum{\'e}, etc). Nous proposons une approche fond{\'e}e sur l{'}utilisation de patrons s{\'e}mantiques v{\'e}rifiant des contraintes dans une base de connaissances."
2016.jeptalnrecital-long.4,Construire un lexique de sentiments par crowdsourcing et propagation (Building a sentiment lexicon through crowdsourcing and spreading),2016,-1,-1,1,1,5594,mathieu lafourcade,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"Cet article pr{\'e}sente une m{\'e}thode de construction d{'}une ressource lexicale de sentiments/{\'e}motions. Son originalit{\'e} est d{'}associer le crowdsourcing via un GWAP (Game With A Purpose) {\`a} un algorithme de propagation, les deux ayant pour support et source de donn{\'e}es le r{\'e}seau lexical JeuxDeMots. Nous d{\'e}crivons le jeu permettant de collecter des informations de sentiments, ainsi que les principes et hypoth{\`e}ses qui sous-tendent le fonctionnement de l{'}algorithme qui les propage au sein du r{\'e}seau. Enfin, nous donnons les r{\'e}sultats quantitatifs et expliquons les m{\'e}thodes d{'}{\'e}valuation qualitative des donn{\'e}es obtenues, {\`a} la fois par le jeu et par la propagation par l{'}algorithme. Ces m{\'e}thodes incluent une comparaison avec Emolex, une autre ressource de sentiments/{\'e}motions."
R15-1044,Collecting and Evaluating Lexical Polarity with A Game With a Purpose,2015,15,5,1,1,5594,mathieu lafourcade,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"Sentiment analysis from a text requires amongst others having a polarity lexical resource. We designed LikeIt, a GWAP (Game With A Purpose) that allows to attribute a positive, negative or neutral value to a term, and thus obtain a resulting polarity for most of the terms of the freely available lexical network of the JeuxDeMots project. We present a quantitative analysis of data obtained through our approach, together with the comparison method we developed to validate them qualitatively."
R15-1045,Medical imaging report indexing: enrichment of index through an algorithm of spreading over a lexico-semantic network,2015,19,0,1,1,5594,mathieu lafourcade,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"In medical imaging domain, digitized data is rapidly expanding Therefore it is of major interest for radiologists to be able to do an efficient and accurate extraction of imaging and clinical data (radiology reports) which are essential for a rigorous diagnosis and for a better management of patients. In daily practice, radiology reports are written using a non-standardized language which is often ambiguous and noisy. The queries of radiological images can be greatly facilitated through textual indexing of associated reports. In order to improve the quality of the analysis of such reports, it is desirable to specify an index enlargement algorithm based on spreading activations over a general lexical-semantic network. In this paper, we present such an algorithm along with its qualitative evaluation."
2015.jeptalnrecital-court.3,"Vous aimez ?...ou pas ? {L}ike{I}t, un jeu pour construire une ressource lexicale de polarit{\\'e}",2015,0,1,1,1,5594,mathieu lafourcade,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"En analyse de discours ou d{'}opinion, savoir caract{\'e}riser la connotation g{\'e}n{\'e}rale d{'}un texte, les sentiments qu{'}il v{\'e}hicule, est une aptitude recherch{\'e}e, qui suppose la constitution pr{\'e}alable d{'}une ressource lexicale de polarit{\'e}. Au sein du r{\'e}seau lexical JeuxDeMots, nous avons mis au point LikeIt, un jeu qui permet d{'}affecter une valeur positive, n{\'e}gative, ou neutre {\`a} un terme, et de constituer ainsi pour chaque terme, {\`a} partir des votes, une polarit{\'e} r{\'e}sultante. Nous pr{\'e}sentons ici l{'}analyse quantitative des donn{\'e}es de polarit{\'e} obtenues, ainsi que la m{\'e}thode pour les valider qualitativement."
2015.jeptalnrecital-court.21,Augmentation d{'}index par propagation sur un r{\\'e}seau lexical Application aux comptes rendus de radiologie,2015,-1,-1,1,1,5594,mathieu lafourcade,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Les donn{\'e}es m{\'e}dicales {\'e}tant de plus en plus informatis{\'e}es, le traitement s{\'e}mantiquement efficace des rapports m{\'e}dicaux est devenu une n{\'e}cessit{\'e}. La recherche d{'}images radiologiques peut {\^e}tre grandement facilit{\'e}e gr{\^a}ce {\`a} l{'}indexation textuelle des comptes rendus associ{\'e}s. Nous pr{\'e}sentons un algorithme d{'}augmentation d{'}index de comptes rendus fond{\'e} sur la propagation d{'}activation sur un r{\'e}seau lexico-s{\'e}mantique g{\'e}n{\'e}raliste."
lafourcade-fort-2014-propa,Propa-{L}: a semantic filtering service from a lexical network created using Games With A Purpose,2014,14,2,1,1,5594,mathieu lafourcade,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This article presents Propa-L, a freely accessible Web service that allows to semantically filter a lexical network. The language resources behind the service are dynamic and created through Games With A Purpose. We show an example of application of this service: the generation of a list of keywords for parental filtering on the Web, but many others can be envisaged. Moreover, the propagation algorithm we present here can be applied to any lexical network, in any language."
zarrouk-lafourcade-2014-relation,Relation Inference in Lexical Networks ... with Refinements,2014,20,1,2,1,7492,manel zarrouk,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Improving lexical networkÂs quality is an important issue in the creation process of these language resources. This can be done by automatically inferring new relations from already existing ones with the purpose of (1) densifying the relations to cover the eventual lack of information and (2) detecting errors. In this paper, we devise such an approach applied to the JeuxDeMots lexical network, which is a freely available lexical and semantic resource for French. We first present the principles behind the lexical network construction with crowdsourcing and games with a purpose and illustrated them with JeuxDeMots (JDM). Then, we present the outline of an elicitation engine based on an inference engine using schemes like deduction, induction and abduction which will be referenced and briefly presented and we will especially highlight the new scheme (Relation Inference Scheme with Refinements) added to our system. An experiment showing the relevance of this scheme is then presented."
F14-2034,Colors of People (Les couleurs des gens) [in {F}rench],2014,-1,-1,1,1,5594,mathieu lafourcade,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
F14-1010,Annotations and inference of relations in a lexical semantic network : Applied to radiology (Annotations et inf{\\'e}rences de relations dans un r{\\'e}seau lexico-s{\\'e}mantique: application {\\`a} la radiologie) [in {F}rench],2014,0,0,3,1,30999,lionel ramadier,Proceedings of TALN 2014 (Volume 1: Long Papers),0,None
E14-1019,About Inferences in a Crowdsourced Lexical-Semantic Network,2014,13,4,1,1,5594,mathieu lafourcade,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Automatically inferring new relations from already existing ones is a way to improve the quality of a lexical network by relation densification and error detection. In this paper, we devise such an approach for the JeuxDeMots lexical network, which is a freely avalaible lexical network for French. We first present deduction (generic to specific) and induction (specific to generic) which are two inference schemes ontologically founded. We then propose abduction as a third form of inference scheme, which exploits examples similar to a target term."
C14-1036,Inferring Knowledge with Word Refinements in a Crowdsourced Lexical-Semantic Network,2014,14,0,2,1,7492,manel zarrouk,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Automatically inferring new relations from already existing ones is a way to improve the quality and coverage of a lexical network and to perform error detection. In this paper, we devise such an approach for the crowdsourced JeuxDeMots lexical network and we focus especially on word refinements. We first present deduction (generic to specific) and induction (specific to generic) which are two inference schemes ontologically founded and then propose a transfer schema devoted to infer relations with and for word refinements."
R13-1096,Inductive and deductive inferences in a Crowdsourced Lexical-Semantic Network,2013,14,4,2,1,7492,manel zarrouk,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"In Computational Linguistics, building lexical-semantic networks and validating contained relations are paramount issues as well as adding some reasoning skills in order to enrich these knowledge bases. In this paper we devise an inference engine which aims at producing new potential relations from already existing ones in the JeuxDeMots network. This network is constructed with the help of a GWAP (game with a purpose) thanks to thousands of players. It handles terms and weighted relations between these terms, and currently contains over 2 million relation occurences. Polysemous terms may be refined in several senses (bank may be a bank>financial institution or a bank>river) but as the network is indefinitely under construction (in the context of a Never Ending Learning approach) some senses may be missing at a given time. The approach we proposed here is founded on the triangulation method through two kinds of inference schemes: deduction (topdown from generic to specific terms) and induction (bottom-up from specific to generic terms). A blocking mechanism, whose purpose is to avoid proposing highly dubious new relations, is based on logical and statistical constraints. Automatically inferred relations are then proposed to human contributors to be validated. In case of invalidation, a reconciliation dialog is undertaken to identify the cause of the wrong inference: an exception, an error in the premises or a previously undetected confusion due to polysemy on the central term common to both premises."
F13-1025,Inductive and deductive inferences in a Crowdsourced Lexical-Semantic Network (Inf{\\'e}rences d{\\'e}ductives et r{\\'e}conciliation dans un r{\\'e}seau lexico-s{\\'e}mantique) [in {F}rench],2013,0,0,2,1,7492,manel zarrouk,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
W12-5102,Long Tail in Weighted Lexical Networks,2012,25,4,1,1,5594,mathieu lafourcade,Proceedings of the 3rd Workshop on Cognitive Aspects of the Lexicon,0,"Lexical networks can be used with benefit for semantic analysis of texts, word sense disambiguation (WSD) and in general for graph-based Natural Language Processing. Usually strong relations between terms (e.g.: cat --> animal) are sufficient to help for the task, but quite often, weak relations (e.g.: cat --> ball of wool) are necessary. Our purpose here is to acquire such relations by means of online serious games as other classical approaches seems impractical. Indeed, it is difficult to ask the users (non experts) to define a proper weighting for the relations they propose, and then we decided to relate weights with the frequency of their propositions. It allows us to acquire first the strongest relations, but also to populate the long tail of an already existing network. Furthermore, trying to get an estimation of our network by the very users thanks to a tip of the tongue (TOT) software, we realized that they rather tend to favor the relations of the long tail and thus promote their emergence. Developing the long tail of a lexical network with standard and non-standard relations of low weight can be of advantage for tasks such that words retrieval from clues or WSD in texts."
joubert-lafourcade-2012-new,A new dynamic approach for lexical networks evaluation,2012,15,5,2,1,32452,alain joubert,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Since September 2007, a large scale lexical network for French is under construction with methods based on popular consensus by means of games (under the JeuxDeMots project). To assess the resource quality, we decided to adopt an approach similar to its construction, that is to say an evaluation by laymen on open class vocabulary with a Tip of the Tongue tool."
2011.jeptalnrecital-long.20,{\\'E}valuation et consolidation d{'}un r{\\'e}seau lexical via un outil pour retrouver le mot sur le bout de la langue (Evaluation and consolidation of a lexical network via a tool to find the word on the tip of the tongue),2011,-1,-1,2,1,32452,alain joubert,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Depuis septembre 2007, un r{\'e}seau lexical de grande taille pour le Fran{\c{c}}ais est en cours de construction {\`a} l{'}aide de m{\'e}thodes fond{\'e}es sur des formes de consensus populaire obtenu via des jeux (projet JeuxDeMots). L{'}intervention d{'}experts humains est marginale en ce qu{'}elle repr{\'e}sente moins de 0,5{\%} des relations du r{\'e}seau et se limite {\`a} des corrections, {\`a} des ajustements ainsi qu{'}{\`a} la validation des sens de termes. Pour {\'e}valuer la qualit{\'e} de cette ressource construite par des participants de jeu (utilisateurs non experts) nous adoptons une d{\'e}marche similaire {\`a} celle de sa construction, {\`a} savoir, la ressource doit {\^e}tre valid{\'e}e sur un vocabulaire de classe ouverte, par des non-experts, de fa{\c{c}}on stable (persistante dans le temps). Pour ce faire, nous proposons de v{\'e}rifier si notre ressource est capable de servir de support {\`a} la r{\'e}solution du probl{\`e}me nomm{\'e} {`}Mot sur le Bout de la Langue{'} (MBL). A l{'}instar de JeuxdeMots, l{'}outil d{\'e}velopp{\'e} peut {\^e}tre vu comme un jeu en ligne. Tout comme ce dernier, il permet d{'}acqu{\'e}rir de nouvelles relations, constituant ainsi un enrichissement de notre r{\'e}seau lexical."
2010.jeptalnrecital-court.2,D{\\'e}termination et pond{\\'e}ration des raffinements d{'}un terme {\\`a} partir de son arbre des usages nomm{\\'e}s,2010,-1,-1,1,1,5594,mathieu lafourcade,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Gr{\^a}ce {\`a} la participation d{'}un grand nombre de personnes via des jeux accessibles sur le web, nous avons construit un r{\'e}seau lexical {\'e}volutif de grande taille pour le Fran{\c{c}}ais. A partir de cette ressource, nous avons abord{\'e} la question de la d{\'e}termination des sens d{'}usage d{'}un terme, puis apr{\`e}s avoir introduit la notion de similarit{\'e} entre ces diff{\'e}rents usages, nous avons pu obtenir pour un terme son arbre des usages : la racine regroupe tous les usages du terme et une descente dans l{'}arbre correspond {\`a} un raffinement de ces usages. Le nommage des diff{\'e}rents noeuds est effectu{\'e} lors d{'}une descente en largeur. En simplifiant l{'}arbre des usages nomm{\'e}s, nous d{\'e}terminons les diff{\'e}rents sens d{'}un terme, sens que nous introduisons dans le r{\'e}seau lexical en tant que noeuds de raffinement du terme consid{\'e}r{\'e}. Nous terminons par une {\'e}valuation empirique des r{\'e}sultats obtenus."
2009.jeptalnrecital-court.38,Sens et usages d{'}un terme dans un r{\\'e}seau lexical {\\'e}volutif,2009,-1,-1,1,1,5594,mathieu lafourcade,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"L{'}obtention d{'}informations lexicales fiables est un enjeu primordial en TALN, mais cette collecte peut s{'}av{\'e}rer difficile. L{'}approche pr{\'e}sent{\'e}e ici vise {\`a} pallier les {\'e}cueils de cette difficult{\'e} en faisant participer un grand nombre de personnes {\`a} un projet contributif via des jeux accessibles sur le web. Ainsi, les joueurs vont construire le r{\'e}seau lexical, en fournissant de plusieurs mani{\`e}res possibles des associations de termes {\`a} partir d{'}un terme cible et d{'}une consigne correspondant {\`a} une relation typ{\'e}e. Le r{\'e}seau lexical ainsi produit est de grande taille et comporte une trentaine de types de relations. A partir de cette ressource, nous abordons la question de la d{\'e}termination des diff{\'e}rents sens et usages d{'}un terme. Ceci est r{\'e}alis{\'e} en analysant les relations entre ce terme et ses voisins imm{\'e}diats dans le r{\'e}seau et en calculant des cliques ou des quasi-cliques. Ceci nous am{\`e}ne naturellement {\`a} introduire la notion de similarit{\'e} entre cliques, que nous interpr{\'e}tons comme une mesure de similarit{\'e} entre ces diff{\'e}rents sens et usages. Nous pouvons ainsi construire pour un terme son arbre des usages, qui est une structure de donn{\'e}es exploitable en d{\'e}sambigu{\""\i}sation de sens. Nous pr{\'e}sentons quelques r{\'e}sultats obtenus en soulignant leur caract{\`e}re {\'e}volutif."
joubert-lafourcade-2008-evolutionary,Evolutionary Basic Notions for a Thematic Representation of General Knowledge,2008,9,0,2,1,32452,alain joubert,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In the field of Natural Language Processing, in order to work out a thematic representation system of general knowledge, methods relying on thesaurus have been used for about twenty years. A thesaurus consists of a set of concepts which define a generating system of a vector space modelling general knowledge. These concepts, often organized in a treelike structure, constitute a fundamental, but completely fixed tool. Even if the concepts evolve (we think for example of the technical fields), a thesaurus as for it can evolve only at the time of a particularly heavy process, because it requires the collaboration of human experts. After detailing the characteristics which a generating system of the vector space of knowledge modelling must have, we define the Âbasic notionsÂ. Basic notions, whose construction is initially based on the concepts of a thesaurus, constitute another generating system of this vector space. We then approach the determination of the acceptions expressing the basic notions. Lastly, we clarify how, being freed from the concepts of the thesaurus, the basic notions evolve progressively with the analysis of new texts by an iterative process."
2008.jeptalnrecital-long.19,D{\\'e}termination des sens d{'}usage dans un r{\\'e}seau lexical construit {\\`a} l{'}aide d{'}un jeu en ligne,2008,-1,-1,1,1,5594,mathieu lafourcade,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les informations lexicales, indispensables pour les t{\^a}ches r{\'e}alis{\'e}es en TALN, sont difficiles {\`a} collecter. En effet, effectu{\'e}e manuellement, cette t{\^a}che n{\'e}cessite la comp{\'e}tence d{'}experts et la dur{\'e}e n{\'e}cessaire peut {\^e}tre prohibitive, alors que r{\'e}alis{\'e}e automatiquement, les r{\'e}sultats peuvent {\^e}tre biais{\'e}s par les corpus de textes retenus. L{'}approche pr{\'e}sent{\'e}e ici consiste {\`a} faire participer un grand nombre de personnes {\`a} un projet contributif en leur proposant une application ludique accessible sur le web. A partir d{'}une base de termes pr{\'e}existante, ce sont ainsi les joueurs qui vont construire le r{\'e}seau lexical, en fournissant des associations qui ne sont valid{\'e}es que si elles sont propos{\'e}es par au moins une paire d{'}utilisateurs. De plus, ces relations typ{\'e}es sont pond{\'e}r{\'e}es en fonction du nombre de paires d{'}utilisateurs qui les ont propos{\'e}es. Enfin, nous abordons la question de la d{\'e}termination des diff{\'e}rents sens d{'}usage d{'}un terme, en analysant les relations entre ce terme et ses voisins imm{\'e}diats dans le r{\'e}seau lexical, avant de pr{\'e}senter bri{\`e}vement la r{\'e}alisation et les premiers r{\'e}sultats obtenus."
2007.jeptalnrecital-long.27,"Les vecteurs conceptuels, un outil compl{\\'e}mentaire aux r{\\'e}seaux lexicaux",2007,6,2,3,1,5694,didier schwab,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Fr{\'e}quemment utilis{\'e}s dans le Traitement Automatique des Langues Naturelles, les r{\'e}seaux lexicaux font aujourd{'}hui l{'}objet de nombreuses recherches. La plupart d{'}entre eux, et en particulier le plus c{\'e}l{\`e}bre WordNet, souffrent du manque d{'}informations syntagmatiques mais aussi d{'}informations th{\'e}matiques (Â« probl{\`e}me du tennis Â»). Cet article pr{\'e}sente les vecteurs conceptuels qui permettent de repr{\'e}senter les id{\'e}es contenues dans un segment textuel quelconque et permettent d{'}obtenir une vision continue des th{\'e}matiques utilis{\'e}es gr{\^a}ce aux distances calculables entre eux. Nous montrons leurs caract{\'e}ristiques et en quoi ils sont compl{\'e}mentaires des r{\'e}seaux lexico-s{\'e}mantiques. Nous illustrons ce propos par l{'}enrichissement des donn{\'e}es de WordNet par des vecteurs conceptuels construits par {\'e}mergence."
lafourcade-2006-conceptual,Conceptual Vector Learning - Comparing Bootstrapping from a Thesaurus or Induction by Emergence,2006,15,3,1,1,5594,mathieu lafourcade,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In the framework of the Word Sense Disambiguation (WSD) and lexical transfer in Machine Translation (MT), the representation of word meanings is one critical issue. The conceptual vector model aims at representing thematic activations for chunks of text, lexical entries, up to whole documents. Roughly speaking, vectors are supposed to encode ideas associated to words or expressions. In this paper, we first expose the conceptual vectors model and the notions of semantic distance and contextualization between terms. Then, we present in details the text analysis process coupled with conceptual vectors, which is used in text classification, thematic analysis and vector learning. The question we focus on is whether a thesaurus is really needed and desirable for bootstrapping the learning. We conducted two experiments with and without a thesaurus and are exposing here some comparative results. Our contribution is that dimension distribution is done more regularly by an emergent procedure. In other words, the resources are more efficiently exploited with an emergent procedure than with a thesaurus terms (concepts) as listed in a thesaurus somehow relate to their importance in the language but nor to their frequency in usage neither to their power of discrimination or representativeness."
2006.jeptalnrecital-poster.15,Approche {\\'e}volutive des notions de base pour une repr{\\'e}sentation th{\\'e}matique des connaissances g{\\'e}n{\\'e}rales,2006,-1,-1,2,1,32452,alain joubert,Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans le domaine du Traitement Automatique du Langage Naturel, pour {\'e}laborer un syst{\`e}me de repr{\'e}sentation th{\'e}matique des connaissances g{\'e}n{\'e}rales, des m{\'e}thodes s{'}appuyant sur des th{\'e}saurus sont utilis{\'e}es depuis une quinzaine d{'}ann{\'e}es. Un th{\'e}saurus est constitu{\'e} d{'}un ensemble de concepts qui d{\'e}finissent un syst{\`e}me g{\'e}n{\'e}rateur d{'}un espace vectoriel mod{\'e}lisant les connaissances g{\'e}n{\'e}rales. Ces concepts, souvent organis{\'e}s en une hi{\'e}rarchie arborescente, constituent un instrument fondamental, mais totalement fig{\'e}. M{\^e}me si les notions {\'e}voluent (nous pensons par exemple aux domaines techniques), un th{\'e}saurus ne peut quant {\`a} lui {\^e}tre modifi{\'e} que lors d{'}un processus particuli{\`e}rement lourd, car n{\'e}cessitant la collaboration d{'}experts humains. C{'}est {\`a} ce probl{\`e}me que nous nous attaquons ici. Apr{\`e}s avoir d{\'e}taill{\'e} les caract{\'e}ristiques que doit poss{\'e}der un syst{\`e}me g{\'e}n{\'e}rateur de l{'}espace vectoriel de mod{\'e}lisation des connaissances, nous d{\'e}finissons les Â« notions de base Â». Celles-ci, dont la construction s{'}appuie initialement sur les concepts d{'}un th{\'e}saurus, constituent un autre syst{\`e}me g{\'e}n{\'e}rateur de cet espace vectoriel. Nous abordons la d{\'e}termination des acceptions exprimant les notions de base, ce qui nous am{\`e}ne naturellement {\`a} nous poser la question de leur nombre. Enfin, nous explicitons comment, s{'}affranchissant des concepts du th{\'e}saurus, ces notions de base {\'e}voluent par un processus it{\'e}ratif au fur et {\`a} mesure de l{'}analyse de nouveaux textes."
2005.jeptalnrecital-long.8,Extraction semi-supervis{\\'e}e de couples d{'}antonymes gr{\\^a}ce {\\`a} leur morphologie,2005,-1,-1,2,1,5694,didier schwab,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le cadre de la recherche sur la repr{\'e}sentation du sens en Traitement Automatique des Langues Naturelles, nous nous concentrons sur la construction d{'}un syst{\`e}me capable d{'}acqu{\'e}rir le sens des mots, et les relations entre ces sens, {\`a} partir de dictionnaires {\`a} usage humain, du Web ou d{'}autres ressources lexicales. Pour l{'}antonymie, il n{'}existe pas de listes s{\'e}parant les antonymies compl{\'e}mentaire, scalaire et duale. Nous pr{\'e}sentons dans cet article une approche semi-supervis{\'e}e permettant de construire ces listes. Notre m{\'e}thode est bas{\'e}e sur les oppositions de nature morphologique qui peuvent exister entre les items lexicaux. {\`A} partir d{'}un premier ensemble de couples antonymes, elle permet non seulement de construire ces listes mais aussi de trouver des oppositions morphologiques. Nous {\'e}tudions les r{\'e}sultats obtenus par cette m{\'e}thode. En particulier, nous pr{\'e}sentons les oppositions de pr{\'e}fixes ainsi d{\'e}couvertes et leur validit{\'e} sur le corpus puis nous discutons de la r{\'e}partition des types d{'}antonymie en fonction des couples oppos{\'e}s de pr{\'e}fixes."
2004.jeptalnrecital-poster.12,Classification automatique de d{\\'e}finitions en sens,2004,-1,-1,2,0,52456,fabien jalabert,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans le cadre de la recherche en s{\'e}mantique lexicale, l{'}{\'e}quipe TAL du LIRMM d{\'e}veloppe actuellement un syst{\`e}me d{'}analyse des aspects th{\'e}matiques des textes et de d{\'e}sambiguisation lexicale bas{\'e} sur les vecteurs conceptuels. Pour la construction des vecteurs, les d{\'e}finitions provenant de sources lexicales diff{\'e}rentes (dictionnaires {\`a} usage humain, listes de synonymes, d{\'e}finitions de th{\'e}saurus, . . .) sont analys{\'e}es. Aucun d{\'e}coupage du sens n{'}est pr{\'e}sent dans la repr{\'e}sentation : un vecteur conceptuel est associ{\'e} {\`a} chaque d{\'e}finition et un autre pour repr{\'e}senter le sens global du mot. Nous souhaitons effectuer une cat{\'e}gorisation afin que chaque {\'e}l{\'e}ment ne soit plus une d{\'e}finition mais un sens. Cette am{\'e}lioration concerne bien sur directement les applications courantes (d{\'e}sambigu{\""\i}sation, transfert lexical, . . .) mais a aussi pour objectif majeur d{'}am{\'e}liorer l{'}apprentissage de la base."
2003.jeptalnrecital-long.22,Am{\\'e}lioration de liens entre acceptions par fonctions lexicales vectorielles sym{\\'e}triques,2003,-1,-1,2,1,5694,didier schwab,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le cadre du projet Papillon qui vise {\`a} la construction de bases lexicales multilingues par acceptions, nous avons d{\'e}fini des strat{\'e}gies pour peupler un dictionnaire pivot de liens interlingues {\`a} partir d{'}une base vectorielle monolingue. Il peut y avoir un nombre important de sens par entr{\'e}e et donc l{'}identification des acceptions correspondantes peut {\^e}tre erron{\'e}e. Nous am{\'e}liorons l{'}int{\'e}grit{\'e} de la base d{'}acception gr{\^a}ce {\`a} des agents experts dans les fonctions lexicales comme la synonymie, l{'}antonymie, l{'}hyp{\'e}ronymie ou l{'}holonymie. Ces agents sont capable de calculer la pertinence d{'}une relation s{\'e}mantique entre deux acceptions par les diverses informations lexicales r{\'e}colt{\'e}es et les vecteurs conceptuels. Si une certaine pertinence est au-dessus d{'}un seuil, ils cr{\'e}ent un lien s{\'e}mantique qui peut {\^e}tre utilis{\'e} par d{'}autres agents charg{\'e}s par exemple de la d{\'e}sambigu{\""\i}sation ou du transfert lexical. Les agents v{\'e}rifiant l{'}int{\'e}grit{\'e} de la base cherchent les incoh{\'e}rences de la base et en avertissent les lexicographes le cas {\'e}ch{\'e}ant."
lafourcade-boitet-2002-unl,{UNL} Lexical Selection with Conceptual Vectors,2002,9,9,1,1,5594,mathieu lafourcade,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"When deconverting a UNL graph into some natural language LG, we often encounter lexical items (called UWs) made of an English headword and formalized semantic restrictions, such as look for (icl>do, agt>person), which are not yet connected to lemmas, so that is it necessary to find a nearest UW in the UNL-LG dictionary, such as look for (icl>action, agt>human, obj>thing). Then, this UW may be connected to several lemmas of LG. In order to solve these problems of incompleteness and polysemy, we are applying a method based on the computation of conceptual vectors, previously used successfully in the context of thematic indexing of French and English documents."
C02-1061,Antonymy and Conceptual Vectors,2002,8,19,2,1,5694,didier schwab,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"For meaning representations in NLP, we focus our attention on thematic aspects and conceptual vectors. The learning strategy of conceptual vectors relies on a morphosyntaxic analysis of human usage dictionary definitions linked to vector propagation. This analysis currently doesn't take into account negation phenomena. This work aims at studying the antonymy aspects of negation, in the larger goal of its integration into the thematic analysis. We present a model based on the idea of symmetry compatible with conceptual vectors. Then, we define antonymy functions which allows the construction of an antonymous vector and the enumeration of its potentially antinomic lexical items. Finally, we introduce a measure which evaluates how a given word is an acceptable antonym for a term."
2002.jeptalnrecital-long.10,"Vers l{'}apprentissage automatique, pour et par les vecteurs conceptuels, de fonctions lexicales. L{'}exemple de l{'}antonymie",2002,3,4,2,1,5694,didier schwab,Actes de la 9{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le cadre de recherches sur le sens en traitement automatique du langage, nous nous concentrons sur la repr{\'e}sentation de l{'}aspect th{\'e}matique des segments textuels {\`a} l{'}aide de vecteurs conceptuels. Les vecteurs conceptuels sont automatiquement appris {\`a} partir de d{\'e}finitions issues de dictionnaires {\`a} usage humain (Schwab, 2001). Un noyau de termes manuellement index{\'e}s est n{\'e}cessaire pour l{'}amor{\c{c}}age de cette analyse. Lorsque l{'}item d{\'e}fini s{'}y pr{\^e}te, ces d{\'e}finitions sont compl{\'e}t{\'e}es par des termes en relation avec lui. Ces relations sont des fonctions lexicales (Mel{'}cuk and al, 95) comme l{'}hyponymie, l{'}hyperonymie, la synonymie ou l{'}antonymie. Cet article propose d{'}am{\'e}liorer la fonction d{'}antonymie na{\""\i}ve expos{\'e}e dans (Schwab, 2001) et (Schwab and al, 2002) gr{\^a}ce {\`a} ces informations. La fonction s{'}auto-modifie, par r{\'e}vision de listes, en fonction des relations d{'}antonymie av{\'e}r{\'e}es entre deux items. Nous exposons la m{\'e}thode utilis{\'e}e, quelques r{\'e}sultats puis nous concluons sur les perspectives ouvertes."
2001.jeptalnrecital-long.21,Synonymies et vecteurs conceptuels,2001,-1,-1,1,1,5594,mathieu lafourcade,Actes de la 8{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"La synonymie est une relation importante en TAL mais qui reste probl{\'e}matique. La distinction entre synonymie relative et synonymie subjective permet de contourner certaines difficult{\'e}s. Dans le cadre des vecteurs conceptuels, il est alors possible de d{\'e}finir formellement des fonctions de test de synonymie et d{'}en exp{\'e}rimenter l{'}usage."
C96-2199,"Structured lexical data: how to make them widely available, useful and reasonably protected? A practicalexample with a trilingual dictionary",1996,5,3,1,1,5594,mathieu lafourcade,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"We are studying under which constraints structured lexical data can bemade, at the same time, widely available to the general public (freely ornot), electronically supported, published and reasonably protected frompiracy? A three facet approach-with dictionary tools, web servers and e-mail servers--seems to be effective. We illustrate our views with Alex, a genericdictionary tool, which is used with a French-English-Malay dictionary. Thevery distinction between output, logical and coding formats is made. Storage is based onthe latter and output formats are dynamically generated on the fly atrequest times-making the tool usable in many configurations. Keeping the data structuredis necessary to make them usable also by automated processes and to allowdynamic filtering."
C94-1045,Manipulating human-oriented dictionaries with very simple tools,1994,3,5,2,0,56526,jean gaschler,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"It is possible to manipulate real-size human-oriented dictionaries on a Macintosh by using only very simple tools. Our methodology has been applied in the construction of a French-English-Malay dictionary. This dictionary has been obtained by crossing semi-automatically two bilingual dictionaries. To revise the dictionary, as well as to obtain a publishable paper form and an on-line electronic form, we use only Microsoft Wordxe2x84xa2, a specialized language for writing transcriptors and a small but powerful dictionary tool."
