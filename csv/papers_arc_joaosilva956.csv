2021.emnlp-main.113,Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning,2021,-1,-1,4,1,8862,ruben branco,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Commonsense is a quintessential human capacity that has been a core challenge to Artificial Intelligence since its inception. Impressive results in Natural Language Processing tasks, including in commonsense reasoning, have consistently been achieved with Transformer neural language models, even matching or surpassing human performance in some benchmarks. Recently, some of these advances have been called into question: so called data artifacts in the training data have been made evident as spurious correlations and shallow shortcuts that in some cases are leveraging these outstanding results. In this paper we seek to further pursue this analysis into the realm of commonsense related language processing tasks. We undertake a study on different prominent benchmarks that involve commonsense reasoning, along a number of key stress experiments, thus seeking to gain insight on whether the models are learning transferable generalizations intrinsic to the problem at stake or just taking advantage of incidental shortcuts in the data items. The results obtained indicate that most datasets experimented with are problematic, with models resorting to non-robust features and appearing not to be learning and generalizing towards the overall tasks intended to be conveyed or exemplified by the datasets."
2020.lrec-1.106,The {BDC}am{\\~o}es Collection of {P}ortuguese Literary Documents: a Research Resource for Digital Humanities and Language Technology,2020,-1,-1,3,0,16829,sara grilo,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents the BDCam{\~o}es Collection of Portuguese Literary Documents, a new corpus of literary texts written in Portuguese that in its inaugural version includes close to 4 million words from over 200 complete documents from 83 authors in 14 genres, covering a time span from the 16th to the 21st century, and adhering to different orthographic conventions. Many of the texts in the corpus have also been automatically parsed with state-of-the-art language processing tools, forming the BDCam{\~o}es Treebank subcorpus. This set of characteristics makes of BDCam{\~o}es an invaluable resource for research in language technology (e.g. authorship detection, genre classification, etc.) and in language science and digital humanities (e.g. comparative literature, diachronic linguistics, etc.)."
2020.lrec-1.598,"The {MWN}.{PT} {W}ord{N}et for {P}ortuguese: Projection, Validation, Cross-lingual Alignment and Distribution",2020,-1,-1,6,0,8863,antonio branco,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The objective of the present paper is twofold, to present the MWN.PT WordNet and to report on its construction and on the lessons learned with it. The MWN.PT WordNet for Portuguese includes 41,000 concepts, expressed by 38,000 lexical units. Its synsets were manually validated and are linked to semantically equivalent synsets of the Princeton WordNet of English, and thus transitively to the many wordnets for other languages that are also linked to this English wordnet. To the best of our knowledge, it is the largest high quality, manually validated and cross-lingually integrated, wordnet of Portuguese distributed for reuse. Its construction was initiated more than one decade ago and its description is published for the first time in the present paper. It follows a three step {\textless}projection, validation with alignment, completion{\textgreater} methodology consisting on the manual validation and expansion of the outcome of an automatic projection procedure of synsets and their hypernym relations, followed by another automatic procedure that transferred the relations of remaining semantic types across wordnets of different languages."
2020.lrec-1.622,Reproduction and Revival of the Argument Reasoning Comprehension Task,2020,-1,-1,3,1,8864,joao rodrigues,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Reproduction of scientific findings is essential for scientific development across all scientific disciplines and reproducing results of previous works is a basic requirement for validating the hypothesis and conclusions put forward by them. This paper reports on the scientific reproduction of several systems addressing the Argument Reasoning Comprehension Task of SemEval2018. Given a recent publication that pointed out spurious statistical cues in the data set used in the shared task, and that produced a revised version of it, we also evaluated the reproduced systems with this new data set. The exercise reported here shows that, in general, the reproduction of these systems is successful with scores in line with those reported in SemEval2018. However, the performance scores are worst than those, and even below the random baseline, when the reproduced systems are run over the revised data set expunged from data artifacts. This demonstrates that this task is actually a much harder challenge than what could have been perceived from the inflated, close to human-level performance scores obtained with the data set used in SemEval2018. This calls for a revival of this task as there is much room for improvement until systems may come close to the upper bound provided by human performance."
2020.lrec-1.680,"A Shared Task of a New, Collaborative Type to Foster Reproducibility: A First Exercise in the Area of Language Science and Technology with {REPROLANG}2020",2020,-1,-1,6,0,8863,antonio branco,Proceedings of the 12th Language Resources and Evaluation Conference,0,"n this paper, we introduce a new type of shared task {---} which is collaborative rather than competitive {---} designed to support and fosterthe reproduction of research results. We also describe the first event running such a novel challenge, present the results obtained, discussthe lessons learned and ponder on future undertakings."
2020.iwltp-1.1,Infrastructure for the Science and Technology of Language {PORTULAN} {CLARIN},2020,-1,-1,5,0,8863,antonio branco,Proceedings of the 1st International Workshop on Language Technology Platforms,0,"This paper presents the PORTULAN CLARIN Research Infrastructure for the Science and Technology of Language, which is part of the European research infrastructure CLARIN ERIC as its Portuguese national node, and belongs to the Portuguese National Roadmap of Research Infrastructures of Strategic Relevance. It encompasses a repository, where resources and metadata are deposited for long-term archiving and access, and a workbench, where Language Technology tools and applications are made available through different modes of interaction, among many other services. It is an asset of utmost importance for the technological development of natural languages and for their preparation for the digital age, contributing to ensure the citizenship of their speakers in the information society."
W19-3510,A Hierarchically-Labeled {P}ortuguese Hate Speech Dataset,2019,0,5,2,0,33,paula fortuna,Proceedings of the Third Workshop on Abusive Language Online,0,"Over the past years, the amount of online offensive speech has been growing steadily. To successfully cope with it, machine learning are applied. However, ML-based techniques require sufficiently large annotated datasets. In the last years, different datasets were published, mainly for English. In this paper, we present a new dataset for Portuguese, which has not been in focus so far. The dataset is composed of 5,668 tweets. For its annotation, we defined two different schemes used by annotators with different levels of expertise. Firstly, non-experts annotated the tweets with binary labels ({`}hate{'} vs. {`}no-hate{'}). Secondly, expert annotators classified the tweets following a fine-grained hierarchical multiple label scheme with 81 hate speech categories in total. The inter-annotator agreement varied from category to category, which reflects the insight that some types of hate speech are more subtle than others and that their detection depends on personal perception. This hierarchical annotation scheme is the main contribution of the presented work, as it facilitates the identification of different types of hate speech and their intersections. To demonstrate the usefulness of our dataset, we carried a baseline classification experiment with pre-trained word embeddings and LSTM on the binary classified data, with a state-of-the-art outcome."
W18-3016,{W}ord{N}et Embeddings,2018,-1,-1,4,1,14538,chakaveh saedi,Proceedings of The Third Workshop on Representation Learning for {NLP},0,"Semantic networks and semantic spaces have been two prominent approaches to represent lexical semantics. While a unified account of the lexical meaning relies on one being able to convert between these representations, in both directions, the conversion direction from semantic networks into semantic spaces started to attract more attention recently. In this paper we present a methodology for this conversion and assess it with a case study. When it is applied over WordNet, the performance of the resulting embeddings in a mainstream semantic similarity task is very good, substantially superior to the performance of word embeddings based on very large collections of texts like word2vec."
W18-2801,Predicting Brain Activation with {W}ord{N}et Embeddings,2018,0,2,3,1,8864,joao rodrigues,Proceedings of the Eight Workshop on Cognitive Aspects of Computational Language Learning and Processing,0,"The task of taking a semantic representation of a noun and predicting the brain activity triggered by it in terms of fMRI spatial patterns was pioneered by Mitchell et al. 2008. That seminal work used word co-occurrence features to represent the meaning of the nouns. Even though the task does not impose any specific type of semantic representation, the vast majority of subsequent approaches resort to feature-based models or to semantic spaces (aka word embeddings). We address this task, with competitive results, by using instead a semantic network to encode lexical semantics, thus providing further evidence for the cognitive plausibility of this approach to model lexical meaning."
L18-1513,Semantic Equivalence Detection: Are Interrogatives Harder than Declaratives?,2018,0,2,4,1,8864,joao rodrigues,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1722,"Browsing and Supporting Pluricentric Global {W}ordnet, or just your {W}ordnet of Interest",2018,0,0,4,0,8863,antonio branco,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
S17-1030,Ways of Asking and Replying in Duplicate Question Detection,2017,5,10,4,1,8864,joao rodrigues,Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*{SEM} 2017),0,"This paper presents the results of systematic experimentation on the impact in duplicate question detection of different types of questions across both a number of established approaches and a novel, superior one used to address this language processing task. This study permits to gain a novel insight on the different levels of robustness of the diverse detection methods with respect to different conditions of their application, including the ones that approximate real usage scenarios."
W16-6405,Adding syntactic structure to bilingual terminology for improved domain adaptation,2016,3,1,5,0,10622,mikel artetxe,Proceedings of the 2nd Deep Machine Translation Workshop,0,None
W16-2332,{SMT} and Hybrid systems of the {QTL}eap project in the {WMT}16 {IT}-task,2016,26,3,12,0,17856,rosa gaudio,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the description of 12 systems submitted to the WMT16 IT-task, covering six different languages, namely Basque, Bulgarian, Dutch, Czech, Portuguese and Spanish. All these systems were developed under the scope of the QTLeap project, presenting a common strategy. For each language two different systems were submitted, namely a phrasebased MT system built using Moses, and a system exploiting deep language engineering approaches, that in all the languages but Bulgarian was implemented using TectoMT. For 4 of the 6 languages, the TectoMT-based system performs better than the Moses-based one."
L16-1246,{CINTIL} {D}ependency{B}ank {PREMIUM} - A Corpus of Grammatical Dependencies for {P}ortuguese,2016,14,1,5,0,17855,rita carvalho,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents a new linguistic resource for the study and computational processing of Portuguese. CINTIL DependencyBank PREMIUM is a corpus of Portuguese news text, accurately manually annotated with a wide range of linguistic information (morpho-syntax, named-entities, syntactic function and semantic roles), making it an invaluable resource specially for the development and evaluation of data-driven natural language processing tools. The corpus is under active development, reaching 4,000 sentences in its current version. The paper also reports on the training and evaluation of a dependency parser over this corpus. CINTIL DependencyBank PREMIUM is freely-available for research purposes through META-SHARE."
L16-1330,{NNB}locks: A Deep Learning Framework for Computational Linguistics Neural Network Models,2016,6,0,3,0,35064,frederico caroli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Lately, with the success of Deep Learning techniques in some computational linguistics tasks, many researchers want to explore new models for their linguistics applications. These models tend to be very different from what standard Neural Networks look like, limiting the possibility to use standard Neural Networks frameworks. This work presents NNBlocks, a new framework written in Python to build and train Neural Networks that are not constrained by a specific kind of architecture, making it possible to use it in computational linguistics."
L16-1483,{QTL}eap {WSD}/{NED} Corpora: Semantic Annotation of Parallel Corpora in Six Languages,2016,9,5,10,0,16264,arantxa otegi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This work presents parallel corpora automatically annotated with several NLP tools, including lemma and part-of-speech tagging, named-entity recognition and classification, named-entity disambiguation, word-sense disambiguation, and coreference. The corpora comprise both the well-known Europarl corpus and a domain-specific question-answer troubleshooting corpus on the IT domain. English is common in all parallel corpora, with translations in five languages, namely, Basque, Bulgarian, Czech, Portuguese and Spanish. We describe the annotated corpora and the tools used for annotation, as well as annotation statistics for each language. These new resources are freely available and will help research on semantic processing for machine translation and cross-lingual transfer."
W15-5503,"Small in Size, Big in Precision: A Case for Using Language-Specific Lexical Resources for Word Sense Disambiguation",2015,-1,-1,2,0,24253,steven neale,Proceedings of the Second Workshop on Natural Language Processing and Linked Open Data,0,None
W15-4101,Bootstrapping a hybrid deep {MT} system,2015,9,4,1,1,8865,joao silva,Proceedings of the Fourth Workshop on Hybrid Approaches to Translation ({H}y{T}ra),0,"We present a Portuguesexe2x86x94English hybrid deep MT system based on an analysistransfer-synthesis architecture, with transfer being done at the level of deep syntax, a level that already includes a great deal of semantic information. The system received a few months of development, but its performance is already similar to that of baseline phrase-based MT, when evaluated using BLEU, and surpasses the baseline under human qualitative assessment."
W15-0208,A Flexible Tool for Manual Word Sense Annotation,2015,0,0,2,0,24253,steven neale,Proceedings of the 11th Joint {ACL}-{ISO} Workshop on Interoperable Semantic Annotation ({ISA}-11),0,None
W12-3409,Assigning Deep Lexical Types Using Structured Classifier Features for Grammatical Dependencies,2012,20,1,1,1,8865,joao silva,Proceedings of the {ACL} 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,0,"Deep linguistic grammars are able to provide rich and highly complex grammatical representations of sentences, capturing, for instance, long-distance dependencies and returning a semantic representation. These grammars lack robustness in the sense that they do not gracefully handle words missing from their lexicon. Several approaches have been explored to handle this problem, many of which consist in pre-annotating the input to the grammar with shallow processing machine-learning tools. Most of these tools, however, use features based on a fixed window of context, such as n-grams. We investigate whether the use of features that encode discrete structures, namely grammatical dependencies, can improve the performance of a machine learning classifier that assigns deep lexical types. In this paper we report on the design and evaluation of this classifier."
branco-etal-2012-propbank,A {P}rop{B}ank for {P}ortuguese: the {CINTIL}-{P}rop{B}ank,2012,12,5,5,0,8863,antonio branco,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"With the CINTIL-International Corpus of Portuguese, an ongoing corpus annotated with fully flegded grammatical representation, sentences get not only a high level of lexical, morphological and syntactic annotation but also a semantic analysis that prepares the data to a manual specification step and thus opens the way for a number of tools and resources for which there is a great research focus at the present. This paper reports on the construction of a propbank that builds on CINTIL-DeepGramBank, with nearly 10 thousand sentences, on the basis of a deep linguistic grammar and on the process and the linguistic criteria guiding that construction, which makes possible to obtain a complete PropBank with both syntactic and semantic levels of linguistic annotation. Taking into account this and the promising scores presented in this study for inter-annotator agreement, CINTIL-PropBank presents itself as a great resource to train a semantic role labeller, one of our goals with this project."
silva-etal-2012-dealing,Dealing with unknown words in statistical machine translation,2012,10,4,1,1,8865,joao silva,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In Statistical Machine Translation, words that were not seen during training are unknown words, that is, words that the system will not know how to translate. In this paper we contribute to this research problem by profiting from orthographic cues given by words. Thus, we report a study of the impact of word distance metrics in cognates' detection and, in addition, on the possibility of obtaining possible translations of unknown words through Logical Analogy. Our approach is tested in the translation of corpora from Portuguese to English (and vice-versa)."
silva-etal-2010-top,Top-Performing Robust Constituency Parsing of {P}ortuguese: Freely Available in as Many Ways as you Can Get it,2010,8,6,1,1,8865,joao silva,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper we present LX-Parser, a probabilistic, robust constituency parser for Portuguese. This parser achieves ca. 88{\%} f-score in the labeled bracketing task, thus reaching a state-of-the-art performance score that is in line with those that are currently obtained by top-ranking parsers for English, the most studied natural language. To the best of our knowledge, LX-Parser is the first state-of-the-art, robust constituency parser for Portuguese that is made freely available. This parser is being distributed in a variety of ways, each suited for a different type of usage. More specifically, LX-Parser is being made available (i) as a downloadable, stand-alone parsing tool that can be run locally by its users; (ii) as a Web service that exposes an interface that can be invoked remotely and transparently by client applications; and finally (iii) as an on-line parsing service, aimed at human users, that can be accessed through any common Web browser."
branco-etal-2010-developing,Developing a Deep Linguistic Databank Supporting a Collection of Treebanks: the {CINTIL} {D}eep{G}ram{B}ank,2010,11,18,3,0,8863,antonio branco,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Corpora of sentences annotated with grammatical information have been deployed by extending the basic lexical and morphological data with increasingly complex information, such as phrase constituency, syntactic functions, semantic roles, etc. As these corpora grow in size and the linguistic information to be encoded reaches higher levels of sophistication, the utilization of annotation tools and, above all, supporting computational grammars appear no longer as a matter of convenience but of necessity. In this paper, we report on the design features, the development conditions and the methodological options of a deep linguistic databank, the CINTIL DeepGramBank. In this corpus, sentences are annotated with fully fledged linguistically informed grammatical representations that are produced by a deep linguistic processing grammar, thus consistently integrating morphological, syntactic and semantic information. We also report on how such corpus permits to straightforwardly obtain a whole range of past generation annotated corpora (POS, NER and morphology), current generation treebanks (constituency treebanks, dependency banks, propbanks) and next generation databanks (logical form banks) simply by means of a very residual selection/extraction effort to get the appropriate ''``views'''' exposing the relevant layers of information."
P09-4002,{LX}-Center: a center of online linguistic services,2009,2,2,6,0,8863,antonio branco,Proceedings of the {ACL}-{IJCNLP} 2009 Software Demonstrations,0,"This is a paper supporting the demonstration of the LX-Center at ACL-IJCNLP-09. LX-Center is a web center of online linguistic services aimed at both demonstrating a range of language technology tools and at fostering the education, research and development in natural language science and technology."
branco-etal-2008-lx,{LX}-Service: Web Services of Language Technology for {P}ortuguese,2008,3,3,5,0,8863,antonio branco,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In the present paper we report on the development of a cluster of web services of language technology for Portuguese that we named as LXService. These web services permit the direct interaction of client applications with language processing tools via the Internet. This way of making available language technology was motivated by the need of its integration in an eLearning environment. In particular, it was motivated by the development of new multilingual functionalities that were aimed at extending a Learning Management System and that needed to resort to the outcome of some of those tools in a distributed and remote fashion. This specific usage situation happens however to be representative of a typical and recurrent set up in the utilization of language processing tools in different settings and projects. Therefore, the approach reported here offers not only a solution for this specific problem, which immediately motivated it, but contributes also some first steps for what we see as an important paradigm shift in terms of the way language technology can be distributed and find a better way to unleash its full potential and impact."
barreto-etal-2006-open,Open Resources and Tools for the Shallow Processing of {P}ortuguese: The {T}ag{S}hare Project,2006,6,22,7,0,50267,florbela barreto,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents the TagShare project and the linguistic resources and tools for the shallow processing of Portuguese developed in its scope. These resources include a 1 million token corpus that has been accurately hand annotated with a variety of linguistic information, as well as several state of the art shallow processing tools capable of automatically producing that type of annotation. At present, the linguistic annotations in the corpus are sentence and paragraph boundaries, token boundaries, morphosyntactic POS categories, values of inflection features, lemmas and namedentities. Hence, the set of tools comprise a sentence chunker, a tokenizer, a POS tagger, nominal and verbal analyzers and lemmatizers, a verbal conjugator, a nominal ÂinflectorÂ, and a namedentity recognizer, some of which underline several online services."
E06-2024,A Suite of Shallow Processing Tools for {P}ortuguese: {LX}-Suite,2006,4,31,2,0,8863,antonio branco,Demonstrations,0,"In this paper we present LX-Suite, a set of tools for the shallow processing of Portuguese. This suite comprises several modules, namely: a sentence chunker, a tokenizer, a POS tagger, featurizers and lemmatizers."
branco-silva-2004-evaluating,Evaluating Solutions for the Rapid Development of State-of-the-Art {POS} Taggers for {P}ortuguese,2004,0,31,2,0,8863,antonio branco,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,None
branco-etal-2002-nexing,Nexing Corpus: a corpus of verbal protocols on syllogistic reasoning,2002,4,0,3,0,8863,antonio branco,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"In this paper, we describe the Nexing Corpus and report on the tools implemented and the tasks undertaken for its development. The Nexing Corpus includes (i) a collection of written transcriptions of verbal data elicited during a psycholinguistic experiment on syllogistic reasoning; and (ii) performance data concerning that experiment, such as latencies, confidence levels and accuracy of answers provided. The verbal productions recorded in the corpus are of a specific linguistic type that is seldom, if at all, represented in corpora. These data are relevant for the development of human language technologies aimed at modeling this type of linguistic behavior, which is not uncommon in evolved interactions of cooperative agents. This corpus with thinking aloud data on syllogistic reasoning is also an important source of material for cognitive science, in particular for research on the nature of human deductive reasoning."
