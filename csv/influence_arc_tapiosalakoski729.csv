K18-2013,K17-2002,0,0.0731186,"Missing"
K18-2013,K17-2001,0,0.351337,"f treebanks and languages. The 2017 task (Zeman et al., 2017) focused primarily on the evaluation of the syntactic trees produced by the participating systems, whereas the 2018 task (Zeman et al., 2018) adds further two metrics which also measure the accuracy of morphological tagging and lemmatization. In this paper, we present the TurkuNLP system submission to the CoNLL 2018 UD Shared Task. The system is an end-toend parsing pipeline, with components for segmentation, morphological tagging, parsing, and lemmatization. The tagger and parser are based on the 2017 winning system by Dozat et al. (2017), while the lemmatizer is a novel approach utilizing the OpenNMT neural machine translation system for sequence-to-sequence learning. Our pipeline LAS The proportion of words which have the correct head word with the correct dependency relation. MLAS Similar to LAS, with the additional requirement that a subset of the morphology features is correctly predicted and the functional dependents of the word are correctly attached. MLAS is only calculated on content-bearing words, and strives to level the field w.r.t. morphological richness of languages. 1 https://dumps.wikimedia.org https://svn.code"
K18-2013,P81-1022,0,0.696953,"Missing"
K18-2013,K17-3002,0,0.361739,"a large set of treebanks and languages. The 2017 task (Zeman et al., 2017) focused primarily on the evaluation of the syntactic trees produced by the participating systems, whereas the 2018 task (Zeman et al., 2018) adds further two metrics which also measure the accuracy of morphological tagging and lemmatization. In this paper, we present the TurkuNLP system submission to the CoNLL 2018 UD Shared Task. The system is an end-toend parsing pipeline, with components for segmentation, morphological tagging, parsing, and lemmatization. The tagger and parser are based on the 2017 winning system by Dozat et al. (2017), while the lemmatizer is a novel approach utilizing the OpenNMT neural machine translation system for sequence-to-sequence learning. Our pipeline LAS The proportion of words which have the correct head word with the correct dependency relation. MLAS Similar to LAS, with the additional requirement that a subset of the morphology features is correctly predicted and the functional dependents of the word are correctly attached. MLAS is only calculated on content-bearing words, and strives to level the field w.r.t. morphological richness of languages. 1 https://dumps.wikimedia.org https://svn.code"
K18-2013,tiedemann-2012-parallel,0,0.294131,"orphological tagging and parsing. 1 2 Task overview CoNLL 2018 UD Shared Task is a follow-up to the 2017 shared task of developing systems predicting syntactic dependencies on raw texts across a number of typologically different languages. In addition to the 82 UD treebanks for 57 languages, which formed the primary training data, the participating teams were allowed to use also additional resources such as Wikipedia dumps1 , raw web crawl data and word embeddings (Ginter et al., 2017), morphological transducers provided by Apertium2 and Giellatekno3 , and the OPUS parallel corpus collection (Tiedemann, 2012). In addition to the 2017 primary metric (LAS), the systems were additionally evaluated also on metrics which include lemmatization and morphology prediction. In brief, the three primary metrics of the task are as follows (see Zeman et al. (2018) for detailed definitions): Introduction The 2017 and 2018 CoNLL UD Shared tasks aim at an evaluation of end-to-end parsing systems on a large set of treebanks and languages. The 2017 task (Zeman et al., 2017) focused primarily on the evaluation of the syntactic trees produced by the participating systems, whereas the 2018 task (Zeman et al., 2018) add"
K18-2013,W11-2123,0,0.0267418,"Missing"
K18-2013,P18-4020,0,0.025348,"Missing"
K18-2013,K17-3001,1,0.903814,"Missing"
K18-2013,K17-2003,0,0.045518,"Missing"
K18-2013,K18-2001,1,0.804081,"Missing"
K18-2013,P17-4012,0,0.184601,"we rely for most but not all languages on the tokenization and sentence splitting provided by the UDPipe baseline (Straka et al., 2016). Tagging and parsing is carried out using the parser of Dozat et al. (2017), the winning entry of the 2017 shared task. Using a simple data manipulation technique, we also obtain the morphological feature predictions from the same tagger which was originally used to produce only universal partof-speech (UPOS) and language-specific part-ofspeech (XPOS) predictions. Finally, the lemmatization is carried out using the OpenNMT neural machine translation toolkit (Klein et al., 2017), casting lemmatization as a machine translation problem. All these components are wrapped into one parsing pipeline, making it possible to run all four steps with one simple command and gain state-of-the-art or very close to state-of-the-art results for each step. In the following, we describe each of these four steps in more detail, while more detailed description of the pipeline itself is given in Section 6. 3.2 Pre-trained embeddings Where available, we used the pre-trained embeddings from the 2017 shared task (Ginter et al., 2017). Embeddings for Afrikaans, Breton, Buryat, Faroese, Gothic"
K18-2013,D15-1166,0,0.0171543,"translation toolkit and translation model implementations. Our current implementation is based on the Python version of the OpenNMT: Open-Source Toolkit for Neural Machine Translation (Klein et al., 2017). We use a deep attentional encoder-decoder network with 2 layered bidirectional LSTM encoder for reading the sequence of input characters + morphological tags and producing a sequence of encoded vectors. Our decoder is a 2 layered unidirectional LSTM with input feeding attention for generating the sequence of output characters based on the encoded representations. In input feeding attention (Luong et al., 2015) the previous attention weights are given as input in the next time step to inform the model about past alignment decisions and prevent the model to repeat the same output multiple times. We use beam search with beam size 5 during decoding. As the lemmatizer does not see the actual sentence where a word appears, morphological tags are used in the input sequence to inform the system about the word’s morpho-syntactic context. The tagger is naturally able to see the full sentence context and in most cases it should produce enough information for the lemmatizer to give it a possibility to lemmatiz"
S13-2108,P05-1022,0,0.0183791,"given attribute to mark them as pre-annotated data for TEES and all character offsets are converted to the TEES format by increasing the end offset by one, resulting in spans denoted with the beginning character and end character plus one, a common convention in programming languages such as Java and Python. Before use, all DDIExtraction 2013 corpora are parsed with the TEES preprocessing pipeline, using the BLLIP parser with David McClosky’s biomodel to produce a Penn-tree style parse which is converted with the Stanford parser tools to the collapsed CC processed Stanford dependency scheme (Charniak and Johnson, 2005; McClosky, 2010; de Marneffe et al., 2006). 2.3 Drug name recognition with TEES For drug name recognition the TEES entity detector module is used. Baseline syntactic features (model 1) are generated from the parse, using both information on the tokens and their linear context, as well as dependency chains starting from the entity head token. External data is added to the head token features, from where it is combined into more complex features. One example is generated for each token in the sentence, and these are classified into negatives or one of the positive classes. As a new feature we g"
S13-2108,de-marneffe-etal-2006-generating,0,0.0473592,"Missing"
S13-2108,N10-1004,0,0.0270844,"m as pre-annotated data for TEES and all character offsets are converted to the TEES format by increasing the end offset by one, resulting in spans denoted with the beginning character and end character plus one, a common convention in programming languages such as Java and Python. Before use, all DDIExtraction 2013 corpora are parsed with the TEES preprocessing pipeline, using the BLLIP parser with David McClosky’s biomodel to produce a Penn-tree style parse which is converted with the Stanford parser tools to the collapsed CC processed Stanford dependency scheme (Charniak and Johnson, 2005; McClosky, 2010; de Marneffe et al., 2006). 2.3 Drug name recognition with TEES For drug name recognition the TEES entity detector module is used. Baseline syntactic features (model 1) are generated from the parse, using both information on the tokens and their linear context, as well as dependency chains starting from the entity head token. External data is added to the head token features, from where it is combined into more complex features. One example is generated for each token in the sentence, and these are classified into negatives or one of the positive classes. As a new feature we generate all subs"
S13-2108,S13-2056,0,0.045994,"Missing"
S16-1142,W06-1670,0,0.528304,"Missing"
S16-1142,P05-1004,0,0.0339688,"nology, University of Turku Turku Centre for Computer Science (TUCS) Faculty of Mathematics and Natural Sciences, FI-20014, Turku, Finland firstname.lastname@utu.fi Abstract form a lexical item. The concept of MWE as used in the DiMSUM task is described in detail in Schneider et al. (2014). The supersenses are broad-coverage, coarse lexical categories, 26 for nouns and 15 for verbs. These supersenses mostly correspond to the WordNet lexicographer files. A detailed description of the supersenses is in Schneider and Smith (2015). Automated supersense tagging has previously been explored by e.g. Curran (2005), Ciaramita and Altun (2006) and Johannsen et al. (2014). The SemEval 2016 DiMSUM Shared Task concerns the detection of minimal semantic units from text and prediction of their coarse lexical categories known as supersenses. Our approach is to define this task as a binary classification problem approachable by straightforward machine learning methods. We start by detecting semantic units by matching text spans against several large dictionaries, including the English WordNet, expressions derived from the Yelp Academic Dataset and concepts from the English Wikipedia, generating a set of potenti"
S16-1142,S14-1001,0,0.139233,"omputer Science (TUCS) Faculty of Mathematics and Natural Sciences, FI-20014, Turku, Finland firstname.lastname@utu.fi Abstract form a lexical item. The concept of MWE as used in the DiMSUM task is described in detail in Schneider et al. (2014). The supersenses are broad-coverage, coarse lexical categories, 26 for nouns and 15 for verbs. These supersenses mostly correspond to the WordNet lexicographer files. A detailed description of the supersenses is in Schneider and Smith (2015). Automated supersense tagging has previously been explored by e.g. Curran (2005), Ciaramita and Altun (2006) and Johannsen et al. (2014). The SemEval 2016 DiMSUM Shared Task concerns the detection of minimal semantic units from text and prediction of their coarse lexical categories known as supersenses. Our approach is to define this task as a binary classification problem approachable by straightforward machine learning methods. We start by detecting semantic units by matching text spans against several large dictionaries, including the English WordNet, expressions derived from the Yelp Academic Dataset and concepts from the English Wikipedia, generating a set of potential supersenses for each matched span. For each potential"
S16-1142,N15-1177,0,0.0762234,"or Expression Detection (BCED) Jari Bj¨orne and Tapio Salakoski Department of Information Technology, University of Turku Turku Centre for Computer Science (TUCS) Faculty of Mathematics and Natural Sciences, FI-20014, Turku, Finland firstname.lastname@utu.fi Abstract form a lexical item. The concept of MWE as used in the DiMSUM task is described in detail in Schneider et al. (2014). The supersenses are broad-coverage, coarse lexical categories, 26 for nouns and 15 for verbs. These supersenses mostly correspond to the WordNet lexicographer files. A detailed description of the supersenses is in Schneider and Smith (2015). Automated supersense tagging has previously been explored by e.g. Curran (2005), Ciaramita and Altun (2006) and Johannsen et al. (2014). The SemEval 2016 DiMSUM Shared Task concerns the detection of minimal semantic units from text and prediction of their coarse lexical categories known as supersenses. Our approach is to define this task as a binary classification problem approachable by straightforward machine learning methods. We start by detecting semantic units by matching text spans against several large dictionaries, including the English WordNet, expressions derived from the Yelp Acad"
S16-1142,schneider-etal-2014-comprehensive,0,0.100098,"mple generation. Even while the Yelp and Wikipedia taggers provide more matches, at the same time the number of examples that are undetectable due to being nested within a false, longer MWE increases by 262. The issue of missing nested examples could be solved by generating examples for matched nested spans, but the corpus annotation might not be compatible with this approach, as each token can belong to a maximum of one annotated semantic unit. In the case of strong MWEs, for example in the idiom “close call”, it is not clear what, if any, supersense the “call” token alone could be assigned (Schneider et al., 2014). However, in an MWE such as “cricket bat” (n.artifact) it is clear what the meaning of “bat” is, and likewise, “cricket” refers to the sport. Nevertheless, there is no annotation within MWEs, so while “cricket” alone has the supersense n.act, nested in “cricket bat” it has no supersense of its own. Thus, examples generated for nested spans would be inconsistent with non-nested examples. 3.2 Supersense classification While MWE detection performance was very low due to the issues in example generation, supersense SYS 214 227 249 255 211 106 108 248 254 263 Team ICL-HD VectorWeavers UW-CSE BCED"
S16-1142,S16-1084,0,0.0204464,"sk is the averaged performance on these tasks, which are also evaluated independently. The systems can approach these tasks either independently (e.g. in a pipeline) or through a joint model. Our system achieves good performance on the supersense classification task but has limited performance for detection of multi-word semantic units. We show that the task of supersense prediction can be effectively defined as a binary classification task. 1 Introduction The SemEval 2016 DiMSUM Shared Task1 concerns the detection of minimal semantic units and their semantic classification using supersenses (Schneider et al., 2016). The minimal semantic units can consist of either single words or multiword expressions (MWE) in cases where multiple words 1 http://dimsum16.github.io/ We approach the DiMSUM task as a machine learning classification task where examples are generated for all semantic units found in a pre-defined dictionary. These semantic units are classified into one of the 41 supersenses by generating an example for each possible semantic unit + supersense pair, turning the task of assigning one of many supersenses into a binary classification problem. In this manner, the task becomes a generalized machine"
W04-1203,P99-1065,0,0.0256684,"nteraction subgraphs can be partially overlapping, because a single link can be part of more than one interaction subgraph. Figure 1 shows an example of an annotated text fragment. 4 Evaluation criteria We evaluated the performance of the LG parser according to the following three quantitative criteria: • Number of dependencies recovered • Number of fully correct linkages • Number of interaction subgraphs recovered The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999)). The number of fully correct linkages, i.e. linkages where all annotated dependencies are recovered, measures the fraction of sentences that are parsed without error. However, a fully correct linkage is not necessary to extract protein-protein interactions from a sentence; to estimate how many interactions can potentially be recovered, we measure the number of interaction subgraphs for which all dependencies were recovered. For each criterion, we measure the performance for the first linkage returned by the parser. However, the first linkage as ordered by the heuristics of the LG parser was"
W06-3605,H05-1003,0,0.029408,"d. Further, each of the various problems in natural language processing is typically approached with a different class of models, ranging from n-gram statistics to complex regressors and classifiers such as the support vector machines. These different approaches need to be combined in order to find the globally optimal solution. Therefore, in our study we aim to develop a search strategy that allows to combine a wider range of target functions. An alternative approach is that of propagating n best solutions through the pipeline system, where each step re-ranks the solutions by local criteria (Ji et al., 2005). Incorporating a wide range of features representing information from all levels of analysis into a single master classifier is other commonly used method (Kambhatla, 2004; Zelenko et al., 2004). In this paper, we assume the possibility of generating the structurally correct solutions incrementally, through a sequence of partially completed solutions. We then derive a probabilistic search algorithm that attempts to identify the globally best solution, without fully completing all structurally correct solutions. Further, we do not impose strong restrictions, such as the Viterbi assumption, on"
W06-3605,P04-3022,0,0.0258244,"egressors and classifiers such as the support vector machines. These different approaches need to be combined in order to find the globally optimal solution. Therefore, in our study we aim to develop a search strategy that allows to combine a wider range of target functions. An alternative approach is that of propagating n best solutions through the pipeline system, where each step re-ranks the solutions by local criteria (Ji et al., 2005). Incorporating a wide range of features representing information from all levels of analysis into a single master classifier is other commonly used method (Kambhatla, 2004; Zelenko et al., 2004). In this paper, we assume the possibility of generating the structurally correct solutions incrementally, through a sequence of partially completed solutions. We then derive a probabilistic search algorithm that attempts to identify the globally best solution, without fully completing all structurally correct solutions. Further, we do not impose strong restrictions, such as the Viterbi assumption, on the target functions. To a certain extent, this approach is related to the problem of cost-sensitive learning, where obtaining a feature value is associated with a cost and"
W06-3605,C90-2040,0,0.0578486,"set of candidate parses and typically also implements a target function that scores the parses based on their structural and lexical features. Each parse that is compatible with both the POS tagger and the parser is structurally correct. The best solution may be defined, for instance, as such a solution that maximizes the sum of the scores of the POS- and parser-centric target functions. In practice, the set of structurally correct solutions may be computed, for example, through the intersection or composition of finite-state automata as in the formalism of finite-state intersection grammars (Koskenniemi, 1990). Finding the best so33 Workshop on Computationally Hard Problemsand Joint Inference in Speech and Language Processing, pages 33–40, c New York City, New York, June 2006. 2006 Association for Computational Linguistics lution may be implemented as a best-path search through Viterbi decoding, given a target function that satisfies the Viterbi condition. Most of the recent approaches to NLP tasks like parse re-ranking make, however, use of featurebased representations and machine-learning induced target functions, which do not allow efficient search strategies that are guaranteed to find the glob"
W07-1004,I05-1006,0,0.310811,"Missing"
W07-1004,de-marneffe-etal-2006-generating,0,0.168812,"Missing"
W07-1004,levy-andrew-2006-tregex,0,0.0261922,"ctic dependencies between the words. The scheme defines a hierarchy of 48 grammatical relations, or dependency types. The most generic relation, dependent, can be specialized as auxiliary, argument, or modifier, which again have several subtypes (de Marneffe et al., 2006). The Stanford conversion transforms phrase structure parses into the Stanford scheme. First, the semantic head of each constituent is identified using head rules similar to those of Collins (1999) and untyped dependencies are then extracted and labeled with the most specific grammatical relations possible using Tregex rules (Levy and Andrew, 2006). The system additionally provides a set of collapsing rules, suggested to be beneficial for IE applications (de Marneffe et al., 2006; Clegg and Shepherd, 2007). These rules collapse some dependencies by incorporating certain parts of speech (mostly Spx CC Pv CC Ss Js A/AN A/AN Cs E MVs Dsu Mp Pv Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated . advcl> <nsubjpass conj> <auxpass cc> <advmod <mark <nsubjpass pobj> <nmod <nmod <det prep> <auxpass Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-r"
W07-1004,1993.iwpt-1.22,0,0.290886,"for dependency comparable to that of PTB for constituency, no widely adopted standard currently exists. In this paper, we present a step towards unifying the diverse syntax schemes in use in IE systems and corpora such as the GENIA Treebank1 and the recently introduced BioInfer corpus (Pyysalo et al., 2007). Clegg and Shepherd (2007) have recently proposed to use the Stanford dependency scheme (de Marneffe et al., 2006) as a common, application-oriented syntax representation. To assess this choice, we develop a set of conversion rules for transforming the Link Grammar (LG) dependency scheme (Sleator and Temperley, 1993) to 1 http://www-tsujii.is.s.u-tokyo.ac.jp/ ∼genia 25 BioNLP 2007: Biological, translational, and clinical language processing, pages 25–32, c Prague, June 2007. 2007 Association for Computational Linguistics the Stanford scheme and then create a version of the BioInfer corpus in the Stanford scheme by applying the conversion rules and manually correcting the errors. By making the BioInfer corpus available in the Stanford scheme, we also increase the value of the corpus for biomedical IE. The transformation has the further benefit of allowing Link Grammar output to be normalized into a more ap"
W07-1004,A00-2018,0,\N,Missing
W07-1004,J03-4003,0,\N,Missing
W08-0601,H05-1091,0,0.0342895,"ach to PPI extraction. Finally, we discuss the effects that different evaluation strategies, choice of corpus and applied metrics have on measured performance, and conclude. P2 &lt;nsubj &lt;cop &lt;det &lt;nn &lt;nn P1 is a P2 binding protein &lt;xsubj xcomp&gt; &lt;aux &lt;nsubj P1 fails to 2 dobj&gt; bind P2 Figure 1: Stanford dependency parses (“collapsed” representation) where the shortest path, shown in bold, excludes important words. We next present our graph representation, formalize the notion of graph kernels, and present our learning method of choice, the sparse RLS. 2.1 et al., 2003) and shortest path kernels (Bunescu and Mooney, 2005) have been proposed and successfully used for relation extraction. However, these methods lack the expressive power to consider representations derived from general, possibly cyclic, dependency graph structures, such as those generated by the Stanford tools. The subsequence kernel approach does not consider parses at all, and the shortest path approach is limited to representing only a single path in the full dependency graph, which excludes relevant words even in many simple cases (Figure 1). Tree kernels can represent more complex structures, but are still restricted to tree representations."
W08-0601,I05-1006,0,0.085227,", 2008), provides an opportunity for building PPI extraction systems automatically using machine learning. A major challenge is how to supply the learner with the contextual and syntactic information needed to distinguish between interactions and non-interactions. To address the ambiguity and variability of the natural language expressions used to state PPI, several recent studies have focused on the development, adaptation and application of NLP tools for the biomedical domain. Many high-quality domain-specific tools are now freely available, including full parsers such as that introduced by Charniak and Lease (2005). Additionally, a number of conversions from phrase structure parses to dependency structures that make the relationships between words more directly accessible have been introduced. These include conversions into representations such as the Stanford dependency scheme (de Marneffe et al., 2006) that are explicitly designed for information extraction purposes. However, specialized feature representations and kernels are required to make learning from such structures possible. Approaches such as subsequence kernels (Bunescu and Mooney, 2006), tree kernels (Zelenko 1 BioNLP 2008: Current Trends i"
W08-0601,de-marneffe-etal-2006-generating,0,0.0576609,"Missing"
W08-0601,E06-1051,0,0.542388,"nteract are positive examples and other co-occuring  pairs negative. Thus, from each sentence, n2 examples are generated, where n is the number of occurrences of protein names in the sentence. Finally, we form the graph representation described earlier for each candidate interaction. We evaluate the method with 10-fold documentlevel cross-validation on all of the corpora. This guarantees the maximal use of the available data, and also allows comparison to relevant earlier work. In particular, on the AImed corpus we apply the exact same 10-fold split that was used by Bunescu et al. (2006) and Giuliano et al. (2006). Performance is measured according to the following criteria: interactions are considered untyped, undirected pairwise relations between specific protein mentions, that is, if the same protein name occurs multiple 1 Available at http://mars.cs.utu.fi/PPICorpora. 5 times in a sentence, the correct interactions must be extracted for each occurrence. Further, we do not consider self-interactions as candidates and remove them from the corpora prior to evaluation. The majority of PPI extraction system evaluations use the balanced F-score measure for quantifying the performance of the systems. This"
W08-0601,W07-1004,1,0.928632,"ic literature is a task of significant interest in the BioNLP field. The most commonly addressed problem has been the extraction of binary interactions, where the system identifies which protein pairs in a sentence have a biologically relevant relationship between them. Proposed solutions include both hand-crafted rule-based systems and machine learning approaches (see e.g. (Bunescu et al., 2005)). A wide range of results have been reported for the systems, but as we will show, differences in The public availability of large annotated PPIcorpora such as AImed (Bunescu et al., 2005), BioInfer (Pyysalo et al., 2007a) and GENIA (Kim et al., 2008), provides an opportunity for building PPI extraction systems automatically using machine learning. A major challenge is how to supply the learner with the contextual and syntactic information needed to distinguish between interactions and non-interactions. To address the ambiguity and variability of the natural language expressions used to state PPI, several recent studies have focused on the development, adaptation and application of NLP tools for the biomedical domain. Many high-quality domain-specific tools are now freely available, including full parsers suc"
W09-1402,W09-4605,1,0.795318,"Missing"
W09-1402,P05-1022,0,0.0377311,"of which may actually be associated with the same event. Similar assumptions are made in the trigger detection phase, where the classifications of individual tokens are independent. A common way to relax independence assumptions is to use N -best re-ranking where N mostlikely candidates are re-ranked using global features that model data dependencies that could not be modelled in the candidate generation step. The best candidate with respect to this re-ranked order is then the final prediction of the system. N -best re-ranking has been successfully applied for example in statistical parsing (Charniak and Johnson, 2005). We generated the ten most likely candidate graphs, as determined by the confidence scores of the individual edges given by the multi-class SVM. A perfect reranking of these ten candidates would lead to 11.5 percentage point improvement in the overall system F-score on the development set. While we were unable to produce a re-ranker sufficiently accurate to improve the system performance in the time given, the large potential gain warrants further research. 15 In trigger word detection, we experimented with a structural SVM incorporating Hidden Markov Model type of sequential dependencies (Al"
W09-1402,C08-1053,0,0.0324557,"hen classified as theme, cause, or a negative denoting the absence of an edge between the two nodes in the given direction. It should be noted that even though event nodes often require multiple outgoing edges corresponding to multiple event arguments, all edges are predicted independently and are not affected by positive or negative classifications of other edges. The feature set makes extensive use of syntactic dependencies, in line with many recent studies in biomedical information extraction (see, e.g. (Kim et al., 2008b; Miwa et al., 2008; Airola et al., 2008; Van Landeghem et al., 2008; Katrenko and Adriaans, 2008)). The central concept in generating features of potential event argument edges is the shortest undirected path of syntactic dependencies in the Stanford scheme parse of the sentence which we assume to accurately capture the relationship expressed by the edge. In Figure 3, we show that the distances among event and named entity nodes in terms of shortest dependency path length are considerably shorter than in terms of their linear order in the sentence. The end points of the path are the syntactic head tokens of the two named entities or event triggers. The head tokens are identified using a s"
W09-1402,W09-1401,0,0.659422,"For each event, its class, trigger expression in the text, and arguments need to be extracted. The task follows the recent movement in BioNLP towards the extraction of semantically typed, complex events the arguments of which can also be other events. This results in a nested structure that captures the underlying biological statements more accurately compared to the prevailing approach of merely detecting binary interactions of pairs of biological entities. Introduction In this paper, we present the best-performing system in the primary task of the BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009).1 The purpose of this shared task was to competitively evaluate information extraction systems targeting complex events in the biomedical domain. Such an evaluation helps to establish the relative merits of competing approaches, allowing direct comparability of results in a controlled setting. The shared task was 1 http://www-tsujii.is.s.u-tokyo.ac.jp/ GENIA/SharedTask 10 Our system is characterized by heavy reliance on efficient, state-of-the-art machine learning techniques and a wide array of features derived from a full dependency analysis of each sentence. The system is a pipeline of thre"
W09-1402,P08-2026,0,0.183383,"ed in the system are trained as follows. First we optimize the regularization parameter C by training on the shared task training set and testing on the shared task development set. We then re-train the final classifier on the union of the training and development sets, using the best value of C in the previous step. The same protocol is followed for the λ and β parameters in trigger detection. 3.2 Dependency parses Both trigger detection and edge prediction rely on a wide array of features derived from full dependency parses of the sentence. We use the McCloskyCharniak domain-adapted parser (McClosky and Charniak, 2008) which is among the best performing parsers trained on the GENIA Treebank corpus. The native constituency output of the parser is transformed to the “collapsed” form of the Stanford dependency scheme (de Marneffe and Manning, 2008) using the Stanford parser tools.4 The parses were provided by the shared task organizers. 4 Results and discussion The final evaluation of the system was performed by the shared task organizers using a test set whose an4 http://nlp.stanford.edu/software/ 16 notation was at no point available to the task participants. By the main criterion of Task 1, approximate span"
W09-1402,W08-1301,0,\N,Missing
W09-4605,W09-1402,1,0.866311,"Missing"
W09-4605,doddington-etal-2004-automatic,0,0.0506133,"Missing"
W09-4605,E06-1051,0,0.0690424,"Missing"
W09-4605,C08-1053,0,0.190084,"Missing"
W09-4605,I05-1006,0,0.0207855,"Missing"
W09-4605,de-marneffe-etal-2006-generating,0,0.0775516,"Missing"
W09-4605,P08-1006,0,0.0407415,"Missing"
W09-4605,W07-1004,1,0.847509,"IE and has served as the basis for real-world applications for e.g. assisted database curation (Alex et al., 2008), its limitations, such as the restriction to events between entity pairs commonly referred to as binary interactions in the domain literature, are increasingly recognized by the biomedical NLP community. In this paper, we argue for an alternate model and present the first machine-learning approach to the extraction of structured, complex events and relationships among bioentities. To overcome the limitations of the pairwise approach to biomedical IE, two recent corpora, BioInfer (Pyysalo et al., 2007a) and the GENIA Event corpus (Kim et al., 2008a) annotate events and static relationships using a more expressive formalism that differs from the prevailing approach in several key aspects: First, type, direction and the trigger statement in the text stating the relationship (often a verb) are annotated. Second, events can have more than two participants whose roles are specified, allowing the accurate representation of statements such as proteins A, B and C form a complex. Finally, events can also act as arguments of other events, enabling the annotation of nested events such as A causes B t"
W09-4605,M95-1002,0,0.0448994,"ng approach in several key aspects: First, type, direction and the trigger statement in the text stating the relationship (often a verb) are annotated. Second, events can have more than two participants whose roles are specified, allowing the accurate representation of statements such as proteins A, B and C form a complex. Finally, events can also act as arguments of other events, enabling the annotation of nested events such as A causes B to bind C (Figure 1A). These representations largely resemble event extraction as formulated in (later) Message Understanding Conferences (MUC) (see, e.g., Sundheim (1995)) and in the Automatic Content Extraction (ACE) program (see, e.g., Doddington (2004)). BioInfer also annotates static relations (e.g. substructure) and both BioInfer and GENIA annotate non-biological relationships (e.g. coreferences) with specialized mechanisms. In this paper, we use the term complex relationship to encompass both event and generic relationship annotation. Learning to Extract Biological Event and Relation Graphs causes xcomp&gt; &lt;nsubj &lt;nsubj dobj&gt; &lt;aux Profilin causes actin NN VBZ NN Protein CAUSE Protein &lt;agent to TO bind VBZ BIND &lt;participant cofilin . NN . Protein . } } part"
W09-4605,W08-2121,0,0.070167,"Missing"
W09-4611,C90-3030,0,0.0378865,"pplications, we refer to the review by de Marneffe and Manning (2008). While numerous corpora and parsers exist for English and many other languages, resources for Finnish are scarce. For instance, there is no publicly available syntactically annotated corpus suitable for statistical parser induction. The only publicly available full parser is Connexor Machinese Syntax,1 a closed-source commercial dependency parser for the general language. Other tools include FinTWOL and FinCG,2 a morphological analyzer and a Constraint Grammar parser that resolves morphological ambiguity (Koskenniemi, 1983; Karlsson, 1990). The rule-based parser of Laippala et al. (2009) used in this work was developed for the clinical domain, and builds full constituency analyses on top of the morpholexical analyses provided by FinTWOL and FinCG. 3 ICU Finnish in the Stanford dependency scheme ICU Finnish differs from standard Finnish in many ways (for details, see the discussion by Laippala et al. (2009)). Some of the most distinguishing features present in ICU Finnish, as well as many clinical sublanguages, are frequent misspellings, abbreviations and technical terms, telegraphic sentences, syntactic structures that would no"
W09-4611,de-marneffe-etal-2006-generating,0,0.0732138,"Missing"
W09-4611,H91-1060,0,0.302648,"Missing"
W09-4611,J08-4003,0,0.250411,"h UMLS Specialist lexicon terms to improve its applicability to medical texts and Pyysalo et al. (2006) incorporate into LG a domain-adapted part-of-speech tagger. The different ways to represent natural language syntax can be broadly distinguished into two categories. A constituency analysis divides the sentence into nested phrases, whereas a dependency analysis consists of a set of labelled dependencies between pairs of words. In this work, we focus on dependency parsing because of its benefits in applications and parser evaluation (see for example Lin (1998), Clegg and Shepherd (2007), and Nivre (2008b)), as well as its applicability to languages with a relatively free word order, such Katri Haverinen, Filip Ginter, Veronika Laippala and Tapio Salakoski Y¨ovuoro Potilas levoton, valittaa kipua. Annettu 100mg [l¨aa¨ ke] hieman rauhottui. HENGITS: Hapettuu hyvin repiraattorissa. Putkesta hiukan nest. illalla. Diureesi: riitt¨av¨aa¨ . Hemodyn: annettu 50 mg/h [l¨aa¨ ke], heikohko vaste vaihdettu [l¨aa¨ ke]. OMAISET: vaimo soittanut jutellut l¨aa¨ k¨arin kanssa. Nightshift Patient restless, complains of pain. Given 100mg [drugname] a little calmed down. BREATING: Oxidates well in repirator. A"
W09-4611,W04-1505,0,0.0276513,"nal structures are semantically similar, it would be desirable to represent them in a similar manner also in the dependency structure. Therefore, we introduce a new dependency type, nommod (nominal modifier), to represent inflectional structures. This same type can also be used in sentences with actual pre- and postpositions. Only one additional type is needed for prepositional structures, a type named adpos (adposition). For an illustration of the usage of these two types, see Figure 3. The structure given to prepositional phrases is similar to that used in the scheme of the Pro3Gres parser (Schneider et al., 2004). A third modification to the SD scheme is required by the nature of the ICU language: sentence boundaries are often not clearly marked, or they lack punctuation altogether (see Figure 4). We split the text into separate sentences only when there is explicit punctuation that marks the sentence boundary. Recovering sentence boundaries that have no explicit surface marking is left to the parser, as recognizing them would be difficult for standard sentence splitters that lack syntax information. We have thus introduced a new dependency type, sdep, to connect these isolated sentences that are not"
W10-1819,W04-2412,0,0.0404405,"Missing"
W10-1819,J93-2004,0,0.0386402,"Missing"
W10-1819,W05-0620,0,0.0419225,"Missing"
W10-1819,J05-1004,0,0.633867,"ing trends, and others (see the extensive review by Friedman and Johnson (2006)). While some of these applications, such as document retrieval and trend mining, can rely solely on word-frequency-based methods, others, such as information extraction and summarization require a detailed linguistic analysis capturing some of the sentence semantics. Among the most important steps in this direction is an analysis of verbs and their argument structures. In this work, we focus on the Finnish language in the clinical domain, analyzing its verbs and their argument structures using the PropBank scheme (Palmer et al., 2005). The choice of this 137 Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 137–141, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics kest¨aa¨ .0: “tolerate” Arg0: the one who tolerates Arg1: what is being tolerated kest¨aa¨ .1: “last” Arg1: the thing that lasts Arg2: how long it lasts <xsubj <nsubj xcomp> Potilas saanut ottaa mehua ja leipää . Patient allowed to_have juice and bread . Figure 1: The PropBank framesets for kest¨aa¨ (translated to English from the original frames file) correspond to two different uses of the verb. Pitk¨a y"
W10-1819,W08-1301,0,0.124115,"Missing"
W10-1819,palmer-etal-2008-pilot,0,0.0301017,"Missing"
W10-1819,W08-2121,0,0.0374597,"Missing"
W10-1819,W03-1707,0,0.0656707,"Missing"
W10-1819,W09-4611,1,0.763101,"unct> dobj:Arg1> <advmod juonut.0 vähän drank little mehua . juice . Figure 4: The PropBank annotation scheme on top of the treebank syntactic annotation. The verb juonut (drank) is marked with its frameset, in this case the frameset number 0. This frameset specifies that Arg0 marks the agent doing the drinking and Arg1 the liquid being consumed. The ArgM-tmp label specifies that Aamulla is a temporal modifier. The example can be translated as In the morning patient drank a little juice. Clinical Finnish and the clinical Finnish treebank This study is based on the clinical Finnish treebank of Haverinen et al. (2009), which consists of 2,081 sentences with 15,335 tokens and 13,457 dependencies. The text of the treebank comprises eight complete patient reports from an intensive care unit in a Finnish hospital. An intensive care patient report describes the condition of the patient and its development in time. The clinical Finnish in these reports has many characteristics typical of clinical languages, including frequent misspellings, abbreviations, domain terms, telegraphic style and non-standard syntactic structures (see Figure 2 for an illustration). For a detailed analysis, we refer the reader to the st"
W10-1904,W09-1402,1,0.418613,"Missing"
W10-1904,de-marneffe-etal-2006-generating,0,0.0630604,"Missing"
W10-1904,W09-1313,1,0.821387,"terms to ones involving the associated genes/proteins. The first challenge, gene/protein name normalization, is a wellstudied task in biomedical NLP for which a number of systems with promising performance have been proposed (Morgan and Hirschman, 2007). The second we believe to be novel. In the following, we propose a method for resolving this task. We base the decision on how to map events referencing broadly defined terms to ones referencing associated gene/protein names in part on a recently introduced dataset of “static relations” (Pyysalo et al., 2009) between named entities and terms (Ohta et al., 2009b). This dataset was created based on approximately 10,000 cases where GGP NEs, as annotated in the GENIA GGP corpus (Ohta et al., 2009a), were embedded in terms, as annotated in the GENIA term corpus (Ohta et al., 2002). For each such case, the relation between the NE and the term was annotated using a set of introduced relation types whose granularity was defined with reference to MeSH terms (see Table 2, Ohta et al., 2009b). From this data, we extracted prefix and suffix strings that, when affixed to a GGP name, produced a term with a predictable relation (within the dataset) to the GGP. Th"
W10-1904,W03-1018,1,0.827599,"achieves results close to the best published on the standard GENETAG dataset and was reported to have the best performance in a recent study comparing publicly available taggers (Kabiljo et al., 2009). Titles and abstracts of all 17.8M citations in the 2009 distribution of PubMed are processed through the BANNER system. Titles and abstracts of PubMed citations in which at least one named entity was identified, and 29 which therefore contain a possible target for event extraction, are subsequently split into sentences using a maximum-entropy based sentence splitter trained on the GENIA corpus (Kazama and Tsujii, 2003) with limited rule-based post-processing for some common errors. All sentences containing at least one named entity are then parsed with the domain-adapted McClosky-Charniak parser (McClosky and Charniak, 2008; McClosky, 2009), which has achieved the currently best published performance on the GENIA Treebank (Tateisi et al., 2005). The constituency parse trees are then transformed to the collapsed-ccprocessed variant of the Stanford Dependency scheme using the conversion tool2 introduced by de Marneffe et al. (2006). Finally, events are extracted using the Turku Event Extraction System of Bj¨o"
W10-1904,W09-1301,1,0.800599,"apping from the events involving automatically extracted terms to ones involving the associated genes/proteins. The first challenge, gene/protein name normalization, is a wellstudied task in biomedical NLP for which a number of systems with promising performance have been proposed (Morgan and Hirschman, 2007). The second we believe to be novel. In the following, we propose a method for resolving this task. We base the decision on how to map events referencing broadly defined terms to ones referencing associated gene/protein names in part on a recently introduced dataset of “static relations” (Pyysalo et al., 2009) between named entities and terms (Ohta et al., 2009b). This dataset was created based on approximately 10,000 cases where GGP NEs, as annotated in the GENIA GGP corpus (Ohta et al., 2009a), were embedded in terms, as annotated in the GENIA term corpus (Ohta et al., 2002). For each such case, the relation between the NE and the term was annotated using a set of introduced relation types whose granularity was defined with reference to MeSH terms (see Table 2, Ohta et al., 2009b). From this data, we extracted prefix and suffix strings that, when affixed to a GGP name, produced a term with a pred"
W10-1904,W09-1401,1,0.830255,"Missing"
W10-1904,I05-2038,1,0.208821,"stracts of PubMed citations in which at least one named entity was identified, and 29 which therefore contain a possible target for event extraction, are subsequently split into sentences using a maximum-entropy based sentence splitter trained on the GENIA corpus (Kazama and Tsujii, 2003) with limited rule-based post-processing for some common errors. All sentences containing at least one named entity are then parsed with the domain-adapted McClosky-Charniak parser (McClosky and Charniak, 2008; McClosky, 2009), which has achieved the currently best published performance on the GENIA Treebank (Tateisi et al., 2005). The constituency parse trees are then transformed to the collapsed-ccprocessed variant of the Stanford Dependency scheme using the conversion tool2 introduced by de Marneffe et al. (2006). Finally, events are extracted using the Turku Event Extraction System of Bj¨orne et al. which achieved the best performance in the BioNLP’09 Shared Task and remains fully competitive with even the most recent advances (Miwa et al., 2010). We use a recent publicly available revision of the event extraction system that performs also extraction of Shared Task subtask 2 and 3 information, providing additional"
W10-1904,P08-2026,0,0.00479175,"es and abstracts of all 17.8M citations in the 2009 distribution of PubMed are processed through the BANNER system. Titles and abstracts of PubMed citations in which at least one named entity was identified, and 29 which therefore contain a possible target for event extraction, are subsequently split into sentences using a maximum-entropy based sentence splitter trained on the GENIA corpus (Kazama and Tsujii, 2003) with limited rule-based post-processing for some common errors. All sentences containing at least one named entity are then parsed with the domain-adapted McClosky-Charniak parser (McClosky and Charniak, 2008; McClosky, 2009), which has achieved the currently best published performance on the GENIA Treebank (Tateisi et al., 2005). The constituency parse trees are then transformed to the collapsed-ccprocessed variant of the Stanford Dependency scheme using the conversion tool2 introduced by de Marneffe et al. (2006). Finally, events are extracted using the Turku Event Extraction System of Bj¨orne et al. which achieved the best performance in the BioNLP’09 Shared Task and remains fully competitive with even the most recent advances (Miwa et al., 2010). We use a recent publicly available revision of"
W10-1914,W08-2227,0,0.0300557,"Missing"
W10-1914,P05-1022,0,0.0203275,"t, family memberships relations (MEMBER) were resolved into single edges and suitable references to text were added for the remaining unbound nodes when possible. In an extreme case, an unbound relationship was discarded. As a result, the differences to the BioNLP’09 Shared Task data set were minimised to additional node and edge types reflecting the wider selection of primary arguments. All employed parses follow the SD scheme. BioInfer contains uncollapsed gold-standard parses while the BioNLP’09 Shared Task corpus includes parses, in the collapsed representation, generated by the parser of Charniak and Johnson (2005) using the model of McClosky and Charniak (2008). For both corpora, additional parses were produced with the improved version of the aforementioned system created by McClosky (2009). These parses were transformed into both the collapsed and the conjunct dependency propagated representations with the tools provided by de Marneffe et al. (2006). All parses 3.2 Experiments Original gold-standard graphs were used in generating decision tree models as well as subjected to projection. Predicted graphs and the projected gold-standard graphs were deprojected with the models. The evaluation of the depr"
W10-1914,N10-1123,0,0.0140803,"be studied. Deprojection is likely to greatly benefit methods based on Markov Logic which is “not yet able to deal with cases where the number and identity of entities is unknown, while relations/links between known objects can be readily modelled” (Riedel et al., 2009). The objective is to combine the graph prediction and the deprojection steps as well as to simultaneously enforce task-specific constraints and adapt to the presence of false positive nodes and edges. This should be achievable by extending the methods developed for the BioNLP’09 Shared Task corpus by Riedel et al. (2009) or by Poon and Vanderwende (2010), both of which determine the correct argument combinations outside of the Markov Logic framework. Semantic role labelling (SRL) is a task similar to the graph-based relationship extraction applied in this paper although the former typically only concerns shallow predicate–argument structures (Hacioglu, 2004; Surdeanu et al., 2008). The similarities between the tasks suggest that exploring them jointly may benefit the development of information extraction methods. In the long term, semantic schemes should be developed such that, ideally, all syntactic tokens are considered for their semantics"
W10-1914,W08-1301,0,0.138814,"Missing"
W10-1914,W09-1301,0,0.0168055,"ections In the future, the proposed method will be studied and further improved with two other corpora, GENIA Event Annotation (Kim et al., 2008) and Gene Regulation Event Corpus (Thompson et al., 2009), which are similar in their purpose compared to the already-analysed corpora. The former corpus is interesting because of the co-operativity of event participants which relaxes the restrictions on asymmetric relationships while the latter contains an extensive annotation for non-primary arguments. The method could also be examined with the static relation extraction task recently introduced by Pyysalo et al. (2009). In addition to improving the method and extending it to non-primary arguments, embedding Another limitation is that the approach expects an annotation scheme in which relationship arguments have the tendency of following syntactic dependencies as observed for BioInfer by Bj¨orne et al. (2008). This expectation may deteriorate the performance on highly refined schemes which do not consider syntax. On the other hand, since it relies more on the syntactic than on the biological properties of the relationships, the proposed approach should be applicable beyond the domain 114 tionship arguments."
W10-1914,de-marneffe-etal-2006-generating,0,0.0745987,"Missing"
W10-1914,W09-1406,0,0.112651,"cy analyses by simplifying the correlation between them and semantic graphs. Due to its independent nature, the method can be coupled to any system identifying relationships on the one-per-token basis. The implemented system will be available upon request. the presented approach to a joint inference system, such as Markov Logic Network (MLN), will be studied. Deprojection is likely to greatly benefit methods based on Markov Logic which is “not yet able to deal with cases where the number and identity of entities is unknown, while relations/links between known objects can be readily modelled” (Riedel et al., 2009). The objective is to combine the graph prediction and the deprojection steps as well as to simultaneously enforce task-specific constraints and adapt to the presence of false positive nodes and edges. This should be achievable by extending the methods developed for the BioNLP’09 Shared Task corpus by Riedel et al. (2009) or by Poon and Vanderwende (2010), both of which determine the correct argument combinations outside of the Markov Logic framework. Semantic role labelling (SRL) is a task similar to the graph-based relationship extraction applied in this paper although the former typically o"
W10-1914,C04-1186,0,0.0120874,"nd the deprojection steps as well as to simultaneously enforce task-specific constraints and adapt to the presence of false positive nodes and edges. This should be achievable by extending the methods developed for the BioNLP’09 Shared Task corpus by Riedel et al. (2009) or by Poon and Vanderwende (2010), both of which determine the correct argument combinations outside of the Markov Logic framework. Semantic role labelling (SRL) is a task similar to the graph-based relationship extraction applied in this paper although the former typically only concerns shallow predicate–argument structures (Hacioglu, 2004; Surdeanu et al., 2008). The similarities between the tasks suggest that exploring them jointly may benefit the development of information extraction methods. In the long term, semantic schemes should be developed such that, ideally, all syntactic tokens are considered for their semantics and semantic relationships readily follow from their dependencies. Such schemes, closely following the syntax, could improve both the graph prediction and the deprojection. In this research direction, graphbased knowledge representations such as conceptual graphs (Sowa, 1976; Chein and Mugnier, 2008) or grap"
W10-1914,P88-1003,0,0.0260168,"odes and valid, real relationships. Also, the edges that are mapped to from the outgoing edges of equal nodes of the deprojected graph are the outgoing edges of a single node of the projected graph. The deprojection of a semantic graph is the task of reproducing the original graph given a projected graph. This can also be seen as a task of finding the sets of outgoing edges that represent all the valid, real relationships. 2.2 result, A–C and B–C pairs of regulation are generated. This approach relates to the collectivity and distributivity of plurals which have been studied, among others, by Scha and Stallard (1988) and Brisson (2003). Technically, the grouping is a series of transformations in each of which a set of successors is replaced with a single, newly-created successor and the original successors become the successors of this node. The successors are first trivially grouped by the corresponding edge type. Finally, they are recursively grouped by syntactic similarity until they form a single group or multiple singleton groups. As a result, nested groups are generated. The groups by syntax are determined by first mapping both the predecessor and the successors into the referred tokens in the synta"
W10-1914,W09-1401,0,0.0433413,"ng step of the method of Bj¨orne et al. (2010) and hence extends this extraction method to arbitrarily deep relationships with unrestricted primary argument combinations. The viability of the method is shown by successfully extracting nested relationships in BioInfer and the corpus of the BioNLP’09 Shared Task on Event Extraction. The reported results, to the best of our knowledge, are the first for the nested relationships in BioInfer on a task in which only named entities are given. 1 Introduction A recent shared task in biomedical text mining, the BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009), showed that the biomedical natural language processing (BioNLP) community is greatly interested in heading towards the extraction of deep, semantically rich relationships. The shared task focused on biomolecular events involving proteins and called for methods that are capable of identifying nested structures. Biomolecular events are a major category of relationships in the biomedical domain in 108 Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 108–116, c Uppsala, Sweden, 15 July 2010. 2010 Association for Computational Linguistics <Cause A Phosph"
W10-1914,P08-2026,0,0.0323492,"esolved into single edges and suitable references to text were added for the remaining unbound nodes when possible. In an extreme case, an unbound relationship was discarded. As a result, the differences to the BioNLP’09 Shared Task data set were minimised to additional node and edge types reflecting the wider selection of primary arguments. All employed parses follow the SD scheme. BioInfer contains uncollapsed gold-standard parses while the BioNLP’09 Shared Task corpus includes parses, in the collapsed representation, generated by the parser of Charniak and Johnson (2005) using the model of McClosky and Charniak (2008). For both corpora, additional parses were produced with the improved version of the aforementioned system created by McClosky (2009). These parses were transformed into both the collapsed and the conjunct dependency propagated representations with the tools provided by de Marneffe et al. (2006). All parses 3.2 Experiments Original gold-standard graphs were used in generating decision tree models as well as subjected to projection. Predicted graphs and the projected gold-standard graphs were deprojected with the models. The evaluation of the deprojected graphs was performed against the origina"
W10-1914,W08-2121,0,\N,Missing
W11-0204,W09-1402,1,0.87622,"Missing"
W11-0204,W10-1904,1,0.917946,"Missing"
W11-0204,W09-1401,0,0.274957,") and publicly available gene database records (Section 2.2). 2.1 Text mining predictions Bj¨orne et al. (2010) have applied to all PubMed abstracts an event extraction pipeline comprising of the BANNER named entity recognizer (Leaman and Gonzalez, 2008) and the Turku Event Extraction System (Bj¨orne et al., 2009). The resulting dataset contains 36.5M occurrences of gene / gene product (GGP) entities and 19.2M occurrences of events pertaining to these entities. The file format and information scheme of the resource correspond to the definition of the BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009). Events are defined as typed relations between arguments that are either entity occurrences or, recursively, other events. There are nine possible event types: Localization, Binding, Gene expression, Transcription, Protein catabolism, Phosphorylation, Regulation, Positive regulation, and Negative regulation. Further, arguments are assigned a role: Theme or Cause for the core arguments and AtLoc, ToLoc, Site, and CSite for auxiliary arguments that define additional information such as cellular location of the event. In addition, each event occurrence may be marked as negative and/or speculativ"
W11-0204,C10-1096,0,0.0422396,"Missing"
W11-0204,P06-4005,0,\N,Missing
W11-1828,W09-1402,1,0.915298,"Missing"
W11-1828,W10-1904,1,0.8914,"Missing"
W11-1828,W09-1403,0,0.0367908,"Missing"
W11-1828,P05-1022,0,0.187432,"d search against the final metric, in the new system only the recall-adjustment param2 http://svmlight.joachims.org/svm_ multiclass.html 185 eter (see Section 2.5) is optimized against the final metric, edge and trigger detector parameters being optimized in isolation to speed up experiments. 2.3 Syntactic Analyses The machine learning features that are used in event detection are mostly derived from the syntactic parses of the sentences. Parsing links together related words that may be distant in their linear order, creating a parse tree (see Figure 1 B). We used the Charniak-Johnson parser (Charniak and Johnson, 2005) with David McClosky’s biomodel (McClosky, 2010) trained on the GENIA corpus and unlabeled PubMed articles. The parse trees produced by the Charniak-Johnson parser were further processed with the Stanford conversion tool (de Marneffe et al., 2006), creating a dependency parse (de Marneffe and Manning, 2008). In the supporting tasks (REL, REN and CO) this parsing was done by us, but in the main tasks the organizers provided official parses which were used. All parses for tasks where named entities were given as gold data were further processed with a protein name splitter that divides at punctu"
W11-1828,de-marneffe-etal-2006-generating,0,0.0389924,"Missing"
W11-1828,W10-1914,1,0.832577,"Missing"
W11-1828,W09-1418,0,0.0770402,"Missing"
W11-1828,W09-1401,0,0.694346,"Missing"
W11-1828,W08-1301,0,0.00767918,"Missing"
W11-1828,N10-1004,0,0.0105609,"e recall-adjustment param2 http://svmlight.joachims.org/svm_ multiclass.html 185 eter (see Section 2.5) is optimized against the final metric, edge and trigger detector parameters being optimized in isolation to speed up experiments. 2.3 Syntactic Analyses The machine learning features that are used in event detection are mostly derived from the syntactic parses of the sentences. Parsing links together related words that may be distant in their linear order, creating a parse tree (see Figure 1 B). We used the Charniak-Johnson parser (Charniak and Johnson, 2005) with David McClosky’s biomodel (McClosky, 2010) trained on the GENIA corpus and unlabeled PubMed articles. The parse trees produced by the Charniak-Johnson parser were further processed with the Stanford conversion tool (de Marneffe et al., 2006), creating a dependency parse (de Marneffe and Manning, 2008). In the supporting tasks (REL, REN and CO) this parsing was done by us, but in the main tasks the organizers provided official parses which were used. All parses for tasks where named entities were given as gold data were further processed with a protein name splitter that divides at punctuation tokens which contain named entities, such"
W11-1828,W10-1905,0,0.0487145,"er type for each token. When edges are predicted between these nodes, the result is a merged graph where overlapping events are merged into a single node and its set of outgoing edges. Taking into account the limits of trigger prediction, the edge detector is also trained on a merged graph version of the gold data. To produce the final events, these merged nodes need to be “pulled apart” into valid trigger and argument combinations. In the BioNLP’09 Shared Task, this was done with a rule-based system. Since then, further research has been done on machine learning approaches for this question (Miwa et al., 2010b; Heimonen et al., 2010). In our current system, unmerging is done as an SVM-classification step. An example is constructed for each argument edge combination of each predicted node, and classified as a true event or a false event to be removed. Tested on the BioNLP’09 Shared Task data, this system performs roughly on par with our earlier rule-based system, but has the advantage of being more general and thus applicable to all BioNLP’11 Shared Task 100 Corpus GE’09 task 1 GE’09 task 2 GE task 1 GE task 2 GE task 3 EPI ID BB BI CO REL REN 80 F-score 60 40 20 0 GE1 GE2 GE3 EPI ID Task BB BI CO"
W11-1828,W09-1406,0,0.151524,"Missing"
W11-1828,W09-1419,0,0.0134085,"Missing"
W11-1828,W11-1801,0,\N,Missing
W12-2410,W11-1828,1,0.799541,"Missing"
W12-2410,W09-1402,1,0.89609,"Missing"
W12-2410,W10-1904,1,0.854996,"Missing"
W12-2410,P05-1022,0,0.0136407,"et VBZ is agent> VBN mediated IN by . . NN CKI EPI detection TEES 2.3 <Theme <Site Entity Serine Theme> Cause> Phosphorylation phosphorylation Protein of T-bet Protein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and foll"
W12-2410,W03-1018,0,0.0217666,"ed by CKI . McCJ-parser + Stanford Conversion <nsubjpass <nn NN Serine prep_of> NN phosphorylation D IN of REL detection <auxpass NN T-bet VBZ is agent> VBN mediated IN by . . NN CKI EPI detection TEES 2.3 <Theme <Site Entity Serine Theme> Cause> Phosphorylation phosphorylation Protein of T-bet Protein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Ea"
W12-2410,W09-1401,1,0.800261,"by existing PubMed-scale event extraction efforts. The methods and data introduced in this study are freely available from bionlp.utu.fi. 1 Introduction Biomedical domain information extraction has in recent years seen a shift from focus on the extraction of simple pairwise relations (Pyysalo et al., 2008; Tikk et al., 2010) towards the extraction of events, represented as structured associations of arbitrary numbers of participants in specific roles (Ananiadou et al., 2010). Domain event extraction has been popularized in particular by the BioNLP Shared Task (ST) challenges in 2009 and 2011 (Kim et al., 2009; Kim et al., 2011). While the BioNLP ST’09 emphasized protein interactions and regulatory relationships, the expressive event formalism can also be applied to the extraction of statements regarding the properties of individual proteins. Accordingly, the EPI (Epigenetics and Post-Translational Modifications) subchallenge of the BioNLP ST’11 provided corpora and competitive evaluations for the detection of epigenetics and post-translational modification (PTM) events, while the REL (Entity Relations) subchallenge covers structural and complex membership relations of proteins (Ohta et al., 2011b;"
W12-2410,W11-1801,1,0.780089,"ein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion to the BioNLP ST format are imported into a database (E). (Adapted from Bj¨orne and Salakoski (2011)). The extraction of events"
W12-2410,de-marneffe-etal-2006-generating,0,0.0781296,"Missing"
W12-2410,N10-1004,0,0.0126786,"d IN by . . NN CKI EPI detection TEES 2.3 <Theme <Site Entity Serine Theme> Cause> Phosphorylation phosphorylation Protein of T-bet Protein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion"
W12-2410,W10-1903,1,0.868585,"Missing"
W12-2410,W11-1803,1,0.805324,"ein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion to the BioNLP ST format are imported into a database (E). (Adapted from Bj¨orne and Salakoski (2011)). The extraction of events"
W12-2410,W09-1301,1,0.907084,"Missing"
W12-2410,W11-1812,1,0.693859,"ein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion to the BioNLP ST format are imported into a database (E). (Adapted from Bj¨orne and Salakoski (2011)). The extraction of events"
W12-2410,W11-1816,1,0.886081,"Missing"
W12-2410,W10-1921,1,0.898429,"Missing"
W13-2003,W09-1401,0,0.481091,", directed arguments, annotated trigger words and the ability to nest other events as arguments, leading to flexible, complex structures. Compared to the more straightforward approach of binary relation extraction, the aim of event extraction is to utilize the added complexity to more accurately depict the content of natural language statements and to produce more detailed text mining results. The BioNLP Shared Task is the primary forum for international evaluation of different event extraction technologies. Organized for the first time in 2009, it has since been held in 2011 and now in 2013 (Kim et al., 2009; Kim et al., 2011). Starting from the single GENIA corpus on NF-kB, it has since been extended to varied domain tasks, such 1 http://jbjorne.github.com/TEES/ 16 Proceedings of the BioNLP Shared Task 2013 Workshop, pages 16–25, c Sofia, Bulgaria, August 9 2013. 2013 Association for Computational Linguistics A mated learning of event annotation rules. As an open source project TEES should also be easily applicable by any team interested in this task, so TEES 2.1 analyses were provided for all interested participants during the system development phase of the competition. 2 Protein Protein Ser(7"
W13-2003,S13-2108,1,0.881515,"Missing"
W13-2003,W11-1801,0,0.192883,"ts, annotated trigger words and the ability to nest other events as arguments, leading to flexible, complex structures. Compared to the more straightforward approach of binary relation extraction, the aim of event extraction is to utilize the added complexity to more accurately depict the content of natural language statements and to produce more detailed text mining results. The BioNLP Shared Task is the primary forum for international evaluation of different event extraction technologies. Organized for the first time in 2009, it has since been held in 2011 and now in 2013 (Kim et al., 2009; Kim et al., 2011). Starting from the single GENIA corpus on NF-kB, it has since been extended to varied domain tasks, such 1 http://jbjorne.github.com/TEES/ 16 Proceedings of the BioNLP Shared Task 2013 Workshop, pages 16–25, c Sofia, Bulgaria, August 9 2013. 2013 Association for Computational Linguistics A mated learning of event annotation rules. As an open source project TEES should also be easily applicable by any team interested in this task, so TEES 2.1 analyses were provided for all interested participants during the system development phase of the competition. 2 Protein Protein Ser(727) STAT3 B may &lt;nn"
W13-2003,W13-2023,0,0.0815749,"Missing"
W13-2003,W13-2007,0,0.0427128,"tion 2013 Shared Task, where the data was used more, maybe due to easier integration into a binary relation extraction task (Segura-Bedmar et al., 2013; Bj¨orne et al., 2013). 3 F-score / SER * 100 80 0 R 46.17 48.76 47.15 15.22 33 P 56.32 64.17 55.78 36.58 78 F 50.74 55.41 51.10 21.50 46 28 12 82 18 42 14 CG PC GRO Task GRN BBT2 BBT3 BBT1 viewed as the primary task for testing different event extraction approaches. In 2013 the GENIA task annotation has been considerably extended and the coreference annotation that in 2011 formed its own supporting task is integrated in the main GENIA corpus (Kim et al., 2013a). The GENIA task is a good example for demonstrating the usefulness of automatically learning the event annotation scheme. The task uses 11 different event types, pairwise binary coreference relations and modality annotation for both speculation and negation. Previous versions of TEES would have encoded all of this information in the program, but with TEES 2.1 the annotation rules are detected automatically and stored in a separate datafile external to the program. Table 1 shows the automatically learned event scheme. It should however be noted that while the learned scheme accurately descri"
W13-2003,W13-2024,0,0.013701,"Missing"
W13-2003,N10-1004,0,0.0263711,"convert the shared task format (txt/a1/a2) corpora into the interaction XML format. Equivalence annotations are resolved into independent events in the process. Figure 1 shows an overview of the TEES event extraction process. In real-world applications, external programs are used to split sentences, detect protein/gene named entities and parse text, but in the BioNLP Shared Tasks these analyses are provided by the organizers. As in previous Shared Tasks, we used the tokenisations and the McCCJ parses converted into the collapsed CCprocessed Stanford dependency scheme (Stenetorp et al., 2013; McClosky, 2010). With the preprocessing done, TEES uses three primary processing steps to detect events. First, event trigger words are detected by classifying each non-named entity token into one of the trigger classes or as a negative. Then, for each (optionally directed) pair of named entity and trigger nodes a relation/argument edge candidate Rac-1 trigger detection D Turku Event Extraction System 2.1 Protein and dobj&gt; &lt;aux appos&gt; Methods involve parsing &lt;Parent 2.1 phosphorylation &lt;Site &lt;Theme Protein Entity Phosphorylation STAT3 Ser(727) phosphorylation E Cause&gt; Regulation Protein involve Vav may Prote"
W13-2003,W13-2004,1,0.434704,"Missing"
W13-2003,W10-1905,0,0.0430327,"Missing"
W13-2003,W13-2009,0,0.0160174,"Missing"
W13-2003,W13-2008,0,0.0203636,"Missing"
W13-2003,W11-1808,0,0.0697046,"Missing"
W13-2003,W13-2013,0,0.0145931,"ersion tools are used to convert the shared task format (txt/a1/a2) corpora into the interaction XML format. Equivalence annotations are resolved into independent events in the process. Figure 1 shows an overview of the TEES event extraction process. In real-world applications, external programs are used to split sentences, detect protein/gene named entities and parse text, but in the BioNLP Shared Tasks these analyses are provided by the organizers. As in previous Shared Tasks, we used the tokenisations and the McCCJ parses converted into the collapsed CCprocessed Stanford dependency scheme (Stenetorp et al., 2013; McClosky, 2010). With the preprocessing done, TEES uses three primary processing steps to detect events. First, event trigger words are detected by classifying each non-named entity token into one of the trigger classes or as a negative. Then, for each (optionally directed) pair of named entity and trigger nodes a relation/argument edge candidate Rac-1 trigger detection D Turku Event Extraction System 2.1 Protein and dobj&gt; &lt;aux appos&gt; Methods involve parsing &lt;Parent 2.1 phosphorylation &lt;Site &lt;Theme Protein Entity Phosphorylation STAT3 Ser(727) phosphorylation E Cause&gt; Regulation Protein invo"
W13-2003,W13-2002,0,\N,Missing
W13-2003,W13-2012,0,\N,Missing
W13-2003,U13-1019,0,\N,Missing
W13-2004,W11-0204,1,0.634815,"Missing"
W13-2004,W13-2003,1,\N,Missing
W13-2004,W11-1828,1,\N,Missing
W13-2004,W11-1805,0,\N,Missing
W13-3728,P92-1003,0,0.306285,"o that achieved by the commonly used Stanford tools. 2 Related work The general problem of coordination scope ambiguity is a widely studied, difficult problem. It is frequently tackled by utilizing lexical parallelism and selectional preferences, as for instance in the works of Kawahara and Kurohashi (2011) and Resnik (1999). In the domain of requirements engineering, Chantree et al. (2005) disambiguate coordinations using heuristics based on the distributions of the words appearing in them. Goldberg (1999) has presented an unsupervised model for a limited range of coordination phenomena, and Agarwal and Boggess (1992) introduce a simplified algorithm for recognizing the correct conjuncts for coordinations. Kawahara and Kurohashi (2007) and van Noord (2007) have incorporated disambiguation methods into parsers of Japanese and Dutch, respectively. In dependency representations, there are multiple ways to treat coordination structures, and the chosen treatment also affects coordination scope ambiguities. The Stanford Dependencies scheme (de Marneffe and Manning, 2008) used in this work considers the first coordinated element the head of the coordination, and uses an additional layer of dependencies to represe"
W13-3728,C10-1011,0,0.0301952,"Missing"
W13-3728,P04-1082,0,0.0289912,"ask is comparatively simple. Separately for the governor and dependent, we generate their token features (the same features as in conjunct propagation) and the set of types of dependencies they govern. As with conjunct propagation, explicit feature pair generation as well as normalization of feature vectors to unit length are employed. 4.3 External subject assignment Unlike in the two previous tasks, we find that assignment of external subjects is best approached by a simple rule-based method, since only clausal complements governed by an xcomp dependency have an external subject. As noted by Campbell (2004), in some highly restricted linguistic problems rule-based approaches are sufficient. The rule assigning external subjects only needs to account for whether the external subject dependency type is the regular subject type xsubj or the copular subject type xsubj-cop. Further, chains of clausal complements with external subjects must be correctly addressed, so that each open clausal complement correctly receives an external subject. 4.4 Combining predictions As mentioned earlier in Section 3.2, the three tasks are not independent of each other: First, if the predicted syntactic function of the r"
W13-3728,P99-1081,0,0.0603513,"erior to each of these baselines. In particular, the method demonstrates performance clearly superior to that achieved by the commonly used Stanford tools. 2 Related work The general problem of coordination scope ambiguity is a widely studied, difficult problem. It is frequently tackled by utilizing lexical parallelism and selectional preferences, as for instance in the works of Kawahara and Kurohashi (2011) and Resnik (1999). In the domain of requirements engineering, Chantree et al. (2005) disambiguate coordinations using heuristics based on the distributions of the words appearing in them. Goldberg (1999) has presented an unsupervised model for a limited range of coordination phenomena, and Agarwal and Boggess (1992) introduce a simplified algorithm for recognizing the correct conjuncts for coordinations. Kawahara and Kurohashi (2007) and van Noord (2007) have incorporated disambiguation methods into parsers of Japanese and Dutch, respectively. In dependency representations, there are multiple ways to treat coordination structures, and the chosen treatment also affects coordination scope ambiguities. The Stanford Dependencies scheme (de Marneffe and Manning, 2008) used in this work considers t"
W13-3728,W09-1201,0,0.102402,"Missing"
W13-3728,P07-2053,0,0.123146,"Missing"
W13-3728,W10-1819,1,0.845146,", which is defined in multiple variants. The basic variant requires sentence structures to be trees, and the other variants can then be used to add further dependencies on top of the tree structure, making the resulting structures graphs rather than trees. Phenomena that are further analyzed in the non-basic variants of SD include relative clauses, open clausal complements, coordinations and prepositional phrases. 252 The dependencies present in non-basic variants of SD can be useful for applications that build on top of the syntactic analysis. For instance, the clinical domain pilot study of Haverinen et al. (2010) has shown that these dependencies can be used in annotating argument structures of verbs using the popular PropBank scheme (Palmer et al., 2005). Also, Yuret et al. (2012) have used the propagated and collapsed variant of the SD scheme to retrieve as semantically meaningful dependencies as possible in the context of textual entailments. The nonbasic variants of SD are also extensively applied in information extraction, as seen for example in the BioNLP shared tasks on event extraction, where a number of top-ranking systems relied on SD analyses (Kim et al., 2011). In this work, we are concern"
W13-3728,D07-1032,0,0.0211954,"ty is a widely studied, difficult problem. It is frequently tackled by utilizing lexical parallelism and selectional preferences, as for instance in the works of Kawahara and Kurohashi (2011) and Resnik (1999). In the domain of requirements engineering, Chantree et al. (2005) disambiguate coordinations using heuristics based on the distributions of the words appearing in them. Goldberg (1999) has presented an unsupervised model for a limited range of coordination phenomena, and Agarwal and Boggess (1992) introduce a simplified algorithm for recognizing the correct conjuncts for coordinations. Kawahara and Kurohashi (2007) and van Noord (2007) have incorporated disambiguation methods into parsers of Japanese and Dutch, respectively. In dependency representations, there are multiple ways to treat coordination structures, and the chosen treatment also affects coordination scope ambiguities. The Stanford Dependencies scheme (de Marneffe and Manning, 2008) used in this work considers the first coordinated element the head of the coordination, and uses an additional layer of dependencies to represent the propagation of conjunct dependencies (see Figures 1 and 2). As a point of comparison, for instance the Link Gramm"
W13-3728,I11-1051,0,0.0133445,"3), pages 252–261, c 2013 Charles University in Prague, Matfyzpress, Prague, Czech Republic Prague, August 27–30, 2013. several baseline methods, and conclude that the proposed method achieves a performance clearly superior to each of these baselines. In particular, the method demonstrates performance clearly superior to that achieved by the commonly used Stanford tools. 2 Related work The general problem of coordination scope ambiguity is a widely studied, difficult problem. It is frequently tackled by utilizing lexical parallelism and selectional preferences, as for instance in the works of Kawahara and Kurohashi (2011) and Resnik (1999). In the domain of requirements engineering, Chantree et al. (2005) disambiguate coordinations using heuristics based on the distributions of the words appearing in them. Goldberg (1999) has presented an unsupervised model for a limited range of coordination phenomena, and Agarwal and Boggess (1992) introduce a simplified algorithm for recognizing the correct conjuncts for coordinations. Kawahara and Kurohashi (2007) and van Noord (2007) have incorporated disambiguation methods into parsers of Japanese and Dutch, respectively. In dependency representations, there are multiple"
W13-3728,W11-1801,0,0.0546911,"Missing"
W13-3728,W03-2401,0,0.0365747,"represent the propagation of conjunct dependencies (see Figures 1 and 2). As a point of comparison, for instance the Link Grammar scheme (Sleator and Temperley, 1993) makes the coordinating conjunction the head word of the coordination, thus partially resolving the scope ambiguities using tree structures only as will be shown in greater detail in Section 5.2. The Stanford tools1 are able to produce output with the additional dependencies of the SD scheme present, but according to de Marneffe and Manning (2008), this part of the tools performs imperfectly. While the English resource PARC 700 (King et al., 2003), annotated in the LFG-formalism (Bresnan, 2001), contains dependencies similar to those considered in this work, 1 http://nlp.stanford.edu/software/ lex-parser.shtml 253 punct&gt; &lt;nsubj Hän He conj&gt; cc&gt; nommod&gt; nommod&gt; soitti minulle ja kertoi tilanteesta . called me and told about_situation . Figure 1: The basic variant of the Stanford Dependencies scheme on a Finnish sentence. The example can be translated as He called me and told me about the situation. to our knowledge the Turku Dependency Treebank (Haverinen et al., 2011) is the only existing manually annotated resource that contains conju"
W13-3728,E06-1011,0,0.0322825,"kertoi tilanteesta . called me and told about_situation . Figure 1: The basic variant of the Stanford Dependencies scheme on a Finnish sentence. The example can be translated as He called me and told me about the situation. to our knowledge the Turku Dependency Treebank (Haverinen et al., 2011) is the only existing manually annotated resource that contains conjunct propagation as described in the SD scheme. In addition to the post-processing approach implemented in the Stanford tools, also methods to directly parse dependency graphs involving tokens with multiple governors have been studied. McDonald and Pereira (2006) introduce a modification of the Maximum Spanning Tree algorithm to infer secondary dependencies in the Danish Dependency Treebank, and Sagae and Tsujii (2008) present a modification of the Shift-Reduce algorithm, which can parse directed acyclic graphs. 3 3.1 Data Turku Dependency Treebank As both the training and testing data of this study, we use the Turku Dependency Treebank (TDT) (Haverinen et al., 2011), which is a publicly available treebank for Finnish. TDT contains 15,126 sentences (204,399 tokens) from ten different genres or text sources, including for instance Wikipedia, EU-text an"
W13-3728,J05-1004,0,0.0293667,"further dependencies on top of the tree structure, making the resulting structures graphs rather than trees. Phenomena that are further analyzed in the non-basic variants of SD include relative clauses, open clausal complements, coordinations and prepositional phrases. 252 The dependencies present in non-basic variants of SD can be useful for applications that build on top of the syntactic analysis. For instance, the clinical domain pilot study of Haverinen et al. (2010) has shown that these dependencies can be used in annotating argument structures of verbs using the popular PropBank scheme (Palmer et al., 2005). Also, Yuret et al. (2012) have used the propagated and collapsed variant of the SD scheme to retrieve as semantically meaningful dependencies as possible in the context of textual entailments. The nonbasic variants of SD are also extensively applied in information extraction, as seen for example in the BioNLP shared tasks on event extraction, where a number of top-ranking systems relied on SD analyses (Kim et al., 2011). In this work, we are concerned with three phenomena represented in the non-basic variants of SD. Most importantly, we consider the dependencies that are the result of conjun"
W13-3728,C08-1095,0,0.0212903,"e translated as He called me and told me about the situation. to our knowledge the Turku Dependency Treebank (Haverinen et al., 2011) is the only existing manually annotated resource that contains conjunct propagation as described in the SD scheme. In addition to the post-processing approach implemented in the Stanford tools, also methods to directly parse dependency graphs involving tokens with multiple governors have been studied. McDonald and Pereira (2006) introduce a modification of the Maximum Spanning Tree algorithm to infer secondary dependencies in the Danish Dependency Treebank, and Sagae and Tsujii (2008) present a modification of the Shift-Reduce algorithm, which can parse directed acyclic graphs. 3 3.1 Data Turku Dependency Treebank As both the training and testing data of this study, we use the Turku Dependency Treebank (TDT) (Haverinen et al., 2011), which is a publicly available treebank for Finnish. TDT contains 15,126 sentences (204,399 tokens) from ten different genres or text sources, including for instance Wikipedia, EU-text and amateur fiction. TDT has been annotated using the SD scheme, which was originally developed to be used with the English language. Thus it has been slightly m"
W13-3728,C12-1147,0,0.0529933,"tructure, making the resulting structures graphs rather than trees. Phenomena that are further analyzed in the non-basic variants of SD include relative clauses, open clausal complements, coordinations and prepositional phrases. 252 The dependencies present in non-basic variants of SD can be useful for applications that build on top of the syntactic analysis. For instance, the clinical domain pilot study of Haverinen et al. (2010) has shown that these dependencies can be used in annotating argument structures of verbs using the popular PropBank scheme (Palmer et al., 2005). Also, Yuret et al. (2012) have used the propagated and collapsed variant of the SD scheme to retrieve as semantically meaningful dependencies as possible in the context of textual entailments. The nonbasic variants of SD are also extensively applied in information extraction, as seen for example in the BioNLP shared tasks on event extraction, where a number of top-ranking systems relied on SD analyses (Kim et al., 2011). In this work, we are concerned with three phenomena represented in the non-basic variants of SD. Most importantly, we consider the dependencies that are the result of conjunct propagation. They resolv"
W13-3728,1993.iwpt-1.22,0,0.402265,"ord (2007) have incorporated disambiguation methods into parsers of Japanese and Dutch, respectively. In dependency representations, there are multiple ways to treat coordination structures, and the chosen treatment also affects coordination scope ambiguities. The Stanford Dependencies scheme (de Marneffe and Manning, 2008) used in this work considers the first coordinated element the head of the coordination, and uses an additional layer of dependencies to represent the propagation of conjunct dependencies (see Figures 1 and 2). As a point of comparison, for instance the Link Grammar scheme (Sleator and Temperley, 1993) makes the coordinating conjunction the head word of the coordination, thus partially resolving the scope ambiguities using tree structures only as will be shown in greater detail in Section 5.2. The Stanford tools1 are able to produce output with the additional dependencies of the SD scheme present, but according to de Marneffe and Manning (2008), this part of the tools performs imperfectly. While the English resource PARC 700 (King et al., 2003), annotated in the LFG-formalism (Bresnan, 2001), contains dependencies similar to those considered in this work, 1 http://nlp.stanford.edu/software/"
W13-3728,W07-2201,0,0.0796595,"Missing"
W13-5609,W10-1811,0,0.0262924,"Missing"
W13-5609,P98-1046,0,0.236343,"RL) is one of the fundamental tasks of natural language processing. In a sense, it continues from where syntactic parsing ends: it identifies the events and participants, such as agents and patients, present in a sentence, and therefore it is an essential step in automatically processing the sentence semantics. SRL can be applied in, for example, text generation, text understanding, machine translation and fact retrieval (Palmer et al., 2005). There have been several different efforts to capture and annotate semantic roles, the best-known projects being FrameNet (Baker et al., 1998), VerbNet (Dang et al., 1998) and PropBank (Palmer et al., 2005), all built for the English language. Out of the three resources, FrameNet is the most fine-grained one, defining roles for specific classes of verbs, such as Cook and Food for verbs relating to cooking. PropBank, in contrast, uses very generic labels, and is the only one of the three intended for corpus annotation rather than as a lexical resource. VerbNet, in turn, is between FrameNet and PropBank in granularity, and somewhat like PropBank, has close ties to syntactic structure. For a more thorough comparison of the three schemes, see the overview by Palmer"
W13-5609,W11-4519,0,0.488288,"n rather than as a lexical resource. VerbNet, in turn, is between FrameNet and PropBank in granularity, and somewhat like PropBank, has close ties to syntactic structure. For a more thorough comparison of the three schemes, see the overview by Palmer et al. (2010). The PropBank scheme in particular has become popular for semantic role labeling resources: after the initial effort on English, PropBanks for different languages have emerged, including, among others, PropBanks for Chinese (Xue and Palmer, 2009), Arabic (Zaghouani et al., 2010), Hindi (Palmer et al., 2009) and Brazilian Portuguese (Duran and Aluísio, 2011). As a PropBank is intended for corpus annotation purposes, and as the annotation scheme is closely tied to syntax, PropBanks are annotated on top of existing treebanks. For Finnish, a freely available general language treebank has recently become available (Haverinen et al., 2010b, 2011), but no corpus annotated for semantic roles exists in the general domain. Haverinen et al. (2010a) have previously made available a small-scale PropBank of clinical Finnish, and thus shown that in principle, the PropBank scheme is suitable for Finnish and combinable with the Stanford Dependency (SD) scheme (d"
W13-5609,W10-1819,1,0.927136,"me in particular has become popular for semantic role labeling resources: after the initial effort on English, PropBanks for different languages have emerged, including, among others, PropBanks for Chinese (Xue and Palmer, 2009), Arabic (Zaghouani et al., 2010), Hindi (Palmer et al., 2009) and Brazilian Portuguese (Duran and Aluísio, 2011). As a PropBank is intended for corpus annotation purposes, and as the annotation scheme is closely tied to syntax, PropBanks are annotated on top of existing treebanks. For Finnish, a freely available general language treebank has recently become available (Haverinen et al., 2010b, 2011), but no corpus annotated for semantic roles exists in the general domain. Haverinen et al. (2010a) have previously made available a small-scale PropBank of clinical Finnish, and thus shown that in principle, the PropBank scheme is suitable for Finnish and combinable with the Stanford Dependency (SD) scheme (de Marneffe and Manning, 2008a,b), the annotation scheme of both the clinical treebank and the general language treebank of Haverinen et al. In this work, we present the first results of a project that aims to create a general language PropBank for Finnish, built on top of the exis"
W13-5609,J93-2004,0,0.0415251,"dencies with an associated PropBank argument are marked in bold. Note how one of the arguments (Arg0) of the latter verb in the sentence is associated with a second-layer dependency. The example sentence can be translated as The judges disqualified the competitor due to deceit and ordered a punishment. 4 Dependency-based PropBanking The PropBank annotation of this work is built on top of the dependency syntax annotation of TDT, including both the first and second annotation layer. This is in contrast to the English PropBank, which has been built on top of the constituency-based Penn Treebank (Marcus et al., 1993). In the Finnish PropBank, each argument of a verb is associated with a dependency (be it first or second layer) in the underlying treebank, which means that the subtree of the dependent word, as defined by the dependencies of the first annotation layer, acts as the argument. For an illustration of the dependency-based PropBank annotation, see Figure 5. In contrast to the original PropBank (Palmer et al., 2005) where in theory any constituent could be an argument, we make use of a heuristic: in most cases, the arguments of a verb will be its direct dependents. However, unlike the clinical lang"
W13-5609,W08-1301,0,0.339099,"Missing"
W13-5609,W04-2705,0,0.285219,"Missing"
W13-5609,J05-1004,0,0.915622,"19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 41 of 474] 1 Introduction Semantic role labeling (SRL) is one of the fundamental tasks of natural language processing. In a sense, it continues from where syntactic parsing ends: it identifies the events and participants, such as agents and patients, present in a sentence, and therefore it is an essential step in automatically processing the sentence semantics. SRL can be applied in, for example, text generation, text understanding, machine translation and fact retrieval (Palmer et al., 2005). There have been several different efforts to capture and annotate semantic roles, the best-known projects being FrameNet (Baker et al., 1998), VerbNet (Dang et al., 1998) and PropBank (Palmer et al., 2005), all built for the English language. Out of the three resources, FrameNet is the most fine-grained one, defining roles for specific classes of verbs, such as Cook and Food for verbs relating to cooking. PropBank, in contrast, uses very generic labels, and is the only one of the three intended for corpus annotation rather than as a lexical resource. VerbNet, in turn, is between FrameNet and"
W13-5609,W12-1506,0,0.0553242,"Missing"
W13-5609,W10-1836,0,0.0218227,"generic labels, and is the only one of the three intended for corpus annotation rather than as a lexical resource. VerbNet, in turn, is between FrameNet and PropBank in granularity, and somewhat like PropBank, has close ties to syntactic structure. For a more thorough comparison of the three schemes, see the overview by Palmer et al. (2010). The PropBank scheme in particular has become popular for semantic role labeling resources: after the initial effort on English, PropBanks for different languages have emerged, including, among others, PropBanks for Chinese (Xue and Palmer, 2009), Arabic (Zaghouani et al., 2010), Hindi (Palmer et al., 2009) and Brazilian Portuguese (Duran and Aluísio, 2011). As a PropBank is intended for corpus annotation purposes, and as the annotation scheme is closely tied to syntax, PropBanks are annotated on top of existing treebanks. For Finnish, a freely available general language treebank has recently become available (Haverinen et al., 2010b, 2011), but no corpus annotated for semantic roles exists in the general domain. Haverinen et al. (2010a) have previously made available a small-scale PropBank of clinical Finnish, and thus shown that in principle, the PropBank scheme is"
W13-5609,C98-1046,0,\N,Missing
W13-5609,P98-1013,0,\N,Missing
W13-5609,C98-1013,0,\N,Missing
W13-5609,duran-aluisio-2012-propbank,0,\N,Missing
W13-5626,C10-1011,0,0.0894175,"Missing"
W13-5626,W08-1301,0,0.14397,"Missing"
W13-5626,2005.mtsummit-papers.11,0,0.0102569,"c Conference Proceedings #85 [page 291 of 474] 1 Introduction In this paper, we describe the methods and resources used to build the FinnTreeBank-3 (FTB-3) parsebank, a 76.4 million token corpus of Finnish with automatically produced morphological and dependency syntax analyses. The corpus is a resource developed within the FIN-CLARIN consortium, the Finnish member of the CLARIN infrastructure project1 and aims at supporting research and language technology development requiring large-scale parsed corpora. Further, as the underlying texts consist of the multilingual parallel corpora EuroParl (Koehn, 2005) and JRCAcquis (Steinberger et al., 2006), corresponding parsebanks can be constructed for a number of other languages into which these two corpora have been translated as well. The larger context of the FTB-3 parsebank is described by Voutilainen et al. (2012b); our involvement in its development was through a public request for quotation issued by FIN-CLARIN, seeking the development of a sufficiently accurate Finnish syntactic parser and its application to the EuroParl and JRC-Acquis corpora. Our starting point for the development was thus untypical as the corpus text, morphological tagset,"
W13-5626,steinberger-etal-2006-jrc,0,0.0442941,"Missing"
W14-1118,W10-1108,1,0.899237,"Missing"
W14-1118,N13-1090,0,0.107499,"ediate context (BoW architecture). The vector space representation is subsequently extracted from the learned weights within the neural network. One of the main practical advantages of the word2vec method lies in its scalability, allowing quick training on large amounts of text, setting it apart from the majority of other methods of distributional semantics. Additionally, the word2vec method has been shown to produce representations that surpass in quality traditional methods such as Latent Semantic Analysis, especially on tasks measuring the preservation of important linguistic regularities (Mikolov et al., 2013b). Weight 1 2 0 1 0 1 J21.1 Figure 2: Weighting applied to ICD-code index vectors when training WSMs based on ICD-10 codes (RI-ICD). 4.2 this similarity is encoded in the resulting WSM. As a example: for a clinical note labelled with the code J21.1, we add the following index vectors to the context vectors of all its constituting words: iv(J) × 0.125, iv(J2) × 0.25, iv(J21) × 0.5 and iv(J21.1) × 1.0. The underlying hypothesis for building a WSM in this way is that it may capture relations between words in a way that better reflects the clinical domain, compared to the other domain-independent"
W14-1118,W13-3210,1,0.852867,"Missing"
W15-1815,P14-2048,0,0.0417197,"Missing"
W15-1815,P13-1157,0,0.0297284,"similar studies include Ilisei et al. (2010) presenting a languageindependent system based on average sentence length or lexical richness, Popescu (2011) using solely character 5-grams (ignoring sentence boundaries) to detect English translations, and Avner, Ordan and Wintner (2014) concentrating on morphological properties in Hebrew. Previous studies on classifying machine translated texts mostly rely on different combinations of lexical and grammatical features as well. Aharoni, Koppel, and Goldberg (2014) use a set of function words, POS tags and a mix of the two to classify texts, whereas Arase and Zhou (2013) concentrate on indicators based on sentenceinternal coherence, also called the phrase salad phenomenon (Lopez, 2008). Despite their relative infrequency, some previous work also concentrate on classifying informality. Unlike those concerning translation classification, these concentrate on lexical rather than morphological features. Lahiri, Mitra, and Lu (2011) explore the Formality Score, a frequency list based on the differences of word classes in a corpus. Mosquera and Moreda (2011) define the most relevant features of informality to be the frequencies of spelling mistakes, interjections,"
W15-1815,S13-1035,0,0.049393,"nalyses. The current version consists of 3.2 billion tokens and 241 million sentences. This article has two main objectives. The first aim is to develop classification methods in order to detect informality, machine translations and human translations from the Parsebank. This would facilitate the use of the Parsebank, as searches or applications could be targeted only at certain parts of the corpus. In the classification, the features used include syntactic n-grams, little subtrees of dependency syntax analyses developed for Finnish by Kanerva et al. (2014), originally produced for English by Goldberg and Orwant (2013). Secondly, the study points research directions for the analysis of the linguistic characteristics of the text classes. The automatic classification based on the data-driven combination of lexical, syntactic and morphological features offers a new approach to the linguistic study of these texts and their characteristics, as traditional linguistic studies often concentrate on the analysis of a limited number of preselected features. The study consists of three sets of classification experiments and their analyses. In the first, texts are classified according to the level of formality to standa"
W15-1815,J03-3001,0,0.0493192,"ation performs well for the indomain experiments, delexicalized methods with morpho-syntactic features prove to be more tolerant to variation caused by genre or source language. In addition, the results show that the features used in the classification provide interesting pointers for further, more detailed studies on the linguistic characteristics of these texts. 1 Introduction With its growing size and coverage, the Internet has become an attractive source of material for linguistic resources, used both for linguistics and natural language processing (NLP) applications (Baroni et al., 2009; Kilgarriff and Grefenstette, 2003). However, automatically collected, very large corpora covering all the text that can be found are very heterogeneous, which may complicate their usage. In linguistics, the origin of the corpus texts is of primary importance (Biber et al., 1998; Sinclair, 1996), and also in many NLP applications, such as automatic syntactic analysis, linguistic variation across different domains affects the results significantly (Laippala et al., 2014). This paper presents the first results on the linguistic variation in the Finnish-language Internet by analyzing informality, machine translations and human tra"
W15-1815,W11-4523,0,0.0303982,"Koppel, and Goldberg (2014) use a set of function words, POS tags and a mix of the two to classify texts, whereas Arase and Zhou (2013) concentrate on indicators based on sentenceinternal coherence, also called the phrase salad phenomenon (Lopez, 2008). Despite their relative infrequency, some previous work also concentrate on classifying informality. Unlike those concerning translation classification, these concentrate on lexical rather than morphological features. Lahiri, Mitra, and Lu (2011) explore the Formality Score, a frequency list based on the differences of word classes in a corpus. Mosquera and Moreda (2011) define the most relevant features of informality to be the frequencies of spelling mistakes, interjections, and emoticons. These same individual features have also been studied as signs of informality in many linguistic studies (Lehti and Laippala, 2014). 3 3.1 Data Finnish Internet Parsebank and Syntactic N-grams The current version of the Finnish Internet Parsebank consists of 3.2 billion tokens and 241 million sentences. It is produced by crawling the Finnish web with the Spiderling web crawler2 . Being designed for collecting text corpora, it can be targeted to crawl only pages in a speci"
W15-1815,R11-1091,0,0.255473,"l of translated texts. Baker (1993) was the first to define potential translation universals: features that all translated texts hypothetically share. The existence of translationese has also been tested by studies applying machine learning. Baroni and Bernardini (2006) use monolingual corpora to experiment with for instance lemmas and POS tags, providing evidence that an algorithm can perform better than humans in recognizing human translated texts. Other similar studies include Ilisei et al. (2010) presenting a languageindependent system based on average sentence length or lexical richness, Popescu (2011) using solely character 5-grams (ignoring sentence boundaries) to detect English translations, and Avner, Ordan and Wintner (2014) concentrating on morphological properties in Hebrew. Previous studies on classifying machine translated texts mostly rely on different combinations of lexical and grammatical features as well. Aharoni, Koppel, and Goldberg (2014) use a set of function words, POS tags and a mix of the two to classify texts, whereas Arase and Zhou (2013) concentrate on indicators based on sentenceinternal coherence, also called the phrase salad phenomenon (Lopez, 2008). Despite their"
W16-2913,W09-1401,0,0.108114,"Missing"
W16-2913,P05-1022,0,0.0554004,"aracter encoding from UTF-8 to ASCII as many of the legacy language processing tools are incapable of handling non-ASCII characters. Additionally, all excess meta data is removed, leaving titles, abstracts and full-text contents for further processing. These documents are subsequently split into sentences using GENIA sentence splitter (Sætre et al., 2007) as most linguistic analyses are done on the sentence level. GENIA sentence splitter is trained on biomedical text (GENIA corpus) and has state-of-the-art performance on this domain. The whole data is parsed with the BLLIP constituent parser (Charniak and Johnson, 2005), using a model adapted for the biomedical domain (McClosky, 2010), as provided in the TEES processing pipeline. The distributed tokenization and POS tagging are also produced with the parser pipeline. We chose to use this tool as the performance of the TEES software has been previously evaluated on a large-scale together with this parsing pipeline (Van Landeghem et al., 2013b) and it should be a reliable choice for biomedical relation extraction. Since dependency parsing has become the prevalent approach in modeling syntactic relations, we also provide conversions to the collapsed Stanford de"
W16-2913,de-marneffe-etal-2006-generating,0,0.135531,"Missing"
W16-2913,N10-1004,0,0.0318647,"tools are incapable of handling non-ASCII characters. Additionally, all excess meta data is removed, leaving titles, abstracts and full-text contents for further processing. These documents are subsequently split into sentences using GENIA sentence splitter (Sætre et al., 2007) as most linguistic analyses are done on the sentence level. GENIA sentence splitter is trained on biomedical text (GENIA corpus) and has state-of-the-art performance on this domain. The whole data is parsed with the BLLIP constituent parser (Charniak and Johnson, 2005), using a model adapted for the biomedical domain (McClosky, 2010), as provided in the TEES processing pipeline. The distributed tokenization and POS tagging are also produced with the parser pipeline. We chose to use this tool as the performance of the TEES software has been previously evaluated on a large-scale together with this parsing pipeline (Van Landeghem et al., 2013b) and it should be a reliable choice for biomedical relation extraction. Since dependency parsing has become the prevalent approach in modeling syntactic relations, we also provide conversions to the collapsed Stanford dependency scheme (De Marneffe et al., 2006). The pipeline is run in"
W16-2913,N06-2024,0,0.0106302,"able for these entity types (Leaman et al., 2015; Leaman and Gonzalez, 2008), we have decided to use a single tool, NERsuite3 , for all types. NERsuite is based on conditional random field classifiers as implemented in the CRFsuite software (Okazaki, 2007). Having a single tool for this processing step instead of using the various state-of-the-art tools is critical for the maintainability of the processing pipeline. NERsuite was selected as several biological models are readily available for this software (Kaewphan et al., 2016; Pyysalo and Ananiadou, 2014) and as it supports label weighting (Minkov et al., 2006) unlike many other NER tools. For cell line names we use a publicly available state-of-the-art model (Kaewphan et al., 2016), whereas for the other entity types we train our own models with manually annotated data from GENETAG (Tanabe et al., 2005), CHEMDNER (Krallinger et al., 2015), SPECIES (Pafilis et al., 2013) and NCBI disease (Doˇgan et al., 2014) corpora for GGPs, chemicals, organisms and diseases, respectively. All these corpora are comprised of biomedical articles and should thus reflect well the text types seen in PubMed. All used corpora provide the data divided to training, develop"
W16-2913,W13-1908,1,0.907063,"Missing"
W16-2913,S13-2056,0,0.0778119,"Missing"
W16-2913,W13-2003,1,\N,Missing
W16-3009,N10-1004,0,0.0234799,"o run a basic preprocessing pipeline of tokenization, POS tagging, and parsing, as well as to remove cross-sentence relations. Like our approach, TEES targets the extraction of associations between entities that occur in the same sentence. To support this functionality, it can detect and eliminate relations that cross sentence boundaries in its input. We use this feature of TEES as an initial preprocessing step to remove such relations from the data. To obtain tokens, POS tags and parse graphs, TEES uses the BLLIP parser (Charniak and Johnson, 2005) with the biomedical domain model created by McClosky (2010). The phrase structure trees produced by the parser are further processed with the Stanford conversion tool (de Marneffe et al., 2006) to create dependency graphs. The Stanford system can produce several variants of the Stanford Dependencies (SD) representation. Here, we use the collapsed variant, which is designed to be useful for information extraction and language understanding tasks (de Marneffe and Manning, 2008). Our approach builds on the shortest dependency path between each pair of entities. However, while dependency parse graphs connect words to others in the same sentence, a number"
W16-3009,W13-2003,1,0.577396,"Missing"
W16-3009,W11-1809,0,0.0535061,"Missing"
W16-3009,W13-2001,1,0.868609,"Missing"
W16-3009,H05-1091,0,0.721626,"e there are various ways of converting the shared task annotations into examples for classification, the numbers we report here may differ from those reported by other participating teams. 3.2 Shortest Dependency Path The syntactic structure connecting two entities e1 and e2 in various forms of syntactic analysis is known to contain most of the words relevant to characterizing the relationship R(e1 , e2 ), while excluding less relevant and uninformative words. This observation has served as the basis for many successful relation extraction approaches in both general and biomedical domain NLP (Bunescu and Mooney, 2005; Airola et al., 2008; Nguyen et al., 2009; Chowdhury et al., 2011). The TEES system also heavily relies on the shortest dependency path for defining and ex1 Official evaluation results on the test data are of course comparable to those of other systems: any cross-sentence relations in the test data count against our submission as false negatives. 74 3.3 tracting features (Bj¨orne et al., 2012; Bj¨orne and Salakoski, 2013). Recently, this idea was applied in an LSTM-based relation extraction system by Xu et al. (2015). Since the dependency parse is directed (i.e. the path from e1 to e2 differs"
W16-3009,D09-1143,0,0.0186528,"ed task annotations into examples for classification, the numbers we report here may differ from those reported by other participating teams. 3.2 Shortest Dependency Path The syntactic structure connecting two entities e1 and e2 in various forms of syntactic analysis is known to contain most of the words relevant to characterizing the relationship R(e1 , e2 ), while excluding less relevant and uninformative words. This observation has served as the basis for many successful relation extraction approaches in both general and biomedical domain NLP (Bunescu and Mooney, 2005; Airola et al., 2008; Nguyen et al., 2009; Chowdhury et al., 2011). The TEES system also heavily relies on the shortest dependency path for defining and ex1 Official evaluation results on the test data are of course comparable to those of other systems: any cross-sentence relations in the test data count against our submission as false negatives. 74 3.3 tracting features (Bj¨orne et al., 2012; Bj¨orne and Salakoski, 2013). Recently, this idea was applied in an LSTM-based relation extraction system by Xu et al. (2015). Since the dependency parse is directed (i.e. the path from e1 to e2 differs from that from e2 to e1 ), they separate"
W16-3009,P05-1022,0,0.0164901,"eloped by members of the TurkuNLP group (Bj¨orne and Salakoski, 2013), to run a basic preprocessing pipeline of tokenization, POS tagging, and parsing, as well as to remove cross-sentence relations. Like our approach, TEES targets the extraction of associations between entities that occur in the same sentence. To support this functionality, it can detect and eliminate relations that cross sentence boundaries in its input. We use this feature of TEES as an initial preprocessing step to remove such relations from the data. To obtain tokens, POS tags and parse graphs, TEES uses the BLLIP parser (Charniak and Johnson, 2005) with the biomedical domain model created by McClosky (2010). The phrase structure trees produced by the parser are further processed with the Stanford conversion tool (de Marneffe et al., 2006) to create dependency graphs. The Stanford system can produce several variants of the Stanford Dependencies (SD) representation. Here, we use the collapsed variant, which is designed to be useful for information extraction and language understanding tasks (de Marneffe and Manning, 2008). Our approach builds on the shortest dependency path between each pair of entities. However, while dependency parse gr"
W16-3009,W11-0216,0,0.0192759,"nto examples for classification, the numbers we report here may differ from those reported by other participating teams. 3.2 Shortest Dependency Path The syntactic structure connecting two entities e1 and e2 in various forms of syntactic analysis is known to contain most of the words relevant to characterizing the relationship R(e1 , e2 ), while excluding less relevant and uninformative words. This observation has served as the basis for many successful relation extraction approaches in both general and biomedical domain NLP (Bunescu and Mooney, 2005; Airola et al., 2008; Nguyen et al., 2009; Chowdhury et al., 2011). The TEES system also heavily relies on the shortest dependency path for defining and ex1 Official evaluation results on the test data are of course comparable to those of other systems: any cross-sentence relations in the test data count against our submission as false negatives. 74 3.3 tracting features (Bj¨orne et al., 2012; Bj¨orne and Salakoski, 2013). Recently, this idea was applied in an LSTM-based relation extraction system by Xu et al. (2015). Since the dependency parse is directed (i.e. the path from e1 to e2 differs from that from e2 to e1 ), they separate the shortest dependency p"
W16-3009,W11-1815,0,0.399828,"Missing"
W16-3009,W08-1301,0,0.0397729,"Missing"
W16-3009,de-marneffe-etal-2006-generating,0,0.0640478,"Missing"
W16-3009,D15-1206,0,0.077098,"ion extraction approaches in both general and biomedical domain NLP (Bunescu and Mooney, 2005; Airola et al., 2008; Nguyen et al., 2009; Chowdhury et al., 2011). The TEES system also heavily relies on the shortest dependency path for defining and ex1 Official evaluation results on the test data are of course comparable to those of other systems: any cross-sentence relations in the test data count against our submission as false negatives. 74 3.3 tracting features (Bj¨orne et al., 2012; Bj¨orne and Salakoski, 2013). Recently, this idea was applied in an LSTM-based relation extraction system by Xu et al. (2015). Since the dependency parse is directed (i.e. the path from e1 to e2 differs from that from e2 to e1 ), they separate the shortest dependency path into two sub-paths, each from an entity to the common ancestor of the two entities, generate features along the two sub-paths, and feed them into different LSTM networks, to process the information in a direction sensitive manner. To avoid doubling the number of LSTM chains (and hence the number of weights), we convert the dependency parse to an undirected graph, find the shortest path between the two entities (BACTERIA and H ABITAT/G EOGRAPHICAL),"
W17-0218,J03-3001,0,0.285008,"Missing"
W17-0218,W15-2124,1,0.90854,"Missing"
W17-0218,sharoff-etal-2010-web,0,0.0431372,"Missing"
W17-0218,P09-1076,0,0.0818757,"Missing"
W17-0510,W17-0249,1,0.73727,"study Filip Ginter Turku NLP Group Department of FT University of Turku filip.ginter@utu.fi of nineteenth-century US newspapers by Ryan Cordell, David A. Smith and their research group (Cordell, 2015; Smith et al., 2015). However, in contrast to the US press, the nineteenth- and early twentieth-century Finnish newspapers were typically printed in the Fraktur typeface, which (together with other possible sources of noise) poses unusual difficulties for Optical Character Recognition (Kettunen, 2016). To solve this problem, we have developed a novel text reuse detection solution based on BLAST (Vesanto et al., 2017) that is accurate and resistant to OCR mistakes and other noise, making the text circulation and virality of newspaper publicity in Finland a feasible research question. 2 Detecting Text Reuse In the nineteenth century, contemporaries saw newspapers as reflections of modern culture. Many phenomena were amplified by the increasing power of the press, including urbanization, consumerism, and business life. The changes in transport technology led to more efficient distribution of information. Before 1880s, there was no copyright agreement to regulate the free copying of texts, which became a dist"
W17-2310,P16-1072,0,0.0202084,"ys traverse the SDP by starting the path from the BACTERIA entity mention to the H ABITAT/G EOGRAPHICAL, regardless of the order of their occurrence in the sentence. Evaluation against the development set showed that this approach leads to better generalization in comparison with simply traversing the path from the first occurring entity mention to the second (with/without considering the direction of the edges). Table 1: BB3-event data statistics. which connects the two candidate entities in the syntactic parse graph. Many successful relation extraction systems have been built utilizing SDP (Cai et al., 2016; Mehryary et al., 2016; Xu et al., 2015; Bj¨orne and Salakoski, 2013; Bj¨orne et al., 2012; Bunescu and Mooney, 2005) since it is known to contain most of the relevant words for expressing the relation between the two entities while excluding less relevant and uninformative words. Since this approach focuses on a single sentence parse graph at a time, it is unable to detect plausible cross-sentence relations, i.e, the cases in which the two candidate entities belong to different sentences. As discussed by Kim et al. (2011), detecting such relations is a major challenge for relation extraction"
W17-2310,P05-1022,0,0.0688858,"coded entity-type vectors are concatenated. The first entity-type vector represents the type of the first occurring entity in the sentence (BACTERIA, H ABITAT or G EOGRAPH ICAL), and the other is used for the second one. The resulting vector is then forwarded into a fully connected hidden layer and finally, the hidden layer connects to a single-node binary classification layer. Preprocessing For preprocessing, we use the preprocessing pipeline of the TEES system (Bj¨orne and Salakoski, 2013) which automates tokenization, part-of-speech tagging and sentence parsing. TEES runs the BLLIP parser (Charniak and Johnson, 2005) with the biomedical domain model created by McClosky (2010). The resulting phrase structure trees are then converted to dependency graphs (nonCollapsed variant of Stanford Dependency) using the Stanford conversion tool (version 2.0.1) (de Marneffe et al., 2006). 2.3.2 For the word features, we use a vector space model with 200-dimensional word embeddings pre-trained by Pyysalo et al. (2013). These are fine-tuned during the training while the POS-tag and dependency type embeddings are learned from scratch after being randomly initialized. Relation extraction system architecture Based on experi"
W17-2310,de-marneffe-etal-2006-generating,0,0.1383,"Missing"
W17-2310,P16-1096,0,0.0271373,"on 3.2). Both of these expansion methods have similar intentions as the preprocessing steps utilized by the winning system in BB3 (BOUN) by Tiftikci et al. (2016), but our system uses more relaxed criteria for finding the full forms and should thus result in better recall at the expense of precision. to NCBI Taxonomy and OntoBiotope identifiers respectively. This task is commonly known as named entity normalization or entity linking and various approaches ranging from Levenshtein edit distances to recurrent neural networks have been suggested as the plausible solutions (Tiftikci et al., 2016; Limsopatham and Collier, 2016). Our categorization method is based on the common approach of TFIDF weighted sparse vector space representations (Salton and Buckley, 1988; Leaman et al., 2013; Hakala, 2015), i.e. the problem is seen as an information retrieval task where each concept name in the ontology is considered a document and the IDF weights are based on these names. Consequently, each concept name and each entity mention is represented with a TFIDF weighted vector and the concept with the highest cosine similarity is assigned for a given entity. Whereas these representations are commonly formed in a bag-of-words fas"
W17-2310,W16-3002,0,0.0945246,"Missing"
W17-2310,N10-1004,0,0.0163206,"represents the type of the first occurring entity in the sentence (BACTERIA, H ABITAT or G EOGRAPH ICAL), and the other is used for the second one. The resulting vector is then forwarded into a fully connected hidden layer and finally, the hidden layer connects to a single-node binary classification layer. Preprocessing For preprocessing, we use the preprocessing pipeline of the TEES system (Bj¨orne and Salakoski, 2013) which automates tokenization, part-of-speech tagging and sentence parsing. TEES runs the BLLIP parser (Charniak and Johnson, 2005) with the biomedical domain model created by McClosky (2010). The resulting phrase structure trees are then converted to dependency graphs (nonCollapsed variant of Stanford Dependency) using the Stanford conversion tool (version 2.0.1) (de Marneffe et al., 2006). 2.3.2 For the word features, we use a vector space model with 200-dimensional word embeddings pre-trained by Pyysalo et al. (2013). These are fine-tuned during the training while the POS-tag and dependency type embeddings are learned from scratch after being randomly initialized. Relation extraction system architecture Based on experiments on the development set, we have set the dimensionality"
W17-2310,P05-1045,0,0.0711618,"couver, Canada, August 4, 2017. 2017 Association for Computational Linguistics 2 Method 2.1 strings under the semantic type geographical area from UMLS database (version 2016AA) (Bodenreider, 2004). All dictionaries prepared in this step are directly provided to NERsuite through the dictionary-tagging module without any normalization. The tagging provides additional features describing whether the tokens are present in some semantic categories, such as bacteria names or geographical places. For G EOGRAPHICAL model, we also add token-level tagging results for location from Stanford NER (SNER) (Finkel et al., 2005) as binary values to NERsuite; 1 and 0 for location and non-location, respectively. Although utilizing dictionary features is beneficial for NER, strict string matching tends to lead to low coverage, an issue which is also common in the categorization task. To remedy this problem, we also generate fuzzy matching features based on our categorization system (see Section 2.2) by measuring the maximum similarity of each token against the NCBI Taxonomy and OntoBiotope ontologies for BACTERIA and H ABITAT respectively. Thus, instead of a binary feature denoting whether a token is present in the onto"
W17-2310,W16-3009,1,0.839766,"P by starting the path from the BACTERIA entity mention to the H ABITAT/G EOGRAPHICAL, regardless of the order of their occurrence in the sentence. Evaluation against the development set showed that this approach leads to better generalization in comparison with simply traversing the path from the first occurring entity mention to the second (with/without considering the direction of the edges). Table 1: BB3-event data statistics. which connects the two candidate entities in the syntactic parse graph. Many successful relation extraction systems have been built utilizing SDP (Cai et al., 2016; Mehryary et al., 2016; Xu et al., 2015; Bj¨orne and Salakoski, 2013; Bj¨orne et al., 2012; Bunescu and Mooney, 2005) since it is known to contain most of the relevant words for expressing the relation between the two entities while excluding less relevant and uninformative words. Since this approach focuses on a single sentence parse graph at a time, it is unable to detect plausible cross-sentence relations, i.e, the cases in which the two candidate entities belong to different sentences. As discussed by Kim et al. (2011), detecting such relations is a major challenge for relation extraction systems. We simply exc"
W17-2310,W16-3008,0,0.171275,"able 6 shows, using previous BBST data for training the NER leads to 3pp increase in F-score of (BACTERIA,G EOGRAPHICAL) relations on the development set and about 11pp for the test set, probably due to the drastically increased performance for G EOGRAPHICAL entity detection. Unfortunately, since there are much less (BACTERIA,G EOGRAPHICAL) relations than (BACTERIA,H ABITAT) relations in the data, our approach increases the overall F-score only by 1pp for the test set. Table 7 compares the performance of our endto-end system with the winning team in the BB3-event+ner task (LIMSI, developed by Grouin (2016)). As it can be seen in the table, our system outperforms the winning team by 19pp in Fscore, achieving the new state-of-the-art score for the task. Even if we solely rely on BB3 data for the NER system, the improvement is 18pp in F-score. We emphasize that no other data than BB3 is used for training/optimization of our relation extraction system in any way. Teams LIMSI Our system F-score 0.192 0.381 Recall 0.191 0.292 Precision 0.193 0.548 SER 1.558 0.891 Table 7: Official evaluation results for BB3event+ner test data of our system compared to LIMSI, the winning team in the Shared Task. 4 Con"
W17-2310,W12-4304,0,0.0316335,"designed for parsing PubMed documents (Pyysalo et al., 2013) 1 . Next we split documents into sentences using the Genia Sentence Splitter (Sætre et al., 2007) and the sentences are subsequently tokenized and part-ofspeech tagged using the tokenization and POStagging modules in NERsuite 2 , respectively. To detect the entity mentions we use NERsuite, a named entity recognition toolkit, as it is relatively easy to train on new corpora, yet supports adding novel user-defined features. In biomedical NER, NERsuite has been a versatile tool achieving excellent performance for various entity types (Ohta et al., 2012; Kaewphan et al., 2014, 2016), however, it is not capable of dealing with overlapping entities. Therefore, we only use the longest spans of overlapping annotated entities as our training data, ignoring embedded entities which are substrings of the longest spans. In biomedical NER, domain knowledge such as controlled vocabularies has been crucial for achieving high performance. In this work we prepare 3 dictionaries, specific for each entity type. For BACTERIA, we compile a dictionary of names exclusively from the NCBI Taxonomy database3 by including all names under bacteria superkingdom (NCBI"
W17-2310,S15-2064,1,0.738953,"axed criteria for finding the full forms and should thus result in better recall at the expense of precision. to NCBI Taxonomy and OntoBiotope identifiers respectively. This task is commonly known as named entity normalization or entity linking and various approaches ranging from Levenshtein edit distances to recurrent neural networks have been suggested as the plausible solutions (Tiftikci et al., 2016; Limsopatham and Collier, 2016). Our categorization method is based on the common approach of TFIDF weighted sparse vector space representations (Salton and Buckley, 1988; Leaman et al., 2013; Hakala, 2015), i.e. the problem is seen as an information retrieval task where each concept name in the ontology is considered a document and the IDF weights are based on these names. Consequently, each concept name and each entity mention is represented with a TFIDF weighted vector and the concept with the highest cosine similarity is assigned for a given entity. Whereas these representations are commonly formed in a bag-of-words fashion, in our experiments using character-level ngrams resulted in better outcome. In the final system we use ngrams of length 1, 2 and 3 characters. These ngram lengths produc"
W17-2310,W16-2913,1,0.834597,"-cat+ner, we use our own implementation by calculating the F-score using exact string matching criteria as our main scoring metric. In this study, we consider BB3event+ner as our primary subtask and thus all hyper-parameters in model selection are optimized against F-score instead of SER. Named entity detection Detecting the BB3 H ABITAT, BACTERIA and G E OGRAPHICAL mentions is a standard named entity recognition task, evaluated based on the correctness of the type and character offsets of the discovered text spans. In our NER pipeline, all documents are preprocessed following the approach of Hakala et al. (2016). In brief, we first convert all documents and annotation files from UTF8 to ASCII encoding using a modified version of publicly available tool designed for parsing PubMed documents (Pyysalo et al., 2013) 1 . Next we split documents into sentences using the Genia Sentence Splitter (Sætre et al., 2007) and the sentences are subsequently tokenized and part-ofspeech tagged using the tokenization and POStagging modules in NERsuite 2 , respectively. To detect the entity mentions we use NERsuite, a named entity recognition toolkit, as it is relatively easy to train on new corpora, yet supports addin"
W17-2310,S14-2143,1,0.86257,"nary features is beneficial for NER, strict string matching tends to lead to low coverage, an issue which is also common in the categorization task. To remedy this problem, we also generate fuzzy matching features based on our categorization system (see Section 2.2) by measuring the maximum similarity of each token against the NCBI Taxonomy and OntoBiotope ontologies for BACTERIA and H ABITAT respectively. Thus, instead of a binary feature denoting whether a token is present in the ontology or not, a similarity score ranging from 0 to 1 is assigned for each token. This approach is similar to (Kaewphan et al., 2014), but instead of using word embedding similarities, our fuzzy matching relies on character ngrams. We do not use these features for the G EO GRAPHICAL entities, which are not categorized by our system. In the official BB3 evaluation, NER is jointly evaluated with either categorization or event extraction system. In BB3-cat+ner task, SER (Slot Error Rate) is used as the main scoring metric, whereas in BB3-event+ner, participating teams are ranked based on F-score of extracted relations. Due to the lack of an official evaluation on NER for all entities in BB3-event+ner and for G EOGRAPHICAL in B"
W17-2310,W16-3007,0,0.199971,"Missing"
W17-2310,D15-1206,0,0.0261839,"from the BACTERIA entity mention to the H ABITAT/G EOGRAPHICAL, regardless of the order of their occurrence in the sentence. Evaluation against the development set showed that this approach leads to better generalization in comparison with simply traversing the path from the first occurring entity mention to the second (with/without considering the direction of the edges). Table 1: BB3-event data statistics. which connects the two candidate entities in the syntactic parse graph. Many successful relation extraction systems have been built utilizing SDP (Cai et al., 2016; Mehryary et al., 2016; Xu et al., 2015; Bj¨orne and Salakoski, 2013; Bj¨orne et al., 2012; Bunescu and Mooney, 2005) since it is known to contain most of the relevant words for expressing the relation between the two entities while excluding less relevant and uninformative words. Since this approach focuses on a single sentence parse graph at a time, it is unable to detect plausible cross-sentence relations, i.e, the cases in which the two candidate entities belong to different sentences. As discussed by Kim et al. (2011), detecting such relations is a major challenge for relation extraction systems. We simply exclude any cross-se"
W17-2310,H05-1091,0,\N,Missing
W17-2310,W13-2024,0,\N,Missing
W18-2311,I17-2072,0,0.0172559,"hods such as the TEES SVM system. The shortest path consists of the tokens and dependencies connecting the two entities of a candidate relation. For each token on the path we define two embeddings, one for the incoming and one for the outgoing dependency. For example, if the shortest path would consist of three tokens and the two dependencies connecting them, the shortest path embedding vectors for the three tokens could be e.g. ([begin], ←nsubj), (←nsubj, dobj→), (dobj→, [end]). Thus, our shortest path embeddings can be seen as a more detailed extrapolation of the “on dep path embeddings” of Fu et al. (2017). Event Argument Embeddings are used only in the unmerging stage where predicted entities and edges are divided into separate events. 2.5 ter optimization. In addition to varying the random seed, we pick a random combination of hyperparameters from the ranges to be optimized, so that different models are randomized both in terms of initialization and the parameters. We test sizes of 200, 400 and 800 for the final dense layer, filter sizes of 128, 256 and 512 for the convolutional layers and dropout values of 0.1, 0.2 and 0.5. In addition, we experiment with path depths of 0–4 for the path embe"
W18-2311,W09-1402,1,0.897752,"Missing"
W18-2311,E06-1051,0,0.360184,"her more than two entities, that they have an annotated trigger word (usually a verb) and that events can act as arguments of other events. In the GENIA corpus, a sentence stating “The binding of proteins A and B is regulated by protein C” would be annotated with two nested events REGULATION(C, BIND(A, B)). While events can capture the semantics of text more accurately, their added complexity makes their extraction a more complicated task. Many methods have been developed for relation extraction, with various kernel methods such as the graph kernel being widely used (Mooney and Bunescu, 2006; Giuliano et al., 2006; Airola et al., 2008). For the more complex task of event extraction approaches such as pipeline systems (Bj¨orne, 2014; Miwa et al., 2010), semantic parsing (McClosky et al., 2011) and joint inference (Riedel and McCallum, 2011) have been explored. In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception. Considerable performance increases have been gained with methods such as convolutional (Zeng et al., 2014) and recurrent neural networks (Miwa and Bansal, 2016). Some proposed systems have relied entirely on wor"
W18-2311,S13-2108,1,0.880205,"Missing"
W18-2311,W13-2004,1,0.899781,"Missing"
W18-2311,W11-1828,1,0.953466,"Missing"
W18-2311,W09-1401,0,0.656365,"the only stage used. In the entity detection stage TEES predicts a maximum of one entity per word token. However, since events are n-ary relations, event nodes may overlap. The unmerging stage duplicates event nodes by classifying each candidate event as a real event or not. Finally, modifier detection can be used to detect event modality (such as speculation or negation) on corpora where this is annotated. Materials and Methods 2.1 Corpora We develop and evaluate our method on a large number of event and relation corpora (See Table 1). These corpora originate from three BioNLP Shared Tasks (Kim et al., 2009, 2011; N´edellec et al., 2013), the two Drug–Drug Interaction (DDI) Extraction tasks (Segura-Bedmar et al., 2011, 2013) and the recent BioCreative VI Chemical–Protein relation extraction task (Krallinger et al., 2017). The BioNLP corpora cover various domains of molecular biology and provide the most complex event annotations. The DDI and BioCreative corpora use pairwise relation annotations, and one of the DDI corpora defines also a drug named entity recognition (NER) task. All of these corpora are used in the TEES XML format and are installed or generated with the TEES system. The corpora a"
W18-2311,W13-2003,1,0.927764,"Missing"
W18-2311,W11-1801,0,0.0800299,"Missing"
W18-2311,P05-1022,0,0.0911431,"asks (Segura-Bedmar et al., 2011, 2013) and the recent BioCreative VI Chemical–Protein relation extraction task (Krallinger et al., 2017). The BioNLP corpora cover various domains of molecular biology and provide the most complex event annotations. The DDI and BioCreative corpora use pairwise relation annotations, and one of the DDI corpora defines also a drug named entity recognition (NER) task. All of these corpora are used in the TEES XML format and are installed or generated with the TEES system. The corpora are parsed with the TEES preprocessing pipeline, which utilizes the BLLIP parser (Charniak and Johnson, 2005) with the McClosky biomodel (McClosky, 2010), followed by conversion of the constituency parses into dependency parses with the Stanford Tools (de Marneffe et al., 2006). These tools generate the deep parse graph which is used as the source for our dependency path features. 2.2 2.3 In TEES the four classification stages are implemented as multiclass classification tasks using the SVMmulticlass support vector machine (Tsochantaridis et al., 2005) and a rich set of features derived mostly from the dependency parse graph. We develop our convolutional neural network method using the Keras (Chollet"
W18-2311,D14-1181,0,0.00717146,"Missing"
W18-2311,S13-2057,0,0.115222,"Missing"
W18-2311,P15-2047,0,0.0331207,"and joint inference (Riedel and McCallum, 2011) have been explored. In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception. Considerable performance increases have been gained with methods such as convolutional (Zeng et al., 2014) and recurrent neural networks (Miwa and Bansal, 2016). Some proposed systems have relied entirely on word embeddings (Quan et al., 2016), while others have developed various network architectures for utilizing parse graphs as an additional source of information (Collobert et al., 2011; Liu et al., 2015; Xu et al., 2015; Ma et al., Event and relation extraction are central tasks in biomedical text mining. Where relation extraction concerns the detection of semantic connections between pairs of entities, event extraction expands this concept with the addition of trigger words, multiple arguments and nested events, in order to more accurately model the diversity of natural language. In this work we develop a convolutional neural network that can be used for both event and relation extraction. We use a linear representation of the input text, where information is encoded with various vector spa"
W18-2311,P15-2029,0,0.0571423,"Missing"
W18-2311,W16-6308,0,0.190116,"Missing"
W18-2311,W13-2001,0,0.428103,"Missing"
W18-2311,N10-1004,0,0.0530066,"ioCreative VI Chemical–Protein relation extraction task (Krallinger et al., 2017). The BioNLP corpora cover various domains of molecular biology and provide the most complex event annotations. The DDI and BioCreative corpora use pairwise relation annotations, and one of the DDI corpora defines also a drug named entity recognition (NER) task. All of these corpora are used in the TEES XML format and are installed or generated with the TEES system. The corpora are parsed with the TEES preprocessing pipeline, which utilizes the BLLIP parser (Charniak and Johnson, 2005) with the McClosky biomodel (McClosky, 2010), followed by conversion of the constituency parses into dependency parses with the Stanford Tools (de Marneffe et al., 2006). These tools generate the deep parse graph which is used as the source for our dependency path features. 2.2 2.3 In TEES the four classification stages are implemented as multiclass classification tasks using the SVMmulticlass support vector machine (Tsochantaridis et al., 2005) and a rich set of features derived mostly from the dependency parse graph. We develop our convolutional neural network method using the Keras (Chollet et al., 2015) package with the TensorFlow b"
W18-2311,P11-1163,0,0.0394335,"The binding of proteins A and B is regulated by protein C” would be annotated with two nested events REGULATION(C, BIND(A, B)). While events can capture the semantics of text more accurately, their added complexity makes their extraction a more complicated task. Many methods have been developed for relation extraction, with various kernel methods such as the graph kernel being widely used (Mooney and Bunescu, 2006; Giuliano et al., 2006; Airola et al., 2008). For the more complex task of event extraction approaches such as pipeline systems (Bj¨orne, 2014; Miwa et al., 2010), semantic parsing (McClosky et al., 2011) and joint inference (Riedel and McCallum, 2011) have been explored. In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception. Considerable performance increases have been gained with methods such as convolutional (Zeng et al., 2014) and recurrent neural networks (Miwa and Bansal, 2016). Some proposed systems have relied entirely on word embeddings (Quan et al., 2016), while others have developed various network architectures for utilizing parse graphs as an additional source of information (Collobert et al., 2011;"
W18-2311,Q17-1008,0,0.266614,"oved performance on several corpora. 1 Introduction Detection of semantic relations is a central task in biomedical text mining where information is retrieved from massive document sets, such as scientific literature or patient records. This information often consists of statements of interactions between named entities, such as signaling pathways between proteins in cells, or the combinatorial effects of drugs administered to a patient. Relation 98 Proceedings of the BioNLP 2018 workshop, pages 98–108 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics 2015; Peng et al., 2017a). In this work we present a new convolutional neural network method for extraction of both events and relations. We integrate our network as a classification module into the Turku Event Extraction System (Bj¨orne, 2014)1 , allowing it to be easily applied to corpora or texts stored in the TEES XML format. Our neural network model is characterized by a unified representation of input examples that can be applied to detection of both keywords as well as their relations. 2 classification tasks (See Figure 2). The first stage is entity detection where each word token in a sentence is classified"
W18-2311,de-marneffe-etal-2006-generating,0,0.175634,"Missing"
W18-2311,D11-1001,0,0.131386,"by protein C” would be annotated with two nested events REGULATION(C, BIND(A, B)). While events can capture the semantics of text more accurately, their added complexity makes their extraction a more complicated task. Many methods have been developed for relation extraction, with various kernel methods such as the graph kernel being widely used (Mooney and Bunescu, 2006; Giuliano et al., 2006; Airola et al., 2008). For the more complex task of event extraction approaches such as pipeline systems (Bj¨orne, 2014; Miwa et al., 2010), semantic parsing (McClosky et al., 2011) and joint inference (Riedel and McCallum, 2011) have been explored. In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception. Considerable performance increases have been gained with methods such as convolutional (Zeng et al., 2014) and recurrent neural networks (Miwa and Bansal, 2016). Some proposed systems have relied entirely on word embeddings (Quan et al., 2016), while others have developed various network architectures for utilizing parse graphs as an additional source of information (Collobert et al., 2011; Liu et al., 2015; Xu et al., 2015; Ma et al., E"
W18-2311,W11-1808,0,0.0603805,"Missing"
W18-2311,P16-1105,0,0.0579031,"kernel being widely used (Mooney and Bunescu, 2006; Giuliano et al., 2006; Airola et al., 2008). For the more complex task of event extraction approaches such as pipeline systems (Bj¨orne, 2014; Miwa et al., 2010), semantic parsing (McClosky et al., 2011) and joint inference (Riedel and McCallum, 2011) have been explored. In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception. Considerable performance increases have been gained with methods such as convolutional (Zeng et al., 2014) and recurrent neural networks (Miwa and Bansal, 2016). Some proposed systems have relied entirely on word embeddings (Quan et al., 2016), while others have developed various network architectures for utilizing parse graphs as an additional source of information (Collobert et al., 2011; Liu et al., 2015; Xu et al., 2015; Ma et al., Event and relation extraction are central tasks in biomedical text mining. Where relation extraction concerns the detection of semantic connections between pairs of entities, event extraction expands this concept with the addition of trigger words, multiple arguments and nested events, in order to more accurately model"
W18-2311,S13-2058,0,0.0728222,"Missing"
W18-2311,C14-1220,0,0.673372,"on, with various kernel methods such as the graph kernel being widely used (Mooney and Bunescu, 2006; Giuliano et al., 2006; Airola et al., 2008). For the more complex task of event extraction approaches such as pipeline systems (Bj¨orne, 2014; Miwa et al., 2010), semantic parsing (McClosky et al., 2011) and joint inference (Riedel and McCallum, 2011) have been explored. In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception. Considerable performance increases have been gained with methods such as convolutional (Zeng et al., 2014) and recurrent neural networks (Miwa and Bansal, 2016). Some proposed systems have relied entirely on word embeddings (Quan et al., 2016), while others have developed various network architectures for utilizing parse graphs as an additional source of information (Collobert et al., 2011; Liu et al., 2015; Xu et al., 2015; Ma et al., Event and relation extraction are central tasks in biomedical text mining. Where relation extraction concerns the detection of semantic connections between pairs of entities, event extraction expands this concept with the addition of trigger words, multiple argument"
W18-2311,W11-1821,0,0.0773592,"Missing"
W18-2311,D14-1090,0,0.684954,"oduced as well as with later research. In the next sections we analyse our results for the different corpus categories. 3.1 The Drug–Drug Interactions Tasks The BioNLP Event Extraction Tasks The BioNLP Event Extraction tasks provide the most complex corpora with often large sets of event types and at times relatively small corpus sizes. The GENIA corpora from 2009 and 2011 have been the subject of most event extraction research. Our proposed method achieves F-scores of 57.84 and 58.10 on GE09 and GE11, respectively. Compared to the best reported results of 58.27 (Miwa et al., 2012) and 58.07 (Venugopal et al., 2014), our method shows similar performance on these corpora. Our CNN reimplementation of TEES outperforms the original TEES SVM system on all the BioNLP corpora. In addition, we achieve to the best of our knowledge the highest reported performance on the GE11, EPI11, REL11, CG13 and PC13 BioNLP Shared Task corpora. 3.3 The CHEMPROT Task Of all the evaluated corpora the CHEMPROT corpus used in the BioCreative VI Chemical–Protein relation extraction task is the most recent. Thus it provides an interesting point of comparison with current methods in relation extraction. All of our models outperform t"
W18-5611,D15-1167,0,0.0342895,"4 Proceedings of the 9th International Workshop on Health Text Mining and Information Analysis (LOUHI 2018), pages 94–100 c Brussels, Belgium, October 31, 2018. 2018 Association for Computational Linguistics are here seen as separate from the section headings used by the clinicians when writing, thus the section headings are considered as input to the classifier along with the free text. As classifiers they use two variations of Bayesian networks. Deep learning methods based on artificial neural networks (ANNs) are currently representing state of the art in many NLP tasks (Zhang et al., 2015; Tang et al., 2015), including text classification, relation extraction and translation. In the presented experiment/prototype system we use the popular long short-term memory (LSTM) recurrent neural network architecture (Hochreiter and Schmidhuber, 1997; Gers et al., 2000) for conducting the text classification. In the data set used here there are 676 unique headings to choose from by the classifier. nursing narratives according to the current care classification standard. A central component is a text classification model based on a long shortterm memory (LSTM) recurrent neural network architecture (Hochreiter"
W18-5611,P82-1020,0,0.78685,"Missing"
W19-6114,N09-1003,0,0.165428,"Missing"
W19-6114,S17-2001,0,0.0171504,"as possible (query vector composition) with a wide enough search for semantically similar n-grams (cos similarity cutoff threshold). Also, the similarity measure used to rank the phrase candidates relative to the query (sim(q, p)) is important for the performance of the system. As future work we also plan to look into the possibility of incorporating ways to automatically exclude non-relevant phrase candidates, e.g. by using a similarity cut-off threshold. Other text similarity measures and approaches could be tried, such as some of those shown to perform well in the SemEval STS shared tasks (Cer et al., 2017). In our relatively straight forward vector composition approach, each word/n-gram are weighted equally (except for stopwords). Improvements may be gained by incorporating some sort of statistical word weighting, like TF-IDF (Salton and Buckley, 1988). Other vector composition approaches could also be considered. Further, we also plan to explore other approaches to generating semantic text representations, such as Sent2Vec (Pagliardini et al., 2018). Also approaches like ELMo (Peters et al., 2017) and BERT (Devlin et al., 2018) could be applicable for this purpose. Additionally, one could also"
W19-6114,P14-1059,0,0.0205897,"is to first use some type of collocation detection. Here the aim is to identify sequences of words that co-occur more often than what is expected by chance in a large corpus. One can then train a semantic model where identified phrases are treated as individual tokens, on the same level as words, like it is done in Mikolov et al. (2013). In the works mentioned so far, the focus is on distributional semantics for representing and calculating semantic similarity and relatedness between predefined lexical units and/or of predefined length (words/n-grams, collocations, clauses, sentences, etc.). Dinu and Baroni (2014) and Turney (2014) take things a step further and approach the more complex and challenging task of using semantic models to enable phrase generation. Their aim is similar to ours: given an input query (phrase) consisting of k words, generate as output t phrases consisting of l words that each expresses its meaning. Their approaches rely on applying a set of separately trained vector composition and decomposition functions able to compose a single vector from a vector pair, or decompose a vector back into estimates of its constituent vectors, possibly in the semantic space of another domain or"
W19-6114,N19-1098,0,0.247746,"(rewrite) candidates for a given query. This is done by first composing vector representation(s) of the query, and then searching for and retrieving n-grams that are close by in the semantic vector space. These n-grams are then concatenated to form the phrase candidates. In this process, the statistical language model helps to quickly discard phrases that are likely nonsensical. Next the phrases are ranked according to their similarity to the query, and finally the search engine checks which phrase candidates actually exist in the targeted corpus, and where. Similar to Zhao et al. (2017) and Gupta et al. (2019) we explore the inclusion of word ngrams of different sizes in the same semantic space/model. One motivation for this is that they both found this to produce improved unigram representations compared to only training with unigram co-occurrence statistics. Another motivation is that we want to use the model to not only retrieve unigrams that are semantically close to each other, but also bigrams and trigrams. 2 Related Work Unsupervised methods for capturing and modeling word-level semantics as vectors, or embeddings, have been popular since the introduction of Latent Semantic Analysis (LSA) (D"
W19-6114,W11-2123,0,0.060679,"semantically similar unigrams, bigrams and trigrams that are near in the semantic space. As a distance measure we apply the commonly used cosine similarity measure (cos). We use a cut-off threshold and a max count as parameters to limit the number of retrieved n-grams and further the number of generated phrase candidates in step 3. Step 3: The third step focuses on generating candidate phrases from the extracted n-grams. This is primarily done by simply exploring all possible permutations of the extracted n-grams. Here we apply the statistical language model, trained using the KenLM toolkit (Heafield, 2011), to efficiently and iteratively check if nonsensical candidate phrases are being generated. For n-grams where n > 1 we also combine with overlapping words – one overlapping word for bigrams and one or two overlapping words for trigrams. As an example, from the bigrams: “a good” and “good cake”, we can construct the phrase “a good cake” since “good” is overlapping. The generation of a phrase will end if no additional n-grams can be added, or if the length reaches a maximum word count threshold relative to the length of the query2 . If, at this point, a phrase has a length that is below a minim"
W19-6114,P14-2050,0,0.0300193,"when it comes to the length of the output phrase suggestions. In addition, we do not want to be concerned with knowledge about word classes in the input and output phrases. We are not aware of previous work presenting a solution to this task. In the next section, Section 3, we describe how our system works. In Section 4 we present a preliminary evaluation followed by discussion and plans for future work directions. 3 3.1 Methods Semantic Model Training In order to train a semantic n-gram model of unigrams, bigrams and trigrams, we initially explored two approaches. First using the Word2Vecf (Levy and Goldberg, 2014) variation of the original Word2Vec toolkit, where one can freely customize the word-to-context training instances as individual rows in the training file – each row containing one source word and one target context to predict. We opted for a skip-gram representation of the training corpus, meaning, for each row in the customized training file, we put the source ngram and one of its neighboring n-grams as target context. The size of the sliding window is decided by how many neighboring (context) n-grams we include for each source n-gram. Overlap between the source n-gram and target n-grams is"
W19-6114,N18-1049,0,0.120037,"etworks. However, recent methods such as ELMo (Peters et al., 2017) and BERT (Devlin et al., 2018) use deep neural networks to represent context sensitive word embeddings, which achieves state-of-the-art performance when used in supervised text classification and similar. Further, there are several relatively recent works focusing on using and/or representing n-gram information as semantic vectors (see e.g. Bojanowski et al. (2016); Zhao et al. (2017); Poliak et al. (2017); Gupta et al. (2019)), possibly to further represent clauses, sentences and/or documents (see e.g. Le and Mikolov (2014); Pagliardini et al. (2018)) in semantic vector spaces. A relatively straight forward approach to identify and represent common phrases as vectors in a semantic space is to first use some type of collocation detection. Here the aim is to identify sequences of words that co-occur more often than what is expected by chance in a large corpus. One can then train a semantic model where identified phrases are treated as individual tokens, on the same level as words, like it is done in Mikolov et al. (2013). In the works mentioned so far, the focus is on distributional semantics for representing and calculating semantic simila"
W19-6114,D14-1162,0,0.0821079,"r capturing and modeling word-level semantics as vectors, or embeddings, have been popular since the introduction of Latent Semantic Analysis (LSA) (Deerwester et al., 1990) around the beginning of the 1990s. Such word vector representations, where the underlying training heuristic is typically based on the distributional hypothesis (Harris, 1954), usually with some form of dimension reduction, have shown to capture word similarity (synonymy and relatedness) and analogy (see e.g. Agirre et al. (2009); Mikolov et al. (2013)). Methods and toolkits like Word2Vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) are nowadays commonly used to (pre-)train word embeddings for further use in various NLP tasks, including supervised text classification with neural networks. However, recent methods such as ELMo (Peters et al., 2017) and BERT (Devlin et al., 2018) use deep neural networks to represent context sensitive word embeddings, which achieves state-of-the-art performance when used in supervised text classification and similar. Further, there are several relatively recent works focusing on using and/or representing n-gram information as semantic vectors (see e.g. Bojanowski et al. (2016); Zhao et al."
W19-6114,P17-1161,0,0.125561,"tor representations, where the underlying training heuristic is typically based on the distributional hypothesis (Harris, 1954), usually with some form of dimension reduction, have shown to capture word similarity (synonymy and relatedness) and analogy (see e.g. Agirre et al. (2009); Mikolov et al. (2013)). Methods and toolkits like Word2Vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) are nowadays commonly used to (pre-)train word embeddings for further use in various NLP tasks, including supervised text classification with neural networks. However, recent methods such as ELMo (Peters et al., 2017) and BERT (Devlin et al., 2018) use deep neural networks to represent context sensitive word embeddings, which achieves state-of-the-art performance when used in supervised text classification and similar. Further, there are several relatively recent works focusing on using and/or representing n-gram information as semantic vectors (see e.g. Bojanowski et al. (2016); Zhao et al. (2017); Poliak et al. (2017); Gupta et al. (2019)), possibly to further represent clauses, sentences and/or documents (see e.g. Le and Mikolov (2014); Pagliardini et al. (2018)) in semantic vector spaces. A relatively"
W19-6114,E17-2081,0,0.0473952,"Missing"
W19-6114,D17-1023,0,0.15911,"set of plausible phrase (rewrite) candidates for a given query. This is done by first composing vector representation(s) of the query, and then searching for and retrieving n-grams that are close by in the semantic vector space. These n-grams are then concatenated to form the phrase candidates. In this process, the statistical language model helps to quickly discard phrases that are likely nonsensical. Next the phrases are ranked according to their similarity to the query, and finally the search engine checks which phrase candidates actually exist in the targeted corpus, and where. Similar to Zhao et al. (2017) and Gupta et al. (2019) we explore the inclusion of word ngrams of different sizes in the same semantic space/model. One motivation for this is that they both found this to produce improved unigram representations compared to only training with unigram co-occurrence statistics. Another motivation is that we want to use the model to not only retrieve unigrams that are semantically close to each other, but also bigrams and trigrams. 2 Related Work Unsupervised methods for capturing and modeling word-level semantics as vectors, or embeddings, have been popular since the introduction of Latent Se"
W19-6125,P16-1154,0,0.0206171,"pop6 We use label weighting to account for the imbalanced distribution, which we optimize against the validation set to 0.85:1 for the positive class (other optimal hyperparameters are C1=35.0, C2=0.5, as well as defaults). We use CRFsuite (Okazaki, 2007) with label weighting by Sampo Pyysalo: https://github.com/spyysalo/crfsuite ular baseline dataset. After that, we describe the training of the generation model on our ice hockey corpus and use automatic evaluation metrics to compare against existing references. 4.1 Model Architecture We use a pointer-generation network (Vinyals et al., 2015; Gu et al., 2016; See et al., 2017), where the neural attention mechanism in the encoder-decoder model is adapted to jointly model a probability distribution over words from the known vocabulary, a distribution over words from the input sequence to copy and a probability that controls the copying mechanism. A separate coverage attention vector, a sum of past attention distributions, is maintained to inform the model of its past attention decisions. Such a coverage model is shown to prevent text repetition in generated output (Tu et al., 2016; See et al., 2017). The model is implemented using the OpenNMT-py li"
W19-6125,W04-1013,0,0.0522025,"Missing"
W19-6125,P16-1008,0,0.0138748,"hitecture We use a pointer-generation network (Vinyals et al., 2015; Gu et al., 2016; See et al., 2017), where the neural attention mechanism in the encoder-decoder model is adapted to jointly model a probability distribution over words from the known vocabulary, a distribution over words from the input sequence to copy and a probability that controls the copying mechanism. A separate coverage attention vector, a sum of past attention distributions, is maintained to inform the model of its past attention decisions. Such a coverage model is shown to prevent text repetition in generated output (Tu et al., 2016; See et al., 2017). The model is implemented using the OpenNMT-py library (Klein et al., 2017). The encoder has two bidirectional LSTM layers with 500 hidden units, together with 500-dimensional word embeddings. The decoder has two unidirectional LSTM layers with 500 hidden units. Both encoder and decoder apply a dropout of 0.3 between LSTM layers. 4.2 Baseline Experiments on the E2E Dataset To demonstrate the performance of our generation model architecture, we report results on a known dataset with published baselines, namely the E2E NLG Challenge (Duˇsek et al., 2018) on end-to-end natural"
W19-6125,H05-1042,0,\N,Missing
W19-6125,P02-1040,0,\N,Missing
W19-6125,W07-0734,0,\N,Missing
W19-6125,P17-4012,0,\N,Missing
W19-6125,P17-1099,0,\N,Missing
W19-6125,D17-1239,0,\N,Missing
W19-6125,W17-3528,0,\N,Missing
W19-6125,D18-1356,0,\N,Missing
W19-6125,K18-2013,1,\N,Missing
W19-6125,W18-6557,0,\N,Missing
W19-6125,D18-1422,0,\N,Missing
W19-6204,W19-4825,0,0.185099,"nt attractors, i.e. an intervening subordinate clause with opposite number of the subject. BERT is also shown to perform well on the agreement task even if tokens are randomly substituted from the same part-of-speech category, making the input semantically meaningless while preserving the syntactic structure. Similarly, Ettinger (2019) evaluates the BERT model on several English psycholinguistic datasets, where the model is shown generally being able to distinguish a good completion from a bad one, while still failing in some more complex categories, for example being insensitive to negation. Lin et al. (2019) uses a diagnostic classifier to study to which extent syntactic or positional information can be predicted from the English BERT embeddings, and how this information is carried through the different layers. The multilingual BERT model is studied in the context of zero-shot cross-lingual transfer, where it is shown to perform competitively to other transfer models. (Pires et al., 2019; Wu and Dredze, 2019) Text generation with BERT is introduced by Wang and Cho (2019), who demonstrate several different algorithms to generate language with a BERT model. They demonstrate that BERT even though no"
W19-6204,L16-1262,1,0.877294,"Missing"
W19-6204,P19-1452,0,0.069369,"Missing"
W19-6204,D19-1077,0,0.0291987,"s, where the model is shown generally being able to distinguish a good completion from a bad one, while still failing in some more complex categories, for example being insensitive to negation. Lin et al. (2019) uses a diagnostic classifier to study to which extent syntactic or positional information can be predicted from the English BERT embeddings, and how this information is carried through the different layers. The multilingual BERT model is studied in the context of zero-shot cross-lingual transfer, where it is shown to perform competitively to other transfer models. (Pires et al., 2019; Wu and Dredze, 2019) Text generation with BERT is introduced by Wang and Cho (2019), who demonstrate several different algorithms to generate language with a BERT model. They demonstrate that BERT even though not being trained on an explicit language generation objective, is capable of generating coherent, varied language. Language English German Danish Finnish Nor. (Bokm˚al) Nor. (Nynorsk) Swedish BERT mono multi mono multi multi multi multi multi multi Test acc. 86.03 87.82 97.27 95.29 89.96 93.20 93.67 94.44 93.00 Baseline 54.93 54.44 69.61 69.19 53.25 50.54 56.19 53.18 62.09 Table 1: Diagnostic classifier res"
