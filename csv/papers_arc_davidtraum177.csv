2020.lrec-1.86,Dialogue-{AMR}: {A}bstract {M}eaning {R}epresentation for Dialogue,2020,-1,-1,8,0.28339,5184,claire bonial,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper describes a schema that enriches Abstract Meaning Representation (AMR) in order to provide a semantic representation for facilitating Natural Language Understanding (NLU) in dialogue systems. AMR offers a valuable level of abstraction of the propositional content of an utterance; however, it does not capture the illocutionary force or speaker{'}s intended contribution in the broader dialogue context (e.g., make a request or ask a question), nor does it capture tense or aspect. We explore dialogue in the domain of human-robot interaction, where a conversational robot is engaged in search and navigation tasks with a human partner. To address the limitations of standard AMR, we develop an inventory of speech acts suitable for our domain, and present {``}Dialogue-AMR{''}, an enhanced AMR that represents not only the content of an utterance, but the illocutionary force behind it, as well as tense and aspect. To showcase the coverage of the schema, we use both manual and automatic methods to construct the {``}DialAMR{''} corpus{---}a corpus of human-robot dialogue annotated with standard AMR and our enriched Dialogue-AMR schema. Our automated methods can be used to incorporate AMR into a larger NLU pipeline supporting human-robot dialogue."
2020.lrec-1.91,Predicting Ratings of Real Dialogue Participants from Artificial Data and Ratings of Human Dialogue Observers,2020,-1,-1,4,0,16796,kallirroi georgila,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We collected a corpus of dialogues in a Wizard of Oz (WOz) setting in the Internet of Things (IoT) domain. We asked users participating in these dialogues to rate the system on a number of aspects, namely, intelligence, naturalness, personality, friendliness, their enjoyment, overall quality, and whether they would recommend the system to others. Then we asked dialogue observers, i.e., Amazon Mechanical Turkers (MTurkers), to rate these dialogues on the same aspects. We also generated simulated dialogues between dialogue policies and simulated users and asked MTurkers to rate them again on the same aspects. Using linear regression, we developed dialogue evaluation functions based on features from the simulated dialogues and the MTurkers{'} ratings, the WOz dialogues and the MTurkers{'} ratings, and the WOz dialogues and the WOz participants{'} ratings. We applied all these dialogue evaluation functions to a held-out portion of our WOz dialogues, and we report results on the predictive power of these different types of dialogue evaluation functions. Our results suggest that for three conversational aspects (intelligence, naturalness, overall quality) just training evaluation functions on simulated data could be sufficient."
2020.lrec-1.92,Which Model Should We Use for a Real-World Conversational Dialogue System? a Cross-Language Relevance Model or a Deep Neural Net?,2020,-1,-1,3,0,16799,seyed alavi,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We compare two models for corpus-based selection of dialogue responses: one based on cross-language relevance with a cross-language LSTM model. Each model is tested on multiple corpora, collected from two different types of dialogue source material. Results show that while the LSTM model performs adequately on a very large corpus (millions of utterances), its performance is dominated by the cross-language relevance model for a more moderate-sized corpus (ten thousands of utterances)."
2020.lrec-1.334,Exploring a {C}hoctaw Language Corpus with Word Vectors and Minimum Distance Length,2020,-1,-1,4,0,17329,jacqueline brixey,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This work introduces additions to the corpus ChoCo, a multimodal corpus for the American indigenous language Choctaw. Using texts from the corpus, we develop new computational resources by using two off-the-shelf tools: word2vec and Linguistica. Our work illustrates how these tools can be successfully implemented with a small corpus."
2020.lrec-1.797,Evaluation of Off-the-shelf Speech Recognizers Across Diverse Dialogue Domains,2020,-1,-1,4,0,16796,kallirroi georgila,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We evaluate several publicly available off-the-shelf (commercial and research) automatic speech recognition (ASR) systems across diverse dialogue domains (in US-English). Our evaluation is aimed at non-experts with limited experience in speech recognition. Our goal is not only to compare a variety of ASR systems on several diverse data sets but also to measure how much ASR technology has advanced since our previous large-scale evaluations on the same data sets. Our results show that the performance of each speech recognizer can vary significantly depending on the domain. Furthermore, despite major recent progress in ASR technology, current state-of-the-art speech recognizers perform poorly in domains that require special vocabulary and language models, and under noisy conditions. We expect that our evaluation will prove useful to ASR consumers and dialogue system designers."
W19-3322,Augmenting {A}bstract {M}eaning {R}epresentation for Human-Robot Dialogue,2019,0,1,6,0.295571,5184,claire bonial,Proceedings of the First International Workshop on Designing Meaning Representations,0,"We detail refinements made to Abstract Meaning Representation (AMR) that make the representation more suitable for supporting a situated dialogue system, where a human remotely controls a robot for purposes of search and rescue and reconnaissance. We propose 36 augmented AMRs that capture speech acts, tense and aspect, and spatial information. This linguistic information is vital for representing important distinctions, for example whether the robot has moved, is moving, or will move. We evaluate two existing AMR parsers for their performance on dialogue data. We also outline a model for graph-to-graph conversion, in which output from AMR parsers is converted into our refined AMRs. The design scheme presented here, though task-specific, is extendable for broad coverage of speech acts using AMR in future task-independent work."
W19-1705,A Blissymbolics Translation System,2019,0,0,2,0,24808,usman sohail,Proceedings of the Eighth Workshop on Speech and Language Processing for Assistive Technologies,0,"Blissymbolics (Bliss) is a pictographic writing system that is used by people with communication disorders. Bliss attempts to create a writing system that makes words easier to distinguish by using pictographic symbols that encapsulate meaning rather than sound, as the English alphabet does for example. Users of Bliss rely on human interpreters to use Bliss. We created a translation system from Bliss to natural English with the hopes of decreasing the reliance on human interpreters by the Bliss community. We first discuss the basic rules of Blissymbolics. Then we point out some of the challenges associated with developing computer assisted tools for Blissymbolics. Next we talk about our ongoing work in developing a translation system, including current limitations, and future work. We conclude with a set of examples showing the current capabilities of our translation system."
W18-5012,Consequences and Factors of Stylistic Differences in Human-Robot Dialogue,2018,0,0,7,1,16783,stephanie lukin,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"This paper identifies stylistic differences in instruction-giving observed in a corpus of human-robot dialogue. Differences in verbosity and structure (i.e., single-intent vs. multi-intent instructions) arose naturally without restrictions or prior guidance on how users should speak with the robot. Different styles were found to produce different rates of miscommunication, and correlations were found between style differences and individual user variation, trust, and interaction experience with the robot. Understanding potential consequences and factors that influence style can inform design of dialogue systems that are robust to natural variation from human users."
P18-4016,{S}cout{B}ot: A Dialogue System for Collaborative Navigation,2018,0,3,10,1,16783,stephanie lukin,"Proceedings of {ACL} 2018, System Demonstrations",0,"ScoutBot is a dialogue interface to physical and simulated robots that supports collaborative exploration of environments. The demonstration will allow users to issue unconstrained spoken language commands to ScoutBot. ScoutBot will prompt for clarification if the user{'}s instruction needs additional input. It is trained on human-robot dialogue collected from Wizard-of-Oz experiments, where robot responses were initiated by a human wizard in previous interactions. The demonstration will show a simulated ground robot (Clearpath Jackal) in a simulated environment supported by ROS (Robot Operating System)."
L18-1017,Dialogue Structure Annotation for Multi-Floor Interaction,2018,0,2,1,1,16786,david traum,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1463,"The Niki and Julie Corpus: Collaborative Multimodal Dialogues between Humans, Robots, and Virtual Agents",2018,0,0,8,0.634409,16785,ron artstein,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1629,Identification of Personal Information Shared in Chat-Oriented Dialogue,2018,0,0,2,0,30196,sarah fillwock,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-5521,"{D}ial{P}ort, Gone Live: An Update After A Year of Development",2017,6,3,7,0,3380,kyusong lee,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,DialPort collects user data for connected spoken dialog systems. At present six systems are linked to a central portal that directs the user to the applicable system and suggests systems that the user may be interested in. User data has started to flow into the system.
W17-2808,Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task,2017,27,4,9,0,1549,matthew marge,Proceedings of the First Workshop on Language Grounding for Robotics,0,"Robot-directed communication is variable, and may change based on human perception of robot capabilities. To collect training data for a dialogue system and to investigate possible communication changes over time, we developed a Wizard-of-Oz study that (a) simulates a robot{'}s limited understanding, and (b) collects dialogues where human participants build a progressively better mental model of the robot{'}s understanding. With ten participants, we collected ten hours of human-robot dialogue. We analyzed the structure of instructions that participants gave to a remote robot before it responded. Our findings show a general initial preference for including metric information (e.g., move forward 3 feet) over landmarks (e.g., move to the desk) in motion commands, but this decreased over time, suggesting changes in perception."
W16-3640,Analyzing the Effect of Entrainment on Dialogue Acts,2016,18,2,4,0,1445,masahiro mizukami,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Entrainment is a factor in dialogue that affects not only human-human but also human-machine interaction. While entrainment on the lexical level is well documented, less is known about how entrainment affects dialogue on a more abstract, structural level. In this paper, we investigate the effect of entrainment on dialogue acts and on lexical choice given dialogue acts, as well as how entrainment changes during a dialogue. We also define a novel measure of entrainment to measure these various types of entrainment. These results may serve as guidelines for dialogue systems that would like to entrain with users in a similar manner."
N16-3007,New Dimensions in Testimony Demonstration,2016,12,1,6,0.737887,16785,ron artstein,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"New Dimensions in Testimony is a prototype dialogue system that allows users to conduct a conversation with a real person who is not available for conversation in real time. Users talk to a persistent representation of Holocaust survivor Pinchas Gutter on a screen, while a dialogue agent selects appropriate responses to user utterances from a set of pre-recorded video statements, simulating a live conversation. The technology is similar to existing conversational agents, but to our knowledge this is the first system to portray a real person. The demonstration will show the system on a range of screens (from mobile phones to large TVs), and allow users to have individual conversations with Mr. Gutter."
L16-1018,Towards a Multi-dimensional Taxonomy of Stories in Dialogue,2016,0,3,2,0,34752,kathryn collins,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we present a taxonomy of stories told in dialogue. We based our scheme on prior work analyzing narrative structure and method of telling, relation to storyteller identity, as well as some categories particular to dialogue, such as how the story gets introduced. Our taxonomy currently has 5 major dimensions, with most having sub-dimensions - each dimension has an associated set of dimension-specific labels. We adapted an annotation tool for this taxonomy and have annotated portions of two different dialogue corpora, Switchboard and the Distress Analysis Interview Corpus. We present examples of some of the tags and concepts with stories from Switchboard, and some initial statistics of frequencies of the tags."
L16-1435,Towards Automatic Identification of Effective Clues for Team Word-Guessing Games,2016,0,1,2,1,30105,eli pincus,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Team word-guessing games where one player, the clue-giver, gives clues attempting to elicit a target-word from another player, the receiver, are a popular form of entertainment and also used for educational purposes. Creating an engaging computational agent capable of emulating a talented human clue-giver in a timed word-guessing game depends on the ability to provide effective clues (clues able to elicit a correct guess from a human receiver). There are many available web resources and databases that can be mined for the raw material for clues for target-words; however, a large number of those clues are unlikely to be able to elicit a correct guess from a human guesser. In this paper, we propose a method for automatically filtering a clue corpus for effective clues for an arbitrary target-word from a larger set of potential clues, using machine learning on a set of features of the clues, including point-wise mutual information between a clue{'}s constituent words and a clue{'}s target-word. The results of the experiments significantly improve the average clue quality over previous approaches, and bring quality rates in-line with measures of human clue quality derived from a corpus of human-human interactions. The paper also introduces the data used to develop this method; audio recordings of people making guesses after having heard the clues being spoken by a synthesized voice."
W15-4605,Reinforcement Learning in Multi-Party Trading Dialog,2015,26,4,4,0,27167,takuya hiraoka,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"In this paper, we apply reinforcement learning (RL) to a multi-party trading scenario where the dialog system (learner) trades with one, two, or three other agents. We experiment with different RL algorithms and reward functions. The negotiation strategy of the learner is learned through simulated dialog with trader simulators. In our experiments, we evaluate how the performance of the learner varies depending on the RL algorithm used and the number of traders. Our results show that (1) even in simple multi-party trading dialog tasks, learning an effective negotiation policy is a very hard problem; and (2) the use of neural fitted Q iteration combined with an incremental reward function produces negotiation policies as effective or even better than the policies of two strong hand-crafted baselines."
W15-4613,Which Synthetic Voice Should {I} Choose for an Evocative Task?,2015,16,4,3,1,30105,eli pincus,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We explore different evaluation methods for 4 different synthetic voices and 1 human voice. We investigate whether intelligibility, naturalness, or likability of a voice is correlated to the voicexe2x80x99s evocative function potential, a measure of the voicexe2x80x99s ability to evoke an intended reaction from the listener. We also investigate the extent to which naturalness and likability ratings vary depending on whether or not exposure to a voice is extended and continuous vs. short-term and sporadic (interleaved with other voices). Finally, we show that an automatic test can replace the standard intelligibility tests for text-to-speech (TTS) systems, which eliminates the need to hire humans to perform transcription tasks saving both time and money."
W15-4629,Evaluating Spoken Dialogue Processing for Time-Offset Interaction,2015,10,11,1,1,16786,david traum,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper presents the first evaluation of a full automated prototype system for time-offset interaction, that is, conversation between a live person and recordings of someone who is not temporally copresent. Speech recognition reaches word error rates as low as 5% with generalpurpose language models and 19% with domain-specific models, and language understanding can identify appropriate direct responses to 60xe2x80x9066% of user utterances while keeping errors to 10xe2x80x9016% (the remainder being indirect, or off-topic responses). This is sufficient to enable a natural flow and relatively open-ended conversations, with a collection of under 2000 recorded statements."
W15-4630,The Real Challenge 2014: Progress and Prospects,2015,3,0,4,0,1592,maxine eskenazi,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"The REAL Challenge took place for the first time in 2014, with a long term goal of creating streams of real data that the research community can use, by fostering the creation of systems that are capable of attracting real users. A novel approach is to have high school and undergraduate students devise the types of applications that would attract many real users and that need spoken interaction. The projects are presented to researchers from the spoken dialog research community and the researchers and students work together to refine and develop the ideas. Eleven projects were presented at the first workshop. Many of them have found mentors to help in the next stages of the projects. The students have also brought out issues in the use of speech for real applications. Those issues involve privacy and significant personalization of the applications. While long-term impact of the challenge remains to be seen, the challenge has already been a success at its immediate aims of bringing new ideas and new researchers into the community, and serves as a model for related outreach efforts."
W14-4325,Initiative Taking in Negotiation,2014,17,2,2,0,22933,elnaz nouri,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"We examine the relationship between initiative behavior in negotiation dialogues and the goals and outcomes of the negotiation. We propose a novel annotation scheme for dialogue initiative, including four labels for initiative and response behavior in a dialogue turn. We annotate an existing human-human negotiation dataset, and use initiative-based features to try to predict both negotiation goal and outcome, comparing our results to prior work using other (non-initiative) features sets. Results show that combining initiative features with other features leads to improvements over either set and a majority class baseline."
W14-4333,{SAWDUST}: a Semi-Automated Wizard Dialogue Utterance Selection Tool for domain-independent large-domain dialogue,2014,10,1,2,1,10831,sudeep gandhe,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"We present a tool that allows human wizards to select appropriate response utterances for a given dialogue context from a set of utterances observed in a dialogue corpus. Such a tool can be used in Wizard-of-Oz studies and for collecting data which can be used for training and/or evaluating automatic dialogue models. We also propose to incorporate such automatic dialogue models back into the tool as an aid in selecting utterances from a large dialogue corpus. The tool allows a user to rank candidate utterances for selection according to these automatic models. 1 Motivation Dialogue corpora play an increasingly important role as a resource for dialogue system creation. In addition to its traditional roles, such as training language models for speech recognition and natural language understanding, the dialogue corpora can be directly used for the selection approach to response formation (Gandhe and Traum, 2010). In the selection approach, the response is formulated by simply picking the appropriate utterance from a set of previously observed utterances. This approach is used in many wizard of oz systems, where the wizard presses a button to select an utterance, as well as in many automated"
W14-4334,A Demonstration of Dialogue Processing in {S}im{S}ensei Kiosk,2014,7,1,5,1,33320,fabrizio morbini,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"This demonstration highlights the dialogue processing in SimSensei Kiosk, a virtual human dialogue system that conducts interviews related to psychological distress conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD). The dialogue processing in SimSensei Kiosk allows the system to conduct coherent spoken interviews of human users that are 15-25 minutes in length, and in which users feel comfortable talking and openly sharing information. We present the design of the individual dialogue components, and show examples of natural conversation flow between the system and users, including expressions of empathy, follow-up responses and continuation prompts, and turn-taking."
P14-1047,Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies,2014,40,18,3,0.624487,16796,kallirroi georgila,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We use single-agent and multi-agent Reinforcement Learning (RL) for learning dialogue policies in a resource allocation negotiation scenario. Two agents learn concurrently by interacting with each other without any need for simulated users (SUs) to train against or corpora to learn from. In particular, we compare the Qlearning, Policy Hill-Climbing (PHC) and Win or Learn Fast Policy Hill-Climbing (PHC-WoLF) algorithms, varying the scenario complexity (state space size), the number of training episodes, the learning rate, and the exploration rate. Our results show that generally Q-learning fails to converge whereas PHC and PHC-WoLF always converge and perform similarly. We also show that very high gradually decreasing exploration rates are required for convergence. We conclude that multiagent RL of dialogue policies is a promising alternative to using single-agent RL and SUs or learning directly from corpora."
gratch-etal-2014-distress,The Distress Analysis Interview Corpus of human and computer interviews,2014,30,95,11,0,4007,jonathan gratch,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Distress Analysis Interview Corpus (DAIC) contains clinical interviews designed to support the diagnosis of psychological distress conditions such as anxiety, depression, and post traumatic stress disorder. The interviews are conducted by humans, human controlled agents and autonomous agents, and the participants include both distressed and non-distressed individuals. Data collected include audio and video recordings and extensive questionnaire responses; parts of the corpus have been transcribed and annotated for a variety of verbal and non-verbal features. The corpus has been used to support the creation of an automated interviewer agent, and for research on the automatic identification of psychological distress."
W13-4032,Verbal indicators of psychological distress in interactive dialogue with a virtual human,2013,16,28,5,1,31518,david devault,Proceedings of the {SIGDIAL} 2013 Conference,0,"We explore the presence of indicators of psychological distress in the linguistic behavior of subjects in a corpus of semistructured virtual human interviews. At the level of aggregate dialogue-level features, we identify several significant differences between subjects with depression and PTSD when compared to nondistressed subjects. At a more fine-grained level, we show that significant differences can also be found among features that represent subject behavior during specific moments in the dialogues. Finally, we present statistical classification results that suggest the potential for automatic assessment of psychological distress in individual interactions with a virtual human dialogue system."
W13-4039,Surface Text based Dialogue Models for Virtual Humans,2013,18,5,2,1,10831,sudeep gandhe,Proceedings of the {SIGDIAL} 2013 Conference,0,We present virtual human dialogue models which primarily operate on the surface text level and can be extended to incorporate additional information state annotations such as topics or results from simpler models. We compare these models with previously proposed models as well as two human-level upper baselines. The models are evaluated by collecting appropriateness judgments from human judges for responses generated for a set of fixed dialogue contexts. Our results show that the best performing models achieve close to human-level performance and require only surface text dialogue transcripts to train.
W13-4061,{R}oundtable: An Online Framework for Building Web-based Conversational Agents,2013,1,3,6,0,38438,eric forbell,Proceedings of the {SIGDIAL} 2013 Conference,0,None
W13-4064,Which {ASR} should {I} choose for my dialogue system?,2013,36,36,9,1,33320,fabrizio morbini,Proceedings of the {SIGDIAL} 2013 Conference,0,"We present an analysis of several publicly available automatic speech recognizers (ASRs) in terms of their suitability for use in different types of dialogue systems. We focus in particular on cloud based ASRs that recently have become available to the community. We include features of ASR systems and desiderata and requirements for different dialogue systems, taking into account the dialogue genre, type of user, and other features. We then present speech recognition results for six different dialogue systems. The most interesting result is that different ASR systems perform best on the data sets. We also show that there is an improvement over a previous generation of recognizers on some of these data sets. We also investigate language understanding (NLU) on the ASR output, and explore the relationship between ASR and NLU performance."
N13-1129,A method for the approximation of incremental understanding of explicit utterance meaning using predictive models in finite domains,2013,15,3,2,1,31518,david devault,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper explores the relationship between explicit and predictive models of incremental speech understanding in a dialogue system that supports a finite set of user utterance meanings. We present a method that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches."
W12-1611,Reinforcement Learning of Question-Answering Dialogue Policies for Virtual Museum Guides,2012,23,24,4,0,38434,teruhisa misu,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We use Reinforcement Learning (RL) to learn question-answering dialogue policies for a real-world application. We analyze a corpus of interactions of museum visitors with two virtual characters that serve as guides at the Museum of Science in Boston, in order to build a realistic model of user behavior when interacting with these characters. A simulated user is built based on this model and used for learning the dialogue policy of the virtual characters using RL. Our learned policy outperforms two baselines (including the original dialogue policy that was used for collecting the corpus) in a simulation setting."
W12-1618,A Demonstration of Incremental Speech Understanding and Confidence Estimation in a Virtual Human Dialogue System,2012,10,0,2,1,31518,david devault,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This demonstration highlights some emerging capabilities for incremental speech understanding and processing in virtual human dialogue systems. This work is part of an ongoing effort that aims to enable realistic spoken dialogue with virtual humans in multi-party negotiation scenarios (Pluss et al., 2011; Traum et al., 2008). In these negotiation scenarios, ideally the virtual humans should demonstrate fluid turn-taking, complex reasoning, and appropriate responses based on factors like trust and emotions. An important component in achieving this naturalistic behavior is for the virtual humans to begin to understand and in some cases respond in real time to users' speech, as the users are speaking (DeVault et al., 2011b). These responses could include relatively straightforward turn management behaviors, like having a virtual human recognize when it is being addressed and turn to look at the user. They could also include more complex responses such as emotional reactions to what users are saying."
W12-1620,A Mixed-Initiative Conversational Dialogue System for Healthcare,2012,6,17,5,1,33320,fabrizio morbini,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We present a mixed initiative conversational dialogue system designed to address primarily mental health care concerns related to military deployment. It is supported by a new information-state based dialogue manager, FLoReS (Forward-Looking, Reward Seeking dialogue manager), that allows both advanced, flexible, mixed initiative interaction, and efficient policy creation by domain experts. To easily reach its target population this dialogue system is accessible as a web application."
N12-3007,Incremental Speech Understanding in a Multi-Party Virtual Human Dialogue System,2012,11,4,2,1,31518,david devault,Proceedings of the Demonstration Session at the Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This demonstration highlights some emerging capabilities for incremental speech understanding and processing in virtual human dialogue systems. This work is part of an ongoing effort that aims to enable realistic spoken dialogue with virtual humans in multi-party negotiation scenarios (Pluss et al., 2011; Traum et al., 2008b). These scenarios are designed to allow trainees to practice their negotiation skills by engaging in face-to-face spoken negotiation with one or more virtual humans."
bunt-etal-2012-iso,{ISO} 24617-2: A semantically-based standard for dialogue annotation,2012,14,51,8,0.145504,16745,harry bunt,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper summarizes the latest, final version of ISO standard 24617-2 ``Semantic annotation framework, Part 2: Dialogue acts''''''''. Compared to the preliminary version ISO DIS 24617-2:2010, described in Bunt et al. (2010), the final version additionally includes concepts for annotating rhetorical relations between dialogue units, defines a full-blown compositional semantics for the Dialogue Act Markup Language DiAML (resulting, as a side-effect, in a different treatment of functional dependence relations among dialogue acts and feedback dependence relations); and specifies an optimally transparent XML-based reference format for the representation of DiAML annotations, based on the systematic application of the notion of `ideal concrete syntax'. We describe these differences and briefly discuss the design and implementation of an incremental method for dialogue act recognition, which proves the usability of the ISO standard for automatic dialogue annotation."
georgila-etal-2012-practical,Practical Evaluation of Human and Synthesized Speech for Virtual Human Dialogue Systems,2012,14,10,4,0.919974,16796,kallirroi georgila,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The current practice in virtual human dialogue systems is to use professional human recordings or limited-domain speech synthesis. Both approaches lead to good performance but at a high cost. To determine the best trade-off between performance and cost, we perform a systematic evaluation of human and synthesized voices with regard to naturalness, conversational aspect, and likability. We vary the type (in-domain vs. out-of-domain), length, and content of utterances, and take into account the age and native language of raters as well as their familiarity with speech synthesis. We present detailed results from two studies, a pilot one and one run on Amazon's Mechanical Turk. Our results suggest that a professional human voice can supersede both an amateur human voice and synthesized voices. Also, a high-quality general-purpose voice or a good limited-domain voice can perform better than amateur human recordings. We do not find any significant differences between the performance of a high-quality general-purpose voice and a limited-domain voice, both trained with speech recorded by actors. As expected, the high-quality general-purpose voice is rated higher than the limited-domain voice for out-of-domain sentences and lower for in-domain sentences. There is also a trend for long or negative-content utterances to receive lower ratings."
aggarwal-etal-2012-twins,The Twins Corpus of Museum Visitor Questions,2012,8,8,7,0,43100,priti aggarwal,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The Twins corpus is a collection of utterances spoken in interactions with two virtual characters who serve as guides at the Museum of Science in Boston. The corpus contains about 200,000 spoken utterances from museum visitors (primarily children) as well as from trained handlers who work at the museum. In addition to speech recordings, the corpus contains the outputs of speech recognition performed at the time of utterance as well as the system interpretation of the utterances. Parts of the corpus have been manually transcribed and annotated for question interpretation. The corpus has been used for improving performance of the museum characters and for a variety of research projects, such as phonetic-based Natural Language Understanding, creation of conversational characters from text resources, dialogue policy learning, and research on patterns of user interaction. It has the potential to be used for research on children's speech and on language used when talking to a virtual human."
W11-2030,An Annotation Scheme for Cross-Cultural Argumentation and Persuasion Dialogues,2011,30,6,5,0.919974,16796,kallirroi georgila,Proceedings of the {SIGDIAL} 2011 Conference,0,"We present a novel annotation scheme for cross-cultural argumentation and persuasion dialogues. This scheme is an adaptation of existing coding schemes on negotiation, following a review of literature on cross-cultural differences in negotiation styles. The scheme has been refined through application to coding both two-party and multi-party negotiation dialogues in three different domains, and is general enough to be applicable to different domains with few if any extensions. Dialogues annotated with the scheme have been used to successfully learn culture-specific dialogue policies for argumentation and persuasion."
W11-2044,Rapid Development of Advanced Question-Answering Characters by Non-experts,2011,9,4,4,1,10831,sudeep gandhe,Proceedings of the {SIGDIAL} 2011 Conference,0,"We demonstrate a dialogue system and the accompanying authoring tools that are designed to allow authors with little or no experience in building dialogue systems to rapidly build advanced question-answering characters. To date seven such virtual characters have been built by non-experts using this architecture and tools. Here we demonstrate one such character, PFC Sean Avery, which was developed by a non-expert in 3 months."
W10-4333,Don{'}t tell anyone! Two Experiments on Gossip Conversations,2010,14,2,3,0,45094,jenny brusk,Proceedings of the {SIGDIAL} 2010 Conference,0,"The purpose of this study is to get a working definition that matches people's intuitive notion of gossip and is sufficiently precise for computational implementation. We conducted two experiments investigating what type of conversations people intuitively understand and interpret as gossip, and whether they could identify three proposed constituents of gossip conversations: third person focus, pejorative evaluation and substantiating behavior. The results show that (1) conversations are very likely to be considered gossip if all elements are present, no intimate relationships exist between the participants, and the person in focus is unambiguous. (2) Conversations that have at most one gossip element are not considered gossip. (3) Conversations that lack one or two elements or have an ambiguous element lead to inconsistent judgments."
W10-4345,"{I}{'}ve said it before, and {I}{'}ll say it again: An empirical investigation of the upper bound of the selection approach to dialogue",2010,11,8,2,1,10831,sudeep gandhe,Proceedings of the {SIGDIAL} 2010 Conference,0,"We perform a study of existing dialogue corpora to establish the theoretical maximum performance of the selection approach to simulating human dialogue behavior in unseen dialogues. This maximum is the proportion of test utterances for which an exact or approximate match exists in the corresponding training corpus. The results indicate that some domains seem quite suitable for a corpus-based selection approach, with over half of the test utterances having been seen before in the corpus, while other domains show much more novelty compared to previous dialogues."
N10-2009,Interpretation of Partial Utterances in Virtual Human Dialogue Systems,2010,8,6,3,0.290586,6910,kenji sagae,Proceedings of the {NAACL} {HLT} 2010 Demonstration Session,0,"Dialogue systems typically follow a rigid pace of interaction where the system waits until the user has finished speaking before producing a response. Interpreting user utterances before they are completed allows a system to display more sophisticated conversational behavior, such as rapid turn-taking and appropriate use of backchannels and interruptions. We demonstrate a natural language understanding approach for partial utterances, and its use in a virtual human dialogue system that can often complete a user's utterances in real time."
bunt-etal-2010-towards,Towards an {ISO} Standard for Dialogue Act Annotation,2010,22,96,12,0.145504,16745,harry bunt,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes an ISO project which aims at developing a standard for annotating spoken and multimodal dialogue with semantic information concerning the communicative functions of utterances, the kind of semantic content they address, and their relations with what was said and done earlier in the dialogue. The project, ISO 24617-2 ''``Semantic annotation framework, Part 2: Dialogue acts'''', is currently at DIS stage. The proposed annotation schema distinguishes 9 orthogonal dimensions, allowing each functional segment in dialogue to have a function in each of these dimensions, thus accounting for the multifunctionality that utterances in dialogue often have. A number of core communicative functions is defined in the form of ISO data categories, available at http://semantic-annotation.uvt.nl/dialogue-acts/iso-datcats.pdf; they are divided into ''``dimension-specific'''' functions, which can be used only in a particular dimension, such as Turn Accept in the Turn Management dimension, and ''``general-purpose'''' functions, which can be used in any dimension, such as Inform and Request. An XML-based annotation language, ''``DiAML'''' is defined, with an abstract syntax, a semantics, and a concrete syntax."
leuski-traum-2010-npceditor,{NPCE}ditor: A Tool for Building Question-Answering Characters,2010,10,24,2,1,16800,anton leuski,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"NPCEditor is a system for building and deploying virtual characters capable of engaging a user in spoken dialog on a limited domain. The dialogue may take any form as long as the character responses can be specified a priori. For example, NPCEditor has been used for constructing question answering characters where a user asks questions and the character responds, but other scenarios are possible. At the core of the system is a state of the art statistical language classification technology for mapping from user's text input to system responses. NPCEditor combines the classifier with a database that stores the character information and relevant language data, a server that allows the character designer to deploy the completed characters, and a user-friendly editor that helps the designer to accomplish both character design and deployment tasks. In the paper we define the overall system architecture, describe individual NPCEditor components, and guide the reader through the steps of building a virtual character."
robinson-etal-2010-dialogues,Dialogues in Context: An Objective User-Oriented Evaluation Approach for Virtual Human Dialogue,2010,0,6,3,1,46244,susan robinson,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"As conversational agents are now being developed to encounter more complex dialogue situations it is increasingly difficult to find satisfactory methods for evaluating these agents. Task-based measures are insufficient where there is no clearly defined task. While user-based evaluation methods may give a general sense of the quality of an agent's performance, they shed little light on the relative quality or success of specific features of dialogue that are necessary for system improvement. This paper examines current dialogue agent evaluation practices and motivates the need for a more detailed approach for defining and measuring the quality of dialogues between agent and user. We present a framework for evaluating the dialogue competence of artificial agents involved in complex and underspecified tasks when conversing with people. A multi-part coding scheme is proposed that provides a qualitative analysis of human utterances, and rates the appropriateness of the agent's responses to these utterances. The scheme is outlined, and then used to evaluate Staff Duty Officer Moleno, a virtual guide in Second Life."
yao-etal-2010-practical,Practical Evaluation of Speech Recognizers for Virtual Human Dialogue Systems,2010,15,8,6,0,37412,xuchen yao,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We perform a large-scale evaluation of multiple off-the-shelf speech recognizers across diverse domains for virtual human dialogue systems. Our evaluation is aimed at speech recognition consumers and potential consumers with limited experience with readily available recognizers. We focus on practical factors to determine what levels of performance can be expected from different available recognizers in various projects featuring different types of conversational utterances. Our results show that there is no single recognizer that outperforms all other recognizers in all domains. The performance of each recognizer may vary significantly depending on the domain, the size and perplexity of the corpus, the out-of-vocabulary rate, and whether acoustic and language model adaptation has been used or not. We expect that our evaluation will prove useful to other speech recognition consumers, especially in the dialogue community, and will shed some light on the key problem in spoken dialogue systems of selecting the most suitable available speech recognition system for a particular application, and what impact training will have."
W09-3902,Can {I} Finish? Learning When to Respond to Incremental Interpretation Results in Interactive Dialogue,2009,20,60,3,1,31518,david devault,Proceedings of the {SIGDIAL} 2009 Conference,0,"We investigate novel approaches to responsive overlap behaviors in dialogue systems, opening possibilities for systems to interrupt, acknowledge or complete a user's utterance while it is still in progress. Our specific contributions are a method for determining when a system has reached a point of maximal understanding of an ongoing user utterance, and a prototype implementation that shows how systems can use this ability to strategically initiate system completions of user utterances. More broadly, this framework facilitates the implementation of a range of overlap behaviors that are common in human dialogue, but have been largely absent in dialogue systems."
W09-3704,A computational account of comparative implicatures for a spoken dialogue agent,2009,13,7,2,0,1052,luciana benotti,Proceedings of the Eight International Conference on Computational Semantics,0,"Comparative constructions are common in dialogue, especially in negotiative dialogue where a choice must be made between different options, and options must be evaluated using multiple metrics. Comparatives explicitly assert a relationship between two elements along a scale, but they may also implicate positions on the scale especially if constraints on the possible values are present. Dialogue systems must often understand more from a comparative than the explicit assertion in order to understand why the comparative was uttered. In this paper we examine the pragmatic meaning of comparative constructions from a computational perspective."
U09-1001,{HCSN}et Plenary Talk: Spoken Dialogue Models for Virtual Humans,2009,0,0,1,1,16786,david traum,Proceedings of the Australasian Language Technology Association Workshop 2009,0,None
N09-2014,Towards Natural Language Understanding of Partial Speech Recognition Results in Dialogue Systems,2009,6,37,4,0.290586,6910,kenji sagae,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,We investigate natural language understanding of partial speech recognition results to equip a dialogue system with incremental language processing capabilities for more realistic human-computer conversations. We show that relatively high accuracy can be achieved in understanding of spontaneous utterances before utterances are completed.
W08-1111,Practical Grammar-Based {NLG} from Examples,2008,25,19,2,1,31518,david devault,Proceedings of the Fifth International Natural Language Generation Conference,0,"We present a technique that opens up grammar-based generation to a wider range of practical applications by dramatically reducing the development costs and linguistic expertise that are required. Our method infers the grammatical resources needed for generation from a set of declarative examples that link surface expressions directly to the application's available semantic representations. The same examples further serve to optimize a run-time search strategy that generates the best output that can be found within an application-specific time frame. Our method offers substantially lower development costs than hand-crafted grammars for application-specific NLG, while maintaining high output quality and diversity."
W08-0107,Degrees of Grounding Based on Evidence of Understanding,2008,16,20,2,1,1546,antonio roque,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"We introduce the Degrees of Grounding model, which defines the extent to which material being discussed in a dialogue has been grounded. This model has been developed and evaluated by a corpus analysis, and includes a set of types of evidence of understanding, a set of degrees of groundedness, a set of grounding criteria, and methods for identifying each of these. We describe how this model can be used for dialogue management."
W08-0127,Evaluation Understudy for Dialogue Coherence Models,2008,32,14,2,1,10831,sudeep gandhe,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"Evaluating a dialogue system is seen as a major challenge within the dialogue research community. Due to the very nature of the task, most of the evaluation methods need a substantial amount of human involvement. Following the tradition in machine translation, summarization and discourse coherence modeling, we introduce the the idea of evaluation understudy for dialogue coherence models. Following (Lapata, 2006), we use the information ordering task as a testbed for evaluating dialogue coherence models. This paper reports findings about the reliability of the information ordering task as applied to dialogues. We find that simple n-gram co-occurrence statistics similar in spirit to BLEU (Papineni et al., 2001) correlate very well with human judgments for dialogue coherence"
W08-0130,Making Grammar-Based Generation Easier to Deploy in Dialogue Systems,2008,20,18,2,1,31518,david devault,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"We present a development pipeline and associated algorithms designed to make grammarbased generation easier to deploy in implemented dialogue systems. Our approach realizes a practical trade-off between the capabilities of a system's generation component and the authoring and maintenance burdens imposed on the generation content author for a deployed system. To evaluate our approach, we performed a human rating study with system builders who work on a common largescale spoken dialogue system. Our results demonstrate the viability of our approach and illustrate authoring/performance trade-offs between hand-authored text, our grammar-based approach, and a competing shallow statistical NLG technique."
hartholt-etal-2008-common,A Common Ground for Virtual Humans: Using an Ontology in a Natural Language Oriented Virtual Human Architecture,2008,26,20,3,0,48105,arno hartholt,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"When dealing with large, distributed systems that use state-of-the-art components, individual components are usually developed in parallel. As development continues, the decoupling invariably leads to a mismatch between how these components internally represent concepts and how they communicate these representations to other components: representations can get out of synch, contain localized errors, or become manageable only by a small group of experts for each module. In this paper, we describe the use of an ontology as part of a complex distributed virtual human architecture in order to enable better communication between modules while improving the overall flexibility needed to change or extend the system. We focus on the natural language understanding capabilities of this architecture and the relationship between language and concepts within the entire system in general and the ontology in particular."
robinson-etal-2008-ask,What would you Ask a conversational Agent? Observations of Human-Agent Dialogues in a Museum Setting,2008,7,43,2,1,46244,susan robinson,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Embodied Conversational Agents have typically been constructed for use in limited domain applications, and tested in very specialized environments. Only in recent years have there been more cases of moving agents into wider public applications (e.g.Bell et al., 2003; Kopp et al., 2005). Yet little analysis has been done to determine the differing needs, expectations, and behavior of human users in these environments. With an increasing trend for virtual characters to Âgo publicÂ, we need to expand our understanding of what this entails for the design and capabilities of our characters. This paper explores these issues through an analysis of a corpus that has been collected since December 2006, from interactions with the virtual character Sgt Blackwell at the Cooper Hewitt Museum in New York. The analysis includes 82 hierarchical categories of user utterances, as well as specific observations on user preferences and behaviors drawn from interactions with Blackwell."
W07-1908,Dynamic Movement and Positioning of Embodied Agents in Multiparty Conversations,2007,10,1,2,0,48941,duvsan jan,Proceedings of the Workshop on Embodied Language Processing,0,"For embodied agents to engage in realistic multiparty conversation, they must stand in appropriate places with respect to other agents and the environment. When these factors change, such as an agent joining the conversation, the agents must dynamically move to a new location and/or orientation to accommodate. This paper presents an algorithm for simulating movement of agents based on observed human behavior using techniques developed for pedestrian movement in crowd simulations. We extend a previous group conversation simulation to include an agent motion algorithm. We examine several test cases and show how the simulation generates results that mirror real-life conversation settings."
2007.sigdial-1.6,A Model of Compliance and Emotion for Potentially Adversarial Dialogue Agents,2007,11,23,2,1,1546,antonio roque,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We present a model of compliance, for domains in which a dialogue agent may become adversarial. This model includes a set of emotions and a set of levels of compliance, and strategies for changing these. 1 Overview"
2007.sigdial-1.15,{H}assan: A Virtual Human for Tactical Questioning,2007,8,33,1,1,16786,david traum,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We present Hassan, a virtual human who engages in Tactical Questioning dialogues. We describe the tactical questioning domain, the motivation for this character, the specific architecture and present brief examples and an evaluation."
W06-1303,Building Effective Question Answering Characters,2006,15,88,3,1,16800,anton leuski,Proceedings of the 7th {SIG}dial Workshop on Discourse and Dialogue,0,"In this paper, we describe methods for building and evaluation of limited domain question-answering characters. Several classification techniques are tested, including text classification using support vector machines, language-model based retrieval, and cross-language information retrieval techniques, with the latter having the highest success rate. We also evaluated the effect of speech recognition errors on performance with users, finding that retrieval is robust until recognition reaches over 50% WER."
W06-1313,An Information State-Based Dialogue Manager for Call for Fire Dialogues,2006,-1,-1,2,1,1546,antonio roque,Proceedings of the 7th {SIG}dial Workshop on Discourse and Dialogue,0,None
P05-3023,{T}ransonics: A Practical Speech-to-Speech Translator for {E}nglish-{F}arsi Medical Dialogs,2005,5,15,10,0,50887,robert belvin,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"We briefly describe a two-way speech-to-speech English-Farsi translation system prototype developed for use in doctor-patient interactions. The overarching philosophy of the developers has been to create a system that enables effective communication, rather than focusing on maximizing component-level performance. The discussion focuses on the general approach and evaluation of the system by an independent government evaluation team."
2005.sigdial-1.25,Dealing with Doctors: A Virtual Human for Non-team Interaction,2005,0,4,1,1,16786,david traum,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,None
garg-etal-2004-evaluation,"Evaluation of Transcription and Annotation Tools for a Multi-modal, Multi-party Dialogue Corpus",2004,5,9,6,0,30605,saurabh garg,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Abstract : This paper reviews none available transcription annotation tools, considering in particular the special difficulties arising from transcribing and annotating multi-party, multi-model dialogue. Tools are evaluated as to the ability to support the user's annotation scheme, ability to visualize the form of the data, compatibility with other tools, flexibility of data representation, and general user-friendliness."
robinson-etal-2004-issues,Issues in Corpus Development for Multi-party Multi-modal Task-oriented Dialogue,2004,6,4,5,1,46244,susan robinson,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,Abstract : This paper describes the development of a multi-modal corpus based on multi-party multi-task driven common goal oriented spoken language interaction. The data consists of approximately 10 hours of audio human simulation radio data and nearly 5 hours of video and audio face-to-face sessions between human trainees and virtual agents.
traum-etal-2004-evaluation,Evaluation of Multi-party Virtual Reality Dialogue Interaction,2004,6,29,1,1,16786,david traum,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We describe a dialogue evaluation plan for a multi-character virtual reality training simulation. A multi-component evaluation plan is presented, including user satisfaction, intended task completion, recognition rate, and a new annotation scheme for appropriateness. Preliminary results for formative tests are also presented."
2001.mtsummit-papers.47,Implicit cues for explicit generation: using telicity as a cue for tense structure in a {C}hinese to {E}nglish {MT} system,2001,0,12,2,1,28559,mari olsen,Proceedings of Machine Translation Summit VIII,0,"Abstract : In translating from Chinese to English, tense and other temporal information must be inferred from other grammatical and lexical cues. Tense information is crucial to providing accurate and fluent translations into English. Perfective and imperfective grammatical aspect markers can provide cues to temporal structure but such information is optional in Chinese and is not present in the majority of sentences. We report on a project that assesses the relative contribution of the lexical aspect features of (a)telicity reflected in the Lexical Conceptual Structure of the input text versus more overt aspectual and adverbial markers of tense, to suggest tense structure in the English translation of a Chinese newspaper corpus. Incorporating this information allows a 20% to 35% boost in the accuracy of tense relization with the best accuracy rate of 92% on a corpus of Chinese articles."
W00-0205,Telicity as a Cue to Temporaland Discourse Structure in {C}hinese-{E}nglish Machine Translation,2000,20,4,2,1,28559,mari olsen,{NAACL}-{ANLP} 2000 Workshop: Applied Interlinguas: Practical Applications of Interlingual Approaches to {NLP},0,"Machine translation between any two languages requires the generation of information that is implicit in the source language. In translating from Chinese to English, tense and other temporal information must be inferred from other grammatical and lexical cues. Moreover, Chinese multiple-clause sentences may contain inter-clausal relations (temporal or otherwise) that must be explicit in English (e.g., by means of a discourse marker). Perfective and imperfective grammatical aspect markers can provide cues to temporal structure, but such information is not present in every sentence. We report on a project to use the lexical aspect features of (a)telicity reflected in the Lexical Conceptual Structure of the input text to suggest tense and discourse structure in the English translation of a Chinese newspaper corpus."
W00-0207,Generation from Lexical Conceptual Structures,2000,11,12,1,1,16786,david traum,{NAACL}-{ANLP} 2000 Workshop: Applied Interlinguas: Practical Applications of Interlingual Approaches to {NLP},0,"This paper describes a system for generating natural language sentences from an interlingual representation, Lexical Conceptual Structure (LCS). This system has been developed as part of a Chinese-English Machine Translation system, however, it promises to be useful for many other MT language pairs. The generation system has also been used in Cross-Language information retrieval research (Levow et al., 2000)."
A00-2001,Modelling Grounding and Discourse Obligations Using Update Rules,2000,13,94,3,0,45119,colin matheson,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper describes an implementation of some key aspects of a theory of dialogue processing whose main concerns are to provide models of GROUNDING and of the role of DISCOURSE OBLIGATIONS in an agent's deliberation processes. Our system uses the TrindiKit dialogue move engine toolkit, which assumes a model of dialogue in which a participant's knowledge is characterised in terms of INFORMATION STATES which are subject to various kinds of updating mechanisms."
W99-0313,A Two-level Approach to Coding Dialogue for Discourse Structure: Activities of the 1998 {DRI} Working Group on Higher-level Structures,1999,-1,-1,1,1,16786,david traum,Towards Standards and Tools for Discourse Tagging,0,None
dorr-etal-1998-thematic,A thematic hierarchy for efficient generation from lexical-conceptual structure,1998,16,14,3,0,14512,bonnie dorr,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,This paper describes an implemented algorithm for syntactic realization of a target-language sentence from an interlingual representation called Lexical Conceptual Structure (LCS). We provide a mapping between LCS thematic roles and Abstract Meaning Representation (AMR) relations; these relations serve as input to an off-the-shelf generator (Nitrogen). There are two contributions of this work: (1) the development of a thematic hierarchy that provides ordering information for realization of arguments in their surface positions; (2) the provision of a diagnostic tool for detecting inconsistencies in an existing online LCS-based lexicon that allows us to enhance principles for thematic-role assignment.
J96-3008,Book Reviews: Spoken Natural Language Dialogue Systems: A Practical Approach,1996,-1,-1,1,1,16786,david traum,Computational Linguistics,0,None
P94-1001,Discourse Obligations in Dialogue Processing,1994,20,186,1,1,16786,david traum,32nd Annual Meeting of the Association for Computational Linguistics,1,"We show that in modeling social interaction, particularly dialogue, the attitude of obligation can be a useful adjunct to the popularly considered attitudes of belief, goal, and intention and their mutual and shared counterparts. In particular, we show how discourse obligations can be used to account in a natural manner for the connection between a question and its answer in dialogue and how obligations can be used along with other parts of the discourse context to extend the coverage of a dialogue system."
W93-0235,"Rhetorical Relations, Action and Intentionality in Conversation",1993,-1,-1,1,1,16786,david traum,Intentionality and Structure in Discourse Relations,0,None
