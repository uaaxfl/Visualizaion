2021.smm4h-1.2,View Distillation with Unlabeled Data for Extracting Adverse Drug Effects from User-Generated Data,2021,-1,-1,2,0,1136,payam karisani,Proceedings of the Sixth Social Media Mining for Health ({\\#}SMM4H) Workshop and Shared Task,0,"We present an algorithm based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents. Then a classifier is trained on each view to label a set of unlabeled documents to be used as an initializer for a new classifier in the other view. Finally, the initialized classifier in each view is further trained using the initial training examples. We evaluated our model in the largest publicly available ADR dataset. The experiments testify that our model significantly outperforms the transformer-based models pretrained on domain-specific data."
2021.nlp4convai-1.9,What Went Wrong? Explaining Overall Dialogue Quality through Utterance-Level Impacts,2021,-1,-1,3,0,2938,james finch,Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI,0,"Improving user experience of a dialogue system often requires intensive developer effort to read conversation logs, run statistical analyses, and intuit the relative importance of system shortcomings. This paper presents a novel approach to automated analysis of conversation logs that learns the relationship between user-system interactions and overall dialogue quality. Unlike prior work on utterance-level quality prediction, our approach learns the impact of each interaction from the overall user rating without utterance-level annotation, allowing resultant model conclusions to be derived on the basis of empirical evidence and at low cost. Our model identifies interactions that have a strong correlation with the overall dialogue quality in a chatbot setting. Experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable."
2021.mrl-1.19,Analysis of Zero-Shot Crosslingual Learning between {E}nglish and {K}orean for Named Entity Recognition,2021,-1,-1,8,0,5236,jongin kim,Proceedings of the 1st Workshop on Multilingual Representation Learning,0,"This paper presents a English-Korean parallel dataset that collects 381K news articles where 1,400 of them, comprising 10K sentences, are manually labeled for crosslingual named entity recognition (NER). The annotation guidelines for the two languages are developed in parallel, that yield the inter-annotator agreement scores of 91 and 88{\%} for English and Korean respectively, indicating sublime quality annotation in our dataset. Three types of crosslingual learning approaches, direct model transfer, embedding projection, and annotation projection, are used to develop zero-shot Korean NER models. Our best model gives the F1-score of 51{\%} that is very encouraging, considering the extremely distinct natures of these two languages. This is pioneering work that explores zero-shot cross-lingual learning between English and Korean and provides rich parallel annotation for a core NLP task such as named entity recognition."
2021.iwpt-1.5,Levi Graph {AMR} Parser using Heterogeneous Attention,2021,-1,-1,2,1,5815,han he,Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021),0,"Coupled with biaffine decoders, transformers have been effectively adapted to text-to-graph transduction and achieved state-of-the-art performance on AMR parsing. Many prior works, however, rely on the biaffine decoder for either or both arc and label predictions although most features used by the decoder may be learned by the transformer already. This paper presents a novel approach to AMR parsing by combining heterogeneous data (tokens, concepts, labels) as one input to a transformer to learn attention, and use only attention matrices from the transformer to predict all elements in AMR graphs (concepts, arcs, labels). Although our models use significantly fewer parameters than the previous state-of-the-art graph parser, they show similar or better accuracy on AMR 2.0 and 3.0."
2021.emnlp-main.451,The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders,2021,-1,-1,2,1,5815,han he,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis."
2021.emnlp-main.538,Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty Estimation,2021,-1,-1,6,1,9754,liyan xu,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Recent multilingual pre-trained language models have achieved remarkable zero-shot performance, where the model is only finetuned on one source language and directly evaluated on target languages. In this work, we propose a self-learning framework that further utilizes unlabeled data of target languages, combined with uncertainty estimation in the process to select high-quality silver labels. Three different uncertainties are adapted and analyzed specifically for the cross lingual transfer: Language Heteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty (EVI). We evaluate our framework with uncertainties on two cross-lingual tasks including Named Entity Recognition (NER) and Natural Language Inference (NLI) covering 40 languages in total, which outperforms the baselines significantly by 10 F1 for NER on average and 2.5 accuracy for NLI."
2021.emnlp-demo.19,{UMR}-Writer: A Web Application for Annotating Uniform Meaning Representations,2021,-1,-1,4,0,8111,jin zhao,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,"We present UMR-Writer, a web-based application for annotating Uniform Meaning Representations (UMR), a graph-based, cross-linguistically applicable semantic representation developed recently to support the development of interpretable natural language applications that require deep semantic analysis of texts. We present the functionalities of UMR-Writer and discuss the challenges in developing such a tool and how they are addressed."
2021.crac-1.3,{F}antasy{C}oref: Coreference Resolution on Fantasy Literature Through Omniscient Writer{'}s Point of View,2021,-1,-1,7,0,11305,sooyoun han,"Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference",0,"This paper presents a new corpus and annotation guideline for a novel coreference resolution task on fictional texts, and analyzes its unique characteristics. FantasyCoref contains 211 stories of Grimms{'} Fairy Tales and 3 other fantasy literature annotated in the omniscient writer{'}s point of view (OWV) to handle distinctive aspects in this genre. This task is more challenging than general coreference resolution in two ways. First, documents in our corpus are 2.5 times longer than the ones in OntoNotes, raising a new layer of difficulty in resolving long-distant referents. Second, annotation of literary styles and concepts raise several issues which are not sufficiently addressed in the existing annotation guidelines. Hence, considerations on such issues and the concept of OWV are necessary to achieve high inter-annotator agreement (IAA) in coreference resolution of fictional texts. We carefully conduct annotation tasks in four stages to ensure the quality of our annotation. As a result, a high IAA score of 87{\%} is achieved using the standard coreference evaluation metric. Finally, state-of-the-art coreference resolution approaches are evaluated on our corpus. After training with our annotated dataset, there was a 2.59{\%} and 3.06{\%} improvement over the model trained on the OntoNotes dataset. Also, we observe that the portion of errors specific to fictional texts declines after the training."
2021.codi-sharedtask.6,Adapted End-to-End Coreference Resolution System for Anaphoric Identities in Dialogues,2021,-1,-1,2,1,9754,liyan xu,"Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue",0,"We present an effective system adapted from the end-to-end neural coreference resolution model, targeting on the task of anaphora resolution in dialogues. Three aspects are specifically addressed in our approach, including the support of singletons, encoding speakers and turns throughout dialogue interactions, and knowledge transfer utilizing existing resources. Despite the simplicity of our adaptation strategies, they are shown to bring significant impact to the final performance, with up to 27 F1 improvement over the baseline. Our final system ranks the 1st place on the leaderboard of the anaphora resolution track in the CRAC 2021 shared task, and achieves the best evaluation results on all four datasets."
2021.cmcl-1.18,Enhancing Cognitive Models of Emotions with Representation Learning,2021,-1,-1,2,0,1171,yuting guo,Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics,0,"We present a novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions. Our framework integrates a contextualized embedding encoder with a multi-head probing model that enables to interpret dynamically learned representations optimized for an emotion classification task. Our model is evaluated on the Empathetic Dialogue dataset and shows the state-of-the-art result for classifying 32 emotions. Our layer analysis can derive an emotion graph to depict hierarchical relations among the emotions. Our emotion representations can be used to generate an emotion wheel directly comparable to the one from Plutchik{'}s model, and also augment the values of missing emotions in the PAD emotional state model."
2020.sigdial-1.29,Towards Unified Dialogue System Evaluation: A Comprehensive Analysis of Current Evaluation Protocols,2020,-1,-1,2,0,2939,sarah finch,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"As conversational AI-based dialogue management has increasingly become a trending topic, the need for a standardized and reliable evaluation procedure grows even more pressing. The current state of affairs suggests various evaluation protocols to assess chat-oriented dialogue management systems, rendering it difficult to conduct fair comparative studies across different approaches and gain an insightful understanding of their values. To foster this research, a more robust evaluation protocol must be set in place. This paper presents a comprehensive synthesis of both automated and human evaluation methods on dialogue systems, identifying their shortcomings while accumulating evidence towards the most effective evaluation dimensions. A total of 20 papers from the last two years are surveyed to analyze three types of evaluation protocols: automated, static, and interactive. Finally, the evaluation dimensions used in these papers are compared against our expert evaluation on the system-user dialogue data collected from the Alexa Prize 2020."
2020.sigdial-1.32,Emora {STDM}: A Versatile Framework for Innovative Dialogue System Development,2020,-1,-1,2,0,2938,james finch,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This demo paper presents Emora STDM (State Transition Dialogue Manager), a dialogue system development framework that provides novel workflows for rapid prototyping of chat-based dialogue managers as well as collaborative development of complex interactions. Our framework caters to a wide range of expertise levels by supporting interoperability between two popular approaches, state machine and information state, to dialogue management. Our Natural Language Expression package allows seamless integration of pattern matching, custom NLP modules, and database querying, that makes the workflows much more efficient. As a user study, we adopt this framework to an interdisciplinary undergraduate course where students with both technical and non-technical backgrounds are able to develop creative dialogue managers in a short period of time."
2020.semeval-1.299,{XD} at {S}em{E}val-2020 Task 12: Ensemble Approach to Offensive Language Identification in Social Media Using Transformer Encoders,2020,-1,-1,2,0,15405,xiangjue dong,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"This paper presents six document classification models using the latest transformer encoders and a high-performing ensemble model for a task of offensive language identification in social media. For the individual models, deep transformer layers are applied to perform multi-head attentions. For the ensemble model, the utterance representations taken from those individual models are concatenated and fed into a linear decoder to make the final decisions. Our ensemble model outperforms the individual models and shows up to 8.6{\%} improvement over the individual models on the development set. On the test set, it achieves macro-F1 of 90.9{\%} and becomes one of the high performing systems among 85 participants in the sub-task A of this shared task. Our analysis shows that although the ensemble model significantly improves the accuracy on the development set, the improvement is not as evident on the test set."
2020.iwpt-1.13,Analysis of the {P}enn {K}orean {U}niversal {D}ependency Treebank ({PKT}-{UD}): Manual Revision to Build Robust Parsing Model in {K}orean,2020,-1,-1,6,0,14276,tae oh,Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,0,"In this paper, we first open on important issues regarding the Penn Korean Universal Treebank (PKT-UD) and address these issues by revising the entire corpus manually with the aim of producing cleaner UD annotations that are more faithful to Korean grammar. For compatibility to the rest of UD corpora, we follow the UDv2 guidelines, and extensively revise the part-of-speech tags and the dependency relations to reflect morphological features and flexible word- order aspects in Korean. The original and the revised versions of PKT-UD are experimented with transformer-based parsing models using biaffine attention. The parsing model trained on the revised corpus shows a significant improvement of 3.0{\%} in labeled attachment score over the model trained on the previous corpus. Our error analysis demonstrates that this revision allows the parsing model to learn relations more robustly, reducing several critical errors that used to be made by the previous model."
2020.iwpt-1.19,Adaptation of Multilingual Transformer Encoder for Robust Enhanced {U}niversal {D}ependency Parsing,2020,-1,-1,2,1,5815,han he,Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,0,"This paper presents our enhanced dependency parsing approach using transformer encoders, coupled with a simple yet powerful ensemble algorithm that takes advantage of both tree and graph dependency parsing. Two types of transformer encoders are compared, a multilingual encoder and language-specific encoders. Our dependency tree parsing (DTP) approach generates only primary dependencies to form trees whereas our dependency graph parsing (DGP) approach handles both primary and secondary dependencies to form graphs. Since DGP does not guarantee the generated graphs are acyclic, the ensemble algorithm is designed to add secondary arcs predicted by DGP to primary arcs predicted by DTP. Our results show that models using the multilingual encoder outperform ones using the language specific encoders for most languages. The ensemble models generally show higher labeled attachment score on enhanced dependencies (ELAS) than the DTP and DGP models. As the result, our best models rank the third place on the macro-average ELAS over 17 languages."
2020.figlang-1.38,Transformer-based Context-aware Sarcasm Detection in Conversation Threads from Social Media,2020,15,0,3,0,15405,xiangjue dong,Proceedings of the Second Workshop on Figurative Language Processing,0,"We present a transformer-based sarcasm detection model that accounts for the context from the entire conversation thread for more robust predictions. Our model uses deep transformer layers to perform multi-head attentions among the target utterance and the relevant context in the thread. The context-aware models are evaluated on two datasets from social media, Twitter and Reddit, and show 3.1{\%} and 7.0{\%} improvements over their baselines. Our best models give the F1-scores of 79.0{\%} and 75.0{\%} for the Twitter and Reddit datasets respectively, becoming one of the highest performing systems among 36 participants in this shared task."
2020.emnlp-main.679,Competence-Level Prediction and Resume {\\&} Job Description Matching Using Context-Aware Transformer Models,2020,-1,-1,6,0,20039,changmao li,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"This paper presents a comprehensive study on resume classification to reduce the time and labor needed to screen an overwhelming number of applications significantly, while improving the selection of suitable candidates. A total of 6,492 resumes are extracted from 24,933 job applications for 252 positions designated into four levels of experience for Clinical Research Coordinators (CRC). Each resume is manually annotated to its most appropriate CRC position by experts through several rounds of triple annotation to establish guidelines. As a result, a high Kappa score of 61{\%} is achieved for inter-annotator agreement. Given this dataset, novel transformer-based classification models are developed for two tasks: the first task takes a resume and classifies it to a CRC level (T1), and the second task takes both a resume and a job description to apply and predicts if the application is suited to the job (T2). Our best models using section encoding and a multi-head attention decoding give results of 73.3{\%} to T1 and 79.2{\%} to T2. Our analysis shows that the prediction errors are mostly made among adjacent CRC levels, which are hard for even experts to distinguish, implying the practical value of our models in real HR platforms."
2020.emnlp-main.686,Revealing the Myth of Higher-Order Inference in Coreference Resolution,2020,-1,-1,2,1,9754,liyan xu,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"This paper analyzes the impact of higher-order inference (HOI) on the task of coreference resolution. HOI has been adapted by almost all recent coreference resolution models without taking much investigation on its true effectiveness over representation learning. To make a comprehensive analysis, we implement an end-to-end coreference system as well as four HOI approaches, attended antecedent, entity equalization, span clustering, and cluster merging, where the latter two are our original methods. We find that given a high-performing encoder such as SpanBERT, the impact of HOI is negative to marginal, providing a new perspective of HOI to this task. Our best model using cluster merging shows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English."
2020.bionlp-1.10,Noise Pollution in Hospital Readmission Prediction: Long Document Classification with Reinforcement Learning,2020,16,0,4,1,9754,liyan xu,Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing,0,"This paper presents a reinforcement learning approach to extract noise in long clinical documents for the task of readmission prediction after kidney transplant. We face the challenges of developing robust models on a small dataset where each document may consist of over 10K tokens with full of noise including tabular text and task-irrelevant sentences. We first experiment four types of encoders to empirically decide the best document representation, and then apply reinforcement learning to remove noisy text from the long documents, which models the noise extraction process as a sequential decision problem. Our results show that the old bag-of-words encoder outperforms deep learning-based encoders on this task, and reinforcement learning is able to improve upon baseline while pruning out 25{\%} text segments. Our analysis depicts that reinforcement learning is able to identify both typical noisy tokens and task-specific noisy text."
2020.acl-main.505,Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering,2020,19,0,2,0,20039,changmao li,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token- and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multi-task learning between the utterance prediction and the token span prediction is applied to fine-tune for span-based question answering (QA). Our approach is evaluated on the FriendsQA dataset and shows improvements of 3.8{\%} and 1.4{\%} over the two state-of-the-art transformer models, BERT and RoBERTa, respectively."
2020.aacl-main.38,Analysis of Hierarchical Multi-Content Text Classification Model on {B}-{SHARP} Dataset for Early Detection of {A}lzheimer{'}s Disease,2020,-1,-1,4,0,23230,renxuan li,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"This paper presents a new dataset, B-SHARP, that can be used to develop NLP models for the detection of Mild Cognitive Impairment (MCI) known as an early sign of Alzheimer{'}s disease. Our dataset contains 1-2 min speech segments from 326 human subjects for 3 topics, (1) daily activity, (2) room environment, and (3) picture description, and their transcripts so that a total of 650 speech segments are collected. Given the B-SHARP dataset, several hierarchical text classification models are developed that jointly learn combinatory features across all 3 topics. The best performance of 74.1{\%} is achieved by an ensemble model that adapts 3 types of transformer encoders. To the best of our knowledge, this is the first work that builds deep learning-based text classification models on multiple contents for the detection of MCI."
W19-5923,{F}riends{QA}: Open-Domain Question Answering on {TV} Show Transcripts,2019,0,3,2,0,23754,zhengzhe yang,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,0,"This paper presents FriendsQA, a challenging question answering dataset that contains 1,222 dialogues and 10,610 open-domain questions, to tackle machine comprehension on everyday conversations. Each dialogue, involving multiple speakers, is annotated with several types of questions regarding the dialogue contexts, and the answers are annotated with certain spans in the dialogue. A series of crowdsourcing tasks are conducted to ensure good annotation quality, resulting a high inter-annotator agreement of 81.82{\%}. A comprehensive annotation analytics is provided for a deeper understanding in this dataset. Three state-of-the-art QA systems are experimented, R-Net, QANet, and BERT, and evaluated on this dataset. BERT in particular depicts promising results, an accuracy of 74.2{\%} for answer utterance selection and an F1-score of 64.2{\%} for answer span selection, suggesting that the FriendsQA task is hard yet has a great potential of elevating QA research on multiparty dialogue to another level."
W19-3309,Meta-Semantic Representation for Early Detection of {A}lzheimer{'}s Disease,2019,0,0,1,1,1137,jinho choi,Proceedings of the First International Workshop on Designing Meaning Representations,0,"This paper presents a new task-oriented meaning representation called meta-semantics, that is designed to detect patients with early symptoms of Alzheimer{'}s disease by analyzing their language beyond a syntactic or semantic level. Meta-semantic representation consists of three parts, entities, predicate argument structures, and discourse attributes, that derive rich knowledge graphs. For this study, 50 controls and 50 patients with mild cognitive impairment (MCI) are selected, and meta-semantic representation is annotated on their speeches transcribed in text. Inter-annotator agreement scores of 88{\%}, 82{\%}, and 89{\%} are achieved for the three types of annotation, respectively. Five analyses are made using this annotation, depicting clear distinctions between the control and MCI groups. Finally, a neural model is trained on features extracted from those analyses to classify MCI patients from normal controls, showing a high accuracy of 82{\%} that is very promising."
W18-6009,Coordinate Structures in {U}niversal {D}ependencies for Head-final Languages,2018,0,0,6,0,1260,hiroshi kanayama,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"This paper discusses the representation of coordinate structures in the Universal Dependencies framework for two head-final languages, Japanese and Korean. UD applies a strict principle that makes the head of coordination the left-most conjunct. However, the guideline may produce syntactic trees which are difficult to accept in head-final languages. This paper describes the status in the current Japanese and Korean corpora and proposes alternative designs suitable for these languages."
S18-1007,{S}em{E}val 2018 Task 4: Character Identification on Multiparty Dialogues,2018,0,2,1,1,1137,jinho choi,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"Character identification is a task of entity linking that finds the global entity of each personal mention in multiparty dialogue. For this task, the first two seasons of the popular TV show Friends are annotated, comprising a total of 448 dialogues, 15,709 mentions, and 401 entities. The personal mentions are detected from nominals referring to certain characters in the show, and the entities are collected from the list of all characters in those two seasons of the show. This task is challenging because it requires the identification of characters that are mentioned but may not be active during the conversation. Among 90+ participants, four of them submitted their system outputs and showed strengths in different aspects about the task. Thorough analyses of the distributed datasets, system outputs, and comparative studies are also provided. To facilitate the momentum, we create an open-source project for this task and publicly release a larger and cleaner dataset, hoping to support researchers for more enhanced modeling."
N18-1185,Challenging Reading Comprehension on Daily Conversation: Passage Completion on Multiparty Dialog,2018,0,12,3,1,9607,kaixin ma,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"This paper presents a new corpus and a robust deep learning architecture for a task in reading comprehension, passage completion, on multiparty dialog. Given a dialog in text and a passage containing factual descriptions about the dialog where mentions of the characters are replaced by blanks, the task is to fill the blanks with the most appropriate character names that reflect the contexts in the dialog. Since there is no dataset that challenges the task of passage completion in this genre, we create a corpus by selecting transcripts from a TV show that comprise 1,681 dialogs, generating passages for each dialog through crowdsourcing, and annotating mentions of characters in both the dialog and the passages. Given this dataset, we build a deep neural model that integrates rich feature extraction from convolutional neural networks into sequence modeling in recurrent neural networks, optimized by utterance and dialog level attentions. Our model outperforms the previous state-of-the-art model on this task in a different genre using bidirectional LSTM, showing a 13.0+{\%} improvement for longer dialogs. Our analysis shows the effectiveness of the attention mechanisms and suggests a direction to machine comprehension on multiparty dialog."
L18-1347,Building {U}niversal {D}ependency Treebanks in {K}orean,2018,0,1,4,0,26292,jayeol chun,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1003,They Exist! Introducing Plural Mentions to Coreference Resolution and Entity Linking,2018,0,2,2,0,30746,ethan zhou,Proceedings of the 27th International Conference on Computational Linguistics,0,"This paper analyzes arguably the most challenging yet under-explored aspect of resolution tasks such as coreference resolution and entity linking, that is the resolution of plural mentions. Unlike singular mentions each of which represents one entity, plural mentions stand for multiple entities. To tackle this aspect, we take the character identification corpus from the SemEval 2018 shared task that consists of entity annotation for singular mentions, and expand it by adding annotation for plural mentions. We then introduce a novel coreference resolution algorithm that selectively creates clusters to handle both singular and plural mentions, and also a deep learning-based entity linking model that jointly handles both types of mentions through multi-task learning. Adjusted evaluation metrics are proposed for these tasks as well to handle the uniqueness of plural mentions. Our experiments show that the new coreference resolution and entity linking models significantly outperform traditional models designed only for singular mentions. To the best of our knowledge, this is the first time that plural mentions are thoroughly analyzed for these two resolution tasks."
W17-5407,Cross-genre Document Retrieval: Matching between Conversational and Formal Writings,2017,16,0,2,1,29487,tomasz jurczyk,Proceedings of the First Workshop on Building Linguistically Generalizable {NLP} Systems,0,"This paper challenges a cross-genre document retrieval task, where the queries are in formal writing and the target documents are in conversational writing. In this task, a query, is a sentence extracted from either a summary or a plot of an episode in a TV show, and the target document consists of transcripts from the corresponding episode. To establish a strong baseline, we employ the current state-of-the-art search engine to perform document retrieval on the dataset collected for this work. We then introduce a structure reranking approach to improve the initial ranking by utilizing syntactic and semantic structures generated by NLP tools. Our evaluation shows an improvement of more than 4{\%} when the structure reranking is applied, which is very promising."
W17-5220,Lexicon Integrated {CNN} Models with Attention for Sentiment Analysis,2017,0,25,3,0,31552,bonggun shin,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"With the advent of word embeddings, lexicons are no longer fully utilized for sentiment analysis although they still provide important features in the traditional setting. This paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into Convolutional Neural Networks. Our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using attention. Our models are experimented on both the SemEval{'}16 Task 4 dataset and the Stanford Sentiment Treebank and show comparative or better results against the existing state-of-the-art systems. Our analysis shows that lexicon embeddings allow building high-performing models with much smaller word embeddings, and the attention mechanism effectively dims out noisy words for sentiment analysis."
W17-4416,Improving Document Clustering by Removing Unnatural Language,2017,0,0,2,0,31681,myungha jang,Proceedings of the 3rd Workshop on Noisy User-generated Text,0,"Technical documents contain a fair amount of unnatural language, such as tables, formulas, and pseudo-code. Unnatural language can bean important factor of confusing existing NLP tools. This paper presents an effective method of distinguishing unnatural language from natural language, and evaluates the impact of un-natural language detection on NLP tasks such as document clustering. We view this problem as an information extraction task and build a multiclass classification model identifying unnatural language components into four categories. First, we create a new annotated corpus by collecting slides and papers in various for-mats, PPT, PDF, and HTML, where unnatural language components are annotated into four categories. We then explore features available from plain text to build a statistical model that can handle any format as long as it is converted into plain text. Our experiments show that re-moving unnatural language components gives an absolute improvement in document cluster-ing by up to 15{\%}. Our corpus and tool are publicly available"
P17-3009,Text-based Speaker Identification on Multiparty Dialogues Using Multi-document Convolutional Neural Networks,2017,3,0,3,1,9607,kaixin ma,"Proceedings of {ACL} 2017, Student Research Workshop",0,None
K17-1023,Robust Coreference Resolution and Entity Linking on Dialogues: Character Identification on {TV} Show Transcripts,2017,12,3,3,0,28737,henry chen,Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017),0,"This paper presents a novel approach to character identification, that is an entity linking task that maps mentions to characters in dialogues from TV show transcripts. We first augment and correct several cases of annotation errors in an existing corpus so the corpus is clearer and cleaner for statistical learning. We also introduce the agglomerative convolutional neural network that takes groups of features and learns mention and mention-pair embeddings for coreference resolution. We then propose another neural model that employs the embeddings learned and creates cluster embeddings for entity linking. Our coreference resolution model shows comparable results to other state-of-the-art systems. Our entity linking model significantly outperforms the previous work, showing the F1 score of 86.76{\%} and the accuracy of 95.30{\%} for character identification."
W16-3612,Character Identification on Multiparty Conversation: Identifying Mentions of Characters in {TV} Shows,2016,13,8,2,0,33715,yuhsin chen,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
P16-3020,{QA}-It: Classifying Non-Referential It for Question Answer Pairs,2016,12,0,3,0,31553,timothy lee,Proceedings of the {ACL} 2016 Student Research Workshop,0,"This paper introduces a new corpus, QA-It, for the classification of non-referential it. Our dataset is unique in a sense that it is annotated on question answer pairs collected from multiple genres, useful for developing advanced QA systems. Our annotation scheme makes clear distinctions between 4 types of it, providing guidelines for many erroneous cases. Several statistical models are built for the classification of it, showing encouraging results. To the best of our knowledge, this is the first time that such a corpus is created for question answering."
N16-1031,Dynamic Feature Induction: The Last Gist to the State-of-the-Art,2016,49,17,1,1,1137,jinho choi,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We introduce a novel technique called dynamic feature induction that keeps inducing high dimensional features automatically until the feature space becomes xe2x80x98morexe2x80x99 linearly separable. Dynamic feature induction searches for the feature combinations that give strong clues for distinguishing certain label pairs, and generates joint features from these combinations. These induced features are trained along with the primitive low dimensional features. Our approach was evaluated on two core NLP tasks, part-of-speech tagging and named entity recognition, and showed the state-of-the-art results for both tasks, achieving the accuracy of 97.64 and the F1-score of 91.00 respectively, with about a 25% increase in the feature space."
P15-1038,It Depends: Dependency Parser Comparison Using A Web-based Evaluation Tool,2015,38,52,1,1,1137,jinho choi,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"The last few years have seen a surge in the number of accurate, fast, publicly available dependency parsers. At the same time, the use of dependency parsing in NLP applications has increased. It can be difficult for a non-expert to select a good xe2x80x9coff-the-shelfxe2x80x9d parser. We present a comparative analysis of ten leading statistical dependency parsers on a multi-genre corpus of English. For our analysis, we developed a new web-based tool that gives a convenient way of comparing dependency parser outputs. Our analysis will help practitioners choose a parser to optimize their desired speed/accuracy tradeoff, and our tool will help practitioners examine and compare parser output."
N15-2019,Semantics-based Graph Approach to Complex Question-Answering,2015,18,2,2,1,29487,tomasz jurczyk,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,0,"This paper suggests an architectural approach of representing knowledge graph for complex question-answering. There are four kinds of entity relations added to our knowledge graph: syntactic dependencies, semantic role labels, named entities, and coreference links, which can be effectively applied to answer complex questions. As a proof of concept, we demonstrate how our knowledge graph can be used to solve complex questions such as arithmetics. Our experiment shows a promising result on solving arithmetic questions, achieving the 3folds cross-validation score of 71.75%."
N15-2023,Computational Exploration to Linguistic Structures of Future: Classification and Categorization,2015,0,1,2,0,37617,aiming ni,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,0,None
W13-4917,Overview of the {SPMRL} 2013 Shared Task: A Cross-Framework Evaluation of Parsing Morphologically Rich Languages,2013,110,38,5,0,167,djame seddah,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper reports on the first shared task on statistical parsing of morphologically rich languages (MRLs). The task features data sets from nine languages, each available both in constituency and dependency annotation. We report on the preparation of the data sets, on the proposed parsing scenarios, and on the evaluation metrics for parsing MRLs given different representation types. We present and analyze parsing results obtained by the task participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios."
W13-3517,Dynamic Knowledge-Base Alignment for Coreference Resolution,2013,30,19,4,0,36923,jiaping zheng,Proceedings of the Seventeenth Conference on Computational Natural Language Learning,0,"Coreference resolution systems can benefit greatly from inclusion of global context, and a number of recent approaches have demonstrated improvements when precomputing an alignment to external knowledge sources. However, since alignment itself is a challenging task and is often noisy, existing systems either align conservatively, resulting in very few links, or combine the attributes of multiple candidates, leading to a conflation of entities. Our approach instead performs joint inference between within-document coreference and entity linking, maintaining ranked lists of candidate entities that are dynamically merged and reranked during inference. Further, we incorporate a large set of surface string variations for each entity by using anchor texts from the web that link to the entity. These forms of global context enables our system to improve classifier-based coreference by 1.09 B 3 F1 points, and improve over the previous state-of-art by 0.41 points, thus introducing a new state-of-art result on the ACE 2004 data."
P13-1104,Transition-based Dependency Parsing with Selectional Branching,2013,40,73,1,1,1137,jinho choi,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a novel approach, called selectional branching, which uses confidence estimates to decide when to employ a beam, providing the accuracy of beam search at speeds close to a greedy transition-based dependency parsing approach. Selectional branching is guaranteed to perform a fewer number of transitions than beam search yet performs as accurately. We also present a new transition-based dependency parsing algorithm that gives a complexity ofO(n) for projective parsing and an expected linear time speed for non-projective parsing. With the standard setup, our parser shows an unlabeled attachment score of 92.96% and a parsing speed of 9 milliseconds per sentence, which is faster and more accurate than the current state-of-the-art transitionbased parser that uses beam search."
P12-2071,Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection,2012,8,23,1,1,1137,jinho choi,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, left-to-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. We believe that this model selection approach can be applied to more sophisticated tagging algorithms and improve their robustness even further."
vaidya-etal-2012-empty,Empty Argument Insertion in the {H}indi {P}rop{B}ank,2012,9,4,2,1,640,ashwini vaidya,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper examines both linguistic behavior and practical implication of empty argument insertion in the Hindi PropBank. The Hindi PropBank is annotated on the Hindi Dependency Treebank, which contains some empty categories but not the empty arguments of verbs. In this paper, we analyze four kinds of empty arguments, *PRO*, *REL*, *GAP*, *pro*, and suggest effective ways of annotating these arguments. Empty arguments such as *PRO* and *REL* can be inserted deterministically; we present linguistically motivated rules that automatically insert these arguments with high accuracy. On the other hand, it is difficult to find deterministic rules to insert *GAP* and *pro*; for these arguments, we introduce a new annotation scheme that concurrently handles both semantic role labeling and empty category insertion, producing fast and high quality annotation. In addition, we present algorithms for finding antecedents of *REL* and *PRO*, and discuss why finding antecedents for some types of *PRO* is difficult."
W11-3801,Statistical Dependency Parsing in {K}orean: From Corpus Generation To Automatic Parsing,2011,19,9,1,1,1137,jinho choi,Proceedings of the Second Workshop on Statistical Parsing of Morphologically Rich Languages,0,"This paper gives two contributions to dependency parsing in Korean. First, we build a Korean dependency Treebank from an existing constituent Treebank. For a morphologically rich language like Korean, dependency parsing shows some advantages over constituent parsing. Since there is not much training data available, we automatically generate dependency trees by applying head-percolation rules and heuristics to the constituent trees. Second, we show how to extract useful features for dependency parsing from rich morphology in Korean. Once we build the dependency Treebank, any statistical parsing approach can be applied. The challenging part is how to extract features from tokens consisting of multiple morphemes. We suggest a way of selecting important morphemes and use only these as features to avoid sparsity. Our parsing approach is evaluated on three different genres using both gold-standard and automatic morphological analysis. We also test the impact of fine vs. coarse-grained morphologies on dependency parsing. With automatic morphological analysis, we achieve labeled attachment scores of 80%. To the best of our knowledge, this is the first time that Korean dependency parsing has been evaluated on labeled edges with such a large variety of data."
W11-0906,Transition-based Semantic Role Labeling Using Predicate Argument Clustering,2011,25,18,1,1,1137,jinho choi,Proceedings of the {ACL} 2011 Workshop on Relational Models of Semantics,0,"This paper suggests two ways of improving semantic role labeling (SRL). First, we introduce a novel transition-based SRL algorithm that gives a quite different approach to SRL. Our algorithm is inspired by shift-reduce parsing and brings the advantages of the transition-based approach to SRL. Second, we present a self-learning clustering technique that effectively improves labeling accuracy in the test domain. For better generalization of the statistical models, we cluster verb predicates by comparing their predicate argument structures and apply the clustering information to the final labeling decisions. All approaches are evaluated on the CoNLL'09 English data. The new algorithm shows comparable results to another state-of-the-art system. The clustering technique improves labeling accuracy for both in-domain and out-of-domain tasks."
W11-0403,Analysis of the {H}indi {P}roposition {B}ank using Dependency Structure,2011,17,14,2,1,640,ashwini vaidya,Proceedings of the 5th Linguistic Annotation Workshop,0,"This paper makes two contributions. First, we describe the Hindi Proposition Bank that contains annotations of predicate argument structures of verb predicates. Unlike PropBanks in most other languages, the Hind PropBank is annotated on top of dependency structure, the Hindi Dependency Treebank. We explore the similarities between dependency and predicate argument structures, so the PropBank annotation can be faster and more accurate. Second, we present a probabilistic rule-based system that maps syntactic dependents to semantic arguments. With simple rules, we classify about 47% of the entire PropBank arguments with over 90% confidence. These preliminary results are promising; they show how well these two frameworks are correlated. This can also be used to speed up our annotations."
P11-2121,Getting the Most out of Transition-based Dependency Parsing,2011,22,51,1,1,1137,jinho choi,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-the-art performance with respect to other parsing approaches evaluated on the same data set."
W10-1811,Retrieving Correct Semantic Boundaries in Dependency Structure,2010,10,4,1,1,1137,jinho choi,Proceedings of the Fourth Linguistic Annotation Workshop,0,"This paper describes the retrieval of correct semantic boundaries for predicate-argument structures annotated by dependency structure. Unlike phrase structure, in which arguments are annotated at the phrase level, dependency structure does not have phrases so the argument labels are associated with head words instead: the subtree of each head word is assumed to include the same set of words as the annotated phrase does in phrase structure. However, at least in English, retrieving such subtrees does not always guarantee retrieval of the correct phrase boundaries. In this paper, we present heuristics that retrieve correct phrase boundaries for semantic arguments, called semantic boundaries, from dependency trees. By applying heuristics, we achieved an F1-score of 99.54% for correct representation of semantic boundaries. Furthermore, error analysis showed that some of the errors could also be considered correct, depending on the interpretation of the annotation."
N10-2004,Multilingual {P}ropbank Annotation Tools: Cornerstone and Jubilee,2010,6,5,1,1,1137,jinho choi,Proceedings of the {NAACL} {HLT} 2010 Demonstration Session,0,"This paper demonstrates two annotation tools related to Propbank: Cornerstone and Jubilee. Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles. Propbank annotation also requires the choice of a sense ID for each predicate, defined in the corresponding frameset file. Jubilee expedites the annotation process by displaying several resources of syntactic and semantic information simultaneously; easy access to each of these resources allows the annotator to quickly absorb and apply the necessary syntactic and semantic information pertinent to each predicate for consistent and efficient annotation. Cornerstone is a user-friendly XML editor, customized to allow frame authors to create and edit frameset files. Both tools have been successfully adapted to many Prop-bank projects; they run platform independently, are light enough to run as X11 applications and support multiple languages such as Arabic, Chinese, English, Hindi and Korean."
choi-etal-2010-propbank,"{P}ropbank Frameset Annotation Guidelines Using a Dedicated Editor, Cornerstone",2010,7,13,1,1,1137,jinho choi,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper gives guidelines of how to create and update Propbank frameset files using a dedicated editor, Cornerstone. Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles in relation to the predicate. Propbank annotation also requires the choice of a sense ID for each predicate. Thus, for each predicate in Propbank, there exists a corresponding frameset file showing the expected predicate argument structure of each sense related to the predicate. Since most Propbank annotations are based on the predicate argument structure defined in the frameset files, it is important to keep the files consistent, simple to read as well as easy to update. The frameset files are written in XML, which can be difficult to edit when using a simple text editor. Therefore, it is helpful to develop a user-friendly editor such as Cornerstone, specifically customized to create and edit frameset files. Cornerstone runs platform independently, is light enough to run as an X11 application and supports multiple languages such as Arabic, Chinese, English, Hindi and Korean."
choi-etal-2010-propbank-instance,"{P}ropbank Instance Annotation Guidelines Using a Dedicated Editor, Jubilee",2010,5,15,1,1,1137,jinho choi,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper gives guidelines of how to annotate Propbank instances using a dedicated editor, Jubilee. Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles in relation to the predicate. Propbank annotation also requires the choice of a sense ID for each predicate. Jubilee facilitates this annotation process by displaying several resources of syntactic and semantic information simultaneously: the syntactic structure of a sentence is displayed in the main frame, the available senses with their corresponding argument structures are displayed in another frame, all available Propbank arguments are displayed for the annotators choice, and example annotations of each sense of the predicate are available to the annotator for viewing. Easy access to each of these resources allows the annotator to quickly absorb and apply the necessary syntactic and semantic information pertinent to each predicate for consistent and efficient annotation. Jubilee has been successfully adapted to many Propbank projects in several universities. The tool runs platform independently, is light enough to run as an X11 application and supports multiple languages such as Arabic, Chinese, English, Hindi and Korean."
2010.amta-papers.15,Detecting Cross-lingual Semantic Similarity Using Parallel {P}rop{B}anks,2010,16,6,2,0,37082,shumin wu,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper suggests a method for detecting cross-lingual semantic similarity using parallel PropBanks. We begin by improving word alignments for verb predicates generated by GIZA++ by using information available in parallel PropBanks. We applied the Kuhn-Munkres method to measure predicate-argument matching and improved verb predicate alignments by an F-score of 12.6{\%}. Using the enhanced word alignments we checked the set of target verbs aligned to a specific source verb for semantic consistency. For a set of English verbs aligned to a Chinese verb, we checked if the English verbs belong to the same semantic class using an existing lexical database, WordNet. For a set of Chinese verbs aligned to an English verb we manually checked semantic similarity between the Chinese verbs within a set. Our results show that the verb sets we generated have a high correlation with semantic classes. This could potentially lead to an automatic technique for generating semantic classes for verbs."
W09-3020,Using Parallel Propbanks to enhance Word-alignments,2009,5,7,1,1,1137,jinho choi,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"This short paper describes the use of the linguistic annotation available in parallel PropBanks (Chinese and English) for the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type."
