2021.nodalida-main.7,{C}omb{A}lign: a Tool for Obtaining High-Quality Word Alignments,2021,-1,-1,3,0.666667,2629,steinthor steingrimsson,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"Being able to generate accurate word alignments is useful for a variety of tasks. While statistical word aligners can work well, especially when parallel training data are plentiful, multilingual embedding models have recently been shown to give good results in unsupervised scenarios. We evaluate an ensemble method for word alignment on four language pairs and demonstrate that by combining multiple tools, taking advantage of their different approaches, substantial gains can be made. This holds for settings ranging from very low-resource to high-resource. Furthermore, we introduce a new gold alignment test set for Icelandic and a new easy-to-use tool for creating manual word alignments."
2021.mtsummit-up.25,"Building {MT} systems in low resourced languages for Public Sector users in {C}roatia, {I}celand, {I}reland, and {N}orway",2021,-1,-1,9,0,4994,roisin moran,Proceedings of Machine Translation Summit XVIII: Users and Providers Track,0,"When developing Machine Translation engines, low resourced language pairs tend to be in a disadvantaged position: less available data means that developing robust MT models can be more challenging.The EU-funded PRINCIPLE project aims at overcoming this challenge for four low resourced European languages: Norwegian, Croatian, Irish and Icelandic. This presentation will give an overview of the project, with a focus on the set of Public Sector users and their use cases for which we have developed MT solutions.We will discuss the range of language resources that have been gathered through contributions from public sector collaborators, and present the extensive evaluations that have been undertaken, including significant user evaluation of MT systems across all of the public sector participants in each of the four countries involved."
2021.mtsummit-research.5,Transformers for Low-Resource Languages: Is F{\\'e}idir Linn!,2021,-1,-1,3,0,5022,seamus lankford,Proceedings of Machine Translation Summit XVIII: Research Track,0,The Transformer model is the state-of-the-art in Machine Translation. However and in general and neural translation models often under perform on language pairs with insufficient training data. As a consequence and relatively few experiments have been carried out using this architecture on low-resource language pairs. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly and the correct choice of subword model is shown to be the biggest driver of translation performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers and testing various regularization techniques and evaluating the optimal number of heads for attention. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model. Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against Google Translate and our translation engines demonstrated significant improvements. The question of whether or not Transformers can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is f{\'e}idir linn - yes we can.
2021.mtsummit-loresmt.15,Machine Translation in the Covid domain: an {E}nglish-{I}rish case study for {L}o{R}es{MT} 2021,2021,-1,-1,3,0,5022,seamus lankford,Proceedings of the 4th Workshop on Technologies for MT of Low Resource Languages (LoResMT2021),0,"Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highestperforming model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points."
2020.wmt-1.27,The {ADAPT} System Description for the {WMT}20 News Translation Task,2020,-1,-1,4,0,13818,venkatesh parthasarathy,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes the ADAPT Centre{'}s submissions to the WMT20 News translation shared task for English-to-Tamil and Tamil-to-English. We present our machine translation (MT) systems that were built using the state-of-the-art neural MT (NMT) model, Transformer. We applied various strategies in order to improve our baseline MT systems, e.g. onolin- gual sentence selection for creating synthetic training data, mining monolingual sentences for adapting our MT systems to the task, hyperparameters search for Transformer in lowresource scenarios. Our experiments show that adding the aforementioned techniques to the baseline yields an excellent performance in the English-to-Tamil and Tamil-to-English translation tasks."
2020.wmt-1.91,The {ADAPT}{'}s Submissions to the {WMT}20 Biomedical Translation Task,2020,-1,-1,3,0,13924,prashant nayak,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes the ADAPT Centre{'}s submissions to the WMT20 Biomedical Translation Shared Task for English-to-Basque. We present the machine translation (MT) systems that were built to translate scientific abstracts and terms from biomedical terminologies, and using the state-of-the-art neural MT (NMT) model: Transformer. In order to improve our baseline NMT system, we employ a number of methods, e.g. {``}pseudo{''} parallel data selection, monolingual data selection for synthetic corpus creation, mining monolingual sentences for adapting our NMT systems to this task, hyperparameters search for Transformer in lowresource scenarios. Our experiments show that systematic addition of the aforementioned techniques to the baseline yields an excellent performance in the English-to-Basque translation task."
2020.wat-1.12,The {ADAPT} Centre{'}s Participation in {WAT} 2020 {E}nglish-to-{O}dia Translation Task,2020,-1,-1,3,0,14098,prashanth nayak,Proceedings of the 7th Workshop on Asian Translation,0,This paper describes the ADAPT Centre sub-missions to WAT 2020 for the English-to-Odia translation task. We present the approaches that we followed to try to build competitive machine translation (MT) systems for English-to-Odia. Our approaches include monolingual data selection for creating synthetic data and identifying optimal sets of hyperparameters for the Transformer in a low-resource scenario. Our best MT system produces 4.96BLEU points on the evaluation test set in the English-to-Odia translation task.
2020.wat-1.17,The {ADAPT} Centre{'}s Neural {MT} Systems for the {WAT} 2020 Document-Level Translation Task,2020,-1,-1,3,0,14099,wandri jooste,Proceedings of the 7th Workshop on Asian Translation,0,"In this paper we describe the ADAPT Centre{'}s submissions to the WAT 2020 document-level Business Scene Dialogue (BSD) Translation task. We only consider translating from Japanese to English for this task and we use the MarianNMT toolkit to train Transformer models. In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters. This paper outlines the experiments we ran to train our systems and report the accuracy achieved through these various experiments."
2020.wat-1.22,An Error-based Investigation of Statistical and Neural Machine Translation Performance on {H}indi-to-{T}amil and {E}nglish-to-{T}amil,2020,-1,-1,4,1,4996,akshai ramesh,Proceedings of the 7th Workshop on Asian Translation,0,"Statistical machine translation (SMT) was the state-of-the-art in machine translation (MT) research for more than two decades, but has since been superseded by neural MT (NMT). Despite producing state-of-the-art results in many translation tasks, neural models underperform in resource-poor scenarios. Despite some success, none of the present-day benchmarks that have tried to overcome this problem can be regarded as a universal solution to the problem of translation of many low-resource languages. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and NMT on two rarely-tested low-resource language-pairs, English-to-Tamil and Hindi-to-Tamil, taking a specialised data domain (software localisation) into consideration. This paper demonstrates our findings including the identification of several issues of the current neural approaches to low-resource domain-specific text translation."
2020.vardial-1.10,Neural Machine Translation for translating into {C}roatian and {S}erbian,2020,-1,-1,4,0,5059,maja popovic,"Proceedings of the 7th Workshop on NLP for Similar Languages, Varieties and Dialects",0,"In this work, we systematically investigate different set-ups for training of neural machine translation (NMT) systems for translation into Croatian and Serbian, two closely related South Slavic languages. We explore English and German as source languages, different sizes and types of training corpora, as well as bilingual and multilingual systems. We also explore translation of English IMDb user movie reviews, a domain/genre where only monolingual data are available. First, our results confirm that multilingual systems with joint target languages perform better. Furthermore, translation performance from English is much better than from German, partly because German is morphologically more complex and partly because the corpus consists mostly of parallel human translations instead of original text and its human translation. The translation from German should be further investigated systematically. For translating user reviews, creating synthetic in-domain parallel data through back- and forward-translation and adding them to a small out-of-domain parallel corpus can yield performance comparable with a system trained on a full out-of-domain corpus. However, it is still not clear what is the optimal size of synthetic in-domain data, especially for forward-translated data where the target language is machine translated. More detailed research including manual evaluation and analysis is needed in this direction."
2020.sltu-1.33,Multiple Segmentations of {T}hai Sentences for Neural Machine Translation,2020,20,0,5,1,13873,alberto poncelas,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),0,"Thai is a low-resource language, so it is often the case that data is not available in sufficient quantities to train an Neural Machine Translation (NMT) model which perform to a high level of quality. In addition, the Thai script does not use white spaces to delimit the boundaries between words, which adds more complexity when building sequence to sequence models. In this work, we explore how to augment a set of English{--}Thai parallel data by replicating sentence-pairs with different word segmentation methods on Thai, as training data for NMT model training. Using different merge operations of Byte Pair Encoding, different segmentations of Thai sentences can be obtained. The experiments show that combining these datasets, performance is improved for NMT models trained with a dataset that has been split using a supervised splitting tool."
2020.nlptea-1.2,Arabisc: Context-Sensitive Neural Spelling Checker,2020,-1,-1,3,0,15987,yasmin moslem,Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications,0,"Traditional statistical approaches to spelling correction usually consist of two consecutive processes {---} error detection and correction {---} and they are generally computationally intensive. Current state-of-the-art neural spelling correction models usually attempt to correct spelling errors directly over an entire sentence, which, as a consequence, lacks control of the process, e.g. they are prone to overcorrection. In recent years, recurrent neural networks (RNNs), in particular long short-term memory (LSTM) hidden units, have proven increasingly popular and powerful models for many natural language processing (NLP) problems. Accordingly, we made use of a bidirectional LSTM language model (LM) for our context-sensitive spelling detection and correction model which is shown to have much control over the correction process. While the use of LMs for spelling checking and correction is not new to this line of NLP research, our proposed approach makes better use of the rich neighbouring context, not only from before the word to be corrected, but also after it, via a dual-input deep LSTM network. Although in theory our proposed approach can be applied to any language, we carried out our experiments on Arabic, which we believe adds additional value given the fact that there are limited linguistic resources readily available in Arabic in comparison to many languages. Our experimental results demonstrate that the proposed methods are effective in both improving the quality of correction suggestions and minimising overcorrection."
2020.ngt-1.17,The {ADAPT} System Description for the {STAPLE} 2020 {E}nglish-to-{P}ortuguese Translation Task,2020,-1,-1,3,1,5016,rejwanul haque,Proceedings of the Fourth Workshop on Neural Generation and Translation,0,"This paper describes the ADAPT Centre{'}s submission to STAPLE (Simultaneous Translation and Paraphrase for Language Education) 2020, a shared task of the 4th Workshop on Neural Generation and Translation (WNGT), for the English-to-Portuguese translation task. In this shared task, the participants were asked to produce high-coverage sets of plausible translations given English prompts (input source sentences). We present our English-to-Portuguese machine translation (MT) models that were built applying various strategies, e.g. data and sentence selection, monolingual MT for generating alternative translations, and combining multiple n-best translations. Our experiments show that adding the aforementioned techniques to the baseline yields an excellent performance in the English-to-Portuguese translation task."
2020.lt4hala-1.7,A Tool for Facilitating {OCR} Postediting in Historical Documents,2020,17,0,5,1,13873,alberto poncelas,Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages,0,"Optical character recognition (OCR) for historical documents is a complex procedure subject to a unique set of material issues, including inconsistencies in typefaces and low quality scanning. Consequently, even the most sophisticated OCR engines produce errors. This paper reports on a tool built for postediting the output of Tesseract, more specifically for correcting common errors in digitized historical documents. The proposed tool suggests alternatives for word forms not found in a specified vocabulary. The assumed error is replaced by a presumably correct alternative in the post-edition based on the scores of a Language Model (LM). The tool is tested on a chapter of the book An Essay Towards Regulating the Trade and Employing the Poor of this Kingdom (Cary, 1719). As demonstrated below, the tool is successful in correcting a number of common errors. If sometimes unreliable, it is also transparent and subject to human intervention."
2020.lrec-1.407,The {E}uropean Language Technology Landscape in 2020: Language-Centric and Human-Centric {AI} for Cross-Cultural Communication in Multilingual {E}urope,2020,4,1,46,0,60,georg rehm,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Multilingualism is a cultural cornerstone of Europe and firmly anchored in the European treaties including full language equality. However, language barriers impacting business, cross-lingual and cross-cultural communication are still omnipresent. Language Technologies (LTs) are a powerful means to break down these barriers. While the last decade has seen various initiatives that created a multitude of approaches and technologies tailored to Europe{'}s specific needs, there is still an immense level of fragmentation. At the same time, AI has become an increasingly important concept in the European Information and Communication Technology area. For a few years now, AI {--} including many opportunities, synergies but also misconceptions {--} has been overshadowing every other topic. We present an overview of the European LT landscape, describing funding programmes, activities, actions and challenges in the different countries with regard to LT, including the current state of play in industry and the LT market. We present a brief overview of the main LT-related activities on the EU level in the last ten years and develop strategic guidance with regard to four key dimensions."
2020.lrec-1.461,On Context Span Needed for Machine Translation Evaluation,2020,-1,-1,3,0.53301,5000,sheila castilho,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Despite increasing efforts to improve evaluation of machine translation (MT) by going beyond the sentence level to the document level, the definition of what exactly constitutes a {``}document level{''} is still not clear. This work deals with the context span necessary for a more reliable MT evaluation. We report results from a series of surveys involving three domains and 18 target languages designed to identify the necessary context span as well as issues related to it. Our findings indicate that, despite the fact that some issues and spans are strongly dependent on domain and on the target language, a number of common patterns can be observed so that general guidelines for context-aware MT evaluation can be drawn."
2020.loresmt-1.14,Using Multiple Subwords to Improve {E}nglish-{E}speranto Automated Literary Translation Quality,2020,-1,-1,4,1,13873,alberto poncelas,Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages,0,"Building Machine Translation (MT) systems for low-resource languages remains challenging. For many language pairs, parallel data are not widely available, and in such cases MT models do not achieve results comparable to those seen with high-resource languages. When data are scarce, it is of paramount importance to make optimal use of the limited material available. To that end, in this paper we propose employing the same parallel sentences multiple times, only changing the way the words are split each time. For this purpose we use several Byte Pair Encoding models, with various merge operations used in their configuration. In our experiments, we use this technique to expand the available data and improve an MT system involving a low-resource language pair, namely English-Esperanto. As an additional contribution, we made available a set of English-Esperanto parallel data in the literary domain."
2020.loresmt-1.15,Investigating Low-resource Machine Translation for {E}nglish-to-{T}amil,2020,-1,-1,4,1,4996,akshai ramesh,Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages,0,"Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades has recently been superseded by the end-to-end deep learning approaches to MT. Although deep neural models produce state-of-the-art results in many translation tasks, they are found to under-perform on resource-poor scenarios. Despite some success, none of the present-day benchmarks that have tried to overcome this problem can be regarded as a universal solution to the problem of translation of many low-resource languages. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialised data domain (software localisation) into consideration. In particular, we produce rankings of our MT systems via a social media platform-based human evaluation scheme, and demonstrate our findings in the low-resource domain-specific text translation task."
2020.iwltp-1.6,"{ELRI}: A Decentralised Network of National Relay Stations to Collect, Prepare and Share Language Resources",2020,-1,-1,12,0,17606,thierry etchegoyhen,Proceedings of the 1st International Workshop on Language Technology Platforms,0,"We describe the European Language Resource Infrastructure (ELRI), a decentralised network to help collect, prepare and share language resources. The infrastructure was developed within a project co-funded by the Connecting Europe Facility Programme of the European Union, and has been deployed in the four Member States participating in the project, namely France, Ireland, Portugal and Spain. ELRI provides sustainable and flexible means to collect and share language resources via National Relay Stations, to which members of public institutions can freely subscribe. The infrastructure includes fully automated data processing engines to facilitate the preparation, sharing and wider reuse of useful language resources that can help optimise human and automated translation services in the European Union."
2020.icon-main.14,Identifying Complaints from Product Reviews: A Case Study on {H}indi,2020,-1,-1,4,0,19109,raghvendra singh,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"Automatic recognition of customer complaints on products or services that they purchase can be crucial for the organisations, multinationals and online retailers since they can exploit this information to fulfil their customers{'} expectations including managing and resolving the complaints. Recently, researchers have applied supervised learning strategies to automatically identify users{'} complaints expressed in English on Twitter. The downside of these approaches is that they require labeled training data for learning, which is expensive to create. This poses a barrier for them being applied to low-resource languages and domains for which task-specific data is not available. Machine translation (MT) can be used as an alternative to the tools that require such task-specific data. In this work, we use state-of-the-art neural MT (NMT) models for translating Hindi reviews into English and investigate performance of the downstream classification task (complaints identification) on their English translations."
2020.icon-adapmt.4,Terminology-Aware Sentence Mining for {NMT} Domain Adaptation: {ADAPT}{'}s Submission to the Adap-{MT} 2020 {E}nglish-to-{H}indi {AI} Translation Shared Task,2020,-1,-1,3,1,5016,rejwanul haque,Proceedings of the 17th International Conference on Natural Language Processing (ICON): Adap-MT 2020 Shared Task,0,"This paper describes the ADAPT Centre{'}s submission to the Adap-MT 2020 AI Translation Shared Task for English-to-Hindi. The neural machine translation (NMT) systems that we built to translate AI domain texts are state-of-the-art Transformer models. In order to improve the translation quality of our NMT systems, we made use of both in-domain and out-of-domain data for training and employed different fine-tuning techniques for adapting our NMT systems to this task, e.g. mixed fine-tuning and on-the-fly self-training. For this, we mined parallel sentence pairs and monolingual sentences from large out-of-domain data, and the mining process was facilitated through automatic extraction of terminology from the in-domain data. This paper outlines the experiments we carried out for this task and reports the performance of our NMT systems on the evaluation test set."
2020.eamt-1.21,Modelling Source- and Target- Language Syntactic Information as Conditional Context in Interactive Neural Machine Translation,2020,-1,-1,5,0,391,kamal gupta,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, which is seen as an effective way to improve the productivity gain in translation. In this study, we model source-language syntactic constituency parse and target-language syntactic descriptions in the form of supertags as conditional context for interactive prediction in neural MT (NMT). We found that the supertags significantly improve productivity gain in translation in interactive-predictive NMT (INMT), while syntactic parsing somewhat found to be effective in reducing human effort in translation. Furthermore, when we model this source- and target-language syntactic information together as the conditional context, both types complement each other and our fully syntax-informed INMT model statistically significantly reduces human efforts in a French{--}to{--}English translation task, achieving 4.30 points absolute (corresponding to 9.18{\%} relative) improvement in terms of word prediction accuracy (WPA) and 4.84 points absolute (corresponding to 9.01{\%} relative) reduction in terms of word stroke ratio (WSR) over the baseline."
2020.eamt-1.26,{MT} syntactic priming effects on {L}2 {E}nglish speakers,2020,-1,-1,3,1,5001,natalia resende,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"In this paper, we tested 20 Brazilian Portuguese speakers at intermediate and advanced English proficiency levels to investigate the influence of Google Translate{'}s MT system on the mental processing of English as a second language. To this end, we employed a syntactic priming experimental paradigm using a pretest-priming design which allowed us to compare participants{'} linguistic behaviour before and after a translation task using Google Translate. Results show that, after performing a translation task with Google Translate, participants more frequently described images in English using the syntactic alternative previously seen in the output of Google Translate, compared to the translation task with no prior influence of the MT output. Results also show that this syntactic priming effect is modulated by English proficiency levels."
2020.eamt-1.46,A human evaluation of {E}nglish-{I}rish statistical and neural machine translation,2020,-1,-1,5,1,20874,meghan dowling,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"With official status in both Ireland and the EU, there is a need for high-quality English-Irish (EN-GA) machine translation (MT) systems which are suitable for use in a professional translation environment. While we have seen recent research on improving both statistical MT and neural MT for the EN-GA pair, the results of such systems have always been reported using automatic evaluation metrics. This paper provides the first human evaluation study of EN-GA MT using professional translators and in-domain (public administration) data for a more accurate depiction of the translation quality available via MT."
2020.eamt-1.54,"Progress of the {PRINCIPLE} Project: Promoting {MT} for {C}roatian, {I}celandic, {I}rish and {N}orwegian",2020,-1,-1,1,1,2631,andy way,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"This paper updates the progress made on the PRINCIPLE project, a 2-year action funded by the European Commission under the Connecting Europe Facility (CEF) programme. PRINCIPLE focuses on collecting high-quality language resources for Croatian, Icelandic, Irish and Norwegian, which have been identified as low-resource languages, especially for building effective machine translation (MT) systems. We report initial achievements of the project and ongoing activities aimed at promoting the uptake of neural MT for the low-resource languages of the project."
2020.eamt-1.69,{MT}rill project: Machine Translation impact on language learning,2020,-1,-1,2,1,5001,natalia resende,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"Over the last decades, massive research investments have been made in the development of machine translation (MT) systems (Gupta and Dhawan, 2019). This has brought about a paradigm shift in the performance of these language tools, leading to widespread use of popular MT systems (Gaspari and Hutchins, 2007). Although the first MT engines were used for gisting purposes, in recent years, there has been an increasing interest in using MT tools, especially the freely available online MT tools, for language teaching and learning (Clifford et al., 2013). The literature on MT and Computer Assisted Language Learning (CALL) shows that, over the years, MT systems have been facilitating language teaching and also language learning (Nin Ìo, 2006). It has been shown that MT tools can increase awareness of grammatical linguistic features of a foreign language. Research also shows the positive role of MT systems in the development of writing skills in English as well as in improving communication skills in English(Garcia and Pena, 2011). However, to date, the cognitive impact of MT on language acquisition and on the syntactic aspects of language processing has not yet been investigated and deserves further scrutiny. The MTril project aims at filling this gap in the literature by examining whether MT is contributing to a central aspect of language acquisition: the so-called language binding, i.e., the ability to combine single words properly in a grammatical sentence (Heyselaar et al., 2017; Ferreira and Bock, 2006). The project focus on the initial stages (pre-intermediate and intermediate) of the acquisition of English syntax by Brazilian Portuguese native speakers using MT systems as a support for language learning."
2020.amta-research.4,Constraining the Transformer {NMT} Model with Heuristic Grid Beam Search,2020,-1,-1,2,0,22363,guodong xie,Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track),0,None
2020.amta-research.7,The Impact of Indirect Machine Translation on Sentiment Classification,2020,-1,-1,4,1,13873,alberto poncelas,Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track),0,None
2020.amta-impact.4,"A Case Study of Natural Gender Phenomena in Translation: A Comparison of {G}oogle {T}ranslate, Bing {M}icrosoft Translator and {D}eep{L} for {E}nglish to {I}talian, {F}rench and {S}panish",2020,-1,-1,3,0,22375,argentina rescigno,Workshop on the Impact of Machine Translation (iMpacT 2020),0,None
2020.acl-srw.25,Effectively Aligning and Filtering Parallel Corpora under Sparse Data Conditions,2020,-1,-1,3,0.666667,2629,steinthor steingrimsson,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"Parallel corpora are key to developing good machine translation systems. However, abundant parallel data are hard to come by, especially for languages with a low number of speakers. When rich morphology exacerbates the data sparsity problem, it is imperative to have accurate alignment and filtering methods that can help make the most of what is available by maximising the number of correctly translated segments in a corpus and minimising noise by removing incorrect translations and segments containing extraneous data. This paper sets out a research plan for improving alignment and filtering methods for parallel texts in low-resource settings. We propose an effective unsupervised alignment method to tackle the alignment problem. Moreover, we propose a strategy to supplement state-of-the-art models with automatically extracted information using basic NLP tools to effectively handle rich morphology."
2020.acl-main.359,Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation,2020,36,0,4,0,13932,xabier soto,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Machine translation (MT) has benefited from using synthetic training data originating from translating monolingual corpora, a technique known as backtranslation. Combining backtranslated data from different sources has led to better results than when using such data in isolation. In this work we analyse the impact that data translated with rule-based, phrase-based statistical and neural MT systems has on new MT systems. We use a real-world low-resource use-case (Basque-to-Spanish in the clinical domain) as well as a high-resource language pair (German-to-English) to test different scenarios with backtranslation and employ data selection to optimise the synthetic corpora. We exploit different data selection strategies in order to reduce the amount of data used, while at the same time maintaining high-quality MT systems. We further tune the data selection method by taking into account the quality of the MT systems used for backtranslation and lexical diversity of the resulting corpora. Our experiments show that incorporating backtranslated data from different sources can be beneficial, and that availing of data selection can yield improved performance."
W19-8629,Selecting Artificially-Generated Sentences for Fine-Tuning Neural Machine Translation,2019,28,0,2,1,13873,alberto poncelas,Proceedings of the 12th International Conference on Natural Language Generation,0,"Neural Machine Translation (NMT) models tend to achieve the best performances when larger sets of parallel sentences are provided for training. For this reason, augmenting the training set with artificially-generated sentence pair can boost the performance. Nonetheless, the performance can also be improved with a small number of sentences if they are in the same domain as the test set. Accordingly, we want to explore the use of artificially-generated sentence along with data-selection algorithms to improve NMT models trained solely with authentic data. In this work, we show how artificially-generated sentences can be more beneficial than authentic pairs and what are their advantages when used in combination with data-selection algorithms."
W19-7202,Transductive Data-Selection Algorithms for Fine-Tuning Neural Machine Translation,2019,38,1,3,1,13873,alberto poncelas,Proceedings of The 8th Workshop on Patent and Scientific Literature Translation,0,"Machine Translation models are trained to translate a variety of documents from one language into another. However, models specifically trained for a particular characteristics of the documents tend to perform better. Fine-tuning is a technique for adapting an NMT model to some domain. In this work, we want to use this technique to adapt the model to a given test set. In particular, we are using transductive data selection algorithms which take advantage the information of the test set to retrieve sentences from a larger parallel set. n In cases where the model is available at translation time (when the test set is provided), it can be adapted with a small subset of data, thereby achieving better performance than a generic model or a domain-adapted model."
W19-6908,Leveraging backtranslation to improve machine translation for {G}aelic languages,2019,-1,-1,3,1,20874,meghan dowling,Proceedings of the Celtic Language Technology Workshop,0,None
W19-6718,"{PRINCIPLE}: Providing Resources in {I}rish, {N}orwegian, {C}roatian and {I}celandic for the Purposes of Language Engineering",2019,-1,-1,1,1,2631,andy way,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,None
W19-6722,Pivot Machine Translation in {INTERACT} Project,2019,0,0,2,1,5085,chaohong liu,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,None
W19-6732,Large-scale Machine Translation Evaluation of the i{ADAATPA} Project,2019,0,0,4,0.616048,5000,sheila castilho,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,"This paper reports the results of an indepth evaluation of 34 state-of-the-art domain-adapted machine translation (MT) systems that were built by four leading MT companies as part of the EU-funded iADAATPA project. These systems support a wide variety of languages for several domains. The evaluation combined automatic metrics and human methods, namely assessments of adequacy, xefxacx82uency, and comparative ranking. The paper also discusses the most effective techniques to build domain-adapted MT systems for the relevant language combinations and domains."
W19-6738,When less is more in Neural Quality Estimation of Machine Translation. An industry case study,2019,0,0,7,1,4966,dimitar shterionov,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,"Quality estimation (QE) of machine translation (MT), the task of predicting the quality of an MT output without human references, is particularly suitable in dynamic translation workxefxacx82ows, where translations need to be assessed continuously with no specixefxacx81c reference provided. In this paper, we investigate sentence-level neural QE and its applicability in an industry use case. We assess six QE approaches, which we divide into two-phase and one-phase approaches, based on quality and cost. Our evaluation shows that while two-phase systems perform best in terms of the predicted QE scores, their computational costs suggest that alternatives should be considered for large-scale translation production."
W19-6622,Lost in Translation: Loss and Decay of Linguistic Richness in Machine Translation,2019,24,0,3,1,5078,eva vanmassenhove,Proceedings of Machine Translation Summit XVII: Research Track,0,"This work presents an empirical approach to quantifying the loss of lexical richness in Machine Translation (MT) systems compared to Human Translation (HT). Our experiments show how current MT systems indeed fail to render the lexical diversity of human generated or translated text. The inability of MT systems to generate diverse outputs and its tendency to exacerbate already frequent patterns while ignoring less frequent ones, might be the underlying cause for, among others, the currently heavily debated issues related to gender biased output. Can we indeed, aside from biased data, talk about an algorithm that exacerbates seen biases?"
W19-3715,Building {E}nglish-to-{S}erbian Machine Translation System for {IMD}b Movie Reviews,2019,0,0,3,1,22365,pintu lohar,Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing,0,"This paper reports the results of the first experiment dealing with the challenges of building a machine translation system for user-generated content involving a complex South Slavic language. We focus on translation of English IMDb user movie reviews into Serbian, in a low-resource scenario. We explore potentials and limits of (i) phrase-based and neural machine translation systems trained on out-of-domain clean parallel data from news articles (ii) creating additional synthetic in-domain parallel corpus by machine-translating the English IMDb corpus into Serbian. Our main findings are that morphology and syntax are better handled by the neural approach than by the phrase-based approach even in this low-resource mismatched domain scenario, however the situation is different for the lexical aspect, especially for person names. This finding also indicates that in general, machine translation of person names into Slavic languages (especially those which require/allow transcription) should be investigated more systematically."
R19-1052,Investigating Terminology Translation in Statistical and Neural Machine Translation: A Case Study on {E}nglish-to-{H}indi and {H}indi-to-{E}nglish,2019,0,0,3,1,5016,rejwanul haque,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Terminology translation plays a critical role in domain-specific machine translation (MT). In this paper, we conduct a comparative qualitative evaluation on terminology translation in phrase-based statistical MT (PB-SMT) and neural MT (NMT) in two translation directions: English-to-Hindi and Hindi-to-English. For this, we select a test set from a legal domain corpus and create a gold standard for evaluating terminology translation in MT. We also propose an error typology taking the terminology translation errors into consideration. We evaluate the MT systems{'} performance on terminology translation, and demonstrate our findings, unraveling strengths, weaknesses, and similarities of PB-SMT and NMT in the area of term translation."
R19-1107,Combining {PBSMT} and {NMT} Back-translated Data for Efficient {NMT},2019,21,1,5,1,13873,alberto poncelas,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Neural Machine Translation (NMT) models achieve their best performance when large sets of parallel data are used for training. Consequently, techniques for augmenting the training set have become popular recently. One of these methods is back-translation, which consists on generating synthetic sentences by translating a set of monolingual, target-language sentences using a Machine Translation (MT) model. Generally, NMT models are used for back-translation. In this work, we analyze the performance of models when the training data is extended with synthetic data using different MT approaches. In particular we investigate back-translated data generated not only by NMT but also by Statistical Machine Translation (SMT) models and combinations of both. The results reveal that the models achieve the best performances when the training set is augmented with back-translated data created by merging different MT approaches."
W18-6312,Attaining the Unattainable? Reassessing Claims of Human Parity in Neural Machine Translation,2018,0,20,4,0,9426,antonio toral,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"We reassess a recent study (Hassan et al., 2018) that claimed that machine translation (MT) has reached human parity for the translation of news from Chinese into English, using pairwise ranking and considering three variables that were not taken into account in that previous study: the language in which the source side of the test set was originally written, the translation proficiency of the evaluators, and the provision of inter-sentential context. If we consider only original source text (i.e. not translated from another language, or translationese), then we find evidence showing that human parity has not been achieved. We compare the judgments of professional translators against those of non-experts and discover that those of the experts result in higher inter-annotator agreement and better discrimination between human and machine translations. In addition, we analyse the human translations of the test set and identify important translation issues. Finally, based on these findings, we provide a set of recommendations for future human evaluations of MT."
W18-6323,Extracting In-domain Training Corpora for Neural Machine Translation Using Data Selection Methods,2018,0,4,4,0,23595,catarina silva,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"Data selection is a process used in selecting a subset of parallel data for the training of machine translation (MT) systems, so that 1) resources for training might be reduced, 2) trained models could perform better than those trained with the whole corpus, and/or 3) trained models are more tailored to specific domains. It has been shown that for statistical MT (SMT), the use of data selection helps improve the MT performance significantly. In this study, we reviewed three data selection approaches for MT, namely Term Frequency{--} Inverse Document Frequency, Cross-Entropy Difference and Feature Decay Algorithm, and conducted experiments on Neural Machine Translation (NMT) with the selected data using the three approaches. The results showed that for NMT systems, using data selection also improved the performance, though the gain is not as much as for SMT systems."
W18-2202,{SMT} versus {NMT}: Preliminary comparisons for {I}rish,2018,0,3,4,1,20874,meghan dowling,Proceedings of the {AMTA} 2018 Workshop on Technologies for {MT} of Low Resource Languages ({L}o{R}es{MT} 2018),0,"In this paper, we provide a preliminary comparison of statistical machine translation (SMT)n and neural machine translation (NMT) for Englishxe2x86x92Irish in the fixed domain of public administration. We discuss the challenges for SMT and NMT of a less-resourced language suchn as Irish, and show that while an out-of-the-box NMT system may not fare quite as well asn our tailor-made domain-specific SMT system, the future may still be promising for ENxe2x86x92GAn NMT"
W18-1808,Balancing Translation Quality and Sentiment Preservation (Non-archival Extended Abstract),2018,0,1,3,1,22365,pintu lohar,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,None
P18-3010,{S}uper{NMT}: Neural Machine Translation with Semantic Supersenses and Syntactic Supertags,2018,0,1,2,1,5078,eva vanmassenhove,"Proceedings of {ACL} 2018, Student Research Workshop",0,"In this paper we incorporate semantic supersensetags and syntactic supertag features into EN{--}FR and EN{--}DE factored NMT systems. In experiments on various test sets, we observe that such features (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores."
N18-1006,Improving Character-Based Decoding Using Target-Side Morphological Information for Neural Machine Translation,2018,19,2,3,1,7213,peyman passban,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Recently, neural machine translation (NMT) has emerged as a powerful alternative to conventional statistical approaches. However, its performance drops considerably in the presence of morphologically rich languages (MRLs). Neural engines usually fail to tackle the large vocabulary and high out-of-vocabulary (OOV) word rate of MRLs. Therefore, it is not suitable to exploit existing word-based models to translate this set of languages. In this paper, we propose an extension to the state-of-the-art model of Chung et al. (2016), which works at the character level and boosts the decoder with target-side morphological information. In our architecture, an additional morphology table is plugged into the model. Each time the decoder samples from a target vocabulary, the table sends auxiliary signals from the most relevant affixes in order to enrich the decoder{'}s current state and constrain it to provide better predictions. We evaluated our model to translate English into German, Russian, and Turkish as three MRLs and observed significant improvements."
N18-1061,Fine-Grained Temporal Orientation and its Relationship with Psycho-Demographic Correlates,2018,0,0,5,0,29421,sabyasachi kamila,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Temporal orientation refers to an individual{'}s tendency to connect to the psychological concepts of past, present or future, and it affects personality, motivation, emotion, decision making and stress coping processes. The study of the social media users{'} psycho-demographic attributes from the perspective of human temporal orientation can be of utmost interest and importance to the business and administrative decision makers as it can provide an extra precious information for them to make informed decisions. In this paper, we propose a very first study to demonstrate the association between the sentiment view of the temporal orientation of the users and their different psycho-demographic attributes by analyzing their tweets. We first create a temporal orientation classifier in a minimally supervised way which classifies each tweet of the users in one of the three temporal categories, namely past, present, and future. A deep Bi-directional Long Short Term Memory (BLSTM) is used for the tweet classification task. Our tweet classifier achieves an accuracy of 78.27{\%} when tested on a manually created test set. We then determine the users{'} overall temporal orientation based on their tweets on the social media. The sentiment is added to the tweets at the fine-grained level where each temporal tweet is given a sentiment with either of the positive, negative or neutral. Our experiment reveals that depending upon the sentiment view of temporal orientation, a user{'}s attributes vary. We finally measure the correlation between the users{'} sentiment view of temporal orientation and their different psycho-demographic factors using regression."
L18-1422,{F}oo{T}weets: A Bilingual Parallel Corpus of World Cup Tweets,2018,0,0,4,0,16881,henny sluytergathje,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"The way information spreads through society has changed significantly over the past decade with the advent of online social networking.n Twitter, one of the most widely used social networking websites, is known as the real-time, public microblogging network where newsn breaks first. Most users love it for its iconic 140-character limitation and unfiltered feed that show them news and opinions in then form of tweets. Tweets are usually multilingual in nature and of varying quality. However, machine translation (MT) of twitter datan is a challenging task especially due to the following two reasons: (i) tweets are informal in nature (i.e., violates linguistic norms), andn (ii) parallel resource for twitter data is scarcely available on the Internet. In this paper, we develop FooTweets, a first parallel corpus ofn tweets for Englishxe2x80x93German language pair. We extract 4, 000 English tweets from the FIFA 2014 world cup and manually translate themn into German with a special focus on the informal nature of the tweets. In addition to this, we also annotate sentiment scores between 0n and 1 to all the tweets depending upon the degree of sentiment associated with them. This data has recently been used to build sentimentn translation engines and an extensive evaluation revealed that such a resource is very useful in machine translation of user generatedn content."
D18-1245,Multi-Level Structured Self-Attentions for Distantly Supervised Relation Extraction,2018,0,11,3,1,21659,jinhua du,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Attention mechanism is often used in deep neural networks for distantly supervised relation extraction (DS-RE) to distinguish valid from noisy instances. However, traditional 1-D vector attention model is insufficient for learning of different contexts in the selection of valid instances to predict the relationship for an entity pair. To alleviate this issue, we propose a novel multi-level structured (2-D matrix) self-attention mechanism for DS-RE in a multi-instance learning (MIL) framework using bidirectional recurrent neural networks (BiRNN). In the proposed method, a structured word-level self-attention learns a 2-D matrix where each row vector represents a weight distribution for different aspects of an instance regarding two entities. Targeting the MIL issue, the structured sentence-level attention learns a 2-D matrix where each row vector represents a weight distribution on selection of different valid instances. Experiments conducted on two publicly available DS-RE datasets show that the proposed framework with multi-level structured self-attention mechanism significantly outperform baselines in terms of PR curves, P@N and F1 measures."
D18-1333,Learning to Jointly Translate and Predict Dropped Pronouns with a Shared Reconstruction Mechanism,2018,12,2,3,1,7026,longyue wang,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Pronouns are frequently omitted in pro-drop languages, such as Chinese, generally leading to significant challenges with respect to the production of complete translations. Recently, Wang et al. (2018) proposed a novel reconstruction-based approach to alleviating dropped pronoun (DP) translation problems for neural machine translation models. In this work, we improve the original model from two perspectives. First, we employ a shared reconstructor to better exploit encoder and decoder representations. Second, we jointly learn to translate and predict DPs in an end-to-end manner, to avoid the errors propagated from an external DP prediction model. Experimental results show that our approach significantly improves both translation performance and DP prediction accuracy."
D18-1334,Getting Gender Right in Neural Machine Translation,2018,22,18,3,1,5078,eva vanmassenhove,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly (Sapir, 1921; Slobin, 1996). One such difference is related to the way gender is expressed in a language. Saying {``}I am happy{''} in English, does not encode any additional knowledge of the speaker that uttered the sentence. However, many other languages do have grammatical gender systems and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, French, the inherent gender information needs to be retained/recovered. The same sentence would become either {``}Je suis heureux{''}, for a male speaker or {``}Je suis heureuse{''} for a female one. Apart from morphological agreement, demographic factors (gender, age, etc.) also influence our use of language in terms of word choices or syntactic constructions (Tannen, 1991; Pennebaker et al., 2003). We integrate gender information into NMT systems. Our contribution is two-fold: (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs."
C18-1265,Tailoring Neural Architectures for Translating from Morphologically Rich Languages,2018,0,2,2,1,7213,peyman passban,Proceedings of the 27th International Conference on Computational Linguistics,0,"A morphologically complex word (MCW) is a hierarchical constituent with meaning-preserving subunits, so word-based models which rely on surface forms might not be powerful enough to translate such structures. When translating from morphologically rich languages (MRLs), a source word could be mapped to several words or even a full sentence on the target side, which means an MCW should not be treated as an atomic unit. In order to provide better translations for MRLs, we boost the existing neural machine translation (NMT) architecture with a double- channel encoder and a double-attentive decoder. The main goal targeted in this research is to provide richer information on the encoder side and redesign the decoder accordingly to benefit from such information. Our experimental results demonstrate that we could achieve our goal as the proposed model outperforms existing subword- and character-based architectures and showed significant improvements on translating from German, Russian, and Turkish into English."
C18-1321,Incorporating Deep Visual Features into Multiobjective based Multi-view Search Results Clustering,2018,0,1,4,0,30937,sayantan mitra,Proceedings of the 27th International Conference on Computational Linguistics,0,"Current paper explores the use of multi-view learning for search result clustering. A web-snippet can be represented using multiple views. Apart from textual view cued by both the semantic and syntactic information, a complimentary view extracted from images contained in the web-snippets is also utilized in the current framework. A single consensus partitioning is finally obtained after consulting these two individual views by the deployment of a multiobjective based clustering technique. Several objective functions including the values of a cluster quality measure measuring the goodness of partitionings obtained using different views and an agreement-disagreement index, quantifying the amount of oneness among multiple views in generating partitionings are optimized simultaneously using AMOSA. In order to detect the number of clusters automatically, concepts of variable length solutions and a vast range of permutation operators are introduced in the clustering process. Finally, a set of alternative partitioning are obtained on the final Pareto front by the proposed multi-view based multiobjective technique. Experimental results by the proposed approach on several benchmark test datasets of SRC with respect to different performance metrics evidently establish the power of visual and text-based views in achieving better search result clustering."
W17-5602,{M}ulti{N}ews: A Web collection of an Aligned Multimodal and Multilingual Corpus,2017,0,1,3,1,5094,haithem afli,Proceedings of the First Workshop on Curation and Applications of Parallel and Comparable Corpora,0,"Integrating Natural Language Processing (NLP) and computer vision is a promising effort. However, the applicability of these methods directly depends on the availability of a specific multimodal data that includes images and texts. In this paper, we present a collection of a Multimodal corpus of comparable texts and their images in 9 languages from the web news articles of Euronews website. This corpus has found widespread use in the NLP community in Multilingual and multimodal tasks. Here, we focus on its acquisition of the images and text data and their multilingual alignment."
W17-2004,Human Evaluation of Multi-modal Neural Machine Translation: A Case-Study on {E}-Commerce Listing Titles,2017,25,2,5,0,4092,iacer calixto,Proceedings of the Sixth Workshop on Vision and Language,0,"In this paper, we study how humans perceive the use of images as an additional knowledge source to machine-translate user-generated product listings in an e-commerce company. We conduct a human evaluation where we assess how a multi-modal neural machine translation (NMT) model compares to two text-only approaches: a conventional state-of-the-art attention-based NMT and a phrase-based statistical machine translation (PBSMT) model. We evaluate translations obtained with different systems and also discuss the data set of user-generated product listings, which in our case comprises both product listings and associated images. We found that humans preferred translations obtained with a PBSMT system to both text-only and multi-modal NMT over 56{\%} of the time. Nonetheless, human evaluators ranked translations from a multi-modal NMT model as better than those of a text-only NMT over 88{\%} of the time, which suggests that images do help NMT in this use-case."
W17-1608,Ethical Considerations in {NLP} Shared Tasks,2017,9,5,5,0.821677,4995,carla escartin,Proceedings of the First {ACL} Workshop on Ethics in Natural Language Processing,0,"Shared tasks are increasingly common in our field, and new challenges are suggested at almost every conference and workshop. However, as this has become an established way of pushing research forward, it is important to discuss how we researchers organise and participate in shared tasks, and make that information available to the community to allow further research improvements. In this paper, we present a number of ethical issues along with other areas of concern that are related to the competitive nature of shared tasks. As such issues could potentially impact on research ethics in the Natural Language Processing community, we also propose the development of a framework for the organisation of and participation in shared tasks that can help mitigate against these issues arising."
W17-1313,Identifying Effective Translations for Cross-lingual {A}rabic-to-{E}nglish User-generated Speech Search,2017,19,1,4,0,32067,ahmad khwileh,Proceedings of the Third {A}rabic Natural Language Processing Workshop,0,"Cross Language Information Retrieval (CLIR) systems are a valuable tool to enable speakers of one language to search for content of interest expressed in a different language. A group for whom this is of particular interest is bilingual Arabic speakers who wish to search for English language content using information needs expressed in Arabic queries. A key challenge in CLIR is crossing the language barrier between the query and the documents. The most common approach to bridging this gap is automated query translation, which can be unreliable for vague or short queries. In this work, we examine the potential for improving CLIR effectiveness by predicting the translation effectiveness using Query Performance Prediction (QPP) techniques. We propose a novel QPP method to estimate the quality of translation for an Arabic-English Cross-lingual User-generated Speech Search (CLUGS) task. We present an empirical evaluation that demonstrates the quality of our method on alternative translation outputs extracted from an Arabic-to-English Machine Translation system developed for this task. Finally, we show how this framework can be integrated in CLUGS to find relevant translations for improved retrieval performance."
I17-4027,{ADAPT} at {IJCNLP}-2017 Task 4: A Multinomial Naive {B}ayes Classification Approach for Customer Feedback Analysis task,2017,0,0,5,1,22365,pintu lohar,"Proceedings of the {IJCNLP} 2017, Shared Tasks",0,"In this age of the digital economy, promoting organisations attempt their best to engage the customers in the feedback provisioning process. With the assistance of customer insights, an organisation can develop a better product and provide a better service to its customer. In this paper, we analyse the real world samples of customer feedback from Microsoft Office customers in four languages, i.e., English, French, Spanish and Japanese and conclude a five-plus-one-classes categorisation (comment, request, bug, complaint, meaningless and undetermined) for meaning classification. The task is to {\%}access multilingual corpora annotated by the proposed meaning categorization scheme and develop a system to determine what class(es) the customer feedback sentences should be annotated as in four languages. We propose following approaches to accomplish this task: (i) a multinomial naive bayes (MNB) approach for multi-label classification, (ii) MNB with one-vs-rest classifier approach, and (iii) the combination of the multilabel classification-based and the sentiment classification-based approach. Our best system produces F-scores of 0.67, 0.83, 0.72 and 0.7 for English, Spanish, French and Japanese, respectively. The results are competitive to the best ones for all languages and secure 3rd and 5th position for Japanese and French, respectively, among all submitted systems."
I17-3009,Semantics-Enhanced Task-Oriented Dialogue Translation: A Case Study on Hotel Booking,2017,0,2,5,1,7026,longyue wang,"Proceedings of the {IJCNLP} 2017, System Demonstrations",0,"We showcase TODAY, a semantics-enhanced task-oriented dialogue translation system, whose novelties are: (i) task-oriented named entity (NE) definition and a hybrid strategy for NE recognition and translation; and (ii) a novel grounded semantic method for dialogue understanding and task-order management. TODAY is a case-study demo which can efficiently and accurately assist customers and agents in different languages to reach an agreement in a dialogue for the hotel booking."
I17-1093,Demographic Word Embeddings for Racism Detection on {T}witter,2017,24,3,3,1,15356,mohammed hasanuzzaman,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"Most social media platforms grant users freedom of speech by allowing them to freely express their thoughts, beliefs, and opinions. Although this represents incredible and unique communication opportunities, it also presents important challenges. Online racism is such an example. In this study, we present a supervised learning strategy to detect racist language on Twitter based on word embedding that incorporate demographic (Age, Gender, and Location) information. Our methodology achieves reasonable classification accuracy over a gold standard dataset (F1=76.3{\%}) and significantly improves over the classification performance of demographic-agnostic models."
E17-2095,Context-Aware Graph Segmentation for Graph-Based Translation,2017,10,0,2,1,5774,liangyou li,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"In this paper, we present an improved graph-based translation model which segments an input graph into node-induced subgraphs by taking source context into consideration. Translations are generated by combining subgraph translations left-to-right using beam search. Experiments on Chinese{--}English and German{--}English demonstrate that the context-aware segmentation significantly improves the baseline graph-based model."
E17-2101,Using Images to Improve Machine-Translating {E}-Commerce Product Listings.,2017,25,5,6,0,4092,iacer calixto,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"In this paper we study the impact of using images to machine-translate user-generated e-commerce product listings. We study how a multi-modal Neural Machine Translation (NMT) model compares to two text-only approaches: a conventional state-of-the-art attentional NMT and a Statistical Machine Translation (SMT) model. User-generated product listings often do not constitute grammatical or well-formed sentences. More often than not, they consist of the juxtaposition of short phrases or keywords. We train our models end-to-end as well as use text-only and multi-modal NMT models for re-ranking $n$-best lists generated by an SMT model. We qualitatively evaluate our user-generated training data also analyse how adding synthetic data impacts the results. We evaluate our models quantitatively using BLEU and TER and find that (i) additional synthetic data has a general positive impact on text-only and multi-modal NMT models, and that (ii) using a multi-modal NMT model for re-ranking n-best lists improves TER significantly across different n-best list sizes."
D17-1301,Exploiting Cross-Sentence Context for Neural Machine Translation,2017,18,24,3,1,7026,longyue wang,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"In translation, considering the document as a whole can help to resolve ambiguities and inconsistencies. In this paper, we propose a cross-sentence context-aware approach and investigate the influence of historical contextual information on the performance of neural machine translation (NMT). First, this history is summarized in a hierarchical way. We then integrate the historical representation into NMT in two strategies: 1) a warm-start of encoder and decoder states, and 2) an auxiliary context source for updating decoder states. Experimental results on a large Chinese-English translation task show that our approach significantly improves upon a strong attention-based NMT system by up to +2.1 BLEU points."
W16-4015,Integrating Optical Character Recognition and Machine Translation of Historical Documents,2016,17,0,2,1,5094,haithem afli,Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities ({LT}4{DH}),0,"Machine Translation (MT) plays a critical role in expanding capacity in the translation industry. However, many valuable documents, including digital documents, are encoded in non-accessible formats for machine processing (e.g., Historical or Legal documents). Such documents must be passed through a process of Optical Character Recognition (OCR) to render the text suitable for MT. No matter how good the OCR is, this process introduces recognition errors, which often renders MT ineffective. In this paper, we propose a new OCR to MT framework based on adding a new OCR error correction module to enhance the overall quality of translation. Experimentation shows that our new system correction based on the combination of Language Modeling and Translation methods outperforms the baseline system by nearly 30{\%} relative improvement."
W16-3403,Improving Phrase-Based {SMT} Using Cross-Granularity Embedding Similarity,2016,19,2,3,1,7213,peyman passban,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W16-3404,Comparing Translator Acceptability of {TM} and {SMT} Outputs,2016,13,3,2,0.921596,20875,joss moorkens,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W16-2372,The {ADAPT} Bilingual Document Alignment system at {WMT}16,2016,14,3,4,1,22365,pintu lohar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"Comparable corpora have been shown ton be useful in several multilingual naturaln language processing (NLP) tasks. Manyn previous papers have focused on how ton improve the extraction of parallel datan from this kind of corpus on different levels. In this paper, we are interested in improving the quality of bilingual comparable corpora according to increased document alignment score. We describe ourn participation in the bilingual documentn alignment shared task of the First Conference on Machine Translation (WMT16).n We propose a technique based on sourceto-target sentence- and word-based scoresn and the fraction of matched source namedn entities. We performed our experiments onn English-to-French document alignmentsn for this bilingual task."
W16-0602,Extending Phrase-Based Translation with Dependencies by Using Graphs,2016,13,0,2,1,5774,liangyou li,Proceedings of the 2nd Workshop on Semantics-Driven Machine Translation ({S}ed{MT} 2016),0,"In this paper, we propose a graph-based translation model which takes advantage of discontinuous phrases. The model segments a graph which combines bigram and dependency relations into subgraphs and produces translations by combining translations of these subgraphs. Experiments on Chinesexe2x80x90English and Germanxe2x80x90English tasks show that our system is significantly better than the phrase-based model. By explicitly modeling the graph segmentation, our system gains further improvement."
P16-2045,Phrase-Level Combination of {SMT} and {TM} Using Constrained Word Lattice,2016,17,1,2,1,5774,liangyou li,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Constrained translation has improved statistical machine translation (SMT) by combining it with translation memory (TM) at sentence-level. In this paper, we propose using a constrained word lattice, which encodes input phrases and TM constraints together, to combine SMT and TM at phrase-level. Experiments on Englishxe2x80x90 Chinese and Englishxe2x80x90French show that our approach is significantly better than previous combination methods, including sentence-level constrained translation and a recent phrase-level combination."
P16-1010,Graph-Based Translation Via Graph Segmentation,2016,27,0,2,1,5774,liangyou li,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
N16-1113,A Novel Approach to Dropped Pronoun Translation,2016,32,6,5,1,7026,longyue wang,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Dropped Pronouns (DP) in which pronounsn are frequently dropped in the source languagen but should be retained in the target languagen are challenge in machine translation. In response to this problem, we propose a semisupervised approach to recall possibly missingn pronouns in the translation. Firstly, we buildn training data for DP generation in which then DPs are automatically labelled according ton the alignment information from a parallel corpus. Secondly, we build a deep learning-basedn DP generator for input sentences in decodingn when no corresponding references exist. Moren specifically, the generation is two-phase: (1)n DP position detection, which is modeled as an sequential labelling task with recurrent neuraln networks; and (2) DP prediction, which employs a multilayer perceptron with rich features. Finally, we integrate the above outputsn into our translation system to recall missingn pronouns by both extracting rules from then DP-labelled training data and translating then DP-generated input sentences. Experimentaln results show that our approach achieves a significant improvement of 1.58 BLEU points inn translation performance with 66% F-score forn DP generation accuracy."
L16-1002,Using {B}abel{N}et to Improve {OOV} Coverage in {SMT},2016,0,8,2,1,21659,jinhua du,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Out-of-vocabulary words (OOVs) are a ubiquitous and difficult problem in statistical machine translation (SMT). This paper studies different strategies of using BabelNet to alleviate the negative impact brought about by OOVs. BabelNet is a multilingual encyclopedic dictionary and a semantic network, which not only includes lexicographic and encyclopedic terms, but connects concepts and named entities in a very large network of semantic relations. By taking advantage of the knowledge in BabelNet, three different methods â using direct training data, domain-adaptation techniques and the BabelNet API â are proposed in this paper to obtain translations for OOVs to improve system performance. Experimental results on EnglishâPolish and EnglishâChinese language pairs show that domain adaptation can better utilize BabelNet knowledge and performs better than other methods. The results also demonstrate that BabelNet is a really useful tool for improving translation performance of SMT systems."
L16-1003,Enhancing Access to Online Education: Quality Machine Translation of {MOOC} Content,2016,19,1,8,0,12066,valia kordoni,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The present work is an overview of the TraMOOC (Translation for Massive Open Online Courses) research and innovation project, a machine translation approach for online educational content. More specifically, videolectures, assignments, and MOOC forum text is automatically translated from English into eleven European and BRIC languages. Unlike previous approaches to machine translation, the output quality in TraMOOC relies on a multimodal evaluation schema that involves crowdsourcing, error type markup, an error taxonomy for translation model comparison, and implicit evaluation via text mining, i.e. entity recognition and its performance comparison between the source and the translated text, and sentiment analysis on the students{'} forum posts. Finally, the evaluation output will result in more and better quality in-domain parallel data that will be fed back to the translation engine for higher quality output. The translation service will be incorporated into the Iversity MOOC platform and into the VideoLectures.net digital library portal."
L16-1153,Using {SMT} for {OCR} Error Correction of Historical Texts,2016,12,10,3,1,5094,haithem afli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"A trend to digitize historical paper-based archives has emerged in recent years, with the advent of digital optical scanners. A lot of paper-based books, textbooks, magazines, articles, and documents are being transformed into electronic versions that can be manipulated by a computer. For this purpose, Optical Character Recognition (OCR) systems have been developed to transform scanned digital text into editable computer text. However, different kinds of errors in the OCR system output text can be found, but Automatic Error Correction tools can help in performing the quality of electronic texts by cleaning and removing noises. In this paper, we perform a qualitative and quantitative comparison of several error-correction techniques for historical French documents. Experimentation shows that our Machine Translation for Error Correction method is superior to other Language Modelling correction techniques, with nearly 13{\%} relative improvement compared to the initial baseline."
L16-1352,{P}rophet{MT}: A Tree-based {SMT}-driven Controlled Language Authoring/Post-Editing Tool,2016,0,0,4,1,35090,xiaofeng wu,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents ProphetMT, a tree-based SMT-driven Controlled Language (CL) authoring and post-editing tool. ProphetMT employs the source-side rules in a translation model and provides them as auto-suggestions to users. Accordingly, one might say that users are writing in a Controlled Language that is understood by the computer. ProphetMT also allows users to easily attach structural information as they compose content. When a specific rule is selected, a partial translation is promptly generated on-the-fly with the help of the structural information. Our experiments conducted on English-to-Chinese show that our proposed ProphetMT system can not only better regularise an author{'}s writing behaviour, but also significantly improve translation fluency which is vital to reduce the post-editing time. Additionally, when the writing and translation process is over, ProphetMT can provide an effective colour scheme to further improve the productivity of post-editors by explicitly featuring the relations between the source and target rules."
L16-1436,Automatic Construction of Discourse Corpora for Dialogue Translation,2016,0,4,4,1,7026,longyue wang,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, a novel approach is proposed to automatically construct parallel discourse corpus for dialogue machine translation. Firstly, the parallel subtitle data and its corresponding monolingual movie script data are crawled and collected from Internet. Then tags such as speaker and discourse boundary from the script data are projected to its subtitle data via an information retrieval approach in order to map monolingual discourse to bilingual texts. We not only evaluate the mapping results, but also integrate speaker information into the translation. Experiments show our proposed method can achieve 81.79{\%} and 98.64{\%} accuracy on speaker and dialogue boundary annotation, and speaker-based language model adaptation can obtain around 0.5 BLEU points improvement in translation qualities. Finally, we publicly release around 100K parallel discourse data with manual speaker and dialogue boundary annotation."
K16-1003,Identifying Temporal Orientation of Word Senses,2016,9,0,5,1,15356,mohammed hasanuzzaman,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,None
C16-1131,Fast Gated Neural Domain Adaptation: Language Model as a Case Study,2016,18,3,3,0.603689,22733,jian zhang,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Neural network training has been shown to be advantageous in many natural language processing applications, such as language modelling or machine translation. In this paper, we describe in detail a novel domain adaptation mechanism in neural network training. Instead of learning and adapting the neural network on millions of training sentences {--} which can be very time-consuming or even infeasible in some cases {--} we design a domain adaptation gating mechanism which can be used in recurrent neural networks and quickly learn the out-of-domain knowledge directly from the word vector representations with little speed overhead. In our experiments, we use the recurrent neural network language model (LM) as a case study. We show that the neural LM perplexity can be reduced by 7.395 and 12.011 using the proposed domain adaptation mechanism on the Penn Treebank and News data, respectively. Furthermore, we show that using the domain-adapted neural LM to re-rank the statistical machine translation n-best list on the French-to-English language pair can significantly improve translation quality."
C16-1170,Topic-Informed Neural Machine Translation,2016,28,9,3,0.603689,22733,jian zhang,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"In recent years, neural machine translation (NMT) has demonstrated state-of-the-art machine translation (MT) performance. It is a new approach to MT, which tries to learn a set of parameters to maximize the conditional probability of target sentences given source sentences. In this paper, we present a novel approach to improve the translation performance in NMT by conveying topic knowledge during translation. The proposed topic-informed NMT can increase the likelihood of selecting words from the same topic and domain for translation. Experimentally, we demonstrate that topic-informed NMT can achieve a 1.15 (3.3{\%} relative) and 1.67 (5.4{\%} relative) absolute improvement in BLEU score on the Chinese-to-English language pair using NIST 2004 and 2005 test sets, respectively, compared to NMT without topic information."
C16-1243,Enriching Phrase Tables for Statistical Machine Translation Using Mixed Embeddings,2016,18,3,3,1,7213,peyman passban,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"The phrase table is considered to be the main bilingual resource for the phrase-based statistical machine translation (PBSMT) model. During translation, a source sentence is decomposed into several phrases. The best match of each source phrase is selected among several target-side counterparts within the phrase table, and processed by the decoder to generate a sentence-level translation. The best match is chosen according to several factors, including a set of bilingual features. PBSMT engines by default provide four probability scores in phrase tables which are considered as the main set of bilingual features. Our goal is to enrich that set of features, as a better feature set should yield better translations. We propose new scores generated by a Convolutional Neural Network (CNN) which indicate the semantic relatedness of phrase pairs. We evaluate our model in different experimental settings with different language pairs. We observe significant improvements when the proposed features are incorporated into the PBSMT pipeline."
2016.gwc-1.24,Using {W}ordnet to Improve Reordering in Hierarchical Phrase-Based Statistical Machine Translation,2016,0,0,3,0,36129,arefeh kazemi,Proceedings of the 8th Global WordNet Conference (GWC),0,"We propose the use of WordNet synsets in a syntax-based reordering model for hierarchical statistical machine translation (HPB-SMT) to enable the model to generalize to phrases not seen in the training data but that have equivalent meaning. We detail our methodology to incorporate synsets{'} knowledge in the reordering model and evaluate the resulting WordNet-enhanced SMT systems on the English-to-Farsi language direction. The inclusion of synsets leads to the best BLEU score, outperforming the baseline (standard HPB-SMT) by 0.6 points absolute."
2016.eamt-2.20,{T}ra{MOOC} (Translation for Massive Open Online Courses): providing reliable {MT} for {MOOC}s,2016,0,1,21,0,12066,valia kordoni,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
2016.amta-users.17,Improving {K}antan{MT} Training Efficiency with fast{\\_}align,2016,-1,-1,6,0.977012,4966,dimitar shterionov,Conferences of the Association for Machine Translation in the Americas: MT Users' Track,0,None
W15-4906,Dependency-based Reordering Model for Constituent Pairs in Hierarchical {SMT},2015,30,1,3,0,36129,arefeh kazemi,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"We propose a novel dependency-based reordering model for hierarchical SMT that predicts the translation order of two types of pairs of constituents of the source tree: head-dependent and dependent-dependent. Our model uses the dependency structure of the source sentence to capture the mediumand long-distance reorderings between these pairs of constituents. We describe our reordering model in detail and then apply it to a language pair in which the languages involved follow different word order patterns, English (SVO) and Farsi (free word order being SOV the most frequent pattern). Our model outperforms a baseline (standard hierarchical SMT) by 0.78 BLEU points absolute, statistically significant at p = 0.01."
W15-4911,Benchmarking {SMT} Performance for {F}arsi Using the {TEP}++ Corpus,2015,14,4,2,1,7213,peyman passban,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"Statistical machine translation (SMT) suffers from various problems which are exacerbated where training data is in shortn supply. In this paper we address the datan sparsity problem in the Farsi (Persian) language and introduce a new parallel corpus, TEP. Compared to previous results the new dataset is more efficient forn Farsi SMT engines and yields better output. In our experiments using TEP asn bilingual training data and BLEU as a metric, we achieved improvements of 11.17n (60%) and 7.76 (63.92%) in the Farsixe2x80x93n English and Englishxe2x80x93Farsi directions, respectively. Furthermore we describe ann engine (SF2FF) to translate between formal and informal Farsi which in terms ofn syntax and terminology can be seen asn different languages. The SF2FF enginen also works as an intelligent normalizer forn Farsi texts. To demonstrate its use, SF2FFn was used to clean the IWSLTxe2x80x932013 datasetn to produce normalized data, which gaven improvements in translation quality overn FBKxe2x80x99s Farsi engine when used as trainingn data"
W15-4935,{T}ra{MOOC}: Translation for Massive Open Online Courses,2015,0,0,4,0,12066,valia kordoni,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-4944,{A}bu-{M}a{T}ran: Automatic building of Machine Translation,2015,48,0,3,0.396779,9426,antonio toral,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-3005,"{P}ar{FDA} for Fast Deployment of Accurate Statistical Machine Translation Systems, Benchmarks, and Statistics",2015,9,11,3,1,13953,ergun biccici,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"We build parallel FDA5 (ParFDA) Moses statistical machine translation (SMT) systems for all language pairs in the workshop on statistical machine translation (Bojar et al., 2015) (WMT15) translation task and obtain results close to the top with an average of 3.176 BLEU points difference using significantly less resources for building SMT systems. ParFDA is a parallel implementation of feature decay algorithms (FDA) developed for fast deploy"
W15-3035,Referential Translation Machines for Predicting Translation Quality and Related Statistics,2015,15,8,3,1,13953,ergun biccici,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,We use referential translation machines (RTMs) for predicting translation performance. RTMs pioneer a language independent approach to all similarity tasks and remove the need to access any task or domain specific information or resource. We improve our RTM models with the
W15-0714,Translating Literary Text between Related Languages using {SMT},2015,30,5,2,0.396779,9426,antonio toral,Proceedings of the Fourth Workshop on Computational Linguistics for Literature,0,"We explore the feasibility of applying machinen translation (MT) to the translation of literaryn texts. To that end, we measure the translatability of literary texts by analysing paralleln corpora and measuring the degree of freedomn of the translations and the narrowness of then domain. We then explore the use of domainn adaptation to translate a novel between two related languages, Spanish and Catalan. Thisn is the first time that specific MT systems aren built to translate novels. Our best system outperforms a strong baseline by 4.61 absoluten points (9.38% relative) in terms of BLEU andn is corroborated by other automatic evaluationn metrics. We provide evidence that MT cann be useful to assist with the translation of novels between closely-related languages, namelyn (i) the translations produced by our best system are equal to the ones produced by a professional human translator in almost 20% ofn cases with an additional 10% requiring at mostn 5 character edits, and (ii) a complementary human evaluation shows that over 60% of then translations are perceived to be of the same (orn even higher) quality by native speakers."
D15-1004,Dependency Graph-to-String Translation,2015,33,2,2,1,5774,liangyou li,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Compared to tree grammars, graph grammars have stronger generative capacity over structures. Based on an edge replacement grammar, in this paper we propose to use a synchronous graph-to-string grammar for statistical machine translation. The graph we use is directly converted from a dependency tree by labelling edges. We build our translation model in the log-linear framework with standard features. Large-scale experiments on Chinesexe2x80x90English and Germanxe2x80x90English tasks show that our model is significantly better than the state-of-the-art hierarchical phrase-based (HPB) model and a recently improved dependency tree-to-string model on BLEU, METEOR and TER scores. Experiments also suggest that our model has better capability to perform long-distance reordering and is more suitable for translating long sentences."
2015.mtsummit-wptp.5,Domain adaptation for social localisation-based {SMT}: a case study using the Trommons platform,2015,0,0,2,1,21659,jinhua du,Proceedings of the 4th Workshop on Post-editing Technology and Practice,0,"Social localisation is a kind of community action, which matches communities and the contentn they need, and supports their localisation efforts. The goal of social localisation-based statistical machine translation (SL-SMT) is to support and bridge global communities exchangingn any type of digital content across different languages and cultures. Trommons is an openn platform maintained by The Rosetta Foundation to connect non-profit translation projects andn organisations with the skills and interests of volunteer translators, where they can translate,n post-edit or proofread different types of documents. Using Trommons as the experimentaln platform, this paper focuses on domain adaptation techniques to augment SL-SMT to facilitaten translators/post-editors. Specifically, the Cross Entropy Difference algorithm is used to adaptn Europarl data to the social localisation data. Experimental results on Englishxe2x80x93Spanish shown that the domain adaptation techniques can significantly improve translation performance byn 6.82 absolute BLEU points and 5.99 absolute TER points compared to the baseline."
2015.mtsummit-papers.14,An empirical study of segment prioritization for incrementally retrained post-editing-based {SMT},2015,0,0,3,1,21659,jinhua du,Proceedings of Machine Translation Summit XV: Papers,0,"Post-editing the output of a statistical machine translation (SMT) system to obtain high-qualityn translation has become an increasingly common application of SMT, which henceforth we refer to as post-editing-based SMT (PE-SMT). PE-SMT is often deployed as an incrementallyn retrained system that can learn knowledge from human post-editing outputs as early as possiblen to augment the SMT models to reduce PE time. In this scenario, the order of input segmentsn plays a very important role in reducing the overall PE time. Under the active learning-basedn (AL) framework, this paper provides an empirical study of several typical segment prioritization methods, namely the cross entropy difference (CED), n-grams, perplexity (PPL) andn translation confidence, and verifies their performance on different data sets and language pairs.n Experiments in a simulated setting show that the confidence of translations performs best withn decreases of 1.72-4.55 points TER absolute on average compared to the sequential PE-basedn incrementally retrained SMT."
2015.eamt-1.7,Dependency-based Reordering Model for Constituent Pairs in Hierarchical {SMT},2015,30,1,3,0,38031,arefeh kazemiy,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"We propose a novel dependency-based reordering model for hierarchical SMT that predicts the translation order of two types of pairs of constituents of the source tree: head-dependent and dependent-dependent. Our model uses the dependency structure of the source sentence to capture the mediumand long-distance reorderings between these pairs of constituents. We describe our reordering model in detail and then apply it to a language pair in which the languages involved follow different word order patterns, English (SVO) and Farsi (free word order being SOV the most frequent pattern). Our model outperforms a baseline (standard hierarchical SMT) by 0.78 BLEU points absolute, statistically significant at p = 0.01."
2015.eamt-1.12,Benchmarking {SMT} Performance for {F}arsi Using the {TEP}++ Corpus,2015,14,4,2,1,7213,peyman passban,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"Statistical machine translation (SMT) suffers from various problems which are exacerbated where training data is in shortn supply. In this paper we address the datan sparsity problem in the Farsi (Persian) language and introduce a new parallel corpus, TEP. Compared to previous results the new dataset is more efficient forn Farsi SMT engines and yields better output. In our experiments using TEP asn bilingual training data and BLEU as a metric, we achieved improvements of 11.17n (60%) and 7.76 (63.92%) in the Farsixe2x80x93n English and Englishxe2x80x93Farsi directions, respectively. Furthermore we describe ann engine (SF2FF) to translate between formal and informal Farsi which in terms ofn syntax and terminology can be seen asn different languages. The SF2FF enginen also works as an intelligent normalizer forn Farsi texts. To demonstrate its use, SF2FFn was used to clean the IWSLTxe2x80x932013 datasetn to produce normalized data, which gaven improvements in translation quality overn FBKxe2x80x99s Farsi engine when used as trainingn data"
2015.eamt-1.36,{T}ra{MOOC}: Translation for Massive Open Online Courses,2015,0,0,4,0,12066,valia kordoni,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
2015.eamt-1.45,{A}bu-{M}a{T}ran: Automatic building of Machine Translation,2015,48,0,3,0.396779,9426,antonio toral,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
W14-4806,Bilingual Termbank Creation via Log-Likelihood Comparison and Phrase-Based Statistical Machine Translation,2014,24,4,3,1,5016,rejwanul haque,Proceedings of the 4th International Workshop on Computational Terminology (Computerm),0,"Bilingual termbanks are important for many natural language processing (NLP) applications, especially in translation workflows in industrial settings. In this paper, we apply a log-likelihood comparison method to extract monolingual terminology from the source and target sides of a parallel corpus. Then, using a Phrase-Based Statistical Machine Translation model, we create a bilingual terminology with the extracted monolingual term lists. We manually evaluate our novel terminology extraction model on English-to-Spanish and English-to-Hindi data sets, and observe excellent performance for all domains. Furthermore, we report the performance of our monolingual terminology extraction model comparing with a number of the state-of-the-art terminology extraction models on the English-to-Hindi datasets."
W14-4014,Transformation and Decomposition for Efficiently Implementing and Improving Dependency-to-String Model In {M}oses,2014,29,5,3,1,5774,liangyou li,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Dependency structure provides grammatical relations between words, which have shown to be effective in Statistical Machine Translation (SMT). In this paper, we present an open source module in Moses which implements a dependency-to-string model. We propose a method to transform the input dependency tree into a corresponding constituent tree for reusing the tree-based decoder in Moses. In our experiments, this method achieves comparable results with the standard model. Furthermore, we enrich this model via the decomposition of dependency structure, including extracting rules from the substructures of the dependency tree during training and creating a pseudo-forest instead of the tree per se as the input during decoding. Large-scale experiments on Chinesexe2x80x90English and Germanxe2x80x90English tasks show that the decomposition approach improves the baseline dependencyto-string model significantly. Our system achieves comparable results with the state-of-the-art hierarchical phrase-based model (HPB). Finally, when resorting to phrasal rules, the dependency-to-string model performs significantly better than Moses HPB."
W14-3303,Parallel {FDA}5 for Fast Deployment of Accurate Statistical Machine Translation Systems,2014,12,13,3,1,13953,ergun biccici,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We use parallel FDA5, an efficiently parameterized and optimized parallel implementation of feature decay algorithms for fast deployment of accurate statistical machine translation systems, taking only about half a day for each translation direction. We build Parallel FDA5 Moses SMT systems for all language pairs in the WMT14 translation task and obtain SMT performance close to the top Moses systems with an average of 3.49 BLEU points difference using significantly less resources for training and development."
W14-3314,The {DCU}-{ICTCAS} {MT} system at {WMT} 2014 on {G}erman-{E}nglish Translation Task,2014,19,8,5,1,5774,liangyou li,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the DCU submission to WMT 2014 on German-English translation task. Our system uses phrasebased translation model with several popular techniques, including Lexicalized Reordering Model, Operation Sequence Model and Language Model interpolation. Our final submission is the result of system combination on several systems which have different pre-processing and alignments."
W14-3319,{A}bu-{M}a{T}ran at {WMT} 2014 Translation Task: Two-step Data Selection and {RBMT}-Style Synthetic Rules,2014,20,4,8,0,8609,raphael rubino,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the machine translation systems submitted by the AbuMaTran project to the WMT 2014 translation task. The language pair concerned is Englishxe2x80x90French with a focus on French as the target language. The French to English translation direction is also considered, based on the word alignment computed in the other direction. Large language and translation models are built using all the datasets provided by the shared task organisers, as well as the monolingual data from LDC. To build the translation models, we apply a two-step data selection method based on bilingual crossentropy difference and vocabulary saturation, considering each parallel corpus individually. Synthetic translation rules are extracted from the development sets and used to train another translation model. We then interpolate the translation models, minimising the perplexity on the development sets, to obtain our final SMT system. Our submission for the English to French translation task was ranked second amongst nine teams and a total of twenty submissions."
W14-3325,{DCU}-Lingo24 Participation in {WMT} 2014 {H}indi-{E}nglish Translation task,2014,19,2,5,1,35090,xiaofeng wu,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the DCU-Lingo24 submission to WMT 2014 for the HindiEnglish translation task. We exploit miscellaneous methods in our system, including: Context-Informed PB-SMT, OOV Word Conversion (OWC), MultiAlignment Combination (MAC), Operation Sequence Model (OSM), Stemming Align and Normal Phrase Extraction (SANPE), and Language Model Interpolation (LMI). We also describe various preprocessing steps we tried for Hindi in this task."
W14-3329,{DCU} Terminology Translation System for Medical Query Subtask at {WMT}14,2014,20,4,3,0.480226,37719,tsuyoshi okita,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,None
W14-3339,Referential Translation Machines for Predicting Translation Quality,2014,35,16,2,1,13953,ergun biccici,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We use referential translation machines (RTM) for quality estimation of translation outputs. RTMs are a computational model for identifying the translation acts between any two data sets with respect to interpretants selected in the same domain, which are effective when making monolingual and bilingual similarity judgments. RTMs achieve top performance in automatic, accurate, and language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality. RTMs remove the need to access any SMT system specific information or prior knowledge of the training data or models used when generating the translations and achieve the top performance in WMT13 quality estimation task (QET13). We improve our RTM models with the Parallel FDA5 instance selection model, with additional features for predicting the translation performance, and with improved learning models. We develop RTM models for each WMT14 QET (QET14) subtask, obtain improvements over QET13 results, and rank 1st in all of the tasks and subtasks of QET14."
S14-2085,{RTM}-{DCU}: Referential Translation Machines for Semantic Similarity,2014,32,12,2,1,13953,ergun biccici,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"We use referential translation machines (RTMs) for predicting the semantic similarity of text. RTMs are a computational model for identifying the translation acts between any two data sets with respect to interpretants selected in the same domain, which are effective when making monolingual and bilingual similarity judgments. RTMs judge the quality or the semantic similarity of text by using retrieved relevant training data as interpretants for reaching shared semantics. We derive features measuring the closeness of the test sentences to the training data via interpretants, the difficulty of translating them, and the presence of the acts of translation, which may ubiquitously be observed in communication. RTMs provide a language independent approach to all similarity tasks and achieve top performance when predicting monolingual cross-level semantic similarity (Task 3) and good results in semantic relatedness and entailment (Task 1) and multilingual semantic textual similarity (STS) (Task 10). RTMs remove the need to access any task or domain specific information or resource."
2014.tc-1.23,Is machine translation ready for literature,2014,-1,-1,2,0.430223,9426,antonio toral,Proceedings of Translating and the Computer 36,0,None
2014.eamt-1.34,Standard language variety conversion for content localisation via {SMT},2014,-1,-1,2,0,9655,federico fancellu,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.eamt-1.45,Extrinsic evaluation of web-crawlers in machine translation: a study on {C}roatian-{E}nglish for the tourism domain,2014,-1,-1,5,0.430223,9426,antonio toral,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.amta-wptp.5,Perception vs. reality: measuring machine translation post-editing productivity,2014,-1,-1,5,0.752788,4999,federico gaspari,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas,0,"This paper presents a study of user-perceived vs real machine translation (MT) post-editing effort and productivity gains, focusing on two bidirectional language pairs: English{---}German and English{---}Dutch. Twenty experienced media professionals post-edited statistical MT output and also manually translated comparative texts within a production environment. The paper compares the actual post-editing time against the users{'} perception of the effort and time required to post-edit the MT output to achieve publishable quality, thus measuring real (vs perceived) productivity gains. Although for all the language pairs users perceived MT post-editing to be slower, in fact it proved to be a faster option than manual translation for two translation directions out of four, i.e. for Dutch to English, and (marginally) for English to German. For further objective scrutiny, the paper also checks the correlation of three state-of-the-art automatic MT evaluation metrics (BLEU, METEOR and TER) with the actual post-editing time."
2014.amta-researchers.8,A probabilistic feature-based fill-up for {SMT},2014,-1,-1,3,0.603689,22733,jian zhang,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"In this paper, we describe an effective translation model combination approach based on the estimation of a probabilistic Support Vector Machine (SVM). We collect domain knowledge from both in-domain and general-domain corpora inspired by a commonly used data selection algorithm, which we then use as features for the SVM training. Drawing on previous work on binary-featured phrase table fill-up (Nakov, 2008; Bisazza et al., 2011), we substitute the binary feature in the original work with our probabilistic domain-likeness feature. Later, we design two experiments to evaluate the proposed probabilistic feature-based approach on the French-to-English language pair using data provided at WMT07, WMT13 and IWLST11 translation tasks. Our experiments demonstrate that translation performance can gain significant improvements of up to +0.36 and +0.82 BLEU scores by using our probabilistic feature-based translation model fill-up approach compared with the binary featured fill-up approach in both experiments."
2014.amta-researchers.19,A discriminative framework of integrating translation memory features into {SMT},2014,-1,-1,2,1,5774,liangyou li,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"Combining Translation Memory (TM) with Statistical Machine Translation (SMT) together has been demonstrated to be beneficial. In this paper, we present a discriminative framework which can integrate TM into SMT by incorporating TM-related feature functions. Experiments on English{--}Chinese and English{--}French tasks show that our system using TM feature functions only from the best fuzzy match performs significantly better than the baseline phrase- based system on both tasks, and our discriminative model achieves comparable results to those of an effective generative model which uses similar features. Furthermore, with the capacity of handling a large amount of features in the discriminative framework, we propose a method to efficiently use multiple fuzzy matches which brings more feature functions and further significantly improves our system."
2013.tc-1.12,Emerging use-cases for machine translation,2013,-1,-1,1,1,2631,andy way,Proceedings of Translating and the Computer 35,0,None
2013.mtsummit-user.3,{COACH}: Designing a new {CAT} tool with Translator Interaction,2013,-1,-1,3,0,41881,laura bota,Proceedings of Machine Translation Summit XIV: User track,0,None
W12-0106,"Combining {EBMT}, {SMT}, {TM} and {IR} Technologies for Quality and Scale",2012,-1,-1,3,1,6023,sandipan dandapat,Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation ({ESIRMT}) and Hybrid Approaches to Machine Translation ({H}y{T}ra),0,None
petukhova-etal-2012-sumat,{SUMAT}: Data Collection and Parallel Corpus Compilation for Machine Translation of Subtitles,2012,12,6,7,0,16746,volha petukhova,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Subtitling and audiovisual translation have been recognized as areas that could greatly benefit from the introduction of Statistical Machine Translation (SMT) followed by post-editing, in order to increase efficiency of subtitle production process. The FP7 European project SUMAT (An Online Service for SUbtitling by MAchine Translation: http://www.sumat-project.eu) aims to develop an online subtitle translation service for nine European languages, combined into 14 different language pairs, in order to semi-automate the subtitle translation processes of both freelance translators and subtitling companies on a large scale. In this paper we discuss the data collection and parallel corpus compilation for training SMT systems, which includes several procedures such as data partition, conversion, formatting, normalization and alignment. We discuss in detail each data pre-processing step using various approaches. Apart from the quantity (around 1 million subtitles per language pair), the SUMAT corpus has a number of very important characteristics. First of all, high quality both in terms of translation and in terms of high-precision alignment of parallel documents and their contents has been achieved. Secondly, the contents are provided in one consistent format and encoding. Finally, additional information such as type of content in terms of genres and domain is available."
C12-1010,Translation Quality-Based Supplementary Data Selection by Incremental Update of Translation Models,2012,27,8,4,1,41915,pratyush banerjee,Proceedings of {COLING} 2012,0,"Supplementary data selection from out-of-domain or related-domain data is a well established technique in domain adaptation of statistical machine translation. The selection criteria for such data are mostly based on measures of similarity with available in-domain data, but not directly in terms of translation quality. In this paper, we present a technique for selecting supplementary data to improve translation performance, directly in terms of translation quality, measured by automatic evaluation metric scores. Batches of data selected from out-of-domain corpora are incrementally added to an existing baseline system and evaluated in terms of translation quality on a development set. A batch is selected only if its inclusion improves translation quality. To assist the process, we present a novel translation model merging technique that allows rapid retraining of the translation models with incremental data. When incorporated into the xe2x80x98in-domainxe2x80x99 translation models, the final cumulatively selected datasets are found to provide statistically significant improvements for a number of different supplementary datasets. Furthermore, the translation model merging technique is found to perform on a par with state-of-the-art methods of phrase-table combination."
2012.eamt-1.2,From Subtitles to Parallel Corpora,2012,5,3,7,0,13955,mark fishel,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,We describe the preparation of parallel corpora based on professional quality subtitles in seven European language pairs. The main focus is the effect of the processing steps on the size and quality of the final corpora.
2012.eamt-1.41,Domain Adaptation in {SMT} of User-Generated Forum Content Guided by {OOV} Word Reduction: Normalization and/or Supplementary Data,2012,14,19,4,1,41915,pratyush banerjee,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"This paper reports a set of domain adaptation techniques for improving Statistical Machine Translation (SMT) for usergenerated web forum content. We investigate both normalization and supplementary training data acquisition techniques, all guided by the aim of reducing the number of Out-Of-Vocabulary (OOV) items in the target language with respect to the training data. We classify OOVs into a set of types, and address each through dedicated normalization and/or supplementary training material selection-based approaches. We investigate the effect of these methods both in an additive as well as a contrastive scenario. Our findings show that (i) normalization and supplementary training material techniques can be complementary, (ii) for general forum data, fully automatic supplementary training data acquisition can perform as well or sometimes better than semi-automatic normalization (although tackling different types of OOVs) and (iii) for very noisy data, normalization really pays off."
2012.eamt-1.44,Extending {CCG}-based Syntactic Constraints in Hierarchical Phrase-Based {SMT},2012,14,6,3,1,43864,hala almaghout,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"In this paper, we describe two approaches to extending syntactic constraints in the Hierarchical Phrase-Based (HPB) Statistical Machine Translation (SMT) model using Combinatory Categorial Grammar (CCG). These extensions target the limitations of previous syntax-augmented HPB SMT systems which limit the coverage of the syntactic constraints applied. We present experiments on Arabicxe2x80x90English and Chinesexe2x80x90English translation. Our experiments show that using extended CCG labels helps to increase nonterminal label coverage and achieve significant improvements over the baseline for Arabicxe2x80x90 English translation. In addition, combining extended CCG labels with CCGaugmented glue grammar helps to improve the performance of the Chinesexe2x80x90English translation over the baseline systems."
2012.amta-wptp.6,{S}mart{MATE}: An Online End-To-End {MT} Post-Editing Framework,2012,-1,-1,2,1,38356,sergio penkale,Workshop on Post-Editing Technology and Practice,0,"It is a well-known fact that the amount of content which is available to be translated and localized far outnumbers the current amount of translation resources. Automation in general and Machine Translation (MT) in particular are one of the key technologies which can help improve this situation. However, a tool that integrates all of the components needed for the localization process is still missing, and MT is still out of reach for most localisation professionals. In this paper we present an online translation environment which empowers users with MT by enabling engines to be created from their data, without a need for technical knowledge or special hardware requirements and at low cost. Documents in a variety of formats can then be post-edited after being processed with their Translation Memories, MT engines and glossaries. We give an overview of the tool and present a case study of a project for a large games company, showing the applicability of our tool."
2012.amta-papers.1,Hierarchical Phrase-Based {MT} for Phonetic Representation-Based Speech Translation,2012,-1,-1,5,1,42269,zeeshan ahmed,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"The paper presents a novel technique for speech translation using hierarchical phrased-based statistical machine translation (HPB-SMT). The system is based on translation of speech from phone sequences as opposed to conventional approach of speech translation from word sequences. The technique facilitates speech translation by allowing a machine translation (MT) system to access to phonetic information. This enables the MT system to act as both a word recognition and a translation component. This results in better performance than conventional speech translation approaches by recovering from recognition error with help of a source language model, translation model and target language model. For this purpose, the MT translation models are adopted to work on source language phones using a grapheme-to-phoneme component. The source-side phonetic confusions are handled using a confusion network. The result on IWLST'10 English- Chinese translation task shows a significant improvement in translation quality. In this paper, results for HPB-SMT are compared with previously published results of phrase-based statistical machine translation (PB-SMT) system (Baseline). The HPB-SMT system outperforms PB-SMT in this regard."
2012.amta-monomt.2,Monolingual Data Optimisation for Bootstrapping {SMT} Engines,2012,-1,-1,2,1,7874,jie jiang,Workshop on Monolingual Machine Translation,0,"Content localisation via machine translation (MT) is a sine qua non, especially for international online business. While most applications utilise rule-based solutions due to the lack of suitable in-domain parallel corpora for statistical MT (SMT) training, in this paper we investigate the possibility of applying SMT where huge amounts of monolingual content only are available. We describe a case study where an analysis of a very large amount of monolingual online trading data from eBay is conducted by ALS with a view to reducing this corpus to the most representative sample in order to ensure the widest possible coverage of the total data set. Furthermore, minimal yet optimal sets of sentences/words/terms are selected for generation of initial translation units for future SMT system-building."
2012.amta-commercial.3,Taking Statistical Machine Translation to the Student Translator,2012,30,13,3,0,40954,stephen doherty,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Commercial MT User Program,0,"Despite the growth of statistical machine translation (SMT) research and development in recent years, it remains somewhat out of reach for the translation community where programming expertise and knowledge of statistics tend not to be commonplace. While the concept of SMT is relatively straightforward, its implementation in functioning systems remains difficult for most, regardless of expertise. More recently, however, developments such as SmartMATE have emerged which aim to assist users in creating their own customized SMT systems and thus reduce the learning curve associated with SMT. In addition to commercial uses, translator training stands to benefit from such increased levels of inclusion and access to state-of-the-art approaches to MT. In this paper we draw on experience in developing and evaluating a new syllabus in SMT for a cohort of post-graduate student translators: we identify several issues encountered in the introduction of student translators to SMT, and report on data derived from repeated measures questionnaires that aim to capture data on students{'} self-efficacy in the use of SMT. Overall, results show that participants report significant increases in their levels of confidence and knowledge of MT in general, and of SMT in particular. Additional benefits {--} such as increased technical competence and confidence {--} and future refinements are also discussed."
2012.amta-commercial.8,Translating User-Generated Content in the Social Networking Space,2012,-1,-1,2,1,7874,jie jiang,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Commercial MT User Program,0,"This paper presents a case-study of work done by Applied Language Solutions (ALS) for a large social networking provider who claim to have built the world{'}s first multi-language social network, where Internet users from all over the world can communicate in languages that are available in the system. In an initial phase, the social networking provider contracted ALS to build Machine Translation (MT) engines for twelve language-pairs: RussianâEnglish, RussianâTurkish, RussianâArabic, TurkishâEnglish, TurkishâArabic and ArabicâEnglish. All of the input data is user-generated content, so we faced a number of problems in building large-scale, robust, high-quality engines. Primarily, much of the source-language data is of {`}poor{'} or at least {`}non-standard{'} quality. This comes in many forms: (i) content produced by non-native speakers, (ii) content produced by native speakers containing non-deliberate typos, or (iii) content produced by native speakers which deliberately departs from spelling norms to bring about some linguistic effect. Accordingly, in addition to the {`}regular{'} pre-processing techniques used in the building of our statistical MT systems, we needed to develop routines to deal with all these scenarios. In this paper, we describe how we handle shortforms, acronyms, typos, punctuation errors, non-dictionary slang, wordplay, censor avoidance and emoticons. We demonstrate automatic evaluation scores on the social network data, together with insights from the the social networking provider regarding some of the typical errors made by the MT engines, and how we managed to correct these in the engines."
W11-1004,Incorporating Source-Language Paraphrases into Phrase-Based {SMT} with Confusion Networks,2011,24,4,3,1,7874,jie jiang,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"To increase the model coverage, source-language paraphrases have been utilized to boost SMT system performance. Previous work showed that word lattices constructed from paraphrases are able to reduce out-of-vocabulary words and to express inputs in different ways for better translation quality. However, such a word-lattice-based method suffers from two problems: 1) path duplications in word lattices decrease the capacities for potential paraphrases; 2) lattice decoding in SMT dramatically increases the search space and results in poor time efficiency. Therefore, in this paper, we adopt word confusion networks as the input structure to carry source-language paraphrase information. Similar to previous work, we use word lattices to build word confusion networks for merging of duplicated paths and faster decoding. Experiments are carried out on small-, medium- and large-scale English-Chinese translation tasks, and we show that compared with the word-lattice-based method, the decoding time on three tasks is reduced significantly (up to 79%) while comparable translation quality is obtained on the large-scale task."
P11-1124,Consistent Translation using Discriminative Learning - A Translation Memory-inspired Approach,2011,23,30,3,1,11802,yanjun ma,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present a discriminative learning method to improve the consistency of translations in phrase-based Statistical Machine Translation (SMT) systems. Our method is inspired by Translation Memory (TM) systems which are widely used by human translators in industrial settings. We constrain the translation of an input sentence using the most similar 'translation example' retrieved from the TM. Differently from previous research which used simple fuzzy match thresholds, these constraints are imposed using discriminative learning to optimise the translation performance. We observe that using this method can benefit the SMT system by not only producing consistent translations, but also improved translation outputs. We report a 0.9 point improvement in terms of BLEU score on English--Chinese technical documents."
2011.mtsummit-papers.7,Phonetic Representation-Based Speech Translation,2011,-1,-1,5,1,7874,jie jiang,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.mtsummit-papers.32,Domain Adaptation in Statistical Machine Translation of User-Forum Data using Component Level Mixture Modelling,2011,-1,-1,4,1,41915,pratyush banerjee,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.mtsummit-papers.52,Rich Linguistic Features for Translation Memory-Inspired Consistent Translation,2011,-1,-1,3,1,12154,yifan he,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.mtsummit-papers.60,A Framework for Diagnostic Evaluation of {MT} Based on Linguistic Checkpoints,2011,-1,-1,4,1,1243,sudip naskar,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.iwslt-evaluation.4,The {DCU} machine translation systems for {IWSLT} 2011,2011,0,3,6,1,41915,pratyush banerjee,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we provide a description of the Dublin City University{'}s (DCU) submissions in the IWSLT 2011 evaluationcampaign.1 WeparticipatedintheArabic-Englishand Chinese-English Machine Translation(MT) track translation tasks. We use phrase-based statistical machine translation (PBSMT) models to create the baseline system. Due to the open-domain nature of the data to be translated, we use domain adaptation techniques to improve the quality of translation. Furthermore, we explore target-side syntactic augmentation for an Hierarchical Phrase-Based (HPB) SMT model. Combinatory Categorial Grammar (CCG) is used to extract labels for target-side phrases and non-terminals in the HPB system. Combining the domain adapted language models with the CCG-augmented HPB system gave us the best translations for both language pairs providing statistically significant improvements of 6.09 absolute BLEU points (25.94{\%} relative) and 1.69 absolute BLEU points (15.89{\%} relative) over the unadapted PBSMT baselines for the Arabic-English and Chinese-English language pairs, respectively."
2011.freeopmt-1.7,Automatic acquisition of named entities for rule-based machine translation,2011,18,4,2,0.430223,9426,antonio toral,Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation,0,"This paper proposes to enrich RBMT dictionaries with Named Entities (NEs) automatically acquired from Wikipedia. The method is applied to the Apertium English{--}Spanish system and its performance compared to that of Apertium with and without handtagged NEs. The system with automatic NEs outperforms the one without NEs, while results vary when compared to a system with handtagged NEs (results are comparable for SpanishâEnglish but slightly worst for EnglishâSpanish). Apart from that, adding automatic NEs contributes to decreasing the amount of unknown terms by more than 10{\%}."
2011.eamt-1.4,A Comparative Evaluation of Research vs. Online {MT} Systems,2011,19,3,4,0.430223,9426,antonio toral,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper reports MT evaluation experiments that were conducted at the end of year 1 of the EU-funded CoSynen 1 project for three language combinations, considering translations from German, Italian and Dutch into English. We present a comparative evaluation of the MT software developed within the project against four of the leading free webbased MT systems across a range of state-of-the-art automatic evaluation metrics. The data sets from the news domain that were created and used for training purposes and also for this evaluation exercise, which are available to the research community, are also described. The evaluation results for the news domain are very encouraging: the CoSyne MT software consistently beats the rule-based MT systems, and for translations from Italian and Dutch into English in particular the scores given by some of the standard automatic evaluation metrics are not too distant from those obtained by wellestablished statistical online MT systems."
2011.eamt-1.5,Experiments on Domain Adaptation for Patent Machine Translation in the {PL}u{TO} project,2011,18,21,4,0,44360,alexandru ceaucsu,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,The PLUTO 1 project (Patent Language Translations Online) aims to provide a rapid solution for the online retrieval and translation of patent documents through the integration of a number of existing state-of-the-art components provided by the project partners. The paper presents some of the experiments on patent domain adaptation of the Machine Translation (MT) systems used in the PLuTO project. The experiments use the International Patent Classification for domain adaptation and are focused on the Englishxe2x80x93French language pair.
2011.eamt-1.11,Towards a User-Friendly Webservice Architecture for Statistical Machine Translation in the {PANACEA} project,2011,-1,-1,4,0.430223,9426,antonio toral,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,None
2011.eamt-1.23,Preliminary Experiments on Using Users{'} Post-Editions to Enhance a {SMT} System Oracle-based Training for Phrase-based Statistical Machine Translation,2011,-1,-1,3,1,31656,ankit srivastava,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,None
2011.eamt-1.28,Using Example-Based {MT} to Support Statistical {MT} when Translating Homogeneous Data in a Resource-Poor Setting,2011,16,10,3,1,6023,sandipan dandapat,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"In this paper, we address the issue of applying example-based machine translation (EBMT) methods to overcome some of the difficulties encountered with statistical machine translation (SMT) techniques. We adopt two different EBMT approaches and present an approach to augment output quality by strategically combining both EBMT approaches with the SMT system to handle issues arising from the use of SMT. We use these approaches for English to Turkish translation using the IWSLT09 dataset. Improved evaluation scores (4% relative BLEU improvement) were achieved when EBMT was used to translate sentences for which SMT failed to produce an adequate translation."
2011.eamt-1.29,Combining Semantic and Syntactic Generalization in Example-Based Machine Translation,2011,21,3,2,0,3154,sarah ebling,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"In this paper, we report our experiments in combining two EBMT systems that rely on generalized templates, Marclator and CMU-EBMT, on an Englishxe2x80x90German translation task. Our goal was to see whether a statistically significant improvement could be achieved over the individual performances of these two systems. We observed that this was not the case. However, our system consistently outperformed a lexical EBMT baseline system."
2011.eamt-1.38,{CCG} Contextual labels in Hierarchical Phrase-Based {SMT},2011,19,11,3,1,43864,hala almaghout,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"In this paper, we present a method to employ target-side syntactic contextual information in a Hierarchical Phrase-Based system. Our method uses Combinatory Categorial Grammar (CCG) to annotate training data with labels that represent the left and right syntactic context of target-side phrases. These labels are then used to assign labels to nonterminals in hierarchical rules. CCG-based contextual labels help to produce more grammatical translations by forcing phrases which replace nonterminals during translations to comply with the contextual constraints imposed by the labels. We present experiments which examine the performance of CCG contextual labels on Chinesexe2x80x90English and Arabicxe2x80x90 English translation in the news and speech expressions domains using different data sizes and CCG-labeling settings. Our experiments show that our CCG contextual labels-based system achieved a 2.42% relative BLEU improvement over a PhraseBased baseline on Arabicxe2x80x90English translation and a 1% relative BLEU improvement over a Hierarchical Phrase-Based system baseline on Chinesexe2x80x90English translation."
2011.eamt-1.40,Towards Using Web-Crawled Data for Domain Adaptation in Statistical Machine Translation,2011,22,25,3,0.833333,23042,pavel pecina,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper reports on the ongoing work focused on domain adaptation of statistical machine translation using domain-specific data obtained by domain-focused web crawling. We present a strategy for crawling monolingual and parallel data and their exploitation for testing, language modelling, and system tuning in a phrase-based machine translation framework. The proposed approach is evaluated on the domains of Natural Environment and Labour Legislation and two language pairs: Englishxe2x80x90French and Englishxe2x80x90Greek."
W10-4006,Multi-Word Expression-Sensitive Word Alignment,2010,20,26,4,1,37719,tsuyoshi okita,Proceedings of the 4th Workshop on Cross Lingual Information Access,0,"This paper presents a new word alignment method which incorporates knowledge about Bilingual Multi-Word Expressions (BMWEs). Our method of word alignment first extracts such BMWEs in a bidirectional way for a given corpus and then starts conventional word alignment,n considering the properties of BMWEs in their grouping as well as their alignment links. We give partial annotation of alignment links as prior knowledge to the wordn alignment process; by replacing the maximum likelihood estimate in the M-step of the IBM Models with the Maximum An Posteriori (MAP) estimate, prior knowledge about BMWEs is embedded in the prior in this MAP estimate. In our experiments, we saw an improvement of 0.77 Bleu points absolute in JPxe2x80x93EN. Except for one case, our method gave better results than the method using only BMWEs grouping. Even though this paper does not directly address the issues in Cross-Lingual Information Retrieval (CLIR), itn discusses an approach of direct relevance to the field. This approach could be viewed as the opposite of current trends in CLIR on semantic space that incorporate a notion of order in the bag-of-words model (e.g. co-occurences)."
W10-3803,Source-side Syntactic Reordering Patterns with Functional Words for Improved Phrase-based {SMT},2010,20,3,3,1,7874,jie jiang,Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation,0,"Inspired by previous source-side syntactic reordering methods for SMT, this paper focuses on using automatically learned syntactic reordering patterns with functional words which indicate structural reorderings between the source and target language. This approach takes advantage of phrase alignments and source-side parse trees for pattern extraction, and then filters out those patterns without functional words. Word lattices transformed by the generated patterns are fed into PBSMT systems to incorporate potential reorderings from the inputs. Experiments are carried out on a medium-sized corpus for a Chinesexe2x80x93English SMT task. The proposed method outperforms the baseline system by 1.38% relative on a randomly selected testset and 10.45% relative on the NIST 2008 testset in terms of BLEU score. Furthermore, a system with just 61.88% of the patterns filtered by functional words obtains a comparable performance with the unfiltered one on the randomly selected testset, and achieves 1.74% relative improvements on the NIST 2008 testset."
W10-3813,{HMM} Word-to-Phrase Alignment with Dependency Constraints,2010,25,1,2,1,11802,yanjun ma,Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation,0,"In this paper, we extend the HMMwordto-phrase alignment model with syntactic dependency constraints. The syntacticn dependencies between multiple words in one language are introduced into the model in a bid to produce coherentn alignments. Our experimental results on a variety of Chinesexe2x80x93English data show that our syntactically constrainedn model can lead to as much as a 3.24% relative improvement in BLEU score over current HMM word-to-phrase alignment models on a Phrase-Based Statistical Machine Translation system when the training data is small, and a comparable performance compared to IBM model 4 on a Hiero-style systemn with larger training data. An intrinsic alignment quality evaluation shows that our alignment model with dependencyn constraints leads to improvements in both precision (by 1.74% relative) and recall (by 1.75% relative) over the model without dependency information."
W10-3707,Handling Named Entities and Compound Verbs in Phrase-Based Statistical Machine Translation,2010,25,23,5,0,13776,santanu pal,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,"Data preprocessing plays a crucial role in phrase-based statistical machine translation (PB-SMT). In this paper, we show how single-tokenization of two types of multi-word expressions (MWE), namely named entities (NE) and compound verbs, as well as their prior alignment can boost the performance of PB-SMT. Single-tokenization of compound verbs and named entities (NE) provides significant gains over the baseline PB-SMT system. Automatic alignment of NEs substantially improves the overall MT performance, and thereby the word alignment quality indirectly. For establishing NE alignments, we transliterate source NEs into the target language and then compare them with the target NEs. Target language NEs are first converted into a canonical form before the comparison takes place. Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an Englishxe2x80x94Bangla translation task."
W10-1720,{MATREX}: The {DCU} {MT} System for {WMT} 2010,2010,29,40,10,1,38356,sergio penkale,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the DCU machine translation system in the evaluation campaign of the Joint Fifth Workshop on Statistical Machine Translation and Metrics in ACL-2010. We describe the modular design of our multi-engine machine translation (MT) system with particular focus on the components used in this participation. We participated in the English--Spanish and English--Czech translation tasks, in which we employed our multi-engine architecture to translate. We also participated in the system combination task which was carried out by the MBR decoder and confusion network decoder."
W10-1742,An Augmented Three-Pass System Combination Framework: {DCU} Combination System for {WMT} 2010,2010,15,5,3,1,21659,jinhua du,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the augmented three-pass system combination framework of the Dublin City University (DCU) MT group for the WMT 2010 system combination task. The basic three-pass framework includes building individual confusion networks (CNs), a super network, and a modified Minimum Bayes-risk (mConMBR) decoder. The augmented parts for WMT2010 tasks include 1) a rescoring component which is used to re-rank the N-best lists generated from the individual CNs and the super network, 2) a new hypothesis alignment metric -- TERp -- that is used to carry out English-targeted hypothesis alignment, and 3) more different backbone-based CNs which are employed to increase the diversity of the mConMBR decoding phase. We took part in the combination tasks of English-to-Czech and French-to-English. Experimental results show that our proposed combination framework achieved 2.17 absolute points (13.36 relative points) and 1.52 absolute points (5.37 relative points) in terms of BLEU score on English-to-Czech and French-to-English tasks respectively than the best single system. We also achieved better performance on human evaluation."
W10-1753,The {DCU} Dependency-Based Metric in {WMT}-{M}etrics{MATR} 2010,2010,15,21,3,1,12154,yifan he,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"We describe DCU's LFG dependency-based metric submitted to the shared evaluation task of WMT-MetricsMATR 2010.n n The metric is built on the LFG F-structure-based approach presented in (Owczarzak et al., 2007). We explore the following improvements on the original metric: 1) we replace the in-house LFG parser with an open source dependency parser that directly parses strings into LFG dependencies; 2) we add a stemming module and unigram paraphrases to strengthen the aligner; 3) we introduce a chunk penalty following the practice of METEOR to reward continuous matches; and 4) we introduce and tune parameters to maximize the correlation with human judgement. Experiments show that these enhancements improve the dependency-based metric's correlation with human judgement."
P10-1064,Bridging {SMT} and {TM} with Translation Recommendation,2010,20,59,4,1,12154,yifan he,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We propose a translation recommendation framework to integrate Statistical Machine Translation (SMT) output with Translation Memory (TM) systems. The framework recommends SMT outputs to a TM user when it predicts that SMT outputs are more suitable for post-editing than the hits provided by the TM. We describe an implementation of this framework using an SVM binary classifier. We exploit methods to fine-tune the classifier and investigate a variety of features of different types. We rely on automatic MT evaluation metrics to approximate human judgements in our experiments. Experimental results show that our system can achieve 0.85 precision at 0.89 recall, excluding exact matches. Furthermore, it is possible for the end-user to achieve a desired balance between precision and recall by adjusting confidence levels."
D10-1041,Facilitating Translation Using Source Language Paraphrase Lattices,2010,13,25,3,1,21659,jinhua du,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"For resource-limited language pairs, coverage of the test set by the parallel corpus is an important factor that affects translation quality in two respects: 1) out of vocabulary words; 2) the same information in an input sentence can be expressed in different ways, while current phrase-based SMT systems cannot automatically select an alternative way to transfer the same information. Therefore, given limited data, in order to facilitate translation from the input side, this paper proposes a novel method to reduce the translation difficulty using source-side lattice-based paraphrases. We utilise the original phrases from the input sentence and the corresponding paraphrases to build a lattice with estimated weights for each edge to improve translation quality. Compared to the baseline system, our method achieves relative improvements of 7.07%, 6.78% and 3.63% in terms of BLEU score on small, medium and large-scale English-to-Chinese translation tasks respectively. The results show that the proposed method is effective not only for resource-limited language pairs, but also for resource-sufficient pairs to some extent."
C10-2043,Integrating N-best {SMT} Outputs into a {TM} System,2010,14,17,3,1,12154,yifan he,Coling 2010: Posters,0,"In this paper, we propose a novel framework to enrich Translation Memory (TM) systems with Statistical Machine Translation (SMT) outputs using ranking. In order to offer the human translators multiple choices, instead of only using the top SMT output and top TM hit, we merge the N-best output from the SMT system and the k-best hits with highest fuzzy match scores from the TM system. The merged list is then ranked according to the prospective post-editing effort and provided to the translators to aid their work. Experiments show that our ranked output achieve 0.8747 precision at top 1 and 0.8134 precision at top 5. Our framework facilitates a tight integration between SMT and TM, where full advantage is taken of TM while high quality SMT output is availed of to improve the productivity of human translators."
C10-1033,A Discriminative Latent Variable-Based {``}{DE}{''} Classifier for {C}hinese-{E}nglish {SMT},2010,17,2,2,1,21659,jinhua du,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Syntactic reordering on the source-side is an effective way of handling word order differences. The (DE) construction is a flexible and ubiquitous syntactic structure in Chinese which is a major source of error in translation quality. In this paper, we propose a new classifier model --- discriminative latent variable model (DPLVM) --- to classify the DE construction to improve the accuracy of the classification and hence the translation quality. We also propose a new feature which can automatically learn the reordering rules to a certain extent. The experimental results show that the MT systems using the data reordered by our proposed model outperform the baseline systems by 6.42% and 3.08% relative points in terms of the BLEU score on PB-SMT and hierarchical phrase-based MT respectively. In addition, we analyse the impact of DE annotation on word alignment and on the SMT phrase table."
2010.iwslt-papers.1,{CCG} augmented hierarchical phrase-based machine translation,2010,8,11,3,1,43864,hala almaghout,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,None
2010.iwslt-evaluation.3,The {DCU} machine translation systems for {IWSLT} 2010,2010,0,2,3,1,43864,hala almaghout,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2010.eamt-1.7,Statistical Analysis of Alignment Characteristics for Phrase-based Machine Translation,2010,20,4,4,1,23604,patrik lambert,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"In most statistical machine translation (SMT) systems, bilingual segments are extracted via word alignment. However, there lacks systematic study as to what alignment characteristics can benefit MT under specific experimental settings such as the language pair or the corpus size. In this paper we produce a set of alignments by directly tuning the alignment model according to alignment F-score and BLEU score in order to investigate the alignment characteristics that are helpful in translation. We report results for a phrasebased SMT system on Chinese-to-English IWSLT data, and Spanish-to-English European Parliament data. With a statistical analysis into alignment characteristics that are correlated with BLEU score, we give alignment hints to improve BLEU score using a phrase-based SMT system and different types of corpus."
2010.eamt-1.23,{TMX} Markup: A Challenge When Adapting {SMT} to the Localisation Environment,2010,13,5,3,1,21659,jinhua du,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"Translation memory (TM) plays an important role in localisation workflows and is used as an efficient and fundamental tool to carry out translation. In recent years, statistical machine translation (SMT) techniques have been rapidly developed, and the translation quality and speed have been significantly improved as well. However, when applying SMT technique to facilitate post-editing in the localisation industry, we need to adapt SMT to the TM data which is formatted with special mark-up. In this paper, we explore some issues when adapting SMT to Symantec formatted TM data. Three different methods are proposed to handle the Translation Memory eXchange (TMX) markup and a comparative study is carried out between them. Furthermore, we also compare the TMX-based SMT systems with a customised SYSTRAN system through human evaluation and automatic evaluation metrics. The experimental results conducted on the French and English language pair show that the SMT can perform well using TMX as input format either during training or at runtime."
2010.eamt-1.26,Lattice Score Based Data Cleaning for Phrase-Based Statistical Machine Translation,2010,24,5,3,1,7874,jie jiang,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"Statistical machine translation relies heavi ly on parallel corpora to train its models for translation tasks. While more and more bilingual corpora are readily available, the quality of the sentence pairs should be taken into consideration. This paper presents a novel lattice score-based data cleaning method to select proper sentence pairs from the ones extracted from a bilingual corpus by the sentence alignment methods. The proposed method is carried out as follows: firstly, an initial phrasebased model is trained on the full sentencealigned corpus; then for each of the sentence pairs in the corpus, word alignments are used to create anchor pairs and sourceside lattices; thirdly, based on the translation model, target-side phrase networks are expanded on the lattices and Viterbi searching is used to find approximated decoding results; finally, BLEU score thresholds are used to filter out the low-score sentence pairs for the data cleaning purpose. Our experiments on the FBIS corpus showed improvements of BLEU score from 23.78 to 24.02 in Chinese-English."
2010.eamt-1.32,The Impact of Source{--}Side Syntactic Reordering on Hierarchical Phrase-based {SMT},2010,14,6,2,1,21659,jinhua du,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"Syntactic reordering has been demonstrated to be helpful and effective for handling different word orders between source and target languages in SMT. However, in terms of hierarchial PB-SMT (HPB), does the syntactic reordering still has a significant impact on its performance? This paper introduces a reordering approach which explores the { (DE) grammatical structure in Chinese. We employ the Stanford DE classifier to recognise the DE structures in both training and test sentences of Chinese, and then perform word reordering to make the Chinese sentences better match the word order of English. The annotated and reordered training data and test data are applied to a re-implemented HPB system and the impact of the DE construction is examined. The experiments are conducted on the NIST 2008 evaluation data and experimental results show that the BLEU and METEOR scores are significantly improved by 1.83/8.91 and 1.17/2.73 absolute/relative points respectively."
2010.amta-papers.9,Using {TER}p to Augment the System Combination for {SMT},2010,26,8,2,1,21659,jinhua du,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"TER-Plus (TERp) is an extended TER evaluation metric incorporating morphology, synonymy and paraphrases. There are three new edit operations in TERp: Stem Matches, Synonym Matches and Phrase Substitutions (Paraphrases). In this paper, we propose a TERp-based augmented system combination in terms of the backbone selection and consensus decoding network. Combining the new properties of the TERp, we also propose a two-pass decoding strategy for the lattice-based phrase-level confusion network (CN) to generate the final result.The experiments conducted on the NIST2008 Chinese-to-English test set show that our TERp-based augmented system combination framework achieves significant improvements in terms of BLEU and TERp scores compared to the state-of-the-art word-level system combination framework and a TER-based combination strategy."
2010.amta-papers.11,Improved Phrase-based {SMT} with Syntactic Reordering Patterns Learned from Lattice Scoring,2010,24,1,3,1,7874,jie jiang,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In this paper, we present a novel approach to incorporate source-side syntactic reordering patterns into phrase-based SMT. The main contribution of this work is to use the lattice scoring approach to exploit and utilize reordering information that is favoured by the baseline PBSMT system. By referring to the parse trees of the training corpus, we represent the observed reorderings with source-side syntactic patterns. The extracted patterns are then used to convert the parsed inputs into word lattices, which contain both the original source sentences and their potential reorderings. Weights of the word lattices are estimated from the observations of the syntactic reordering patterns in the training corpus. Finally, the PBSMT system is tuned and tested on the generated word lattices to show the benefits of adding potential source-side reorderings in the inputs. We confirmed the effectiveness of our proposed method on a medium-sized corpus for Chinese-English machine translation task. Our method outperformed the baseline system by 1.67{\%} relative on a randomly selected testset and 8.56{\%} relative on the NIST 2008 testset in terms of BLEU score."
2010.amta-papers.16,Combining Multi-Domain Statistical Machine Translation Models using Automatic Classifiers,2010,20,31,5,1,41915,pratyush banerjee,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper presents a set of experiments on Domain Adaptation of Statistical Machine Translation systems. The experiments focus on Chinese-English and two domain-specific corpora. The paper presents a novel approach for combining multiple domain-trained translation models to achieve improved translation quality for both domain-specific as well as combined sets of sentences. We train a statistical classifier to classify sentences according to the appropriate domain and utilize the corresponding domain-specific MT models to translate them. Experimental results show that the method achieves a statistically significant absolute improvement of 1.58 BLEU (2.86{\%} relative improvement) score over a translation model trained on combined data, and considerable improvements over a model using multiple decoding paths of the Moses decoder, for the combined domain test set. Furthermore, even for domain-specific test sets, our approach works almost as well as dedicated domain-specific models and perfect classification."
2010.amta-papers.23,Supertags as Source Language Context in Hierarchical Phrase-Based {SMT},2010,31,16,4,1,5016,rejwanul haque,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Statistical machine translation (SMT) models have recently begun to include source context modeling, under the assumption that the proper lexical choice of the translation for an ambiguous word can be determined from the context in which it appears. Various types of lexical and syntactic features have been explored as effective source context to improve phrase selection in SMT. In the present work, we introduce lexico-syntactic descriptions in the form of supertags as source-side context features in the state-of-the-art hierarchical phrase-based SMT (HPB) model. These features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. In our experiments two kinds of supertags are employed: those from lexicalized tree-adjoining grammar (LTAG) and combinatory categorial grammar (CCG). We use a memory-based classification framework that enables the efficient estimation of these features. Despite the differences between the two supertagging approaches, they give similar improvements. We evaluate the performance of our approach on an English-to-Dutch translation task, and report statistically significant improvements of 4.48{\%} and 6.3{\%} BLEU scores in translation quality when adding CCG and LTAG supertags, respectively, as context-informed features."
2010.amta-papers.27,Improving the Post-Editing Experience using Translation Recommendation: A User Study,2010,20,17,4,1,12154,yifan he,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We report findings from a user study with professional post-editors using a translation recommendation framework (He et al., 2010) to integrate Statistical Machine Translation (SMT) output with Translation Memory (TM) systems. The framework recommends SMT outputs to a TM user when it predicts that SMT outputs are more suitable for post-editing than the hits provided by the TM. We analyze the effectiveness of the model as well as the reaction of potential users. Based on the performance statistics and the users{'} comments, we find that translation recommendation can reduce the workload of professional post-editors and improve the acceptance of MT in the localization industry."
2010.amta-papers.28,Accuracy-Based Scoring for Phrase-Based Statistical Machine Translation,2010,26,2,4,1,38356,sergio penkale,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Although the scoring features of state-of-the-art Phrase-Based Statistical Machine Translation (PB-SMT) models are weighted so as to optimise an objective function measuring translation quality, the estimation of the features themselves does not have any relation to such quality metrics. In this paper, we introduce a translation quality-based feature to PB-SMT in a bid to improve the translation quality of the system. Our feature is estimated by averaging the edit-distance between phrase pairs involved in the translation of oracle sentences, chosen by automatic evaluation metrics from the N-best outputs of a baseline system, and phrase pairs occurring in the N-best list. Using our method, we report a statistically significant 2.11{\%} relative improvement in BLEU score for the WMT 2009 Spanish-to-English translation task. We also report that using our method we can achieve statistically significant improvements over the baseline using many other MT evaluation metrics, and a substantial increase in speed and reduction in memory use (due to a reduction in phrase-table size of 87{\%}) while maintaining significant gains in translation quality."
2010.amta-commercial.14,{PL}u{TO}: {MT} for On-Line Patent Translation,2010,-1,-1,2,1,20890,john tinsley,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Commercial MT User Program,0,"PLuTO {--} Patent Language Translation Online {--} is a partially EU-funded commercialization project which specializes in the automatic retrieval and translation of patent documents. At the core of the PLuTO framework is a machine translation (MT) engine through which web-based translation services are offered. The fully integrated PLuTO architecture includes a translation engine coupling MT with translation memories (TM), and a patent search and retrieval engine. In this paper, we first describe the motivating factors behind the provision of such a service. Following this, we give an overview of the PLuTO framework as a whole, with particular emphasis on the MT components, and provide a real world use case scenario in which PLuTO MT services are ex- ploited."
Y09-2027,Experiments on Domain Adaptation for {E}nglish{--}{H}indi {SMT},2009,29,10,4,1,5016,rejwanul haque,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 2",0,"Statistical Machine Translation (SMT) systems are usually trained on large amounts of bilingual text and monolingual target language text. If a significant amount of out-of-domain data is added to the training data, the quality of translation can drop. On the other hand, training an SMT system on a small amount of training material for given in- domain data leads to narrow lexical coverage which again results in a low translation quality. In this paper, (i) we explore domain-adaptation techniques to combine large out-of-domain training data with small-scale in-domain training data for Englishxe2x80x94Hindi statistical machine translation and (ii) we cluster large out-of-domain training data to extract sentences similar to in-domain sentences and apply adaptation techniques to combine clustered sub-corpora with in-domain training data into a unified framework, achieving a 0.44 absolute corresponding to a 4.03% relative improvement in terms of BLEU over the baseline."
Y09-1007,Capturing Lexical Variation in {MT} Evaluation Using Automatically Built Sense-Cluster Inventories,2009,24,1,3,0,2673,marianna apidianaki,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"The strict character of most of the existing Machine Translation (MT) evaluation metrics does not permit them to capture lexical variation in translation. However, a central issue in MT evaluation is the high correlation that the metrics should have with human judg- ments of translation quality. In order to achieve a higher correlation, the identification of sense correspondences between the compared translations becomes really important. Given that most metrics are looking for exact correspondences, the evaluation results are often mis- leading concerning translation quality. Apart from that, existing metrics do not permit one to make a conclusive estimation of the impact of Word Sense Disambiguation techniques into MT systems. In this paper, we show how information acquired by an unsupervised semantic analysis method can be used to render MT evaluation more sensitive to lexical semantics. The sense inventories built by this data-driven method are incorporated into METEOR: they replace WordNet for evaluation in English and render METEOR's synonymy module operable in French. The evaluation results demonstrate that the use of these inventories gives rise to an increase in the number of matches and the correlation with human judgments of translation quality, compared to precision-based metrics."
Y09-1019,Dependency Relations as Source Context in Phrase-Based {SMT},2009,31,9,4,1,5016,rejwanul haque,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"The Phrase-Based Statistical Machine Translation (PB-SMT) model has recently begun to include source context modeling, under the assumption that the proper lexicaln choice of an ambiguous word can be determined from the context in which it appears. Various types of lexical and syntactic features such as words, parts-of-speech, andn supertags have been explored as effective source context in SMT. In this paper, we show that position-independent syntactic dependency relations of the head of a source phrase can be modeled as useful source context to improve target phrase selection and thereby improve overall performance of PB-SMT. On a Dutchxe2x80x94English translation task, by combining dependency relations and syntactic contextual features (part-of-speech), we achieved a 1.0 BLEU (Papineni et al., 2002) point improvement (3.1% relative) over the baseline."
W09-3523,{E}nglish-{H}indi Transliteration Using Context-Informed {PB}-{SMT}: the {DCU} System for {NEWS} 2009,2009,15,15,5,1,5016,rejwanul haque,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"This paper presents English---Hindi transliteration in the NEWS 2009 Machine Transliteration Shared Task adding source context modeling into state-of-the-art log-linear phrase-based statistical machine translation (PB-SMT). Source context features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. We use a memory-based classification framework that enables efficient estimation of these features while avoiding data sparseness problems.We carried out experiments both at character and transliteration unit (TU) level. Position-dependent source context features produce significant improvements in terms of all evaluation metrics."
W09-1509,Web Service Integration for Next Generation Localisation,2009,6,10,6,0,34988,david lewis,"Proceedings of the Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing ({SETQA}-{NLP} 2009)",0,"Developments in Natural Language Processing technologies promise a variety of benefits to the localization industry, both in its current form in performing bulk enterprise-based localization and in the future in supporting personalized web-based localization on increasingly user-generated content. As an increasing variety of natural language processing services become available, it is vital that the localization industry employs the flexible software integration techniques that will enable it to make best use of these technologies. To date however, the localization industry has been slow reap the benefits of modern integration technologies such as web service integration and orchestration. Based on recent integration experiences, we examine how the localization industry can best exploit web-based integration technologies in developing new services and exploring new business models"
W09-0416,{MATREX}: The {DCU} {MT} System for {WMT} 2009,2009,16,25,4,1,21659,jinhua du,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"In this paper, we describe the machine translation system in the evaluation campaign of the Fourth Workshop on Statistical Machine Translation at EACL 2009.n n We describe the modular design of our multi-engine MT system with particular focus on the components used in this participation.n n We participated in the translation task for the following translation directions: French--English and English--French, in which we employed our multi-engine architecture to translate. We also participated in the system combination task which was carried out by the MBR decoder and Confusion Network decoder. We report results on the provided development and test sets."
R09-1025,Lexicalized Semi-incremental Dependency Parsing,2009,26,7,3,1,6587,hany hassan,Proceedings of the International Conference {RANLP}-2009,0,"Even leaving aside concerns of cognitive plausibility, incremental parsing is appealing for applications such as speech recognition and machine translation because it could allow for incorporating syntactic features into the decoding process without blowing up the search space. Yet, incremental parsing is often associated with greedy parsing decisions and intolerable loss of accuracy. Would the use of lexicalized grammars provide a new perspective on incremental parsing? In this paper we explore incremental left-to-right dependency parsing using a lexicalized grammatical formalism that works with lexical categories (supertags) and a small set of combinatory operators. A strictly incremental parser would conduct only a single pass over the input, use no lookahead and make only local decisions at every word. We show that such a parser suffers heavy loss of accuracy. Instead, we explore the utility of a two-pass approach that incrementally builds a dependency structure by first assigning a supertag to every input word and then selecting an incremental operator that allows assembling every supertag with the dependency structure built so-far to its left. We instantiate this idea in different models that allow a trade-off between aspects of full incrementality and performance, and explore the differences between these models empirically. Our exploration shows that a semi-incremental (two-pass), linear-time parser that employs fixed and limited look-ahead exhibits an appealing balance between the efficiency advantages of incrementality and the achieved accuracy. Surprisingly, taking local or global decisions matters very little for the accuracy of this linear-time parser. Such a parser fits seemlessly with the currently dominant finite-state decoders for machine translation."
E09-1063,Bilingually Motivated Domain-Adapted Word Segmentation for Statistical Machine Translation,2009,23,29,2,1,11802,yanjun ma,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"We introduce a word segmentation approach to languages where word boundaries are not orthographically marked, with application to Phrase-Based Statistical Machine Translation (PB-SMT). Instead of using manually segmented monolingual domain-specific corpora to train segmenters, we make use of bilingual corpora and statistical word alignment techniques. First of all, our approach is adapted for the specific translation task at hand by taking the corresponding source (target) language into account. Secondly, this approach does not rely on manually segmented training data so that it can be automatically adapted for different domains. We evaluate the performance of our segmentation approach on PB-SMT tasks from two domains and demonstrate that our approach scores consistently among the best results across different data conditions."
D09-1039,Accuracy-Based Scoring for {DOT}: Towards Direct Error Minimization for {D}ata-{O}riented {T}ranslation,2009,26,4,3,0,46651,daniel galron,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"In this work we present a novel technique to rescore fragments in the Data-Oriented Translation model based on their contribution to translation accuracy. We describe three new rescoring methods, and present the initial results of a pilot experiment on a small subset of the Europarl corpus. This work is a proof-of-concept, and is the first step in directly optimizing translation decisions solely on the hypothesized accuracy of potential translations resulting from those decisions."
D09-1123,A Syntactified Direct Translation Model with Linear-time Decoding,2009,23,14,3,1,6587,hany hassan,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"Recent syntactic extensions of statistical translation models work with a synchronous context-free or tree-substitution grammar extracted from an automatically parsed parallel corpus. The decoders accompanying these extensions typically exceed quadratic time complexity.n n This paper extends the Direct Translation Model 2 (DTM2) with syntax while maintaining linear-time decoding. We employ a linear-time parsing algorithm based on an eager, incremental interpretation of Combinatory Categorial Grammar (CCG). As every input word is processed, the local parsing decisions resolve ambiguity eagerly, by selecting a single supertag-operator pair for extending the dependency parse incrementally. Alongside translation features extracted from the derived parse tree, we explore syntactic features extracted from the incremental derivation process. Our empirical experiments show that our model significantly outperforms the state-of-the art DTM2 system."
2009.mtsummit-posters.7,Source-Side Context-Informed Hypothesis Alignment for Combining Outputs from Machine Translation Systems,2009,17,5,3,1,21659,jinhua du,Proceedings of Machine Translation Summit XII: Posters,0,"This paper presents a new hypothesis alignment method for combining outputs of multiple machine translation (MT) systems. Traditional hypothesis alignment algorithms suchn as TER, HMM and IHMM do not directly utilise the context information of the source side but rather address the alignment issues via the output data itself. In this paper, a source-side context-informed (SSCI) hypothesis alignment method is proposed to carry out the word alignment and word reordering issues. First of all, the sourcexe2x80x93target word alignment links are produced as the hidden variables by exporting source phrase spans during the translation decoding process. Secondly, a mapping strategy and normalisation model are employed to acquire the 1-n to-1 alignment links and build the confusion network (CN). The source-side context-based method outperforms the state-of-the-art TERbased alignment model in our experimentsn on the WMT09 English-to-French and NIST Chinese-to-English data sets respectively. Experimental results demonstrate that our proposed approach scores consistently among then best results across different data and language pair conditions."
2009.mtsummit-posters.8,Improving the Objective Function in Minimum Error Rate Training,2009,22,17,2,1,12154,yifan he,Proceedings of Machine Translation Summit XII: Posters,0,"In Minimum Error Rate Training (MERT), the parameters of an SMT system are tuned on a certain evaluation metric to improve translation quality. In this paper, we present empirical results in which parameters tuned on one metric (e.g. BLEU) may not lead to optimal scores on the same metric. The score can be improved significantly by tuning on an entirely different metric (e.g. METEOR, by 0.82n BLEU points or 3.38% relative improvement on WMT08 Englishxe2x80x93French dataset). We analyse the impact of choice of objective function in MERT and further propose threen combination strategies of different metrics to reduce the bias of a single metric, and obtain parameters that receive better scores (0.99 BLEU points or 4.08% relative improvement) on evaluation metrics than those tuned on then standalone metric itself."
2009.mtsummit-posters.12,Tracking Relevant Alignment Characteristics for Machine Translation,2009,18,7,4,1,23604,patrik lambert,Proceedings of Machine Translation Summit XII: Posters,0,"In most statistical machine translation (SMT) systems, bilingual segments are extracted via word alignment. In this paper we compare alignments tuned directly according to alignment F-score and BLEU score in order to investigaten the alignment characteristics that are helpful in translation. We report results for two different SMT systems (a phrase-based and an n-gram-based system) on Chinese to English IWSLT data, and Spanish to Englishn European Parliament data. We give alignment hints to improve BLEU score, depending on the SMT system used and the type of corpus."
2009.mtsummit-posters.18,Using Percolated Dependencies for Phrase Extraction in {SMT},2009,26,6,2,1,31656,ankit srivastava,Proceedings of Machine Translation Summit XII: Posters,0,"Statistical Machine Translation (SMT) systems rely heavily on the quality of the phrase pairs induced from large amounts of training data. Apart from the widely used method of heuristic learning of n-gram phrase translations from word alignments, there are numerous methods for extracting these phrase pairs. One such class of approaches uses translation information encoded in parallel treebanks to extract phrase pairs. Work to date has demonstrated the usefulness of translation models induced from both constituency structure trees and dependency structure trees. Both syntactic annotations rely on the existence of natural language parsers for both the source and target languages. We depart from the norm by directly obtaining dependency parses from constituency structures using head percolation tables. The paper investigates the use of aligned chunks induced from percolated dependencies in Frenchxe2x80x93English SMT and contrasts it with the aforementioned extracted phrases.n We observe that adding phrase pairs from any other method improves translation performance over the baseline n-gram-based system, percolated dependencies are a good substitute for parsed dependencies, and that supplementing with our novel head percolation-induced chunks shows a general trend toward improving all system types across two data sets up to a 5.26% relative increase in BLEU."
2009.iwslt-evaluation.4,Low-resource machine translation using {M}a{T}r{E}x,2009,-1,-1,5,1,11802,yanjun ma,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we give a description of the Machine Translation (MT) system developed at DCU that was used for our fourth participation in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT 2009). Two techniques are deployed in our system in order to improve the translation quality in a low-resource scenario. The first technique is to use multiple segmentations in MT training and to utilise word lattices in decoding stage. The second technique is used to select the optimal training data that can be used to build MT systems. In this year{'}s participation, we use three different prototype SMT systems, and the output from each system are combined using standard system combination method. Our system is the top system for Chinese{--}English CHALLENGE task in terms of BLEU score."
2009.eamt-1.7,Learning Labelled Dependencies in Machine Translation Evaluation,2009,18,4,2,1,12154,yifan he,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"Recently novel MT evaluation metrics have been presented which go beyond pure string matching, and which correlate better than other existing metrics with human judgements. Other research in this area has presented machine learning methods which learn directly from human judgements. In this paper, we present a novel combination of dependency- and machine learning-based approaches to automatic MT evaluation, and demonstrate greater correlations with human judgement than the existing state-of-the-art methods. In addition, we examine the extent to which our novel method can be generalised across different tasks and domains."
2009.eamt-1.14,Optimal Bilingual Data for {F}rench-{E}nglish {PB}-{SMT},2009,13,20,2,0.77381,46337,sylwia ozdowska,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"We investigate the impact of the original source language (SL) on Frenchxe2x80x90English PB-SMT. We train four configurations of a state-of-the-art PB-SMT system based on Frenchxe2x80x90English parallel corpora which differ in terms of the original SL, and conduct experiments in both translation directions. We see that data containing original French and English translated from French is optimal when building a system translating from French into English. Conversely, using data comprising exclusively French and English translated from several other languages is suboptimal regardless of the translation direction. Accordingly, the clamour for more data needs to be tempered somewhat; unless the quality of such data is controlled, more training data can cause translation performance to decrease drastically, by up to 38% relative B LEU in our experiments."
2009.eamt-1.20,Marker-Based Filtering of Bilingual Phrase Pairs for {SMT},2009,32,8,2,0,9988,felipe sanchezmartinez,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,Spanish Ministry of Education and Science (project TIN2006-15071-C03-01). Science Foundation Ireland through grants 05/IN/1732 and 06/RF/CMS064.
2009.eamt-1.32,Using Supertags as Source Language Context in {SMT},2009,34,27,4,1,5016,rejwanul haque,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"Recent research has shown that Phrase-Based Statistical Machine Translation (PB-SMT) systems can benefit from twon enhancements: (i) using words and POS tags as context-informed features on the source side; and (ii) incorporating lexical syntactic descriptions in the form of supertags on the target side. In this work wen present a novel PB-SMT model that combines these two aspects by using supertags as source language contextinformed features. These features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. In our experiments twon kinds of supertags are employed: those from Lexicalized Tree-Adjoining Grammar and Combinatory Categorial Grammar.n We use a memory-based classification framework that enables the estimation of these features while avoidingn problems of sparseness. Despite the differences between these two approaches, the supertaggers give similar improvements. We evaluate the performance of our approach on an English-to-Chinese translation task using a state-of-the-art phrase-based SMT system, and report ann improvement of 7.88% BLEU score in translation quality when adding supertags as context-informed features."
2009.eamt-1.34,Tuning Syntactically Enhanced Word Alignment for Statistical Machine Translation,2009,23,3,3,1,11802,yanjun ma,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"We introduce a syntactically enhanced word alignment model that is more flexible than state-of-the-art generative wordn alignment models and can be tuned according to different end tasks. First of all, this model takes the advantages ofn both unsupervised and supervised word alignment approaches by obtaining anchor alignments from unsupervised generativen models and seeding the anchor alignments into a supervised discriminative model. Second, this model offers the flexibility of tuning the alignment according to differentn optimisation criteria. Our experiments show that using our word alignment in a Phrase-Based Statistical Machine Translation system yields a 5.38% relative increasen on IWSLT 2007 task in terms of BLEU score."
W08-0409,Improving Word Alignment Using Syntactic Dependencies,2008,29,28,4,1,11802,yanjun ma,Proceedings of the {ACL}-08: {HLT} Second Workshop on Syntax and Structure in Statistical Translation ({SSST}-2),0,"We introduce a word alignment framework that facilitates the incorporation of syntax encoded in bilingual dependency tree pairs. Our model consists of two sub-models: an anchor word alignment model which aims to find a set of high-precision anchor links and a syntaxenhanced word alignment model which focuses on aligning the remaining words relying on dependency information invoked by the acquired anchor links. We show that our syntaxenhanced word alignment approach leads to a 10.32% and 5.57% relative decrease in alignment error rate compared to a generative word alignment model and a syntax-proof discriminative word alignment model respectively. Furthermore, our approach is evaluated extrinsically using a phrase-based statistical machine translation system. The results show that SMT systems based on our word alignment approach tend to generate shorter outputs. Without length penalty, using our word alignments yields statistically significant improvement in Chinese-English machine translation in comparison with the baseline word alignment."
W08-0326,{M}a{T}r{E}x: The {DCU} {MT} System for {WMT} 2008,2008,15,20,4,1,20890,john tinsley,Proceedings of the Third Workshop on Statistical Machine Translation,0,"In this paper, we give a description of the machine translation system developed at DCU that was used for our participation in the evaluation campaign of the Third Workshop on Statistical Machine Translation at ACL 2008.n n We describe the modular design of our data-driven MT system with particular focus on the components used in this participation. We also describe some of the significant modules which were unused in this task.n n We participated in the EuroParl task for the following translation directions: Spanish-English and French-English, in which we employed our hybrid EBMT-SMT architecture to translate. We also participated in the Czech-English News and News Commentary tasks which represented a previously untested language pair for our system. We report results on the provided development and test sets."
bungeroth-etal-2008-atis,The {ATIS} Sign Language Corpus,2008,5,26,6,0,48344,jan bungeroth,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Systems that automatically process sign language rely on appropriate data. We therefore present the ATIS sign language corpus that is based on the domain of air travel information. It is available for five languages, English, German, Irish sign language, German sign language and South African sign language. The corpus can be used for different tasks like automatic statistical translation and automatic sign language recognition and it allows the specific modeling of spatial references in signing space."
J08-1003,Wide-Coverage Deep Statistical Parsing Using Automatic Dependency Structure Annotation,2008,64,47,6,0.638298,4873,aoife cahill,Computational Linguistics,0,"A number of researchers have recently conducted experiments comparing deep hand-crafted wide-coverage with shallow treebank-and machine-learning-based parsers at the level of dependencies, using simple and automatic methods to convert tree output generated by the shallow parsers into dependencies. In this article, we revisit such experiments, this time using sophisticated automatic LFG f-structure annotation methodologies with surprising results. We compare various PCFG and history-based parsers to find a baseline parsing system that fits best into our automatic dependency structure annotation technique. This combined system of syntactic parser and dependency structure annotation is compared to two hand-crafted, deep constraint-based parsers, RASP and XLE. We evaluate using dependency-based gold standards and use the Approximate Randomization Test to test the statistical significance of the results. Our experiments show that machine-learning-based shallow grammars augmented with sophisticated automatic dependency annotation technology outperform hand-crafted, deep, wide-coverage constraint grammars. Currently our best system achieves an f-score of 82.73% against the PARC 700 Dependency Bank, a statistically significant improvement of 2.18% over the most recent results of 80.55% for the hand-crafted LFG grammar and XLE parsing system and an f-score of 80.23% against the CBS 500 Dependency Bank, a statistically significant 3.66% improvement over the 76.57% achieved by the hand-crafted RASP grammar and parsing system."
C08-1139,Automatic Generation of Parallel Treebanks,2008,18,38,2,0.632184,40415,ventsislav zhechev,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"The need for syntactically annotated data for use in natural language processing has increased dramatically in recent years. This is true especially for parallel treebanks, of which very few exist. The ones that exist are mainly hand-crafted and too small for reliable use in data-oriented applications. In this paper we introduce a novel platform for fast and robust automatic generation of parallel treebanks. The software we have developed based on this platform has been shown to handle large data sets. We also present evaluation results demonstrating the quality of the derived treebanks and discuss some possible modifications and improvements that can lead to even better results. We expect the presented platform to help boost research in the field of data-oriented machine translation and lead to advancements in other fields where parallel treebanks can be employed."
2008.iwslt-evaluation.3,Exploiting alignment techniques in {MATREX}: the {DCU} machine translation system for {IWSLT} 2008.,2008,23,10,5,1,11802,yanjun ma,Proceedings of the 5th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we give a description of the machine translation (MT) system developed at DCU that was used for our third participation in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT 2008). In this participation, we focus on various techniques for word and phrase alignment to improve system quality. Specifically, we try out our word packing and syntax-enhanced word alignment techniques for the Chinese{--}English task and for the English{--}Chinese task for the first time. For all translation tasks except Arabic{--}English, we exploit linguistically motivated bilingual phrase pairs extracted from parallel treebanks. We smooth our translation tables with out-of-domain word translations for the Arabic{--}English and Chinese{--}English tasks in order to solve the problem of the high number of out of vocabulary items. We also carried out experiments combining both in-domain and out-of-domain data to improve system performance and, finally, we deploy a majority voting procedure combining a language model-based method and a translation-based method for case and punctuation restoration. We participated in all the translation tasks and translated both the single-best ASR hypotheses and the correct recognition results. The translation results confirm that our new word and phrase alignment techniques are often helpful in improving translation quality, and the data combination method we proposed can significantly improve system performance."
W07-0714,Labelled Dependencies in Machine Translation Evaluation,2007,20,52,3,1,29329,karolina owczarzak,Proceedings of the Second Workshop on Statistical Machine Translation,0,"We present a method for evaluating the quality of Machine Translation (MT) output, using labelled dependencies produced by a Lexical-Functional Grammar (LFG) parser. Our dependency-based method, in contrast to most popular string-based evaluation metrics, does not unfairly penalize perfectly valid syntactic variations in the translation, and the addition of WordNet provides a way to accommodate lexical variation. In comparison with other metrics on 16,800 sentences of Chinese-English newswire text, our method reaches high correlation with human scores."
W07-0411,Dependency-Based Automatic Evaluation for Machine Translation,2007,16,51,3,1,29329,karolina owczarzak,"Proceedings of {SSST}, {NAACL}-{HLT} 2007 / {AMTA} Workshop on Syntax and Structure in Statistical Translation",0,"We present a novel method for evaluating the output of Machine Translation (MT), based on comparing the dependency structures of the translation and reference rather than their surface string forms. Our method uses a treebank-based, widecoverage, probabilistic Lexical-Functional Grammar (LFG) parser to produce a set of structural dependencies for each translation-reference sentence pair, and then calculates the precision and recall for these dependencies. Our dependency-based evaluation, in contrast to most popular string-based evaluation metrics, will not unfairly penalize perfectly valid syntactic variations in the translation. In addition to allowing for legitimate syntactic differences, we use paraphrases in the evaluation process to account for lexical variation. In comparison with other metrics on 16,800 sentences of Chinese-English newswire text, our method reaches high correlation with human scores. An experiment with two translations of 4,000 sentences from Spanish-English Europarl shows that, in contrast to most other metrics, our method does not display a high bias towards statistical models of translation."
P07-1037,Supertagged Phrase-Based Statistical Machine Translation,2007,15,61,3,1,6587,hany hassan,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Until quite recently, extending Phrase-based Statistical Machine Translation (PBSMT) with syntactic structure caused system performance to deteriorate. In this work we show that incorporating lexical syntactic descriptions in the form of supertags can yield significantly better PBSMT systems. We describe a novel PBSMT model that integrates supertags into the target language model and the target side of the translation model. Two kinds of supertags are employed: those from Lexicalized Tree-Adjoining Grammar and Combinatory Categorial Grammar. Despite the differences between these two approaches, the supertaggers give similar improvements. In addition to supertagging, we also explore the utility of a surface global grammaticality measure based on combinatory operators. We perform various experiments on the Arabic to English NIST 2005 test set addressing issues such as sparseness, scalability and the utility of system subcomponents. Our best result (0.4688 BLEU) improves by 6.1% relative to a state-of-theart PBSMT model, which compares very favourably with the leading systems on the NIST 2005 task."
P07-1039,Bootstrapping Word Alignment via Word Packing,2007,29,43,3,1,11802,yanjun ma,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"We introduce a simple method to pack words for statistical word alignment. Our goal is to simplify the task of automatic word alignment by packing several consecutive words together when we believe they correspond to a single word in the opposite language. This is done using the word aligner itself, i.e. by bootstrapping on its output. We evaluate the performance of our approach on a Chinese-to-English machine translation task, and report a 12.2% relative increase in BLEU score over a state-of-the art phrasebased SMT system."
2007.tmi-papers.11,Capturing translational divergences with a statistical tree-to-tree aligner,2007,25,20,4,1,48768,mary hearne,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"Parallel treebanks, which comprise paired source-target parse trees aligned at sub-sentential level, could be usefuln for many applications, particularly data-driven machine translation. In this paper, we focus on how translationaln divergences are captured within a parallel treebank using a fully automatic statistical tree-to-tree aligner. Wen observe that while the algorithm performs well at the phrase level, performance on lexical-level alignmentsn is compromised by an inappropriate bias towards coverage rather than precision. This preference for high precisionn rather than broad coverage in terms of expressing translational divergences through tree-alignment stands inn direct opposition to the situation for SMT word-alignment models. We suggest that this has implications not onlyn for tree-alignment itself but also for the broader area of induction of syntaxaware models for SMT."
2007.tmi-papers.14,Alignment-guided chunking,2007,22,8,3,1,11802,yanjun ma,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"We introduce an adaptable monolingual chunking approachxe2x80x93Alignment-Guided Chunking (AGC)xe2x80x93which makes use of knowledge of word alignments acquired from bilingualn corpora. Our approach is motivated by the observation that a sentence should be chunked differently dependingn the foreseen end-tasks. For example, given the differentn requirements of translation into (say) French and German, it is inappropriate to chunk up an English string in exactly the same way as preparation for translation into onen or other of these languages. We test our chunking approachn on two language pairs: Frenchxe2x80x93English and Germanxe2x80x93English, where these two bilingual corpora share the same English sentences. Two chunkers trained on Frenchxe2x80x93Englishn (FE-Chunker) and Germanxe2x80x93English(DE-Chunker ) respectively are used to perform chunking on the same English sentences. We construct two test sets, each suitable for Frenchxe2x80x93n English and Germanxe2x80x93English respectively. The performance of the two chunkers is evaluated on the appropriate test set and with one reference translation only, we report Fscoresn of 32.63% for the FE-Chunker and 40.41% for the DE-Chunker."
2007.tmi-papers.26,Hand in hand: automatic sign language to {E}nglish translation,2007,9,12,5,0.882353,32003,daniel stein,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"In this paper, we describe the first data-driven automatic sign-language-to- speech translation system. While both sign language (SL) recognition and translation techniques exist, both use an intermediate notation systemn not directly intelligible for untrained users. We combine a SL recognizing framework with a state-of-the-art phrase-based machine translation (MT) system, using corpora of both American Sign Language and Irish Sign Languagen data. In a set of experiments we show the overall results and also illustrate the importance of including an vision-based knowledge source in the development of a complete SL translation system."
2007.tmi-papers.28,Exploiting source similarity for {SMT} using context-informed features,2007,29,59,3,1,49191,nicolas stroppa,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"In this paper, we introduce context informed features in a log-linear phrase-based SMT framework; these features enable us to exploit source similarity in addition to target similarity modeled by the language model. Wen present a memory-based classification framework that enables the estimation of these features while avoidingn sparseness problems. We evaluate the performance of our approach on Italian-to-English and Chinese-to-English translation tasks using a state-of-the-art phrase-based SMTn system, and report significant improvements for both BLEU and NIST scores when adding the context-informed features."
2007.mtsummit-papers.40,Comparing rule-based and data-driven approaches to {S}panish-to-{B}asque machine translation,2007,23,19,3,0,8822,gorka labaka,Proceedings of Machine Translation Summit XI: Papers,0,"In this paper, we compare the rule-based and data-drivenn approaches in the context of Spanish-to-Basque Machine Translation. The rule-based system we consider has been developed specifically for Spanish-to-Basque machine translation, and is tuned to this language pair. On the contrary, the data-driven system we use is generic, and has not been specifically designed to deal with Basque. Spanish-to-Basque Machine Translation is a challenge for data-drivenn approaches for at least two reasons. First, there is lack ofn bilingual data on which a data-driven MT system can be trained. Second, Basque is a morphologically-rich agglutinative language and translating to Basque requires a huge generation of morphological information, a difficult task for a generic system not specifically tuned to Basque. We present the results of a series of experiments, obtained on two different corpora, one being xe2x80x9cin-domainxe2x80x9d and then other one xe2x80x9cout-of-domainxe2x80x9d with respect to the data-drivenn system. We show that n-gram based automatic evaluation and edit-distance-based human evaluation yield two different sets of results. According to BLEU, the data-driven system outperforms the rule-based system on the in-domain data, while according to the human evaluation, the rule-basedn approach achieves higher scores for both corpora."
2007.mtsummit-papers.44,Combining data-driven {MT} systems for improved sign language translation,2007,25,14,2,1,42572,sara morrissey,Proceedings of Machine Translation Summit XI: Papers,0,"In this paper, we investigate the feasibility of combining two data-driven machine translation (MT) systems for the translation of sign languages (SLs). We take the MT systems of two prominent data-driven research groups, the MaTrEx system developed at DCU and the Statistical Machinen Translation (SMT) system developed at RWTH Aachen University, and apply their respective approaches to the task of translating Irish Sign Language and German Sign Language into English and German. In a set of experiments supported by automatic evaluation results, we show thatn there is a definite value to the prospective merging of MaTrExxe2x80x99s Example-Based MT chunks and distortion limit increase with RWTHxe2x80x99s constraint reordering."
2007.mtsummit-papers.62,Robust language pair-independent sub-tree alignment,2007,23,30,4,1,20890,john tinsley,Proceedings of Machine Translation Summit XI: Papers,0,"Data-driven approaches to machine translation (MT) achieve state-of-the-art results. Many syntax-aware approaches, such as Example-Based MT and Data-Oriented Translation, make use of tree pairs aligned at sub-sentential level. Obtaining sub-sentential alignments manually is time-consuming and error-prone, and requires expert knowledge of both source and target languages. We propose a novel, language pair-independent algorithm which automatically induces alignments between phrase-structure trees. We evaluate the alignments themselves against a manually aligned gold standard, and perform an extrinsic evaluation by using the aligned data to train and test a DOT system. Our results show that translation accuracy is comparable to that of the same translation system trained on manually aligned data, and coverage improves."
2007.iwslt-1.10,{M}a{T}r{E}x: the {DCU} machine translation system for {IWSLT} 2007,2007,0,5,3,1,6587,hany hassan,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"In this paper, we give a description of the machine translation system developed at DCU that was used for our second participation in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT 2007). In this participation, we focus on some new methods to improve system quality. Specifically, we try our word packing technique for different language pairs, we smooth our translation tables with out-of-domain word translations for the Arabic{--}English and Chinese{--}English tasks in order to solve the high number of out of vocabulary items, and finally we deploy a translation-based model for case and punctuation restoration. We participated in both the classical and challenge tasks for the following translation directions: Chinese{--}English, Japanese{--}English and Arabic{--}English. For the last two tasks, we translated both the single-best ASR hypotheses and the correct recognition results; for Chinese{--}English, we just translated the correct recognition results. We report the results of the system for the provided evaluation sets, together with some additional experiments carried out following identification of some simple tokenisation errors in the official runs."
W06-3112,Contextual Bitext-Derived Paraphrases in Automatic {MT} Evaluation,2006,17,40,4,1,29329,karolina owczarzak,Proceedings on the Workshop on Statistical Machine Translation,0,"In this paper we present a novel method for deriving paraphrases during automatic MT evaluation using only the source and reference texts, which are necessary for the evaluation, and word and phrase alignment software. Using target language paraphrases produced through word and phrase alignment a number of alternative reference sentences are constructed automatically for each candidate translation. The method produces lexical and low-level syntactic paraphrases that are relevant to the domain in hand, does not use external knowledge resources, and can be combined with a variety of automatic MT evaluation system."
2006.iwslt-evaluation.4,{MATREX}: {DCU} machine translation system for {IWSLT} 2006.,2006,36,58,2,1,49191,nicolas stroppa,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we give a description of the machine translation system developed at DCU that was used for our second participation in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT 2007). In this participation, we focus on some new methods to improve system quality. Specifically, we try our word packing technique for different language pairs, we smooth our translation tables with out-of-domain word translations for the Arabicxe2x80x93English and Chinesexe2x80x93English tasks in order to solve the high number of out of vocabulary items, and finally we deploy a translation-based model for case and punctuation restoration. We participated in both the classical and challenge tasks for the following translation directions: Chinesexe2x80x93English, Japanesexe2x80x93English and Arabicxe2x80x93English. For the last two tasks, we translated both the single-best ASR hypotheses and the correct recognition results; for Chinesexe2x80x93 English, we just translated the correct recognition results. We report the results of the system for the provided evaluation sets, together with some additional experiments carried out following identification of some simple tokenisation errors in the official runs."
2006.eamt-1.8,Disambiguation Strategies for Data-Oriented Translation,2006,15,24,2,1,48768,mary hearne,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,"The Data-Oriented Translation (DOT) model { originally proposed in (Poutsma, 1998, 2003) and based on Data-Oriented Parsing (DOP) (e.g. (Bod, Scha, & Sima'an, 2003)) { is best described as a hybrid model ofn translation as it combines examples, linguistic information and a statistical translation model. Although theoretically interesting, it inherits the computational complexity associated with DOP. In this paper, we focus onn one computational challenge for this model: efficiently selecting the `best' translation to output. We present four different disambiguation strategies in terms of how they are implemented in our DOT system, along with experimentsn which investigate how they compare in terms of accuracy andn efficiency."
2006.eamt-1.15,Hybridity in {MT}. Experiments on the {E}uroparl Corpus,2006,-1,-1,2,1,6302,declan groves,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,None
2006.eamt-1.24,A Syntactic Skeleton for Statistical Machine Translation,2006,15,13,5,1,45520,bart mellebeek,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,"We present a method for improving statistical machine translation performance by using linguistically motivated syntactic information. Our algorithm recursively decomposes source language sentences into syntactically simpler and shorter chunks, and recomposes their translation to form target language sentences. This improves both the word order and lexical selection of the translation. We report statistically significant relative improvementsof 3.3% BLEU score in an experiment (English!Spanish) carried out onn an 800-sentence test set extracted from the Europarl corpus."
2006.amta-papers.13,Multi-Engine Machine Translation by Recursive Sentence Decomposition,2006,20,16,4,1,45520,bart mellebeek,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"In this paper, we present a novel approach to combine the outputs of multiple MT engines into a consensus translation. In contrast to previous Multi-Engine Machine Translation (MEMT) techniques, we do not rely on word alignments of output hypotheses, but prepare the input sentence for multi-engine processing. We do this by using a recursive decomposition algorithm that produces simple chunks as input to the MT engines. A consensus translation is produced by combining the best chunk translations, selected through majority voting, a trigram language model score and a confidence score assigned to each MT engine. We report statistically significant relative improvements of up to 9{\%} BLEU score in experiments (EnglishâSpanish) carried out on an 800-sentence test set extracted from the Penn-II Treebank."
2006.amta-papers.17,Wrapper Syntax for Example-based Machine Translation,2006,17,11,5,1,29329,karolina owczarzak,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"TransBooster is a wrapper technology designed to improve the performance of wide-coverage machine translation systems. Using linguistically motivated syntactic information, it automatically decomposes source language sentences into shorter and syntactically simpler chunks, and recomposes their translation to form target language sentences. This generally improves both the word order and lexical selection of the translation. To date, TransBooster has been successfully applied to rule-based MT, statistical MT, and multi-engine MT. This paper presents the application of TransBooster to Example-Based Machine Translation. In an experiment conducted on test sets extracted from Europarl and the Penn II Treebank we show that our method can raise the BLEU score up to 3.8{\%} relative to the EBMT baseline. We also conduct a manual evaluation, showing that TransBooster-enhanced EBMT produces a better output in terms of fluency than the baseline EBMT in 55{\%} of the cases and in terms of accuracy in 53{\%} of the cases."
2006.amta-papers.26,Example-Based Machine Translation of the {B}asque Language,2006,28,26,3,1,49191,nicolas stroppa,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"Basque is both a minority and a highly inflected language with free order of sentence constituents. Machine Translation of Basque is thus both a real need and a test bed for MT techniques. In this paper, we present a modular Data-Driven MT system which includes different chunkers as well as chunk aligners which can deal with the free order of sentence constituents of Basque. We conducted Basque to English translation experiments, evaluated on a large corpus (270,000 sentence pairs). The experimental results show that our system significantly outperforms state-of-the-art approaches according to several common automatic evaluation metrics."
W05-0833,Hybrid Example-Based {SMT}: the Best of Both Worlds?,2005,16,40,2,1,6302,declan groves,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"(Way and Gough, 2005) provide an in-depth comparison of their Example-Based Machine Translation (EBMT) system with a Statistical Machine Translation (SMT) system constructed from freely available tools. According to a wide variety of automatic evaluation metrics, they demonstrated that their EBMT system outperformed the SMT system by a factor of two to one.n n Nevertheless, they did not test their EBMT system against a phrase-based SMT system. Obtaining their training and test data for English--French, we carry out a number of experiments using the Pharaoh SMT Decoder. While better results are seen when Pharaoh is seeded with Giza word- and phrase-based data compared to EBMT sub-sentential alignments, in general better results are obtained when combinations of this 'hybrid' data is used to construct the translation and probability models. While for the most part the EBMT system of (Gough & Way, 2004b) outperforms any flavour of the phrase-based SMT systems constructed in our experiments, combining the data sets automatically induced by both Giza and their EBMT system leads to a hybrid system which improves on the EBMT system per se for French--English."
J05-3003,Large-Scale Induction and Evaluation of Lexical Resources from the {P}enn-{II} and {P}enn-{III} Treebanks,2005,48,36,5,1,48509,ruth odonovan,Computational Linguistics,0,"We present a methodology for extracting subcategorization frames based on an automatic lexical-functional grammar (LFG) f-structure annotation algorithm for the Penn-II and Penn-III Treebanks. We extract syntactic-function-based subcategorization frames (LFG semantic forms) and traditional CFG category-based subcategorization frames as well as mixed function/category-based frames, with or without preposition information for obliques and particle information for particle verbs. Our approach associates probabilities with frames conditional on the lemma, distinguishes between active and passive frames, and fully reflects the effects of long-distance dependencies in the source data structures. In contrast to many other approaches, ours does not predefine the subcategorization frame types extracted, learning them instead from the source data. Including particles and prepositions, we extract 21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English."
2005.mtsummit-papers.38,Improving Online Machine Translation Systems,2005,6,11,5,1,45520,bart mellebeek,Proceedings of Machine Translation Summit X: Papers,0,"In (Mellebeek et al., 2005), we proposed the design, implementation and evaluation of a novel and modular approach to boost the translation performance of existing, wide-coverage, freely available machine translation systems, based on reliable and fast automatic decomposition of the translation input and corresponding composition of translation output. Despite showing some initial promise, our method did not improve on the baseline Logomedia1 and Systran2 MT systems. In this paper, we improve on the algorithm presented in (Mellebeek et al., 2005), and on the same test data, show increased scores for a range of automatic evaluation metrics. Our algorithm now outperforms Logomedia, obtains similar results to SDL3 and falls tantalisingly short of the performance achieved by Systran."
2005.mtsummit-ebmt.14,An Example-Based Approach to Translating Sign Language,2005,16,56,2,1,42572,sara morrissey,Workshop on example-based machine translation,0,"Users of sign languages are often forced to use a language in which they have reduced competence simply because documentation in their preferred format is not available. While some research exists on translating between natural and sign languages, we present here what we believe to be the first attempt to tackle this problem using an example-based (EBMT) approach. Having obtained a set of English{--}Dutch Sign Language examples, we employ an approach to EBMT using the {`}Marker Hypothesis{'} (Green, 1979), analogous to the successful system of (Way {\&} Gough, 2003), (Gough {\&} Way, 2004a) and (Gough {\&} Way, 2004b). In a set of experiments, we show that encouragingly good translation quality may be obtained using such an approach."
2005.eamt-1.26,{T}rans{B}ooster: boosting the performance of wide-coverage machine translation systems,2005,8,10,4,1,45520,bart mellebeek,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"We propose the design, implementation and evaluation of a novel and modular approach to boost the translation performance of existing, wide-coverage, freely available machine translation systems based on reliable and fast automatic decomposition of the translation input and corresponding composition of translation output. We provide details of our method, and experimental results compared to the MT systems SYSTRAN and Logomedia. While many avenues for further experimentation remain, to date we fall just behind the baseline systems on the full 800-sentence testset, but in certain cases our method causes the translation quality obtained via the MT systems to improve."
Y04-1016,Treebank-Based Acquisition of a {C}hinese {L}exical-{F}unctional {G}rammar,2004,21,20,8,1,48508,michael burke,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,"Scaling wide-coverage, constraint-based grammars such as Lexical-Functional Grammars (LFG) (Kaplan and Bresnan, 1982; Bresnan, 2001) or Head-Driven Phrase Structure Grammars (HPSG) (Pollard and Sag, 1994) from fragments to naturally occurring unrestricted text is knowledge-intensive, time-consuming and (often prohibitively) expensive. A number of researchers have recently presented methods to automatically acquire wide-coverage, probabilistic constraint-based grammatical resources from treebanks (Cahill et al., 2002, Cahill et al., 2003; Cahill et al., 2004; Miyao et al., 2003; Miyao et al., 2004; Hockenmaier and Steedman, 2002; Hockenmaier, 2003), addressing the knowledge acquisition bottleneck in constraint-based grammar development. Research to date has concentrated on English and German. In this paper we report on an experiment to induce wide-coverage, probabilistic LFG grammatical and lexical resources for Chinese from the Penn Chinese Treebank (CTB) (Xue et al., 2002) based on an automatic f-structure annotation algorithm. Currently 96.751% of the CTB trees receive a single, covering and connected f-structure, 0.112% do not receive an fstructure due to feature clashes, while 3.137% are associated with multiple f-structure fragments. From the f-structure-annotated CTB we extract a total of 12975 lexical entries with 20 distinct subcategorisation frame types. Of these 3436 are verbal entries with a total of 11 different frame types. We extract a number of PCFG-based LFG approximations. Currently our best automatically induced grammars achieve an f-score of 81.57% against the trees in unseen articles 301-325; 86.06% f-score (all grammatical functions) and 73.98% (preds-only) against the dependencies derived from the f-structures automatically generated for the original trees in 301-325 and 82.79% (all grammatical functions) and 67.74% (preds-only) against the dependencies derived from the manually annotated gold-standard f-structures for 50 trees randomly selected from articles 301-325."
P04-1041,Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage {PCFG}-Based {LFG} Approximations,2004,21,107,5,1,4873,aoife cahill,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"This paper shows how finite approximations of long distance dependency (LDD) resolution can be obtained automatically for wide-coverage, robust, probabilistic Lexical-Functional Grammar (LFG) resources acquired from treebanks. We extract LFG subcategorisation frames and paths linking LDD reentrancies from f-structures generated automatically for the Penn-II treebank trees and use them in an LDD resolution algorithm to parse new text. Unlike (Collins, 1999; Johnson, 2000), in our approach resolution of LDDs is done at f-structure (attribute-value structure representations of basic predicate-argument or dependency structure) without empty productions, traces and coindexation in CFG parse trees. Currently our best automatically induced grammars achieve 80.97% f-score for f-structures parsing section 23 of the WSJ part of the Penn-II treebank and evaluating against the DCU 1051 and 80.24% against the PARC 700 Dependency Bank (King et al., 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al., 2004)."
P04-1047,Large-Scale Induction and Evaluation of Lexical Resources from the {P}enn-{II} Treebank,2004,19,26,5,1,48509,ruth odonovan,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"In this paper we present a methodology for extracting subcategorisation frames based on an automatic LFG f-structure annotation algorithm for the Penn-II Treebank. We extract abstract syntactic function-based subcategorisation frames (LFG semantic forms), traditional CFG category-based subcategorisation frames as well as mixed function/category-based frames, with or without preposition information for obliques and particle information for particle verbs. Our approach does not predefine frames, associates probabilities with frames conditional on the lemma, distinguishes between active and passive frames, and fully reflects the effects of long-distance dependencies in the source data structures. We extract 3586 verb lemmas, 14348 semantic form types (an average of 4 per lemma) with 577 frame types. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource."
C04-1154,Robust Sub-Sentential Alignment of Phrase-Structure Trees,2004,14,40,3,1,6302,declan groves,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Data-Oriented Translation (DOT), based on Data-Oriented Parsing (DOP), is a language-independent MT engine which exploits parsed, aligned bitexts to produce very high quality translations. However, data acquisition constitutes a serious bottleneck as DOT requires parsed sentences aligned at both sentential and sub-structural levels. Manual sub-structural alignment is time-consuming, error-prone and requires considerable knowledge of both source and target languages and how they are related. Automating this process is essential in order to carry out the large-scale translation experiments necessary to assess the full potential of DOT.We present a novel algorithm which automatically induces sub-structural alignments between context-free phrase structure trees in a fast and consistent fashion requiring little or no knowledge of the language pair. We present results from a number of experiments which indicate that our method provides a serious alternative to manual alignment."
2004.tmi-1.11,Robust large-scale {EBMT} with marker-based segmentation,2004,16,49,2,1,52430,nano gough,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"Previous work on marker-based EBMT [Gough & Way, 2003, Way & Gough, 2004] suffered from problems such as data-sparseness and disparity between the training and test data. We have developed a large-scale robust EBMT system. In a comparison with the systems listed in [Somers, 2003], ours is the third largest EBMT system and certainly the largest English-French EBMT system. Previous work used the on-line MT system Logomedia to translate source language material as a means of populating the systemxe2x80x99s database where bitexts were unavailable. We derive our sententially aligned strings from a Sun Translation Memory (TM) and limit the integration of Logomedia to the derivation of our word-level lexicon. We also use Logomedia to provide a baseline comparison for our system and observe that wen outperform Logomedia and previous marker-based EBMT systems in a number of tests."
2004.eamt-1.9,Example-based controlled translation,2004,13,16,2,1,52430,nano gough,Proceedings of the 9th EAMT Workshop: Broadening horizons of machine translation and its applications,0,"The first research on integrating controlled language data in an Example-Based Machine Translation (EBMT) system was published in [Gough & Way, 2003]. We improve on their sub-sentential alignment algorithm to populate the systemxe2x80x99s databases with more than six times as many potentially useful fragments. Together with two simple novel improvementsxe2x80x94correcting mistranslations in the lexicon, and allowing multiple translations in the lexiconxe2x80x94translation quality improves considerably when target languagen translations are constrained. We also develop the first EBMT system which attempts to filter the source language data using controlled language specifications. We providen detailed automatic and human evaluations of a number of experiments carried out to test the quality of the system. We observe that our system outperforms Logomedia in a number of tests. Finally, despite conflicting results from different automatic evaluation metrics, we observe a preference for controlling the source data rather than the target translations."
J03-3004,w{EBMT}: Developing and Validating an Example-Based Machine Translation System using the World Wide Web,2003,33,38,1,1,2631,andy way,Computational Linguistics,0,"We have developed an example-based machine translation (EBMT) system that uses the World Wide Web for two different purposes: First, we populate the system's memory with translations gathered from rule-based MT systems located on the Web. The source strings input to these systems were extracted automatically from an extremely small subset of the rule types in the Penn-II Treebank. In subsequent stages, the xe2x8cxa9source, targetxe2x8cxaa translation pairs obtained are automatically transformed into a series of resources that render the translation process more successful. Despite the fact that the output from on-line MT systems is often faulty, we demonstrate in a number of experiments that when used to seed the memories of an EBMT system, they can in fact prove useful in generating translations of high quality in a robust fashion. In addition, we demonstrate the relative gain of EBMT in comparison to on-line systems. Second, despite the perception that the documents available on the Web are of questionable quality, we demonstrate in contrast that such resources are extremely useful in automatically postediting translation candidates proposed by our system."
2003.mtsummit-tttt.8,Teaching and assessing empirical approaches to machine translation,2003,0,0,1,1,2631,andy way,Workshop on Teaching Translation Technologies and Tools,0,"Empirical methods in Natural Language Processing (NLP) and Machine Translation (MT) have become mainstream in the research field. Accordingly, it is important that the tools and techniques in these paradigms be taught to potential future researchers and developers in University courses. While many dedicated courses on Statistical NLP can be found, there are few, if any courses on Empirical Approaches to MT. This paper presents the development and assessment of one such course as taught to final year undergraduates taking a degree in NLP."
2003.mtsummit-papers.18,Controlled generation in example-based machine translation,2003,9,8,2,1,52430,nano gough,Proceedings of Machine Translation Summit IX: Papers,0,"The theme of controlled translation is currently in vogue in the area of MT. Recent research (Scha Ìler et al., 2003; Carl, 2003) hypothesises that EBMT systems are perhaps best suited to this challenging task. In this paper, we present an EBMT system where the generation of the target string is filtered by data written according to controlled language specifications. As far as we are aware, this is the only research available on this topic. In the field of controlled language applications, it is more usual to constrain the source language in this way rather than the target. We translate a small corpus of controlled English into French using the on-line MT system Logomedia, and seed the memories of our EBMT system with a set of automatically induced lexical resources using the Marker Hypothesis as a segmentation tool. We test our system on a large set of sentences extracted from a Sun Translation Memory, and provide both an automatic and a human evaluation. For comparative purposes, we also provide results for Logomedia itself."
2003.mtsummit-papers.22,Seeing the wood for the trees: data-oriented translation,2003,11,39,2,1,48768,mary hearne,Proceedings of Machine Translation Summit IX: Papers,0,"Data-Oriented Translation (DOT), which is based on Data-Oriented Parsing (DOP), comprises an experience-based approach to translation, where new translations are derived with reference to grammatical analyses of previous translations. Previous DOT experiments [Poutsma, 1998, Poutsma, 2000a, Poutsma, 2000b] were small in scale because important advances in DOP technology were not incorporated into the translation model. Despite this, related work [Way, 1999, Way, 2003a, Way, 2003b] reports that DOT models are viable in that solutions to {`}hard{'} translation cases are readily available. However, it has not been shown to date that DOT models scale to larger datasets. In this work, we describe a novel DOT system, inspired by recent advances in DOP parsing technology. We test our system on larger, more complex corpora than have been used heretofore, and present both automatic and human evaluations which show that high quality translations can be achieved at reasonable speeds."
2002.eamt-1.6,Testing students{'} understanding of complex transfer,2002,0,0,1,1,2631,andy way,Proceedings of the 6th EAMT Workshop: Teaching Machine Translation,0,"Courses on Machine Translation (MT) need to be tailored to different sets of students with differing skills and demands (Kenny & Way, 2001) Nevertheless, any contemporary course on MT ought to equip students with at least a superficial knowledge of the differences between rule-based and statistical MT direct and indirect approaches and transfer- based and interlingual systems. With regard to this latter distinction, the issue of complex transfer is an integral component to this section of a course on MT, whether this be to computational linguists, translatorsn or language students. This paper presents a method of assessing the level of understanding of the issues pertaining to complex transfer for final year undergraduates studying a degree programme in Computational Linguistics. The intention is that this methodology may contribute to a suite of exercises which may be used by other instructors in Machine Translation."
carl-etal-2002-toward,Toward a hybrid integrated translation environment,2002,16,10,2,0,5265,michael carl,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"In this paper we present a model for the future use of Machine Translation (MT) and Computer Assisted Translation. In order to accommodate the future needs in middle value translations, we discuss a number of MT techniques and architectures. We anticipate a hybrid environment that integrates data- and rule-driven approaches where translations will be routed through the available translation options and consumers will receive accurate information on the quality, pricing and time implications of their translation choice."
gough-etal-2002-example,Example-based machine translation via the Web,2002,7,10,2,1,52430,nano gough,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"One of the limitations of translation memory systems is that the smallest translation units currently accessible are aligned sentential pairs. We propose an example-based machine translation system which uses a {`}phrasal lexicon{'} in addition to the aligned sentences in its database. These phrases are extracted from the Penn Treebank using the Marker Hypothesis as a constraint on segmentation. They are then translated by three on-line machine translation (MT) systems, and a number of linguistic resources are automatically constructed which are used in the translation of new input. We perform two experiments on testsets of sentences and noun phrases to demonstrate the effectiveness of our system. In so doing, we obtain insights into the strengths and weaknesses of the selected on-line MT systems. Finally, like many example-based machine translation systems, our approach also suffers from the problem of {`}boundary friction{'}. Where the quality of resulting translations is compromised as a result, we use a novel, post hoc validation procedure via the World Wide Web to correct imperfect translations prior to their being output to the user."
2001.mtsummit-teach.6,Teaching machine translation {\\&} translation technology: a contrastive study,2001,9,13,2,0,43904,dorothy kenny,Workshop on Teaching Machine Translation,0,"The Machine Translation course at Dublin City University is taught to undergraduate students in Applied Computational Linguistics, while Computer-Assisted Translation is taught on two translator-training programmes, one undergraduate and one postgraduate. Given the differing backgrounds of these sets of students, the course material, methods of teaching and assessment all differ. We report here on our experiences of teaching these courses over a number of years, which we hope will be of interest to lecturers of similar existing courses, as well as providing a reference point for others who may be considering the introduction of such material."
2001.mtsummit-ebmt.8,Translating with examples,2001,0,10,1,1,2631,andy way,Workshop on Example-Based machine Translation,0,"Machine Translation (MT) systems based on Data-Oriented Parsing (DOP: Bod, 1998) and LFG-DOPn (Bod & Kaplan, 1998) may be viewed as instances of Example-Based MT (EBMT). In both approaches,n new translations are processed with respect to previously seen translations residing in the system'sn database. We describe the DOT models of translation (Poutsma 1998; 2000) based on DOP. We demon-n strate that DOT1 is not guaranteed to produce the correct translation, despite provably deriving then most probable translation. The DOT2 translation model solves most of the problems of DOT1, butn suffers from limited compositionality when confronted with certain data. Notwithstanding the successn of DOT2, any system based purely on trees will ultimately be found wanting as a general solution ton the wide diversity of translation problems, as certain linguistic phenomena require a description at levelsn deeper than surface syntax. We then show how LFG-DOP can be extended to serve as a novel hybridn model for MT, LFG-DOT (Way, 2001), which promises to improve upon DOT and other EBMT systems."
W00-2040,"{LFG}-{DOT}: a probabilistic, constraint-based model for machine translation",2000,0,0,1,1,2631,andy way,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,None
W99-1024,{LFG}-{DOT}: Combining Constraint-Based and Empirical Methodologies for Robust {MT},2000,5,0,1,1,2631,andy way,Proceedings of the 12th Nordic Conference of Computational Linguistics ({NODALIDA} 1999),0,None
