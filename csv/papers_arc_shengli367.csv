2021.woah-1.1,Exploiting Auxiliary Data for Offensive Language Detection with Bidirectional Transformers,2021,-1,-1,2,0,0,sumer singh,Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021),0,"Offensive language detection (OLD) has received increasing attention due to its societal impact. Recent work shows that bidirectional transformer based methods obtain impressive performance on OLD. However, such methods usually rely on large-scale well-labeled OLD datasets for model training. To address the issue of data/label scarcity in OLD, in this paper, we propose a simple yet effective domain adaptation approach to train bidirectional transformers. Our approach introduces domain adaptation (DA) training procedures to ALBERT, such that it can effectively exploit auxiliary data from source domains to improve the OLD performance in a target domain. Experimental results on benchmark datasets show that our approach, ALBERT (DA), obtains the state-of-the-art performance in most cases. Particularly, our approach significantly benefits underrepresented and under-performing classes, with a significant improvement over ALBERT."
2021.naacl-main.221,Edge: Enriching Knowledge Graph Embeddings with External Text,2021,-1,-1,6,0,3915,saed rezayi,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Knowledge graphs suffer from sparsity which degrades the quality of representations generated by various methods. While there is an abundance of textual information throughout the web and many existing knowledge bases, aligning information across these diverse data sources remains a challenge in the literature. Previous work has partially addressed this issue by enriching knowledge graph entities based on {``}hard{''} co-occurrence of words present in the entities of the knowledge graphs and external text, while we achieve {``}soft{''} augmentation by proposing a knowledge graph enrichment and embedding framework named Edge. Given an original knowledge graph, we first generate a rich but noisy augmented graph using external texts in semantic and structural level. To distill the relevant knowledge and suppress the introduced noise, we design a graph alignment term in a shared embedding space between the original graph and augmented graph. To enhance the embedding learning on the augmented graph, we further regularize the locality relationship of target entity based on negative sampling. Experimental results on four benchmark datasets demonstrate the robustness and effectiveness of Edge in link prediction and node classification."
2020.ccl-1.102,{CAN}-{GRU}: a Hierarchical Model for Emotion Recognition in Dialogue,2020,-1,-1,4,0,22168,ting jiang,Proceedings of the 19th Chinese National Conference on Computational Linguistics,0,"Emotion recognition in dialogue systems has gained attention in the field of natural language processing recent years, because it can be applied in opinion mining from public conversational data on social media. In this paper, we propose a hierarchical model to recognize emotions in the dialogue. In the first layer, in order to extract textual features of utterances, we propose a convolutional self-attention network(CAN). Convolution is used to capture n-gram information and attention mechanism is used to obtain the relevant semantic information among words in the utterance. In the second layer, a GRU-based network helps to capture contextual information in the conversation. Furthermore, we discuss the effects of unidirectional and bidirectional networks. We conduct experiments on Friends dataset and EmotionPush dataset. The results show that our proposed model(CAN-GRU) and its variants achieve better performance than baselines."
W18-3105,A Simple End-to-End Question Answering Model for Product Information,2018,0,2,3,0,715,tuan lai,Proceedings of the First Workshop on Economics and Natural Language Processing,0,"When evaluating a potential product purchase, customers may have many questions in mind. They want to get adequate information to determine whether the product of interest is worth their money. In this paper we present a simple deep learning model for answering questions regarding product facts and specifications. Given a question and a product specification, the model outputs a score indicating their relevance. To train and evaluate our proposed model, we collected a dataset of 7,119 questions that are related to 153 different products. Experimental results demonstrate that {--}despite its simplicity{--} the performance of our model is shown to be comparable to a more complex state-of-the-art baseline."
P18-1252,Supervised Treebank Conversion: Data and Approaches,2018,0,8,5,0,29210,xinzhou jiang,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Treebank conversion is a straightforward and effective way to exploit various heterogeneous treebanks for boosting parsing performance. However, previous work mainly focuses on unsupervised treebank conversion and has made little progress due to the lack of manually labeled data where each sentence has two syntactic trees complying with two different guidelines at the same time, referred as bi-tree aligned data. In this work, we for the first time propose the task of supervised treebank conversion. First, we manually construct a bi-tree aligned dataset containing over ten thousand sentences. Then, we propose two simple yet effective conversion approaches (pattern embedding and treeLSTM) based on the state-of-the-art deep biaffine parser. Experimental results show that 1) the two conversion approaches achieve comparable conversion accuracy, and 2) treebank conversion is superior to the widely used multi-task learning framework in multi-treebank exploitation and leads to significantly higher parsing accuracy."
C18-1181,A Review on Deep Learning Techniques Applied to Answer Selection,2018,0,15,3,0,715,tuan lai,Proceedings of the 27th International Conference on Computational Linguistics,0,"Given a question and a set of candidate answers, answer selection is the task of identifying which of the candidates answers the question correctly. It is an important problem in natural language processing, with applications in many areas. Recently, many deep learning based methods have been proposed for the task. They produce impressive performance without relying on any feature engineering or expensive external resources. In this paper, we aim to provide a comprehensive review on deep learning methods applied to answer selection."
K16-2009,{S}o{NLP}-{DP} System for {C}on{LL}-2016 {E}nglish Shallow Discourse Parsing,2016,15,1,2,0.919974,6709,fang kong,Proceedings of the {C}o{NLL}-16 shared task,0,None
K16-2011,{S}o{NLP}-{DP} System for {C}on{LL}-2016 {C}hinese Shallow Discourse Parsing,2016,15,1,3,0,9182,junhui li,Proceedings of the {C}o{NLL}-16 shared task,0,None
K15-2004,The {S}o{NLP}-{DP} System in the {C}o{NLL}-2015 shared Task,2015,19,7,2,0.919974,6709,fang kong,Proceedings of the Nineteenth Conference on Computational Natural Language Learning - Shared Task,0,This paper describes the submitted discourse parsing system of the natural language group of Soochow University (SoNLP-DP) to the CoNLL 2015 shared task. Our System classifies discourse relations into explicit and non-explicit relations and uses a pipeline platform to conduct every subtask to form an end-toend shallow discourse parser in the Penn Discourse Treebank (PDTB). Our system is evaluated on the CoNLL-2015 Shared Task closed track and achieves the 18.51% in F1-measure on the official blind test set.
J15-4007,Lifetime Achievement Award: Translating Today into Tomorrow,2015,-1,-1,1,1,1,sheng li,Computational Linguistics,0,None
D15-1106,Hierarchical Recurrent Neural Network for Document Modeling,2015,24,89,6,0,37802,rui lin,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"This paper proposes a novel hierarchical recurrent neural network language model (HRNNLM) for document modeling. After establishing a RNN to capture the coherence between sentences in a document, HRNNLM integrates it as the sentence history information into the word level RNN to predict the word sequence with cross-sentence contextual information. A two-step training approach is designed, in which sentence-level and word-level language models are approximated for the convergence in a pipeline style. Examined by the standard sentence reordering scenario, HRNNLM is proved for its better accuracy in modeling the sentence coherence. And at the word level, experimental results also indicate a significant lower model perplexity, followed by a practical better translation result when applied to a Chinese-English document translation reranking task."
W14-6811,Detection on Inconsistency of Verb Phrase in {T}ree{B}ank,2014,8,0,4,0,32523,chaoqun duan,Proceedings of The Third {CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,"Annotating linguistic data is often a complex, time consuming and expensive endeavor. Even with strict annotation guidelines, human subjects often deviate in their analyses, each bring different biases, interpretations of the task and levels of consistency. The aim of this paper is to explore a way to find out the inconsistencies in the corpus TreeBank which is used for syntactic analysis through the procedure we study the inconsistencies of verb phrase tagging in the corpus TreeBank. At the same time, we can analyze the inconsistencies of verb phrase tagging which are found in the corpus TreeBank in order that we can find a way to improve the consistency of verb phrase tagging automatically which is effective to improve the quality of corpus."
I13-1068,A Hierarchical Semantics-Aware Distributional Similarity Scheme,2013,30,0,6,1,2937,shuqi sun,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"The context type and similarity calculation are two essential features of a distributional similarity scheme (DSS). In this paper, we propose a hierarchical semanticaware DSS that exploits semantic relation words as extra context information to guide the similarity calculation. First, we define and extract five types of semantic relations, and then develop relation-based similarities from the distributional similarities among the top-ranked relation words. Finally, we integrate various similarities using learning-to-rank technique. Experiments show that semantic relations are beneficial to predicting accurate similarity. On 6904 pairwise similarity comparisons, the predictive accuracy of our approach reaches 83.9%, which significantly outperforms the baseline approaches. We also conduct intrinsic analysis by varying the quality of semantic relations and the usage of individual similarities."
I13-1128,Repairing Incorrect Translation with Examples,2013,11,2,3,0,22051,junguo zhu,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"This paper proposes an example driven approach to improve the quality of MT system outputs. Specifically, We extend the system combination method in SMT to combine the examples by two strategies: 1) estimating the confidence of examples by the similarity between source input and the source part of examples; 2) approximating target word posterior probability by the word alignments of the bilingual examples. Experimental results show a significant improvement of 0.64 BLEU score as compared to one online translation service (Google Translate)."
D13-1085,Microblog Entity Linking by Leveraging Extra Posts,2013,20,14,4,1,12264,yuhang guo,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"Linking name mentions in microblog posts to a knowledge base, namely microblog entity linking, is useful for text mining tasks on microblog. Entity linking in long text has been well studied in previous works. However few work has focused on short text such as microblog post. Microblog posts are short and noisy. Previous method can extract few features from the post context. In this paper we propose to use extra posts for the microblog entity linking task. Experimental results show that our proposed method significantly improves the linking accuracy over traditional methods by 8.3% and 7.5% respectively."
P11-1104,Reordering with Source Language Collocations,2011,24,4,5,1,32600,zhanyi liu,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"This paper proposes a novel reordering model for statistical machine translation (SMT) by means of modeling the translation orders of the source language collocations. The model is learned from a word-aligned bilingual corpus where the collocated words in source sentences are automatically detected. During decoding, the model is employed to softly constrain the translation orders of the source language collocations, so as to constrain the translation orders of those source phrases containing these collocated words. The experimental results show that the proposed method significantly improves the translation quality, achieving the absolute improvements of 1.1~1.4 BLEU score over the baseline methods."
I11-1113,A Graph-based Method for Entity Linking,2011,22,30,4,1,12264,yuhang guo,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"In this paper, we formalize the task of finding a knowledge base entry that a given named entity mention refers to, namely entity linking, by identifying the most xe2x80x9cimportantxe2x80x9d node among the graph nodes representing the candidate entries. With the aim of ranking these entities by their xe2x80x9cimportancexe2x80x9d, we introduce three degree-based measures of graph connectivity. Experimental results on the TACKBP benchmark data sets show that our graph-based method performs comparably with the state-of-the-art methods. We also show that using the name phrase feature outperforms the commonly used bagof-word feature for entity linking."
I11-1114,Harvesting Related Entities with a Search Engine,2011,28,0,5,1,2937,shuqi sun,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper addresses the problem of related entity extraction and focuses on extracting related persons as a case study. The proposed method builds on a search engine. Specifically, we mine candidate related persons for a query person q using qxe2x80x99s search results and the query logs containing q. The acquired candidates are then automatically rated and ranked using a SVM regression model that investigates multiple features. Experimental results on a set of 200 randomly sampled query persons show that the precision of the extracted top-1, 5, and 10 related persons exceeds 91%, 90%, and 84%, respectively, which significantly outperforms a state-ofthe-art baseline."
2011.mtsummit-papers.65,Hypergraph Training and Decoding of System Combination in {SMT},2011,-1,-1,3,0,44910,yupeng liu,Proceedings of Machine Translation Summit XIII: Papers,0,None
W10-4113,Selecting Optimal Feature Template Subset for {CRF}s,2010,0,0,5,0,45148,xingjun xu,{CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,None
W10-4151,Complete Syntactic Analysis Bases on Multi-level Chunking,2010,0,1,5,0,45186,zhipeng jiang,{CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,None
S10-1091,{HIT}-{CIR}: An Unsupervised {WSD} System Based on Domain Most Frequent Sense Estimation,2010,11,1,5,1,12264,yuhang guo,Proceedings of the 5th International Workshop on Semantic Evaluation,0,This paper presents an unsupervised system for all-word domain specific word sense disambiguation task. This system tags target word with the most frequent sense which is estimated using a thesaurus and the word distribution information in the domain. The thesaurus is automatically constructed from bilingual parallel corpus using paraphrase technique. The recall of this system is 43.5% on SemEval-2 task 17 English data set.
P10-1085,Improving Statistical Machine Translation with Monolingual Collocation,2010,22,15,4,1,32600,zhanyi liu,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"This paper proposes to use monolingual collocations to improve Statistical Machine Translation (SMT). We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT. The experimental results show that our method improves the performance of both word alignment and translation quality significantly. As compared to baseline systems, we achieve absolute improvements of 2.40 BLEU score on a phrase-based SMT system and 1.76 BLEU score on a parsing-based SMT system."
C10-2080,Reexamination on Potential for Personalization in Web Search,2010,24,0,4,0,46469,daren li,Coling 2010: Posters,0,"Various strategies have been proposed to enhance web search through utilizing individual user information. However, considering the well acknowledged recurring queries and repetitive clicks among users, it is still an open issue whether using individual user information is a proper direction of efforts in improving the web search. In this paper, we first quantitatively demonstrate that individual user information is more beneficial than common user information. Then we statistically compare the benefit of individual and common user information through Kappa statistic. Finally, we calculate potential for personalization to present an overview of what queries can benefit more from individual user information. All these analyses are conducted on both English AOL log and Chinese Sogou log, and a bilingual perspective statistics consistently confirms our findings."
C10-2086,Head-modifier Relation based Non-lexical Reordering Model for Phrase-Based Translation,2010,30,2,2,0,45617,shui liu,Coling 2010: Posters,0,"Phrase-based statistical MT (SMT) is a milestone in MT. However, the translation model in the phrase based SMT is structure free which greatly limits its reordering capacity. To address this issue, we propose a non-lexical head-modifier based reordering model on word level by utilizing constituent based parse tree in source side. Our experimental results on the NIST Chinese-English benchmarking data show that, with a very small size model, our method significantly outperforms the baseline by 1.48% bleu score."
C10-2134,Bridging Topic Modeling and Personalized Search,2010,29,13,4,0,13184,wei song,Coling 2010: Posters,0,This work presents a study to bridge topic modeling and personalized search. A probabilistic topic model is used to extract topics from user search history. These topics can be seen as a roughly summary of user preferences and further treated as feedback within the KL-Divergence retrieval model to estimate a more accurate query model. The topics more relevant to current query contribute more in updating the query model which helps to distinguish between relevant and irrelevant parts and filter out noise in user search history. We designed task oriented user study and the results show that: (1) The extracted topics can be used to cluster queries according to topics. (2) The proposed approach improves ranking quality consistently for queries matching user past interests and is robust for queries not matching past interests.
C10-2138,"Utilizing Variability of Time and Term Content, within and across Users in Session Detection",2010,15,0,2,1,2937,shuqi sun,Coling 2010: Posters,0,"In this paper, we describe a SVM classification framework of session detection task on both Chinese and English query logs. With eight features on the aspects of temporal and content information extracted from pairs of successive queries, the classification models achieve significantly superior performance than the stat-of-the-art method. Additionally, we find through ROC analysis that there exists great discrimination power variability among different features and within the same feature across different users. To fully utilize this variability, we build local models for individual users and combine their predictions with those from the global model. Experiments show that the local models do make significant improvements to the global model, although the amount is small."
C10-2175,All in Strings: a Powerful String-based Automatic {MT} Evaluation Metric with Multiple Granularities,2010,26,9,4,0,22051,junguo zhu,Coling 2010: Posters,0,"String-based metrics of automatic machine translation (MT) evaluation are widely applied in MT research. Meanwhile, some linguistic motivated metrics have been suggested to improve the string-based metrics in sentence-level evaluation. In this work, we attempt to change their original calculation units (granularities) of string-based metrics to generate new features. We then propose a powerful string-based automatic MT evaluation metric, combining all the features with various granularities based on SVM rank and regression models. The experimental results show that i) the new features with various granularities can contribute to the automatic evaluation of translation quality; ii) our proposed string-based metrics with multiple granularities based on SVM regression model can achieve higher correlations with human assessments than the state-of-art automatic metrics."
W09-2305,References Extension for the Automatic Evaluation of {MT} by Syntactic Hybridization,2009,11,0,4,0.784314,7051,bo wang,Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation ({SSST}-3) at {NAACL} {HLT} 2009,0,"Because of the variations of the languages, the coverage of the references is very important to the reference based automatic evaluation of machine translation systems. We propose a method to extend the reference set of the automatic evaluation only based on multiple manual references and their syntactic structures. In our approach, the syntactic equivalents in the reference sentences are identified and hybridized to generate new references. The new method need no external knowledge and can obtain the equivalents of long subsegments of reference sentences. The experimental results show that using the extended reference set the popular automatic evaluation metrics achieve better correlations with the human assessments."
W09-2306,A Study of Translation Rule Classification for Syntax-based Statistical Machine Translation,2009,24,0,2,1,44874,hongfei jiang,Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation ({SSST}-3) at {NAACL} {HLT} 2009,0,"Recently, numerous statistical machine translation models which can utilize various kinds of translation rules are proposed. In these models, not only the conventional syntactic rules but also the non-syntactic rules can be applied. Even the pure phrase rules are includes in some of these models. Although the better performances are reported over the conventional phrase model and syntax model, the mixture of diversified rules still leaves much room for study. In this paper, we present a refined rule classification system. Based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization. Especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules. This novel classification system may supports the SMT research community with some helpful references."
P09-2032,A Statistical Machine Translation Model Based on a Synthetic Synchronous Grammar,2009,9,2,4,1,44874,hongfei jiang,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"Recently, various synchronous grammars are proposed for syntax-based machine translation, e.g. synchronous context-free grammar and synchronous tree (sequence) substitution grammar, either purely formal or linguistically motivated. Aiming at combining the strengths of different grammars, we describes a synthetic synchronous grammar (SSG), which tentatively in this paper, integrates a synchronous context-free grammar (SCFG) and a synchronous tree sequence substitution grammar (STSSG) for statistical machine translation. The experimental results on NIST MT05 Chinese-to-English test set show that the SSG based translation system achieves significant improvement over three baseline systems."
P09-1094,Application-driven Statistical Paraphrase Generation,2009,26,87,4,1,28404,shiqi zhao,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Paraphrase generation (PG) is important in plenty of NLP applications. However, the research of PG is far from enough. In this paper, we propose a novel method for statistical paraphrase generation (SPG), which can (1) achieve various applications based on a uniform statistical model, and (2) naturally combine multiple resources to enhance the PG performance. In our experiments, we use the proposed method to generate paraphrases for three different applications. The results show that the method can be easily transformed from one application to another and generate valuable and interesting paraphrases."
D09-1051,Collocation Extraction Using Monolingual Word Alignment Method,2009,10,25,4,1,32600,zhanyi liu,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"Statistical bilingual word alignment has been well studied in the context of machine translation. This paper adapts the bilingual word alignment algorithm to monolingual scenario to extract collocations from monolingual corpus. The monolingual corpus is first replicated to generate a parallel corpus, where each sentence pair consists of two identical sentences in the same language. Then the monolingual word alignment algorithm is employed to align the potentially collocated words in the monolingual sentences. Finally the aligned word pairs are ranked according to refined alignment probabilities and those with higher scores are extracted as collocations. We conducted experiments using Chinese and English corpora individually. Compared with previous approaches, which use association measures to extract collocations from the co-occurring word pairs within a given window, our method achieves higher precision and recall. According to human evaluation in terms of precision, our method achieves absolute improvements of 27.9% on the Chinese corpus and 23.6% on the English corpus, respectively. Especially, we can extract collocations with longer spans, achieving a high precision of 69% on the long-span (>6) Chinese collocations."
W08-2134,A Cascaded Syntactic and Semantic Dependency Parsing System,2008,5,29,7,1,1017,wanxiang che,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"We describe our CoNLL 2008 Shared Task system in this paper. The system includes two cascaded components: a syntactic and a semantic dependency parsers. A first-order projective MSTParser is used as our syntactic dependency parser. In order to overcome the shortcoming of the MSTParser, that it cannot model more global information, we add a relabeling stage after the parsing to distinguish some confusable labels, such as ADV, TMP, and LOC. Besides adding a predicate identification and a classification stages, our semantic dependency parsing simplifies the traditional four stages semantic role labeling into two: a maximum entropy based argument classification and an ILP-based post inference. Finally, we gain the overall labeled macro F1 = 82.66, which ranked the second position in the closed challenge."
P08-1064,A Tree Sequence Alignment-based Tree-to-Tree Translation Model,2008,34,104,6,0.485213,3694,min zhang,Proceedings of ACL-08: HLT,1,"This paper presents a translation model that is based on tree sequence alignment, where a tree sequence refers to a single sequence of subtrees that covers a phrase. The model leverages on the strengths of both phrase-based and linguistically syntax-based method. It automatically learns aligned tree sequence pairs with mapping probabilities from word-aligned biparsed parallel texts. Compared with previous models, it not only captures non-syntactic phrases and discontinuous phrases with linguistically structured features, but also supports multi-level structure reordering of tree typology with larger span. This gives our model stronger expressive power than other reported models. Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems."
P08-1089,Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora,2008,21,65,4,1,28404,shiqi zhao,Proceedings of ACL-08: HLT,1,"Paraphrase patterns are useful in paraphrase recognition and generation. In this paper, we present a pivot approach for extracting paraphrase patterns from bilingual parallel corpora, whereby the English paraphrase patterns are extracted using the sentences in a foreign language as pivots. We propose a loglinear model to compute the paraphrase likelihood of two patterns and exploit feature functions based on maximum likelihood estimation (MLE) and lexical weighting (LW). Using the presented method, we extract over 1,000,000 pairs of paraphrase patterns from 2M bilingual sentence pairs, the precision of which exceeds 67%. The evaluation results show that: (1) The pivot approach is effective in extracting paraphrase patterns, which significantly outperforms the conventional method DIRT. Especially, the log-linear model with the proposed feature functions achieves high performance. (2) The coverage of the extracted paraphrase patterns is high, which is above 84%. (3) The extracted paraphrase patterns can be classified into 5 types, which are useful in various applications."
P08-1096,An Entity-Mention Model for Coreference Resolution with Inductive Logic Programming,2008,18,62,6,0,47859,xiaofeng yang,Proceedings of ACL-08: HLT,1,"The traditional mention-pair model for coreference resolution cannot capture information beyond mention pairs for both learning and testing. To deal with this problem, we present an expressive entity-mention model that performs coreference resolution at an entity level. The model adopts the Inductive Logic Programming (ILP) algorithm, which provides a relational way to organize different knowledge of entities and mentions. The solution can explicitly express relations between an entity and the contained mentions, and automatically learn first-order rules important for coreference decision. The evaluation on the ACE data set shows that the ILP based entity-mention model is effective for the coreference resolution task."
P08-1116,Combining Multiple Resources to Improve {SMT}-based Paraphrasing Model,2008,25,49,5,1,28404,shiqi zhao,Proceedings of ACL-08: HLT,1,"This paper proposes a novel method that exploits multiple resources to improve statistical machine translation (SMT) based paraphrasing. In detail, a phrasal paraphrase table and a feature function are derived from each resource, which are then combined in a log-linear SMT model for sentence-level paraphrase generation. Experimental results show that the SMT-based paraphrasing model can be enhanced using multiple resources. The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively. In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality."
I08-2109,Fast Computing Grammar-driven Convolution Tree Kernel for Semantic Role Labeling,2008,11,0,6,1,1017,wanxiang che,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"Grammar-driven convolution tree kernel (GTK) has shown promising results for semantic role labeling (SRL). However, the time complexity of computing the GTK is exponential in theory. In order to speed up the computing process, we design two fast grammar-driven convolution tree kernel (FGTK) algorithms, which can compute the GTK in polynomial time. Experimental results on the CoNLL-2005 SRL data show that our two FGTK algorithms are much faster than the GTK."
C08-1138,Grammar Comparison Study for Translational Equivalence Modeling and Statistical Machine Translation,2008,31,19,5,0.485213,3694,min zhang,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"This paper presents a general platform, namely synchronous tree sequence substitution grammar (STSSG), for the grammar comparison study in Translational Equivalence Modeling (TEM) and Statistical Machine Translation (SMT). Under the STSSG platform, we compare the expressive abilities of various grammars through synchronous parsing and a real translation platform on a variety of Chinese-English bilingual corpora. Experimental results show that the STSSG is able to better explain the data in parallel corpora than other grammars. Our study further finds that the complexity of structure divergence is much higher than suggested in literature, which imposes a big challenge to syntactic transformation-based SMT."
W07-2418,The Extraction of Trajectories from Real Texts Based on Linear Classification,2007,5,7,3,0,45610,hanjing li,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,"Text-to-scene conversion systems need to share the spatial descriptions between natural language and the 3D scene. Such applications are the ideal candidates for the extraction of spatial relations from free texts, in which the extraction to trajectories that are focus objects in spatial descriptions is an essential problem. We present an analysis of how the space relations are described in Chinese. Based on this study, we propose a method where the extraction of trajectories is modeled as a binary classification problem and resolved based on a linear classifier with syntactic features. Moreover, experimental results are analyzed in detail to demonstrate the effectiveness of the linear classifier to the extraction problem of the trajectory concept."
S07-1036,{HIT}: Web based Scoring Method for {E}nglish Lexical Substitution,2007,12,13,5,1,28404,shiqi zhao,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes the HIT system and its participation in SemEval-2007 English Lexical Substitution Task. Two main steps are included in our method: candidate substitute extraction and candidate scoring. In the first step, candidate substitutes for each target word in a given sentence are extracted from WordNet. In the second step, the extracted candidates are scored and ranked using a web-based scoring method. The substitute ranked first is selected as the best substitute. For the multiword subtask, a simple WordNet-based approach is employed."
P07-1026,A Grammar-driven Convolution Tree Kernel for Semantic Role Classification,2007,27,25,7,0.491638,3694,min zhang,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Convolution tree kernel has shown promising results in semantic role classification. However, it only carries out hard matching, which may lead to over-fitting and less accurate similarity measure. To remove the constraint, this paper proposes a grammardriven convolution tree kernel for semantic role classification by introducing more linguistic knowledge into the standard tree kernel. The proposed grammar-driven tree kernel displays two advantages over the previous one: 1) grammar-driven approximate substructure matching and 2) grammardriven approximate tree node matching. The two improvements enable the grammardriven tree kernel explore more linguistically motivated structure features than the previous one. Experiments on the CoNLL-2005 SRL shared task show that the grammardriven tree kernel significantly outperforms the previous non-grammar-driven one in SRL. Moreover, we present a composite kernel to integrate feature-based and tree kernel-based methods. Experimental results show that the composite kernel outperforms the previously best-reported methods."
2007.mtsummit-papers.71,A tree-to-tree alignment-based model for statistical machine translation,2007,-1,-1,5,0.491638,3694,min zhang,Proceedings of Machine Translation Summit XI: Papers,0,None
W06-2931,Dependency Parsing Based on Dynamic Local Optimization,2006,14,11,4,0.8,1018,ting liu,Proceedings of the Tenth Conference on Computational Natural Language Learning ({C}o{NLL}-X),0,This paper presents a deterministic parsing algorithm for projective dependency grammar. In a bottom-up way the algorithm finds the local optimum dynamically. A constraint procedure is made to use more structure information. The algorithm parses sentences in linear time and labeling is integrated with the parsing. This parser achieves 63.29% labeled attachment score on the average in CoNLL-X Shared Task.
P06-2010,A Hybrid Convolution Tree Kernel for Semantic Role Labeling,2006,30,18,4,1,1017,wanxiang che,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"A hybrid convolution tree kernel is proposed in this paper to effectively model syntactic structures for semantic role labeling (SRL). The hybrid kernel consists of two individual convolution kernels: a Path kernel, which captures predicate-argument link features, and a Constituent Structure kernel, which captures the syntactic structure features of arguments. Evaluation on the datasets of CoNLL-2005 SRL shared task shows that the novel hybrid convolution tree kernel out-performs the previous tree kernels. We also combine our new hybrid tree kernel based method with the standard rich flat feature based method. The experimental results show that the combinational method can get better performance than each of them individually."
P06-1058,An Equivalent Pseudoword Solution to {C}hinese Word Sense Disambiguation,2006,21,13,5,0,49978,zhimao lu,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents a new approach based on Equivalent Pseudowords (EPs) to tackle Word Sense Disambiguation (WSD) in Chinese language. EPs are particular artificial ambiguous words, which can be used to realize unsupervised WSD. A Bayesian classifier is implemented to test the efficacy of the EP solution on Senseval-3 Chinese test set. The performance is better than state-of-the-art results with an average F-measure of 0.80. The experiment verifies the value of EP for unsupervised WSD."
W05-0627,Semantic Role Labeling System Using Maximum Entropy Classifier,2005,0,23,3,1,1018,ting liu,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,None
I05-5007,Automated Generalization of Phrasal Paraphrases from the Web,2005,15,11,4,0,50988,weigang li,Proceedings of the Third International Workshop on Paraphrasing ({IWP}2005),0,"Rather than creating and storing thousands of paraphrase examples, paraphrase templates have strong representation capacity and can be used to generate many paraphrase examples. This paper describes a new template representation and generalization method. Combing a semantic dictionary, it uses multiple semantic codes to represent a paraphrase template. Using an existing search engine to extend the word clusters and generalize the examples. We also design three metrics to measure our generalized templates. The experimental results show that the representation method is reasonable and the generalized templates have a higher precision and coverage."
I05-2003,A Hybrid {C}hinese Language Model based on a Combination of Ontology with Statistical Method,2005,15,1,3,1,36315,dequan zheng,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"In this paper, we present a hybrid Chinese language model based on a combination of ontology with statistical method. In this study, we determined the structure of such a Chinese language model. This structure is firstly comprised of an ontology description framework for Chinese words and a representation of Chinese lingual ontology knowledge. Subsequently, a Chinese lingual ontology knowledge bank is automatically acquired by determining, for each word, its cooccurrence with semantic, pragmatics, and syntactic information from the training corpus and the usage of Chinese words will be gotten from lingual ontology knowledge bank for a actual document. To evaluate the performance of this language model, we completed two groups of experiments on texts reordering for Chinese information retrieval and texts similarity computing. Compared with previous works, the proposed method improved the precision of nature language processing."
W04-1108,Combining Neural Networks and Statistics for {C}hinese Word Sense Disambiguation,2004,0,6,3,0,49978,zhimao lu,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,None
W04-1120,A New {C}hinese Natural Language Understanding Architecture Based on Multilayer Search Mechanism,2004,4,1,3,1,1017,wanxiang che,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,None
W04-1121,Aligning Bilingual Corpora Using Sentences Location Information,2004,9,5,4,0,50988,weigang li,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,"Large amounts of bilingual resource on the Internet provide us with the probability of building a large scale of bilingual corpus. The irregular characteristics of the real texts, especially without the strictly aligned paragraph boundaries, bring a challenge to alignment technology. The traditional alignment methods have some difficulties in competency for doing this. This paper describes a new method for aligning real bilingual texts using sentence pair location information. The model was motivated by the observation that the location of a sentence pair with certain length is distributed in the whole text similarly. It uses (1:1) sentence beads instead of high frequency words as the candidate anchors. The method was developed and evaluated through many different test data. The results show that it can achieve good aligned performance and be robust and language independent. It can resolve the alignment problem on real bilingual text."
C02-1003,Learning {C}hinese Bracketing Knowledge Based on a Bilingual Language Model,2002,7,12,2,0,37737,yajuan lu,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper proposes a new method for automatic acquisition of Chinese bracketing knowledge from English-Chinese sentence-aligned bilingual corpora. Bilingual sentence pairs are first aligned in syntactic structure by combining English parse trees with a statistical bilingual language model. Chinese bracketing knowledge is then extracted automatically. The preliminary experiments show automatically learned knowledge accords well with manually annotated brackets. The proposed method is particularly useful to acquire bracketing knowledge for a less studied language that lacks tools and resources found in a second language more studied. Although this paper discusses experiments with Chinese and English, the method is also applicable to other language pairs."
C02-1057,An Automatic Evaluation Method for Localization Oriented Lexicalised {EBMT} System,2002,11,4,5,0.512821,12358,jianmin yao,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"To help developing a localization oriented EBMT system, an automatic machine translation evaluation method is implemented which adopts edit distance, cosine correlation and Dice coefficient as criteria. Experiment shows that the evaluation method distinguishes well between good translations and bad ones. To prove that the method is consistent with human evaluation, 6 MT systems are scored and compared. Theoretical analysis is made to validate the experimental results. Correlation coefficient and significance tests at 0.01 level are made to ensure the reliability of the results. Linear regression equations are calculated to map the automatic scoring results to human scorings."
O01-2004,Automatic Translation Template Acquisition Based on Bilingual Structure Alignment,2001,16,11,3,0,37737,yajuan lu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 6, Number 1, {F}ebruary 2001: Special Issue on Natural Language Processing Researches in {MSRA}",0,Knowledge acquisition is a bottleneck in machine translation and many NLP tasks. A method for automatically acquiring translation templates from bilingual corpora is proposed in this paper. Bilingual sentence pairs are first aligned in syntactic structure by combining a language parsing with a statistical bilingual language model. The alignment results are used to extract translation templates which turn out to be very useful in real machine translation.
