2007.iwslt-1.4,W06-3711,0,0.0292572,"able speech translation system which allows an English speaker to converse with a target language speaker. Our systems have been evaluated on a regular basis as part of the DARPA TransTac program. These evaluations are run by NIST, and involve military users and target language users who have never used our system before. The evaluations consist of communicating through the translation device for a number of pre-designed scenarios (which were previously unknown to us). The tests take place both indoors and outdoors. Other systems in the TransTac program include those developed by BBN [5], IBM [6], SRI, Sehda/Fluential, and USC [7] [8]. 2. Challenges The two target languages in the TransTac program are Iraqi Arabic and Farsi. Iraqi Arabic is defined as the spoken form of Arabic used by the people of Iraq in everyday conversations. It is distinct from the formal Modern Standard Arabic (MSA) used in written communication. As Iraqi Arabic is normally not written, even with transcription conventions there is greater variability in the spelling conventions than in a standard written language. Farsi (Persian), mainly spoken in Iran and areas of Afghanistan, also uses the Arabic script, thoug"
2007.iwslt-1.4,2005.mtsummit-papers.33,1,0.758733,"ple raftin vs. raftid ""you went"". The word forms (inside of the word) may be modified to represent their colloquial pronunciation for instance khune vs. khAne 'house', midam vs. midaham 'i give'). 5.4. Language models The language model is a standard 6-gram language model with Good-Turing smoothing implemented as a suffix array (SA LM) [10]. Another option of language model is the 4-gram modified Kneser-Ney smoothing trained using the SRI language modeling toolkit (SRI LM) [11]. 5.5. Translation models 5.5.1. PESA phrase extraction In Iraqi-English we applied the PESA phrase extraction method [9]. For a given source phrase PESA tries to find the optimal sentence splits of the training sentences containing this source phrase based on inner and outer IBM1 word alignment probabilities. We applied PESA as an online phrase extraction which means that phrase pairs are dynamically extracted from the training data as needed during the translation of the test set. We compared the performance here with a standard Pharaoh phrase table but we saw considerable improvements using the PESA approach. For Iraqi-English a considerable amount of training data is available and parts of the test dialogs a"
2007.iwslt-1.4,2005.eamt-1.39,1,0.834249,"lization steps need to be agreed upon. However, it is not easy to reach a consensus since Iraqi Arabic lacks a standard writing system. Furthermore, there are issues with speaking style. Words can be used with their formal or informal/colloquial endings for example raftin vs. raftid ""you went"". The word forms (inside of the word) may be modified to represent their colloquial pronunciation for instance khune vs. khAne 'house', midam vs. midaham 'i give'). 5.4. Language models The language model is a standard 6-gram language model with Good-Turing smoothing implemented as a suffix array (SA LM) [10]. Another option of language model is the 4-gram modified Kneser-Ney smoothing trained using the SRI language modeling toolkit (SRI LM) [11]. 5.5. Translation models 5.5.1. PESA phrase extraction In Iraqi-English we applied the PESA phrase extraction method [9]. For a given source phrase PESA tries to find the optimal sentence splits of the training sentences containing this source phrase based on inner and outer IBM1 word alignment probabilities. We applied PESA as an online phrase extraction which means that phrase pairs are dynamically extracted from the training data as needed during the t"
2007.iwslt-1.4,2005.eamt-1.36,1,0.72462,"ar in the training corpus, because they occur in the phrase table only embedded in longer phrases. This leads to an unnecessary high number of untranslated words. On the other side, the PESA phrase alignment will generate translations for all n-grams including all individual words, which can be found in the training corpus. To guarantee that the phrase table can cover all source vocabulary and to leverage the PESA’s strength in arbitrary long matching, we trained two phrase tables and interpolated them. The interpolation parameters are optimized through a minimum-error-rate training framework [12]. 5.5.4. Speed constraint To limit delays, the translation has to be performed during the replay of the ASR output. This has to be the case for even very long sentences. For all practical considerations we assume to have about 200 ms on average to do the translation. Some of speeding strategies we applied is phrase table pruning and restrict the search space during the decoding process. Those techniques help to decrease the system running time significantly. 5.5.5. Decoder For this evaluation the system is running on a standard laptop with 2 GB of memory so we could use our regular decoder [2]"
2007.iwslt-1.4,2007.mtsummit-papers.72,1,0.769394,"ery long sentences. For all practical considerations we assume to have about 200 ms on average to do the translation. Some of speeding strategies we applied is phrase table pruning and restrict the search space during the decoding process. Those techniques help to decrease the system running time significantly. 5.5.5. Decoder For this evaluation the system is running on a standard laptop with 2 GB of memory so we could use our regular decoder [2]. The previous system described in [1] was running on a PDA. Due to lack of memory and computing power an earlier version of the decoder described in [18] had to be used that did not support word reordering and required heavily pruned models. 5.5.6. Translation results We report the performance of translation component in terms of BLEU score [20]. On the test sets the system achieved a score of 42.12 for English to Iraqi and 63.49 for Iraqi to English. The Farsi systems use similar technologies as the Iraqi systems. Table 8 shows the translation performance of the provided training data on various setups. Table 8: Farsi translation performance (in BLEU) Farsi→English Dev. Pharaoh + 4-gram SRI LM 24.64 PESA + 6-gram SA LM 23.06 English→Farsi Pha"
2007.iwslt-1.4,koen-2004-pharaoh,0,0.0298013,"online phrase extraction does not have to extract the phrases pairs dynamically. Instead, the online phrase extraction is only used for long or rarely seen phrases. This did not give any significant change in performance but resulted in a considerable speedup. The system uses the same corpora to extract online PESA phrases for both translation directions so we combined the Iraqi-English and English-Iraqi corpora for this. However, the pre-extracted phrases were extracted separately for each direction from the respective corpus. 5.5.3. Interpolate Pharaoh and PESA We observed that the Pharaoh [19] phrase table does not contain entries for all words in the source vocabulary. This comes from the heuristics applied to avoid unlikely translations. Therefore, some words will not be translated, even though they appear in the training corpus, because they occur in the phrase table only embedded in longer phrases. This leads to an unnecessary high number of untranslated words. On the other side, the PESA phrase alignment will generate translations for all n-grams including all individual words, which can be found in the training corpus. To guarantee that the phrase table can cover all source v"
2007.iwslt-1.4,P02-1040,0,0.073748,"the search space during the decoding process. Those techniques help to decrease the system running time significantly. 5.5.5. Decoder For this evaluation the system is running on a standard laptop with 2 GB of memory so we could use our regular decoder [2]. The previous system described in [1] was running on a PDA. Due to lack of memory and computing power an earlier version of the decoder described in [18] had to be used that did not support word reordering and required heavily pruned models. 5.5.6. Translation results We report the performance of translation component in terms of BLEU score [20]. On the test sets the system achieved a score of 42.12 for English to Iraqi and 63.49 for Iraqi to English. The Farsi systems use similar technologies as the Iraqi systems. Table 8 shows the translation performance of the provided training data on various setups. Table 8: Farsi translation performance (in BLEU) Farsi→English Dev. Pharaoh + 4-gram SRI LM 24.64 PESA + 6-gram SA LM 23.06 English→Farsi Pharaoh + SRI LM 10.07 PESA + SA LM 9.45 Pharaoh + SA LM 10.41 Pharaoh + PESA + SA LM 10.23 Unseen 23.3 19.9 14.87 14.67 15.42 16.44 6. Text-to-Speech Text-to-speech was provided by Cepstral, LLC's"
2007.iwslt-1.4,2005.iwslt-1.16,0,\N,Missing
2007.iwslt-1.4,2005.iwslt-1.6,1,\N,Missing
2011.iwslt-papers.3,E03-1035,0,0.30853,"Missing"
2011.iwslt-papers.3,J03-3002,0,0.159638,"Missing"
2011.iwslt-papers.3,N04-1036,0,0.0818659,"Missing"
2011.iwslt-papers.3,2010.iwslt-papers.14,1,0.832985,"Missing"
2011.iwslt-papers.3,P07-2045,0,0.0045147,"Missing"
2011.iwslt-papers.3,P06-1010,0,0.081669,"Missing"
2011.iwslt-papers.3,O08-2010,0,\N,Missing
2016.gwc-1.60,D08-1031,0,0.0144057,"ritten or document-oriented context (for example, a word sense for airwave is included in the file). The present work also identifies several DE senses outside of this lexicographer file. Overall, the meta-communicative focus of the present work is novel compared to prior efforts. The task of automatically identifying instances of DE reference bears some similarity to coreference resolution. However, coreference resolvers are not suited for the present task; those tried by the researchers include CoreNLP (Recasens, de Marneffe, & Potts, 2013), ArkRef (O’Connor & Heilman, 2013) and the work of Bengtson and Roth (2008). One problem is that many DEs are partly pictorial or are not recognized by NLP tools as cohesive entities. Many DEs are distinguished by their non-linguistic aspects (i.e., diagrams) or stylistic markup (bulleted lists, quotations delimited by quote marks). The task at hand also has commonalities with entity linking (Hachey et al., 2013) and Wikification, the process of linking named entities in text with corresponding Wikipedia pages (Cheng & Roth, 2013). However, DEs differ markedly from named entities. DEs vary widely in their representation and they often reside in the same communication"
2016.gwc-1.60,J96-2004,0,0.0373269,"emaining. Figure 3 shows some example labels. One annotator produced labels for all 523 new synsets, and two annotators respectively labeled new synsets in the high rank and broad rank samples. Thus, each new synset was labeled twice. Annotators worked independently and met to resolve differences. To promote domain-independent results, annotators were unaware which corpus (or corpora) triggered the inclusion of each synset. Kappa values between the annotators who labeled the high rank set and the broad rank set were 0.60 and 0.72, respectively. Although kappa is an imperfect agreement metric (Carletta, 1996), these values are generally regarded as moderate to substantial (Viera & Garrett, 2005). The contrast in kappa values mostly arose from differing interpretations of the DE status of psychological entities. All annotators agreed that it was challenging to determine the degree of their presence in a document and thus their DE status. Table 4 summarizes the results of labeling, with positive and negative representing “y” and “n” marks respectively. The numbers do not sum to 723 (the total number of unique synsets labeled) due to redundancies among the sets of synsets. Since the broad rank sets d"
2016.gwc-1.60,Y09-1009,0,0.0722447,"Missing"
2016.gwc-1.60,D13-1184,0,0.0165442,"se tried by the researchers include CoreNLP (Recasens, de Marneffe, & Potts, 2013), ArkRef (O’Connor & Heilman, 2013) and the work of Bengtson and Roth (2008). One problem is that many DEs are partly pictorial or are not recognized by NLP tools as cohesive entities. Many DEs are distinguished by their non-linguistic aspects (i.e., diagrams) or stylistic markup (bulleted lists, quotations delimited by quote marks). The task at hand also has commonalities with entity linking (Hachey et al., 2013) and Wikification, the process of linking named entities in text with corresponding Wikipedia pages (Cheng & Roth, 2013). However, DEs differ markedly from named entities. DEs vary widely in their representation and they often reside in the same communication medium as references to them. References to DEs often incorporate pragmatic information: for example, the referent of ""this figure"" may be the closest figure or the one most recently referred to. The potentially non-textual nature of DEs also separates them from mentioned language (Wilson, 2012), although the phenomena share a metalinguistic quality. Shell nouns are nouns used anaphorically to refer to complex concepts such as points, assumptions, acts, or"
2016.gwc-1.60,W03-1022,0,0.0113173,"the present work. Mayer (2009) presented the cognitive theory of multimedia learning and explored how pictorial DEs augment and enhance textual artifacts. Similarly, Ayres and Sweller (2005) argued that learning materials should be presented so that “disparate sources of information are physically and temporally integrated”. Power, et al. (2003) argued for “abstract document structure as a separate descriptive level in the analysis and generation of written texts”, further motivating our work. The aggregation of word senses discussed in the present work has a precedent in supersense tagging (Ciaramita & Johnson, 2003), especially for Wikipedia text (Chang, Tsai, & Chang, 2009). Notably, one of WordNet’s lexicographer files is noun.communication, which contains “nouns denoting communicative processes and contents” (“WordNet 3.0 Reference Manual”, 2012). However, the set of senses in this file is a poor match for current purposes, as it includes many senses that do not fit a written or document-oriented context (for example, a word sense for airwave is included in the file). The present work also identifies several DE senses outside of this lexicographer file. Overall, the meta-communicative focus of the pre"
2016.gwc-1.60,D14-1056,0,0.0159954,"may be the closest figure or the one most recently referred to. The potentially non-textual nature of DEs also separates them from mentioned language (Wilson, 2012), although the phenomena share a metalinguistic quality. Shell nouns are nouns used anaphorically to refer to complex concepts such as points, assumptions, acts, or feelings (Schmid, 2000). Their referents intersect with DEs, although neither set subsumes the other: Schmid’s taxonomy of shell nouns does not include typical DEreferential nouns like section, figure, or list, yet it does include non-DEs like fury, miracle, and pride. Kolhatkar and Hirst (2014) have automatically detected referents of some shell nouns, but their methods share the limitations of coreference resolvers, as described above. Statistic Documents Words Cand. Phrases Privacy Policies Wikipedia Wikibooks 1010 500 149 2646864 720013 5429978 34181 2371 47546 Table 2. Statistics on each of the three corpora. Figure 1. Pipeline used to process the corpora. 4 Synset Collection and Labeling The prior study of DE senses provided groundwork for the study of DE reference, but the dataset it created lacked the size and diversity for appreciable machine learning results. This section d"
2016.gwc-1.60,C14-1084,0,0.0197302,"data arranged in rows and columns n: table.n.02: a piece of furniture having a smooth flat top that is usually supported by one or more vertical legs n: table.n.03: a piece of furniture with tableware for a meal laid out on it Figure 3. Examples of synset labels. Set Name PP WB WP High Rank 205 (35/170) 200 (62/138) 200 (28/172) Broad Rank 57 (21/36) 93 (16/77) 136 (26/110) Table 4. Sizes of the sets of synsets, along with their label compositions (positive/negative). Table 2 shows descriptive statistics for the three corpora, which consisted of: • Privacy Policies (PP): a corpus collected by Liu et al. (2014) to reflect Alexa Internet’s assessment of the internet’s most popular sites lemmas, whose 200 synsets were labeled by the prior study. Those labels are reused in the present work. • Wikibooks (WB): all English books with printable versions • Wikipedia (WP): random English articles, excluding disambiguation and stub pages Table 3 shows the most frequent lemmas in candidate phrases, illustrating topical differences between corpora. The frequency distribution for Wikibooks showed a “heavier tail”, as the text in its candidate phrases was more varied. It was hypothesized that this was not a refle"
2016.gwc-1.60,W11-1508,0,0.0377444,"Missing"
2016.gwc-1.60,J03-2003,0,0.0329872,"e definition of problem.n.02) could refer to a question embedded in informative prose or an orthographically-distinct exercise in a problem set. 3 Related Work Prior studies showed the communicative value of multiple representations and their tight integration, motivating the present work. Mayer (2009) presented the cognitive theory of multimedia learning and explored how pictorial DEs augment and enhance textual artifacts. Similarly, Ayres and Sweller (2005) argued that learning materials should be presented so that “disparate sources of information are physically and temporally integrated”. Power, et al. (2003) argued for “abstract document structure as a separate descriptive level in the analysis and generation of written texts”, further motivating our work. The aggregation of word senses discussed in the present work has a precedent in supersense tagging (Ciaramita & Johnson, 2003), especially for Wikipedia text (Chang, Tsai, & Chang, 2009). Notably, one of WordNet’s lexicographer files is noun.communication, which contains “nouns denoting communicative processes and contents” (“WordNet 3.0 Reference Manual”, 2012). However, the set of senses in this file is a poor match for current purposes, as i"
2016.gwc-1.60,N13-1071,0,0.0713323,"Missing"
2016.gwc-1.60,P13-1045,0,0.0152174,"Missing"
2016.gwc-1.60,P12-1067,1,0.830098,"s commonalities with entity linking (Hachey et al., 2013) and Wikification, the process of linking named entities in text with corresponding Wikipedia pages (Cheng & Roth, 2013). However, DEs differ markedly from named entities. DEs vary widely in their representation and they often reside in the same communication medium as references to them. References to DEs often incorporate pragmatic information: for example, the referent of ""this figure"" may be the closest figure or the one most recently referred to. The potentially non-textual nature of DEs also separates them from mentioned language (Wilson, 2012), although the phenomena share a metalinguistic quality. Shell nouns are nouns used anaphorically to refer to complex concepts such as points, assumptions, acts, or feelings (Schmid, 2000). Their referents intersect with DEs, although neither set subsumes the other: Schmid’s taxonomy of shell nouns does not include typical DEreferential nouns like section, figure, or list, yet it does include non-DEs like fury, miracle, and pride. Kolhatkar and Hirst (2014) have automatically detected referents of some shell nouns, but their methods share the limitations of coreference resolvers, as described"
2016.gwc-1.60,I13-1091,1,0.810337,"at a practical ceiling exists for classifier performance on the task as currently conceived. 6.2 Additional Analysis Figure 4 shows receiver operating characteristic (ROC) curves for the LOOCV high rank runs (T1). All three show a drawback of achieving high recall for the task: many DE synsets resist correct classification without a high tolerance for false positives. ROC curves for cross-training runs were similar. These observations resemble prior results on mentioned language, a related metalinguistic phenomenon for which many positive instances appear to lack reliable predictive features (Wilson, 2013). On the other hand, labeling a small “core” group of positive instances with high precision seems possible. Finally, information gain was used to rank the utility of features for T1, and Table 8 shows the results. The hyper_synset and gloss_hypo feature families dominated the top features for all corpora. The strength of hyper_synset was expected, given prior observations of DE “neighborhoods” in the ontology. The strength of gloss_hypo (and the relative absence of gloss_self) was not expected, though an intuitive explanation for it exists: the aggregated vocabulary of multiple hyponyms’ defi"
2016.gwc-1.60,P14-2067,1,0.817129,"a prior study of DE reference, with examples of the phenomenon and differences from the present work. Several related topics are reviewed in Section 3. Section 4 details the collection of word senses and the manual annotation process. In Sections 5 and 6, the procedure for the automatic labeling of synsets is presented, along with results for intradomain and cross-domain labeling. We conclude with a discussion of the significance of these results and some directions for future work. 2 Background The present work builds upon findings from a prior study of word senses relevant to DE reference (Wilson & Oberlander, 2014). There, the set of 122 English Wikibooks1 textbooks with printable versions was selected as a corpus. The set contained eleven subject areas, including computing, humanities, sciences, and languages. This corpus was chosen for several reasons. Among the alternatives, it provided the largest volume of text with a reuse-friendly license. It addressed a diverse set of topics with text written to inform, thus implying a diverse set of DEs. Additionally, 1 http://en.wikibooks.org/ the corpus represented the collaboration of a large number of writers. Phrase templates were used to gather candidate"
2020.acl-main.169,W19-3402,1,0.875908,"r, while the latter is the central theme of our work. Prior work on Enron corpus (Yeh and Harnly, 2006) has been mostly from a socio-linguistic perspective to observe social power dynamics (Bramsen et al., 2011; McCallum et al., 2007), formality (Peterson et al., 2011) and politeness (Prabhakaran et al., 2014). We build upon this body of work by using this corpus as a source for the style transfer task. Prior work on style transfer has largely focused on tasks of sentiment modification (Hu et al., 2017; Shen et al., 2017; Li et al., 2018), caption transfer (Li et al., 2018), persona transfer (Chandu et al., 2019; Zhang et al., 2018), gender and political slant transfer (Reddy and Knight, 2016; Prabhumoye et al., 2018), and formality transfer (Rao and Tetreault, 2018; Xu et al., 2019). Note that formality and politeness are loosely connected but independent styles (Kang and Hovy, 2019). We focus our efforts on carving out a task for politeness transfer and creating a dataset for such a task. Current style transfer techniques (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; John et al., 2019) try to disentangle source style from content and then combine the content with the targ"
2020.acl-main.169,P13-1025,0,0.50267,"wn et al., 1987), the phenomenon of politeness is rich and multifaceted. Second, politeness of a sentence depends on the culture, language, and social structure of both the speaker and the addressed person. For instance, while using “please” in requests made to the closest friends is common amongst the native speakers of North American English, such an act would be considered awkward, if not rude, in the Arab culture (K´ad´ar and Mills, 2011). We circumscribe the scope of politeness for the purpose of this study as follows: First, we adopt the data driven definition of politeness proposed by (Danescu-Niculescu-Mizil et al., 2013). Second, we base our experiments on a dataset derived from the Enron corpus (Klimt and Yang, 2004) which consists of email exchanges in an American corporation. Thus, we restrict our attention to the notion of politeness as widely accepted by the speakers of North American English in a formal setting. Even after framing politeness transfer as a task, there are additional challenges involved that differentiate politeness from other styles. Consider a common directive in formal communication, “send me the data”. While the sentence is not impolite, a rephrasing “could you please send me the data"
2020.acl-main.169,W11-2107,0,0.135215,"Missing"
2020.acl-main.169,W17-4902,0,0.0334517,"ons (Coppock, 2005), organizational settings like emails (Peterson et al., 2011), memos, official documents, and many other settings. Notably, politeness has also been identified as an interpersonal style which can be decoupled from content (Kang and Hovy, 2019). Motivated by its central importance, in this paper we study the task of converting non-polite sentences to polite sentences while preserving the meaning. Prior work on text style transfer (Shen et al., 2017; Li et al., 2018; Prabhumoye et al., 2018; ∗ authors contributed equally to this work. Rao and Tetreault, 2018; Xu et al., 2012; Jhamtani et al., 2017) has not focused on politeness as a style transfer task, and we argue that defining it is cumbersome. While native speakers of a language and cohabitants of a region have a good working understanding of the phenomenon of politeness for everyday conversation, pinning it down as a definition is non-trivial (Meier, 1995). There are primarily two reasons for this complexity. First, as noted by (Brown et al., 1987), the phenomenon of politeness is rich and multifaceted. Second, politeness of a sentence depends on the culture, language, and social structure of both the speaker and the addressed pers"
2020.acl-main.169,P19-1041,0,0.145314,"et al., 2017; Li et al., 2018), caption transfer (Li et al., 2018), persona transfer (Chandu et al., 2019; Zhang et al., 2018), gender and political slant transfer (Reddy and Knight, 2016; Prabhumoye et al., 2018), and formality transfer (Rao and Tetreault, 2018; Xu et al., 2019). Note that formality and politeness are loosely connected but independent styles (Kang and Hovy, 2019). We focus our efforts on carving out a task for politeness transfer and creating a dataset for such a task. Current style transfer techniques (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; John et al., 2019) try to disentangle source style from content and then combine the content with the target style to generate the sentence in the target style. Compared to prior work, “Delete, Retrieve and Generate” (Li et al., 2018) (referred to as DRG henceforth) and its extension (Sudhakar et al., 2019) are effective methods to generate out1870 puts in the target style while having a relatively high rate of source content preservation. However, DRG has several limitations: (1) the delete module often marks content words as stylistic markers and deletes them, (2) the retrieve step relies on the presence of s"
2020.acl-main.169,N18-1169,0,0.126915,"Missing"
2020.acl-main.169,Q18-1027,0,0.244392,"lves going from a neutral style to the target style. Finally, we design a “tag and generate” pipeline that is particularly well suited for tasks like politeness, while being general enough to match or beat the performance of the existing systems on popular style transfer tasks. 2 Related Work Politeness and its close relation with power dynamics and social interactions has been well documented (Brown et al., 1987). Recent work (Danescu-Niculescu-Mizil et al., 2013) in computational linguistics has provided a corpus of requests annotated for politeness curated from Wikipedia and StackExchange. Niu and Bansal (2018) uses this corpus to generate polite dialogues. Their work focuses on contextual dialogue response generation as opposed to content preserving style transfer, while the latter is the central theme of our work. Prior work on Enron corpus (Yeh and Harnly, 2006) has been mostly from a socio-linguistic perspective to observe social power dynamics (Bramsen et al., 2011; McCallum et al., 2007), formality (Peterson et al., 2011) and politeness (Prabhakaran et al., 2014). We build upon this body of work by using this corpus as a source for the style transfer task. Prior work on style transfer has larg"
2020.acl-main.169,P02-1040,0,0.107063,"re accuracy, we use a classifier trained on the nonparallel style corpora for the respective datasets (barring politeness). The architecture of the classifier is based on AWD - LSTM (Merity et al., 2017) and a softmax layer trained via cross-entropy loss. We use the implementation provided by fastai.5 For politeness, we use the classifier trained by (Niu and Bansal, 2018).6 The metric of transfer accuracy (Acc) is defined as the percentage of generated sentences classified to be in the target domain by the classifier. The standard metric for measuring content preservation is BLEU-self (BL-s) (Papineni et al., 2002) which is computed with respect to the original sentences. Additionally, we report the BLEU-reference (BL-r) scores using the human reference sentences on the Yelp, Amazon and Captions datasets (Li et al., 2018). We also report ROUGE (ROU) (Lin, 2004) and METEOR (MET) (Denkowski and Lavie, 5 https://docs.fast.ai/ This is trained on the dataset given by (DanescuNiculescu-Mizil et al., 2013). 6 2011) scores. In particular, METEOR also uses synonyms and stemmed forms of the words in candidate and reference sentences, and thus may be better at quantifying semantic similarities. Table 1 shows that"
2020.acl-main.169,D19-1322,0,0.350737,"e that formality and politeness are loosely connected but independent styles (Kang and Hovy, 2019). We focus our efforts on carving out a task for politeness transfer and creating a dataset for such a task. Current style transfer techniques (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; John et al., 2019) try to disentangle source style from content and then combine the content with the target style to generate the sentence in the target style. Compared to prior work, “Delete, Retrieve and Generate” (Li et al., 2018) (referred to as DRG henceforth) and its extension (Sudhakar et al., 2019) are effective methods to generate out1870 puts in the target style while having a relatively high rate of source content preservation. However, DRG has several limitations: (1) the delete module often marks content words as stylistic markers and deletes them, (2) the retrieve step relies on the presence of similar content in both the source and target styles, (3) the retrieve step is time consuming for large datasets, (4) the pipeline makes the assumption that style can be transferred by deleting stylistic markers and replacing them with target style phrases, (5) the method relies on a fixed"
2020.acl-main.169,W11-0711,0,0.122804,"Missing"
2020.acl-main.169,D14-1211,0,0.0182126,"2013) in computational linguistics has provided a corpus of requests annotated for politeness curated from Wikipedia and StackExchange. Niu and Bansal (2018) uses this corpus to generate polite dialogues. Their work focuses on contextual dialogue response generation as opposed to content preserving style transfer, while the latter is the central theme of our work. Prior work on Enron corpus (Yeh and Harnly, 2006) has been mostly from a socio-linguistic perspective to observe social power dynamics (Bramsen et al., 2011; McCallum et al., 2007), formality (Peterson et al., 2011) and politeness (Prabhakaran et al., 2014). We build upon this body of work by using this corpus as a source for the style transfer task. Prior work on style transfer has largely focused on tasks of sentiment modification (Hu et al., 2017; Shen et al., 2017; Li et al., 2018), caption transfer (Li et al., 2018), persona transfer (Chandu et al., 2019; Zhang et al., 2018), gender and political slant transfer (Reddy and Knight, 2016; Prabhumoye et al., 2018), and formality transfer (Rao and Tetreault, 2018; Xu et al., 2019). Note that formality and politeness are loosely connected but independent styles (Kang and Hovy, 2019). We focus our"
2020.acl-main.169,L18-1445,0,0.0160067,"ansfer, the captions task also involves going from a style neutral (factual) to a style rich (humorous or romantic) parlance. For sentiment transfer, we use the Yelp restaurant review dataset (Shen et al., 2017) to train, and evaluate on a test set of 1000 sentences released by Li et al. (2018). We also use the Amazon dataset of product reviews (He and McAuley, 2016). We use the Yelp review dataset labelled for the Gender of the author, released by Prabhumoye et al. (2018) compiled from Reddy and Knight (2016). For the Political slant task (Prabhumoye et al., 2018), we use dataset released by Voigt et al. (2018). 4 Methodology We are given non-parallel samples of sentences (1) (1) (2) (2) X1 = {x1 . . . xn } and X2 = {x1 . . . xm } from styles S1 and S2 respectively. The objective of the task is to efficiently generate samples (2) (2) ˆ 1 = {ˆ X x1 . . . x ˆn } in the target style S2 , conditioned on samples in X1 . For a style Sv where v ∈ {1, 2}, we begin by learning a set of phrases (Γv ) which characterize the style Sv . The presence of phrases from Γv in a sentence xi would associate the sentence with the style Sv . For example, phrases like “pretty good” and “worth every penny” are characterist"
2020.acl-main.169,P18-1080,1,0.611497,"2013). It is also imperative to use the appropriate level of politeness for smooth communication in conversations (Coppock, 2005), organizational settings like emails (Peterson et al., 2011), memos, official documents, and many other settings. Notably, politeness has also been identified as an interpersonal style which can be decoupled from content (Kang and Hovy, 2019). Motivated by its central importance, in this paper we study the task of converting non-polite sentences to polite sentences while preserving the meaning. Prior work on text style transfer (Shen et al., 2017; Li et al., 2018; Prabhumoye et al., 2018; ∗ authors contributed equally to this work. Rao and Tetreault, 2018; Xu et al., 2012; Jhamtani et al., 2017) has not focused on politeness as a style transfer task, and we argue that defining it is cumbersome. While native speakers of a language and cohabitants of a region have a good working understanding of the phenomenon of politeness for everyday conversation, pinning it down as a definition is non-trivial (Meier, 1995). There are primarily two reasons for this complexity. First, as noted by (Brown et al., 1987), the phenomenon of politeness is rich and multifaceted. Second, politeness o"
2020.acl-main.169,N18-1012,0,0.231584,"ess for smooth communication in conversations (Coppock, 2005), organizational settings like emails (Peterson et al., 2011), memos, official documents, and many other settings. Notably, politeness has also been identified as an interpersonal style which can be decoupled from content (Kang and Hovy, 2019). Motivated by its central importance, in this paper we study the task of converting non-polite sentences to polite sentences while preserving the meaning. Prior work on text style transfer (Shen et al., 2017; Li et al., 2018; Prabhumoye et al., 2018; ∗ authors contributed equally to this work. Rao and Tetreault, 2018; Xu et al., 2012; Jhamtani et al., 2017) has not focused on politeness as a style transfer task, and we argue that defining it is cumbersome. While native speakers of a language and cohabitants of a region have a good working understanding of the phenomenon of politeness for everyday conversation, pinning it down as a definition is non-trivial (Meier, 1995). There are primarily two reasons for this complexity. First, as noted by (Brown et al., 1987), the phenomenon of politeness is rich and multifaceted. Second, politeness of a sentence depends on the culture, language, and social structure o"
2020.acl-main.169,W16-5603,0,0.379489,"s (Yeh and Harnly, 2006) has been mostly from a socio-linguistic perspective to observe social power dynamics (Bramsen et al., 2011; McCallum et al., 2007), formality (Peterson et al., 2011) and politeness (Prabhakaran et al., 2014). We build upon this body of work by using this corpus as a source for the style transfer task. Prior work on style transfer has largely focused on tasks of sentiment modification (Hu et al., 2017; Shen et al., 2017; Li et al., 2018), caption transfer (Li et al., 2018), persona transfer (Chandu et al., 2019; Zhang et al., 2018), gender and political slant transfer (Reddy and Knight, 2016; Prabhumoye et al., 2018), and formality transfer (Rao and Tetreault, 2018; Xu et al., 2019). Note that formality and politeness are loosely connected but independent styles (Kang and Hovy, 2019). We focus our efforts on carving out a task for politeness transfer and creating a dataset for such a task. Current style transfer techniques (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; John et al., 2019) try to disentangle source style from content and then combine the content with the target style to generate the sentence in the target style. Compared to prior work, “De"
2020.acl-main.169,C12-1177,0,0.0479898,"ion in conversations (Coppock, 2005), organizational settings like emails (Peterson et al., 2011), memos, official documents, and many other settings. Notably, politeness has also been identified as an interpersonal style which can be decoupled from content (Kang and Hovy, 2019). Motivated by its central importance, in this paper we study the task of converting non-polite sentences to polite sentences while preserving the meaning. Prior work on text style transfer (Shen et al., 2017; Li et al., 2018; Prabhumoye et al., 2018; ∗ authors contributed equally to this work. Rao and Tetreault, 2018; Xu et al., 2012; Jhamtani et al., 2017) has not focused on politeness as a style transfer task, and we argue that defining it is cumbersome. While native speakers of a language and cohabitants of a region have a good working understanding of the phenomenon of politeness for everyday conversation, pinning it down as a definition is non-trivial (Meier, 1995). There are primarily two reasons for this complexity. First, as noted by (Brown et al., 1987), the phenomenon of politeness is rich and multifaceted. Second, politeness of a sentence depends on the culture, language, and social structure of both the speake"
2020.acl-main.169,P18-1205,0,0.0162901,"s the central theme of our work. Prior work on Enron corpus (Yeh and Harnly, 2006) has been mostly from a socio-linguistic perspective to observe social power dynamics (Bramsen et al., 2011; McCallum et al., 2007), formality (Peterson et al., 2011) and politeness (Prabhakaran et al., 2014). We build upon this body of work by using this corpus as a source for the style transfer task. Prior work on style transfer has largely focused on tasks of sentiment modification (Hu et al., 2017; Shen et al., 2017; Li et al., 2018), caption transfer (Li et al., 2018), persona transfer (Chandu et al., 2019; Zhang et al., 2018), gender and political slant transfer (Reddy and Knight, 2016; Prabhumoye et al., 2018), and formality transfer (Rao and Tetreault, 2018; Xu et al., 2019). Note that formality and politeness are loosely connected but independent styles (Kang and Hovy, 2019). We focus our efforts on carving out a task for politeness transfer and creating a dataset for such a task. Current style transfer techniques (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; John et al., 2019) try to disentangle source style from content and then combine the content with the target style to generate"
2020.acl-main.169,P11-1078,0,\N,Missing
2020.acl-main.169,W04-1013,0,\N,Missing
2020.acl-main.169,P16-1162,0,\N,Missing
2020.acl-main.217,N18-1008,0,0.0479177,"all synthetic corpus and evaluated on speech-to-text alignments rather than translation. Subsequently Weiss et al. (2017) extended these neural attentional models to deep, multitask models with excellent results on Fisher Spanish– English, exceeding a cascade for the first time. However, efforts from the community have not yet replicated their success (Stoian et al., 2020; Sperber et al., 2019; Salesky et al., 2019). End-to-end models have performed inconsistently compared to cascades on other corpora: B´erard et al. (2018) perform well on high-resource audiobooks but do not exceed a cascade; Anastasopoulos and Chiang (2018) found ‘triangle’ models performed better than cascades for 2 of 3 very low-resource language pairs; and in the most recent IWSLT evaluation campaigns, cascades have remained the highest-performing systems (Niehues et al., 2018, 2019). Similarly-motivated work exists in speech translation. In addition to Salesky et al. (2019); Sperber et al. (2019) addressed above, preliminary cascades using phone-like units have been explored for low-resource speech translation, motivated by translation of unwritten languages where a traditional cascade would not be possible. To this end, Bansal et al. (2018)"
2020.acl-main.217,N19-1006,0,0.350565,"ired by Weiss et al. (2017) modified to train within lower resources; specifically, each model converges within ≈5 days on one GPU. We build encoder-decoder models with attention in xnmt (Neubig et al., 2018) with 512 hidden units. Our pyramidal encoder uses 3-layer BiLSTMs with linear network-in-network (NiN) projections and batch normalization between layers (Sperber et al., 2019; Zhang et al., 2017). The NiN projections are used to downsample by a factor of 2 between layers, resulting in the same total 4× downsampling in time as the additional convolutional layers from Weiss et al. (2017); Bansal et al. (2019): They give us the benefit of added depth with fewer additional parameters. We use single layer MLP attention (Bahdanau et al., 2015) with 128 units and 1 decoder layer as opposed to 3 or 4 in previous work – we did not see consistent benefits from additional depth. In line with previous work on this dataset, all experiments preprocess target text by lowercasing and removing punctuation aside from apostrophes. We use 40-dimensional Mel filterbank features as previous work did not see significant difference with higherdimensional features (Salesky et al., 2019). We use 1k BPE units for translat"
2020.acl-main.217,D18-1366,0,0.0535695,"Missing"
2020.acl-main.217,N18-1031,0,0.0234971,"ecoder). Using the pyramidal architecture resulted in the same performance as the BiLSTM model when translating BPE transcriptions from ASR, but gave us consistent improvements of up to 1.5 BLEU when instead translating phone sequences; we posit this is because phone sequences are longer than BPE equivalents. Accordingly, we use the same model architecture for all our ASR, MT, and ST models. We use layer dropout with p = 0.2 and target embedding dropout with p = 0.1 (Gal and Ghahramani, 2016). We apply label smoothing with p = 0.1 (Szegedy et al., 2016) and fix the target embedding norm to 1 (Nguyen and Chiang, 2018). For inference, we use beam of size 15 and length normalization with exponent 1.5. We set the batch size dynamically depending on the input sequence length with average batch size was 36. We use Adam (Kingma and Ba, 2015) with initial learning rate 0.0003, decayed by 0.5 when validation BLEU did not improve for 10 epochs initially and subsequently 5 epochs. We do not use L2 weight decay or Gaussian noise, and use a single model replica. We use input feeding (Luong et al., 2015), and exclude utterances longer than 1500 frames in training for memory. 2390 6 Prior Work: Cascaded vs End-to-End Mo"
2020.acl-main.217,1998.amta-tutorials.1,0,0.610646,"Missing"
2020.acl-main.217,2013.iwslt-papers.14,0,0.0508782,"granularity to character-based MT. The averaged feature vectors remain continuously-valued, and are locally summarized: a given phone across the corpus will still have different representations in each instance. 3 Data 4 We use the Fisher Spanish-English corpus, which consists of parallel speech, transcripts, and translations, enabling comparisons between cascaded and direct models on the same data and allowing us to generate phone supervision using matched data. The dataset contains 160 hours of Spanish telephone speech, split into 138K utterances, which were translated via crowdsourcing by Post et al. (2013). We use the standard dev and test sets, each with ∼4k utterances. Because we are particularly interested in how our methods will affect training across differently-resourced conditions, we compare results using randomly selected 40 hour and 20 hour subsets of the data. 4 2389 joshua.incubator.apache.org/data/fisher-callhome-corpus 4 Generating Phone Supervision To generate phoneme-level labels for sequences of speech features, we generate frame-level alignments using a trained speech recognizer. Specifically, we extract 40-dimensional Mel filterbank features with per-speaker mean and variance"
2020.acl-main.217,P19-1179,1,0.283453,"rn the task at hand more efficiently and yielding greater robustness to lower-resource conditions. We propose two simple heuristics to integrate phoneme-level information into neural speech translation models: (1) as a more robust intermediate representation in a cascade; and (2) as a concatenated embedding factor. We use the common Fisher Spanish–English dataset to compare with previous work, and simulate high-, mid-, and low-resource conditions to compare model performance across different data conditions. We compare to recent work using phone segmentation for end-to-end speech translation (Salesky et al., 2019), and show that our methods outperform this model by up to 2 20 BLEU on our lowest-resource condition. Further, our models outperform all previous academic work on this dataset, achieving similar performance trained on 20 hours as a baseline end-to-end model trained on the full 160 hour dataset. Finally, we test model robustness by varying the quality of our phone features, which may indicate which models will better generalize across 3 differently-resourced conditions. 2 Models with Phone Supervision We add higher-level phone features to low-level speech features to improve our models’ robust"
2020.acl-main.217,W16-2209,0,0.0551634,"Missing"
2020.acl-main.217,D17-1145,0,0.181933,"erbank features may allow our end-to-end models to recover from discrete label errors, our results testing various phone qualities suggest this may only be the case under higher-resource settings with sufficient examples. 9 Related Work Speech translation was initially performed by cascading separately trained ASR and MT models, allowing each model to be trained on larger data sources without parallel speech, transcriptions, and translations, but potentially yielding unrecoverable errors between models. Linking models through lattices with both phrase-based (Kumar et al., 2014) and neural MT (Sperber et al., 2017) reduced many such errors. Using one model to directly translate speech was later enabled by attentional encoder-decoder models. Direct end-to-end speech translation was first explored as a way to reduce both error propagation, and also the need for high quality intermediate transcriptions (e.g. for unwritten languages). The first such models were investigated in B´erard et al. (2016); Duong et al. (2016), but these used, respectively, a small synthetic corpus and evaluated on speech-to-text alignments rather than translation. Subsequently Weiss et al. (2017) extended these neural attentional"
2020.acl-main.217,N16-1109,0,0.0194987,"h, transcriptions, and translations, but potentially yielding unrecoverable errors between models. Linking models through lattices with both phrase-based (Kumar et al., 2014) and neural MT (Sperber et al., 2017) reduced many such errors. Using one model to directly translate speech was later enabled by attentional encoder-decoder models. Direct end-to-end speech translation was first explored as a way to reduce both error propagation, and also the need for high quality intermediate transcriptions (e.g. for unwritten languages). The first such models were investigated in B´erard et al. (2016); Duong et al. (2016), but these used, respectively, a small synthetic corpus and evaluated on speech-to-text alignments rather than translation. Subsequently Weiss et al. (2017) extended these neural attentional models to deep, multitask models with excellent results on Fisher Spanish– English, exceeding a cascade for the first time. However, efforts from the community have not yet replicated their success (Stoian et al., 2020; Sperber et al., 2019; Salesky et al., 2019). End-to-end models have performed inconsistently compared to cascades on other corpora: B´erard et al. (2018) perform well on high-resource audi"
2020.acl-main.217,Q19-1020,0,0.0673126,"eam results by &gt;10 BLEU. Producing phone features in this way uses the same data (source speech and transcripts) as the ASR task in a cascade, and auxiliary ASR tasks from multi-task end-to-end models, but as we show, to far greater effect. Further, auxiliary tasks as used in previous work rely on three-way parallel data, while it is possible to generate effective phoneme-level supervision using a recognizer trained on other corpora or languages (Salesky et al., 2019), though we do not do this here. 5 Model & Training Procedure As in previous academic work on this corpus (Bansal et al., 2018; Sperber et al., 2019; Salesky et al., 2019), we use a sequence-to-sequence architecture inspired by Weiss et al. (2017) modified to train within lower resources; specifically, each model converges within ≈5 days on one GPU. We build encoder-decoder models with attention in xnmt (Neubig et al., 2018) with 512 hidden units. Our pyramidal encoder uses 3-layer BiLSTMs with linear network-in-network (NiN) projections and batch normalization between layers (Sperber et al., 2019; Zhang et al., 2017). The NiN projections are used to downsample by a factor of 2 between layers, resulting in the same total 4× downsampling i"
2020.acl-main.217,D15-1166,0,0.159678,"Missing"
2020.acl-main.217,W18-1818,0,0.0192068,"vious work rely on three-way parallel data, while it is possible to generate effective phoneme-level supervision using a recognizer trained on other corpora or languages (Salesky et al., 2019), though we do not do this here. 5 Model & Training Procedure As in previous academic work on this corpus (Bansal et al., 2018; Sperber et al., 2019; Salesky et al., 2019), we use a sequence-to-sequence architecture inspired by Weiss et al. (2017) modified to train within lower resources; specifically, each model converges within ≈5 days on one GPU. We build encoder-decoder models with attention in xnmt (Neubig et al., 2018) with 512 hidden units. Our pyramidal encoder uses 3-layer BiLSTMs with linear network-in-network (NiN) projections and batch normalization between layers (Sperber et al., 2019; Zhang et al., 2017). The NiN projections are used to downsample by a factor of 2 between layers, resulting in the same total 4× downsampling in time as the additional convolutional layers from Weiss et al. (2017); Bansal et al. (2019): They give us the benefit of added depth with fewer additional parameters. We use single layer MLP attention (Bahdanau et al., 2015) with 128 units and 1 decoder layer as opposed to 3 or"
2020.acl-main.248,P12-1039,0,0.0369395,"ask. The results on both automatic and human metrics across four different datasets show that this new technique is better at capturing coherence in documents. 1 Introduction Sentence ordering is the task of arranging sentences into an order which maximizes the coherence of the text (Barzilay and Lapata, 2008). This is important in applications where we have to determine the sequence of pre-selected set of information to be presented. This task has been well-studied in the community due to its significance in down stream applications such as ordering of: concepts in conceptto-text generation (Konstas and Lapata, 2012), information from each document in multi-document summarization (Barzilay and Elhadad, 2002; Nallapati et al., 2017), events in storytelling (Fan et al., 2019; Hu et al., 2019), cooking steps in recipe generation (Chandu et al., 2019), and positioning of new information in existing summaries for update summarization (Prabhumoye et al., 2019). Student essays are evaluated based on how coherent and well structured they are. Hence, automated essay scoring (Burstein et al., 2010; Miltsakaki and Kukich, 2004) can use this task to improve the efficiency of their systems. Early work on coherence mod"
2020.acl-main.248,P03-1069,0,0.633873,", 2017), events in storytelling (Fan et al., 2019; Hu et al., 2019), cooking steps in recipe generation (Chandu et al., 2019), and positioning of new information in existing summaries for update summarization (Prabhumoye et al., 2019). Student essays are evaluated based on how coherent and well structured they are. Hence, automated essay scoring (Burstein et al., 2010; Miltsakaki and Kukich, 2004) can use this task to improve the efficiency of their systems. Early work on coherence modeling and sentence ordering task uses probabilistic transition model based on vectors of linguistic features (Lapata, 2003), content model which represents topics as states in an HMM (Barzilay and Lee, 2004), and entity based approach (Barzilay and Lapata, 2008). Recent work uses neural approaches to model coherence and to solve sentence ordering task. Li and Hovy (2014) introduced a neural model based on distributional sentence representations using recurrent or recursive neural networks and avoided the need of feature engineering for this task. In (Li and Jurafsky, 2017), they extend it to domain independent neural models for coherence and they introduce new latent variable Markovian generative models to capture"
2020.acl-main.248,J06-4002,0,0.192923,"which the entire sequence was correctly predicted (Chen et al., 2016). PMR = 1 PN 1{ˆ oi = o∗i }, where N is the number of i=1 N samples in the dataset. It is the strictest metric. Sentence Accuracy (Acc): measures the percentage of sentences for which their absolute position was correctlyP predicted (Logeswaran et al., 1 Pvi oij = o∗i 2018). Acc = N1 N j } , j=1 1{ˆ i=1 vi th where vi is the number of sentences in the i document. It is a also a stringent metric. Kendall Tau (Tau): quantifies the distance between the predicted order and the correct order in terms of the number of inversions (Lapata, 2006).  τ = 1 − 2I/ v2i , where I is the number of pairs in the predicted order with incorrect relative order and τ ∈ [−1, 1]. Rouge-S: calculates the percentage of skipbigrams for which the relative order is predicted correctly (Chen et al., 2016). Skip-bigrams are the  total number of pairs v2i in a document. Note that it does not penalize any arbitrary gaps between two sentences as long as their relative order is correct. Rouge-S = v1i Skip(ˆ o) ∩ Skip(o∗ ) , where the (2) Skip(.) function returns the set of skip-bigrams of the given order. Longest Common Subsequence (LCS): calculates the rati"
2020.acl-main.248,D14-1218,0,0.117848,"ssays are evaluated based on how coherent and well structured they are. Hence, automated essay scoring (Burstein et al., 2010; Miltsakaki and Kukich, 2004) can use this task to improve the efficiency of their systems. Early work on coherence modeling and sentence ordering task uses probabilistic transition model based on vectors of linguistic features (Lapata, 2003), content model which represents topics as states in an HMM (Barzilay and Lee, 2004), and entity based approach (Barzilay and Lapata, 2008). Recent work uses neural approaches to model coherence and to solve sentence ordering task. Li and Hovy (2014) introduced a neural model based on distributional sentence representations using recurrent or recursive neural networks and avoided the need of feature engineering for this task. In (Li and Jurafsky, 2017), they extend it to domain independent neural models for coherence and they introduce new latent variable Markovian generative models to capture sentence dependencies. These models used windows of sentences as context to predict sentence pair orderings. Gong et al. (2016) proposed end-to-end neural architecture for sentence ordering task which uses pointer networks to utilize the contextual"
2020.acl-main.248,D17-1019,0,0.0996642,"their systems. Early work on coherence modeling and sentence ordering task uses probabilistic transition model based on vectors of linguistic features (Lapata, 2003), content model which represents topics as states in an HMM (Barzilay and Lee, 2004), and entity based approach (Barzilay and Lapata, 2008). Recent work uses neural approaches to model coherence and to solve sentence ordering task. Li and Hovy (2014) introduced a neural model based on distributional sentence representations using recurrent or recursive neural networks and avoided the need of feature engineering for this task. In (Li and Jurafsky, 2017), they extend it to domain independent neural models for coherence and they introduce new latent variable Markovian generative models to capture sentence dependencies. These models used windows of sentences as context to predict sentence pair orderings. Gong et al. (2016) proposed end-to-end neural architecture for sentence ordering task which uses pointer networks to utilize the contextual information in the entire piece of text. Recently hierarchical architectures have been proposed for this task. In (Logeswaran et al., 2018), the model uses two levels of LSTMs to first get the encoding of t"
2020.acl-main.248,N19-1269,1,0.839367,"s where we have to determine the sequence of pre-selected set of information to be presented. This task has been well-studied in the community due to its significance in down stream applications such as ordering of: concepts in conceptto-text generation (Konstas and Lapata, 2012), information from each document in multi-document summarization (Barzilay and Elhadad, 2002; Nallapati et al., 2017), events in storytelling (Fan et al., 2019; Hu et al., 2019), cooking steps in recipe generation (Chandu et al., 2019), and positioning of new information in existing summaries for update summarization (Prabhumoye et al., 2019). Student essays are evaluated based on how coherent and well structured they are. Hence, automated essay scoring (Burstein et al., 2010; Miltsakaki and Kukich, 2004) can use this task to improve the efficiency of their systems. Early work on coherence modeling and sentence ordering task uses probabilistic transition model based on vectors of linguistic features (Lapata, 2003), content model which represents topics as states in an HMM (Barzilay and Lee, 2004), and entity based approach (Barzilay and Lapata, 2008). Recent work uses neural approaches to model coherence and to solve sentence orde"
2020.acl-main.248,N10-1099,0,\N,Missing
2020.acl-main.248,J08-1001,0,\N,Missing
2020.acl-main.248,D18-1465,0,\N,Missing
2020.acl-main.248,P19-1254,0,\N,Missing
2020.acl-main.248,N19-1423,0,\N,Missing
2020.acl-main.415,2020.lrec-1.520,0,0.0419634,"on requires access to large amounts of cross-linguistic data. Previous cross-linguistic phonetic studies have been limited to a small number of languages with available data (Disner, 1983; Cho and Ladefoged, 1999), or have relied on previously reported measures from many studies (Whalen and Levitt, 1995; Becker-Kristal, 2010; Gordon and Roettger, 2017; Chodroff et al., 2019). Existing multilingual speech corpora have similar restrictions, with data too limited for many tasks (Engstrand and Cunningham-Andersson, 1988; Ladefoged and Maddieson, 2007) or approximately 20 to 30 recorded languages (Ardila et al., 2020; Harper, 2011; Schultz, 2002). The recently developed CMU Wilderness corpus (Black, 2019) constitutes an exception to this rule with over 600 languages. This makes it the largest and most typologically diverse speech corpus to date. In addition to its coverage, the CMU Wilderness corpus is unique in two additional aspects: cleanly recorded, read speech exists for all languages in the corpus, and the same content (modulo translation) exists across all languages. However, this massively multilingual speech corpus is challenging to work with directly. Copyright, computational restrictions, and s"
2020.acl-main.415,2020.lrec-1.521,0,0.334554,"e mean mel cepstral distortion score (see §3.1.3) converges. Baum-Welch does not change the predicted phoneme labels, but obtains a language-specific, reading-specific, contextual (triphone) acoustic model for each phoneme type in the language. We then use Viterbi alignment to identify an audio segment for each phoneme token. 3.1.2 High-Resource Languages A subset of the languages in our corpus are supported by existing pronunciation resources. Two such resources are Epitran (Mortensen et al., 2018), a G2P tool based on language-specific rules, available in both IPA and X-SAMPA, and WikiPron (Lee et al., 2020), a collection of crowd-sourced pronunciations scraped from Wiktionary. These are mapped from IPA to X-SAMPA for label consistency across our corpus. Epitran covers 29 of our languages (39 readings), while WikiPron’s ‘phonemic’ annotations7 provide partial coverage of 13 additional languages (18 readings). We use Epitran for languages with regular orthographies where it provides high-quality support, and WikiPron for other languages covered by WikiPron annotations. While Unitran and Epitran provide a single pronunciation for a word from the orthography, WikiPron may include multiple pronunciat"
2020.acl-main.415,qian-etal-2010-python,0,0.477559,"for each utterance. A pronunciation is predicted from the text alone using some graphemeto-phoneme (G2P) method. Each word’s predicted pronunciation is a sequence of categorical labels, which are ‘phoneme-level’ in the sense that they are usually intended to distinguish the words of the language. We then align this predicted sequence of ‘phonemes’ to the corresponding audio. 3.1.1 All Languages Most of our languages have neither existing pronunciation lexicons nor G2P resources. To provide coverage for all languages, we generate pronunciations using the simple ‘universal’ G2P system Unitran (Qian et al., 2010, as extended by Black, 2019), which deterministically expands each grapheme to a fixed sequence of phones in the Extended Speech Assessment Methods Phonetic Alphabet (XSAMPA) (Wells, 1995/2000). This naive process is error-prone for languages with opaque orthographies, as we show in §3.1.3 below and discuss further in §3.4 (Caveat B). Even so, it provides a starting point for exploring low-resource languages: after some manual inspection, a linguist may be 6 able to correct the labels in a given language by a combination of manual and automatic methods. For each reading, to align the pronunci"
2020.acl-main.651,N03-1007,0,0.525765,"Missing"
2020.acl-main.651,W15-4640,0,0.0463758,"p ∈ P is a post and q ∈ qp is a comment made on p, the task is to predict whether q is an actual clarification question for p. This makes it a binary classification problem, where a label 1 indicates q being an an actual clarification question and 0 indicates otherwise. Bootstrapping First, we initialise a seed dataset that is used to train L using the process of iterative refinement as described later. Iterative-refinement itself is subdivided into two parts: (1) Down-Sampling (2) Up-Sampling. 2.2.1 Classifier L We utilise a neural network based architecture for the classifier L. Inspired by Lowe et al. (2015), L utilises a dual encoder mechanism i.e it uses two separate LSTMs (Hochreiter and Schmidhuber, 1997) for encoding a post p and a question q. The dual encoder generates hidden representations hp and hq for p and q respectively. The resulting element-wise product of hp and hq is further passed on to fully connected layers before making predictions via softmax. More formally, the entire process can be summarised as follows: Methodology Stackexchange is a network of online question answering websites. On these websites, users may comment on the original post with content such as third party URL"
2020.acl-main.651,P18-1255,0,0.138214,"Missing"
2020.acl-main.651,N19-1013,0,0.0711545,"Missing"
2020.acl-main.651,P18-1204,0,0.019501,"eads to an under-specified question containing information gaps which lowers the probability of providing the correct answer. Thus, it would be an improvement if a conversational or a question answering system had a mechanism for refining 1 https://github.com/vaibhav4595/ClarQ user questions with follow-ups (De Boni and Manandhar, 2003). In literature, such questions have been termed Clarification Questions (De Boni and Manandhar, 2003; Rao and Daum´e III, 2018, 2019). In the domain of question-answering, the major advantages of a clarification question are its ability to resolve ambiguities (Wang et al., 2018; Aliannejadi et al., 2019) and to improve the probability of finding the most relevant answer. For conversational systems, asking such questions help in driving the conversation deeper along with better engagement of the user (Li et al., 2016; Yu et al., 2016). Recently, Rao and Daum´e III (2018, 2019) have provided a dataset based on stackexchange and used it for clarification question retrieval as well as generation. They also modify a dataset based on Amazon Question-Answering and Product Reviews (McAuley et al., 2015; McAuley and Yang, 2016) to make it suitable for the same task. On the o"
2020.acl-main.651,W16-3649,1,0.83144,"ibhav4595/ClarQ user questions with follow-ups (De Boni and Manandhar, 2003). In literature, such questions have been termed Clarification Questions (De Boni and Manandhar, 2003; Rao and Daum´e III, 2018, 2019). In the domain of question-answering, the major advantages of a clarification question are its ability to resolve ambiguities (Wang et al., 2018; Aliannejadi et al., 2019) and to improve the probability of finding the most relevant answer. For conversational systems, asking such questions help in driving the conversation deeper along with better engagement of the user (Li et al., 2016; Yu et al., 2016). Recently, Rao and Daum´e III (2018, 2019) have provided a dataset based on stackexchange and used it for clarification question retrieval as well as generation. They also modify a dataset based on Amazon Question-Answering and Product Reviews (McAuley et al., 2015; McAuley and Yang, 2016) to make it suitable for the same task. On the other hand, Aliannejadi et al. (2019) created a dataset (Qulac) built on top of TREC web collections. However, there are several shortcomings to these datasets, which limit the development of generalizable and large-scale models aimed to tackle the problem of cl"
2020.bea-1.15,W19-3621,0,0.0114594,"laws in default implementations of Transformers (Bolukbasi et al., 2016; Zhao et al., 2017, 2018). These works typicallly seek to reduce the amplification of bias in pretrained models, starting with easy-to-measure proof that demographic bias can be “removed” from word embedding spaces. But iterating on inputs to algorithmic classifiers – precisely the intended use case of formative eeedback for writers! – can reduce the efficacy of “de-biasing” (Liu et al., 2018; Dwork and Ilvento, 2019). More recent research has shown that bias may simply be masked by these approaches, rather than resolved (Gonen and Goldberg, 2019). What these questions offer, though, is a wellspring of new and innovative technical research. Developers of learning analytics software, including AES, are currently encouraged to focus on scalable experimental evidence of efficacy for learning outcomes (Saxberg, 2017), rather than focus on specific racial or gender bias, or other equity outcomes that are more difficult to achieve through engineering. But Transformer architectures are nuanced enough to capture immense world knowledge, producing a rapid increase in explainability in NLP (Rogers et al., 2020). Meanwhile, in the field of learni"
2020.bea-1.15,P18-2080,0,0.205583,"negative result for GloVe in the AES domain; only Dong et al. (2017) uses GloVe as the primary representation of ASAP texts in an LSTM model, reporting lower QWK results than any baseline we presented here. One simple explanation for this may be that individual keywords matter a great deal for model performance. It is well established that vocabularybased approaches are effective in AES tasks (Higgins et al., 2014) and the lack of access to specific word-based features may hinder semantic vector representation. Indeed, only one competitive recent paper on AES uses non-contextual word vectors: Cozma et al. (2018). In this implementation, they do use word2vec, but rather than use word embeddings directly they first cluster words into a set of 500 “embedding clusters.” Words that appear in texts are then counted in the feature vector as the centroid of that cluster - in effect, creating a 500-dimensional bag-of-words model. Our results would suggest that fine-tuning with BERT also reaches approximately the same level • An early deep learning approach using a combination CNN+LSTM architecture that outperformed most reported results at that time (Taghipour and Ng, 2016). • Two recent results using traditi"
2020.bea-1.15,P19-1285,0,0.0286844,"t without finetuning, with reduced hardware requirements. But the greatest recent innovation has been contextual word embeddings, based on deep neural networks and in particular, Transformers. Rather than encoding a word’s semantics as a static vector, these models adjust the representation of words based on their context in new documents. With multiple layers and sophisticated attention mechanisms (Bahdanau et al., 2015), these newer models have outperformed the state-of-the-art on numerous tasks, and are currently the most accurate models on a very wide range of tasks (Vaswani et al., 2017; Dai et al., 2019). The most popular architecture, BERT, produces a 768dimensional final embedding based on a network with over 100 million total parameters in 12 layers; pre-trained models are available for open source use (Devlin et al., 2019). 3.1 Bag-of-Words Representations The simplest features for document classification tasks, “bag-of-words,” extracts surface N -grams of length 1-2 with “one-hot” binary values indicating presence or absence in a document. In prior AES results, this representation is surprisingly effective, and can be improved with simple extensions: N -grams based on part-of-speech tags"
2020.bea-1.15,P84-1044,0,0.227501,"Missing"
2020.bea-1.15,N19-1423,0,0.16245,"g (AES) mimics the judgment of educators evaluating the quality of student writing. Originally used for summative purposes in standardized testing and the GRE (Chen et al., 2016), these systems are now frequently found in classrooms (Wilson and Roscoe, 2019), typically enabled by training data scored on reliable rubrics to give consistent and clear goals for writers (Reddy and Andrade, 2010). More broadly, the natural language processing (NLP) research community in recent years has been dominated by deep neural network research, in particular, the Transformer architecture popularized by BERT (Devlin et al., 2019). These models use large volumes of existing text data to pre-train multilayer neural networks with context-sensitive meaning of, and relations between, words. The models, which often consist of over 100 million parameters, are then fine-tuned to a specific new labeled dataset and used for classification, generation, or structured prediction. 2 Background In AES, student essays are scored either on a single holistic scale, or analytically following a rubric that breaks out subscores based on “traits.” These scores are almost always integer-valued, and almost universally have fewer than 10 poss"
2020.bea-1.15,W17-1605,0,0.06,"Missing"
2020.bea-1.15,P19-1356,0,0.0221602,"l Linguistics A loss function, propagating backward to the network, allows the model to learn relationships between the class labels in the new data and the contextual meaning of the words in the text. A learning rate determines the amount of change to a model’s parameters. Extensive results have shown that careful control of the learning rate in a curriculum can produce an effective fine-tuning process (Smith, 2018). While remarkably effective, our community is only just beginning to identify exactly what is learned in this process; research in “BERT-ology” is ongoing (Kovaleva et al., 2019; Jawahar et al., 2019; Tenney et al., 2019). These neural models are just starting to be used in machine learning for AES, especially as an intermediate representation for automated essay feedback (Fiacco et al., 2019; Nadeem et al., 2019). End-to-end neural AES models are in their infancy and have only seen exploratory studies like Rodriguez et al. (2019); to our knowledge, no commercial vendor yet uses Transformers as the representation for high-stakes automated scoring. as many as 60 points (Shermis, 2014). In most contexts, students respond to “prompts,” a specific writing activity with predefined content. Wor"
2020.bea-1.15,W19-4446,1,0.801189,"Missing"
2020.bea-1.15,P18-1100,0,0.203967,"Missing"
2020.bea-1.15,W19-4450,0,0.235006,"determines the amount of change to a model’s parameters. Extensive results have shown that careful control of the learning rate in a curriculum can produce an effective fine-tuning process (Smith, 2018). While remarkably effective, our community is only just beginning to identify exactly what is learned in this process; research in “BERT-ology” is ongoing (Kovaleva et al., 2019; Jawahar et al., 2019; Tenney et al., 2019). These neural models are just starting to be used in machine learning for AES, especially as an intermediate representation for automated essay feedback (Fiacco et al., 2019; Nadeem et al., 2019). End-to-end neural AES models are in their infancy and have only seen exploratory studies like Rodriguez et al. (2019); to our knowledge, no commercial vendor yet uses Transformers as the representation for high-stakes automated scoring. as many as 60 points (Shermis, 2014). In most contexts, students respond to “prompts,” a specific writing activity with predefined content. Work in natural language processing and speech evaluation has used advanced features like discourse coherence (Wang et al., 2013) and argument extraction (Nguyen and Litman, 2018); for proficient writers in professional s"
2020.bea-1.15,D19-1445,0,0.0223304,"iation for Computational Linguistics A loss function, propagating backward to the network, allows the model to learn relationships between the class labels in the new data and the contextual meaning of the words in the text. A learning rate determines the amount of change to a model’s parameters. Extensive results have shown that careful control of the learning rate in a curriculum can produce an effective fine-tuning process (Smith, 2018). While remarkably effective, our community is only just beginning to identify exactly what is learned in this process; research in “BERT-ology” is ongoing (Kovaleva et al., 2019; Jawahar et al., 2019; Tenney et al., 2019). These neural models are just starting to be used in machine learning for AES, especially as an intermediate representation for automated essay feedback (Fiacco et al., 2019; Nadeem et al., 2019). End-to-end neural AES models are in their infancy and have only seen exploratory studies like Rodriguez et al. (2019); to our knowledge, no commercial vendor yet uses Transformers as the representation for high-stakes automated scoring. as many as 60 points (Shermis, 2014). In most contexts, students respond to “prompts,” a specific writing activity with p"
2020.bea-1.15,W14-1712,0,0.0152599,"s like Rodriguez et al. (2019); to our knowledge, no commercial vendor yet uses Transformers as the representation for high-stakes automated scoring. as many as 60 points (Shermis, 2014). In most contexts, students respond to “prompts,” a specific writing activity with predefined content. Work in natural language processing and speech evaluation has used advanced features like discourse coherence (Wang et al., 2013) and argument extraction (Nguyen and Litman, 2018); for proficient writers in professional settings, automated scaffolds like grammatical error detection and correction also exist (Ng et al., 2014). Natural language processing has historically used n-gram bag-of-words features to predict labels for documents. These were the standard representation of text data for decades and are still in widespread use (Jurafsky and Martin, 2014). In the last decade, the field moved to word embeddings, where words are represented not as a single feature but as dense vectors learned from large unsupervised corpora. While early approaches to dense representations using latent semantic analysis have been a major part of the literature on AES (Foltz et al., 2000; Miller, 2003), these were corpus-specific r"
2020.bea-1.15,D14-1162,0,0.0986001,"hese were the standard representation of text data for decades and are still in widespread use (Jurafsky and Martin, 2014). In the last decade, the field moved to word embeddings, where words are represented not as a single feature but as dense vectors learned from large unsupervised corpora. While early approaches to dense representations using latent semantic analysis have been a major part of the literature on AES (Foltz et al., 2000; Miller, 2003), these were corpus-specific representations. In contrast, recent work is general-purpose, resulting in offthe-shelf representations like GloVe (Pennington et al., 2014). This allows similar words to have approximately similar representations, effectively managing lexical sparsity. 3 NLP for Automated Essay Scoring To date, there are no best practices on finetuning Transformers for AES; in this section we present options. We begin with a classical baseline of traditional bag-of-words approaches and noncontextual word embeddings, used with Na¨ıve Bayes and logistic regression classifiers, respectively. We then describe three curriculum learning options for fine-tuning BERT using AES data based on broader best practices. We end with two approaches based on BERT"
2020.bea-1.15,W19-4302,0,0.103144,"niors; datasets #3 and 4 were responses to specific texts while others were open-ended; and scores in dataset #2 was actually scored on two separate traits, the second of which is often discarded in followup work (as it is here). Our work here does not specifically isolate effects of these differences that would lead to discrepancies in performance or in modeling behavior. titioners in low-resource settings may not have access to appropriate cloud computing environments for these techniques. Previous work has described a compromise approach for using Transformer models without fine-tuning. In Peters et al. (2019), the authors describe a new pipeline. Document texts are processed with an untuned BERT model; the final activations from network on the [CLS] token are then used directly as contextual word embeddings. This 768-dimensional feature vector represents the full document, and is used as inputs for a linear classifier. In the education context, a similar approach was described in Nadeem et al. (2019) as a baseline for evaluation of language-learner essays. This process allows us to use the world knowledge embedded in BERT without requiring fine-tuning of the model itself, and without need for GPUs"
2020.bea-1.15,D19-1250,0,0.0577589,"Missing"
2020.bea-1.15,P19-1355,0,0.0515566,"Missing"
2020.bea-1.15,D15-1049,0,0.219219,"ublished claims of speed 156 other domains. We prioritize three major areas: domain transfer, style, and fairness. In each we cite specific past work that indicates a plausible path forward for research. 6.1 A major challenge in AES is the inability of prompt-specific models to generalize to new essay topics (Attali et al., 2010; Lee, 2016). Collection of new prompt-specific training sets, with reliable scores, continues to be one of the major stumbling blocks to expansion of AES systems in curricula (Woods et al., 2017). Relatively few researchers have made progress on generic essay scoring: Phandi et al. (2015) introduces a Bayesian regression approach that extracts N -gram features then capitalizes on correlated features across prompts. Jin et al. (2018) shows promising prompt-independent results using an LSTM architecture with surface and part-of-speech N -gram inputs, underperforming prompt-specific models by relatively small margins across all ASAP datasets. But in implementations, much of the work of practitioners is based on workarounds for prompt-specific models; Wilson et al. (2019), for instance, describes psychometric techniques for measuring generic writing ability across a small sample o"
2020.bea-1.15,D16-1193,0,0.104359,"n AES uses non-contextual word vectors: Cozma et al. (2018). In this implementation, they do use word2vec, but rather than use word embeddings directly they first cluster words into a set of 500 “embedding clusters.” Words that appear in texts are then counted in the feature vector as the centroid of that cluster - in effect, creating a 500-dimensional bag-of-words model. Our results would suggest that fine-tuning with BERT also reaches approximately the same level • An early deep learning approach using a combination CNN+LSTM architecture that outperformed most reported results at that time (Taghipour and Ng, 2016). • Two recent results using traditional nonneural models: Woods et al. (2017), which uses n-gram features in an ordinal logistic regression, and Cozma et al. (2018), which uses a mix of string kernels and word2vec embeddings in a support vector regression. • Rodriguez et al. (2019), the one previouslypublished work that attempts AES with a variety of pretrained neural models, including BERT and the similar XLNet (Yang et al., 2019), with numerous alternate configurations and training methods. We report their result with a baseline BERT fine-tuning process, as well as their best-tuned model af"
2020.bea-1.15,P18-1080,1,0.807214,"descriptive, or forceful.” This critique is valid: research on machine translation, for instance, has shown that writer style is not preserved across languages (Rabinovich et al., 2017). There is uncharted territory for AES to adapt to individual writer styles and give feedback based on individual writing rather than prompt-specific exemplars. Natural language understanding researchers now argue that “...style is formed by a complex combination of different stylistic factors” (Kang and Hovy, 2019); Stylespecific natural language generation has shown promise in other domains (Hu et al., 2017; Prabhumoye et al., 2018) and has been extended not just to individual preferences but also to overlapping identities based on attitudes like sentiment and personal attributes like gender (Subramanian et al.). Early work suggests that style-specific models do see major improvements when shifting to high-dimensionality Transformer architectures (Keskar et al., 2019). This topic bridges an important gap: for assessment, research has shown that “authorial voice” has measurable outcomes on writing impact (Matsuda and Tardy, 2007), while individual expression is central to decades of pedagogy (Elbow, 1987). Moving the fiel"
2020.bea-1.15,P19-1452,0,0.0306382,"unction, propagating backward to the network, allows the model to learn relationships between the class labels in the new data and the contextual meaning of the words in the text. A learning rate determines the amount of change to a model’s parameters. Extensive results have shown that careful control of the learning rate in a curriculum can produce an effective fine-tuning process (Smith, 2018). While remarkably effective, our community is only just beginning to identify exactly what is learned in this process; research in “BERT-ology” is ongoing (Kovaleva et al., 2019; Jawahar et al., 2019; Tenney et al., 2019). These neural models are just starting to be used in machine learning for AES, especially as an intermediate representation for automated essay feedback (Fiacco et al., 2019; Nadeem et al., 2019). End-to-end neural AES models are in their infancy and have only seen exploratory studies like Rodriguez et al. (2019); to our knowledge, no commercial vendor yet uses Transformers as the representation for high-stakes automated scoring. as many as 60 points (Shermis, 2014). In most contexts, students respond to “prompts,” a specific writing activity with predefined content. Work in natural language"
2020.bea-1.15,E17-1101,0,0.0152756,"ises a host of questions about these topics specifically in the context of AES, asking how algorithmic intervention can produce strong writers rather than merely good essays: “revision, as adjudicated by the platform, is [...] a re-direction toward the predetermined shape of the ideal written form [...] a puzzle-doer recursively consulting the image on the puzzlebox, not that of author returning to their words to make them more lucid, descriptive, or forceful.” This critique is valid: research on machine translation, for instance, has shown that writer style is not preserved across languages (Rabinovich et al., 2017). There is uncharted territory for AES to adapt to individual writer styles and give feedback based on individual writing rather than prompt-specific exemplars. Natural language understanding researchers now argue that “...style is formed by a complex combination of different stylistic factors” (Kang and Hovy, 2019); Stylespecific natural language generation has shown promise in other domains (Hu et al., 2017; Prabhumoye et al., 2018) and has been extended not just to individual preferences but also to overlapping identities based on attitudes like sentiment and personal attributes like gender"
2020.bea-1.15,W19-4411,0,0.0208928,"ned models are available for open source use (Devlin et al., 2019). 3.1 Bag-of-Words Representations The simplest features for document classification tasks, “bag-of-words,” extracts surface N -grams of length 1-2 with “one-hot” binary values indicating presence or absence in a document. In prior AES results, this representation is surprisingly effective, and can be improved with simple extensions: N -grams based on part-of-speech tags (of length 2-3) to capture syntax independent of content, and character-level N -grams of length 34, to provide robustness to misspellings (Woods et al., 2017; Riordan et al., 2019). This highdimensional representation typically has a cutoff threshold where rare tokens are excluded: in our implementation, we exclude N -grams without at For document classification, BERT is “finetuned” by adding a final layer at the end of the Transformer architecture, with one output neuron per class label. When learning from a new set of labeled training data, BERT evaluates the training set multiple times (each pass is called an epoch). 152 least 5 occurrences in training data. Even after this reduction, this is a sparse feature space with thousands of dimensions. For learning with bago"
2020.bea-1.15,N13-1101,0,0.028057,"ally as an intermediate representation for automated essay feedback (Fiacco et al., 2019; Nadeem et al., 2019). End-to-end neural AES models are in their infancy and have only seen exploratory studies like Rodriguez et al. (2019); to our knowledge, no commercial vendor yet uses Transformers as the representation for high-stakes automated scoring. as many as 60 points (Shermis, 2014). In most contexts, students respond to “prompts,” a specific writing activity with predefined content. Work in natural language processing and speech evaluation has used advanced features like discourse coherence (Wang et al., 2013) and argument extraction (Nguyen and Litman, 2018); for proficient writers in professional settings, automated scaffolds like grammatical error detection and correction also exist (Ng et al., 2014). Natural language processing has historically used n-gram bag-of-words features to predict labels for documents. These were the standard representation of text data for decades and are still in widespread use (Jurafsky and Martin, 2014). In the last decade, the field moved to word embeddings, where words are represented not as a single feature but as dense vectors learned from large unsupervised cor"
2020.bea-1.15,2020.tacl-1.54,0,0.0204584,"oaches, rather than resolved (Gonen and Goldberg, 2019). What these questions offer, though, is a wellspring of new and innovative technical research. Developers of learning analytics software, including AES, are currently encouraged to focus on scalable experimental evidence of efficacy for learning outcomes (Saxberg, 2017), rather than focus on specific racial or gender bias, or other equity outcomes that are more difficult to achieve through engineering. But Transformer architectures are nuanced enough to capture immense world knowledge, producing a rapid increase in explainability in NLP (Rogers et al., 2020). Meanwhile, in the field of learning analytics, a burgeoning new field of fairness studies are learning how to investigate these issues in algorithmic educational systems (Mayfield et al., 2019; Holstein and Doroudi, 2019). Outside of technology applications but in writing assessment more broadly, fairness is also a rich topic with a history of literature to learn from (Poe and Elliot, 2019). Researchers at the intersection of both these fields have an enormous open opportunity to better understand AES in the context fairness, using the latest tools not just to build reliable scoring but to a"
2020.bea-1.15,W12-2004,0,0.580486,"Missing"
2020.bea-1.15,D17-1323,0,0.0280604,"ike word count (Perelman, 2014). Fairness Years ago, researchers suggested that demographic bias is worth checking in AES systems (Williamson et al., 2012). But years later, the field has primarily reported fairness experiments on simulated data, and shared toolkits for measuring bias, rather than results on real-world AES implementations or high-stakes data (Madnani et al., 2017; Loukina et al., 2019). Prompted by social scientists (Noble, 2018), NLP researchers have seen a renaissance of fairness research based on the flaws in default implementations of Transformers (Bolukbasi et al., 2016; Zhao et al., 2017, 2018). These works typicallly seek to reduce the amplification of bias in pretrained models, starting with easy-to-measure proof that demographic bias can be “removed” from word embedding spaces. But iterating on inputs to algorithmic classifiers – precisely the intended use case of formative eeedback for writers! – can reduce the efficacy of “de-biasing” (Liu et al., 2018; Dwork and Ilvento, 2019). More recent research has shown that bias may simply be masked by these approaches, rather than resolved (Gonen and Goldberg, 2019). What these questions offer, though, is a wellspring of new and"
2020.bea-1.15,D18-1521,0,0.029849,"Missing"
2020.coling-main.1,K16-1002,0,0.065493,"en s can be over-shadowed by he and the generator may not be able to pay attention to s. Hence it is important to choose comparable dimensions for s and he . But this increases the size of model considerably and could be quite costly. Linear transform avoids these issues and performs better than the other two techniques for Hoang et al. (2016). 2.2 Stochastic Changes Kingma and Welling (2014) introduce variational auto-encoder, where you can stochastically draw a continuous latent variable z from a Gaussian distribution. The initialization of the generator h0 is based on this latent variable. Bowman et al. (2016) use this concept for generating sentences from this continuous latent representation. This process of changing the encoder state he can only be used with Kullback-Leibler (KL) Divergence training objective described in §6.2. In (Wang et al., 2019b), Variational Auto-Encoder (VAE) is used to guide the generation process with topics of a document. A gaussian mixture model is used to incorporate topics into latent variables. In (Xu et al., 2019), VAE is used to control for sentiment attribute in style transfer task by constraining the posterior mean to a learned probability simplex. Such a desig"
2020.coling-main.1,W19-3402,1,0.901601,"text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and politeness of emails (Madaan et al., 2020). Report generation can be controlled by pulling disparate source documents into a coherent unified whole, which can use a shared set of sources such as Wikipedia article generation (Liu et al., 2018; Prabhumoye et al., 2019). Although there is a large body of prior work in controllable text generation, there is no unifying theme. Each work addresses a specific task in a specific context. In this paper we o"
2020.coling-main.1,N19-1423,0,0.01846,"l., 2019). This type of loss design encounters increasing number of loss terms depending on the number of styles. The third way to motivate this loss term is to discriminating between a sentence x from data which belongs to style s1 and a generated sentence x ˆ which belongs to the same style s1 (Yang et al., 2018). Again, you would need as many loss terms as the number of styles in this case. All of these works use cross entropy loss function to measure their losses. Hu et al. (2019a) use a classifier based loss in the visual storytelling task. The classifier is a pre-trained language model (Devlin et al., 2019) used to measure the coherence between generated sentences of the story. Particularly, the classifier takes as input two sentences at a time x ˆ1 and x ˆ2 and outputs a binary label which indicates if x ˆ2 follows x ˆ1 . In this case, the control variable is coherence in stories which is used to guide the generator to produce consistent sentences. 6.4 Task Specific Loss Depending on the end task and the attribute to be controlled, you can design different loss objectives to ensure that generations abide by the target attributes. Strategy Loss: Zhou et al. (2020) use a dialogue strategy based o"
2020.coling-main.1,P18-1082,0,0.0417422,"tive candidates which is based on repeating tokens or n-grams and frequent tokens (Welleck et al., 2020). This set is updated at each time step as tokens are generated. This works at both token and sequence level and the objective tries to minimize the repetitions in generations. This is used at train time in augmentation with the maximum likelihood objective and can be used for any task. Decoding strategies: These strategies are not used as a loss objective during training. Many of these objectives rely on post-hoc decoding strategies such as stochastic decoding which include Top k-sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2020), or beam search variants (Paulus et al., 2018; Kulikov et al., 2019; Vijayakumar et al., 2018; Holtzman et al., 2018). Specifically, we discuss the Diversity-Promoting objective which is used to generate a varied set of sentences given similar inputs. Particularly, Li et al. (2016a) use Maximum Mutual Information (MMI) as an objective function for the dialogue response generation task. Most generation systems use maximum likelihood objective but this objective additionally tries to reduce the proportion of generic responses. It is given by: ˆ = argmax"
2020.coling-main.1,N19-1320,0,0.0137912,"tic and attribute compatible sentences. The adversarial loss tries to match the distribution of sentence and attribute vector pairs (x, s) where the sentence can either be a real or generated sentence. Similarly, in (Shen et al., 2017), a two discriminator losses in the style transfer task. Each discriminator is trained to distinguish between a sentence which came from the real target attribute distribution and a sentence that was transferred from source to target attribute. This work uses Professor-Forcing (Lamb et al., 2016) to match the hidden states of the generator and the discriminator. Gong et al. (2019) also control the output latent space by providing different types of rewards like style reward, semantic reward and fluency reward in the reinforcement learning setup. The discriminator used to obtain the adversarial loss has to be jointly trained with the generator. 7 5.3 Arithmetic or Linear Transform Hoang et al. (2016) demonstrate three simple ways of changing the output ot of an RNN to control for meta information like topic, keywords etc. The three ways demonstrated in (Hoang et al., 2016) are: (1) addition, where the modified output ˜ ot is ˜ ot = ot + s, (2) concatenation, where the m"
2020.coling-main.1,W19-8101,0,0.0266223,"be defined at each time step of the definition generation process. Unfortunately, for this task, this technique has not proved to be effective compared to other techniques of controlling the generation. Zhou et al. (2018) concatenate the hidden representation of the external source of information s to each time step of dialogue response generation. Similarly, Prabhumoye et al. (2019) also concatenate the hidden representation of the external source of information s to each time step of Wikipedia update generation process. This technique did not achieve impressive results in this work as well. Harrison et al. (2019) concatenate a side constraint s which represents style and personality into the generation process. For this task of generating language from meaning representations with stylistic variation, this method performed better than conditioning the encoder with side constraint in terms of BLEU metric. Chandu et al. (2019) also concatenate the personality representation P at each time step of the story generation process. This is used to control the personality of the visual stories. In addition to concatenation, this work proposes to modify the sequential input as x ˜t = xt − S + P (here S denotes"
2020.coling-main.1,N16-1149,0,0.402404,"nformation from external sources to dialogue context to generate dialogue responses. Chandu et al. (2019) concatenate personality representation P derived from a separate corpus to generate visual stories. They also experiment with a simple arithmetic operation on he given by h0 = he − S + P to get the initialization of the generator (here S denotes the average representation of the story). They observed that while concatenation technique is better at preserving the meaning of the generated story, the arithmetic operation provides a better signal of the personality for the generation process. Hoang et al. (2016) uses both the concatenation technique as well as performs a linear transform of s to obtain h0 for language modelling task. The control vectors in this case represents meta data such as key-words, topics etc. In case of the linear transform h0 = tanh(W1 he + W2 s + b). The paper also explores adding the control vector to the encoder representation (h0 = he + s). In case of addition, the resulting h0 would be averaged representation of the input representation he and s. Information could be lost in this case as control is not explicit. In case of concatenation, if the size of the control vecto"
2020.coling-main.1,P18-1152,0,0.0211633,"re generated. This works at both token and sequence level and the objective tries to minimize the repetitions in generations. This is used at train time in augmentation with the maximum likelihood objective and can be used for any task. Decoding strategies: These strategies are not used as a loss objective during training. Many of these objectives rely on post-hoc decoding strategies such as stochastic decoding which include Top k-sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2020), or beam search variants (Paulus et al., 2018; Kulikov et al., 2019; Vijayakumar et al., 2018; Holtzman et al., 2018). Specifically, we discuss the Diversity-Promoting objective which is used to generate a varied set of sentences given similar inputs. Particularly, Li et al. (2016a) use Maximum Mutual Information (MMI) as an objective function for the dialogue response generation task. Most generation systems use maximum likelihood objective but this objective additionally tries to reduce the proportion of generic responses. It is given by: ˆ = argmax {logp(T|S) − λlogp(T)} T T ˆ is the generated target sequence, T is the reference target sequence and S is the source sequence. where T The second term control"
2020.coling-main.1,P19-3027,0,0.044925,"Missing"
2020.coling-main.1,P19-1041,0,0.0160744,"larly, the adversarial loss is also used in (Wang et al., 2019a) to control the latent representation h0 for style attributes. In (Romanov et al., 2019), an adversarial loss is used to ensure that the meaning representation m does not carry any style signals. The adversarial loss is obtained by training a discriminator which takes as input a representation m and indicates if it carries the target style signal. Similarly, this work also employs a motivator loss which is the opposite of the adversarial loss to ensure that the style representation f actually does carry the stylistic information. John et al. (2019) use multiple losses to control the style and content information represented in h0 . The discriminator which provides external feedback has to be jointly trained with the generator. This technique can be useful with the decompose technique to ensure that the decomposed sub-spaces represent the desired control attributes. 3 Sequential Input In this section we discuss the different techniques which can be used to manipulate the sequential input xt to the decoder at each time step. xt here is used to denote the word embedding of the token at time step t. This is marked as position (2) in Figure"
2020.coling-main.1,D16-1032,0,0.019386,"ored LSTM, which 5 controls style representation in image caption task. The parameters of the LSTM module which are responsible to transform the input xt are factored into three components U, S and V. The operations of the input (it ), forget (ft ) and output gate (ot ) are given by: it = sigmoid(Uix Six Vix xt + Wih ht−1 ) ft = sigmoid(Uf x Sf x Vf x xt + Wf h ht−1 ) ot = sigmoid(Uox Sox Vox xt + Woh ht−1 ) ˜ ct = tanh(Ucx Scx Vcx xt + Wch ht−1 ) Particularly, the matrix set {S} is specific to each style in the task and is responsible to capture the underlying style features in the data. In (Kiddon et al., 2016), the GRU unit is modified to accommodate extra inputs - goal g and agenda ˜ t is given by: items Etnew in the recipe generation task. The operation of the new component h ˜ t = tanh(Wh xt + rt Uh ht−1 + st Yg + qt (1TL ZEnew h )T ) t where st is a goal select gate and qt is a item select gate. With this modification, the generation process is controlled for the items to be generation in the recipe and the goal. Wen et al. (2015) adapt the LSTM to control the dialogue act information in the generation process. The operation to compute the cell value ct is given by: ct = ft ct−1 + it ˜ ct + tan"
2020.coling-main.1,W19-8609,0,0.0169266,"his set is updated at each time step as tokens are generated. This works at both token and sequence level and the objective tries to minimize the repetitions in generations. This is used at train time in augmentation with the maximum likelihood objective and can be used for any task. Decoding strategies: These strategies are not used as a loss objective during training. Many of these objectives rely on post-hoc decoding strategies such as stochastic decoding which include Top k-sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2020), or beam search variants (Paulus et al., 2018; Kulikov et al., 2019; Vijayakumar et al., 2018; Holtzman et al., 2018). Specifically, we discuss the Diversity-Promoting objective which is used to generate a varied set of sentences given similar inputs. Particularly, Li et al. (2016a) use Maximum Mutual Information (MMI) as an objective function for the dialogue response generation task. Most generation systems use maximum likelihood objective but this objective additionally tries to reduce the proportion of generic responses. It is given by: ˆ = argmax {logp(T|S) − λlogp(T)} T T ˆ is the generated target sequence, T is the reference target sequence and S is th"
2020.coling-main.1,N16-1014,0,0.33333,"ion Controllable text generation is the task of generating natural sentences whose attributes can be controlled. The attributes to control can range from being stylistic such politeness, sentiment, formality, etc.; demographic attributes of the person writing the text such as gender, age, etc.; content such as information, keywords, entities, etc.; ordering of information, events, like plot summaries etc. Controlling various attributes of text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and poli"
2020.coling-main.1,P16-1094,0,0.193691,"ion Controllable text generation is the task of generating natural sentences whose attributes can be controlled. The attributes to control can range from being stylistic such politeness, sentiment, formality, etc.; demographic attributes of the person writing the text such as gender, age, etc.; content such as information, keywords, entities, etc.; ordering of information, events, like plot summaries etc. Controlling various attributes of text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and poli"
2020.coling-main.1,D18-1441,0,0.0231731,"es that lead to better negotiations. This loss captures the probability of a particular strategy occurring for the next utterance given the dialogue history. It guides the generator to align the responses with particular strategies. Coverage Loss: Generating repeated words or phrases is a common problem for text generation systems, and this becomes especially pronounced for multi-sentence text generation task such as abstractive document summarization. See et al. (2017) introduce a coverage loss which penalizes repeatedly attending to the same locations of the source document. Structure loss: Li et al. (2018) introduce two new loss objectives structural compression and structural coverage based on sentence-level attention. These objectives are specially designed for the task of abstractive document summarization. structural compression is used to generate a sentence by compressing several specific source sentences and structural coverage is used to cover more salient information of the original document. These objectives leverage document structure in document summarization, and 9 explore the effectiveness of capturing structural properties of document summarization by regularization of the genera"
2020.coling-main.1,Q18-1005,0,0.0454012,"ntrol for sentiment attribute in style transfer task by constraining the posterior mean to a learned probability simplex. Such a design of controllable text generation works when the control attributes can be represented as latent variables for example style, topics, strategies etc. This design is difficult to work for content grounded text generation tasks where specific information, keywords or entities have to guide the generation process. 3 2.3 Decompose The encoder representation he can be decomposed into multiple subspaces, each of which signifies a different attribute to be controlled. Liu and Lapata (2018) split the encoder representation he into two components, one which represents the structure in the document and the other represents the semantic information. This formulation was used by (Balachandran et al., 2020) for controlling structure in abstractive summarization. This work performs the split with respect to the dimensions of he . The method forces the first n dimensions of he to capture meaning and the latter to capture structure. Balachandran et al. (2020) also show quantitative and qualitative analysis on the types of structures of documents learnt by this technique. Romanov et al."
2020.coling-main.1,D15-1166,0,0.0609805,"marked as position (4) in Figure 1. 5.1 Attention Attention is the most popular way of guiding the generation process. It is typically used to guide the generation process to focus on the source sequence (Bahdanau et al., 2015). The attention calculating module takes as input the current hidden state ht of the generator at each time step t. The aim of this module is to determine a context vector ct that captures relevant source-side information to help predict the token x ˆt . In case of global attention, all the hidden states of the encoder are considered to calculate the context vector ct (Luong et al., 2015). This faces the the downside of expensive calculation especially for longer source sequences like documents. To overcome this challenge, local attention only chooses to focus only on a small subset of the source positions per target word. In this case, ct is calculated over a window of size D of the source hidden states. Vaswani et al. (2017) view attention as a mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a com"
2020.coling-main.1,2020.acl-main.169,1,0.834412,"rious aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and politeness of emails (Madaan et al., 2020). Report generation can be controlled by pulling disparate source documents into a coherent unified whole, which can use a shared set of sources such as Wikipedia article generation (Liu et al., 2018; Prabhumoye et al., 2019). Although there is a large body of prior work in controllable text generation, there is no unifying theme. Each work addresses a specific task in a specific context. In this paper we outline a new schema which connects prior work and provides an insight into various aspects of controllable text generation. The schema contains five modules that cover the overall generation"
2020.coling-main.1,Q18-1027,0,0.02249,"attributes can be controlled. The attributes to control can range from being stylistic such politeness, sentiment, formality, etc.; demographic attributes of the person writing the text such as gender, age, etc.; content such as information, keywords, entities, etc.; ordering of information, events, like plot summaries etc. Controlling various attributes of text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and politeness of emails (Madaan et al., 2020). Report generation can be controlled by pulling di"
2020.coling-main.1,W18-1505,0,0.025168,"ontrolling various attributes of text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and politeness of emails (Madaan et al., 2020). Report generation can be controlled by pulling disparate source documents into a coherent unified whole, which can use a shared set of sources such as Wikipedia article generation (Liu et al., 2018; Prabhumoye et al., 2019). Although there is a large body of prior work in controllable text generation, there is no unifying theme. Each work addresses a specific task in a s"
2020.coling-main.1,P18-1080,1,0.859201,"you to approximate the posterior distribution of the control variables in the latent z-space. 6.3 Classifier Loss This loss is specifically used to ensure that the generated tokens x ˆ comply with the control attributes s. Note the difference between this loss and the external feedback loss used for the external input module and the output module is that this loss operates at the token level and the external feedback loss works on the latent hidden representations. In case of style transfer task, this loss is used to guide the generation process to output the target style tokens. Some works (Prabhumoye et al., 2018; Sudhakar et al., 2019; Hu et al., 2017) use this loss to discriminate between all the styles in their task (one verses all fashion). This type of design will suffer from low accuracy scores when the number of styles increases. To counter this problem, this loss can be setup to calculate if the generated sentence x ˆ belongs to style s1 or not and similarly to calculate another separate loss term for each style (Chandu et al., 2019). This type of loss design encounters increasing number of loss terms depending on the number of styles. The third way to motivate this loss term is to discriminat"
2020.coling-main.1,N19-1269,1,0.918641,"18), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and politeness of emails (Madaan et al., 2020). Report generation can be controlled by pulling disparate source documents into a coherent unified whole, which can use a shared set of sources such as Wikipedia article generation (Liu et al., 2018; Prabhumoye et al., 2019). Although there is a large body of prior work in controllable text generation, there is no unifying theme. Each work addresses a specific task in a specific context. In this paper we outline a new schema which connects prior work and provides an insight into various aspects of controllable text generation. The schema contains five modules that cover the overall generation pipeline and provide an understanding of the effect of each component on the generation process. Prior work has focused on specific parts of the schema that we outline here and we provide insights into their similarities. We"
2020.coling-main.1,N18-1012,0,0.0210764,"+ rt Uh ht−1 + st Yg + qt (1TL ZEnew h )T ) t where st is a goal select gate and qt is a item select gate. With this modification, the generation process is controlled for the items to be generation in the recipe and the goal. Wen et al. (2015) adapt the LSTM to control the dialogue act information in the generation process. The operation to compute the cell value ct is given by: ct = ft ct−1 + it ˜ ct + tanh(Wd dt ) The dialogue act representation dt is build using another LSTM cell. RNNs, LSTMs and GRUs are commonly used to model controllable text generation tasks (Prabhumoye et al., 2019; Rao and Tetreault, 2018; See et al., 2017; Zhou et al., 2018; Fu et al., 2018). Most of these variants still have trouble remembering long sequences and are hence commonly used with attention mechanism (§5.1) on the source sequence. 4.2 Transformer Transformers are proposed by (Vaswani et al., 2017) and they rely on attention mechanism to draw global dependencies between input and output. The Transformer uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder stacks N identical layers, each of which has two sub-layers. The first sub-layer is a multi-head self-"
2020.coling-main.1,N19-1088,0,0.385028,"d Lapata (2018) split the encoder representation he into two components, one which represents the structure in the document and the other represents the semantic information. This formulation was used by (Balachandran et al., 2020) for controlling structure in abstractive summarization. This work performs the split with respect to the dimensions of he . The method forces the first n dimensions of he to capture meaning and the latter to capture structure. Balachandran et al. (2020) also show quantitative and qualitative analysis on the types of structures of documents learnt by this technique. Romanov et al. (2019) decompose the encoder representation he into a form vector f and a meaning vector m. During the training phase, a discriminator enforces m to not carry any information about the form using an adversarial loss and a motivator is used for a motivational loss that encourages f to carry the information about the form. The generation process can then be guided to adhere to the desired target form. As opposed to splitting he with respect to dimensions, this work learns subspaces Wm and Wf given by m = tanh(Wm he + bm ) and f = tanh(Wf he + bf ) respectively. When he is projected on Wm , it yields t"
2020.coling-main.1,P17-1099,0,0.267564,"t (1TL ZEnew h )T ) t where st is a goal select gate and qt is a item select gate. With this modification, the generation process is controlled for the items to be generation in the recipe and the goal. Wen et al. (2015) adapt the LSTM to control the dialogue act information in the generation process. The operation to compute the cell value ct is given by: ct = ft ct−1 + it ˜ ct + tanh(Wd dt ) The dialogue act representation dt is build using another LSTM cell. RNNs, LSTMs and GRUs are commonly used to model controllable text generation tasks (Prabhumoye et al., 2019; Rao and Tetreault, 2018; See et al., 2017; Zhou et al., 2018; Fu et al., 2018). Most of these variants still have trouble remembering long sequences and are hence commonly used with attention mechanism (§5.1) on the source sequence. 4.2 Transformer Transformers are proposed by (Vaswani et al., 2017) and they rely on attention mechanism to draw global dependencies between input and output. The Transformer uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder stacks N identical layers, each of which has two sub-layers. The first sub-layer is a multi-head self-attention mechanis"
2020.coling-main.1,D19-1322,0,0.232117,". Computations over a sequence can be parallelized in this case and hence it is faster. The modifications made to the computing units of RNN mentioned in §4.1 which use parameters specific to control attributes such as style, dialog act etc. have not been explored with the transformers architecture. 4.3 Pre-trained models Recently pre-trained conditional language models are used for text generation like GPT (Radford et al., 2018), GPT2 (Radford et al., 2019), XLNet (Yang et al., 2019), etc. Several works have fine-tuned the pre-trained models for downstream controllable text generation tasks (Sudhakar et al., 2019; Dinan et al., 2018; Urbanek et al., 2019). The language modeling aspects of generation like fluency and grammaticality are already learnt if pre-trained models are used. These models are hard to fine-tune for sequence-to-sequence tasks such as machine translation, abstractive summarization etc. BART (Lewis et al., 2019) is a denoising autoencoder built with a sequence-tosequence model and is particularly effective when fine tuned for text generation. Alternatively, T5 (Raffel et al., 2019) treats every NLP problem as a “text-to-text” problem, i.e. taking text as input and producing new text"
2020.coling-main.1,D19-1062,0,0.0237007,"Missing"
2020.coling-main.1,N19-1015,0,0.249332,"m avoids these issues and performs better than the other two techniques for Hoang et al. (2016). 2.2 Stochastic Changes Kingma and Welling (2014) introduce variational auto-encoder, where you can stochastically draw a continuous latent variable z from a Gaussian distribution. The initialization of the generator h0 is based on this latent variable. Bowman et al. (2016) use this concept for generating sentences from this continuous latent representation. This process of changing the encoder state he can only be used with Kullback-Leibler (KL) Divergence training objective described in §6.2. In (Wang et al., 2019b), Variational Auto-Encoder (VAE) is used to guide the generation process with topics of a document. A gaussian mixture model is used to incorporate topics into latent variables. In (Xu et al., 2019), VAE is used to control for sentiment attribute in style transfer task by constraining the posterior mean to a learned probability simplex. Such a design of controllable text generation works when the control attributes can be represented as latent variables for example style, topics, strategies etc. This design is difficult to work for content grounded text generation tasks where specific inform"
2020.coling-main.1,W19-3620,0,0.0215457,"ot which is further projected on to the vocabulary space to predict the token x ˆt at each time step. (5) Training Objective module takes care of the loss functions used for training the generator. This schema provides an insight into the contributions of the various modules for controllable text generation. The main advantage of this schema is that it can be used with any algorithmic paradigm like sequence-to-sequence, adversarial methods, reinforcement learning, etc. The schema can also be used with non-autoregressive algorithms which may generate text using graphical structures like trees (Welleck et al., 2019; Guo et al., 2019). In this paper, we focus on how this schema can be used to describe controllable text generation focusing particularly on the use of autoregressive models. This work paves way to designing new architectures based on our schema. This can be done by identifying promising techniques for each module and then combining them. Our schema can also be potentially used for applying these techniques on new tasks of similar nature. It also provides a standardized framework to position and compare new architectures with existing techniques. The prior work on unifying text generation mod"
2020.coling-main.1,D15-1199,0,0.134428,"Missing"
2020.coling-main.1,P18-1205,0,0.273597,"s paper. 1 Introduction Controllable text generation is the task of generating natural sentences whose attributes can be controlled. The attributes to control can range from being stylistic such politeness, sentiment, formality, etc.; demographic attributes of the person writing the text such as gender, age, etc.; content such as information, keywords, entities, etc.; ordering of information, events, like plot summaries etc. Controlling various attributes of text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the f"
2020.coling-main.1,D18-1076,1,0.695608,"iment, formality, etc.; demographic attributes of the person writing the text such as gender, age, etc.; content such as information, keywords, entities, etc.; ordering of information, events, like plot summaries etc. Controlling various attributes of text generation has manifold applications. For instance in dialogue response generation task, work has been done in controlling persona (Zhang et al., 2018; Li et al., 2016b), controlling various aspects of the response such as politeness (Niu and Bansal, 2018), formality, authority etc, grounding the responses in external source of information (Zhou et al., 2018; Dinan et al., 2018; Ghazvininejad et al., 2018), and controlling topic sequence (Tang et al., 2019; Prabhumoye et al., 2020). Another application is story generation where you can control the ending (Peng et al., 2018), the persona (Chandu et al., 2019), the plot (Yao et al., 2019), and the topic sequence (Huang et al., 2019). Controllable text generation is also used to modulate the formality and politeness of emails (Madaan et al., 2020). Report generation can be controlled by pulling disparate source documents into a coherent unified whole, which can use a shared set of sources such as Wi"
2020.conll-1.46,2020.lrec-1.223,0,0.0219066,"l factors on users’ CS patterns across Spanglish and Hinglish. 2 Code-Switching Strategies Given that CS is used in very nuanced ways, researchers have been studying how people codeswitch, examining the switch-points of languages syntactically (Poplack, 1980; Solorio and Liu, 2008), prosodically (Fricke et al., 2016), lexically (Kootstra, 2012), pragmatically (Begum et al., 2016), and so forth. Many works have attempted to model code-switching text and speech from a statistical perspective (Garg et al., 2018a,b). Recent works and benchmarks such as Linguistic Codeswitching Evaluation (LinCE) (Aguilar et al., 2020) and GLUECoS (Khanuja et al., 2020) have provided a unified platform to evaluate CS data for various NLP tasks across various language pairs. Our work is in line with these recent efforts to provide NLP capabilities to users with diverse linguistic backgrounds. We extend the human–machine CS dialogue system by Ahn et al. (2020) to a new language pair of Hindi-English. In order to better understand the style and usage of languages in a code-switched utterance, we cluster and characterize these utterances by a set of predefined CS strategies. Previous works have mainly identified two commonly us"
2020.conll-1.46,2020.scil-1.32,1,0.521461,"mate goal to enable adaptive codeswitching dialogue agents, in this paper we study user accommodation, i.e., entrainment (Brennan 565 Proceedings of the 24th Conference on Computational Natural Language Learning, pages 565–577 c Online, November 19-20, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 and Clark, 1996) in CS human–machine dialogues. Our exploratory analysis of user accommodation will facilitate better development of dialogue agents which can eventually accommodate to users in return. To this end, we adopt a collaborative dialogue framework of Ahn et al. (2020), which converses with Spanish–English (Spanglish) bilinguals. To facilitate a more general analysis, we extend this framework to Hindi–English (Hinglish), a language pair which is typologically distinct from Spanglish and is spoken by millions of people. We begin by providing background on codeswitching (§2) and linguistic accommodation (§3) We then introduce our generalized bilingual dialogue system (§4). In §5, we describe our experimental setup for Hinglish data collection and discuss the data statistics. We later provide our exploratory analysis of language accommodation and other socio-l"
2020.conll-1.46,W18-3210,0,0.0239202,"le adjust their behaviors or speech styles to their conversational partners’ (Giles et al., 1973). Linguistic accommodation has proven to reduce interpersonal distance (Camilleri, 1996) and is correlated with dialogue success and engagement (Nenkova et al., 2008). Although well-studied in the monolingual dialogues (Brennan and Clark, 1996; Niederhoffer and Pennebaker, 2002), it is relatively new in the CS setting. Soto et al. (2018) found rate of code-switching to be accommodated in human–human Spanish-English dialogues. Choice of language when code-switching can also be adapted in dialogues (Bawa et al., 2018). Fricke et al. (2016) further discover that part-of-speech of a CS utterance may impact the following language choice. Our work adds to this field by studying accommodation of language choice for lexical classes. In terms of quantifying accommodation, we adapt a metric from Mizukami et al. (2016) to measure accommodation (we refer it to as global accommodation). Global accommodation extends the score proposed in Nenkova et al. (2008) by aggregating a speaker’s word usage across an entire dialogue and biases it relatively with other non-partners in the corpus.PFor two partners a and b, we deno"
2020.conll-1.46,L16-1260,0,0.0145913,"9 Hindi-English human–machine conversations, (3) adaptation of accommodation metrics and a corresponding analysis of accommodation of language style and choice in CS dialogues, and (4) an exploratory study of linguistic and socio-cultural factors on users’ CS patterns across Spanglish and Hinglish. 2 Code-Switching Strategies Given that CS is used in very nuanced ways, researchers have been studying how people codeswitch, examining the switch-points of languages syntactically (Poplack, 1980; Solorio and Liu, 2008), prosodically (Fricke et al., 2016), lexically (Kootstra, 2012), pragmatically (Begum et al., 2016), and so forth. Many works have attempted to model code-switching text and speech from a statistical perspective (Garg et al., 2018a,b). Recent works and benchmarks such as Linguistic Codeswitching Evaluation (LinCE) (Aguilar et al., 2020) and GLUECoS (Khanuja et al., 2020) have provided a unified platform to evaluate CS data for various NLP tasks across various language pairs. Our work is in line with these recent efforts to provide NLP capabilities to users with diverse linguistic backgrounds. We extend the human–machine CS dialogue system by Ahn et al. (2020) to a new language pair of Hindi"
2020.conll-1.46,D18-1346,1,0.835378,"language style and choice in CS dialogues, and (4) an exploratory study of linguistic and socio-cultural factors on users’ CS patterns across Spanglish and Hinglish. 2 Code-Switching Strategies Given that CS is used in very nuanced ways, researchers have been studying how people codeswitch, examining the switch-points of languages syntactically (Poplack, 1980; Solorio and Liu, 2008), prosodically (Fricke et al., 2016), lexically (Kootstra, 2012), pragmatically (Begum et al., 2016), and so forth. Many works have attempted to model code-switching text and speech from a statistical perspective (Garg et al., 2018a,b). Recent works and benchmarks such as Linguistic Codeswitching Evaluation (LinCE) (Aguilar et al., 2020) and GLUECoS (Khanuja et al., 2020) have provided a unified platform to evaluate CS data for various NLP tasks across various language pairs. Our work is in line with these recent efforts to provide NLP capabilities to users with diverse linguistic backgrounds. We extend the human–machine CS dialogue system by Ahn et al. (2020) to a new language pair of Hindi-English. In order to better understand the style and usage of languages in a code-switched utterance, we cluster and characterize"
2020.conll-1.46,P17-1162,0,0.0272605,"ally across turns within a single dialogue. For two partners a and b, we can formulate this metric as   local(a,b) (C) = P r TbC |TaC − P r TbC Our bilingual human–machine dialogue system mainly serves two important purposes: (1) collection of CS data and (2) experimentation of new agent strategies. Previous work (Ramanarayanan and Suendermann-Oeft, 2017) developed a rulebased CS dialogue system restricted to a fixed set of prompts. Ahn et al. (2020) proposed a more flexible bilingual system for English-Spanish as an extension of a monolingual goal-oriented collaborative dialogue framework (He et al., 2017), originally designed for the M UTUAL F RIENDS task. This task provides the two conversational partners A and B individually with a knowledge base (KB) of friends, out of which there is exactly one friend common in both KBs. Each friend in the KB has several attributes such as hobby, location of work, etc. The goal of the task is to collaboratively find this mutual friend by text conversations between the two partners–which can be human or machine. The modifications made by Ahn et al. (2020) for extending this monolingual system to support bilingual Spanish-English dialogues were mainly in thr"
2020.conll-1.46,2020.acl-main.329,0,0.0289223,"oss Spanglish and Hinglish. 2 Code-Switching Strategies Given that CS is used in very nuanced ways, researchers have been studying how people codeswitch, examining the switch-points of languages syntactically (Poplack, 1980; Solorio and Liu, 2008), prosodically (Fricke et al., 2016), lexically (Kootstra, 2012), pragmatically (Begum et al., 2016), and so forth. Many works have attempted to model code-switching text and speech from a statistical perspective (Garg et al., 2018a,b). Recent works and benchmarks such as Linguistic Codeswitching Evaluation (LinCE) (Aguilar et al., 2020) and GLUECoS (Khanuja et al., 2020) have provided a unified platform to evaluate CS data for various NLP tasks across various language pairs. Our work is in line with these recent efforts to provide NLP capabilities to users with diverse linguistic backgrounds. We extend the human–machine CS dialogue system by Ahn et al. (2020) to a new language pair of Hindi-English. In order to better understand the style and usage of languages in a code-switched utterance, we cluster and characterize these utterances by a set of predefined CS strategies. Previous works have mainly identified two commonly used code-switching (CS) strategies:"
2020.conll-1.46,2020.acl-main.169,1,0.80705,"of the languages, switching from one MatL to another. In our work, we focus on the Hindi-English language pair. We experiment with 4 CS strategies ins (1) EN−−→HI (inserting English phrases into Hindi ins MatL), (2) HI−−→EN (inserting Hindi phrases into alt English MatL), (3) HI−→EN (alternating from alt Hindi MatL to English MatL), and (4) EN−→HI (alternating from English MatL to Hindi MatL). CS is also observed more often in informal and casual settings than formal ones (Sitaram et al., 2019). We test this hypothesis by inducing informality in the agent’s strategies. Although recent works (Madaan et al., 2020) have introduced neural methods to induce informality, we deploy a simple way to moderate formality by adding discourse markers (e.g. “so”, “well”) at the beginning and ending of sentences. These markers are independent of context and syntax (Schiffrin, 1988), and are often associated with informality (Jucker, 2002). Thus, we define four more agent strategies by infusing informality (+ Informality) in each of the previously described 4 CS strategies. 566 3 Measuring Accommodation in Dialogue Communication Accommodation Theory posits that people adjust their behaviors or speech styles to their"
2020.conll-1.46,W16-3640,0,0.0201085,"monolingual dialogues (Brennan and Clark, 1996; Niederhoffer and Pennebaker, 2002), it is relatively new in the CS setting. Soto et al. (2018) found rate of code-switching to be accommodated in human–human Spanish-English dialogues. Choice of language when code-switching can also be adapted in dialogues (Bawa et al., 2018). Fricke et al. (2016) further discover that part-of-speech of a CS utterance may impact the following language choice. Our work adds to this field by studying accommodation of language choice for lexical classes. In terms of quantifying accommodation, we adapt a metric from Mizukami et al. (2016) to measure accommodation (we refer it to as global accommodation). Global accommodation extends the score proposed in Nenkova et al. (2008) by aggregating a speaker’s word usage across an entire dialogue and biases it relatively with other non-partners in the corpus.PFor two partners a and b, we denote Ea,b = − w∈V |P ra (w) − P rb (w) |for a given word class V (where P r(w) is the empirical probability of word w). Denoting the set of non-partners for the speaker a by Na , we define ratio as   E(a,b) > E(a,np) 1 ratio(E(a,b) , E(a,np) ) = 0.5 E(a,b) = E(a,np)   0 E(a,b) < E(a,np) (and Ta"
2020.conll-1.46,P08-2043,0,0.0251553,"These markers are independent of context and syntax (Schiffrin, 1988), and are often associated with informality (Jucker, 2002). Thus, we define four more agent strategies by infusing informality (+ Informality) in each of the previously described 4 CS strategies. 566 3 Measuring Accommodation in Dialogue Communication Accommodation Theory posits that people adjust their behaviors or speech styles to their conversational partners’ (Giles et al., 1973). Linguistic accommodation has proven to reduce interpersonal distance (Camilleri, 1996) and is correlated with dialogue success and engagement (Nenkova et al., 2008). Although well-studied in the monolingual dialogues (Brennan and Clark, 1996; Niederhoffer and Pennebaker, 2002), it is relatively new in the CS setting. Soto et al. (2018) found rate of code-switching to be accommodated in human–human Spanish-English dialogues. Choice of language when code-switching can also be adapted in dialogues (Bawa et al., 2018). Fricke et al. (2016) further discover that part-of-speech of a CS utterance may impact the following language choice. Our work adds to this field by studying accommodation of language choice for lexical classes. In terms of quantifying accommo"
2020.conll-1.46,D19-5558,0,0.0265839,"syntactic, grammatical and morphological levels (Sitaram et al., 2019). Code-switching has been studied in linguistics and sociolinguistics for decades (Poplack, 1980; Gumperz, 1982; Milroy et al., 1995; Auer, 1 The code and data is available at https://github. com/TanmayParekh/commonDost 2013; Gardner-Chloros and Weston, 2015) since it reveals various linguistic and socio-cultural behaviours (Heller, 1982). However, NLP studies of written CS are limited to social media texts, rather than natural conversation, and tend to focus on single sentences, rather than be contextualized in a dialogue (Rabinovich et al., 2019). Advances in dialogue research (Vinyals and Le, 2015; Zhang et al., 2020; Serban et al., 2016) have enabled conversational AI technologies for human– machine interactions, like Alexa and Siri. Although these technologies are pervasive, they still have limited abilities to accommodate to the user, and they do not account for the ubiquity of multilingual communication. Due to the lack of code-switching abilities in existing language technologies, there has been limited work in studying linguistic accommodation in written CS dialogues. With the ultimate goal to enable adaptive codeswitching dial"
2020.conll-1.46,D08-1102,0,0.0480537,"stem easily generalizable to a new CS language pair, (2) a new dataset, C OMMON D OST, comprising of 439 Hindi-English human–machine conversations, (3) adaptation of accommodation metrics and a corresponding analysis of accommodation of language style and choice in CS dialogues, and (4) an exploratory study of linguistic and socio-cultural factors on users’ CS patterns across Spanglish and Hinglish. 2 Code-Switching Strategies Given that CS is used in very nuanced ways, researchers have been studying how people codeswitch, examining the switch-points of languages syntactically (Poplack, 1980; Solorio and Liu, 2008), prosodically (Fricke et al., 2016), lexically (Kootstra, 2012), pragmatically (Begum et al., 2016), and so forth. Many works have attempted to model code-switching text and speech from a statistical perspective (Garg et al., 2018a,b). Recent works and benchmarks such as Linguistic Codeswitching Evaluation (LinCE) (Aguilar et al., 2020) and GLUECoS (Khanuja et al., 2020) have provided a unified platform to evaluate CS data for various NLP tasks across various language pairs. Our work is in line with these recent efforts to provide NLP capabilities to users with diverse linguistic backgrounds."
2020.conll-1.46,2020.acl-demos.30,0,0.0326858,"itching has been studied in linguistics and sociolinguistics for decades (Poplack, 1980; Gumperz, 1982; Milroy et al., 1995; Auer, 1 The code and data is available at https://github. com/TanmayParekh/commonDost 2013; Gardner-Chloros and Weston, 2015) since it reveals various linguistic and socio-cultural behaviours (Heller, 1982). However, NLP studies of written CS are limited to social media texts, rather than natural conversation, and tend to focus on single sentences, rather than be contextualized in a dialogue (Rabinovich et al., 2019). Advances in dialogue research (Vinyals and Le, 2015; Zhang et al., 2020; Serban et al., 2016) have enabled conversational AI technologies for human– machine interactions, like Alexa and Siri. Although these technologies are pervasive, they still have limited abilities to accommodate to the user, and they do not account for the ubiquity of multilingual communication. Due to the lack of code-switching abilities in existing language technologies, there has been limited work in studying linguistic accommodation in written CS dialogues. With the ultimate goal to enable adaptive codeswitching dialogue agents, in this paper we study user accommodation, i.e., entrainment"
2020.emnlp-main.93,P19-1606,1,0.504676,"isual infilling technique on narratives that have stronger contextual dependencies on the rest of the sentences. 2 Related Work Multimodal Language: Language generation from visual modality has seen a steep rise in interest with the introduction of several large scale tasks such as image captioning (Hossain et al., 2019), visual question answering (Antol et al., 2015) and visual dialog (Das et al., 2017; Mostafazadeh et al., 2017; De Vries et al., 2017). Visual Storytelling: Huang et al. (2016) ventured into sequential step wise generation of stories by introducing visual storytelling (ViST). Chandu et al. (2019) also proposed a dataset of 16k recipes in a similar form. Recent methods have tackled ViST using adversarial learning, reinforcement learning (Wang et al., 2018; Huang et al., 2019; Hu et al., 2019), modality-fusion (Smilevski et al., 2018), traditional seq2seq models (Kim et al., 2018; Jung et al., 2020; Hsu et al., 2018) and explicit structures (Bosselut et al., 2016; Bisk et al., 2019). Though the stories in ViST demonstrate a sense of continuity, the overarching sequential context is feeble. Procedures such as cooking recipes (Salvador et al., 2019; Wang et al., 2019) on the other hand, d"
2020.emnlp-main.93,N18-1204,0,0.0611894,"Missing"
2020.emnlp-main.93,P18-1083,0,0.0290617,"tion from visual modality has seen a steep rise in interest with the introduction of several large scale tasks such as image captioning (Hossain et al., 2019), visual question answering (Antol et al., 2015) and visual dialog (Das et al., 2017; Mostafazadeh et al., 2017; De Vries et al., 2017). Visual Storytelling: Huang et al. (2016) ventured into sequential step wise generation of stories by introducing visual storytelling (ViST). Chandu et al. (2019) also proposed a dataset of 16k recipes in a similar form. Recent methods have tackled ViST using adversarial learning, reinforcement learning (Wang et al., 2018; Huang et al., 2019; Hu et al., 2019), modality-fusion (Smilevski et al., 2018), traditional seq2seq models (Kim et al., 2018; Jung et al., 2020; Hsu et al., 2018) and explicit structures (Bosselut et al., 2016; Bisk et al., 2019). Though the stories in ViST demonstrate a sense of continuity, the overarching sequential context is feeble. Procedures such as cooking recipes (Salvador et al., 2019; Wang et al., 2019) on the other hand, demonstrate this characteristic inviolably. Hence, we present a large scale ViPT dataset to encourage research in this direction. Infilling and Masking: The idea"
2020.emnlp-main.93,D18-1356,0,0.0273931,"ion of meaning patches with missing portions of text is experimented by Zhu et al. (2019); Donahue et al. (2020); Fedus et al. (2018) to generate meaningful patches.Similarly, Ippolito et al. (2019) proposed a hierarchical model to generate middle span using a bag of predicted words from left and right contexts. In a similar spirit, this paper studies the effects of infilling techniques for visual narrative generation. An alternate stream of work to improve the context in stories include providing supporting information such as entities (Clark et al., 2018; Xu et al., 2018), latent templates (Wiseman et al., 2018), knowledge graphs (Yang et al., 2019), etc., explicitly. In contrast to this, infilling provides an opportune platform to implicitly learn the contextual information. Our work is positioned in the intersection of infilling and multimodal language generation. 3 Dataset Description This section describes our new ViPT dataset and highlights the differences with ViST. Procedures vs Stories: Narrative properties such as content and structure in these forms are sufficiently contrastive (Gatt and Krahmer, 2018). Content in stories include characters and events while procedures include ingredients, m"
2020.emnlp-main.93,D18-1462,0,0.012621,", 2019; Lewis et al., 2019). Generation of meaning patches with missing portions of text is experimented by Zhu et al. (2019); Donahue et al. (2020); Fedus et al. (2018) to generate meaningful patches.Similarly, Ippolito et al. (2019) proposed a hierarchical model to generate middle span using a bag of predicted words from left and right contexts. In a similar spirit, this paper studies the effects of infilling techniques for visual narrative generation. An alternate stream of work to improve the context in stories include providing supporting information such as entities (Clark et al., 2018; Xu et al., 2018), latent templates (Wiseman et al., 2018), knowledge graphs (Yang et al., 2019), etc., explicitly. In contrast to this, infilling provides an opportune platform to implicitly learn the contextual information. Our work is positioned in the intersection of infilling and multimodal language generation. 3 Dataset Description This section describes our new ViPT dataset and highlights the differences with ViST. Procedures vs Stories: Narrative properties such as content and structure in these forms are sufficiently contrastive (Gatt and Krahmer, 2018). Content in stories include characters and event"
2020.lrec-1.350,N19-1009,0,0.0408851,"Missing"
2020.lrec-1.350,L16-1632,0,0.0416335,"Missing"
2020.lrec-1.350,W17-0102,0,0.0279178,") developed hybrid ruleand phrase-based Statistical Machine Translation systems. Naturally, similar works in collecting corpora in Indigenous languages of Latin America are abundant, but very few, if any, have the scale and potential of our resource to be useful in many downstream language-specific and interdisciplinary applications. A general overview of the state of NLP for the under-represented languages of the Americas can be found at (Mager et al., 2018). To name a few of the many notable works, (Monta˜no et al., 2019) created a parallel Mixtec-Spanish corpus for Machine Translation and (Kazeminejad et al., 2017) created lexical resources ´ for Arapaho, while (Cardenas et al., 2018) and (Cavar et al., 2016) focused on building speech corpora for Southern Quechua and Chatino respectively. 4. The Resource 1 The resource is comprised of 142 hours of spoken Mapudungun that was recorded during the AVENUE project (Levin et al., 2002) in 2001 to 2005. The data was recorded under a partnership between the AVENUE project, funded by the US National Science Foundation at Carnegie Mellon University, the Chilean Ministry of Education (Mineduc), and the Instituto de Estudios Ind´ıgenas at Universidad de La Frontera"
2020.lrec-1.350,monson-etal-2004-data,1,0.674738,"Missing"
2020.lrec-1.350,monson-etal-2008-linguistic,1,0.46873,"Missing"
2020.lrec-1.350,W19-3650,0,0.033218,"Missing"
2020.lrec-1.350,P02-1040,0,0.110151,"Missing"
2020.lrec-1.350,W15-3049,0,0.0486746,"Missing"
2020.lrec-1.350,W18-6319,0,0.011561,"ity as well as label smoothing set to 0.1. We train with the Adam optimizer (Kingma and Ba, 2014) for up to 200 epochs using learning decay with a patience of six epochs. The baseline results using different portions of the training set (10k, 50k, 100k, and all (220k) parallel sentences) on both translation directions are presented in Table 3, using detokenized BLEU (Papineni et al., 2002) (a standard MT 2875 metric) and chrF (Popovi´c, 2015) (a metric that we consider to be more appropriate for polysynthetic languages, as it does not rely on word n-grams) computed with the sacreBLEU toolkit (Post, 2018). It it worth noting the difference in quality between the two directions, with translation into Spanish reaching 20.4 (almost 21) BLEU points in the development set, while the opposite direction (translating into Mapudungun) shows about a 7 BLEU points worse performance. This is most likely due to Mapudungun being a polysynthetic language, with its complicated morphology posing a challenge for proper generation. 7. Conclusion With this work we present a resource that will be extremely useful for building language systems in an endangered, under-represented language, Mapudungun. We benchmark N"
2020.lrec-1.350,P16-1162,0,0.0325849,"Missing"
2020.lrec-1.656,L18-1530,1,0.837929,"t al., 2017; Littell et al., 2018). In our experience, the most requested speech technology for very-low-resource languages is transcription acceleration, an application of speech recognition for decreasing the workload of transcribers. Many low-resource and endangered languages do already have extensive untranscribed speech collections, in the form of recorded radio broadcasts, linguists’ field recordings, or other personal recordings. Transcribing these collections is a high priority for many speech communities, as an untranscribed corpus is difficult to use in either research or education (Adams et al., 2018; Foley et al., 2019). AlloVera and Allosaurus were originally and primarily intended for use in transcription acceleration, although we will also be exploring other practical applications. Another priority technology is approximate search of speech databases. While the aforementioned untranscribed speech collections can straightforwardly be made available online, they are not especially accessible as such. A researcher, teacher, or student cannot in practice listen to years’ worth of radio recordings in search of a particular word or topic. AlloVera and Allosaurus, by making an approximate te"
2020.lrec-1.656,W17-4607,1,0.839092,"is approximate search of speech databases. While the aforementioned untranscribed speech collections can straightforwardly be made available online, they are not especially accessible as such. A researcher, teacher, or student cannot in practice listen to years’ worth of radio recordings in search of a particular word or topic. AlloVera and Allosaurus, by making an approximate text representation of the corpus, open up the possibility for efficient approximate phonetic search through otherwise-untranscribed speech databases. Previous work has demonstrated the feasibility of such an approach (Anastasopoulos et al., 2017; Boito et al., 2017), but the quality of the search results can be significantly boosted by improvements in a first-pass phonetic transcription (Ondel et al., 2018). We are also planning on integrating AlloVera and Allosaurus into a language-neutral forced-alignment pipeline. While forced-alignment is a task that is already commonly done in a zero-shot scenario (by manually mapping target-language phones to the vocabulary of a pretrained acoustic model, often an English one), the extensive phonetic vocabulary of AlloVera means that many phones are already covered. This greatly expands the num"
2020.lrec-1.656,2021.eacl-main.58,0,0.114164,"Missing"
2020.lrec-1.656,W17-0106,1,0.837055,"ance over both the shared phoneme model and the private phoneme model substantially. 4. Applications Currently, we intend to integrate AlloVera and Allosaurus (or other future systems trained using AlloVera) into three practical downstream systems for very-low-resource languages, addressing tasks identified as development priori5333 Shared Phoneme PER Private Phoneme PER Allosaurus PER Inuktitut Tusom 94.1 86.2 73.1 93.5 85.8 64.2 Table 5: Comparisons of phone error rates in two unseen languages ties in recent surveys of indigenous and other low-resource language technology (Thieberger, 2016; Levow et al., 2017; Littell et al., 2018). In our experience, the most requested speech technology for very-low-resource languages is transcription acceleration, an application of speech recognition for decreasing the workload of transcribers. Many low-resource and endangered languages do already have extensive untranscribed speech collections, in the form of recorded radio broadcasts, linguists’ field recordings, or other personal recordings. Transcribing these collections is a high priority for many speech communities, as an untranscribed corpus is difficult to use in either research or education (Adams et al"
2020.lrec-1.656,C18-1222,1,0.85747,"hared phoneme model and the private phoneme model substantially. 4. Applications Currently, we intend to integrate AlloVera and Allosaurus (or other future systems trained using AlloVera) into three practical downstream systems for very-low-resource languages, addressing tasks identified as development priori5333 Shared Phoneme PER Private Phoneme PER Allosaurus PER Inuktitut Tusom 94.1 86.2 73.1 93.5 85.8 64.2 Table 5: Comparisons of phone error rates in two unseen languages ties in recent surveys of indigenous and other low-resource language technology (Thieberger, 2016; Levow et al., 2017; Littell et al., 2018). In our experience, the most requested speech technology for very-low-resource languages is transcription acceleration, an application of speech recognition for decreasing the workload of transcribers. Many low-resource and endangered languages do already have extensive untranscribed speech collections, in the form of recorded radio broadcasts, linguists’ field recordings, or other personal recordings. Transcribing these collections is a high priority for many speech communities, as an untranscribed corpus is difficult to use in either research or education (Adams et al., 2018; Foley et al.,"
2020.lrec-1.656,L18-1429,1,0.90023,"For language-specific models and questions, such representations are often adequate and may even be preferable to the alternatives. However, in multilingual models, the language-specific nature of phonemic abstractions can be a liability. The added phonetic realism of even a broad phonetic representation moves transcriptions closer to a universal space where categories transcend the bounds of a particular language. This paper describes AlloVera1 , a resource that maps between the phonemic representations produced by many NLP tools—including grapheme-to-phoneme (G2P) transducers like our own (Mortensen et al., 2018)—and broad phonetic representations. Specifically, it is a database of phonemeallophone pairs (where an allophone is a phonetic realization of a phoneme—see § 1.1. below) for 14 languages. It is designed for notational compatibility with existing G2P systems. The phonetic representations are relatively broad, a consequence of our sources, but they are phonetically realistic enough to improve performance on a speech-to-phone recognition task, as shown in § 3. 1 https://github.com/dmort27/allovera This resource has applications beyond universal speechto-phone recognition, including approximate s"
2020.lrec-1.656,rousseau-etal-2012-ted,0,0.0854531,"Missing"
2020.lrec-1.656,1996.amta-1.36,0,0.808006,"y manually mapping target-language phones to the vocabulary of a pretrained acoustic model, often an English one), the extensive phonetic vocabulary of AlloVera means that many phones are already covered. This greatly expands the number of languages that can be aligned without the need for an extensive transcribed corpus or manual system configuration. 5. Related Work AlloVera builds on work in three major areas: phonetics and theoretical phonology, phonological ontologies, and human language technologies. The term allophone was coined by Benjamin Lee Whorf in the 1920s and was popularized by Trager and Block (1941). However, the idea goes back much further, to Baudoin de Courtenay (1894). The idea of allophony most relevant to our work here comes from American Structuralist linguists like Harris (1951), but we also invoke the concept of the archiphoneme, associated with the Prague Circle (Trubetskoy, 1939). In the 1950s and 1960s, the structuralist notions of the “taxonomic” phoneme and of allophones came under attack by generative linguists (Chomsky and Halle, 1968; Halle, 1962; Halle, 1959), but they have retained their importance both in linguistic practice and linguistic theory. Various resources co"
2020.scil-1.32,W18-3219,0,0.0576668,"Missing"
2020.scil-1.32,C18-1319,0,0.0643179,"Missing"
2020.scil-1.32,W18-3210,0,0.383612,"Missing"
2020.scil-1.32,L16-1260,0,0.434662,"Missing"
2020.scil-1.32,W18-3204,1,0.873366,"Missing"
2020.scil-1.32,W18-3211,1,0.875399,"Missing"
2020.scil-1.32,C82-1023,0,0.44955,"aneous speech (Deuchar et al., 2014), and a Twitter corpus (Molina et al., 2016). Examples of an utterance in each strategy along with the distribution of these strategies in both Twitter and Miami corpora are given in Table 1. We follow Muysken’s (2000) approach. The first strategy from Muysken (2000) is Insertional code-switching, which follows the Myers-Scotton framework of a Matrix Language (MatL) and an Embedded Language (EmbL). The structure and grammar of the MatL is maintained while inserting the EmbL (often single words or phrases) in certain spots (Myers-Scotton, 1993). According to Joshi (1982), closed class items such as determiners, quantifiers, etc., would remain in the MatL. This has also been shown to be more commonly used when the speakers are not equally proficient in both languages (Deuchar et al., 2007). We experiment with two conditions: (1) retaining the grammar of English while insertins ing Spanish nouns (SP !EN), and (2) using Spanish grammar while inserting English nouns ins (EN !SP). Next, we experiment with Alternational codeswitching, when the two languages remain more separate and alternate after clauses. Switch-points adhere to constituent boundaries (Sankoff and"
2020.scil-1.32,N13-2012,0,0.0155114,"rder to learn how these varieties may be linguistically or functionally comparative to our findings. The implications of our current work, which reveal which CS strategies are more entrainable than others, could help CS agents adapt to users and to better parse and predict user utterances with a more informed CS language model.13 Future agents should incorporate different CS strategies dynamically within a single conversation that entrain to the user. In order to move beyond a rule13 This approach is similar to a method where ASR systems that lexically entrain users can lower ASR error rates (Levitan, 2013). based agent, in future work we can leverage neural language generation systems (e.g., Park and Tsvetkov, 2019) trained on CS data. From here, we can usher in an era of bilingual dialogue systems that brings human–computer interactions to a more personalized space. 8 Acknowledgments We acknowledge helpful input from the anonymous reviewers. We also thank Gayatri Bhat, Cindy Blanco, Anjalie Field, Melinda Fricke, Shirley Anugrah Hayati, He He, Sachin Kumar, Chan Young Park, Anat Prior, Sai Krishna Rallabandi, Shruti Rijhwani, Shuly Wintner, and Yiheng Zhou for fruitful discussions. Finally, we"
2020.scil-1.32,D14-1098,0,0.0258074,"Missing"
2020.scil-1.32,P17-1162,0,0.0689247,"t need to collect examples of multilingual human–computer dialogues, a resource that does not yet exist. To collect human–computer dialogues in a controlled manner, we (1) modify an existing goaloriented dialogue framework to code-switch; (2) create multiple instances of code-switching dialogue systems, where each instance follows one pre-defined strategy of CS as described in §3; and (3) analyze collected dialogues and study how people communicate differently with dialogue agents following a particular strategy. We begin by modifying an existing goaloriented collaborative dialogue framework (He et al., 2017). The framework implements a scenario of discussing mutual friends given a knowledge base, private to each interlocutor. Each of the interlocutors has a list of friends with attributes such as hobby and major. Only one friend is the same across both lists, and the goal is to find that mutual friend via collaborative discussion over text chat. We extend this framework to a bilingual Spanish–English goal-oriented collaborative dialogue. In our bilingual interface, users see the private table of friends and attributes in both Spanish and English. To code-switch in language generation, we add modi"
2020.scil-1.32,P08-2043,0,0.642632,"Missing"
2020.scil-1.32,D19-5626,1,0.822923,"he implications of our current work, which reveal which CS strategies are more entrainable than others, could help CS agents adapt to users and to better parse and predict user utterances with a more informed CS language model.13 Future agents should incorporate different CS strategies dynamically within a single conversation that entrain to the user. In order to move beyond a rule13 This approach is similar to a method where ASR systems that lexically entrain users can lower ASR error rates (Levitan, 2013). based agent, in future work we can leverage neural language generation systems (e.g., Park and Tsvetkov, 2019) trained on CS data. From here, we can usher in an era of bilingual dialogue systems that brings human–computer interactions to a more personalized space. 8 Acknowledgments We acknowledge helpful input from the anonymous reviewers. We also thank Gayatri Bhat, Cindy Blanco, Anjalie Field, Melinda Fricke, Shirley Anugrah Hayati, He He, Sachin Kumar, Chan Young Park, Anat Prior, Sai Krishna Rallabandi, Shruti Rijhwani, Shuly Wintner, and Yiheng Zhou for fruitful discussions. Finally, we sincerely thank our annotator, Joshua Baumgarten. This work was supported by NSF grant IIS-1812327 and NSF GRFP"
2020.scil-1.32,P18-1143,0,0.115955,"Missing"
2020.scil-1.32,D19-5558,0,0.111858,"Missing"
2020.scil-1.32,W18-5009,0,0.0387168,"Missing"
2020.scil-1.32,P17-1180,0,0.20533,"Missing"
2020.scil-1.32,D16-1121,0,0.0449551,"Missing"
2020.scil-1.32,D08-1102,0,0.182558,"Missing"
2020.scil-1.32,W18-3201,0,0.0683939,"Missing"
2020.semeval-1.230,W18-3507,1,0.834655,"York Times.3 We scraped articles from 2018 to mid-2019 to ensure that the articles follow the same topical distribution as that of the training articles. We provide the unlabeled data, split to sentences, and train BERT on masked LM and next sentence prediction losses (Devlin et al., 2019). We leverage the pipeline provided by the Huggingface transformers library.4 2.4 Class-Imbalance Since our corpus suffers from class imbalance in both sentence classification and word-level span identification task, we associate higher weight to the loss incurred by samples of the minority class. Following Khosla (2018), we calculate these weights as inverse of the normalized P frequency of samples of each class and plug them into the cross-entropy loss. Namely L = − N1 N n=1 wn ∗ lossn , where wn is the weight associated with the loss for each sample. 3 Experimental Setup We used the BERT model from hugging-face library which was then fine-tuned on the corpus. Since the test-set was not made available during the competition, we hold out a small part of the training data as dev-set which was used to tune the models. The submitted model was chosen based on its Span-level Normalized F1-Score on the validation"
2020.semeval-1.230,2020.lrec-1.94,1,0.732679,"s-entropy loss with sigmoid activation for sentence-level classification, whereas the token-level classification is trained using a cross-entropy loss with softmax activation. The losses Lsent , Ltok are jointly optimized using hyper-parameter α to control the strength of both losses: L = αLsent + (1 − α)Ltok . 2.2 (4) Additional Features We incorporate additional lexical, syntactic, linguistic, and topical features at word, sentence and document levels to better inform the model. Syntactic Features: Inspired by prior work that leveraged syntactic features effectively (Vashishth et al., 2018; Kumar et al., 2020), and motivated by the observation that many propaganda spans are persuasive or idiomatic phrases, we extract phrasal features from constituency parse trees to explicitly incorporate structural syntactic information. We encode the path from a word to the root in the parse tree as a dc dimensional embedding.2 Stanford CoreNLP (Manning et al., 2014) was used to extract the constituency parses as well as part-of-speech tags that were also used as features. Affective and Semantic Features: In addition to structural cues, prior work has shown that propaganda is marked with affective and emotional w"
2020.semeval-1.230,P14-5010,0,0.0026891,"orporate additional lexical, syntactic, linguistic, and topical features at word, sentence and document levels to better inform the model. Syntactic Features: Inspired by prior work that leveraged syntactic features effectively (Vashishth et al., 2018; Kumar et al., 2020), and motivated by the observation that many propaganda spans are persuasive or idiomatic phrases, we extract phrasal features from constituency parse trees to explicitly incorporate structural syntactic information. We encode the path from a word to the root in the parse tree as a dc dimensional embedding.2 Stanford CoreNLP (Manning et al., 2014) was used to extract the constituency parses as well as part-of-speech tags that were also used as features. Affective and Semantic Features: In addition to structural cues, prior work has shown that propaganda is marked with affective and emotional words and phrases (Gupta et al., 2019; Alhindi et al., 2019). Motivated by that, we append to word embeddings of the ith token (after BERT) features extracted using affective lexicons, including the LIWC (Tausczik and Pennebaker, 2010) dictionary, NRC lexicons of Word Emotion, VAD and Affect Intensity (Mohammad and Turney, 2013; Mohammad, 2018a; Mo"
2020.semeval-1.230,P18-1017,0,0.0118142,"nning et al., 2014) was used to extract the constituency parses as well as part-of-speech tags that were also used as features. Affective and Semantic Features: In addition to structural cues, prior work has shown that propaganda is marked with affective and emotional words and phrases (Gupta et al., 2019; Alhindi et al., 2019). Motivated by that, we append to word embeddings of the ith token (after BERT) features extracted using affective lexicons, including the LIWC (Tausczik and Pennebaker, 2010) dictionary, NRC lexicons of Word Emotion, VAD and Affect Intensity (Mohammad and Turney, 2013; Mohammad, 2018a; Mohammad, 2018b). We also assign a score to each token that corresponds to the frequency of the word in the propaganda spans as opposed to the non-propaganda ones. For example, words like ‘invader’, will have a high score, as it is salient to propaganda spans. Furthermore, we incorporate semantic class features. These include named entities (such as Person, Place, Temporal Expressions) as identified by the CoreNLP NER tagger (Manning et al., 2014) and finer-grained topical categories from Empath (Fast et al., 2016) (such as Government, War, Violence). These word-level features (Fword ) are"
2020.semeval-1.230,L18-1027,0,0.0287622,"nning et al., 2014) was used to extract the constituency parses as well as part-of-speech tags that were also used as features. Affective and Semantic Features: In addition to structural cues, prior work has shown that propaganda is marked with affective and emotional words and phrases (Gupta et al., 2019; Alhindi et al., 2019). Motivated by that, we append to word embeddings of the ith token (after BERT) features extracted using affective lexicons, including the LIWC (Tausczik and Pennebaker, 2010) dictionary, NRC lexicons of Word Emotion, VAD and Affect Intensity (Mohammad and Turney, 2013; Mohammad, 2018a; Mohammad, 2018b). We also assign a score to each token that corresponds to the frequency of the word in the propaganda spans as opposed to the non-propaganda ones. For example, words like ‘invader’, will have a high score, as it is salient to propaganda spans. Furthermore, we incorporate semantic class features. These include named entities (such as Person, Place, Temporal Expressions) as identified by the CoreNLP NER tagger (Manning et al., 2014) and finer-grained topical categories from Empath (Fast et al., 2016) (such as Government, War, Violence). These word-level features (Fword ) are"
2020.semeval-1.230,D17-1317,0,0.061674,"ers are not able to identify it, but their opinions are shaped according to the propagandist’s hidden agenda (Barrón-Cedeño et al., 2019); it is thus very difficult to identify propaganda automatically. However, automatic identification and analysis of propaganda in news articles and on social media are essential to understand propaganda at scale and develop approaches to countering it (King et al., 2017; Starbird, 2018; Field et al., 2018). Prior research on propaganda detection focused primarily on identifying propaganda at a document level, due to the dearth of finer-grained labelled data (Rashkin et al., 2017; Barrón-Cedeño et al., 2019). This has resulted in classifying all news articles from a particular source as propaganda (or hoax, disinformation, etc.), which is often not the case, and which can obfuscate a finer-grained analysis of propagandistic strategies (Da San Martino et al., 2019; Horne et al., 2018). Recently, Da San Martino et al. (2019) carried out a seminal task of fine-grained propaganda detection and curated a dataset consisting of about 550 news articles. The dataset contains word-span level annotations provided by high-quality professionals along with additional information ab"
2020.semeval-1.230,D18-1157,1,0.846797,"tok ). (3) We use a cross-entropy loss with sigmoid activation for sentence-level classification, whereas the token-level classification is trained using a cross-entropy loss with softmax activation. The losses Lsent , Ltok are jointly optimized using hyper-parameter α to control the strength of both losses: L = αLsent + (1 − α)Ltok . 2.2 (4) Additional Features We incorporate additional lexical, syntactic, linguistic, and topical features at word, sentence and document levels to better inform the model. Syntactic Features: Inspired by prior work that leveraged syntactic features effectively (Vashishth et al., 2018; Kumar et al., 2020), and motivated by the observation that many propaganda spans are persuasive or idiomatic phrases, we extract phrasal features from constituency parse trees to explicitly incorporate structural syntactic information. We encode the path from a word to the root in the parse tree as a dc dimensional embedding.2 Stanford CoreNLP (Manning et al., 2014) was used to extract the constituency parses as well as part-of-speech tags that were also used as features. Affective and Semantic Features: In addition to structural cues, prior work has shown that propaganda is marked with affe"
2020.wnut-1.22,N18-1090,0,0.0182262,". Due to the scarcity of examples in CS-NLI, we focus our efforts on the modification and augmentation of the data used to fine-tune these models. In this section, we describe techniques to address the code-mixed, low-resource, and conversational aspects of the task. 4.1 Addressing Code-Mixing sence of code-mixing in the data used to pre-train transformer models. Masked Language Modeling: We fine-tune mBERT on the masked language modeling objective, following Khanuja et al. (2020b), on a combination of in-domain code-mixed movie scripts and publicly available datasets by Roy et al. (2013) and Bhat et al. (2018) to obtain modified mBERT (mod-mBERT) to be fine-tuned on the sentencepair classification task. Transliteration: We perform token-level language identification and transliterate the detected Romanized Hindi words in CS-NLI to Devanagari script using the approach in Singh et al. (2018), to enable mBERT to better understand them. Translation: Due to the difficulty in training codemixed to monolingual translation models, we follow the approach in Dhar et al. (2018) to obtain translations. We first transliterate the Romanized Hindi words, and then translate English phrases to Hindi using the Googl"
2020.wnut-1.22,D15-1075,0,0.146649,"Missing"
2020.wnut-1.22,2020.acl-main.747,0,0.117759,"Missing"
2020.wnut-1.22,D18-1269,0,0.024271,"he approach in Singh et al. (2018), to enable mBERT to better understand them. Translation: Due to the difficulty in training codemixed to monolingual translation models, we follow the approach in Dhar et al. (2018) to obtain translations. We first transliterate the Romanized Hindi words, and then translate English phrases to Hindi using the Google Cloud translation API. 3 . 4.2 Addressing the Low-Resource Aspect Due to the limited amount of code-mixed NLI data available for fine-tuning, we augment CS-NLI with 4000 monolingual entailment and contradiction examples sampled from the SNLI, XNLI (Conneau et al., 2018), and MPE (Lai et al., 2017) datasets. Transliterations of Devanagari Hindi sentence-pairs from the XNLI dataset provide additional NLI data in Romanized Hindi while SNLI examples do the same in English. The MPE dataset adds examples requiring aggregation of information across sentences (Lai et al., 2017). 4.3 Approaches to Conversational NLI Each premise in CS-NLI contains turns in the form “Speaker Name: Utterance”. Khanuja et al. (2020a) show that a number of hypotheses require an understanding of the transition between speakers, in addition to the meaning of the utterance itself. In order"
2020.wnut-1.22,W18-3817,0,0.320219,"anuja et al. (2020b), on a combination of in-domain code-mixed movie scripts and publicly available datasets by Roy et al. (2013) and Bhat et al. (2018) to obtain modified mBERT (mod-mBERT) to be fine-tuned on the sentencepair classification task. Transliteration: We perform token-level language identification and transliterate the detected Romanized Hindi words in CS-NLI to Devanagari script using the approach in Singh et al. (2018), to enable mBERT to better understand them. Translation: Due to the difficulty in training codemixed to monolingual translation models, we follow the approach in Dhar et al. (2018) to obtain translations. We first transliterate the Romanized Hindi words, and then translate English phrases to Hindi using the Google Cloud translation API. 3 . 4.2 Addressing the Low-Resource Aspect Due to the limited amount of code-mixed NLI data available for fine-tuning, we augment CS-NLI with 4000 monolingual entailment and contradiction examples sampled from the SNLI, XNLI (Conneau et al., 2018), and MPE (Lai et al., 2017) datasets. Transliterations of Devanagari Hindi sentence-pairs from the XNLI dataset provide additional NLI data in Romanized Hindi while SNLI examples do the same in"
2020.wnut-1.22,2020.calcs-1.2,0,0.122865,"Missing"
2020.wnut-1.22,2020.acl-main.329,0,0.148546,"tute Carnegie Mellon University {sharanyc, aumapath, awb}@cs.cmu.edu Abstract differences between monolingual and code-mixed text due to the intermixing of affixes, and nonstandard transliteration between the writing systems involved. In CS-NLI, Hindi is present in a non-standard Romanized form. Multilingual speakers most often code-mix in informal settings such as social media, in-person, and telephonic conversations, due to which there is a dearth of clean, large-scale code-mixed corpora such as Wikipedia articles and books that can be used for pre-training, making this a low-resource task. Khanuja et al. (2020a) leverage Bollywood movie scripts containing Hinglish text to create CSNLI, with conversations as premises. The creation of hypotheses based on dialogue-like premises transforms the task from one of textual entailment to one of conversational entailment. The inclusion of scripts from multiple movies makes this data inherently noisy due to non-standard Romanization of Hindi, the variation in dialects across movies and differing grammar styles among Hinglish speakers. In this work, we explore and analyze a variety of techniques to leverage existing pre-trained models such as BERT (Devlin et al"
2020.wnut-1.22,I17-1011,0,0.0187566,"8), to enable mBERT to better understand them. Translation: Due to the difficulty in training codemixed to monolingual translation models, we follow the approach in Dhar et al. (2018) to obtain translations. We first transliterate the Romanized Hindi words, and then translate English phrases to Hindi using the Google Cloud translation API. 3 . 4.2 Addressing the Low-Resource Aspect Due to the limited amount of code-mixed NLI data available for fine-tuning, we augment CS-NLI with 4000 monolingual entailment and contradiction examples sampled from the SNLI, XNLI (Conneau et al., 2018), and MPE (Lai et al., 2017) datasets. Transliterations of Devanagari Hindi sentence-pairs from the XNLI dataset provide additional NLI data in Romanized Hindi while SNLI examples do the same in English. The MPE dataset adds examples requiring aggregation of information across sentences (Lai et al., 2017). 4.3 Approaches to Conversational NLI Each premise in CS-NLI contains turns in the form “Speaker Name: Utterance”. Khanuja et al. (2020a) show that a number of hypotheses require an understanding of the transition between speakers, in addition to the meaning of the utterance itself. In order to estimate whether BERT und"
2020.wnut-1.22,P19-1334,0,0.0394719,"Missing"
2020.wnut-1.22,N18-1101,0,0.130511,"Missing"
2021.acl-long.319,2020.findings-emnlp.66,0,0.285473,"mplete and insufficient to provide notice about the collection of users’ contact data (FTC, 2013). 4127 Task Goal Consumer Regulator Enterprise 3 3 3 3 Data Practice Identification (Wilson et al., 2016b) Annotate segments of privacy policies with described data practices. 3 Opt-Out Identification (Sathyendra et al., 2017; Bannihatti Kumar et al., 2020) Extract opt-out choices buried in privacy policy text. 3 Compliance Analysis (Zimmeck et al., 2017, 2019a) Analyze mobile app code and privacy policy to identify potential compliance issues. Privacy Question-Answering (Ravichander et al., 2019; Ahmad et al., 2020) Allow consumers to selectively query privacy policies for issues that are important to them. 3 Policy Summarization (Zaeem et al., 2018; Keymanesh et al., 2020) Construct summaries to aid consumers to quickly digest the content of privacy policies. 3 Readability Analysis (Massey et al., 2013; Meiselwitz, 2013) Characterize the ease of understanding or comprehension of privacy policies. 3 Table 2: Overview of some applications of NLP to privacy policies, and primary stakeholders they are intended to benefit. fectively also requires several additional capabilities such as reasoning over vaguene"
2021.acl-long.319,C12-1075,0,0.0867615,"Missing"
2021.acl-long.319,2020.acl-main.670,0,0.0394197,"Missing"
2021.acl-long.319,N18-1149,0,0.0495462,"Missing"
2021.acl-long.319,D18-1387,0,0.0130644,"from privacy policies (Costante et al., 2012a). Shvartzshanider et al. (2018); Shvartzshnaider et al. (2019, 2020) identify contextual integrity parameters (Nissenbaum, 2004) in policy text. Studies have also tried to extract other, more specific kinds of information from policies, such as third party entities (Libert, 2018b; Bokaie Hosseini et al., 2020) and information about regulated information types (Bhatia et al., 2016; Evans et al., 2017) as well as their similarity (Hosseini et al., 2016). There have also been efforts to analyze vague statements in privacy policies (Liu et al., 2016b; Lebanoff and Liu, 2018), and explore how benchmarks in this domain can be constructed through crowdsourcing (Ramanath et al., 2014b; Wilson et al., 2016c; Audich et al., 2018). Lastly, there has been research focused on identifying header information in privacy policies (Mysore Gopinath et al., 2018) and generating them (Gopinath et al., 2020). Techniques to 4130 Legal Expert Annotator Asker Cannot See Evidence Unanswerable Questions Non-Contiguous Answer Twitter users ask questions to a company. 7 3 7 7 1750 Crowdworkers ask questions about a mobile app. 3 3 3 3 714 Skilled annotators are shown a text span and data"
2021.acl-long.319,N15-1114,1,0.763913,". Results of the analysis of this large corpus of privacy policies revealed a particularly large number of potential compliance problems, with a subset of results shared with the Federal Trade Commission. The system was also reported to have been used by a large electronics manufacturer to verify compliance of legacy mobile apps prior to the introduction of GDPR. 3.4 Policy Summarization Due to the lengthy and verbose nature of privacy policies, it is appealing to attempt to develop automated text summarization techniques to generate short and concise summaries of a privacy policy’s contents (Liu et al., 2015). Tomuro et al. (2016) develop an extractive summarization system that identifies important sentences in a privacy policy along five categories: purpose, third parties, limited collection, limited use and data retention. Zaeem et al. (2018, 2020) identify ten questions about privacy policies, and automatically categorize ‘risk levels’ associated with each of the questions, as shown in Table. 3. Keymanesh et al. (2020) focus on extractive summarization approaches to identify ‘risky sections’ of the privacy policy, which are sentences that are likely to describe a privacy risk posed to the end-u"
2021.acl-long.319,C14-1084,1,0.921082,"es can have impact. 2 2 Our survey includes relevant papers from major NLP venues, including ACL, EMNLP, NAACL, EACL, COLING, CoNLL, SemEval, TACL, and CL. We supplemented these publications with a review of the literature at venues such as SOUPS, PETS, WWW, ACM, and NDSS. We also included relevant legal venues, such as law reviews and journals. 3.1 Data Practice Identification Initial efforts in applying NLP in the privacy domain have largely focused on discovering or identifying data practice categories in privacy policies (Costante et al., 2012a; Ammar et al., 2012; Costante et al., 2012b; Liu et al., 2014b; Ramanath et al., 2014a; Wilson et al., 2016b). Automating the identification of such data practices could potentially support users in navigating privacy policies more effectively3 , as well as automate analysis for regulators who currently do not have techniques to assess a large number of privacy policies. Wilson et al. (2016b) create a corpus of 115 website privacy policies annotated with detailed information of the privacy policies described. The corpus and associated taxonomy have been of utility in the development of several subsequent privacy-enhancing language technologies (Mysore S"
2021.acl-long.319,D18-1099,1,0.920805,"ze the ease of understanding or comprehension of privacy policies. 3 Table 2: Overview of some applications of NLP to privacy policies, and primary stakeholders they are intended to benefit. fectively also requires several additional capabilities such as reasoning over vagueness and ambiguity, understanding elements such as lists (including when they are intended to be exhaustive and when they are not (Bhatia et al., 2016)), effectively incorporating ‘co-text’- aspects of web document structure such as document headers that are meaningful semantically to the content of privacy policies(Mysore Gopinath et al., 2018) and incorporating domain knowledge (for example, understanding whether information is sensitive requires background knowledge in the form of applicable regulation). Privacy policies also differ from several closely related domains, such as legal texts which are largely meant to be processed by domain experts. In contrast, privacy policies are legal documents with legal effects—generally drafted by experts—that are ostensibly meant to be understood by everyday users. NLP applications in the privacy domain also need to be designed with end user requirements in mind. For example, from a legal st"
2021.acl-long.319,D17-1294,1,0.651906,", processing them ef1 For example, in United States v. Path, the defendant’s (Path) privacy policy described that its app collected ”certain information such as your Internet Protocol (IP) address, your operating system, the browser type.” The Federal Trade Commission found this disclosure to be incomplete and insufficient to provide notice about the collection of users’ contact data (FTC, 2013). 4127 Task Goal Consumer Regulator Enterprise 3 3 3 3 Data Practice Identification (Wilson et al., 2016b) Annotate segments of privacy policies with described data practices. 3 Opt-Out Identification (Sathyendra et al., 2017; Bannihatti Kumar et al., 2020) Extract opt-out choices buried in privacy policy text. 3 Compliance Analysis (Zimmeck et al., 2017, 2019a) Analyze mobile app code and privacy policy to identify potential compliance issues. Privacy Question-Answering (Ravichander et al., 2019; Ahmad et al., 2020) Allow consumers to selectively query privacy policies for issues that are important to them. 3 Policy Summarization (Zaeem et al., 2018; Keymanesh et al., 2020) Construct summaries to aid consumers to quickly digest the content of privacy policies. 3 Readability Analysis (Massey et al., 2013; Meiselwi"
2021.acl-long.319,K16-1028,0,0.063998,"Missing"
2021.acl-long.319,D18-1206,0,0.0136915,"cessing privacy policies to meet the needs of Internet and mobile users. NLP has made inroads in digesting large amounts of text in domains such as scientific publications and news (Jain et al., 2020; Cachola et al., 2020; Kang et al., 2018; Rush et al., 2015; See et al., 2017), with several practical tools based on these technologies helping users every day (Cachola et al., 2020; TLDR, 2021; News, 2021). These domains have also received considerable research attention: several benchmark datasets and technologies are based in texts from these domains (Nallapati et al., 2016; See et al., 2017; Narayan et al., 2018; Beltagy et al., 2019). We highlight that the privacy domain can also benefit from increased research attention from the community. Moreover, technologies developed in the privacy domain have potential for significant and large-scale positive social impact—the affected population includes virtually every Internet or mobile user (Sadeh et al., 2013). Automated processing of privacy policies opens the door to a number of scenarios where language technologies can be developed to support users in the context of different tasks. This includes saving data subjects the trouble of having to read the"
2021.acl-long.319,P18-2124,0,0.0209813,"r incomprehensible, irrelevant or atypical. Understanding these factors could lead to the development of more proactive QA functionality- for example, rather than wait for users to form questions, the QA system could prompt users to reflect on certain privacy issues. • Challenges to QA: Additionally, privacy question-answering systems themselves will require several capabilities in order to have larger impact. These systems must be capable of doing question-answering iteratively, working with the user towards resolving information-seeking needs. They will also need to consider unanswerability(Rajpurkar et al., 2018; Ravichander et al., 2019; Asai and Choi, 2020) as a graded problem, recognizing to what extent the privacy policy contains an answer and communicating both what is known and what is not known to the user. QA systems must also consider what kinds of answers are useful, identifying appropriate response format and tailoring answers to the user’s level of knowledge and individual preferences. • Domain Knowledge: It remains an open question how to best incorporate expert knowledge into the processing of privacy policies. Although privacy policies are intended to be read by everyday users, experts"
2021.acl-long.319,P14-2099,1,0.913916,"2 2 Our survey includes relevant papers from major NLP venues, including ACL, EMNLP, NAACL, EACL, COLING, CoNLL, SemEval, TACL, and CL. We supplemented these publications with a review of the literature at venues such as SOUPS, PETS, WWW, ACM, and NDSS. We also included relevant legal venues, such as law reviews and journals. 3.1 Data Practice Identification Initial efforts in applying NLP in the privacy domain have largely focused on discovering or identifying data practice categories in privacy policies (Costante et al., 2012a; Ammar et al., 2012; Costante et al., 2012b; Liu et al., 2014b; Ramanath et al., 2014a; Wilson et al., 2016b). Automating the identification of such data practices could potentially support users in navigating privacy policies more effectively3 , as well as automate analysis for regulators who currently do not have techniques to assess a large number of privacy policies. Wilson et al. (2016b) create a corpus of 115 website privacy policies annotated with detailed information of the privacy policies described. The corpus and associated taxonomy have been of utility in the development of several subsequent privacy-enhancing language technologies (Mysore Sathyendra et al., 2017a;"
2021.acl-long.319,D15-1044,0,0.00968855,"processed before making informed privacy decisions. In practice, people seldom read privacy policies, as this would require prohibitive amounts of their time (McDonald and Cranor, 2008; Cate, 2010; Cranor, 2012; Reidenberg et al., 2015; Schaub et al., 2015; Jain et al., 2016). Thus, an opportunity exists for language technologies to bridge this gap by processing privacy policies to meet the needs of Internet and mobile users. NLP has made inroads in digesting large amounts of text in domains such as scientific publications and news (Jain et al., 2020; Cachola et al., 2020; Kang et al., 2018; Rush et al., 2015; See et al., 2017), with several practical tools based on these technologies helping users every day (Cachola et al., 2020; TLDR, 2021; News, 2021). These domains have also received considerable research attention: several benchmark datasets and technologies are based in texts from these domains (Nallapati et al., 2016; See et al., 2017; Narayan et al., 2018; Beltagy et al., 2019). We highlight that the privacy domain can also benefit from increased research attention from the community. Moreover, technologies developed in the privacy domain have potential for significant and large-scale posi"
2021.acl-long.319,P17-1099,0,0.0119906,"aking informed privacy decisions. In practice, people seldom read privacy policies, as this would require prohibitive amounts of their time (McDonald and Cranor, 2008; Cate, 2010; Cranor, 2012; Reidenberg et al., 2015; Schaub et al., 2015; Jain et al., 2016). Thus, an opportunity exists for language technologies to bridge this gap by processing privacy policies to meet the needs of Internet and mobile users. NLP has made inroads in digesting large amounts of text in domains such as scientific publications and news (Jain et al., 2020; Cachola et al., 2020; Kang et al., 2018; Rush et al., 2015; See et al., 2017), with several practical tools based on these technologies helping users every day (Cachola et al., 2020; TLDR, 2021; News, 2021). These domains have also received considerable research attention: several benchmark datasets and technologies are based in texts from these domains (Nallapati et al., 2016; See et al., 2017; Narayan et al., 2018; Beltagy et al., 2019). We highlight that the privacy domain can also benefit from increased research attention from the community. Moreover, technologies developed in the privacy domain have potential for significant and large-scale positive social impact—"
2021.acl-long.319,D19-1500,1,0.844146,"this disclosure to be incomplete and insufficient to provide notice about the collection of users’ contact data (FTC, 2013). 4127 Task Goal Consumer Regulator Enterprise 3 3 3 3 Data Practice Identification (Wilson et al., 2016b) Annotate segments of privacy policies with described data practices. 3 Opt-Out Identification (Sathyendra et al., 2017; Bannihatti Kumar et al., 2020) Extract opt-out choices buried in privacy policy text. 3 Compliance Analysis (Zimmeck et al., 2017, 2019a) Analyze mobile app code and privacy policy to identify potential compliance issues. Privacy Question-Answering (Ravichander et al., 2019; Ahmad et al., 2020) Allow consumers to selectively query privacy policies for issues that are important to them. 3 Policy Summarization (Zaeem et al., 2018; Keymanesh et al., 2020) Construct summaries to aid consumers to quickly digest the content of privacy policies. 3 Readability Analysis (Massey et al., 2013; Meiselwitz, 2013) Characterize the ease of understanding or comprehension of privacy policies. 3 Table 2: Overview of some applications of NLP to privacy policies, and primary stakeholders they are intended to benefit. fectively also requires several additional capabilities such as r"
2021.acl-long.319,P16-1126,1,0.315271,"though policies tend to feature literal language (compared to more subjective domains like literature or blog posts), processing them ef1 For example, in United States v. Path, the defendant’s (Path) privacy policy described that its app collected ”certain information such as your Internet Protocol (IP) address, your operating system, the browser type.” The Federal Trade Commission found this disclosure to be incomplete and insufficient to provide notice about the collection of users’ contact data (FTC, 2013). 4127 Task Goal Consumer Regulator Enterprise 3 3 3 3 Data Practice Identification (Wilson et al., 2016b) Annotate segments of privacy policies with described data practices. 3 Opt-Out Identification (Sathyendra et al., 2017; Bannihatti Kumar et al., 2020) Extract opt-out choices buried in privacy policy text. 3 Compliance Analysis (Zimmeck et al., 2017, 2019a) Analyze mobile app code and privacy policy to identify potential compliance issues. Privacy Question-Answering (Ravichander et al., 2019; Ahmad et al., 2020) Allow consumers to selectively query privacy policies for issues that are important to them. 3 Policy Summarization (Zaeem et al., 2018; Keymanesh et al., 2020) Construct summaries"
2021.calcs-1.13,2020.findings-emnlp.148,0,0.40775,"ance for codeswitched languages in tasks like offensive language identification (Jayanthi and Gupta, 2021) and sentiment analysis (Gupta et al., 2021). We will build unsupervised models on top of BERT. BERT (Devlin et al., 2018) based models have achieved state of the art performance in many downstream tasks due to their superior contextualized representations 3.1 Optimizing Performance of language, providing true bidirectional context The most important blocks in the Unsupervised to word embeddings. We will use the sentiment Self-Training framework with respect to maximizanalysis model from (Barbieri et al., 2020), trained ing performance are the Initialization Block and the on a large corpus of English Tweets (60 million Tweets) for initializing our algorithm. We will re- Selection Block (Figure 1). To improve initialization, we must choose the most compatible model fer to the sentiment analysis model from (Barbieri et al., 2020) as the TweetEval model in the remain- for the chosen task. Additionally, to improve performance, we can use several training strategies der of the paper. The TweetEval model is built 1 on top of an English RoBERTa (Liu et al., 2019) The code for the framework can be found her"
2021.calcs-1.13,2020.sltu-1.25,0,0.514986,"aining such that we only use the zero-shot predictions made by our initialization model to train our models and never use actual labels. Sentiment analysis is a popular task in industry as well as within the research community, used in analysing the markets (Nanli et al., 2012), election campaigns (Haselmayer and Jenny, 2017) etc. A large amount of social media text in most bilingual communities is code-mixed and many labelled datasets have been released to perform sentiment analysis. We will be working with four code-mixed datasets for sentiment analysis, Malayalam-English and Tamil-English (Chakravarthi et al., 2020a,b,c) and Spanglish and Hinglish (Patwa et al., 2020). 3 Proposed Approach: Unsupervised Self-Training Our proposed algorithm is centred around the idea of creating an unsupervised learning algorithm that is able to harness the power of cross-lingual transfer in the most efficient way possible, with the aim of producing unsupervised sentiment labels. In its most fundamental form, our proposed Unsupervised Self-Training algorithm1 is shown in Figure 1 is shown in Figure 1. We begin by producing zero-shot results for sentiment classification using a selected pre-trained model trained for the sa"
2021.calcs-1.13,2020.sltu-1.28,0,0.5193,"aining such that we only use the zero-shot predictions made by our initialization model to train our models and never use actual labels. Sentiment analysis is a popular task in industry as well as within the research community, used in analysing the markets (Nanli et al., 2012), election campaigns (Haselmayer and Jenny, 2017) etc. A large amount of social media text in most bilingual communities is code-mixed and many labelled datasets have been released to perform sentiment analysis. We will be working with four code-mixed datasets for sentiment analysis, Malayalam-English and Tamil-English (Chakravarthi et al., 2020a,b,c) and Spanglish and Hinglish (Patwa et al., 2020). 3 Proposed Approach: Unsupervised Self-Training Our proposed algorithm is centred around the idea of creating an unsupervised learning algorithm that is able to harness the power of cross-lingual transfer in the most efficient way possible, with the aim of producing unsupervised sentiment labels. In its most fundamental form, our proposed Unsupervised Self-Training algorithm1 is shown in Figure 1 is shown in Figure 1. We begin by producing zero-shot results for sentiment classification using a selected pre-trained model trained for the sa"
2021.calcs-1.13,P19-4007,0,0.0583948,"Missing"
2021.calcs-1.13,2021.naacl-main.426,0,0.0699046,"Missing"
2021.calcs-1.13,2021.ccl-1.108,0,0.0580296,"Missing"
2021.calcs-1.13,P95-1026,0,0.883959,"Missing"
2021.calcs-1.13,2021.dravidianlangtech-1.44,1,0.766875,"sensitive to initialization. Care must be taken to initialize the algorithm with a compatible model. For example, for the task of sentiment classification of Hinglish Twitter data, an example of a compatible initial model would be a sentiment classification model trained on either English or Hindi sentiment data. It would be even more compatible if the model was trained on Twitter sentiment data, the data thus being from the same domain. Previous work has shown BERT based models to achieve state of the art performance for codeswitched languages in tasks like offensive language identification (Jayanthi and Gupta, 2021) and sentiment analysis (Gupta et al., 2021). We will build unsupervised models on top of BERT. BERT (Devlin et al., 2018) based models have achieved state of the art performance in many downstream tasks due to their superior contextualized representations 3.1 Optimizing Performance of language, providing true bidirectional context The most important blocks in the Unsupervised to word embeddings. We will use the sentiment Self-Training framework with respect to maximizanalysis model from (Barbieri et al., 2020), trained ing performance are the Initialization Block and the on a large corpus of"
2021.calcs-1.14,W18-1105,0,0.0531044,"Missing"
2021.calcs-1.14,Q17-1010,0,0.0213486,"rent views of an input. Text Tokenization: Motivated by some recent related works on using different word-level and sub-word-level embeddings (Winata et al., 2019; Aguilar and Solorio, 2020), our toolkit offers different tokenization methods for encoding text. Among the encoders available in our toolkit (§ 2.2), pretrained transformer-based encoders can either be tokenized using their default tokenization technique (i.e. subwords) or by using a character-CNN architecture (Boukkouri et al., 2020). LSTM-based models can take inputs in the form of tensor representations– eg. word-level FastText (Bojanowski et al., 2017) or semi-character (Sakaguchi et al., 2017) representations, or character-level representations– eg. char-BiLSTM3 . Tag-Informed Modeling: Studies in the past have shown the usefulness of language tag-aware modeling for mixed and cross-lingual 3 114 Sequence Tagging with Tensorflow Benchmarking transformer based models (F1 / Accuracy) Text Classification Tasks Sentiment Classification Model mBert w/ Task adaptive w/ Domain adaptive XLM-RoBERTa w/ Task adaptive w/ Domain adaptive HIN-ENG1 65.9 / 65.7 67.4 / 67.2 71.4 / 71.3 68.9 / 69.1 70.4 / 70.4 72.1 / 72.2 HIN-ENG2 58.8 / 60.7 61.4 / 61.5 62"
2021.calcs-1.14,2020.coling-main.609,0,0.0773521,"Missing"
2021.calcs-1.14,2020.acl-main.740,0,0.0383212,"Missing"
2021.calcs-1.14,2020.sltu-1.28,0,0.0889987,"Missing"
2021.calcs-1.14,2021.dravidianlangtech-1.44,1,0.781941,"Missing"
2021.calcs-1.14,W18-3211,1,0.915104,"view integration w/ language-tag informed w/ fasttext-BiLSTM fusion w/ char-BiLSTM fusion w/ semi-char-BiLSTM fusion w/ data noising w/ monolingual corpora Sentiment Classification HIN-ENG1 HIN-ENG2 68.9 / 69.1 61.5 / 61.5 71.1 / 71.3 62.0 / 62.8 68.9 / 69.3 62.8 / 63.1 69.9 / 70.0 61.2 / 62.1 69.3 / 69.1 62.0 / 62.3 69.4 / 68.9 60.0 / 60.8 70.5 / 70.5 61.9 / 62.2 68.9 / 69.3 68.2 / 68.3 Table 2: Results of various modelling techniques (F1 / Accuracy) when used with a pretrained transformers-based encoder. HIN-ENG1 refers (Patwa et al., 2020) and HIN-ENG2 refers to (Patra et al., 2018) texts (Chandu et al., 2018; Lample and Conneau, 2019). However, their usefulness in the context of pretrained models and code-mixing is not thoroughly investigated. To this end, we offer a more generalized method in our toolkit to conduct any tag-aware fine-tuning, wherein representations for different kinds of tags can be added to the text representations. Examples of such tags include POS tags, Language IDs, etc. 2.2 Models Encoders: An Encoder in our toolkit can consist of a transformer-based or BiLSTM-based architecture. Specifically, for the former, we utilize pretrained models from the HuggingFace library (Wolf e"
2021.calcs-1.14,W18-4401,0,0.0624015,"Missing"
2021.calcs-1.14,2020.semeval-1.100,0,0.0708122,"Missing"
2021.calcs-1.14,P19-1493,0,0.0167129,"r-based models such as Multilingual BERT (Devlin et al., The NLP community has witnessed steep 2019) & XLM-RoBERTa (Conneau et al., 2020), progress in a variety of tasks across the realms and their pretraining techniques. On various mixed of monolingual and multilingual language processing recently. These successes, in datasets, recent studies have shown that adopting conjunction with the proliferating mixed multilingual pretrained models can perform better language interactions on social media have than their previous deep learning counterparts boosted interest in modeling code-mixed texts. (Pires et al., 2019; Khanuja et al., 2020; Aguilar In this work, we present C ODEMIXED NLP, an et al., 2020; Chakravarthy et al., 2020; Jayanthi open-source library with the goals of bringing and Gupta, 2021). While this looks promising together the advances in code-mixed NLP and for multilingual, the same is not translated to opening it up to a wider machine learning community. The library consists of tools code-mixing. Hence, a critical investigation is to develop and benchmark versatile model required to understand generalizable modeling architectures that are tailored for mixed texts, strategies to enhance p"
2021.calcs-1.14,2021.calcs-1.20,0,0.0226883,", an et al., 2020; Chakravarthy et al., 2020; Jayanthi open-source library with the goals of bringing and Gupta, 2021). While this looks promising together the advances in code-mixed NLP and for multilingual, the same is not translated to opening it up to a wider machine learning community. The library consists of tools code-mixing. Hence, a critical investigation is to develop and benchmark versatile model required to understand generalizable modeling architectures that are tailored for mixed texts, strategies to enhance performance on mixed texts methods to expand training sets, techniques (Winata et al., 2021; Aguilar and Solorio, 2020; to quantify mixing styles, and fine-tuned Sitaram et al., 2020). state-of-the-art models for 7 tasks in Hinglish1 . At the same time, practitioners who require We believe this work has a potential to foster an off-the-shelf tool into their downstream a distributed yet collaborative and sustainable ecosystem in an otherwise dispersed space of mixed text application (eg. sentiment or code-mixing research. The toolkit is designed language identification), currently have to resort to be simple, easily extensible, and resourceful to monolingual toolkits such as NLTK, Fl"
2021.dravidianlangtech-1.9,2020.findings-emnlp.148,0,0.651064,"n problem, where each query is classified to have a positive, negative or neutral sentiment (Thavareesan and Mahesan, 2019, 2020a,b; Nanli et al., 2012). It has various applications like understanding the sentiment of different tweets, facebook and youtube comments, understanding product reviews etc (Puranik et al., 2021; Hegde et al., 2021; Yasaswini et al., 2021; Ghanghor et al., 2021b,a). In times of the pandemic, where the entire world is living online, it has become an even more important tool . Robust systems for sentiment analysis already exist for high resource languages like English (Barbieri et al., 2020), yet progress needs to be made for lower resource and code-switched languages. One of the major bottlenecks in dealing with Code-Switched languages is the lack of availability of annotated datasets in the Code-Mixed languages. To alleviate this problem for Dravidian languages, datasets have been released for Sentiment Analysis in Tamil-English (Chakravarthi et al., 2020b) and Malayalam-English (Chakravarthi et al., 2020a). Various shared tasks (Patwa et al., 2020) (Chakravarthi et al., 2020c) have also been accompanied by the release of these datasets to advance research in this domain. Model"
2021.dravidianlangtech-1.9,2020.sltu-1.25,0,0.382344,"anghor et al., 2021b,a). In times of the pandemic, where the entire world is living online, it has become an even more important tool . Robust systems for sentiment analysis already exist for high resource languages like English (Barbieri et al., 2020), yet progress needs to be made for lower resource and code-switched languages. One of the major bottlenecks in dealing with Code-Switched languages is the lack of availability of annotated datasets in the Code-Mixed languages. To alleviate this problem for Dravidian languages, datasets have been released for Sentiment Analysis in Tamil-English (Chakravarthi et al., 2020b) and Malayalam-English (Chakravarthi et al., 2020a). Various shared tasks (Patwa et al., 2020) (Chakravarthi et al., 2020c) have also been accompanied by the release of these datasets to advance research in this domain. Models built on top of contextualized word embeddings have recently received huge amount of success and are used in most state of the art models. Systems built on top of BERT (Devlin et al., 2018) and its multilingual variants mBERT and XLMRoBERTa (Conneau et al., 2019) have been the top ranking systems in both the above competitions. In this paper, we train four different BE"
2021.dravidianlangtech-1.9,2021.ltedi-1.8,0,0.024254,"Missing"
2021.dravidianlangtech-1.9,2020.sltu-1.28,0,0.322502,"anghor et al., 2021b,a). In times of the pandemic, where the entire world is living online, it has become an even more important tool . Robust systems for sentiment analysis already exist for high resource languages like English (Barbieri et al., 2020), yet progress needs to be made for lower resource and code-switched languages. One of the major bottlenecks in dealing with Code-Switched languages is the lack of availability of annotated datasets in the Code-Mixed languages. To alleviate this problem for Dravidian languages, datasets have been released for Sentiment Analysis in Tamil-English (Chakravarthi et al., 2020b) and Malayalam-English (Chakravarthi et al., 2020a). Various shared tasks (Patwa et al., 2020) (Chakravarthi et al., 2020c) have also been accompanied by the release of these datasets to advance research in this domain. Models built on top of contextualized word embeddings have recently received huge amount of success and are used in most state of the art models. Systems built on top of BERT (Devlin et al., 2018) and its multilingual variants mBERT and XLMRoBERTa (Conneau et al., 2019) have been the top ranking systems in both the above competitions. In this paper, we train four different BE"
2021.dravidianlangtech-1.9,P19-4007,0,0.0429164,"Missing"
2021.dravidianlangtech-1.9,2021.dravidianlangtech-1.30,0,0.058019,"Missing"
2021.dravidianlangtech-1.9,2021.ltedi-1.30,0,0.0595396,"Missing"
2021.dravidianlangtech-1.9,2021.dravidianlangtech-1.16,0,0.0560469,"Missing"
2021.dravidianlangtech-1.9,2021.dravidianlangtech-1.24,0,0.0191203,"ew.cmu.edu, {srallaba, awb}@cs.cmu.edu Abstract Muralidaran, 2021; Chakravarthi et al., 2021b; Suryawanshi and Chakravarthi, 2021). Sentiment analysis poses the task of inferring opinion and emotions of a text query (usually social media comments or Tweets) as a classification problem, where each query is classified to have a positive, negative or neutral sentiment (Thavareesan and Mahesan, 2019, 2020a,b; Nanli et al., 2012). It has various applications like understanding the sentiment of different tweets, facebook and youtube comments, understanding product reviews etc (Puranik et al., 2021; Hegde et al., 2021; Yasaswini et al., 2021; Ghanghor et al., 2021b,a). In times of the pandemic, where the entire world is living online, it has become an even more important tool . Robust systems for sentiment analysis already exist for high resource languages like English (Barbieri et al., 2020), yet progress needs to be made for lower resource and code-switched languages. One of the major bottlenecks in dealing with Code-Switched languages is the lack of availability of annotated datasets in the Code-Mixed languages. To alleviate this problem for Dravidian languages, datasets have been released for Sentiment"
2021.eacl-main.259,2020.lrec-1.232,0,0.0459699,"Missing"
2021.eacl-main.259,H94-1010,0,0.534753,"greater community interest in the issues that arise when our systems actually need to be of utility to humans.1 1 Introduction Everyday users now benefit from powerful QA technologies in a range of consumer-facing applications including health (Jacquemart and Zweigenbaum, 2003; Luo et al., 2015; Abacha and DemnerFushman, 2016; Kilicoglu et al., 2018; Guo et al., 2018), privacy (Sathyendra et al., 2017; Harkous et al., 2018; Ravichander et al., 2019), personal finance (Alloatti et al., 2019), search (Yang, 2015; Bajaj et al., 2016; He et al., 2018; Kwiatkowski et al., 2019) and dialog agents (Dahl et al., 1994; Raux et al., 2005). Voice assistants such as Amazon Alexa2 or Google Home3 have brought natural language technologies to several million homes globally (Osborne, 2016; Jeffs, 2018). Yet, even with 1 All resources available at noiseqa.github.io . developer.amazon.com/alexa 3 assistant.google.com 2 millions of users now interacting with these technologies on a daily basis, there has been surprisingly little research attention devoted to studying the issues that arise when people use QA systems. Traditional QA evaluations do not reflect the needs of many users who can benefit from QA technologi"
2021.eacl-main.259,N19-1423,0,0.528759,"cenario of the noise being introduced to the question by the interface through which the user interacts with the QA engine. For each type of noise, we both build a synthetic generator that can introduce noise on a large scale, as well as manually create ‘natural’ noise challenge sets to imitate real-world noise. Our challenge sets are based on SQuAD 1.1 (Rajpurkar et al., 2016),7 a large-scale machine comprehension dataset based on Wikipedia articles where the answer to each question is a span in a provided context. We choose SQuAD both for its popularity as a benchmark (Gardner et al., 2018; Devlin et al., 2019; Radford et al., 2018; Wolf et al., 2019) and to avoid additional confounds such as unanswerable questions (Rajpurkar et al., 2018).8 We use the standard ∼90K/10K train/development split and construct the challenge sets from the XQuAD data (Artetxe et al., 2020), a subset of 1,190 SQuAD development set questions accompanied by professional translations into ten languages.9 Below we discuss each challenge set in more detail. 7 Though in principle, these constructions could be applied to any kind of QA dataset 8 Future work would pursue a context-driven evaluation of unanswerability, identifyin"
2021.eacl-main.259,D17-1091,0,0.0246754,"9; Asai and Choi, 2020). 9 Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi. 2977 3.1 MT Noise O RIGINAL How many Panthers defense players were seQ UESTION lected for the Pro Bowl? Our first challenge set emulates machine translation noise introduced when the question is asked in a language other than the language of the QA system’s training data. We use English as the QA system language, pairing English contexts with non-English questions. Synthetic Challenge Set Our synthetic noise generator employs the back-translation technique (Sennrich et al., 2016; Dong et al., 2017; Yu et al., 2018). In our case, back-translation is not meant to act as a data augmentation technique but rather to simulate noise that could be introduced by an MT engine when translating the question from another language. We imperfectly approximate natural non-English input by automatically translating English questions into a pivot language (German); we then translate them back to English, imitating a scenario where the user submits a query through an MT engine. We use the HuggingFace implementation (Wolf et al., 2019) of MarianNMT (JunczysDowmunt et al., 2018).10 Natural Challenge Set To"
2021.eacl-main.259,W18-2501,0,0.0161915,"eplicate a realistic scenario of the noise being introduced to the question by the interface through which the user interacts with the QA engine. For each type of noise, we both build a synthetic generator that can introduce noise on a large scale, as well as manually create ‘natural’ noise challenge sets to imitate real-world noise. Our challenge sets are based on SQuAD 1.1 (Rajpurkar et al., 2016),7 a large-scale machine comprehension dataset based on Wikipedia articles where the answer to each question is a span in a provided context. We choose SQuAD both for its popularity as a benchmark (Gardner et al., 2018; Devlin et al., 2019; Radford et al., 2018; Wolf et al., 2019) and to avoid additional confounds such as unanswerable questions (Rajpurkar et al., 2018).8 We use the standard ∼90K/10K train/development split and construct the challenge sets from the XQuAD data (Artetxe et al., 2020), a subset of 1,190 SQuAD development set questions accompanied by professional translations into ten languages.9 Below we discuss each challenge set in more detail. 7 Though in principle, these constructions could be applied to any kind of QA dataset 8 Future work would pursue a context-driven evaluation of unansw"
2021.eacl-main.259,P18-2103,0,0.0285693,"similar to how our synthetic set is constructed. However, our results show that TTS does not realistically replicate human voice variation. Besides, stakeholders relying on commercial transcription services will not have white2983 box access to ASR; our post-hoc mitigation strategies would be better suited for such cases. Challenge sets Model robustness evaluation with adversarial schemes is common in NLP tasks (Smith, 2012), including dependency parsing (Rimell et al., 2009), information extraction (Schneider et al., 2017), natural language inference (Marelli et al., 2014; Naik et al., 2018; Glockner et al., 2018), machine translation (Isabelle et al., 2017; Belinkov and Bisk, 2018; Bawden et al., 2018; Burlot and Yvon, 2017) and QA (Jia and Liang, 2017; Aspillaga et al., 2020). Unlike most prior work, we do not create our challenge sets to break QA systems, but rather for a more realistic evaluation of the systems’ real-world utility. 6 Conclusion In this work, we advocate for QA evaluations that reflect challenges associated with real-world use. In particular, we focus on questions that are written in another language, spoken, or typed, and the noise introduced into them by the corresponding interfac"
2021.eacl-main.259,W18-2605,0,0.0160728,"consider real-world use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans.1 1 Introduction Everyday users now benefit from powerful QA technologies in a range of consumer-facing applications including health (Jacquemart and Zweigenbaum, 2003; Luo et al., 2015; Abacha and DemnerFushman, 2016; Kilicoglu et al., 2018; Guo et al., 2018), privacy (Sathyendra et al., 2017; Harkous et al., 2018; Ravichander et al., 2019), personal finance (Alloatti et al., 2019), search (Yang, 2015; Bajaj et al., 2016; He et al., 2018; Kwiatkowski et al., 2019) and dialog agents (Dahl et al., 1994; Raux et al., 2005). Voice assistants such as Amazon Alexa2 or Google Home3 have brought natural language technologies to several million homes globally (Osborne, 2016; Jeffs, 2018). Yet, even with 1 All resources available at noiseqa.github.io . developer.amazon.com/alexa 3 assistant.google.com 2 millions of users now interacting with these technologies on a daily basis, there has been surprisingly little research attention devoted to studying the issues that arise when people use QA systems. Traditional QA evaluations do not re"
2021.eacl-main.259,D19-1259,0,0.0166616,"g natural data is infeasible, but individual practitioners should carefully identify and simulate the likely sources of error appropriate for their applications. 5 Related Work Question Answering QA systems have a rich history in NLP, with early successes in domainspecific applications (Green et al., 1961; Woods, 1977; Wilensky et al., 1988; Hirschman and Gaizauskas, 2001). Considerable research effort has been devoted to collecting datasets to support a wider variety of applications (Quaresma and Pimenta Rodrigues, 2005; Monroy et al., 2009; Feng et al., 2015; Liu et al., 2015; Nguyen, 2019; Jin et al., 2019) and improving model performance on them (Lally et al., 2017; Wang et al., 2018; Yu et al., 2018; Yang et al., 2019). We too focus on QA systems but center the utility to users rather than new applications or techniques. There has also been interest in studying the interaction between speech and QA systems. Lee et al. (2018a) examine transcription errors for Chinese QA, and Lee et al. (2018b) propose Spoken SQuAD, with spoken contexts and text-based questions, but they address a fundamentally different use case of searching through speech. Closest to our work is that of Peskov et al. (2019), w"
2021.eacl-main.259,P18-4020,0,0.0317587,"Missing"
2021.eacl-main.259,Q19-1026,0,0.0241109,"rld use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans.1 1 Introduction Everyday users now benefit from powerful QA technologies in a range of consumer-facing applications including health (Jacquemart and Zweigenbaum, 2003; Luo et al., 2015; Abacha and DemnerFushman, 2016; Kilicoglu et al., 2018; Guo et al., 2018), privacy (Sathyendra et al., 2017; Harkous et al., 2018; Ravichander et al., 2019), personal finance (Alloatti et al., 2019), search (Yang, 2015; Bajaj et al., 2016; He et al., 2018; Kwiatkowski et al., 2019) and dialog agents (Dahl et al., 1994; Raux et al., 2005). Voice assistants such as Amazon Alexa2 or Google Home3 have brought natural language technologies to several million homes globally (Osborne, 2016; Jeffs, 2018). Yet, even with 1 All resources available at noiseqa.github.io . developer.amazon.com/alexa 3 assistant.google.com 2 millions of users now interacting with these technologies on a daily basis, there has been surprisingly little research attention devoted to studying the issues that arise when people use QA systems. Traditional QA evaluations do not reflect the needs of many use"
2021.eacl-main.259,P18-1157,0,0.0123339,"evaluation of QA systems that takes into account the challenges associated with their real-world deployment. We hope to encourage development of future user-centered or participatory design approaches to building QA datasets and evaluations, where practitioners work with potential users to understand user requirements and the contexts in which systems are used in practice. Community priorities for QA systems: While leaderboards on established benchmarks have facilitated rapid progress (Rajpurkar et al., 2016, 2018) and bolstered development of a variety of semantic models (Xiong et al., 2018; Liu et al., 2018; Huang et al., 2018; Devlin et al., 2019), we call for practitioners to consider the orthogonal direction of system utility in their model design. We believe these subareas to be complementary, and community attention towards both will help produce NLP systems that are both accurate and usable. Acknowledgments We thank Aakanksha Naik, Sujeath Pareddy, Taylor Berg-Kirkpatrick, and Matthew Gormley for helpful discussion and the anonymous reviewers for their valuable feedback. This work used the Bridges system, which is supported by NSF award number ACI-1445606, at the Pittsburgh Supercomputing"
2021.eacl-main.259,L18-1429,1,0.894188,"Missing"
2021.eacl-main.259,C18-1198,1,0.92991,"ons paired with professional translations into ten other languages.11 For each of the test set languages, we use Google’s commercial translation engine12 to produce the English translation of the question. This allows us to construct ten challenge sets of translations from different languages with 1,190 questions each. 3.2 Keyboard Noise This challenge set represents the noise introduced in the process of typing a question up on a keyboard, for example, when a question is submitted to a QA system through a search engine. Synthetic Challenge Set Inspired by prior work (Belinkov and Bisk, 2018; Naik et al., 2018), our basic noise generator introduces per-character 10 huggingface.co/Helsinki-NLP/ opus-mt-{en-de|de-en} 11 A subtle nuance is that XQuAD questions are not originally written in these languages but translated from English; acknowledging this, we use XQuAD data as the natural challenge set because its fully parallel nature allows varying input language while controlling for content for fair comparison. 12 translate.google.com G OOGLE ASR how many Santa’s defense players selected for the Pro Bowl ESP NET how many pantols the tent places were slected ( WITH LM) for the probol K ALDI how many fr"
2021.eacl-main.259,P19-2008,0,0.021171,"when collecting natural data is infeasible, but individual practitioners should carefully identify and simulate the likely sources of error appropriate for their applications. 5 Related Work Question Answering QA systems have a rich history in NLP, with early successes in domainspecific applications (Green et al., 1961; Woods, 1977; Wilensky et al., 1988; Hirschman and Gaizauskas, 2001). Considerable research effort has been devoted to collecting datasets to support a wider variety of applications (Quaresma and Pimenta Rodrigues, 2005; Monroy et al., 2009; Feng et al., 2015; Liu et al., 2015; Nguyen, 2019; Jin et al., 2019) and improving model performance on them (Lally et al., 2017; Wang et al., 2018; Yu et al., 2018; Yang et al., 2019). We too focus on QA systems but center the utility to users rather than new applications or techniques. There has also been interest in studying the interaction between speech and QA systems. Lee et al. (2018a) examine transcription errors for Chinese QA, and Lee et al. (2018b) propose Spoken SQuAD, with spoken contexts and text-based questions, but they address a fundamentally different use case of searching through speech. Closest to our work is that of Pesk"
2021.eacl-main.259,marelli-etal-2014-sick,0,0.0223911,"nscribes speech using TTS–ASR pipelines, similar to how our synthetic set is constructed. However, our results show that TTS does not realistically replicate human voice variation. Besides, stakeholders relying on commercial transcription services will not have white2983 box access to ASR; our post-hoc mitigation strategies would be better suited for such cases. Challenge sets Model robustness evaluation with adversarial schemes is common in NLP tasks (Smith, 2012), including dependency parsing (Rimell et al., 2009), information extraction (Schneider et al., 2017), natural language inference (Marelli et al., 2014; Naik et al., 2018; Glockner et al., 2018), machine translation (Isabelle et al., 2017; Belinkov and Bisk, 2018; Bawden et al., 2018; Burlot and Yvon, 2017) and QA (Jia and Liang, 2017; Aspillaga et al., 2020). Unlike most prior work, we do not create our challenge sets to break QA systems, but rather for a more realistic evaluation of the systems’ real-world utility. 6 Conclusion In this work, we advocate for QA evaluations that reflect challenges associated with real-world use. In particular, we focus on questions that are written in another language, spoken, or typed, and the noise introdu"
2021.eacl-main.259,N18-1202,0,0.0114719,"three kinds of interface errors. For practitioners, this could suggest that simply choosing the highest-accuracy QA model without separately evaluating robustness to interface noise may lead to sub-optimal performance in practice. Below we discuss the effect of each interface in more detail. 14 F1 scores on SQuAD dev set: BiDAF: 77.8; BiDAFELMo: 80.7; BERT: 88.8; RoBERTa: 89.9. For hyperparameters and implementation details, see Appendix A. 15 Uncased detokenized BLEU using SacreBLEU (Post, 2018). 2979 XQuADE N Model EM ASR F1 EM MT Keyboard F1 EM F1 EM F1 BiDAF (Seo et al., 2017) BiDAF-ELMo (Peters et al., 2018) BERT (Devlin et al., 2019) RoBERTa (Liu et al., 2019) 60.08 62.61 72.77 72.35 Synthetic 71.96 54.62 75.38 56.81 84.66 61.93 84.42 68.07 66.39 70.30 77.02 81.38 55.97 57.39 67.23 68.40 68.01 70.05 79.08 80.93 45.21 50.93 61.76 65.04 57.78 63.80 73.64 76.97 BiDAF (Seo et al., 2017) BiDAF-ELMo (Peters et al., 2018) BERT (Devlin et al., 2019) RoBERTa (Liu et al., 2019) 60.08 62.61 72.77 72.35 Natural 71.96 45.97 75.38 49.16 84.66 52.94 84.42 60.08 57.64 62.49 67.13 73.61 54.87 59.24 68.82 70.00 66.90 71.06 79.98 82.13 56.89 60.76 69.16 70.92 68.33 73.32 81.84 83.37 Table 4: Performance of the QA"
2021.eacl-main.259,W18-6319,0,0.0200446,"Missing"
2021.eacl-main.259,D16-1264,0,0.73846,"with QA systems.6 We analyze errors introduced by three interface types that could be connected to a QA engine: speech recognizers converting spoken queries to text, keyboards used to type queries into the system, and translation systems processing queries in other languages. Our contributions are as follows: 1. We identify and describe the problem of interface noise for QA systems. We construct a challenge set framework for errors introduced by three kinds of interfaces: speech recognizers, keyboard interfaces, and translation engines, based on the popular SQuAD questionanswering benchmark (Rajpurkar et al., 2016). We define synthetic noise generators, as well 4 More than 3.4 million American adults over the age of 40 have a form of visual impairment (Congdon et al., 2004). 5 As of 2021-01-24, there are 6,235,415 articles on English Wikipedia making it the largest edition: wikicount.net 6 ‘QA system’ refers to any computing engine that receives a users’ question and constructs an answer. It may consist of an end-to-end neural architecture or a structured pipeline. 2976 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 2976–2992 April 19 -"
2021.eacl-main.259,D19-1500,1,0.939257,"for progress before QA systems can be effectively deployed, highlight the need for QA evaluation to expand to consider real-world use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans.1 1 Introduction Everyday users now benefit from powerful QA technologies in a range of consumer-facing applications including health (Jacquemart and Zweigenbaum, 2003; Luo et al., 2015; Abacha and DemnerFushman, 2016; Kilicoglu et al., 2018; Guo et al., 2018), privacy (Sathyendra et al., 2017; Harkous et al., 2018; Ravichander et al., 2019), personal finance (Alloatti et al., 2019), search (Yang, 2015; Bajaj et al., 2016; He et al., 2018; Kwiatkowski et al., 2019) and dialog agents (Dahl et al., 1994; Raux et al., 2005). Voice assistants such as Amazon Alexa2 or Google Home3 have brought natural language technologies to several million homes globally (Osborne, 2016; Jeffs, 2018). Yet, even with 1 All resources available at noiseqa.github.io . developer.amazon.com/alexa 3 assistant.google.com 2 millions of users now interacting with these technologies on a daily basis, there has been surprisingly little research attention devoted"
2021.eacl-main.259,D09-1085,0,0.054855,"in QA, assuming whitebox access to the ASR systems. Most such work automatically generates and transcribes speech using TTS–ASR pipelines, similar to how our synthetic set is constructed. However, our results show that TTS does not realistically replicate human voice variation. Besides, stakeholders relying on commercial transcription services will not have white2983 box access to ASR; our post-hoc mitigation strategies would be better suited for such cases. Challenge sets Model robustness evaluation with adversarial schemes is common in NLP tasks (Smith, 2012), including dependency parsing (Rimell et al., 2009), information extraction (Schneider et al., 2017), natural language inference (Marelli et al., 2014; Naik et al., 2018; Glockner et al., 2018), machine translation (Isabelle et al., 2017; Belinkov and Bisk, 2018; Bawden et al., 2018; Burlot and Yvon, 2017) and QA (Jia and Liang, 2017; Aspillaga et al., 2020). Unlike most prior work, we do not create our challenge sets to break QA systems, but rather for a more realistic evaluation of the systems’ real-world utility. 6 Conclusion In this work, we advocate for QA evaluations that reflect challenges associated with real-world use. In particular,"
2021.eacl-main.259,W17-5402,0,0.055776,"Missing"
2021.eacl-main.259,P16-1009,0,0.0126541,"Ravichander et al., 2019; Asai and Choi, 2020). 9 Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi. 2977 3.1 MT Noise O RIGINAL How many Panthers defense players were seQ UESTION lected for the Pro Bowl? Our first challenge set emulates machine translation noise introduced when the question is asked in a language other than the language of the QA system’s training data. We use English as the QA system language, pairing English contexts with non-English questions. Synthetic Challenge Set Our synthetic noise generator employs the back-translation technique (Sennrich et al., 2016; Dong et al., 2017; Yu et al., 2018). In our case, back-translation is not meant to act as a data augmentation technique but rather to simulate noise that could be introduced by an MT engine when translating the question from another language. We imperfectly approximate natural non-English input by automatically translating English questions into a pivot language (German); we then translate them back to English, imitating a scenario where the user submits a query through an MT engine. We use the HuggingFace implementation (Wolf et al., 2019) of MarianNMT (JunczysDowmunt et al., 2018).10 Natur"
2021.eacl-main.259,J88-4003,0,0.21038,"ise improves model robustness to natural noise for all noise types in this study (Table 6), suggesting that synthetic noise generators may be capturing some aspects of natural noise. Our proposed generators could serve as templates for synthesizing interface noise when collecting natural data is infeasible, but individual practitioners should carefully identify and simulate the likely sources of error appropriate for their applications. 5 Related Work Question Answering QA systems have a rich history in NLP, with early successes in domainspecific applications (Green et al., 1961; Woods, 1977; Wilensky et al., 1988; Hirschman and Gaizauskas, 2001). Considerable research effort has been devoted to collecting datasets to support a wider variety of applications (Quaresma and Pimenta Rodrigues, 2005; Monroy et al., 2009; Feng et al., 2015; Liu et al., 2015; Nguyen, 2019; Jin et al., 2019) and improving model performance on them (Lally et al., 2017; Wang et al., 2018; Yu et al., 2018; Yang et al., 2019). We too focus on QA systems but center the utility to users rather than new applications or techniques. There has also been interest in studying the interaction between speech and QA systems. Lee et al. (2018"
2021.eacl-main.259,P15-2006,0,0.0113234,"d for QA evaluation to expand to consider real-world use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans.1 1 Introduction Everyday users now benefit from powerful QA technologies in a range of consumer-facing applications including health (Jacquemart and Zweigenbaum, 2003; Luo et al., 2015; Abacha and DemnerFushman, 2016; Kilicoglu et al., 2018; Guo et al., 2018), privacy (Sathyendra et al., 2017; Harkous et al., 2018; Ravichander et al., 2019), personal finance (Alloatti et al., 2019), search (Yang, 2015; Bajaj et al., 2016; He et al., 2018; Kwiatkowski et al., 2019) and dialog agents (Dahl et al., 1994; Raux et al., 2005). Voice assistants such as Amazon Alexa2 or Google Home3 have brought natural language technologies to several million homes globally (Osborne, 2016; Jeffs, 2018). Yet, even with 1 All resources available at noiseqa.github.io . developer.amazon.com/alexa 3 assistant.google.com 2 millions of users now interacting with these technologies on a daily basis, there has been surprisingly little research attention devoted to studying the issues that arise when people use QA systems."
2021.eacl-main.259,N19-4013,0,0.0435842,"Missing"
2021.findings-acl.375,K17-1037,0,0.147719,"8), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et a"
2021.findings-acl.375,W14-1607,0,0.0135399,"t al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al."
2021.findings-acl.375,W19-3402,1,0.798008,"lly deriving annotations with weak supervision. 1a) New datasets: There has been an increase in efforts for curating new datasets with task specific annotations. These are briefly overlaid in Table 1 along with their modalities, domains and tasks. 1b) Augment annotations: These curated datasets can also be used subsequently to augment with task specific annotations instead of collecting the data from scratch, which might be more expensive. • Non-textual Modality: Static grounding here includes using adversarial references to ground visual referring expressions (Akula et al., 2020), narration (Chandu et al., 2019b, 2020a), language learning (Suglia et al., 2020; Jin et al., 2020) etc., • Textual Modality: Static grounding includes entity slot filling (Bisk et al., 2016). • Interactive: Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, wea"
2021.findings-acl.375,2020.emnlp-main.93,1,0.85101,"ocalizing the concept, it is also essential to make the concept and its attributes consistent with the available knowledge sources. Most of the current research is focused on localizing with few efforts towards extending it to maintain a consistency of the grounded concept with other knowledge sources. Stage 3: Common sense: After establishing consistency of the concept, a human-like interaction additionally calls for grounding the common sense associated with the concept in that scenario. In addition to the basic level of practical knowledge that concerns with day to day scenarios Sap et al. (2020), the concept should also be reasoned based on that particular context. This contextual common sense moves the idiosyncratic sense towards a sense of collective understanding. For instance, if the human feels cold and asks the agent to get a blue coat, the agent needs to understand that the coat in this instance is a sweater coat and not a formal coat. This implicit common sense minimizes the effort in building a common ground reducing articulation of meticulous details. Therefore it is essential to incorporate this explicitly in our modeling as well. Stage 4: Personalized consensus: As a part"
2021.findings-acl.375,P19-1606,1,0.898793,"on is a very common technique in scenarios involving multiple modalities. In scenarios with a single modality, representations are often concatenated. • Non-textual modality: Fusion is applied with images for tasks like referring expressions (Roy et al., 2019), SRL (Yang et al., 2016) etc., For videos, some tasks are grounding action descriptions (Regneri et al., 2013), spatio-temporal QA (Lei et al., 4287 2020), concept similarity (Kiela and Clark, 2015), mapping events (Fleischman and Roy, 2008) etc., • Textual Modality: With text, this is similar to concatenating context (Prabhumoye et al. (2019) perform content transfer by augmenting context). • Interactive: In a conversational setting, work is explored in reference resolution (Takmaz et al., 2020; Haber et al., 2019), generating engaging response (Shuster et al., 2020), document grounded response generation Zhou et al. (2018b), etc., • Others: Nakano et al. (2003) study face-to-face grounding in instruction giving for agents. 2b) Alignment: An alternative to combining representations is aligning them with one another. • Non-textual modality: Wang et al. (2020) perform phrase localization in images and Hessel et al. (2020) study temp"
2021.findings-acl.375,C18-1295,0,0.0704865,"kmaz et al., 2020; Haber et al., 2019), generating engaging response (Shuster et al., 2020), document grounded response generation Zhou et al. (2018b), etc., • Others: Nakano et al. (2003) study face-to-face grounding in instruction giving for agents. 2b) Alignment: An alternative to combining representations is aligning them with one another. • Non-textual modality: Wang et al. (2020) perform phrase localization in images and Hessel et al. (2020) study temporal alignment in videos. • Interactive: Han and Schlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learning image attributes (Silberer and Lapata, 2014), representation learning of images (Zarrieß and Schlangen, 2017) and speech (Vijayakumar et al., 2017). • Textual modality: Tsai and Roth (2016b) demonstrate cross-lingua"
2021.findings-acl.375,2020.conll-1.22,0,0.0378151,"Missing"
2021.findings-acl.375,2020.emnlp-main.158,0,0.0221276,"e has been an increase in efforts for curating new datasets with task specific annotations. These are briefly overlaid in Table 1 along with their modalities, domains and tasks. 1b) Augment annotations: These curated datasets can also be used subsequently to augment with task specific annotations instead of collecting the data from scratch, which might be more expensive. • Non-textual Modality: Static grounding here includes using adversarial references to ground visual referring expressions (Akula et al., 2020), narration (Chandu et al., 2019b, 2020a), language learning (Suglia et al., 2020; Jin et al., 2020) etc., • Textual Modality: Static grounding includes entity slot filling (Bisk et al., 2016). • Interactive: Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, weak supervision is used in the contexts of automatic object proposals"
2021.findings-acl.375,P19-1655,0,0.0234884,"nseen words by projecting a graph to the pre-trained embeddings space. and Titov, 2020). Joint modeling was used in multiresolution language grounding Koncel-Kedziorski et al. (2014), identifying referring expressions Roy et al. (2019), multimodal MT (Zhou et al., 2018c), video parsing Ross et al. (2018), learning latent semantic annotations (Qin et al., 2018) etc., • Interactive: In a conversational setting, multitasking is used to compute concept similarity judgements (Silberer and Lapata, 2014), knowledge grounded response generation (Majumder et al., 2020), grounding language instructions Hu et al. (2019). Joint modeling is used by Li and Boyer (2015) to address dialog for complex problem solving in computer programs. 3b) Loss Function: It is crucial to utilize appropriate loss designed for the specific grounding task. The main difference between multitasking and a loss function adaptation is that while multitasking reweights combinations of existing loss functions, novel loss functions are informed by the data/task at hand, adapting to a novel use case. • Non-textual Modality: Grujicic et al. (2020) design soft organ distance loss to model inter and intra organ interactions for relative groun"
2021.findings-acl.375,P19-1349,0,0.0449469,"Missing"
2021.findings-acl.375,K19-1006,0,0.0161848,"t modeling is used by Li and Boyer (2015) to address dialog for complex problem solving in computer programs. 3b) Loss Function: It is crucial to utilize appropriate loss designed for the specific grounding task. The main difference between multitasking and a loss function adaptation is that while multitasking reweights combinations of existing loss functions, novel loss functions are informed by the data/task at hand, adapting to a novel use case. • Non-textual Modality: Grujicic et al. (2020) design soft organ distance loss to model inter and intra organ interactions for relative grounding. Ilharco et al. (2019) improve diversity in spoken captions with a masked margin softmax loss. 3c) Adversarial: Leveraging deceptive grounded inputs in an attempt to fool the model is capable of making it robust to certain errors. • Non-textual Modality: Chen et al. (2018); Akula et al. (2020) present an algorithm to craft visuallysimilar adversarial examples. • Textual Modality: Zellers et al. (2018) perform adversarial filtering and constructs a de-biased dataset by iteratively training stylistic classifiers. Summary: Manipulating learning objective is a modeling capability aiding as an additional comSummary: Mod"
2021.findings-acl.375,P19-1651,0,0.0136411,"c annotations instead of collecting the data from scratch, which might be more expensive. • Non-textual Modality: Static grounding here includes using adversarial references to ground visual referring expressions (Akula et al., 2020), narration (Chandu et al., 2019b, 2020a), language learning (Suglia et al., 2020; Jin et al., 2020) etc., • Textual Modality: Static grounding includes entity slot filling (Bisk et al., 2016). • Interactive: Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, weak supervision is used in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries"
2021.findings-acl.375,P18-1085,0,0.0651857,"Missing"
2021.findings-acl.375,P15-2133,0,0.0155368,"nd but steps 2 and 3 loop as the conversation progresses to build this common ground. The process of successfully grounding the query not only relies on the ability of the agent to link the query but also to construct the common ground from the mutually shared information with respect to the human. Although there are efforts about clarification questioning (), the coverage of phenomena are still far from comprehensive (Benotti and Blackburn, 2021b). Cognitive sciences in the perspective of language acquisition (Carpenter et al., 1998) present two ways of dynamic grounding via joint attention (Koleva et al., 2015; Tan et al., 2020): Dyadic joint attention and Triadic joint attention. In our case, dyadic attention describes the interaction between the human and the agent and any clarification or confirmation is done strictly between the both of them. Triadic attention also includes a tangible entity along with the human and the agent. The human can provide clarifications by gazing or pointing to this additional piece in the triad. Summary: The community should prioritize dynamic grounding as it is more general and more accurately matches real experiences. 2.2 Dimension 2: Purviews of grounding Next, we"
2021.findings-acl.375,D14-1043,0,0.0276901,"tomatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisatio"
2021.findings-acl.375,C10-2070,0,0.0998624,"Missing"
2021.findings-acl.375,2020.acl-main.730,0,0.0252329,"ntaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media intervie"
2021.findings-acl.375,N15-1085,0,0.175757,"., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media interviews spatial reasoning navigation problem solving Table 1: Example datasets introduced for grounding. temporal alignments between utterances and a set of events (Koncel-Kedziorski et al., 2014) etc., • Textual Modality: In the contexts of text, Tsai and Roth (2016a) work towards disambiguating concept mentions appearing in documents and grounding them in multiple KBs which is a step towards Stage 3 in §2.2. Poon (2013) perform question answering with a single database and (Parikh et al., 2015) with symbols. Summary: While augm"
2021.findings-acl.375,P19-1002,0,0.045007,"Missing"
2021.findings-acl.375,P14-2003,0,0.0400669,"Missing"
2021.findings-acl.375,2020.emnlp-main.96,0,0.0500072,"Missing"
2021.findings-acl.375,N15-1077,0,0.0283814,"r et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media interviews spatial reasoning navigation problem solving Table 1: Example datasets introduced for grounding. temporal alignments between utterances and a set of events (Koncel-Kedziorski et al., 2014) etc., • Textual Modality: In the contexts of text, Tsai and Roth (2016a) work towards disambiguating concept mentions appearing in documents and grounding them in multiple KBs which is a step towards Stage 3 in §2.2. Poon (2013) perform question answering with a single database and (Parikh et al., 2015) with symbols. Summary: While augmentation and weak supervision can be leveraged for dimensions of coordination and purviews, curating new datasets is the need of the hour to explore various constraints. 2. Manipulating representations: Grounding concepts often involves multiple modalities or representations that are linked. Three major methods to approach this are detailed here. 2a) Fusion and concatenation: Fusion is a very common technique in scenarios involving multiple modalities. In scenarios with a single modality, representations are often concatenated. • Non-textual modality: Fusion i"
2021.findings-acl.375,P13-1092,0,0.031645,"t al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media interviews spatial reasoning navigation problem solving Table 1: Example datasets introduced for grounding. temporal alignments between utterances and a set of events (Koncel-Kedziorski et al., 2014) etc., • Textual Modality: In the contexts of text, Tsai and Roth (2016a) work towards disambiguating concept mentions appearing in documents and grounding them in multiple KBs which is a step towards Stage 3 in §2.2. Poon (2013) perform question answering with a single database and (Parikh et al., 2015) with symbols. Summary: While augmentation and weak supervision can be leveraged for dimensions of coordination and purviews, curating new datasets is the need of the hour to explore various constraints. 2. Manipulating representations: Grounding concepts often involves multiple modalities or representations that are linked. Three major methods to approach this are detailed here. 2a) Fusion and concatenation: Fusion is a very common technique in scenarios involving multiple modalities. In scenarios with a single modali"
2021.findings-acl.375,P18-1255,0,0.0360093,"Missing"
2021.findings-acl.375,Q13-1003,0,0.246906,"ches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring e"
2021.findings-acl.375,D16-1117,0,0.0672963,"Missing"
2021.findings-acl.375,2020.acl-tutorials.7,0,0.0387766,"dition to localizing the concept, it is also essential to make the concept and its attributes consistent with the available knowledge sources. Most of the current research is focused on localizing with few efforts towards extending it to maintain a consistency of the grounded concept with other knowledge sources. Stage 3: Common sense: After establishing consistency of the concept, a human-like interaction additionally calls for grounding the common sense associated with the concept in that scenario. In addition to the basic level of practical knowledge that concerns with day to day scenarios Sap et al. (2020), the concept should also be reasoned based on that particular context. This contextual common sense moves the idiosyncratic sense towards a sense of collective understanding. For instance, if the human feels cold and asks the agent to get a blue coat, the agent needs to understand that the coat in this instance is a sweater coat and not a formal coat. This implicit common sense minimizes the effort in building a common ground reducing articulation of meticulous details. Therefore it is essential to incorporate this explicitly in our modeling as well. Stage 4: Personalized consensus: As a part"
2021.findings-acl.375,E09-1081,0,0.0296917,"ld scenarios. Stage 1: Localization: The first stage is the localization of the concept either in the physical or mental contexts. This step is idiosyncratic and relates to the ability of the agent alone to localize the concept. These concepts often are also linked in a compositional form. For instance, consider a scenario in which the agent is to locate a ‘blue sweater’. The agent needs to understand each of the concepts of ‘blue’ and ‘sweater’ individually and then locate the composition of the whole unit. Clark and Krych (2004) from cognitive sciences demonstrate how incremental grounding (Schlangen and Skantze, 2009; DeVault and Traum, 2013; Eshghi et al., 2015) is performed with these compositions and show how recognition and interpretation of fragments help in this by breaking down instructions into simpler ones. This localization occurs at word, phrase and even sentence level in the language modality and pixel, object and scene level in the visual modality. Stage 2: External Knowledge: After localizing the concept, the next step is to ensure consistency of the current context of the concept with existing knowledge. Often times, the references of grounding either match or contradict the references from"
2021.findings-acl.375,P18-1238,0,0.155589,"kmaz et al., 2020; Haber et al., 2019), generating engaging response (Shuster et al., 2020), document grounded response generation Zhou et al. (2018b), etc., • Others: Nakano et al. (2003) study face-to-face grounding in instruction giving for agents. 2b) Alignment: An alternative to combining representations is aligning them with one another. • Non-textual modality: Wang et al. (2020) perform phrase localization in images and Hessel et al. (2020) study temporal alignment in videos. • Interactive: Han and Schlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learning image attributes (Silberer and Lapata, 2014), representation learning of images (Zarrieß and Schlangen, 2017) and speech (Vijayakumar et al., 2017). • Textual modality: Tsai and Roth (2016b) demonstrate cross-lingua"
2021.findings-acl.375,P19-1180,0,0.0610694,"Missing"
2021.findings-acl.375,2020.acl-main.727,0,0.0611265,"Missing"
2021.findings-acl.375,2020.acl-main.219,0,0.0623937,"t al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media interviews spatial reasoning navigation problem solving Table 1: Example datasets introduced for grounding. temporal alignments between utterances and a set of events (Koncel-Kedziorski et al., 2014) etc., • Textual Modality: In the contexts of text, Tsai and Roth (2016a) work towards disambiguating concept mentions appearing in documents and grounding them in multiple KBs which is a step towards Stage 3 in §2.2. Poon (2013) perform question answer"
2021.findings-acl.375,P15-1092,0,0.0650898,"Missing"
2021.findings-acl.375,2020.emnlp-main.373,0,0.0314305,"Missing"
2021.findings-acl.375,P19-1644,0,0.0142583,"supervision is used in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas"
2021.findings-acl.375,P14-1068,0,0.0354795,"ization in images and Hessel et al. (2020) study temporal alignment in videos. • Interactive: Han and Schlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learning image attributes (Silberer and Lapata, 2014), representation learning of images (Zarrieß and Schlangen, 2017) and speech (Vijayakumar et al., 2017). • Textual modality: Tsai and Roth (2016b) demonstrate cross-lingual NER and mention grounding model by activating corresponding language features.Yang et al. (2019) perform imputation of embeddings for rare and unseen words by projecting a graph to the pre-trained embeddings space. and Titov, 2020). Joint modeling was used in multiresolution language grounding Koncel-Kedziorski et al. (2014), identifying referring expressions Roy et al. (2019), multimodal MT (Zhou et al., 2018c), video pars"
2021.findings-acl.375,D18-1282,0,0.0216688,": Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, weak supervision is used in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Al"
2021.findings-acl.375,D16-1101,0,0.0481391,"Missing"
2021.findings-acl.375,2020.findings-emnlp.242,0,0.0131173,"es entity slot filling (Bisk et al., 2016). • Interactive: Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, weak supervision is used in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and"
2021.findings-acl.375,P04-1002,0,0.305282,"Missing"
2021.findings-acl.375,J99-3001,0,0.470467,"Missing"
2021.findings-acl.375,2020.acl-main.682,0,0.0212151,"a) New datasets: There has been an increase in efforts for curating new datasets with task specific annotations. These are briefly overlaid in Table 1 along with their modalities, domains and tasks. 1b) Augment annotations: These curated datasets can also be used subsequently to augment with task specific annotations instead of collecting the data from scratch, which might be more expensive. • Non-textual Modality: Static grounding here includes using adversarial references to ground visual referring expressions (Akula et al., 2020), narration (Chandu et al., 2019b, 2020a), language learning (Suglia et al., 2020; Jin et al., 2020) etc., • Textual Modality: Static grounding includes entity slot filling (Bisk et al., 2016). • Interactive: Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, weak supervision is used in the contexts of automati"
2021.findings-acl.375,2020.acl-main.16,0,0.0368801,"Missing"
2021.findings-acl.375,Q16-1011,0,0.120539,"010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media interviews spatial reasoning navigation problem solving Table 1: Example datasets introduced for grounding. temporal alignments between utterances and a set of events (Koncel-Kedziorski et al., 2014) etc., • Textual Modality: In the contexts of text, Tsai and Roth (2016a) work towards disambiguating concept mentions appearing in documents and grounding them in multiple KBs which is a step towards Stage 3 in §2.2. Poon (2013) perform question answering with a single database and (Parikh et al., 2015) with symbols. Summary: While augmentation and weak supervision can be leveraged for dimensions of coordination and purviews, curating new datasets is the need of the hour to explore various constraints. 2. Manipulating representations: Grounding concepts often involves multiple modalities or representations that are linked. Three major methods to approach this ar"
2021.findings-acl.375,C16-2031,0,0.100884,"010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner et al., 2018) (Ku et al., 2020) (Li and Boyer, 2015) referring expressions Visual Other emotions and styles media interviews spatial reasoning navigation problem solving Table 1: Example datasets introduced for grounding. temporal alignments between utterances and a set of events (Koncel-Kedziorski et al., 2014) etc., • Textual Modality: In the contexts of text, Tsai and Roth (2016a) work towards disambiguating concept mentions appearing in documents and grounding them in multiple KBs which is a step towards Stage 3 in §2.2. Poon (2013) perform question answering with a single database and (Parikh et al., 2015) with symbols. Summary: While augmentation and weak supervision can be leveraged for dimensions of coordination and purviews, curating new datasets is the need of the hour to explore various constraints. 2. Manipulating representations: Grounding concepts often involves multiple modalities or representations that are linked. Three major methods to approach this ar"
2021.findings-acl.375,2020.findings-emnlp.67,0,0.0232674,"used subsequently to augment with task specific annotations instead of collecting the data from scratch, which might be more expensive. • Non-textual Modality: Static grounding here includes using adversarial references to ground visual referring expressions (Akula et al., 2020), narration (Chandu et al., 2019b, 2020a), language learning (Suglia et al., 2020; Jin et al., 2020) etc., • Textual Modality: Static grounding includes entity slot filling (Bisk et al., 2016). • Interactive: Though not fully dynamic grounding, some efforts here are amongst tasks like understanding spatial expressions (Udagawa et al., 2020), collaborative drawing (Kim et al., 2019) etc., 1c) Weak supervision: While the above two are based on human efforts, we can also perform weak supervision to use a model trained to derive automatic soft annotations required for the task. • Non-Textual Modality: In the visual modality, weak supervision is used in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption r"
2021.findings-acl.375,D17-1096,0,0.0270051,"hlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learning image attributes (Silberer and Lapata, 2014), representation learning of images (Zarrieß and Schlangen, 2017) and speech (Vijayakumar et al., 2017). • Textual modality: Tsai and Roth (2016b) demonstrate cross-lingual NER and mention grounding model by activating corresponding language features.Yang et al. (2019) perform imputation of embeddings for rare and unseen words by projecting a graph to the pre-trained embeddings space. and Titov, 2020). Joint modeling was used in multiresolution language grounding Koncel-Kedziorski et al. (2014), identifying referring expressions Roy et al. (2019), multimodal MT (Zhou et al., 2018c), video parsing Ross et al. (2018), learning latent semantic annotations (Qin et al., 2018) etc., • Interactive: In"
2021.findings-acl.375,C18-1199,0,0.0220086,"en et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text negotiations documents improvisation (Cadilhac et al., 2013) (Zhou et al., 2018b) (Cho and May, 2020) (Haber et al., 2019) (Takmaz et al., 2020) (Shuster et al., 2020) (Majumder et al., 2020) (J¨anner"
2021.findings-acl.375,Q19-1029,0,0.0382204,"Missing"
2021.findings-acl.375,2020.emnlp-main.159,0,0.018809,"tual Modality: With text, this is similar to concatenating context (Prabhumoye et al. (2019) perform content transfer by augmenting context). • Interactive: In a conversational setting, work is explored in reference resolution (Takmaz et al., 2020; Haber et al., 2019), generating engaging response (Shuster et al., 2020), document grounded response generation Zhou et al. (2018b), etc., • Others: Nakano et al. (2003) study face-to-face grounding in instruction giving for agents. 2b) Alignment: An alternative to combining representations is aligning them with one another. • Non-textual modality: Wang et al. (2020) perform phrase localization in images and Hessel et al. (2020) study temporal alignment in videos. • Interactive: Han and Schlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learni"
2021.findings-acl.375,2020.acl-main.166,0,0.0611649,"Missing"
2021.findings-acl.375,N16-1019,0,0.0202464,"Missing"
2021.findings-acl.375,2020.findings-emnlp.172,0,0.0247383,"Missing"
2021.findings-acl.375,D17-1100,0,0.0237351,"ment in videos. • Interactive: Han and Schlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learning image attributes (Silberer and Lapata, 2014), representation learning of images (Zarrieß and Schlangen, 2017) and speech (Vijayakumar et al., 2017). • Textual modality: Tsai and Roth (2016b) demonstrate cross-lingual NER and mention grounding model by activating corresponding language features.Yang et al. (2019) perform imputation of embeddings for rare and unseen words by projecting a graph to the pre-trained embeddings space. and Titov, 2020). Joint modeling was used in multiresolution language grounding Koncel-Kedziorski et al. (2014), identifying referring expressions Roy et al. (2019), multimodal MT (Zhou et al., 2018c), video parsing Ross et al. (2018), learning latent semantic annotations (Qin"
2021.findings-acl.375,D18-1009,1,0.81299,"s are informed by the data/task at hand, adapting to a novel use case. • Non-textual Modality: Grujicic et al. (2020) design soft organ distance loss to model inter and intra organ interactions for relative grounding. Ilharco et al. (2019) improve diversity in spoken captions with a masked margin softmax loss. 3c) Adversarial: Leveraging deceptive grounded inputs in an attempt to fool the model is capable of making it robust to certain errors. • Non-textual Modality: Chen et al. (2018); Akula et al. (2020) present an algorithm to craft visuallysimilar adversarial examples. • Textual Modality: Zellers et al. (2018) perform adversarial filtering and constructs a de-biased dataset by iteratively training stylistic classifiers. Summary: Manipulating learning objective is a modeling capability aiding as an additional comSummary: Modeling different representations efponent in bringing grounding adjunct to several fectively aid in improving both consistency across other end tasks across all the dimensions. purviews and media based constraints. 3.4 3. Learning Objective: Grounding is often performed to support a more defined end purpose task. We identified 3 ways that are broadly adopted to incorporate groundi"
2021.findings-acl.375,2020.acl-main.184,0,0.0671575,"Missing"
2021.findings-acl.375,2020.emnlp-main.354,0,0.509859,"ocalizing the concept, it is also essential to make the concept and its attributes consistent with the available knowledge sources. Most of the current research is focused on localizing with few efforts towards extending it to maintain a consistency of the grounded concept with other knowledge sources. Stage 3: Common sense: After establishing consistency of the concept, a human-like interaction additionally calls for grounding the common sense associated with the concept in that scenario. In addition to the basic level of practical knowledge that concerns with day to day scenarios Sap et al. (2020), the concept should also be reasoned based on that particular context. This contextual common sense moves the idiosyncratic sense towards a sense of collective understanding. For instance, if the human feels cold and asks the agent to get a blue coat, the agent needs to understand that the coat in this instance is a sweater coat and not a formal coat. This implicit common sense minimizes the effort in building a common ground reducing articulation of meticulous details. Therefore it is essential to incorporate this explicitly in our modeling as well. Stage 4: Personalized consensus: As a part"
2021.findings-acl.375,2020.emnlp-main.558,0,0.0527971,"Missing"
2021.findings-acl.375,D18-1231,0,0.277593,"in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text"
2021.findings-acl.375,D18-1076,1,0.905303,"kmaz et al., 2020; Haber et al., 2019), generating engaging response (Shuster et al., 2020), document grounded response generation Zhou et al. (2018b), etc., • Others: Nakano et al. (2003) study face-to-face grounding in instruction giving for agents. 2b) Alignment: An alternative to combining representations is aligning them with one another. • Non-textual modality: Wang et al. (2020) perform phrase localization in images and Hessel et al. (2020) study temporal alignment in videos. • Interactive: Han and Schlangen (2017) align GUI actions to sub-utterances in conversations and J¨anner et al. (2018) align local neighborhoods to the corresponding verbalizations. 2c) Projecting into a common space: A widely used approach is to also bring the different representations on to a joint common space. • Non-textual modality: Projection to a joint semantic space is used in spoken image captioning (Chrupala et al., 2017; Alishahi et al., 2017; Havard et al., 2019), bicoding for learning image attributes (Silberer and Lapata, 2014), representation learning of images (Zarrieß and Schlangen, 2017) and speech (Vijayakumar et al., 2017). • Textual modality: Tsai and Roth (2016b) demonstrate cross-lingua"
2021.findings-acl.375,D18-1400,0,0.174011,"in the contexts of automatic object proposals for different tasks like spoken image captioning (Srinivasan et al., 2020), visual semantic role labeling (Silberer and Pinkal, 2018), phrase grounding (Chen et al., 2019), loose Textual Figure 3: Categorical approaches to grounding caption relevance multimodal MT sports commentaries semantic role labeling instruction following navigation Images causality spatial expressions spoken image captioning entailment image search scene generation action segmentation semantic parsing Videos instruction following question answering Work (Suhr et al., 2019) (Zhou et al., 2018c) (Koncel-Kedziorski et al., 2014) (Silberer and Pinkal, 2018) (Han and Schlangen, 2017) (Andreas and Klein, 2014) (Gao et al., 2016) (Kelleher et al., 2006) (Alishahi et al., 2017) (Vu et al., 2018) (Kiros et al., 2018) (Chang et al., 2015) (Regneri et al., 2013) (Ross et al., 2018) (Liu et al., 2016) (Lei et al., 2020) Text content transfer commonsense inference reference resolution symbol grounding bilingual lexicon extraction POS tagging (Prabhumoye et al., 2019) (Zellers et al., 2018) (Kennington and Schlangen, 2015) (Kameko et al., 2015) (Laws et al., 2010) (Cardenas et al., 2019) Text"
2021.findings-emnlp.373,L18-1193,0,0.0338394,"Missing"
2021.findings-emnlp.373,2020.acl-main.329,0,0.341385,"performance while retaining the overall performance on two distinct language pairs in both the tasks. We plan to release our models and the code for all our experiments. 1 Introduction ios. In this paper, we present solutions to address these two problems specifically. The advent of pretraining techniques marshalled the celebrated successes of several language understanding and generation tasks in English (Dong et al., 2019) and multilingual tasks (Chaudhary et al., 2020). However, the same level of commendatory results are not translated to CS scenarios; as studied by Aguilar et al. (2020); Khanuja et al. (2020) presenting a preliminary evaluation of multi-lingual pretrained models for CS scenarios. It is still largely unclear if the inadequacies are resulting due to dearth of data or ineptitude of quick adoption of multilingual models. We study precisely this problem of identifying the artifacts that hinder the competent performance of pretrained models on CS with a case study on sequence labeling tasks including Part-Of-Speech (POS) tagging and Named Entity Recognition (NER). Our contributions from this work are as follows: (1) We first conduct a comprehensive benchmarking of different pretrained m"
2021.findings-emnlp.373,2020.ccl-1.92,0,0.0125859,". We present a comprehensive evaluation of different BERT-based mono-lingual and multi-lingual pretrained models when adapted to the chosen CS datasets/tasks. We performed sequence tagging on different transformer models: (a) We use the uncased base implementation of BERT and mBERT (Devlin et al., 2018) (b) Distill mBERT (Sanh et al., 2019), (c) XLM-RoBERTa (Conneau et al., 2019) trained using knowledge distillation and (d) Char-BERT(Boukkouri et al., 2020) that employs Character CNN to capture unknown and misspelled words. Motivated by prior works on multi-task learning (Chandu et al., 2018; Li et al., 2020), we also experiment with language-aware modeling. In these experiments, we added a language token either as the input encoding or output prediction. Motivation for our work - Gaps in CS adaptation: Building off the prior work, we will briefly discuss primarily three techniques that demonstrated usefulness in adapting models to CS. First, non-standardization of cross-scripting (i.e, transliteration of words to another language) is identified as one of the major reasons behind the noisiness of CS datasets (Chandu et al., 2019). Prior literature on noisy texts proved the superiority of character"
2021.findings-emnlp.373,N19-1201,0,0.0606304,"Missing"
2021.findings-emnlp.373,W18-0201,0,0.0247397,"udCS. We believe that the reasons behind this are (1) ied in the context of many NLP tasks including the lack of efforts in leveraging existing large scale language identification (Solorio et al., 2014) (Bali multilingual resources or pretrained models and (2) et al., 2014), POS tagging (Soto and Hirschberg, dearth of annotated resources in switching scenar- 2018) (Molina et al., 2019) (Das, 2016), NER 4389 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 4389–4397 November 7–11, 2021. ©2021 Association for Computational Linguistics (Aguilar et al., 2019), parsing (Partanen et al., 2018), sentiment analysis(Vilares et al., 2015), and question answering (Chandu et al., 2019) (Raghavi et al., 2015). Many CS datasets have been made available through the shared-task series FIRE (Choudhury et al., 2014); (Roy et al., 2013) and CALCS (Aguilar et al., 2018), which have focused mostly on core NLP tasks. Additionally, other researchers have provided datasets such as humor detection (Khandelwal et al., 2018), sub-word CS detection (Mager et al., 2019) among others. More recently new CS benchmarks (Aguilar et al., 2020) (Khanuja et al., 2020) have been developed to compare models across"
2021.findings-emnlp.373,D18-1344,0,0.0261893,"et al., 2018), which have focused mostly on core NLP tasks. Additionally, other researchers have provided datasets such as humor detection (Khandelwal et al., 2018), sub-word CS detection (Mager et al., 2019) among others. More recently new CS benchmarks (Aguilar et al., 2020) (Khanuja et al., 2020) have been developed to compare models across language pairs, domains and general language processing in CS. Pretrained Models for CS: Before the advent of pretrained multingual models, pretrained monolingual models were combined in different ways to derive word embeddings (AlGhamdi and Diab, 2019; Pratapa et al., 2018), POS tagging (Bhattu et al., 2020), sentiment analysis (Singh and Lefever, 2020) etc., Similarly, pretrained multilingual models have been explored on various CS tasks like language identification, POS tagging, NER, question answering and Natural language inference (Khanuja et al., 2020). However, (Winata et al., 2021) show that these pretrained models do not assure high quality representations on CS. We examine prospective reasons for this and present a data augmentation technique to mitigate this. Corpus Twitter (Singh et al., 2018a) UD (Bhat et al., 2018) ICON (Jamatia et al., 2016) ICON ("
2021.findings-emnlp.373,W18-3503,0,0.0606559,"Missing"
2021.findings-emnlp.373,2020.calcs-1.6,0,0.0234808,"r researchers have provided datasets such as humor detection (Khandelwal et al., 2018), sub-word CS detection (Mager et al., 2019) among others. More recently new CS benchmarks (Aguilar et al., 2020) (Khanuja et al., 2020) have been developed to compare models across language pairs, domains and general language processing in CS. Pretrained Models for CS: Before the advent of pretrained multingual models, pretrained monolingual models were combined in different ways to derive word embeddings (AlGhamdi and Diab, 2019; Pratapa et al., 2018), POS tagging (Bhattu et al., 2020), sentiment analysis (Singh and Lefever, 2020) etc., Similarly, pretrained multilingual models have been explored on various CS tasks like language identification, POS tagging, NER, question answering and Natural language inference (Khanuja et al., 2020). However, (Winata et al., 2021) show that these pretrained models do not assure high quality representations on CS. We examine prospective reasons for this and present a data augmentation technique to mitigate this. Corpus Twitter (Singh et al., 2018a) UD (Bhat et al., 2018) ICON (Jamatia et al., 2016) ICON (Jamatia et al., 2016) ICON (Jamatia et al., 2016) Miami (AlGhamdi et al., 2019) T"
2021.findings-emnlp.373,W18-2405,0,0.0607286,"Missing"
2021.findings-emnlp.373,W18-3201,0,0.0555639,"Missing"
2021.findings-emnlp.373,2021.calcs-1.20,0,0.030102,"o compare models across language pairs, domains and general language processing in CS. Pretrained Models for CS: Before the advent of pretrained multingual models, pretrained monolingual models were combined in different ways to derive word embeddings (AlGhamdi and Diab, 2019; Pratapa et al., 2018), POS tagging (Bhattu et al., 2020), sentiment analysis (Singh and Lefever, 2020) etc., Similarly, pretrained multilingual models have been explored on various CS tasks like language identification, POS tagging, NER, question answering and Natural language inference (Khanuja et al., 2020). However, (Winata et al., 2021) show that these pretrained models do not assure high quality representations on CS. We examine prospective reasons for this and present a data augmentation technique to mitigate this. Corpus Twitter (Singh et al., 2018a) UD (Bhat et al., 2018) ICON (Jamatia et al., 2016) ICON (Jamatia et al., 2016) ICON (Jamatia et al., 2016) Miami (AlGhamdi et al., 2019) Twitter (Singh et al., 2018b) CALCS (Aguilar et al., 2019) Notation EnHi-Tw-P EnHi-UD-P EnHi-I-P EnBn-I-P EnTe-I-P EnEs-M-P EnHi-Tw-N EnEs-Tw-N Task POS POS POS POS POS POS NER NER # Sentences 1489 1311 2630 625 1979 27893 1243 50757 Table 1"
2021.findings-emnlp.373,W18-3207,0,0.0279019,"tasets (Chandu et al., 2019). Prior literature on noisy texts proved the superiority of character level modeling to combat this problem (Cherry et al., 2018); (Adouane et al., 2018). Secondly, the domains of most of these noisy datasets are 3.2 Analysis of Benchmarking still vastly scattered. In order to improve generalThe results for the aforementioned experiments are ization in CS patterns, prior studies have shown presented in Table 2. The baseline in this table the potency of multitasking with an auxiliary task indicates the current state-of-the-art models on reof language tag prediction (Winata et al., 2018). spective datasets as cited in the table. Here are our Thirdly, the dearth of annotated CS data has been main observations from these results. a dramatic problem across tasks. (Bhattu et al., • Multi-task Learning did not help much: Despite 2020) compare pretrained models with fined-tuned models augmented with unlabeled Twitter text to the effectiveness of multi-tasking in non-pretrained 4390 Model Baseline eng-BERT M-BERT M-BERT (lang-input) M-BERT (lang-output) Distill M-BERT XLM-ROBERTa char-BERT char-BERT (lang-input) char-BERT (lang-output) EnHi-Tw-P 91.03 (A) 84.01 89.27 89.74 88.89 90."
2021.naacl-main.297,W13-3515,0,0.0220628,"traffic rules. The decision made by the police officer (the action) can then be judged to be in accordance (or not) with a human-selected set of ethically acceptable action and rationale pairs. Similarly, for court hearing transcripts, the rationales of the arguments can be extracted and the verdict of the judge can be checked using them (Branting et al., 2020; Aletras et al., 2019). NLP tools such as commonsense knowledge graph generation (Bosselut et al., 2019; Saito et al., 2018; Malaviya et al., 2019), semantic role labeling (Gildea and Jurafsky, 2000), open domain information extraction (Angeli and Manning, 2013) etc. can be used to extract rationales, entities from text and also find relations between them to better understand the underlying intent of the text. The way forward: There is a fair amount of research on the social aspects of human-computer dialogue both in general and specifically with regards to children (Druga et al., 2017; Shen, 2015; Kahn Jr et al., 2013). Although it is difficult to gain a complete understanding of how dialogue systems affect the development of children, the most salient facts (e.g., children regarding virtual assistants as person-like) should be communicated to pare"
2021.naacl-main.297,W19-5301,0,0.0384694,"Missing"
2021.naacl-main.297,2020.acl-tutorials.2,0,0.0387053,"Card and Smith (2020) present an analysis of ethics in machine learning under a consequentialist framework. This paper is a kindred spirit in that we both seek to make a philosophical theory of ethics concrete within machine learning and NLP, yet the methods of the paper are somewhat orthogonal. Card and Smith (2020) provide a comprehensive overview of how the particular nature of consequentialist ethics is relevant to machine learning whereas we intend to provide tangible examples of how deontological ethical principles can identify ethically important areas of research. Saltz et al. (2019); Bender et al. (2020) advocate for explicitly teaching ethical theory as a part of machine learning and NLP courses; the case studies in this paper would be a logical extension of the material presented in such a course. NLP research on ethics has primarily focused on two directions: (1) exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure,"
2021.naacl-main.297,2020.acl-main.154,0,0.0568634,"Missing"
2021.naacl-main.297,P16-2096,0,0.025724,"s relevant to machine learning whereas we intend to provide tangible examples of how deontological ethical principles can identify ethically important areas of research. Saltz et al. (2019); Bender et al. (2020) advocate for explicitly teaching ethical theory as a part of machine learning and NLP courses; the case studies in this paper would be a logical extension of the material presented in such a course. NLP research on ethics has primarily focused on two directions: (1) exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina"
2021.naacl-main.297,N19-1357,0,0.0244459,"; explainability is still important for a near-perfect QA system. First, the source of an answer could be fallible (even if the content was interpreted correctly), in which case it is important to be able to point which sources were used. Second, answers can often be ambiguous, so a user might naturally ask for clarification to be sure of what the answer means. Finally, it is natural for humans to build trust when working with a system, and explainability is an important step in this process. predictions, making them unsuitable for explainability (Pruthi et al., 2020; Serrano and Smith, 2019; Jain and Wallace, 2019). Recently, generating natural language explanations (Rajani et al., 2019; Latcinnik and Berant, 2020) for predictions has gained traction. These methods train a language generation model to generate explanations for the QA predictions. Using a black-box model for text generation, though, pushes the same problem further down the line. Part of the issue with both of the aforementioned methods is that the “reasoning” for the answer is determined after the answer has been generated (i.e., reasoning should inform the answer, not vice-versa). The way forward: A method which reaches the prediction t"
2021.naacl-main.297,L18-1433,0,0.0136661,"ons. Using a black-box model for text generation, though, pushes the same problem further down the line. Part of the issue with both of the aforementioned methods is that the “reasoning” for the answer is determined after the answer has been generated (i.e., reasoning should inform the answer, not vice-versa). The way forward: A method which reaches the prediction through reasoning would be more in line with the generalization principle. For example, reaching the prediction through traversal of a knowledge graph. This has been used in scenarios where a knowledge base exists (Han et al., 2020; Jansen et al., 2018) for a QA system as well as in dynamic graph generation to reach the prediction (Liu et al., 2020; Rajagopal et al., 2020; Bosselut and Choi, 2019). In these methods, the reasoning is part of the process to generate the final answer, which is more suitable in failing gracefully and building user trust. 4.2 Detecting Objectionable Content Attention weights have been widely used for ex- Social media platforms have made the world plaining QA predictions. Attention weights learnt smaller. At the same time, the world has seen a by neural models denote the words or phrases in a surge in hate-speech,"
2021.naacl-main.297,P98-1103,0,0.157153,"Missing"
2021.naacl-main.297,W15-4615,0,0.0148696,"hical research is not merely a checklist to be satisfied tionally, parents can be provided with fine-grained by abiding to the principles mentioned here. It control over the topics, sources and language that requires our persistent attention and open-minded would be generated by the agent. For example, the engagement with the problem. parent can select for a polite language and topics One limitation of this work is in the principles related to science to support their child’s develthat we choose.6 For example, the interaction of opment efforts. Much research has focused on controlling topics (Kim et al., 2015; Jokinen et al., machine learning and privacy is of huge ethical 6 1998), style (Niu and Bansal, 2018), content (Zhou Kant would argue that the generalization principle can et al., 2018; Zhao et al., 2020; Dinan et al., 2019) account for all ethical decisions, but we make no such claim. 3791 importance. While the respect for autonomy may address this issue in part, it would be more productive to utilize a deontological principle to the effect of the right to privacy with which such matters can be judged. Another instance is that in this work, we have not discussed the principle of interaction"
2021.naacl-main.297,W17-1601,0,0.0260314,"n A taken for reasons R is unethical if and only if a world where all people perform A for reasons R logically contradicts R. The main utility of the generalization principle is that it can identify unethical actions that may seem acceptable in isolated occurrences but lead to problems when habitually taken by everyone. For example, let us take making and breaking a legal contract (the action) whenever it is convenient (the reasons); implicit in the reasons for making a Most of the work providing algorithmic solutions has been focused on bias in NLP systems. Shah et al. (2020); Tatman (2017); Larson (2017) aim to study the social impact of bias in NLP systems and propose frameworks to understand it bet4 ter. A large body of work (Bolukbasi et al., 2016; It is also referred to as the “universal law” formulation of Sun et al., 2019; Zhao et al., 2019, 2017; Sap et al., Kant’s categorical imperative. 3786 contract is that the other person believes we will follow through (Johnson and Cureton, 2019). If we universalize this and conceive of a world where everyone makes contracts which they have no intent of keeping, no one would believe in the sincerity of a contract. Hence, no one would make contrac"
2021.naacl-main.297,W17-1604,0,0.0156099,"material presented in such a course. NLP research on ethics has primarily focused on two directions: (1) exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias"
2021.naacl-main.297,W17-1607,0,0.0254987,"f NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide an extensive survey of this work and point out the weaknesses"
2021.naacl-main.297,D16-1230,0,0.0120844,"ucation (Godea and Nielsen, 2018; Raamadhurai of ethics. In particular, we are using a prescriptive, et al., 2019), privacy (Ravichander et al., 2019; rather than descriptive, theory of ethics; prescripShvartzshanider et al., 2018); machine translation tive theories define and recommend ethical behavsystems (Cherry et al., 2019; Barrault et al., 2019; ior whereas descriptive theories merely report how Nakazawa et al., 2019; Liu, 2018), conversational people generally conceive of ethical behavior. agents (Pietquin et al., 2020; Serban et al., 2018; We select two ethical principles from the deonLiu et al., 2016), recommendation systems (Al- tological tradition of ethics and focus on how these harthi and Inkpen, 2019; Greenquist et al., 2019) principles are relevant to research in NLP. Namely etc. are deployed and used by millions of users. we look at the generalization principle and respect NLP systems have become pervasive in current hu- for autonomy through informed consent (Johnson man lifestyle by performing mundane tasks like and Cureton, 2019; Kleinig, 2009). We select desetting reminders and alarms to complex tasks like onotology because it is reasonable, provides clear ∗ authors contributed e"
2021.naacl-main.297,W19-4401,0,0.0187871,"t (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide an extensive survey of this work and point out the weaknesses in the research design. It makes recommendations of grounding work analyzing bias in NLP systems"
2021.naacl-main.297,W19-4446,1,0.782526,"llenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide an extensive survey of this work and point out the weaknesses in the research design. It makes recommendations of grounding work analyzi"
2021.naacl-main.297,P18-2050,0,0.0355847,"Missing"
2021.naacl-main.297,W17-1603,0,0.0252519,"d (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide an extensive survey of this work and point out the weaknesses in the research"
2021.naacl-main.297,D15-1238,0,0.0662538,"Missing"
2021.naacl-main.297,D15-1130,0,0.0656758,"Missing"
2021.naacl-main.297,Q18-1027,0,0.0124983,"ne-grained by abiding to the principles mentioned here. It control over the topics, sources and language that requires our persistent attention and open-minded would be generated by the agent. For example, the engagement with the problem. parent can select for a polite language and topics One limitation of this work is in the principles related to science to support their child’s develthat we choose.6 For example, the interaction of opment efforts. Much research has focused on controlling topics (Kim et al., 2015; Jokinen et al., machine learning and privacy is of huge ethical 6 1998), style (Niu and Bansal, 2018), content (Zhou Kant would argue that the generalization principle can et al., 2018; Zhao et al., 2020; Dinan et al., 2019) account for all ethical decisions, but we make no such claim. 3791 importance. While the respect for autonomy may address this issue in part, it would be more productive to utilize a deontological principle to the effect of the right to privacy with which such matters can be judged. Another instance is that in this work, we have not discussed the principle of interactional fairness (Bies, 2015, 2001) which refers to the quality of interpersonal treatment including respect"
2021.naacl-main.297,W17-1608,0,0.0225071,"NLP research on ethics has primarily focused on two directions: (1) exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, an"
2021.naacl-main.297,S18-2023,0,0.0624322,"Missing"
2021.naacl-main.297,Q18-1033,0,0.0252223,"de by such systems can be assisted by these theories. NLP can also aid in making decisions in accordance with the deontological framework. Recall that the generalization principle judges the ethical standing of pairs of actions and reasons; these pairs could be extracted with various NLP techniques from textual content. In the case of flagging objectionable content (§4.2), extracting the deeper intents and implications corresponds to the reasons for the action of flagging the content. Another example is building an automatic institutional dialog act annotator for traffic police conversations (Prabhakaran et al., 2018). These dialog acts contain the rationales of the two agents in the conversation: the police officer and the civilian stopped for breaking traffic rules. The decision made by the police officer (the action) can then be judged to be in accordance (or not) with a human-selected set of ethically acceptable action and rationale pairs. Similarly, for court hearing transcripts, the rationales of the arguments can be extracted and the verdict of the judge can be checked using them (Branting et al., 2020; Aletras et al., 2019). NLP tools such as commonsense knowledge graph generation (Bosselut et al.,"
2021.naacl-main.297,W19-3637,1,0.840693,"has primarily focused on two directions: (1) exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et"
2021.naacl-main.297,2020.acl-main.432,0,0.0260836,"han a matter of the (in)accuracy of the answer; explainability is still important for a near-perfect QA system. First, the source of an answer could be fallible (even if the content was interpreted correctly), in which case it is important to be able to point which sources were used. Second, answers can often be ambiguous, so a user might naturally ask for clarification to be sure of what the answer means. Finally, it is natural for humans to build trust when working with a system, and explainability is an important step in this process. predictions, making them unsuitable for explainability (Pruthi et al., 2020; Serrano and Smith, 2019; Jain and Wallace, 2019). Recently, generating natural language explanations (Rajani et al., 2019; Latcinnik and Berant, 2020) for predictions has gained traction. These methods train a language generation model to generate explanations for the QA predictions. Using a black-box model for text generation, though, pushes the same problem further down the line. Part of the issue with both of the aforementioned methods is that the “reasoning” for the answer is determined after the answer has been generated (i.e., reasoning should inform the answer, not vice-versa). The wa"
2021.naacl-main.297,W19-4435,0,0.0497803,"Missing"
2021.naacl-main.297,E17-1101,0,0.0309934,"Missing"
2021.naacl-main.297,2020.findings-emnlp.300,0,0.0201138,"sue with both of the aforementioned methods is that the “reasoning” for the answer is determined after the answer has been generated (i.e., reasoning should inform the answer, not vice-versa). The way forward: A method which reaches the prediction through reasoning would be more in line with the generalization principle. For example, reaching the prediction through traversal of a knowledge graph. This has been used in scenarios where a knowledge base exists (Han et al., 2020; Jansen et al., 2018) for a QA system as well as in dynamic graph generation to reach the prediction (Liu et al., 2020; Rajagopal et al., 2020; Bosselut and Choi, 2019). In these methods, the reasoning is part of the process to generate the final answer, which is more suitable in failing gracefully and building user trust. 4.2 Detecting Objectionable Content Attention weights have been widely used for ex- Social media platforms have made the world plaining QA predictions. Attention weights learnt smaller. At the same time, the world has seen a by neural models denote the words or phrases in a surge in hate-speech, offensive language, stereosentence that the model focuses on. Hence, words type and bias on online platforms. These onli"
2021.naacl-main.297,P19-1487,0,0.0176856,"source of an answer could be fallible (even if the content was interpreted correctly), in which case it is important to be able to point which sources were used. Second, answers can often be ambiguous, so a user might naturally ask for clarification to be sure of what the answer means. Finally, it is natural for humans to build trust when working with a system, and explainability is an important step in this process. predictions, making them unsuitable for explainability (Pruthi et al., 2020; Serrano and Smith, 2019; Jain and Wallace, 2019). Recently, generating natural language explanations (Rajani et al., 2019; Latcinnik and Berant, 2020) for predictions has gained traction. These methods train a language generation model to generate explanations for the QA predictions. Using a black-box model for text generation, though, pushes the same problem further down the line. Part of the issue with both of the aforementioned methods is that the “reasoning” for the answer is determined after the answer has been generated (i.e., reasoning should inform the answer, not vice-versa). The way forward: A method which reaches the prediction through reasoning would be more in line with the generalization principle."
2021.naacl-main.297,D19-1500,1,0.822053,"ora of NLP applications such oretical and applied branch of philosophy which as question-answering systems (Bouziane et al., studies what is good and right, especially as it per2015; Gillard et al., 2006; Yang et al., 2018) tains to how humans ought to behave in the most used in diverse fields like healthcare (Sarrouti and general sense (Fieser, 1995). As NLP research qualOuatik El Alaoui, 2017; Zweigenbaum, 2009), ed- ifies as a human activity, it is within the purview ucation (Godea and Nielsen, 2018; Raamadhurai of ethics. In particular, we are using a prescriptive, et al., 2019), privacy (Ravichander et al., 2019; rather than descriptive, theory of ethics; prescripShvartzshanider et al., 2018); machine translation tive theories define and recommend ethical behavsystems (Cherry et al., 2019; Barrault et al., 2019; ior whereas descriptive theories merely report how Nakazawa et al., 2019; Liu, 2018), conversational people generally conceive of ethical behavior. agents (Pietquin et al., 2020; Serban et al., 2018; We select two ethical principles from the deonLiu et al., 2016), recommendation systems (Al- tological tradition of ethics and focus on how these harthi and Inkpen, 2019; Greenquist et al., 2019)"
2021.naacl-main.297,K18-1014,0,0.0134177,"dialog acts contain the rationales of the two agents in the conversation: the police officer and the civilian stopped for breaking traffic rules. The decision made by the police officer (the action) can then be judged to be in accordance (or not) with a human-selected set of ethically acceptable action and rationale pairs. Similarly, for court hearing transcripts, the rationales of the arguments can be extracted and the verdict of the judge can be checked using them (Branting et al., 2020; Aletras et al., 2019). NLP tools such as commonsense knowledge graph generation (Bosselut et al., 2019; Saito et al., 2018; Malaviya et al., 2019), semantic role labeling (Gildea and Jurafsky, 2000), open domain information extraction (Angeli and Manning, 2013) etc. can be used to extract rationales, entities from text and also find relations between them to better understand the underlying intent of the text. The way forward: There is a fair amount of research on the social aspects of human-computer dialogue both in general and specifically with regards to children (Druga et al., 2017; Shen, 2015; Kahn Jr et al., 2013). Although it is difficult to gain a complete understanding of how dialogue systems affect the"
2021.naacl-main.297,P19-1163,0,0.0452422,"Missing"
2021.naacl-main.297,2020.acl-main.486,0,0.0148595,"power differ- doctorate. On the other hand, in Japanese it would be disrespectful to use the more common “-san” entials between different social groups. Breitfeller et al. (2019) provide a new typology to better un- honorific (the rough equivalent of “Ms.” or “Mr.”) in place of “-sensei” which refers specifically to derstand the nature of microaggressions and their teachers or mentors and shows them a special level impact on different social groups. Fig. 1b presents of respect. If the MT system cannot reasonably insuch a comment and how we would like the NLP systems to annotate such content. Sap et al. (2020) fer how to resolve the ambiguity in such situations, the English speaker should be informed about it. perform the task of generating the consequences and implications of comments which is a step to- The English speaker must be notified that such an ambiguity needs to be resolved because there is a wards judging content based on its meaning and not risk of offending the Japanese speaker otherwise. simply which words it happens to use. Although such an aim does not automatically solve the probIn general, there is a trade-off in translation be3789 tween literality and fluency in certain situatio"
2021.naacl-main.297,W17-2337,0,0.020592,"Missing"
2021.naacl-main.297,W18-0801,0,0.0227796,") exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide an extensive sur"
2021.naacl-main.297,W17-1611,0,0.0278185,"two directions: (1) exploring and understanding the impact of NLP on society, and (2) providing algorithmic solutions to ethical challenges. Hovy and Spruit (2016) started the conversation about the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide"
2021.naacl-main.297,N16-1005,0,0.232009,"Missing"
2021.naacl-main.297,P19-1282,0,0.0144278,"in)accuracy of the answer; explainability is still important for a near-perfect QA system. First, the source of an answer could be fallible (even if the content was interpreted correctly), in which case it is important to be able to point which sources were used. Second, answers can often be ambiguous, so a user might naturally ask for clarification to be sure of what the answer means. Finally, it is natural for humans to build trust when working with a system, and explainability is an important step in this process. predictions, making them unsuitable for explainability (Pruthi et al., 2020; Serrano and Smith, 2019; Jain and Wallace, 2019). Recently, generating natural language explanations (Rajani et al., 2019; Latcinnik and Berant, 2020) for predictions has gained traction. These methods train a language generation model to generate explanations for the QA predictions. Using a black-box model for text generation, though, pushes the same problem further down the line. Part of the issue with both of the aforementioned methods is that the “reasoning” for the answer is determined after the answer has been generated (i.e., reasoning should inform the answer, not vice-versa). The way forward: A method which"
2021.naacl-main.297,2020.acl-main.468,0,0.035636,"n phrased in the negative. An action A taken for reasons R is unethical if and only if a world where all people perform A for reasons R logically contradicts R. The main utility of the generalization principle is that it can identify unethical actions that may seem acceptable in isolated occurrences but lead to problems when habitually taken by everyone. For example, let us take making and breaking a legal contract (the action) whenever it is convenient (the reasons); implicit in the reasons for making a Most of the work providing algorithmic solutions has been focused on bias in NLP systems. Shah et al. (2020); Tatman (2017); Larson (2017) aim to study the social impact of bias in NLP systems and propose frameworks to understand it bet4 ter. A large body of work (Bolukbasi et al., 2016; It is also referred to as the “universal law” formulation of Sun et al., 2019; Zhao et al., 2019, 2017; Sap et al., Kant’s categorical imperative. 3786 contract is that the other person believes we will follow through (Johnson and Cureton, 2019). If we universalize this and conceive of a world where everyone makes contracts which they have no intent of keeping, no one would believe in the sincerity of a contract. He"
2021.naacl-main.297,W18-2608,0,0.0254758,"as question-answering systems (Bouziane et al., studies what is good and right, especially as it per2015; Gillard et al., 2006; Yang et al., 2018) tains to how humans ought to behave in the most used in diverse fields like healthcare (Sarrouti and general sense (Fieser, 1995). As NLP research qualOuatik El Alaoui, 2017; Zweigenbaum, 2009), ed- ifies as a human activity, it is within the purview ucation (Godea and Nielsen, 2018; Raamadhurai of ethics. In particular, we are using a prescriptive, et al., 2019), privacy (Ravichander et al., 2019; rather than descriptive, theory of ethics; prescripShvartzshanider et al., 2018); machine translation tive theories define and recommend ethical behavsystems (Cherry et al., 2019; Barrault et al., 2019; ior whereas descriptive theories merely report how Nakazawa et al., 2019; Liu, 2018), conversational people generally conceive of ethical behavior. agents (Pietquin et al., 2020; Serban et al., 2018; We select two ethical principles from the deonLiu et al., 2016), recommendation systems (Al- tological tradition of ethics and focus on how these harthi and Inkpen, 2019; Greenquist et al., 2019) principles are relevant to research in NLP. Namely etc. are deployed and used by"
2021.naacl-main.297,P19-1159,0,0.0200948,"seem acceptable in isolated occurrences but lead to problems when habitually taken by everyone. For example, let us take making and breaking a legal contract (the action) whenever it is convenient (the reasons); implicit in the reasons for making a Most of the work providing algorithmic solutions has been focused on bias in NLP systems. Shah et al. (2020); Tatman (2017); Larson (2017) aim to study the social impact of bias in NLP systems and propose frameworks to understand it bet4 ter. A large body of work (Bolukbasi et al., 2016; It is also referred to as the “universal law” formulation of Sun et al., 2019; Zhao et al., 2019, 2017; Sap et al., Kant’s categorical imperative. 3786 contract is that the other person believes we will follow through (Johnson and Cureton, 2019). If we universalize this and conceive of a world where everyone makes contracts which they have no intent of keeping, no one would believe in the sincerity of a contract. Hence, no one would make contracts in the first place since they are never adhered to. This is the sort of contradiction by which the generalization principle condemns an action and the rationale behind it. Another example is plagiarism of research papers in c"
2021.naacl-main.297,W17-1610,0,0.0187789,"bout the potential social harms of NLP technology. They discussed the concepts of exclusion, overgeneralization, bias confirmation, topic under- and overexposure, and dual use from the perspective of NLP research. A lot of work followed this discussion and made contributions towards ethical frameworks and design practices (Leidner and Plachouras, 2017; Parra Escartín et al., 2017; Prabhumoye et al., 2019; Schnoebelen, 2017; Schmaltz, 2018), data handling practices (Lewis et al., 2017; Mieskes, 2017) and specific domains like education (Mayfield et al., 2019; Loukina et al., 2019), healthcare (Šuster et al., 2017; Benton et al., 2017) and conversational agents (Cercas Curry and Rieser, 2018; Henderson et al., 2018). Our paper does not focus on a particular domain but calls for attention towards various NLP systems and what ethical issues may arise in them. 2019; Hanna et al., 2020; Davidson et al., 2019) directs its efforts to mitigate bias in data, representations, and algorithms. Blodgett et al. (2020) provide an extensive survey of this work and point out the weaknesses in the research design. It makes recommendations of grounding work analyzing bias in NLP systems in the relevant literature outsid"
2021.naacl-main.297,W17-1606,0,0.0149286,"ative. An action A taken for reasons R is unethical if and only if a world where all people perform A for reasons R logically contradicts R. The main utility of the generalization principle is that it can identify unethical actions that may seem acceptable in isolated occurrences but lead to problems when habitually taken by everyone. For example, let us take making and breaking a legal contract (the action) whenever it is convenient (the reasons); implicit in the reasons for making a Most of the work providing algorithmic solutions has been focused on bias in NLP systems. Shah et al. (2020); Tatman (2017); Larson (2017) aim to study the social impact of bias in NLP systems and propose frameworks to understand it bet4 ter. A large body of work (Bolukbasi et al., 2016; It is also referred to as the “universal law” formulation of Sun et al., 2019; Zhao et al., 2019, 2017; Sap et al., Kant’s categorical imperative. 3786 contract is that the other person believes we will follow through (Johnson and Cureton, 2019). If we universalize this and conceive of a world where everyone makes contracts which they have no intent of keeping, no one would believe in the sincerity of a contract. Hence, no one wou"
2021.naacl-main.297,W16-4620,0,0.307292,"Missing"
2021.naacl-main.297,D18-1259,1,0.801922,"thics in philosophy which leaves 1 Introduction a rich body of knowledge untapped. The 21st century is witnessing a major shift in Our work bridges this gap by illustrating how the way people interact with technology, and nat- a philosophical theory of ethics can be applied to ural language processing (NLP) is playing a cen- NLP research. Ethics (or ethical theory), is a thetral role. A plethora of NLP applications such oretical and applied branch of philosophy which as question-answering systems (Bouziane et al., studies what is good and right, especially as it per2015; Gillard et al., 2006; Yang et al., 2018) tains to how humans ought to behave in the most used in diverse fields like healthcare (Sarrouti and general sense (Fieser, 1995). As NLP research qualOuatik El Alaoui, 2017; Zweigenbaum, 2009), ed- ifies as a human activity, it is within the purview ucation (Godea and Nielsen, 2018; Raamadhurai of ethics. In particular, we are using a prescriptive, et al., 2019), privacy (Ravichander et al., 2019; rather than descriptive, theory of ethics; prescripShvartzshanider et al., 2018); machine translation tive theories define and recommend ethical behavsystems (Cherry et al., 2019; Barrault et al.,"
2021.naacl-main.297,P18-1205,0,0.0170369,"ousands of years to learn about human-human interaction, we have only had a half-century to learn about the effects of human-machine (and thus, child-machine) interaction (Reeves and Nass, 1996). We suggest two key areas which are important for dialogue system researchers: (1) they must answer the question of what unique social role do dialogue systems fulfill—that is, in what respects can they be regarded as human-like vs. machinelike, and (2) the dialogue systems must have some way of modeling the social dynamics and cues of the interlocutor to fulfill the social role properly. and persona (Zhang et al., 2018) of dialogue agents which can be used for this purpose. 5 Ethical Decision Making with NLP So far we have discussed how NLP systems can be evaluated using ethical frameworks and how decisions made by such systems can be assisted by these theories. NLP can also aid in making decisions in accordance with the deontological framework. Recall that the generalization principle judges the ethical standing of pairs of actions and reasons; these pairs could be extracted with various NLP techniques from textual content. In the case of flagging objectionable content (§4.2), extracting the deeper intents"
2021.naacl-main.297,N19-1064,0,0.0543729,"Missing"
2021.naacl-main.297,D17-1323,0,0.0322003,"Missing"
2021.naacl-main.297,D18-1076,1,0.892944,"Missing"
2021.naacl-main.297,W09-2701,0,0.0535283,"teract with technology, and nat- a philosophical theory of ethics can be applied to ural language processing (NLP) is playing a cen- NLP research. Ethics (or ethical theory), is a thetral role. A plethora of NLP applications such oretical and applied branch of philosophy which as question-answering systems (Bouziane et al., studies what is good and right, especially as it per2015; Gillard et al., 2006; Yang et al., 2018) tains to how humans ought to behave in the most used in diverse fields like healthcare (Sarrouti and general sense (Fieser, 1995). As NLP research qualOuatik El Alaoui, 2017; Zweigenbaum, 2009), ed- ifies as a human activity, it is within the purview ucation (Godea and Nielsen, 2018; Raamadhurai of ethics. In particular, we are using a prescriptive, et al., 2019), privacy (Ravichander et al., 2019; rather than descriptive, theory of ethics; prescripShvartzshanider et al., 2018); machine translation tive theories define and recommend ethical behavsystems (Cherry et al., 2019; Barrault et al., 2019; ior whereas descriptive theories merely report how Nakazawa et al., 2019; Liu, 2018), conversational people generally conceive of ethical behavior. agents (Pietquin et al., 2020; Serban et"
2021.naacl-main.338,P18-1082,0,0.0232609,"to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task specific modeling tems (Mirkin and Meunier, 2015; Rabinovich et al., techniques (Zhao et al., 2020a,b; Prabhumoye et al., 2017), story generation (Fan et al., 2018; Yao et al., 2019). Our work unifies these tasks and formally 2019), and question answering systems (Gatius, shows the similarity in them: presence of a context 2017; Reddy et al., 2019). and a document to ground the information in the Despite these mainstream applications, NLG sys- generation process. tems face the challenges of being bland, devoid of Our work introduces two novel improvements content, generating generic outputs and hallucinatto the architectures of large scale pre-trained moding information (Wiseman et al., 2017; Li et al., els (Lewis et al., 2019; Raffel et al., 2019): (1)"
2021.naacl-main.338,W17-3518,0,0.0607496,"Missing"
2021.naacl-main.338,W17-3530,0,0.0608403,"Missing"
2021.naacl-main.338,W18-6467,0,0.0449273,"Missing"
2021.naacl-main.338,D16-1128,0,0.0577594,"Missing"
2021.naacl-main.338,2020.acl-main.703,0,0.0638364,"Missing"
2021.naacl-main.338,N16-1014,0,0.0356773,"nd a source of content (document). Additionally, the generated text should coherently fit the context and 3 Methodology contain information from the document. We focus on content present in unstructured form in docu- A natural way to model pθ (xi |ci , di ) is to train an ments to ground text generation. Figure 1 illus- encoder-decoder model using cross-entropy loss trates such an example. Dialogue response gener- − log pθ with respect to the ground-truth output ation is traditionally conditioned on the dialogue text. We discuss two ways of building effective repcontext (Vinyals and Le, 2015; Li et al., 2016). resentations for encoder-decoder models to focus 4275 on di : (1) combine encoder representations of ci and di , (2) include an additional attention multihead at each layer of the transformer to specifically focus on the content in di . 3.1 Baselines Low-Res: Zhao et al. (2020a) introduce the stateof-the-art model for document grounded dialogue generation. As described in (§2), the chat history serves as the context ci and xi is the response to be generated. Zhao et al. (2020a) pre-train their architecture on the dialogue specific Reddit (Dziri et al., 2018) dataset and learn separate parame"
2021.naacl-main.338,N16-1086,0,0.0606216,"Missing"
2021.naacl-main.338,2020.coling-main.1,1,0.843515,"rundkiewicz (2018) use an additional attention multi-head in transformer architecture for automatic post-editing task. We demonstrate how attention can be enhanced in pre-trained models. The CoDR model fuses the representations of the document and the context in the decoder which is inspired by the fusion-in-decoder model in open-domain QA (Izacard and Grave, 2020). Although Bruyn et al. (2020) introduce the usage of BART for knowledge grounded dialogues, it is primarily from the perspective of improving knowledge retrieval. We provide benchmark BART numbers (Table 1) for the generation task. Prabhumoye et al. (2020) provide a schema containing five modules which can be changed to control the generation process. While Zhao et al. (2020a) modify the external input and the output module, we focus on the external input and the generator module of the pre-trained language model. 8 Conclusion and Future Work provides us with insight on how to model these tasks in future. Particularly, future work can focus on designing better evaluation metrics which don’t penalize linguistic variations in generation. Better models can also be constructed to focus on cases of partial hallucination or incorrect responses. 9 Eth"
2021.naacl-main.338,N19-1269,1,0.778815,"closeness to reference and ability of data in unstructured form (e.g. books, relevance to the document. Furthermore, we encyclopedias, news articles, and Wikipedia artiperform comprehensive manual inspection of cles). This enhances the applicability of document the generated output and categorize errors to grounded generation to a wide range of domains provide insights into future directions in modwith limited (or no) availability of structured data. eling these tasks. Hence, recent work has focused on defining new tasks and carving the scope of the problems (Liu 1 Introduction et al., 2018; Prabhumoye et al., 2019; Faltings et al., Natural language generation (NLG) systems are 2020; Zhou et al., 2018; Dinan et al., 2018). increasingly expected to be naturalistic, contentWe focus on two different document grounded ful, and situation-aware due to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tas"
2021.naacl-main.338,D15-1238,0,0.0225819,". increasingly expected to be naturalistic, contentWe focus on two different document grounded ful, and situation-aware due to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task specific modeling tems (Mirkin and Meunier, 2015; Rabinovich et al., techniques (Zhao et al., 2020a,b; Prabhumoye et al., 2017), story generation (Fan et al., 2018; Yao et al., 2019). Our work unifies these tasks and formally 2019), and question answering systems (Gatius, shows the similarity in them: presence of a context 2017; Reddy et al., 2019). and a document to ground the information in the Despite these mainstream applications, NLG sys- generation process. tems face the challenges of being bland, devoid of Our work introduces two novel improvements content, generating generic outputs and hallucinatto the architectures of large scale"
2021.naacl-main.338,E17-1101,0,0.0255671,"Missing"
2021.naacl-main.338,I17-1047,0,0.0563027,"Missing"
2021.naacl-main.338,K16-1028,0,0.0280317,"generation is completely incorrect and hallucinates all of the information. Future work can focus on improving the error in the Incorrect and Partial Hallucination error classes. els produce appropriate outputs which can be used as alternate responses/updates. Our models are preferred over the reference in both the tasks suggesting that the automated evaluation is insufficient and the sole reference should not be considered as the only correct response to the context. 7 Related Work Generation grounded in document has been studied through a large body of summarization work (Rush et al., 2015; Nallapati et al., 2016) and similar tasks such as headline generation (Tan et al., 2017). MulReference Comparison: With the insights from manual inspection, we performed another compara- tiple new works have extended this research in new tive study with human judges (on Amazon Mechan- directions; Wikipedia Update Generation (Prabhuical Turk). This was to understand how our mod- moye et al., 2019) introduces the task of generating an update to the Wikipedia context based on a news els perform in comparison with the reference. The document; Wikipedia article generation (Liu et al., judges are instructed to “Pick the o"
2021.naacl-main.338,Q18-1027,0,0.0135903,"ngs et al., Natural language generation (NLG) systems are 2020; Zhou et al., 2018; Dinan et al., 2018). increasingly expected to be naturalistic, contentWe focus on two different document grounded ful, and situation-aware due to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task specific modeling tems (Mirkin and Meunier, 2015; Rabinovich et al., techniques (Zhao et al., 2020a,b; Prabhumoye et al., 2017), story generation (Fan et al., 2018; Yao et al., 2019). Our work unifies these tasks and formally 2019), and question answering systems (Gatius, shows the similarity in them: presence of a context 2017; Reddy et al., 2019). and a document to ground the information in the Despite these mainstream applications, NLG sys- generation process. tems face the challenges of being bland, devoid of Our work introduces two"
2021.naacl-main.338,P19-1659,0,0.0491576,"Missing"
2021.naacl-main.338,P02-1040,0,0.109448,".00 24.14 11.50 14.62 14.98 15.08 7.50 10.24 10.64 10.68 Wizard of Wikipedia (Unseen) Low-Res (Zhao et al., 2020a) BART (baseline) CoDR DoHA 20.70 21.88 21.84 22.31 10.10 12.54 12.74 13.04 6.20 8.44 8.60 8.89 Table 1: Results on the automated metrics for the three datasets 5 Experiments and Results We implement all our models with the transformers tool (Wolf et al., 2019), and the details are in §A. 5.1 Automated Evaluation Following prior work (Prabhumoye et al., 2019; Zhao et al., 2020a), we evaluate our systemgenerated sentences against the reference sentences on Rouge-L (Lin, 2004), BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2011) metrics.2 Rouge-L measures the longest common subsequence between the generated sentence and the reference, capturing both lexical selection and word order. METEOR also uses synonyms and stemmed forms of the words in candidate and reference sentences, and thus may be better at quantifying semantic similarities. Additionally, we present F1 which indicates the unigram overlap between the generated output and the reference sentence.3 Table 1 shows that the BART baseline outperforms previous state-of-the-art models (Zhao et al., 2020a; Prabhumoye et al., 201"
2021.naacl-main.338,Q19-1016,0,0.0120441,"et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task specific modeling tems (Mirkin and Meunier, 2015; Rabinovich et al., techniques (Zhao et al., 2020a,b; Prabhumoye et al., 2017), story generation (Fan et al., 2018; Yao et al., 2019). Our work unifies these tasks and formally 2019), and question answering systems (Gatius, shows the similarity in them: presence of a context 2017; Reddy et al., 2019). and a document to ground the information in the Despite these mainstream applications, NLG sys- generation process. tems face the challenges of being bland, devoid of Our work introduces two novel improvements content, generating generic outputs and hallucinatto the architectures of large scale pre-trained moding information (Wiseman et al., 2017; Li et al., els (Lewis et al., 2019; Raffel et al., 2019): (1) 2016; Holtzman et al., 2020; Welleck et al., 2020). we focus on building context driven representation Grounding the generation in different modalities of the document, where the context"
2021.naacl-main.338,Q13-1003,0,0.0951158,"Missing"
2021.naacl-main.338,D15-1044,0,0.0554012,"of the cases, the generation is completely incorrect and hallucinates all of the information. Future work can focus on improving the error in the Incorrect and Partial Hallucination error classes. els produce appropriate outputs which can be used as alternate responses/updates. Our models are preferred over the reference in both the tasks suggesting that the automated evaluation is insufficient and the sole reference should not be considered as the only correct response to the context. 7 Related Work Generation grounded in document has been studied through a large body of summarization work (Rush et al., 2015; Nallapati et al., 2016) and similar tasks such as headline generation (Tan et al., 2017). MulReference Comparison: With the insights from manual inspection, we performed another compara- tiple new works have extended this research in new tive study with human judges (on Amazon Mechan- directions; Wikipedia Update Generation (Prabhuical Turk). This was to understand how our mod- moye et al., 2019) introduces the task of generating an update to the Wikipedia context based on a news els perform in comparison with the reference. The document; Wikipedia article generation (Liu et al., judges are"
2021.naacl-main.338,D18-1419,0,0.0458749,"Missing"
2021.naacl-main.338,P18-1205,0,0.182254,"oblems (Liu 1 Introduction et al., 2018; Prabhumoye et al., 2019; Faltings et al., Natural language generation (NLG) systems are 2020; Zhou et al., 2018; Dinan et al., 2018). increasingly expected to be naturalistic, contentWe focus on two different document grounded ful, and situation-aware due to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task specific modeling tems (Mirkin and Meunier, 2015; Rabinovich et al., techniques (Zhao et al., 2020a,b; Prabhumoye et al., 2017), story generation (Fan et al., 2018; Yao et al., 2019). Our work unifies these tasks and formally 2019), and question answering systems (Gatius, shows the similarity in them: presence of a context 2017; Reddy et al., 2019). and a document to ground the information in the Despite these mainstream applications, NLG sys- generation process. t"
2021.naacl-main.338,2020.emnlp-main.272,0,0.182334,"us on two different document grounded ful, and situation-aware due to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task specific modeling tems (Mirkin and Meunier, 2015; Rabinovich et al., techniques (Zhao et al., 2020a,b; Prabhumoye et al., 2017), story generation (Fan et al., 2018; Yao et al., 2019). Our work unifies these tasks and formally 2019), and question answering systems (Gatius, shows the similarity in them: presence of a context 2017; Reddy et al., 2019). and a document to ground the information in the Despite these mainstream applications, NLG sys- generation process. tems face the challenges of being bland, devoid of Our work introduces two novel improvements content, generating generic outputs and hallucinatto the architectures of large scale pre-trained moding information (Wiseman et al., 20"
2021.naacl-main.338,D18-1076,1,0.941011,"document. Furthermore, we encyclopedias, news articles, and Wikipedia artiperform comprehensive manual inspection of cles). This enhances the applicability of document the generated output and categorize errors to grounded generation to a wide range of domains provide insights into future directions in modwith limited (or no) availability of structured data. eling these tasks. Hence, recent work has focused on defining new tasks and carving the scope of the problems (Liu 1 Introduction et al., 2018; Prabhumoye et al., 2019; Faltings et al., Natural language generation (NLG) systems are 2020; Zhou et al., 2018; Dinan et al., 2018). increasingly expected to be naturalistic, contentWe focus on two different document grounded ful, and situation-aware due to their popularity generation tasks: (1) Wikipedia Update Generation and pervasiveness in human life (Reiter and Dale, task (Prabhumoye et al., 2019) and (2) Dialogue 2000; Mitchell et al., 2014). This is particularly response generation (Zhou et al., 2018; Dinan et al., relevant in dialogue systems (Zhang et al., 2018a; 2018). Prior work has studied these two tasks indeNiu and Bansal, 2018), machine translation sys- pendently and focused on task spe"
2021.naacl-main.338,D15-1199,0,0.0488658,"Missing"
2021.naacl-main.338,2020.emnlp-demos.6,0,0.096674,"Missing"
C12-2070,2005.iwslt-1.8,0,0.0165691,"eline similar to the one described in (Koehn et al., 2003). First, the word alignments were generated using IBM model 4. Then, the translation model was generate using the phrase extraction algorithm (Paul et al., 2010)(Koehn et al., 2007). The maximum size of the phrase pairs is set to 7, both for the source and the target language. The model uses as features: • • • • • Translation probability Reverse translation probability Lexical translation probability Reverse lexical translation probability Phrase penalty The reordering model is built using the lexicalized reordering model described in (Axelrod et al., 2005), with MSD (mono, swap and discontinuous) reordering features for orientations. All the translation and reordering features are considered during the calculation of the relative entropy. As in (Zens et al., 2012), we removed all singleton phrase pairs from the phrase table. This will lower the effectiveness of significance pruning, since a large amount of least significant phrase pairs will be removed a priori. The filtered translation model contains, approximately 50 million phrase pairs. As language model, a 5-gram model with Kneser-ney smoothing was used. The baseline model was tuned using"
C12-2070,N09-1025,0,0.0272792,"are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, to maximize a translation quality, which makes the procedure extremely expensive. A similar model is used in (Venugopal et al., 2003) without any parameter tuning. (Zettlemoyer and Moore, 2007) use an already tuned model (using MERT) 714 in a competitive linking algorithm to keep the best one-to-one phras"
C12-2070,P08-1010,0,0.0162618,"analyses both algorithms and preceeds our combination approach in sub-section 2.4. The results obtained with the EUROPARL corpus (Koehn, 2005) are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, to maximize a translation quality, which makes the procedure extremely expensive. A similar model is used in (Venugopal et al., 2003) without any parameter tun"
C12-2070,D07-1103,0,0.385725,"based on relative entropy is described in (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). In these approaches, a criteria based on the KL divergence is applied, so that higher order n-grams are only included in the model when they provide enough additional information to the model, given the lower order n-grams. Recently, this concept was applied for translation model pruning (Ling et al., 2012; Zens et al., 2012), and results indicate that this method yields a better phrase table size and translation quality ratio than previous methods, such as the well known method in (Johnson et al., 2007), which uses the Fisher’s exact test to calculate how well a phrase pair is supported by data. In this work, we attempt to improve the relative entropy model, by combining it with the significance based approach presented in (Johnson et al., 2007).The main motivation is that, as suggested in (Ling et al., 2012), relative entropy and significance based methods are complementary. On one hand, relative entropy aims at pruning phrase pairs that can be reproduced using smaller constituents with a small or no loss in terms of the models predictions. On the other hand, significance pruning aims at re"
C12-2070,2005.mtsummit-papers.11,0,0.242631,"nd are originated from incorrect alignments at sentence or word level. This indicates that both methods can be combined to obtain better results. We propose a log-linear interpolation of the two metrics to achieve a better trade off between the number of phrase pairs and the translation quality. This paper is structured as follows: Section 2 includes a brief summary of relative entropy and significance pruning approaches in sub-sections 2.1 and 2.2. Sub-section 2.3 analyses both algorithms and preceeds our combination approach in sub-section 2.4. The results obtained with the EUROPARL corpus (Koehn, 2005) are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004;"
C12-2070,P07-2045,0,0.0067566,"ance score of 10. 3 Experimental Results 3.1 Data Sets Experiments were performed using the publicly available EUROPARL (Koehn, 2005) corpora for the English-French language pair. From this corpus, 1.2M sentence pairs were selected for training, 2000 for tuning and another 2000 for testing. 3.2 Baseline System The baseline translation system was trained using a conventional pipeline similar to the one described in (Koehn et al., 2003). First, the word alignments were generated using IBM model 4. Then, the translation model was generate using the phrase extraction algorithm (Paul et al., 2010)(Koehn et al., 2007). The maximum size of the phrase pairs is set to 7, both for the source and the target language. The model uses as features: • • • • • Translation probability Reverse translation probability Lexical translation probability Reverse lexical translation probability Phrase penalty The reordering model is built using the lexicalized reordering model described in (Axelrod et al., 2005), with MSD (mono, swap and discontinuous) reordering features for orientations. All the translation and reordering features are considered during the calculation of the relative entropy. As in (Zens et al., 2012), we r"
C12-2070,N03-1017,0,0.0919428,"s structured as follows: Section 2 includes a brief summary of relative entropy and significance pruning approaches in sub-sections 2.1 and 2.2. Sub-section 2.3 analyses both algorithms and preceeds our combination approach in sub-section 2.4. The results obtained with the EUROPARL corpus (Koehn, 2005) are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, t"
C12-2070,D12-1088,1,0.819902,"al selection criteria. The challenge in this task is to choose the entries that will least degenerate the quality of the task for which the model is used. For language models, an effective algorithm based on relative entropy is described in (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). In these approaches, a criteria based on the KL divergence is applied, so that higher order n-grams are only included in the model when they provide enough additional information to the model, given the lower order n-grams. Recently, this concept was applied for translation model pruning (Ling et al., 2012; Zens et al., 2012), and results indicate that this method yields a better phrase table size and translation quality ratio than previous methods, such as the well known method in (Johnson et al., 2007), which uses the Fisher’s exact test to calculate how well a phrase pair is supported by data. In this work, we attempt to improve the relative entropy model, by combining it with the significance based approach presented in (Johnson et al., 2007).The main motivation is that, as suggested in (Ling et al., 2012), relative entropy and significance based methods are complementary. On one hand, rela"
C12-2070,D09-1078,0,0.0220035,"s to more search errors due to the large search space. Furthermore, larger models are more expensive to store, which limits the portability of such models to smaller devices. Pruning is one approach to address this problem, where models are made more compact by discarding entries from the model, based on additional selection criteria. The challenge in this task is to choose the entries that will least degenerate the quality of the task for which the model is used. For language models, an effective algorithm based on relative entropy is described in (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). In these approaches, a criteria based on the KL divergence is applied, so that higher order n-grams are only included in the model when they provide enough additional information to the model, given the lower order n-grams. Recently, this concept was applied for translation model pruning (Ling et al., 2012; Zens et al., 2012), and results indicate that this method yields a better phrase table size and translation quality ratio than previous methods, such as the well known method in (Johnson et al., 2007), which uses the Fisher’s exact test to calculate how well a phrase pair is supported by"
C12-2070,P03-1021,0,0.0139315,"ono, swap and discontinuous) reordering features for orientations. All the translation and reordering features are considered during the calculation of the relative entropy. As in (Zens et al., 2012), we removed all singleton phrase pairs from the phrase table. This will lower the effectiveness of significance pruning, since a large amount of least significant phrase pairs will be removed a priori. The filtered translation model contains, approximately 50 million phrase pairs. As language model, a 5-gram model with Kneser-ney smoothing was used. The baseline model was tuned using MERT tuning (Och, 2003). We did not rerun tuning again after pruning to avoid adding noise to the results. Finally, we present the results evaluated with BLEU-4 (Papineni et al., 2002). After computing the negative log likelihood of both scores, we also rescale both score’s values by mean, so that scores will have similar values. This step is performed so the interpolation weights, in the results appear more intuitive. 718 3.3 Results We can see the results in table 2, where the first two rows, represent the BLEU scores for relative entropy pruning and significance pruning, respectively. Then, we have the scores obt"
C12-2070,N04-1021,0,0.0271312,"pus (Koehn, 2005) are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, to maximize a translation quality, which makes the procedure extremely expensive. A similar model is used in (Venugopal et al., 2003) without any parameter tuning. (Zettlemoyer and Moore, 2007) use an already tuned model (using MERT) 714 in a competitive linking algorithm to keep the"
C12-2070,P02-1040,0,0.0848059,"of the relative entropy. As in (Zens et al., 2012), we removed all singleton phrase pairs from the phrase table. This will lower the effectiveness of significance pruning, since a large amount of least significant phrase pairs will be removed a priori. The filtered translation model contains, approximately 50 million phrase pairs. As language model, a 5-gram model with Kneser-ney smoothing was used. The baseline model was tuned using MERT tuning (Och, 2003). We did not rerun tuning again after pruning to avoid adding noise to the results. Finally, we present the results evaluated with BLEU-4 (Papineni et al., 2002). After computing the negative log likelihood of both scores, we also rescale both score’s values by mean, so that scores will have similar values. This step is performed so the interpolation weights, in the results appear more intuitive. 718 3.3 Results We can see the results in table 2, where the first two rows, represent the BLEU scores for relative entropy pruning and significance pruning, respectively. Then, we have the scores obtained using the scorer in 4 of these 2 scores, with α weights at intervals of 0.1. Finally, we have the scores using the scorer 5, also with the weight α set at"
C12-2070,2010.iwslt-evaluation.1,0,0.0164305,"d with the significance score of 10. 3 Experimental Results 3.1 Data Sets Experiments were performed using the publicly available EUROPARL (Koehn, 2005) corpora for the English-French language pair. From this corpus, 1.2M sentence pairs were selected for training, 2000 for tuning and another 2000 for testing. 3.2 Baseline System The baseline translation system was trained using a conventional pipeline similar to the one described in (Koehn et al., 2003). First, the word alignments were generated using IBM model 4. Then, the translation model was generate using the phrase extraction algorithm (Paul et al., 2010)(Koehn et al., 2007). The maximum size of the phrase pairs is set to 7, both for the source and the target language. The model uses as features: • • • • • Translation probability Reverse translation probability Lexical translation probability Reverse lexical translation probability Phrase penalty The reordering model is built using the lexicalized reordering model described in (Axelrod et al., 2005), with MSD (mono, swap and discontinuous) reordering features for orientations. All the translation and reordering features are considered during the calculation of the relative entropy. As in (Zens"
C12-2070,2008.amta-srw.6,0,0.0176384,"en their probabilities log P(t|s) . This value is then weighted by the empirical distribution P(s, t), so that phrase pairs that are more likely to be observed in the data are less likely to be pruned. The empirical distribution is given as: P(s, t) = C(s, t) (2) N Where C(s, t) denotes, the number of sentence pairs where s and t are observed, and N denotes the number of sentence pairs. Computing Pp (t|s) is the most computationally expensive operation in this model, since it involves finding all possible derivations of a phrase pair using smaller units, which involves a forced decoding step (Schwartz, 2008). While minimizing D(Pp ||P) would lead to optimal results, such optimization is computationally infeasible. Thus, an approximation is the find the local values for each phrase pair: RelEnt(s,t) = −P(s, t)l og Pp (t|s) P(t|s) (3) This score can be viewed as the relative entropy between Pp (t|s) and P(t|s), if only the phrase pair with source s and target t is pruned. The problem with this approximation is that, we might assume a given phrase pair A can be pruned, because it can be composed by phrase pairs B and C , only to discover later that B is also pruned. 2.2 Significance Pruning Signific"
C12-2070,2009.mtsummit-papers.17,1,0.786811,"sults, such optimization is computationally infeasible. Thus, an approximation is the find the local values for each phrase pair: RelEnt(s,t) = −P(s, t)l og Pp (t|s) P(t|s) (3) This score can be viewed as the relative entropy between Pp (t|s) and P(t|s), if only the phrase pair with source s and target t is pruned. The problem with this approximation is that, we might assume a given phrase pair A can be pruned, because it can be composed by phrase pairs B and C , only to discover later that B is also pruned. 2.2 Significance Pruning Significance pruning of phrase tables (Johnson et al., 2007; Tomeh et al., 2009) relies on a statistical test that assesses the strength of the association between the source and target phrases in a phrase pair. Such association can be represented using a two-by-two contingency table: 715 C(s, t) C(t) − C(s, t) C(s) − C(s, t) N − C(s) − C(t) + C(s, t) where N is the size of the training parallel corpus, C(s) is the count of the source phrase, C(t) is the count of the target phrase, and C(s, t) is the count of the co-occurences of s and t . The probability of this particular table is given by the the hypergeometric distribution: ph (C(s, t)) = C(s)  N −C(s)  C(s,t) C(t)−"
C12-2070,2011.iwslt-papers.10,1,0.758963,"combination approach in sub-section 2.4. The results obtained with the EUROPARL corpus (Koehn, 2005) are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, to maximize a translation quality, which makes the procedure extremely expensive. A similar model is used in (Venugopal et al., 2003) without any parameter tuning. (Zettlemoyer and Moore, 2007) use an alr"
C12-2070,P03-1041,0,0.0349745,"rithms and preceeds our combination approach in sub-section 2.4. The results obtained with the EUROPARL corpus (Koehn, 2005) are shown in Section 3. Finally, we conclude and present directions for future research in Section 4. 2 Combining Relative Entropy and Significance Pruning In principle, any method of evaluation of phrase pairs can be used as the basis for pruning. This includes phrase counts and probabilities (Koehn et al., 2003), statistical significance tests (Johnson et al., 2007), and relative entropy scores (Ling et al., 2012; Zens et al., 2012) and many others (Deng et al., 2008; Venugopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, to maximize a translation quality, which makes the procedure extremely expensive. A similar model is used in (Venugopal et al., 2003) without any parameter tuning. (Zettlemoyer and Mo"
C12-2070,D12-1089,0,0.176872,"ia. The challenge in this task is to choose the entries that will least degenerate the quality of the task for which the model is used. For language models, an effective algorithm based on relative entropy is described in (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). In these approaches, a criteria based on the KL divergence is applied, so that higher order n-grams are only included in the model when they provide enough additional information to the model, given the lower order n-grams. Recently, this concept was applied for translation model pruning (Ling et al., 2012; Zens et al., 2012), and results indicate that this method yields a better phrase table size and translation quality ratio than previous methods, such as the well known method in (Johnson et al., 2007), which uses the Fisher’s exact test to calculate how well a phrase pair is supported by data. In this work, we attempt to improve the relative entropy model, by combining it with the significance based approach presented in (Johnson et al., 2007).The main motivation is that, as suggested in (Ling et al., 2012), relative entropy and significance based methods are complementary. On one hand, relative entropy aims at"
C12-2070,N07-2053,0,0.0172899,"gopal et al., 2003; Tomeh et al., 2011), in addition to the features typically found in phrase tables (Och et al., 2004; Chiang et al., 2009). Each method reflects some characteristics of phrase pairs that are not sought by the other, and hence trying to combine them is a tempting idea. (Deng et al., 2008) incorporate several features into a log-linear model parametrized with yk that are tuned, along with the extraction threshold, to maximize a translation quality, which makes the procedure extremely expensive. A similar model is used in (Venugopal et al., 2003) without any parameter tuning. (Zettlemoyer and Moore, 2007) use an already tuned model (using MERT) 714 in a competitive linking algorithm to keep the best one-to-one phrase matching in each training sentence. In our work we favor efficiency and we focus on relative entropy and significance pruning, which can be efficiently computed, without the need to external information. They also deliver good practical performance. 2.1 Relative Entropy Pruning Relative entropy pruning for translation models (Ling et al., 2012; Zens et al., 2012) has a solid foundation on information theory. The goal in these methods is to find a pruned model Pp (t|s) that yields"
C92-4175,C86-1156,0,0.305644,"ot discourses. A discourse rcprcsenlalion structure ( I ) R S ) is dctined at each s t a g e in a discourse describing the cllrrellt state of the analys/8. A I)RS consists of two parts; a set of domain markrr.s, whicll can be bound to objects introduced into the current discourse, and a set of conditions on these markers. I)ltSs are typically written as boxes with the m a r k e r s in the top part and conditions below. For e x a m p l e a I)RS for the u t t e r a n c e ""a m a n 81liftS"" iS X =an ( X) l_='72 ] T h e following description of I ) R T in ASTL is based on lhe I ) H T definition in [6]. First we need a syntactic backbone to be able to discuss the constructi(m of a I ) R S for a discourse. As seen (briefly) above AS'I'I, oilers a basic g r a m m a r f o r m a l i s m . T h a t is, g r a m m a r rules are Sl)ecilled as e o a s t r a i n t s betwet'n iltterance siluatiollS, I'ROC. OF COLING-92, NANrFs, AUG. 23-28, 1992 Given such a backbone we need to define an aSTL representation for DRSs. DRSs have two parts. Discourse m a r k e r s c0.n be represenled as parallleters ill ASTI.. Ill situation theor3 p a r a m e t e r s denote partially d e t e r m i n e d objects. P a r a m"
D12-1088,J93-2003,0,0.0282878,"bilities. This model is then applied to phrase table pruning. Tests show that considerable amounts of phrase pairs can be excluded, without much impact on the translation quality. In fact, we show that better translations can be obtained using our pruned models, due to the compression of the search space during decoding. 1 Introduction Phrase-based Machine Translation Models (Koehn et al., 2003) model n-to-m translations of n source words to m target words, which are encoded in phrase pairs and stored in the translation model. This approach has an advantage over Word-based Translation Models (Brown et al., 1993), since translating multiple source words allows the context for each source word to be considered during transHowever, not all words add the same amount of contextual information. Using the same example for “in”, if we add the context “(hid the key) in”, it is still not possible to accurately identify the best translation for the word “in”. The phrase extraction algorithm (Ling et al., 2010) does not discriminate which phrases pairs encode contextual information, and extracts all phrase pairs with consistent alignments. Hence, phrases that add no contextual information, such as, p(hid the key"
D12-1088,W06-1607,0,0.0192687,", the possible derivations are either using phrase p(s, t) or one element of its support set S1 , S2 or S3 . On the other hand, on the pruned model where p(s, t) does not exist, only S1 , S2 and S3 can be used. Thus, given a s, t pair one of three situations may occur. First, if the probability of the phrase pair p(s, t) is lower than the highest probability element in SP (p(s, t)), then both the models will choose that element, in which P (t|s) case, Pp(t|s) = 1. This can happen, if we define 966 features that penalize longer phrase pairs, such as lexical weighting, or if we apply smoothing (Foster et al., 2006). Secondly, if the probability of p(s, t) is equal to the most likely element in SP (p(s, t)), regardless of whether the unpruned model choses to use p(s, t) or that element, the probability emissions of the pruned and unpruned model will be identiP (t|s) cal. Thus, for this case Pp(t|s) = 1. Finally, if the probability of p(s, t) is higher than other possible derivations, the unpruned model will choose to emit the probability of p(s, t), while the pruned model will emit the most likely element in SP (p(s, t)). Hence, the probability loss between the 2 models, will be the ratio between the pro"
D12-1088,D07-1103,0,0.253111,"tion 5. Finally, we conclude in section 6. 2 Phrase Table Pruning Phrase table pruning algorithms are important in translation, since they efficiently reduce the size of the translation model, without having a large negative impact in the translation quality. This is especially relevant in environments where memory constraints are imposed, such as translation systems for small devices like cellphones, and also when time constraints for the translation are defined, such as online Speech-to-Speech systems. 963 2.1 Significance Pruning A relevant reference in phrase table pruning is the work of (Johnson and Martin, 2007), where it is shown that a significant portion of the phrase table can be discarded without a considerable negative impact on translation quality, or even positive one. This work computes the probability, named p-value, that the joint occurrence event of the source phrase s and target phrase t occurring in same sentence pair happens by chance, and are actually statistically independent. Phrase pairs that have a high p-value, are more likely to be spurious and more prone to be pruned. This work is followed in (Tomeh et al., 2009), where phrase pairs are treated discriminately based on their com"
D12-1088,N03-1017,0,0.0838211,"Missing"
D12-1088,P07-2045,0,0.00825301,"sentence. Using this distribution, the model is more biased in pruning phrase pairs with s, t pairs that do not occur frequently. 3.4 Computing Pp (t|s) P (t|s) P (t|s) The computation of Pp(t|s) depends on how the decoder adapts when a phrase pair is pruned from the model. In the case of back-off language models, this can be solved by calculating the difference of the logs between the n-gram estimate and the backoff estimate. However, a translation decoder generally functions differently. In our work, we will assume that the decoding will be performed using a Viterbi decoder, such as MOSES (Koehn et al., 2007), where the translation with the highest score is chosen. In the example above, where s=”John in Portugal” and t=”John em Portugal”, the decoder would choose the derivation with the highest probability from s to t. Using the unpruned model, the possible derivations are either using phrase p(s, t) or one element of its support set S1 , S2 or S3 . On the other hand, on the pruned model where p(s, t) does not exist, only S1 , S2 and S3 can be used. Thus, given a s, t pair one of three situations may occur. First, if the probability of the phrase pair p(s, t) is lower than the highest probability"
D12-1088,2005.mtsummit-papers.11,0,0.0197343,"del would eliminate p3 and keep p1 , yet the best decision could be to keep p3 and remove p1 , if p3 is also frequently used in derivations of other phrase pairs. Thus, we leave the problem of finding the best set of phrases to prune as future work. 5 Experiments We tested the performance of our system under two different environments. The first is the small scale DIALOG translation task for IWSLT 2010 evaluation (Paul et al., 2010) using a small corpora for the Chinese-English language pair (henceforth referred to as “IWSLT”). The second one is a large scale test using the complete EUROPARL (Koehn, 2005) corpora for the Portuguese-English language pair, which we will denote by “EUROPARL”. 5.1 Corpus The IWSLT model was trained with 30K training sentences. The development corpus and test corpus were taken from the evaluation dataset in IWSLT 2006 (489 tuning and 500 test sentences with 7 references). The EUROPARL model was trained using the EUROPARL corpora with approximately 1.3M sentence pairs, leaving out 1K sentences for tuning and another 1K sentences for tests. 5.2 Setup In the IWSLT experiment, word alignments were generated using an HMM model (Vogel et al., 1996), with symmetric poster"
D12-1088,2007.mtsummit-papers.22,0,0.468875,"Missing"
D12-1088,D09-1078,0,0.198151,"nsiderable negative impact on translation quality, or even positive one. This work computes the probability, named p-value, that the joint occurrence event of the source phrase s and target phrase t occurring in same sentence pair happens by chance, and are actually statistically independent. Phrase pairs that have a high p-value, are more likely to be spurious and more prone to be pruned. This work is followed in (Tomeh et al., 2009), where phrase pairs are treated discriminately based on their complexity. Significance-based pruning has also been successfully applied in language modeling in (Moore and Quirk, 2009). Our work has a similar objective, but instead of trying to predict the independence between the source and target phrases in each phrase pair, we attempt to predict the independence between a phrase pair and other phrase pairs in the model. 2.2 Relevance Pruning Another proposed approach (Matthias Eck and Waibel, 2007) consists at collecting usage statistics for phrase pairs. This algorithm decodes the training corpora and extracts the number of times each phrase pair is used in the 1-best translation hypothesis. Thus, phrase pairs that are rarely used during decoding are excluded first duri"
D12-1088,P03-1021,0,0.0751012,"Missing"
D12-1088,2010.iwslt-evaluation.1,0,0.0454513,"Missing"
D12-1088,2008.amta-srw.6,0,0.0613165,"hing in the space of possible translations, but in the space of possible derivations, which are sequences of phrase translations p1 (s1 , t1 ), ..., pn (sn , tn ) that can be applied to s to Qgenerate an output t with the score given by P (t) ni=1 P (si , ti ). Our algorithm to determine SP (p(s, t)) can be described as an adaptation to the decoding algorithm in Moses, where we restrict the search space to the subspace SP (p(s, t)), that is, our search space is only composed by derivations that output t, without using p itself. This can be done using the forced decoding algorithm proposed in (Schwartz, 2008). Secondly, the score of a given translation hypothesis does not depend on the language model probability P (t), since all derivations in this search space have the same t, thus we discard this probability from the score function. Finally, rather than using beam search, we exhaustively search all the search space, to reduce the hypothesis of incurring a search error at this stage. This is possible, since phrase pairs are generally smaller than text (less than 8 words), and because we are constraining the search space to t, which is an order of magnitude smaller than the reg967 ular search spac"
D12-1088,2009.mtsummit-papers.17,0,0.472482,"relevant reference in phrase table pruning is the work of (Johnson and Martin, 2007), where it is shown that a significant portion of the phrase table can be discarded without a considerable negative impact on translation quality, or even positive one. This work computes the probability, named p-value, that the joint occurrence event of the source phrase s and target phrase t occurring in same sentence pair happens by chance, and are actually statistically independent. Phrase pairs that have a high p-value, are more likely to be spurious and more prone to be pruned. This work is followed in (Tomeh et al., 2009), where phrase pairs are treated discriminately based on their complexity. Significance-based pruning has also been successfully applied in language modeling in (Moore and Quirk, 2009). Our work has a similar objective, but instead of trying to predict the independence between the source and target phrases in each phrase pair, we attempt to predict the independence between a phrase pair and other phrase pairs in the model. 2.2 Relevance Pruning Another proposed approach (Matthias Eck and Waibel, 2007) consists at collecting usage statistics for phrase pairs. This algorithm decodes the training"
D12-1088,J10-3007,1,0.896555,"Missing"
D12-1088,C96-2141,0,0.348977,"using the complete EUROPARL (Koehn, 2005) corpora for the Portuguese-English language pair, which we will denote by “EUROPARL”. 5.1 Corpus The IWSLT model was trained with 30K training sentences. The development corpus and test corpus were taken from the evaluation dataset in IWSLT 2006 (489 tuning and 500 test sentences with 7 references). The EUROPARL model was trained using the EUROPARL corpora with approximately 1.3M sentence pairs, leaving out 1K sentences for tuning and another 1K sentences for tests. 5.2 Setup In the IWSLT experiment, word alignments were generated using an HMM model (Vogel et al., 1996), with symmetric posterior constraints (V. Grac¸a et al., 2010), using the Geppetto toolkit2 . This setup was used in the official evaluation in (Ling et al., 2010). For the EUROPARL experiment the word alignments were generated using IBM model 4. In both experiments, the translation model was built using the phrase extraction algorithm (Paul et al., 2010), with commonly used features in Moses (Ex: probability, lexical weighting, lexicalized reordering model). The optimization of the translation model weights was done using MERT tuning (Och, 2003) and the results were evaluated using BLEU-4. 5"
D12-1088,2010.iwslt-papers.14,1,\N,Missing
D13-1008,P06-2005,0,0.119477,"Missing"
D13-1008,2005.iwslt-1.8,0,0.0618985,"Missing"
D13-1008,P05-1074,0,0.444565,"Missing"
D13-1008,P11-1131,0,0.0205445,"Missing"
D13-1008,J92-4003,0,0.0391747,"Missing"
D13-1008,J93-2003,0,0.0256659,"Missing"
D13-1008,W11-2107,0,0.0305025,"Missing"
D13-1008,P08-1115,0,0.0452721,"Missing"
D13-1008,N13-1073,1,0.862904,"Missing"
D13-1008,P11-1137,0,0.00905253,"Missing"
D13-1008,N13-1037,0,0.00849129,"Missing"
D13-1008,W11-2210,0,0.028087,"Missing"
D13-1008,P11-1038,0,0.106633,"Missing"
D13-1008,D12-1039,0,0.166445,"Missing"
D13-1008,N03-1017,0,0.0474429,"Missing"
D13-1008,P07-2045,1,0.0119874,"Missing"
D13-1008,P13-1018,1,0.283107,"Missing"
D13-1008,J03-1002,0,0.0062214,"Missing"
D13-1008,J04-4002,0,0.110137,"Missing"
D13-1008,P03-1021,0,0.0134582,"Missing"
D13-1008,P02-1040,0,0.105491,"Missing"
D13-1008,P11-1002,0,0.0235515,"Missing"
D13-1008,J03-3002,0,0.0406716,"Missing"
D13-1008,P12-1021,0,0.0203959,"Missing"
D13-1008,C96-2141,0,0.0951178,"Missing"
D13-1008,N13-1050,0,0.1235,"Missing"
D13-1008,W13-2515,0,0.541542,"Missing"
D13-1008,D13-1007,0,0.0725911,"Missing"
D13-1008,2010.iwslt-papers.14,1,\N,Missing
D15-1161,P14-2131,0,0.0497195,"uage Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA Instituto Superior T´ecnico, Lisbon, Portugal {lingwang,chuchenl,ytsvetko,cdyer,awb}@cs.cmu.edu {ramon.astudillo,samir,isabel.trancoso}@inesc-id.pt Abstract The continuous bag-of-words (Mikolov et al., 2013) is one of the many models that learns word representations from raw textual data. While these models are adequate for learning semantic features, one of the problems of this model is the lack of sensitivity for word order, which limits their ability of learn syntactically motivated embeddings (Ling et al., 2015a; Bansal et al., 2014). While models have been proposed to address this problem, the complexity of these models (“Structured skip-n-gram” and “CWindow”) grows linearly as size of the window of words considered increases, as a new set of parameters is created for each relative position. On the other hand, the continuous bag-of-words model requires no additional parameters as it builds the context representation by summing over the embeddings in the window and its performance is an order of magnitude higher than of other models. We introduce an extension to the bag-ofwords model for learning words representations tha"
D15-1161,D14-1082,0,0.00523589,"local context (e.g. function words), while other words are more suited for determining global context, such as the topic of the document. Experiments performed on both semantically and syntactically oriented tasks show gains using our model over the existing bag of words model. Furthermore, compared to other more sophisticated models, our model scales better as we increase the size of the context of the model. 1 Introduction Learning word representations using raw text data have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These embeddings are generally learnt by defining an objective function, which predicts words conditioned on the context surrounding those words. Once trained, these can be used as features (Turian et al., 2010), as initializations of other neural networks (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). In this work, we propose an extension to the continuous bag-of-words model, which adds an attention model that considers contextu"
D15-1161,P14-1129,0,0.0182429,"pic of the document. Experiments performed on both semantically and syntactically oriented tasks show gains using our model over the existing bag of words model. Furthermore, compared to other more sophisticated models, our model scales better as we increase the size of the context of the model. 1 Introduction Learning word representations using raw text data have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These embeddings are generally learnt by defining an objective function, which predicts words conditioned on the context surrounding those words. Once trained, these can be used as features (Turian et al., 2010), as initializations of other neural networks (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). In this work, we propose an extension to the continuous bag-of-words model, which adds an attention model that considers contextual words differently depending on the word type and its relative position to the predicted word (distance to the le"
D15-1161,D14-1012,0,0.0194663,"data have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These embeddings are generally learnt by defining an objective function, which predicts words conditioned on the context surrounding those words. Once trained, these can be used as features (Turian et al., 2010), as initializations of other neural networks (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). In this work, we propose an extension to the continuous bag-of-words model, which adds an attention model that considers contextual words differently depending on the word type and its relative position to the predicted word (distance to the left/right). The main intuition behind our model is that the prediction of a word is only dependent on certain words within the context. For instance, in the sentence We won the game! Nicely played!, the prediction of the word played, depends on both the syntactic relation from nicely, which narrows down the list of candidates to verbs, and on the semant"
D15-1161,P12-1092,0,0.059041,"e a large drop on this semantically oriented task. Our attention-based model, on the other hand, out performs all other models on syntax-based tasks, while maintaining a competitive score on semantic tasks. This is an encouraging result that shows that it is possible to learn representations that can perform well on both semantic and syntactic tasks. 4 Related Work Many methods have been proposed for learning word representations. Earlier work learns embeddings using a recurrent language model (Collobert et al., 2011), while several simpler and more lightweight adaptations have been proposed (Huang et al., 2012; Mikolov et al., 2013). While most of the learnt vectors are semantically oriented, work has been done in order to extend the model to learn syntactically oriented embeddings (Ling et al., 2015a). Attention models are common in vision related tasks (Tang et al., 2014), where models learn to pay attention to certain parts of a image in order to make accurate predictions. This idea has been recently introduced in many NLP tasks, such as machine translation (Bahdanau et al., 2014). In the area of word representation learning, no prior work that uses attention models exists to our knowledge. 5 Co"
D15-1161,D13-1176,0,0.00900077,"g global context, such as the topic of the document. Experiments performed on both semantically and syntactically oriented tasks show gains using our model over the existing bag of words model. Furthermore, compared to other more sophisticated models, our model scales better as we increase the size of the context of the model. 1 Introduction Learning word representations using raw text data have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These embeddings are generally learnt by defining an objective function, which predicts words conditioned on the context surrounding those words. Once trained, these can be used as features (Turian et al., 2010), as initializations of other neural networks (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). In this work, we propose an extension to the continuous bag-of-words model, which adds an attention model that considers contextual words differently depending on the word type and its relative position to the predicted wor"
D15-1161,D14-1108,1,0.740924,"ction words), while other words are more suited for determining global context, such as the topic of the document. Experiments performed on both semantically and syntactically oriented tasks show gains using our model over the existing bag of words model. Furthermore, compared to other more sophisticated models, our model scales better as we increase the size of the context of the model. 1 Introduction Learning word representations using raw text data have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These embeddings are generally learnt by defining an objective function, which predicts words conditioned on the context surrounding those words. Once trained, these can be used as features (Turian et al., 2010), as initializations of other neural networks (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). In this work, we propose an extension to the continuous bag-of-words model, which adds an attention model that considers contextual words differently"
D15-1161,N15-1144,1,0.0648252,"ver, this model does not scale well as b increases as it requires V × dw more parameters for each new word in the window. Finally, setting a good value for b is difficult as larger values may introduce a degenerative behavior in the model, as more effort is spent predicting words that are conditioned on unrelated words, while smaller values of b may lead to cases where the window size is not large enough include words that are semantically related. For syntactic tasks, it has been shown that increasing the window size can adversely impact in the quality of the embeddings (Bansal et al., 2014; Lin et al., 2015). 2.2 CBOW with Attention We present a solution to these problems while maintaining the efficiency underlying the bag-ofwords model, and allowing it to consider contextual words within the window in a non-uniform way. We first rewrite the context window c as: X c= ai (wi )wi (2) i∈[−b,b]−{0} (1) where Oc corresponds to the projection of the context vector c onto the vocabulary V and v is a one-hot representation. For larger vocabularies it is inefficient to compute the normalizer P > v∈V exp v Oc. Solutions for problem are using the hierarchical softmax objective function (Mikolov et al., 2013"
D15-1161,N15-1142,1,0.386366,"isbon, Portugal Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA Instituto Superior T´ecnico, Lisbon, Portugal {lingwang,chuchenl,ytsvetko,cdyer,awb}@cs.cmu.edu {ramon.astudillo,samir,isabel.trancoso}@inesc-id.pt Abstract The continuous bag-of-words (Mikolov et al., 2013) is one of the many models that learns word representations from raw textual data. While these models are adequate for learning semantic features, one of the problems of this model is the lack of sensitivity for word order, which limits their ability of learn syntactically motivated embeddings (Ling et al., 2015a; Bansal et al., 2014). While models have been proposed to address this problem, the complexity of these models (“Structured skip-n-gram” and “CWindow”) grows linearly as size of the window of words considered increases, as a new set of parameters is created for each relative position. On the other hand, the continuous bag-of-words model requires no additional parameters as it builds the context representation by summing over the embeddings in the window and its performance is an order of magnitude higher than of other models. We introduce an extension to the bag-ofwords model for learning wo"
D15-1161,P14-1140,0,0.0283868,"Missing"
D15-1161,D07-1043,0,0.00495254,"embeddings in the domain of part-of-speech tagging in both supervised (Ling et al., 2015b) and unsupervised tasks (Lin et al., 2015). This later task is newly proposed, but we argue that success in it is a compelling demonstration of separation of words into syntactically coherent clusters. Part-of-speech induction. The work in (Lin et al., 2015) attempts to infer POS tags with a standard bigram hmm, which uses word embeddings to infer POS tags without supervision. We use the same dataset, obtained from the ConLL 2007 shared task (Nivre et al., 2007) Scoring is performed using the V-measure (Rosenberg and Hirschberg, 2007), which is used to predict syntactic classes at the word level. It has been shown in (Lin et al., 2015) that word embeddings learnt from structured skip-ngrams tend to work better at this task, mainly because it is less sensitive to larger window sizes. These results are consistent with our observations found in Table 1, in rows “Skip-ngram” and “SSkip-ngram”. We can observe that our attention based CBOW model (row “CBOW Attention”) improves over these results for both tasks and also the original CBOW model (row “CBOW”). 1369 CBOW Skip-ngram SSkip-ngram CBOW Attention POS Induction 50.40 33.86"
D15-1161,D13-1170,0,0.00265235,"sented in (Ling et al., 2015b) using the same hyper-parameters. Results on the POS accuracy on the test set are reported on Table 1. We can observe our model can obtain similar results compared to the structured skip-ngram model on this task, while training the model is significantly faster. The gap between the usage of different embeddings is not as large as in POS induction, as this is a supervised task, where pre-training generally leads to smaller improvements. 3.3 Semantic Evaluation To evaluate the quality of our vectors in terms of semantics, we use the sentiment analysis task (Senti) (Socher et al., 2013), which is a binary classification task for movie reviews. We simply use the mean of the word vectors of words in a sentence, and use them as features in an `2 regularized logistic regression classifier. We use the standard training/dev/test split and report accuracy on the test set in table 1. We can see that in this task, our models do not perform as well as the CBOW and Skipngram model, which hints that our model is learning embeddings that learn more towards syntax. This is expected as it is generally uncommon for embeddings to outperform existing models on both syntactic and semantic task"
D15-1161,P10-1040,0,0.138833,"better as we increase the size of the context of the model. 1 Introduction Learning word representations using raw text data have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These embeddings are generally learnt by defining an objective function, which predicts words conditioned on the context surrounding those words. Once trained, these can be used as features (Turian et al., 2010), as initializations of other neural networks (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). In this work, we propose an extension to the continuous bag-of-words model, which adds an attention model that considers contextual words differently depending on the word type and its relative position to the predicted word (distance to the left/right). The main intuition behind our model is that the prediction of a word is only dependent on certain words within the context. For instance, in the sentence We won the game! Nicely played!, the prediction of the word played, depen"
D15-1161,D15-1176,1,\N,Missing
D15-1161,D07-1096,0,\N,Missing
D15-1176,afonso-etal-2002-floresta,0,0.054909,"., 2001; Mueller et al., 2013). We now show that some of these features can be learnt automatically using our model. eat embedings for words words1 .This 5 cats NNS VBP NN Figure 3: Illustration of our neural network for POS tagging. 5.2 Experiments Datasets For English, we conduct experiments on the Wall Street Journal of the Penn Treebank dataset (Marcus et al., 1993), using the standard splits (sections 1–18 for train, 19–21 for tuning and 22–24 for testing). We also perform tests on 4 other languages, which we obtained from the CoNLL shared tasks (Mart´ı et al., 2007; Brants et al., 2002; Afonso et al., 2002; Atalay et al., 2003). While the PTB dataset provides standard train, tuning and test splits, there are no tuning sets in the datasets in other languages, so we withdraw the last 100 sentences from the training dataset and use them for tuning. Setup The POS model requires two sets of hyperparameters. Firstly, words must be converted into continuous representations and the same hyperparametrization as in language modeling (Section 4) is used. Additionally, we also compare to the convolutional model of Santos and Zadrozny (2014), which also requires the dimensionality for characters and the wor"
D15-1176,D15-1041,1,0.487282,"eling, it is frequent to prune higher order ngrams that do not encode any additional information (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). The same be applied in machine translation (Ling et al., 2012; Zens et al., 2012) by removing longer translation pairs that can be replicated using smaller ones. In essence our model learns regularities at the subword level that can be leveraged for building more compact word representations. Finally, our work has been applied to dependency parsing and found similar improvements over word models in morphologically rich languages (Ballesteros et al., 2015). 7 Conclusion We propose a C2W model that builds word embeddings for words without an explicit word lookup table. Thus, it benefits from being sensitive to lexical aspects within words, as it takes characters as atomic units to derive the embeddings for the word. On POS tagging, our models using characters alone can still achieve comparable or better results than state-of-the-art systems, without the need to manually engineer such lexical features. Although both language modeling and POS tagging both benefit strongly from morphological cues, the success of our models in languages with impover"
D15-1176,D13-1008,1,0.162387,"susceptible to these problems as they combine windows of characters at each convolution, where the order within the window is preserved. However, the order between extracted windows is not, so the problem still persists for longer words, such as those found in agglutinative languages. Yet, these approaches work in conjunction with a word lookup table, as they compensate for this inability. Aside from neural approaches, characterbased models have been applied to address multiple lexically oriented tasks, such as transliteration (Kang and Choi, 2000) and twitter normalization (Xu et al., 2013; Ling et al., 2013). Compacting models has been a focus of research in tasks, such as language modeling and machine translation, as extremely large models can be built with the large amounts of training data that are available in these tasks. In language modeling, it is frequent to prune higher order ngrams that do not encode any additional information (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). The same be applied in machine translation (Ling et al., 2012; Zens et al., 2012) by removing longer translation pairs that can be replicated using smaller ones. In essence our model learns regul"
D15-1176,N15-1142,1,0.116424,"y are not found labelled in the training data, the model would be dependent on context to determine their tags, which could lead to errors in ambiguous contexts. Unsupervised training methods such as the Skip-n-gram model (Mikolov et al., 2013) can be used to pretrain the word representations on unannotated corpora. If such pretraining places cat, dog and snake near each other in vector space, and the supervised POS data contains evidence that cat and dog are nouns, our model will be likely to label snake with the same tag. We train embeddings using English wikipedia with the dataset used in (Ling et al., 2015), and the Structured Skip-n-gram model. Results using pre-trained word lookup tables and the C2W with the pre-trained word lookup tables as additional parameters are shown in rows “word(sskip)” and “C2W + word(sskip)”. We can observe that both systems can obtain improvements over their random initializations (rows “word” and (C2W)). Finally, we also found that when using the C2W model in conjunction pre-trained word embeddings, that adding a non-linearity to the representations extracted from the C2W model eC w improves the results over using a simple linear trans+feat no no yes yes yes yes no"
D15-1176,P14-1140,0,0.0196322,"tors and Wordless Word Vectors It is commonplace to represent words as vectors. In contrast to na¨ıve models in which all word types in a vocabulary V are equally different from each other, vector space models capture the intuition that words may be different or similar along a variety of dimensions. Learning vector representations of words by treating them as optimizable parameters in various kinds of language models has been found to be a remarkably effective means for generating vector representations that perform well in other tasks (Collobert et al., 2011; Kalchbrenner and Blunsom, 2013; Liu et al., 2014; Chen and Manning, 2014). Formally, such models define a matrix P ∈ Rd×|V |, which contains d parameters for each word in the vocabulary V . For a given word type w ∈ V , a column is selected by right-multiplying P by a one-hot vector of length |V |, which we write 1w , that is zero in every dimension except for the element corresponding to w. Thus, P is often referred to as word lookup d table and we shall denote by eW w ∈ R the embedding obtained from a word lookup table for w as eW w = P · 1w . This allows tasks with low amounts of annotated data to be trained jointly with other tasks with"
D15-1176,W13-3512,0,0.437991,"are not independent. The wellknown “past tense debate” between connectionists and proponents of symbolic accounts concerns disagreements about how humans represent knowledge of inflectional processes (e.g., the formation of the English past tense), not whether such knowledge exists (Marslen-Wilson and Tyler, 1998). 2.2 Solution: Compositional Models Our solution to these problems is to construct a vector representation of a word by composing smaller pieces into a representation of the larger form. This idea has been explored in prior work by composing morphemes into representations of words (Luong et al., 2013; Botha and Blunsom, 2014; Soricut and Och, 2015). Morphemes are an ideal primitive for such a model since they are— by definition—the minimal meaning-bearing (or syntax-bearing) units of language. The drawback to such approaches is they depend on a morphological analyzer. In contrast, we would like to compose representations of characters into representations of words. However, the relationship between words 1521 forms and their meanings is non-trivial (de Saussure, 1916). While some compositional relationships exist, e.g., morphological processes such as adding -ing or -ly to a stem have rel"
D15-1176,D14-1082,0,0.0447531,"Word Vectors It is commonplace to represent words as vectors. In contrast to na¨ıve models in which all word types in a vocabulary V are equally different from each other, vector space models capture the intuition that words may be different or similar along a variety of dimensions. Learning vector representations of words by treating them as optimizable parameters in various kinds of language models has been found to be a remarkably effective means for generating vector representations that perform well in other tasks (Collobert et al., 2011; Kalchbrenner and Blunsom, 2013; Liu et al., 2014; Chen and Manning, 2014). Formally, such models define a matrix P ∈ Rd×|V |, which contains d parameters for each word in the vocabulary V . For a given word type w ∈ V , a column is selected by right-multiplying P by a one-hot vector of length |V |, which we write 1w , that is zero in every dimension except for the element corresponding to w. Thus, P is often referred to as word lookup d table and we shall denote by eW w ∈ R the embedding obtained from a word lookup table for w as eW w = P · 1w . This allows tasks with low amounts of annotated data to be trained jointly with other tasks with large amounts of data an"
D15-1176,J93-2004,0,0.0572265,"ls Experiments: Part-of-speech Tagging As a second illustration of the utility of our model, we turn to POS tagging. As morphology is a strong indicator for syntax in many languages, a much effort has been spent engineering features (Nakagawa et al., 2001; Mueller et al., 2013). We now show that some of these features can be learnt automatically using our model. eat embedings for words words1 .This 5 cats NNS VBP NN Figure 3: Illustration of our neural network for POS tagging. 5.2 Experiments Datasets For English, we conduct experiments on the Wall Street Journal of the Penn Treebank dataset (Marcus et al., 1993), using the standard splits (sections 1–18 for train, 19–21 for tuning and 22–24 for testing). We also perform tests on 4 other languages, which we obtained from the CoNLL shared tasks (Mart´ı et al., 2007; Brants et al., 2002; Afonso et al., 2002; Atalay et al., 2003). While the PTB dataset provides standard train, tuning and test splits, there are no tuning sets in the datasets in other languages, so we withdraw the last 100 sentences from the training dataset and use them for tuning. Setup The POS model requires two sets of hyperparameters. Firstly, words must be converted into continuous r"
D15-1176,D09-1078,0,0.0117625,"from neural approaches, characterbased models have been applied to address multiple lexically oriented tasks, such as transliteration (Kang and Choi, 2000) and twitter normalization (Xu et al., 2013; Ling et al., 2013). Compacting models has been a focus of research in tasks, such as language modeling and machine translation, as extremely large models can be built with the large amounts of training data that are available in these tasks. In language modeling, it is frequent to prune higher order ngrams that do not encode any additional information (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). The same be applied in machine translation (Ling et al., 2012; Zens et al., 2012) by removing longer translation pairs that can be replicated using smaller ones. In essence our model learns regularities at the subword level that can be leveraged for building more compact word representations. Finally, our work has been applied to dependency parsing and found similar improvements over word models in morphologically rich languages (Ballesteros et al., 2015). 7 Conclusion We propose a C2W model that builds word embeddings for words without an explicit word lookup table. Thus, it benefits from b"
D15-1176,D13-1176,0,0.0372417,"onclude in Section 7. 2 Word Vectors and Wordless Word Vectors It is commonplace to represent words as vectors. In contrast to na¨ıve models in which all word types in a vocabulary V are equally different from each other, vector space models capture the intuition that words may be different or similar along a variety of dimensions. Learning vector representations of words by treating them as optimizable parameters in various kinds of language models has been found to be a remarkably effective means for generating vector representations that perform well in other tasks (Collobert et al., 2011; Kalchbrenner and Blunsom, 2013; Liu et al., 2014; Chen and Manning, 2014). Formally, such models define a matrix P ∈ Rd×|V |, which contains d parameters for each word in the vocabulary V . For a given word type w ∈ V , a column is selected by right-multiplying P by a one-hot vector of length |V |, which we write 1w , that is zero in every dimension except for the element corresponding to w. Thus, P is often referred to as word lookup d table and we shall denote by eW w ∈ R the embedding obtained from a word lookup table for w as eW w = P · 1w . This allows tasks with low amounts of annotated data to be trained jointly wit"
D15-1176,kang-choi-2000-automatic,0,0.0359805,"tion according to the lexical model. Convolutional model are less susceptible to these problems as they combine windows of characters at each convolution, where the order within the window is preserved. However, the order between extracted windows is not, so the problem still persists for longer words, such as those found in agglutinative languages. Yet, these approaches work in conjunction with a word lookup table, as they compensate for this inability. Aside from neural approaches, characterbased models have been applied to address multiple lexically oriented tasks, such as transliteration (Kang and Choi, 2000) and twitter normalization (Xu et al., 2013; Ling et al., 2013). Compacting models has been a focus of research in tasks, such as language modeling and machine translation, as extremely large models can be built with the large amounts of training data that are available in these tasks. In language modeling, it is frequent to prune higher order ngrams that do not encode any additional information (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). The same be applied in machine translation (Ling et al., 2012; Zens et al., 2012) by removing longer translation pairs that can be r"
D15-1176,D15-1278,0,0.049515,"Missing"
D15-1176,D12-1088,1,0.613165,"Missing"
D15-1176,D13-1032,0,0.0412355,"Missing"
D15-1176,P11-2009,0,0.0797599,"Missing"
D15-1176,N15-1186,0,0.0289151,"se debate” between connectionists and proponents of symbolic accounts concerns disagreements about how humans represent knowledge of inflectional processes (e.g., the formation of the English past tense), not whether such knowledge exists (Marslen-Wilson and Tyler, 1998). 2.2 Solution: Compositional Models Our solution to these problems is to construct a vector representation of a word by composing smaller pieces into a representation of the larger form. This idea has been explored in prior work by composing morphemes into representations of words (Luong et al., 2013; Botha and Blunsom, 2014; Soricut and Och, 2015). Morphemes are an ideal primitive for such a model since they are— by definition—the minimal meaning-bearing (or syntax-bearing) units of language. The drawback to such approaches is they depend on a morphological analyzer. In contrast, we would like to compose representations of characters into representations of words. However, the relationship between words 1521 forms and their meanings is non-trivial (de Saussure, 1916). While some compositional relationships exist, e.g., morphological processes such as adding -ing or -ly to a stem have relatively regular effects, many words with lexical"
D15-1176,E09-1087,0,0.00853859,"Missing"
D15-1176,W13-2515,0,0.0187849,"al model are less susceptible to these problems as they combine windows of characters at each convolution, where the order within the window is preserved. However, the order between extracted windows is not, so the problem still persists for longer words, such as those found in agglutinative languages. Yet, these approaches work in conjunction with a word lookup table, as they compensate for this inability. Aside from neural approaches, characterbased models have been applied to address multiple lexically oriented tasks, such as transliteration (Kang and Choi, 2000) and twitter normalization (Xu et al., 2013; Ling et al., 2013). Compacting models has been a focus of research in tasks, such as language modeling and machine translation, as extremely large models can be built with the large amounts of training data that are available in these tasks. In language modeling, it is frequent to prune higher order ngrams that do not encode any additional information (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). The same be applied in machine translation (Ling et al., 2012; Zens et al., 2012) by removing longer translation pairs that can be replicated using smaller ones. In essence ou"
D15-1176,D12-1089,0,0.00506125,"xically oriented tasks, such as transliteration (Kang and Choi, 2000) and twitter normalization (Xu et al., 2013; Ling et al., 2013). Compacting models has been a focus of research in tasks, such as language modeling and machine translation, as extremely large models can be built with the large amounts of training data that are available in these tasks. In language modeling, it is frequent to prune higher order ngrams that do not encode any additional information (Seymore and Rosenfeld, 1996; Stolcke, 1998; Moore and Quirk, 2009). The same be applied in machine translation (Ling et al., 2012; Zens et al., 2012) by removing longer translation pairs that can be replicated using smaller ones. In essence our model learns regularities at the subword level that can be leveraged for building more compact word representations. Finally, our work has been applied to dependency parsing and found similar improvements over word models in morphologically rich languages (Ballesteros et al., 2015). 7 Conclusion We propose a C2W model that builds word embeddings for words without an explicit word lookup table. Thus, it benefits from being sensitive to lexical aspects within words, as it takes characters as atomic un"
D15-1176,D14-1179,0,\N,Missing
D15-1176,W03-2405,0,\N,Missing
D18-1076,W17-5526,0,0.0571829,"Missing"
D18-1076,W11-0609,0,0.127348,"Missing"
D18-1076,L16-1147,0,0.0264445,"where a specific task is the goal of the conversation (e.g. getting bus information or weather for a particular location); or non-task oriented where conversations are more for the sake of themselves, be it entertainment or passing the time. Ultimately, we want our agents to smoothly interleave between task-related information flow and casual chat for the given situation. There is a dire need of a dataset which caters to both these objectives. Serban et al. (2015) provide a comprehensive list of available datasets for building end-to-end conversational agents. Datasets based on movie scripts (Lison and Tiedemann, 2016; DanescuNiculescu-Mizil and Lee, 2011a) contain artificial conversations. The Ubuntu Dialogue Corpus (Lowe et al., 2015) is based on technical support logs from the Ubuntu forum. The Frames dataset 2 The Document Grounded Dataset To create a dataset for document grounded conversations, we seek the following things: (1) A set of documents (2) Two humans chatting about the content of the document for more than 12 turns. We collected conversations about the documents through Amazon Mechanical Turk (AMT). We restrict the topic of the documents to be movierelated articles to facilitate the convers"
D18-1076,W15-4640,0,0.0242913,"n-task oriented where conversations are more for the sake of themselves, be it entertainment or passing the time. Ultimately, we want our agents to smoothly interleave between task-related information flow and casual chat for the given situation. There is a dire need of a dataset which caters to both these objectives. Serban et al. (2015) provide a comprehensive list of available datasets for building end-to-end conversational agents. Datasets based on movie scripts (Lison and Tiedemann, 2016; DanescuNiculescu-Mizil and Lee, 2011a) contain artificial conversations. The Ubuntu Dialogue Corpus (Lowe et al., 2015) is based on technical support logs from the Ubuntu forum. The Frames dataset 2 The Document Grounded Dataset To create a dataset for document grounded conversations, we seek the following things: (1) A set of documents (2) Two humans chatting about the content of the document for more than 12 turns. We collected conversations about the documents through Amazon Mechanical Turk (AMT). We restrict the topic of the documents to be movierelated articles to facilitate the conversations. We initially experimented with different potential domains. Since movies are engaging and widely known, people ac"
D18-1076,D15-1166,0,0.0236595,"N ∩ M )  H)  S|. Let the tokens that appear in all the utterances (xi , . . . , xi+k ) corresponding to the current section si be K and the tokens that appear in all the utterances (xi , . . . , xi+p ) corresponding to the previous section si−1 be P . In scenario 2, we calculate the set operation (NW) as |((K ∩M )P )S|. The results in Table 6 show that people use the information in the new sections and are not fixated on old sections. It also shows that they use the information to construct the responses. t ˆ <t are the tokens generated before x where, x ˆt . We also use global attention (Luong et al., 2015) with copy mechanism (See et al., 2017) to guide our generators to replace the unknown (UNK) tokens. We call this model SEQ. With section: We extend the sequence-tosequence framework to include the section si corresponding the current turn. We use the same encoder to encode both the utterance and the section. We get the representation hxi of the current utterance xi using Eq. 1. The representation of the section is given by: hsi = Encoder(si ; θ E ) (3) The input at each time step t to the generative model is given by ht = [xt−1 ; hs ], where xt−1 is the embedding of the word at the previous t"
D18-1076,P02-1040,0,0.106386,"the statistics on the total number of conversations, utterances, and average number of utterances per conversation and average length of utterances for all the three ratings. One of the salient features of CMUDoG dataset is that it has mapping of the conversation turns to each section of the document, which can then be used to model conversation responses. Another useful aspect is that we report the quality of the conversations in terms of how much the conversation adheres to the information in the document. Split Criteria: We automatically measure the quality of the conversations using BLEU (Papineni et al., 2002) score. We use BLEU because we want to measure the overlap of the turns of the conversation with the sections of the document. Hence, a good quality conversation should use more information from the document than a low quality conversation. We divide our dataset into three ratings based on this measure. The BLEU score is calculated between all the utterances {x1 , . . . , xn } of a conversation Ci and the document di corresponding to Ci . We eliminate incomplete conversations that have less than 10 turns. The percentiles for the remaining conversations are shown in Table 5. We split the datase"
D18-1076,P18-1205,0,0.127649,"Missing"
D19-1500,D18-1241,0,0.173016,"ll privacy policies in this corpus are in English. 5 P RIVACY QA is freely available at https://github. com/AbhilashaRavichander/PrivacyQA_EMNLP. approach differs in several ways: 1) The P RIVA CY QA dataset is larger, containing 10x as many questions and answers. 2) Answers are formulated by domain experts with legal training. 6 3) P RIVACY QA includes diverse question types, including unanswerable and subjective questions. Our work is also related to reading comprehension in the open domain, which is frequently based upon Wikipedia passages (Rajpurkar et al., 2016, 2018; Joshi et al., 2017; Choi et al., 2018) and news articles (Trischler et al., 2017; Hermann et al., 2015; Onishi et al., 2016). Table.1 presents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. This arrangement is problematic because the ent"
D19-1500,N19-1423,0,0.0673743,"esence of answer and whether the question could be anticipated. the question as well as length of the question in words (SVM-BOW + LEN), and lastly we extract bag-of-words features, length of the question in words as well as part-of-speech tags for the question (SVM-BOW + LEN + POS). This results in vectors of 200, 201 and 228 dimensions respectively, which are provided to an SVM with a linear kernel. CNN: We utilize a CNN neural encoder for answerability prediction. We use GloVe word embeddings (Pennington et al., 2014), and a filter size of 5 with 64 filters to encode questions. BERT: BERT (Devlin et al., 2019) is a bidirectional transformer-based language-model (Vaswani et al., 2017).14 We fine-tune BERT-base on our binary answerability identification task with a learning rate of 2e-5 for 3 epochs, with a maximum sequence length of 128. 14 We utilize the HuggingFace implementtation available at https://github.com/huggingface/ pytorch-transformers 4952 4.2 Privacy Question Answering Our goal is to identify evidence within a privacy policy for questions asked by a user. This is framed as an answer sentence selection task, where models identify a set of evidence sentences from all candidate sentences"
D19-1500,N18-2017,0,0.0520149,"Missing"
D19-1500,P17-1147,0,0.023501,"privacy policy. 4 All privacy policies in this corpus are in English. 5 P RIVACY QA is freely available at https://github. com/AbhilashaRavichander/PrivacyQA_EMNLP. approach differs in several ways: 1) The P RIVA CY QA dataset is larger, containing 10x as many questions and answers. 2) Answers are formulated by domain experts with legal training. 6 3) P RIVACY QA includes diverse question types, including unanswerable and subjective questions. Our work is also related to reading comprehension in the open domain, which is frequently based upon Wikipedia passages (Rajpurkar et al., 2016, 2018; Joshi et al., 2017; Choi et al., 2018) and news articles (Trischler et al., 2017; Hermann et al., 2015; Onishi et al., 2016). Table.1 presents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. This arrangement is problem"
D19-1500,D18-1546,0,0.0266339,"uestions indicates if the respective corpus includes unanswerable questions. ‘Asker Cannot See Evidence’ indicates that the asker of the question was not shown evidence from the document at the time of formulating questions. 3.1 Crowdsourced Question Elicitation The intended audience for privacy policies consists of the general public. This informs the decision to elicit questions from crowdworkers on the contents of privacy policies. We choose not to show the contents of privacy policies to crowdworkers, a procedure motivated by a desire to avoid inadvertent biases (Weissenborn et al., 2017; Kaushik and Lipton, 2018; Poliak et al., 2018; Gururangan et al., 2018; Naik et al., 2018), and encourage crowdworkers to ask a variety of questions beyond only asking questions based on practices described in the document. Figure 2: User interface for question elicitation. of this threshold.9 All policies included in the corpus are in English, and were collected before April 1, 2018, predating many companies’ GDPRfocused (Voigt and Von dem Bussche, 2017) updates. We leave it to future studies (Gallé et al., 2019) to look at the impact of the GDPR (e.g., to what extent GDPR requirements contribute to making it possib"
D19-1500,Q18-1023,0,0.0599635,"Missing"
D19-1500,Q19-1026,0,0.0683129,"Missing"
D19-1500,J07-1004,0,0.0269601,"s, including unanswerable and subjective questions. Our work is also related to reading comprehension in the open domain, which is frequently based upon Wikipedia passages (Rajpurkar et al., 2016, 2018; Joshi et al., 2017; Choi et al., 2018) and news articles (Trischler et al., 2017; Hermann et al., 2015; Onishi et al., 2016). Table.1 presents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. This arrangement is problematic because the entities that write privacy policies often have different goals than the audience. Feng et al. (2015); Tan et al. (2016) examine question answering in the insurance domain, another specialized domain similar to privacy, where the intended audience is the general public. 3 Data Collection We describe the data collection methodology used to construct P RIVACY QA. With the goal of ach"
D19-1500,D17-1294,1,0.488783,"rmation-seeking intent. By releasing this resource, we hope to provide an impetus to develop systems capable of language understanding in this increasingly important domain.5 2 Related Work Prior work has aimed to make privacy policies easier to understand. Prescriptive approaches towards communicating privacy information (Kelley et al., 2009; Micheti et al., 2010; Cranor, 2003) have not been widely adopted by industry. Recently, there have been significant research effort devoted to understanding privacy policies by leveraging NLP techniques (?Liu et al., 2016; Oltramari et al., 2017; Mysore Sathyendra et al., 2017; Wilson et al., 2017), especially by identifying specific data practices within a privacy policy. We adopt a personalized approach to understanding privacy policies, that allows users to query a document and selectively explore content salient to them. Most similar is the PolisisQA corpus (Harkous et al., 2018), which examines questions users ask corporations on Twitter. Our 1 https://play.google.com/store/apps/ details?id=com.gotokeep.keep.intl 2 https://play.google.com/store/apps/ details?id=com.viber.voip 3 A question might not have any supporting evidence for an answer within the privacy"
D19-1500,C18-1198,1,0.873945,"Missing"
D19-1500,D16-1241,0,0.0170979,"at https://github. com/AbhilashaRavichander/PrivacyQA_EMNLP. approach differs in several ways: 1) The P RIVA CY QA dataset is larger, containing 10x as many questions and answers. 2) Answers are formulated by domain experts with legal training. 6 3) P RIVACY QA includes diverse question types, including unanswerable and subjective questions. Our work is also related to reading comprehension in the open domain, which is frequently based upon Wikipedia passages (Rajpurkar et al., 2016, 2018; Joshi et al., 2017; Choi et al., 2018) and news articles (Trischler et al., 2017; Hermann et al., 2015; Onishi et al., 2016). Table.1 presents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. This arrangement is problematic because the entities that write privacy policies often have different goals than the audience. Feng e"
D19-1500,D14-1162,0,0.0826626,"able. These answerable questions are further analyzed along the factors of scope, subjectivity, presence of answer and whether the question could be anticipated. the question as well as length of the question in words (SVM-BOW + LEN), and lastly we extract bag-of-words features, length of the question in words as well as part-of-speech tags for the question (SVM-BOW + LEN + POS). This results in vectors of 200, 201 and 228 dimensions respectively, which are provided to an SVM with a linear kernel. CNN: We utilize a CNN neural encoder for answerability prediction. We use GloVe word embeddings (Pennington et al., 2014), and a filter size of 5 with 64 filters to encode questions. BERT: BERT (Devlin et al., 2019) is a bidirectional transformer-based language-model (Vaswani et al., 2017).14 We fine-tune BERT-base on our binary answerability identification task with a learning rate of 2e-5 for 3 epochs, with a maximum sequence length of 128. 14 We utilize the HuggingFace implementtation available at https://github.com/huggingface/ pytorch-transformers 4952 4.2 Privacy Question Answering Our goal is to identify evidence within a privacy policy for questions asked by a user. This is framed as an answer sentence s"
D19-1500,S18-2023,0,0.0637063,"Missing"
D19-1500,P18-2124,0,0.0272484,"many of them were identified as subjective by the annotators, and at least one annotator marked 19 of these questions as having no answer within the privacy policy. However, only 6 of these questions were unexpected or do not usually have an answer in privacy policies. These findings suggest that a more nuanced understanding of answerability might help improve model performance in his challenging domain. 5.2 What makes Questions Unanswerable? We further ask legal experts to identify potential causes of unanswerability of questions. This analysis has considerable implications. While past work (Rajpurkar et al., 2018) has treated unanswerable questions as homogeneous, a question answering system might wish to have different treatments for different categories of ‘unanswerable’ questions. The following factors were identified to play a role in unanswerability: • Incomprehensibility: If a question is incomprehensible to the extent that its meaning is not intelligible. • Relevance: Is this question in the scope of what could be answered by reading the privacy policy. • Ill-formedness: Is this question ambiguous or vague. An ambiguous statement will typically contain expressions that can refer to multiple pote"
D19-1500,D16-1264,0,0.417453,"dence for an answer within the privacy policy. 4 All privacy policies in this corpus are in English. 5 P RIVACY QA is freely available at https://github. com/AbhilashaRavichander/PrivacyQA_EMNLP. approach differs in several ways: 1) The P RIVA CY QA dataset is larger, containing 10x as many questions and answers. 2) Answers are formulated by domain experts with legal training. 6 3) P RIVACY QA includes diverse question types, including unanswerable and subjective questions. Our work is also related to reading comprehension in the open domain, which is frequently based upon Wikipedia passages (Rajpurkar et al., 2016, 2018; Joshi et al., 2017; Choi et al., 2018) and news articles (Trischler et al., 2017; Hermann et al., 2015; Onishi et al., 2016). Table.1 presents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. T"
D19-1500,D13-1020,0,0.0285528,"Missing"
D19-1500,P16-1044,0,0.0211813,"ents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. This arrangement is problematic because the entities that write privacy policies often have different goals than the audience. Feng et al. (2015); Tan et al. (2016) examine question answering in the insurance domain, another specialized domain similar to privacy, where the intended audience is the general public. 3 Data Collection We describe the data collection methodology used to construct P RIVACY QA. With the goal of achieving broad coverage across application types, we collect privacy policies from 35 mobile applications representing a number of different categories in the Google Play Store.78 One of our goals is to include both policies from well-known applications, which are likely to have carefully-constructed privacy policies, and lesser-known a"
D19-1500,W17-2623,0,0.0268948,"in English. 5 P RIVACY QA is freely available at https://github. com/AbhilashaRavichander/PrivacyQA_EMNLP. approach differs in several ways: 1) The P RIVA CY QA dataset is larger, containing 10x as many questions and answers. 2) Answers are formulated by domain experts with legal training. 6 3) P RIVACY QA includes diverse question types, including unanswerable and subjective questions. Our work is also related to reading comprehension in the open domain, which is frequently based upon Wikipedia passages (Rajpurkar et al., 2016, 2018; Joshi et al., 2017; Choi et al., 2018) and news articles (Trischler et al., 2017; Hermann et al., 2015; Onishi et al., 2016). Table.1 presents the desirable attributes our dataset shares with past approaches. This work is also tied into research in applying NLP approaches to legal documents (Monroy et al., 2009; Quaresma and Rodrigues, 2005; Do et al., 2017; Kim et al., 2015; Liu et al., 2015; Mollá and Vicedo, 2007; Frank et al., 2007). While privacy policies have legal implications, their intended audience consists of the general public rather than individuals with legal expertise. This arrangement is problematic because the entities that write privacy policies often ha"
D19-1500,K17-1028,0,0.0205704,"ion metric. Unanswerable questions indicates if the respective corpus includes unanswerable questions. ‘Asker Cannot See Evidence’ indicates that the asker of the question was not shown evidence from the document at the time of formulating questions. 3.1 Crowdsourced Question Elicitation The intended audience for privacy policies consists of the general public. This informs the decision to elicit questions from crowdworkers on the contents of privacy policies. We choose not to show the contents of privacy policies to crowdworkers, a procedure motivated by a desire to avoid inadvertent biases (Weissenborn et al., 2017; Kaushik and Lipton, 2018; Poliak et al., 2018; Gururangan et al., 2018; Naik et al., 2018), and encourage crowdworkers to ask a variety of questions beyond only asking questions based on practices described in the document. Figure 2: User interface for question elicitation. of this threshold.9 All policies included in the corpus are in English, and were collected before April 1, 2018, predating many companies’ GDPRfocused (Voigt and Von dem Bussche, 2017) updates. We leave it to future studies (Gallé et al., 2019) to look at the impact of the GDPR (e.g., to what extent GDPR requirements cont"
D19-1500,D15-1237,0,0.131625,"Missing"
D19-5502,P17-4012,0,0.0125438,"ess direct) across different languages. Han et al. (2017) presented a Seq2Seq model that uses two switches with tensor product to control the style transfer in the encoding and decoding processes. Fu et al. (2018) proposed adversarial networks for the task of textual style transfer. Yang et al. (2018) presented a new technique that uses a target domain language model as the discriminator to improve training. Our method is modular with respect to the main Seq2Seq neural model, so it can more easily leverage state-of-theart (Merity et al., 2017) new models, e.g. most recent versions of OpenNMT (Klein et al., 2017). Shen et al. (2017) proposed a model that assumes a shared latent content distribution across different text corpora, and leverages refined alignment of latent representations to perform style transfer. Our method does not assume such shared latent content distribution across different corpora. We instead leverage shared latent content distribution across different styles of a same corpus. Zhang et al. (2018) presented a Seq2Seq model architecture using shared and private model parameters to better train a model from multiple corpora of different domains. Our method is modular with respect to"
D19-5502,N18-1169,0,0.0573661,"Missing"
D19-5502,P18-1080,1,0.899568,"Missing"
D19-5502,N18-1012,0,0.286101,"n-Domain Training via POS Masking Isak Czeresnia Etinger Alan W. Black Language Technologies Institute Carnegie Mellon University {ice,awb}@cs.cmu.edu Abstract an available dataset of parallel data with vocabulary and structure similar to the one requested. This is especially significant for style transfer with noisy/user-generated text, where a mismatch is common even when the training dataset is also noisy/user-generated. We explore formality transfer specifically for noisy/user-generated text. To the best of our knowledge, the best dataset for this is currently the Yahoo Formality Dataset (Rao and Tetreault, 2018). However, this dataset is limited to few domains and to the context of Yahoo answers instead of other websites or in-person chat. To overcome this problem, we propose a technique to derive a dataset of aligned pairs from an unlabeled corpus by using an auxiliary dataset; and we apply this technique to the task of formality transfer on noisy/user-generated conversations. Typical datasets used for style transfer in NLP contain aligned pairs of two opposite extremes of a style. As each existing dataset is sourced from a specific domain and context, most use cases will have a sizable mismatch fro"
D19-5502,W17-4901,0,0.015007,"tic one. This can be done by one of 3 ways (Tikhonov and Yamshchikov, 2018): employing back-translation; training a stylistic discriminator; or embedding words or sentences and segmenting embedding state-space into semantic and stylistic sections. Our method differs from those works in many aspects. Artetxe et al. (2017) worked on unsupervised machine translation. It differs from our objective Introduction Typical datasets used for style transfer in NLP contain aligned pairs of two opposite extremes of a style (Hughes et al., 2012; Xu et al., 2012; Jhamtani et al., 2017; Carlson et al., 2017; Xu, 2017; Rao and Tetreault, 2018). Those datasets are useful for training neural networks that perform style transfer on text that is similar (both in vocabulary and structure) to the text in the datasets. However, as each of those datasets is sourced from a specific domain and context, in most use cases there is not 1 https:/github.com/ICEtinger/ StyleTransfer 11 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 11–16 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics fixes the encoder and decoder in order to employ the back-tran"
D19-5502,C12-1177,0,0.0344501,"hange the stylistic representation while maintaining the semantic one. This can be done by one of 3 ways (Tikhonov and Yamshchikov, 2018): employing back-translation; training a stylistic discriminator; or embedding words or sentences and segmenting embedding state-space into semantic and stylistic sections. Our method differs from those works in many aspects. Artetxe et al. (2017) worked on unsupervised machine translation. It differs from our objective Introduction Typical datasets used for style transfer in NLP contain aligned pairs of two opposite extremes of a style (Hughes et al., 2012; Xu et al., 2012; Jhamtani et al., 2017; Carlson et al., 2017; Xu, 2017; Rao and Tetreault, 2018). Those datasets are useful for training neural networks that perform style transfer on text that is similar (both in vocabulary and structure) to the text in the datasets. However, as each of those datasets is sourced from a specific domain and context, in most use cases there is not 1 https:/github.com/ICEtinger/ StyleTransfer 11 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 11–16 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics fixes t"
D19-5502,N18-1138,0,0.0295627,"ur method is modular with respect to the main Seq2Seq neural model, so it can more easily leverage state-of-theart (Merity et al., 2017) new models, e.g. most recent versions of OpenNMT (Klein et al., 2017). Shen et al. (2017) proposed a model that assumes a shared latent content distribution across different text corpora, and leverages refined alignment of latent representations to perform style transfer. Our method does not assume such shared latent content distribution across different corpora. We instead leverage shared latent content distribution across different styles of a same corpus. Zhang et al. (2018) presented a Seq2Seq model architecture using shared and private model parameters to better train a model from multiple corpora of different domains. Our method is modular with respect to the main Seq2Seq neural model, and is trained with a single corpus each time. Li et al. (2018) proposed a method that uses retrieval of training sentences (after a deletion operation) during inference time to improve sentence generation. Our method uses a similar inspiration of selecting the “deleted” terms, but instead of being deleted, they are replaced by a latent shared representation of syntactic structu"
D19-5527,S18-1001,0,0.0405227,"Missing"
D19-5527,E14-3007,0,0.0228076,"ng things opposite to what is meant (McQuarrie and Mick, 1996; Curcó, 2007). Many studies have diverse opinions regarding sarcasm and irony being different phenomenon (Sperber and Wilson, 1981; Grice, 1978, 1975) or being the same (Reyes et al., 2013; Attardo et al., 2003). In this work, we do not make a distinction between sarcasm and irony. Previous work on irony detection relied on hand-crafted features such as punctuation and smiles (Veale and Hao, 2010) or lexical features, such as gap between rare and common words, intensity of adverbs and adjectives, sentiments, and sentence structure (Barbieri and Saggion, 2014). More recently, Van Hee et al. (2016) explore constructions of verbal irony in social media texts, reporting that detection of contrasting polarities is a strong indicator and use sentiment analysis ∗ equal contributions https://expandedramblings.com/index.php/interestingemoji-statistics/ 1 212 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 212–216 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics Train All # Tweets # Tweets containing emoji # Unique emojis Test # Tweets # Tweets containing emoji # Unique emojis 3817 4"
D19-5527,N18-1202,0,0.0291291,"gorithms such as SVMs informed with sentiment features have shown good performance gains in irony detection (Van Hee, 2017, 2018). Some neural network-based methods have been conducted. LSTM has proven to be successful for predicting irony. Wu et al. (2018), that ranks first for SemEval 2018: Shared Task on Irony in English Tweets Task A, utilizes multitask-learning dense LSTM network. The second-ranked participants, Baziotis et al. (2017), uses bidirectional LSTM (biLSTM) and self-attention mechanism layer. Ili´c et al. (2018)’s architecture is based on Embeddings from Language Model (ELMo) (Peters et al., 2018) and passes the contextualized embeddings to a biLSTM. Ili´c et al. (2018)’s model becomes the state of the art for sarcasm and irony detection in 6 out of 7 datasets from 3 different data sources (Twitter, dialog, Reddit). 3 3.1 3.2 Manual Data Augmentation To further analyze the role of emoji in ironic expressions, we conduct qualitative analysis while controlling the effect of the text content. Concretely, we generate ironic and non-ironic texts by manipulating emoji without changing the texts. The resulting texts give us an insight about emoji use and can also be used as an evaluation reso"
D19-5527,S17-2126,0,0.179371,"neration pipeline. Table 2: Top 10 most frequent emojis in ironic tweets and non-ironic tweets along with the count and percentage of each emoji. for the same. Machine learning algorithms such as SVMs informed with sentiment features have shown good performance gains in irony detection (Van Hee, 2017, 2018). Some neural network-based methods have been conducted. LSTM has proven to be successful for predicting irony. Wu et al. (2018), that ranks first for SemEval 2018: Shared Task on Irony in English Tweets Task A, utilizes multitask-learning dense LSTM network. The second-ranked participants, Baziotis et al. (2017), uses bidirectional LSTM (biLSTM) and self-attention mechanism layer. Ili´c et al. (2018)’s architecture is based on Embeddings from Language Model (ELMo) (Peters et al., 2018) and passes the contextualized embeddings to a biLSTM. Ili´c et al. (2018)’s model becomes the state of the art for sarcasm and irony detection in 6 out of 7 datasets from 3 different data sources (Twitter, dialog, Reddit). 3 3.1 3.2 Manual Data Augmentation To further analyze the role of emoji in ironic expressions, we conduct qualitative analysis while controlling the effect of the text content. Concretely, we generat"
D19-5527,L16-1283,0,0.0698982,"Missing"
D19-5527,D17-1169,0,0.165619,"Missing"
D19-5527,S18-1005,0,0.0304551,"Missing"
D19-5527,S15-2080,0,0.0242285,"rate accurate ironic/nonironic tweets. 4 0.8 0.6 0.4 0.2 0.0 Rec F1 Acc Prec Emoji only Rec F1 are initialized with 300D pre-trained word embeddings, word2vec model trained on tweets for English ((Baziotis et al., 2017)). 4.3 Result We train the model on our augmented data and test it on the Imoji dataset as shown in Figure 1. To make sure that the performance change by our augmented data (Ours) is not only from the increased number of training instances, we also collect the same number of ironic detection instances as the generated instances from another dataset containing irony annotations (Ghosh et al., 2015). Interestingly, the classifier trained on our augmented dataset achieve much higher recall. Preprocessing 5 Conclusion In this work, we presented an automatic pipeline for generating ironic data using sentiment analysis. We observe that our method works well for the irony based on polarity contrast. In summary, the experimental results show our augmented data helped classifiers improve their sensitivity to emojis in irony detection tasks without damaging the overall performance of irony detection on the whole datasets. An interesting future direction is to apply our method to multilingual iro"
D19-5527,S18-1006,0,0.0360183,"Missing"
D19-5527,W18-6202,0,0.028278,"Missing"
D19-6121,L18-1429,0,0.0256989,"d: [AE n d @ s E k @ n d] 100.00 20.00 Total Scores 50.00 10.00 Example #1: ‘An example’ Train Dev ID Test OoD Test Verses Words Length (min) 10,000 1,000 1,000 1,000 139,796 13,937 13,815 15,418 1060 106 104 107 Predicted: [@ n I g z AE m p @ l] Gold: [@ n I g z AE m p @ l] Example #2: ‘And a second’ Table 3: Statistics for Wilderness-based corpus Table 4: Examples for SER and PER calculations 194 and SER are functionally identical for Wiktionary, which comprises single-word grapheme-phoneme pairs. We note that other multilingual g2p systems exist, such as Deri and Knight (2016) and Epitran (Mortensen et al., 2018), although we do not include these systems in the results. The Peters et al. (2017) model previously outperformed the Deri and Knight (2016) system on Wiktionary by a significant margin, and Epitran is a rule-based system that does not support the vast majority of the low-resource languages we use. ficients from graphemes (auxiliary task) and the other predicts IPA character sequences (primary task). Each task corresponds to a separate loss function. During training, three sequences are available to the model: grapheme characters Xt , speech MFCCs St , and phoneme characters Yt . The encoder i"
D19-6121,P16-1038,0,0.305224,"ystems were monolingual and often restricted to English due to dataset availability (Weide, 1998; Kingsbury et al., 1997; Sejnowski, 1987). These early systems were designed to address the problem of intra-language discrepancies through rule based transition systems. These systems required painstaking tailoring to individual languages, and their performance was largely limited to that language’s domain. Recent work has extended finite state automata constructed in this way for high resource languages to very similar low resource languages by applying distance metrics and linguistic expertise (Deri and Knight, 2016), but this approach is limited in application and performance. Relieving some of the burden of technical expertise, statistical methods surpassed rule-based ones, with emphasis on joint sequence modeling (Chen, 2003; Bisani and Ney, 2008; Jiampojamarn et al., 2007). These methods improved performance, but they mandate explicit training alignments. This can be avoided by using neural attentional models, as in Toshniwal and Livescu (2016). Their work makes clear the parallel between this sequence prediction task and more traditional machine translation; this parallel inspires the model proposed"
D19-6121,W17-5403,0,0.368118,"Missing"
D19-6121,W18-3308,0,0.0203999,"nsion MFCC vector Sˆt . Multimodal Approach Multimodal models have been frequently explored for feature mining (e.g., text, image, audio). Multimodal learning commonly focuses on three areas: fusion of information, cross-modality learning, and shared representation mining (Ngiam et al., 2011). A deep multimodal learning method for automatic speech recognition was designed (Mroueh et al., 2015) to fuse both audio and visual modalities. In this case, the latent audio and video features were concatenated and used jointly for the prediction of speech. Recent work on multimodal sentiment analysis (Pham et al. (2018b) and Pham et al. (2018a)) demonstrated that an auxiliary task of translating from a source to one or more target modalities results in a joint representation that captures interactions between the modalities. We base our model on this approach and apply it to a sequence prediction task on multilingual data. We develop a recurrent sequence-to-sequence model with attention that learns a robust joint representation for graphemes and speech data across multiple languages, which is then used to predict a phoneme sequence given only graphemes3 . We hypothesize that the inclusion of the speech moda"
D19-6121,N07-1047,0,0.0924546,"Missing"
D19-6121,P17-4012,0,0.0331103,"es, as well as expansions of the abbreviations, see Table 9 at the end of the paper. In-Domain Multilingual neural machine translation techniques have recently been applied to the g2p problem (Peters et al., 2017) to accommodate the lack of data for low-resource languages. With many low-resource languages sharing similar writing systems with high-resource languages, orthographic representations of words in any language are mapped to the corresponding phonemic representations in a multisource sequence-to-sequence model. We reproduce their architecture as our performance baseline using OpenNMT (Klein et al., 2017) on the Wiktionary and Wilderness datasets. Briefly, the source graphemes (augmented with language tags) and target phonemes are first processed as character-based embedding sequences. The model uses an encoder-decoder structure and the global attention layer proposed by Luong et al. (2015). We selected this model because it achieved state-of-the-art results on Wiktionary and represents a strong baseline for sequence-tosequence model performance on g2p. Two common evaluation metrics for g2p models are Phoneme Error Rate (PER) and Word Error Rate (WER). Phoneme Error Rate represents the Levensh"
D19-6121,D15-1166,0,0.0943234,"ource languages sharing similar writing systems with high-resource languages, orthographic representations of words in any language are mapped to the corresponding phonemic representations in a multisource sequence-to-sequence model. We reproduce their architecture as our performance baseline using OpenNMT (Klein et al., 2017) on the Wiktionary and Wilderness datasets. Briefly, the source graphemes (augmented with language tags) and target phonemes are first processed as character-based embedding sequences. The model uses an encoder-decoder structure and the global attention layer proposed by Luong et al. (2015). We selected this model because it achieved state-of-the-art results on Wiktionary and represents a strong baseline for sequence-tosequence model performance on g2p. Two common evaluation metrics for g2p models are Phoneme Error Rate (PER) and Word Error Rate (WER). Phoneme Error Rate represents the Levenshtein distance over the target and predicted phonemes, normalized by the target sequence length. Word Error Rate represents the percentage of predicted phoneme words which do not exactly match their target phoneme words. For our experiments, we extend the concept of Word Error Rate to a metr"
D19-6302,de-marneffe-etal-2014-universal,0,0.0340041,"Missing"
D19-6302,N19-1423,0,0.00927617,"e non-projective trees, one may want to use a linearization algorithm alternative to TreeLinearize that generates the whole sequence based on the topological order of nodes returned by TreeSort. At each step, the choices of nodes should be limited to those that are not preceded by any unselected nodes with higher topological order. 3.4 Morphology The MSR challenge requires realizaton of lemmatized words. Since this is not the main focus of our paper, we briefly describe our approach here. After the words are ordered into sentences in the first stage described above, we obtain BERT embeddings (Devlin et al., 2019) of each word. We train a character-level sequence-to-sequence model with attention for morphological inflection, where the source is the lemmatized word and the target is the realization. The BERT embedding is used for constructing the initial state of the decoder, so that the morphology model may use contextual information. The concatenation of decoder hidden states and embeddings of syntactic information such as tense and number is used for predicting characters. To see why tree decoding is advantageous over ordering the whole sequence at a time, consider the size of the search space of bot"
D19-6302,N19-1377,1,0.837412,"our framework on a downstream task – surface realization – that has many impactful applications. We believe our approach is applicable to other problem domains. 2 Graph structures are ubiquitous in representations of natural language. Despite the success of sequence-to-sequence learning for language generation (especially machine translation), NLP researchers have started to pay a substantial amount of efforts into incorporating tree structures into neural language generation in the recent years. Application domains include machine translation (Wang et al., 2018), dialog response generation (Du and Black, 2019), and document summarization (Liu et al., 2019). Tree-based language generation models typically sequentialize the parse tree of sentences by some pre-defined traversal order, and generate the tree node in an autoregressive manner. The most common traversal orders are depth-first, left-to-right (pre-order) and breadthfirst, left-to-right (level-order). Related Work We survey the work related to our approach from the following three aspects: deep learning for combinatorial optimization, deep learning for graphs, and structured language generation. 2.1 Neural Combinatorial Optimization Most sequ"
D19-6302,P17-2021,0,0.0156153,"in the recent years, and deep learning has achieved success in graph-related tasks such as classification (Kipf and Welling, 2017) and generation (You et al., 2018). Graph neural networks generally follow a recursive neighborhood aggregation scheme, where the embedding of each node is computed with the embeddings of its neighbors and itself. After k iterations, the embedding contains the information of its k-hop neighborhood in the graph. Besides graph representation learning, extensive research has been conducted on the transduction between sequences and graphs, including sequence-to-graph (Aharoni and Goldberg, 2017), graph-to-sequence (Beck et al., 2018), and graph-to-graph (Sun and Li, 2019) learning problems. hi0 = X Ea(vi ) a where E is the embedding matrix of attributes. For each node i, the importance of neighbor j is computed with the scaled inner product of projected features of i and j and normalized by soft19 (a) (b) (c) Figure 1: The order of visits for sentence ”Both of my dogs like eating sausages.” in our decoding algorithm. The nodes being considered for ordering are highlighted with red. Since dependency graphs are directed, it might be natural to perform unilateral attention (i.e. the par"
D19-6302,N19-1173,0,0.0235361,"lization – that has many impactful applications. We believe our approach is applicable to other problem domains. 2 Graph structures are ubiquitous in representations of natural language. Despite the success of sequence-to-sequence learning for language generation (especially machine translation), NLP researchers have started to pay a substantial amount of efforts into incorporating tree structures into neural language generation in the recent years. Application domains include machine translation (Wang et al., 2018), dialog response generation (Du and Black, 2019), and document summarization (Liu et al., 2019). Tree-based language generation models typically sequentialize the parse tree of sentences by some pre-defined traversal order, and generate the tree node in an autoregressive manner. The most common traversal orders are depth-first, left-to-right (pre-order) and breadthfirst, left-to-right (level-order). Related Work We survey the work related to our approach from the following three aspects: deep learning for combinatorial optimization, deep learning for graphs, and structured language generation. 2.1 Neural Combinatorial Optimization Most sequence-to-sequence models only handles outputs of"
D19-6302,P18-1026,0,0.0236976,"eved success in graph-related tasks such as classification (Kipf and Welling, 2017) and generation (You et al., 2018). Graph neural networks generally follow a recursive neighborhood aggregation scheme, where the embedding of each node is computed with the embeddings of its neighbors and itself. After k iterations, the embedding contains the information of its k-hop neighborhood in the graph. Besides graph representation learning, extensive research has been conducted on the transduction between sequences and graphs, including sequence-to-graph (Aharoni and Goldberg, 2017), graph-to-sequence (Beck et al., 2018), and graph-to-graph (Sun and Li, 2019) learning problems. hi0 = X Ea(vi ) a where E is the embedding matrix of attributes. For each node i, the importance of neighbor j is computed with the scaled inner product of projected features of i and j and normalized by soft19 (a) (b) (c) Figure 1: The order of visits for sentence ”Both of my dogs like eating sausages.” in our decoding algorithm. The nodes being considered for ordering are highlighted with red. Since dependency graphs are directed, it might be natural to perform unilateral attention (i.e. the parent uses the information of its childre"
D19-6302,D19-6301,0,0.0742573,"tworks, or parse trees in natural language processing (NLP). There has been a surging interest in modelling graphs with deep neural networks in the last few years. Unlike traditional spectral approaches that work with the spectral representations of graphs (Belkin and Niyogi, 2002), deep learning has the flexibility that it provides end-to-end solutions to much more complex problems such as graph generation and transduction. Surface realization is a natural language generation task in which sentences are generated given input meanings. In particular, the Multilingual Surface Realization Task (Mille et al., 2019) derived inputs from universal dependency (UD) treebank (De Marneffe et al., 2014), a framework that aims to facilitate cross-lingually consistent grammatical annotations. The task consists of two tracks. The shallow track starts from UDs with word order information removed and words are lemmatized. The task consists in determining the word order and inflecting the words. The deep track further removes function words that are leaves in the dependency structures, and the task additionally consists in introducing removed function words. In this paper, we are interested in the scenario where the"
D19-6302,W18-6527,0,0.0986065,"al in the number of vertices (i.e. |V |!). In graph decoding, at each node v, the number of nodes to be ordered is the degree of v, d(v) (since the nodes to be ordered include v but not parent of v). In the example shown above, the total number of permutations of the sentence is 7! = 5040, while with tree decoding, the number of ordering to be considered reduced to (3!)3 = 216. The difference is even larger when there are more words in the sentence. So tree decoding gains performance by reducing the size of search space. 4 4.1 Experiments Data and Preprocessing We use SR&apos;19 challenge dataset (Mille et al., 2018). The data is obtained from the universal dependency treebank (Zeman et al., 2018). The dataset includes many major languages, such as English, Spanish, and Chinese. Word orders are hidden and words are randomly shuffled. Our model uses the following attributes for graph atThe full model is trained by maximizing the likelihood of choices of indices. We apply candidate masking, i.e. the candidates that are already selected in previous steps are assigned zero probability. 21 Table 1: Average performance on English dataset (dev) of shallow track with different hyperparameters. All results are eva"
D19-6302,D18-1509,0,0.0221078,"dering graph elements. Furthermore, we evaluated our framework on a downstream task – surface realization – that has many impactful applications. We believe our approach is applicable to other problem domains. 2 Graph structures are ubiquitous in representations of natural language. Despite the success of sequence-to-sequence learning for language generation (especially machine translation), NLP researchers have started to pay a substantial amount of efforts into incorporating tree structures into neural language generation in the recent years. Application domains include machine translation (Wang et al., 2018), dialog response generation (Du and Black, 2019), and document summarization (Liu et al., 2019). Tree-based language generation models typically sequentialize the parse tree of sentences by some pre-defined traversal order, and generate the tree node in an autoregressive manner. The most common traversal orders are depth-first, left-to-right (pre-order) and breadthfirst, left-to-right (level-order). Related Work We survey the work related to our approach from the following three aspects: deep learning for combinatorial optimization, deep learning for graphs, and structured language generation"
D19-6302,K18-2001,0,0.0620389,"Missing"
E87-1003,C86-1066,0,0.0851399,"Missing"
E87-1003,J87-3008,1,\N,Missing
E87-1003,P86-1009,0,\N,Missing
E91-1018,P84-1038,0,0.0301342,"work described below attempts to carry out. The Alvey Natural Language Tools Morphological System ([5],[6]), already provides a comprehensive morphological analyser system. This system allows morphological analysis of words into morphemes based on user-defined rules. The basic system does not offer analysis of words containing unknown morphemes, nor does it provide a rank ordering of the output analyses. Both these latter features have been added in the work described below. The system consists of a two tier process: first a morphological analysis, based on Koskenniemi's two-level morphology ([3]); secondly the statement of morphosyntactic constraints (not available in Koskenniemi's system) based on a GPSG-like feature grammar. The morphographemic rules are specified as a set of high level rules (rather than directly as finite state transducers) which describe the - +:e <==&gt; { < s : s h : h &gt; s : s x:x z : z y : i } - - - S:a specifies that a surface character e must match with a lexicalcharacter + when preceded by one of sh, s, x, z or the pair y:i (as in skies to sky+s), and succeeded by s. The &quot;---~ denotes where the rule pair fitsinto the context. For example the above rule would"
E91-1018,J87-3008,1,0.838174,"erial. For example, without morphological analysis, penthouse may be wrongly pronounced as / p e n t h au s / , with a voiceless dental fricative. It is known that letter-to-sound rules are more accurate if they are not allowed to apply across morpheme boundaries (see [1, Ch. 6]), and this method takes advantage of that fact. Thus greater accuracy is obtained, for polymorphemic unknown words, if known morphs can be stripped before the application of letter-tosound rules. It is this task that the work described below attempts to carry out. The Alvey Natural Language Tools Morphological System ([5],[6]), already provides a comprehensive morphological analyser system. This system allows morphological analysis of words into morphemes based on user-defined rules. The basic system does not offer analysis of words containing unknown morphemes, nor does it provide a rank ordering of the output analyses. Both these latter features have been added in the work described below. The system consists of a two tier process: first a morphological analysis, based on Koskenniemi's two-level morphology ([3]); secondly the statement of morphosyntactic constraints (not available in Koskenniemi's system) ba"
E91-1018,J92-1003,0,\N,Missing
E91-1018,W83-0114,0,\N,Missing
font-llitjos-black-2002-evaluation,J96-2004,0,\N,Missing
frederking-etal-2002-field,A94-1016,1,\N,Missing
frederking-etal-2002-field,C96-1030,1,\N,Missing
georgila-etal-2012-practical,W10-4318,1,\N,Missing
I11-1006,2005.iwslt-1.8,0,0.117751,"are small, but per2 Lexicalized Reordering models In this section we will present the lexicalized reordering models approaches that are relevant for this work. 47 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 47–55, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP 2.1 Word-based Reordering prev word(s) The lexicalized reordering model is possibly the most used lexicalized reordering model and it calculates, as features, the reordering orientation for the previous and the next word, for each phrase pair. In the word-based reordering model (Axelrod et al., 2005), during the phrase extraction, given a source sentence S and a target sentence T , the alignment set A, where aji is an alignment from i to j, the phrase pair with words in positions between i and j in S, Sij , and n and m in T , Tnm , can be classified with one of three orientations with respect to the previous word. The orientation is a) source phrase next word(s) target phrase n−1 n−1 • Pc (p, S) = Wj+1 (1 − Wi−1 ) n−1 n−1 • Pc (p, D) = Wi−1 Wj+1 n−1 n−1 + (1 − Wi−1 )(1 − Wj+1 ) (1) 2.3 Phrase-based Reordering The problem with the word-based lexicalized reordering model is that it is assum"
I11-1006,P08-1115,0,0.0496024,"Missing"
I11-1006,D08-1089,0,0.366999,"gnment (Venugopal et al., 2009; Mi et al., 2008; Christopher Dyer et al., 2008). More recently, a more efficient representation of multiple alignments was proposed in (Liu et al., 2009) named weighted alignment matrices, which represents the alignment probability distribution over the words of each parallel sentence. The method for building a word-based lexicalized reordering model using these matrices is proposed in (Ling et al., 2011). However, phrase-based reordering models have been shown to perform better than word-based models for several language pairs (Tillmann, 2004; Su et al., 2010; Galley and Manning, 2008), such as Chinese-English and Arabic-English. Lexicalized reordering models play a central role in phrase-based statistical machine translation systems. Starting from the distance-based reordering model, improvements have been made by considering adjacent words in word-based models, adjacent phrases pairs in phrasebased models, and finally, all phrases pairs in a sentence pair in the reordering graphs. However, reordering graphs treat all phrase pairs equally and fail to weight the relationships between phrase pairs. In this work, we propose an extension to the reordering models, named weighte"
I11-1006,D09-1106,0,0.0357024,"Missing"
I11-1006,P08-1023,0,0.0619174,"Missing"
I11-1006,2010.iwslt-evaluation.1,0,0.0498423,"Missing"
I11-1006,P10-2003,0,0.193049,"Missing"
I11-1006,N04-4026,0,0.553008,"heses, rather than the 1-best alignment (Venugopal et al., 2009; Mi et al., 2008; Christopher Dyer et al., 2008). More recently, a more efficient representation of multiple alignments was proposed in (Liu et al., 2009) named weighted alignment matrices, which represents the alignment probability distribution over the words of each parallel sentence. The method for building a word-based lexicalized reordering model using these matrices is proposed in (Ling et al., 2011). However, phrase-based reordering models have been shown to perform better than word-based models for several language pairs (Tillmann, 2004; Su et al., 2010; Galley and Manning, 2008), such as Chinese-English and Arabic-English. Lexicalized reordering models play a central role in phrase-based statistical machine translation systems. Starting from the distance-based reordering model, improvements have been made by considering adjacent words in word-based models, adjacent phrases pairs in phrasebased models, and finally, all phrases pairs in a sentence pair in the reordering graphs. However, reordering graphs treat all phrase pairs equally and fail to weight the relationships between phrase pairs. In this work, we propose an exten"
I11-1006,J10-3007,1,0.878594,"Missing"
I11-1006,N03-1017,0,\N,Missing
I11-1006,P11-2079,1,\N,Missing
I11-1006,2010.iwslt-papers.14,1,\N,Missing
I11-1006,2008.amta-papers.18,0,\N,Missing
J16-2005,W10-0710,0,0.108835,"lations within the same document, has some similarities with our work, since parenthetical translations are within the same document. However, parenthetical translations are generally used to translate names or terms, which is more limited than our work targeting the extraction of whole sentence translations. More recently, a similar method for extracting parallel data from multilingual Facebook posts was proposed (Eck et al. 2014). 312 Ling et al. Mining Parallel Corpora from Sina Weibo and Twitter Finally, crowdsourcing techniques can be used to obtain translations of text from new domains (Ambati and Vogel 2010; Zaidan and Callison-Burch 2011; Ambati, Vogel, and Carbonell 2012; Post, Callison-Burch, and Osborne 2012). These approaches require compensating workers for their efforts, and the workers themselves must be generally proficient in two languages, making the technique quite expensive. Previous work has relied on employing workers to translate segments. Crowdsourcing methods must also address the need for quality control. Thus, in order to find good translations, subsequent post-editing and/or ranking is generally necessary. 3. The Intra-Document Alignment (IDA) Model As discussed above, conte"
J16-2005,W12-2108,0,0.0274338,"weets in the pair are translations. In our work, single tweets are considered, and the problem is to determine whether the tweet contains translations and, if so, which spans are parallel. Efficient multilingual document detection - Parallel tweets are a relative rarity, but because of the volumes of data involved, we can find a large amount of content. We must efficiently detect multilingual tweets, as monolingual tweets do not contain translations. Although language identification is a well-studied problem (Zissman 1996; Gottron and Lipka 2010; Greenhill 2011), even in the microblog domain (Bergsma et al. 2012), these assume that only one language is present within a document and cannot be directly applied to this problem. Furthermore, because of the magnitude of tweets that must be processed, many of the proposed solutions cannot be applied due to their computational complexity. In our work, we propose an efficient implementation for large-scale detection of multilingual documents. Crowdsourcing for parallel data extraction - To tune the parameters of our parallel data extractor and perform MT experiments, user-verified annotations must be obtained. To obtain this, we propose a simple crowdsourcing"
J16-2005,C10-2010,0,0.0214145,"the translation of xai . Model 1 naively assigns a uniform prior probability to all alignment configurations. Although this is an obviously flawed assumption, the posterior alignment probability under Model 1 (i.e., PM1 (a |x, y)) is surprisingly informative. More robust models make less-naive prior assumptions and generally produce higher-quality alignments, but the uniform prior probability assumption simplifies the complexity of performing inference. Despite its simplicity, Model 1 has shown particularly good performance as a component in sentence alignment systems (Xu, Zens, and Ney 2005; Braune and Fraser 2010). Some work on parallel data extraction has also focused on extracting parallel segments from comparable corpora (Smith, Quirk, and Toutanova 2010; Munteanu, Fraser, and Marcu 2004). Smith et al. (2010) uses conditional random fields to identify parallel segments from comparable Wikipedia documents (since Wikipedia documents in multiple languages are not generally translations of each other, although they are about the same topics). The work of Jehl, Hieber, and Riezler (2012) uses cross-lingual information retrieval techniques to extract candidate English–Arabic translations from Twitter. The"
J16-2005,J93-2003,0,0.116606,"Missing"
J16-2005,N13-1073,1,0.853048,"Missing"
J16-2005,2014.iwslt-papers.7,0,0.0308749,"also possible to focus the extraction in one particular type of phenomena. For example, the work on mining parenthetical translations (Lin et al. 2008), which attempts to find translations within the same document, has some similarities with our work, since parenthetical translations are within the same document. However, parenthetical translations are generally used to translate names or terms, which is more limited than our work targeting the extraction of whole sentence translations. More recently, a similar method for extracting parallel data from multilingual Facebook posts was proposed (Eck et al. 2014). 312 Ling et al. Mining Parallel Corpora from Sina Weibo and Twitter Finally, crowdsourcing techniques can be used to obtain translations of text from new domains (Ambati and Vogel 2010; Zaidan and Callison-Burch 2011; Ambati, Vogel, and Carbonell 2012; Post, Callison-Burch, and Osborne 2012). These approaches require compensating workers for their efforts, and the workers themselves must be generally proficient in two languages, making the technique quite expensive. Previous work has relied on employing workers to translate segments. Crowdsourcing methods must also address the need for quali"
J16-2005,W06-1008,0,0.0705046,"Missing"
J16-2005,P91-1023,0,0.541067,"n features - In informal domains, there are many terms that are not translated, such as hashtags (e.g., #twitter), at mentions (e.g., @NYC), numbers, and people’s names. The presence of such repeated terms in the same tweet can be a strong cue for detecting translations. Hence, we define features that trigger if a given word type occurs in a pair within a tweet. The word types considered are hashtags, at mentions, numbers, and words beginning with capital letters. Length feature - It has been known that the length differences between parallel sentences can be modeled by a normal distribution (Gale and Church 1991). Thus, we used parallel training data (used to train the alignment model) in the respective language pair to determine (µ˜ , σ˜ 2 ), which lets us calculate the likelihood of two hypothesized segments being parallel. For each language pair s, t, we train separate classifiers for each language pair on annotated parallel data Dgold (s, t). The method used to obtain the necessary annotations is described in Section 5. Intrinsic evaluation. The quality of the classifier can be determined in terms of precision and recall. We count one as a true positive (tp) if we correctly identify a parallel twe"
J16-2005,P11-2008,0,0.0478665,"Missing"
J16-2005,J11-4003,0,0.0223833,"te pairs of tweets and determines whether the tweets in the pair are translations. In our work, single tweets are considered, and the problem is to determine whether the tweet contains translations and, if so, which spans are parallel. Efficient multilingual document detection - Parallel tweets are a relative rarity, but because of the volumes of data involved, we can find a large amount of content. We must efficiently detect multilingual tweets, as monolingual tweets do not contain translations. Although language identification is a well-studied problem (Zissman 1996; Gottron and Lipka 2010; Greenhill 2011), even in the microblog domain (Bergsma et al. 2012), these assume that only one language is present within a document and cannot be directly applied to this problem. Furthermore, because of the magnitude of tweets that must be processed, many of the proposed solutions cannot be applied due to their computational complexity. In our work, we propose an efficient implementation for large-scale detection of multilingual documents. Crowdsourcing for parallel data extraction - To tune the parameters of our parallel data extractor and perform MT experiments, user-verified annotations must be obtaine"
J16-2005,P11-1038,0,0.0259193,"till with me or what?) and nonstandard abbreviations (idk! smh). Automated language processing tools (e.g., those that perform linguistic analysis or translation) face particular difficulty with this new kind of content. On one hand, these have been developed with the conventions of more edited genres in mind. For example, they often make strong assumptions about orthographic and lexical uniformity (e.g., that there is just one way to spell you, and that cool, cooool, and cooooool represent completely unrelated lexical items). While modeling innovations are helping to relax these assumptions (Han and Baldwin 2011; Ritter et al. 2012; Owoputi et al. 2013; Ling et al. 2015), a second serious challenge is that many of the annotated text resources that our tools are learned from are drawn from edited genres, and poor generalization from edited to user-generated genres is a major source of errors (Gimpel et al. 2011; Kong et al. 2014). In this work, we present methods for finding naturally occurring parallel data on social media sites that is suitable for training machine translation (MT) systems. In MT, the domain mismatch problem is quite acute because most existing sources of parallel data are governmen"
J16-2005,W12-3153,0,0.0424014,"Missing"
J16-2005,D07-1103,0,0.0213949,"hus, for each language, we extract all data from Wikipedia up to a limit of 100K lines in order to keep the model compact. 7.1.3 Translation Lexicons. The IDA model uses translation lexicons to determine the translation score, as described in Section 3.1.1, which are estimated using parallel corpora. More specifically, we use the aligner described in Dyer, Chahuneau, and Smith (2013) to obtain the bidirectional alignments from the parallel sentences. Afterwards, we intersect the bidirectional alignments to obtain sure alignment points. Finally, we prune the lexicon using significance pruning (Johnson et al. 2007) with the threshold α +  (as defined in that work). The intersection and the pruning are performed to reduce the size of the lexicon to make the look-up faster. The breakdown of the different lexicons built is shown in Table 1. 7.2 Building Gold Standards To train and test the classifier described in Section 4.3, and perform MT experiments, a corpus of annotated tweets is needed for different language pairs. Table 2 summarizes the annotated corpora for the two domains (column Source) and the different language pairs (column Language Pair). We also report the method used to obtain the annotati"
J16-2005,D14-1108,1,0.842008,"hey often make strong assumptions about orthographic and lexical uniformity (e.g., that there is just one way to spell you, and that cool, cooool, and cooooool represent completely unrelated lexical items). While modeling innovations are helping to relax these assumptions (Han and Baldwin 2011; Ritter et al. 2012; Owoputi et al. 2013; Ling et al. 2015), a second serious challenge is that many of the annotated text resources that our tools are learned from are drawn from edited genres, and poor generalization from edited to user-generated genres is a major source of errors (Gimpel et al. 2011; Kong et al. 2014). In this work, we present methods for finding naturally occurring parallel data on social media sites that is suitable for training machine translation (MT) systems. In MT, the domain mismatch problem is quite acute because most existing sources of parallel data are governmental, religious, or commercial, which are quite different from usergenerated content, both in language use and in topic. The extracted parallel data can then be used to create systems designed to translate user-generated content. Additionally, because microblogs host discussions of virtually limitless topics, they are also"
J16-2005,I08-2120,0,0.190188,"he elaboration of this work, we made the following contributions to the field of NLP and MT. Figure 1 Examples of parallel posts in different language pairs and from different sources. Translated material is highlighted, non-translated material is not. DE = German; EN = English; ES = Spanish; PT = Portuguese; AR = Arabic; JA = Japanese; KO = Korean; RU = Russian; ZH = Chinese. 309 Computational Linguistics r r r Volume 42, Number 2 A method for extracting parallel data within documents - Existing methods for detecting parallel data (Resnik and Smith 2003; Fukushima, Taura, and Chikayama 2006; Li and Liu 2008; Uszkoreit et al. 2010; Ture and Lin 2012) assume that the source and target documents are separate. That is, these methods reason about the probability that documents A and B are translations. Previous work on extracting parallel data from Twitter (Jehl, Hieber, and Riezler 2012) retrieves candidate pairs of tweets and determines whether the tweets in the pair are translations. In our work, single tweets are considered, and the problem is to determine whether the tweet contains translations and, if so, which spans are parallel. Efficient multilingual document detection - Parallel tweets are"
J16-2005,P08-1113,0,0.0607684,"Missing"
J16-2005,D13-1008,1,0.90112,"e quite different from usergenerated content, both in language use and in topic. The extracted parallel data can then be used to create systems designed to translate user-generated content. Additionally, because microblogs host discussions of virtually limitless topics, they are also a potential source of information about how to translate names and words associated with breaking events, and, as such, may be useful for translation of texts from more traditional domains. Apart from machine translation, parallel data in this domain can improve and help create applications in other areas in NLP (Ling et al. 2013; Peng, Wang, and Dredze 2014; Wang et al. 2014). Our method is inspired by the (perhaps surprising) observation that a reasonable number of microblog users tweet “in parallel” in two or more languages. For instance, the American entertainer Snoop Dogg maintains an account on Sina Weibo that regularly posts English–Chinese parallel messages, for example, watup Kenny !!, where an English message and its Chinese Mayne!! - Kenny Mayne translation are in the same post, separated by a dash. It is not only celebrities (or 308 Ling et al. Mining Parallel Corpora from Sina Weibo and Twitter their publ"
J16-2005,D15-1176,1,0.850166,"Missing"
J16-2005,W14-3356,1,0.854061,"parallel segment is correct. If so, the material is extracted, otherwise it is discarded. This research is an extension of the preliminary work described in Ling et al. (2013), in which we obtained over 1 million Chinese–English parallel segments from Sina Weibo, using only their public application program interface (API). This automatically extracted parallel data yielded substantial translation quality improvements in translating microblog text and modest improvements in translating edited news. Following this work, we developed a method for crowdsourcing judgments about parallel segments (Ling et al. 2014), which was then used to build gold standard data for other language pairs and for the Twitter domain. This article extends these two papers in several ways: r 310 Improved language pair detection - The previous work assumes that the language pair is formed by two languages with different unicode ranges, such as English–Chinese, and does not support the extraction of parallel data if the languages share the same unicode range (such as English–Portuguese). This issue is addressed in this article, where we present a novel approach for finding multilingual tweets. Ling et al. r r Mining Parallel"
J16-2005,P13-1018,1,0.731322,"e quite different from usergenerated content, both in language use and in topic. The extracted parallel data can then be used to create systems designed to translate user-generated content. Additionally, because microblogs host discussions of virtually limitless topics, they are also a potential source of information about how to translate names and words associated with breaking events, and, as such, may be useful for translation of texts from more traditional domains. Apart from machine translation, parallel data in this domain can improve and help create applications in other areas in NLP (Ling et al. 2013; Peng, Wang, and Dredze 2014; Wang et al. 2014). Our method is inspired by the (perhaps surprising) observation that a reasonable number of microblog users tweet “in parallel” in two or more languages. For instance, the American entertainer Snoop Dogg maintains an account on Sina Weibo that regularly posts English–Chinese parallel messages, for example, watup Kenny !!, where an English message and its Chinese Mayne!! - Kenny Mayne translation are in the same post, separated by a dash. It is not only celebrities (or 308 Ling et al. Mining Parallel Corpora from Sina Weibo and Twitter their publ"
J16-2005,Q14-1003,0,0.0561496,"Missing"
J16-2005,J05-4003,0,0.318213,"the appropriately aligned parallel segments. Obviously, Ds,t will contain a considerable number of non-parallel segments, as multilingual messages in Tmult are not guaranteed to contain translated material. Furthermore, we must also consider errors from misalignments of the IDA model and misclassifications of the multilingual message detector. Thus, in order to identify messages that are actually parallel, a final identification step is necessary. 4.3 Identification Given a candidate sentence pair (s, t), many existing methods for detecting parallel data can be applied (Resnik and Smith 2003; Munteanu and Marcu 2005), as this problem becomes a regular unstructured bitext identification problem. In our initial work (Ling et al. 2013), we simply defined a threshold τ on the IDA model score, which was determined empirically. To obtain better results we train a logistic regression classifier for each language pair, similar to that presented in Munteanu and Marcu (2005), which detects whether two segments are parallel in a given language pair by looking at features of the candidate pair. Training is performed to maximize the classification decisions on annotated candidate pairs. 324 Ling et al. Mining Parallel"
J16-2005,N04-1034,0,0.0600954,"Missing"
J16-2005,P03-1021,0,0.0143381,"Missing"
J16-2005,N13-1039,1,0.773659,"regarding existing languages allows the detector to estimate the language probabilities more accurately. As we are using a character trigram model, a large amount of data is not required to saturate the model probabilities. Thus, for each language, we extract all data from Wikipedia up to a limit of 100K lines in order to keep the model compact. 7.1.3 Translation Lexicons. The IDA model uses translation lexicons to determine the translation score, as described in Section 3.1.1, which are estimated using parallel corpora. More specifically, we use the aligner described in Dyer, Chahuneau, and Smith (2013) to obtain the bidirectional alignments from the parallel sentences. Afterwards, we intersect the bidirectional alignments to obtain sure alignment points. Finally, we prune the lexicon using significance pruning (Johnson et al. 2007) with the threshold α +  (as defined in that work). The intersection and the pruning are performed to reduce the size of the lexicon to make the look-up faster. The breakdown of the different lexicons built is shown in Table 1. 7.2 Building Gold Standards To train and test the classifier described in Section 4.3, and perform MT experiments, a corpus of annotated"
J16-2005,P02-1040,0,0.0967467,"Missing"
J16-2005,P14-2110,0,0.0370301,"Missing"
J16-2005,W12-3152,0,0.0412989,"Missing"
J16-2005,J03-3002,0,0.467405,"s many challenges to current NLP and MT methods. As part of the elaboration of this work, we made the following contributions to the field of NLP and MT. Figure 1 Examples of parallel posts in different language pairs and from different sources. Translated material is highlighted, non-translated material is not. DE = German; EN = English; ES = Spanish; PT = Portuguese; AR = Arabic; JA = Japanese; KO = Korean; RU = Russian; ZH = Chinese. 309 Computational Linguistics r r r Volume 42, Number 2 A method for extracting parallel data within documents - Existing methods for detecting parallel data (Resnik and Smith 2003; Fukushima, Taura, and Chikayama 2006; Li and Liu 2008; Uszkoreit et al. 2010; Ture and Lin 2012) assume that the source and target documents are separate. That is, these methods reason about the probability that documents A and B are translations. Previous work on extracting parallel data from Twitter (Jehl, Hieber, and Riezler 2012) retrieves candidate pairs of tweets and determines whether the tweets in the pair are translations. In our work, single tweets are considered, and the problem is to determine whether the tweet contains translations and, if so, which spans are parallel. Efficient"
J16-2005,N10-1063,0,0.0245615,"1 (i.e., PM1 (a |x, y)) is surprisingly informative. More robust models make less-naive prior assumptions and generally produce higher-quality alignments, but the uniform prior probability assumption simplifies the complexity of performing inference. Despite its simplicity, Model 1 has shown particularly good performance as a component in sentence alignment systems (Xu, Zens, and Ney 2005; Braune and Fraser 2010). Some work on parallel data extraction has also focused on extracting parallel segments from comparable corpora (Smith, Quirk, and Toutanova 2010; Munteanu, Fraser, and Marcu 2004). Smith et al. (2010) uses conditional random fields to identify parallel segments from comparable Wikipedia documents (since Wikipedia documents in multiple languages are not generally translations of each other, although they are about the same topics). The work of Jehl, Hieber, and Riezler (2012) uses cross-lingual information retrieval techniques to extract candidate English–Arabic translations from Twitter. These candidates are then refined using a more expressive model to identify translations (Xu, Weischedel, and Nguyen 2001). It is also possible to focus the extraction in one particular type of phenomena."
J16-2005,N12-1079,0,0.0918698,"following contributions to the field of NLP and MT. Figure 1 Examples of parallel posts in different language pairs and from different sources. Translated material is highlighted, non-translated material is not. DE = German; EN = English; ES = Spanish; PT = Portuguese; AR = Arabic; JA = Japanese; KO = Korean; RU = Russian; ZH = Chinese. 309 Computational Linguistics r r r Volume 42, Number 2 A method for extracting parallel data within documents - Existing methods for detecting parallel data (Resnik and Smith 2003; Fukushima, Taura, and Chikayama 2006; Li and Liu 2008; Uszkoreit et al. 2010; Ture and Lin 2012) assume that the source and target documents are separate. That is, these methods reason about the probability that documents A and B are translations. Previous work on extracting parallel data from Twitter (Jehl, Hieber, and Riezler 2012) retrieves candidate pairs of tweets and determines whether the tweets in the pair are translations. In our work, single tweets are considered, and the problem is to determine whether the tweet contains translations and, if so, which spans are parallel. Efficient multilingual document detection - Parallel tweets are a relative rarity, but because of the volum"
J16-2005,C10-1124,0,0.3794,"this work, we made the following contributions to the field of NLP and MT. Figure 1 Examples of parallel posts in different language pairs and from different sources. Translated material is highlighted, non-translated material is not. DE = German; EN = English; ES = Spanish; PT = Portuguese; AR = Arabic; JA = Japanese; KO = Korean; RU = Russian; ZH = Chinese. 309 Computational Linguistics r r r Volume 42, Number 2 A method for extracting parallel data within documents - Existing methods for detecting parallel data (Resnik and Smith 2003; Fukushima, Taura, and Chikayama 2006; Li and Liu 2008; Uszkoreit et al. 2010; Ture and Lin 2012) assume that the source and target documents are separate. That is, these methods reason about the probability that documents A and B are translations. Previous work on extracting parallel data from Twitter (Jehl, Hieber, and Riezler 2012) retrieves candidate pairs of tweets and determines whether the tweets in the pair are translations. In our work, single tweets are considered, and the problem is to determine whether the tweet contains translations and, if so, which spans are parallel. Efficient multilingual document detection - Parallel tweets are a relative rarity, but"
J16-2005,D14-1122,0,0.0205903,"oth in language use and in topic. The extracted parallel data can then be used to create systems designed to translate user-generated content. Additionally, because microblogs host discussions of virtually limitless topics, they are also a potential source of information about how to translate names and words associated with breaking events, and, as such, may be useful for translation of texts from more traditional domains. Apart from machine translation, parallel data in this domain can improve and help create applications in other areas in NLP (Ling et al. 2013; Peng, Wang, and Dredze 2014; Wang et al. 2014). Our method is inspired by the (perhaps surprising) observation that a reasonable number of microblog users tweet “in parallel” in two or more languages. For instance, the American entertainer Snoop Dogg maintains an account on Sina Weibo that regularly posts English–Chinese parallel messages, for example, watup Kenny !!, where an English message and its Chinese Mayne!! - Kenny Mayne translation are in the same post, separated by a dash. It is not only celebrities (or 308 Ling et al. Mining Parallel Corpora from Sina Weibo and Twitter their publicists) who tweet in multiple languages; we see"
J16-2005,2005.eamt-1.37,0,0.0799727,"Missing"
J16-2005,P11-1122,0,0.136156,"document, has some similarities with our work, since parenthetical translations are within the same document. However, parenthetical translations are generally used to translate names or terms, which is more limited than our work targeting the extraction of whole sentence translations. More recently, a similar method for extracting parallel data from multilingual Facebook posts was proposed (Eck et al. 2014). 312 Ling et al. Mining Parallel Corpora from Sina Weibo and Twitter Finally, crowdsourcing techniques can be used to obtain translations of text from new domains (Ambati and Vogel 2010; Zaidan and Callison-Burch 2011; Ambati, Vogel, and Carbonell 2012; Post, Callison-Burch, and Osborne 2012). These approaches require compensating workers for their efforts, and the workers themselves must be generally proficient in two languages, making the technique quite expensive. Previous work has relied on employing workers to translate segments. Crowdsourcing methods must also address the need for quality control. Thus, in order to find good translations, subsequent post-editing and/or ranking is generally necessary. 3. The Intra-Document Alignment (IDA) Model As discussed above, content-based filtering is a method f"
J16-2005,J93-1004,0,\N,Missing
J16-2005,N03-1017,0,\N,Missing
J87-3008,E87-1003,1,0.853849,"Missing"
J87-3008,C73-2019,0,0.819767,"Missing"
J87-3008,C86-1066,0,\N,Missing
L16-1546,W14-3914,0,0.0438383,"Missing"
L16-1546,W14-3908,0,0.120208,"Missing"
L16-1546,W06-3201,0,0.0233647,"ulating phonetic 3426 similarity. Le et al. (Le et al., 2006) used a top-down bottom-up knowledge based approach for calculating phoneme similarity. They use models of similar phonemes cross lingually to create context dependent Acoustic Models in new languages. They used IPA rules to create a hierarchical graph of phoneme similarity, which splits phonemes into categories like Consonant-Vowel, Close-Back Vowels, CloseFront, Close-Back vowels etc. Acoustic Models were built with multiple languages and used for recognizing Vietnamese speech with a small amount of adaptation data. Melnar et al. (Melnar and Liu, 2006) describe an approach to measuring phoneme distance cross lingually by representing phonemes as a feature matrix, with feature weights based on lexical frequency. In addition to traditionally used phonetic features, they also include corrolary features that represent allophonic realizations of the phones. This approach was shown to perform well on cross-lingual ASR tasks. Pucher et al. (Pucher et al., 2007) describe phonetic similarity measures for ASR grammar optimization in which they compare minimum edit distance based measures, perceptually motivated measures and HMM-distance based measure"
L16-1546,W97-1102,0,0.204949,"di corpus, but chose to replace them with more frequent phonemes. In all the experiments described above, we mapped phonemes from English to Hindi manually. However, we wanted to automate the process as much as possible. The approach described by Nerbonne et al. (Nerbonne et al., 1996) uses Levenshtein distance to measure the distance between words in different dialects of Dutch, and uses this to group dialects together. A common set of words are compared across all dialects, with the distance being compared based on letters with different weights for insertions, substitutions and deletions. (Nerbonne and Heeringa, 1997) extend this work by using phonetic features and a variety of distance metrics. Sriram et al. (Sriram et al., 2004) describe a technique for multilingual query processing, in which words in the queries are converted into a language independent ’common ground’ representation, after which a weighted phonetic distance measure is used to match and rank queries. Phonetic features include vowel rounding, frontness, height, length, voicing, aspiration etc. which are the same features that are used in the standard Festival phonetic feature set. The authors also suggest weights that can be given to the"
L16-1546,W14-3907,0,0.0141299,"k for synthesizing code-mixed text. The organization of the paper is as follows. Section 2 relates this work to previous work in code switching and code-mixing. Section 3 describes our work on synthesizing code-mixed text written in different scripts. Section 4 describes our framework for synthesizing code-mixed text written in the same script. Section 5 concludes. 2. Relation to Prior Work Code switching and code-mixing have been identified as challenges for language technologies ranging from Information Retrieval to Automatic Speech Recognition. The Code Switching shared task at EMNLP 2014 (Solorio et al., 2014) consisted of data from 4 mixed languages (English-Spanish, Nepali-English, Arabic-Arabic dialect, Mandarin-English) and the task was to identify for each word which language it belonged to, or whether it was mixed, ambiguous or a named entity. Chittaranjan et al. (Chittaranjan et al., 2014) describe a CRF based approach for word level Language Identification for this task, in which they used various lexical and character-based features. Recently, code-mixing in text has been studied for languages of the Indian subcontinent, which exhibit a lot of mixing with English and other Indian languages"
L16-1546,D14-1105,0,0.0781565,"Missing"
N03-4015,W02-0717,1,\N,Missing
N03-4015,lavie-etal-2002-nespole,1,\N,Missing
N04-3010,H01-1018,1,0.895093,"Missing"
N06-1030,2005.iwslt-1.22,0,0.131091,"Missing"
N09-2038,2007.iwslt-1.4,1,0.789571,"adapt the system based on its usage automatically without having to ship data back to the laboratory for retraining. This paper investigates the scenario of a two-day event. We wish to improve the system for the second day based on the data collected on the first day. Our system is designed for eyes-free use and hence provides no graphical user interface. This allows the user to concentrate on his surrounding environment during an operation. The system only provides audio control and feedback. Additionally the system operates on a push-totalk method. Previously the system (Hsiao et al., 2006; Bach et al., 2007) needed 2 buttons to operate, one for the English speaker and the other one for the Iraqi speaker. To make the system easier and faster to use, we propose to use a single button which can be controlled by the English speaker. We mounted a microphone and a Wii remote controller together as shown in 1. Since the Wii controller has an accelerometer which can be used to detect the orientation of the controller, this feature can be applied to identify who is speaking. When the English speaker points towards himself, the system will switch to English-Iraqi translation. However, when the Wii is point"
N09-2038,P08-2040,0,0.0125219,"0K sentence pairs collected under the TransTac program. We used PESA phrase extraction (Vogel, 2005) and a suffix array language model (Zhang and Vogel, 2005). To adapt SMT components one approach is to optimize LM interpolation weights by minimizing perplexity of the 1-best translation output (Bulyko et al., 2007). Related work including (Eck et al., 2004) attempts to use information retrieval to select training sentences similar to those in the test set. To adapt the SMT components we use a domain-specific LM on top of the background language models. This approach is similar to the work in (Chen et al., 2008). sThe adaptation framework is 1) create a domain-specific LM via an n-best list of day 1 machine translation hypothesis, or day 1 translation references; 2) re-tune the translation system on day 1 via minimum error rate training (MERT) (Venugopal and Vogel, 2005). Use 500 Best MT Hypos Day 1 Day 2 Baseline 29.39 27.41 1gramLM 2gramLM 3gramLM 29.18 29.53 29.36 27.23 27.50 27.23 The first question we would like to address is whether our adaptation obtains improvements via an unsupervised manner. We take day 1 baseline ASR hypothesis and use the baseline SMT to get the MT hypothesis and a 500bes"
N09-2038,eck-etal-2004-language,1,0.856377,"d and supervised ASR adaptation on performance of SMT on day 2. However, we can see that the difference in WER on day 2 of unsupervised and supervised ASR adaptation is relatively small. 4 SMT Adaptation The Iraqi-English SMT system is trained with around 650K sentence pairs collected under the TransTac program. We used PESA phrase extraction (Vogel, 2005) and a suffix array language model (Zhang and Vogel, 2005). To adapt SMT components one approach is to optimize LM interpolation weights by minimizing perplexity of the 1-best translation output (Bulyko et al., 2007). Related work including (Eck et al., 2004) attempts to use information retrieval to select training sentences similar to those in the test set. To adapt the SMT components we use a domain-specific LM on top of the background language models. This approach is similar to the work in (Chen et al., 2008). sThe adaptation framework is 1) create a domain-specific LM via an n-best list of day 1 machine translation hypothesis, or day 1 translation references; 2) re-tune the translation system on day 1 via minimum error rate training (MERT) (Venugopal and Vogel, 2005). Use 500 Best MT Hypos Day 1 Day 2 Baseline 29.39 27.41 1gramLM 2gramLM 3gra"
N09-2038,P02-1040,0,0.0766368,"FCC and we concatenate adjacent 15 frames and perform LDA to reduce the dimension to 42 for the final feature vectors. The language model of the ASR system is a trigram LM trained on the audio transcripts with around three million words with Kneser-Ney smoothing (Stolcke, 2002). To perform LM adaptation for the ASR system, we use the ASR hypotheses from day 1 to build a LM. This LM is then interpolated with the original trigram LM to produce an adapted LM for day 2. We also evaluate the effect 150 Table 2 shows the impact of ASR adaptation on the performance of the translation system in BLEU (Papineni et al., 2002). In these experiments we only performed adaptation on ASR and still using the baseline SMT component. There is no obvious difference between unsupervised and supervised ASR adaptation on performance of SMT on day 2. However, we can see that the difference in WER on day 2 of unsupervised and supervised ASR adaptation is relatively small. 4 SMT Adaptation The Iraqi-English SMT system is trained with around 650K sentence pairs collected under the TransTac program. We used PESA phrase extraction (Vogel, 2005) and a suffix array language model (Zhang and Vogel, 2005). To adapt SMT components one a"
N09-2038,2005.eamt-1.36,1,0.647983,"exity of the 1-best translation output (Bulyko et al., 2007). Related work including (Eck et al., 2004) attempts to use information retrieval to select training sentences similar to those in the test set. To adapt the SMT components we use a domain-specific LM on top of the background language models. This approach is similar to the work in (Chen et al., 2008). sThe adaptation framework is 1) create a domain-specific LM via an n-best list of day 1 machine translation hypothesis, or day 1 translation references; 2) re-tune the translation system on day 1 via minimum error rate training (MERT) (Venugopal and Vogel, 2005). Use 500 Best MT Hypos Day 1 Day 2 Baseline 29.39 27.41 1gramLM 2gramLM 3gramLM 29.18 29.53 29.36 27.23 27.50 27.23 The first question we would like to address is whether our adaptation obtains improvements via an unsupervised manner. We take day 1 baseline ASR hypothesis and use the baseline SMT to get the MT hypothesis and a 500best list. We train a domain LM using the 500-best list and use the MT hypotheses as the reference in MERT. We treat day 1 as a development set and day 2 as an unseen test set. In Table 3 we compare the performance of four systems: the baseline which does not have an"
N09-2038,2005.mtsummit-papers.33,1,0.693382,"impact of ASR adaptation on the performance of the translation system in BLEU (Papineni et al., 2002). In these experiments we only performed adaptation on ASR and still using the baseline SMT component. There is no obvious difference between unsupervised and supervised ASR adaptation on performance of SMT on day 2. However, we can see that the difference in WER on day 2 of unsupervised and supervised ASR adaptation is relatively small. 4 SMT Adaptation The Iraqi-English SMT system is trained with around 650K sentence pairs collected under the TransTac program. We used PESA phrase extraction (Vogel, 2005) and a suffix array language model (Zhang and Vogel, 2005). To adapt SMT components one approach is to optimize LM interpolation weights by minimizing perplexity of the 1-best translation output (Bulyko et al., 2007). Related work including (Eck et al., 2004) attempts to use information retrieval to select training sentences similar to those in the test set. To adapt the SMT components we use a domain-specific LM on top of the background language models. This approach is similar to the work in (Chen et al., 2008). sThe adaptation framework is 1) create a domain-specific LM via an n-best list o"
N09-2038,2005.eamt-1.39,1,0.826207,"he translation system in BLEU (Papineni et al., 2002). In these experiments we only performed adaptation on ASR and still using the baseline SMT component. There is no obvious difference between unsupervised and supervised ASR adaptation on performance of SMT on day 2. However, we can see that the difference in WER on day 2 of unsupervised and supervised ASR adaptation is relatively small. 4 SMT Adaptation The Iraqi-English SMT system is trained with around 650K sentence pairs collected under the TransTac program. We used PESA phrase extraction (Vogel, 2005) and a suffix array language model (Zhang and Vogel, 2005). To adapt SMT components one approach is to optimize LM interpolation weights by minimizing perplexity of the 1-best translation output (Bulyko et al., 2007). Related work including (Eck et al., 2004) attempts to use information retrieval to select training sentences similar to those in the test set. To adapt the SMT components we use a domain-specific LM on top of the background language models. This approach is similar to the work in (Chen et al., 2008). sThe adaptation framework is 1) create a domain-specific LM via an n-best list of day 1 machine translation hypothesis, or day 1 translati"
N15-1142,P14-2133,0,0.00813576,"ilt using these models are suboptimal for tasks involving syntax, such as part-ofspeech tagging or dependency parsing. This is because syntax defines “what words go where?”, while semantics than “what words go together”. Obviously, in a model where word order is discarded, the many syntactic relations between words cannot be captured properly. For instance, while most words occur with the word the, only nouns tend to occur exactly afterwords (e.g. the cat). This is supported by empirical evidence that suggests that order-insensitivity does indeed lead to substandard syntactic representations (Andreas and Klein, 2014; Bansal et al., 2014), where systems using pre-trained with Word2Vec models yield slight improvements while the computationally far more expensive which use word order information embeddings of Collobert et al. (2011) yielded much better results. 1299 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1299–1304, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics In this work, we describe two simple modifications to Word2Vec, one for the skip-gram model and one for the CBOW model, that improve the quali"
N15-1142,P14-2131,0,0.0361448,"e suboptimal for tasks involving syntax, such as part-ofspeech tagging or dependency parsing. This is because syntax defines “what words go where?”, while semantics than “what words go together”. Obviously, in a model where word order is discarded, the many syntactic relations between words cannot be captured properly. For instance, while most words occur with the word the, only nouns tend to occur exactly afterwords (e.g. the cat). This is supported by empirical evidence that suggests that order-insensitivity does indeed lead to substandard syntactic representations (Andreas and Klein, 2014; Bansal et al., 2014), where systems using pre-trained with Word2Vec models yield slight improvements while the computationally far more expensive which use word order information embeddings of Collobert et al. (2011) yielded much better results. 1299 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1299–1304, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics In this work, we describe two simple modifications to Word2Vec, one for the skip-gram model and one for the CBOW model, that improve the quality of the embeddings f"
N15-1142,D14-1082,0,0.416746,"o generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models. 1 Introduction Word representations learned from neural language models have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of"
N15-1142,P14-1129,0,0.00965647,"they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models. 1 Introduction Word representations learned from neural language models have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of the most widely used tools for building word vectors are the models described in (Mikolov et al., 2013), implement"
N15-1142,E14-1049,1,0.0586898,"isabel.trancoso@inesc-id.pt Abstract in particular the “skip-gram” and the “continuous bag-of-words” (CBOW) models. These two models make different independence and conditioning assumptions; however, both models discard word order information in how they account for context. Thus, embeddings built using these models have been shown to capture semantic information between words, and pre-training using these models has been shown to lead to major improvements in many tasks (Collobert et al., 2011). While more sophisticated approaches have been proposed (Dhillon et al., 2011; Huang et al., 2012; Faruqui and Dyer, 2014; Levy and Goldberg, 2014; Yang and Eisenstein, 2015), Word2Vec remains a popular choice due to their efficiency and simplicity. We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing"
N15-1142,P11-2008,0,0.0164828,"Missing"
N15-1142,D14-1012,0,0.0227742,"g (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of the most widely used tools for building word vectors are the models described in (Mikolov et al., 2013), implemented in the Word2Vec tool, However, as these models are insensitive to word order, embeddings built using these models are suboptimal for tasks involving syntax, such as part-ofspeech tagging or dependency parsing. This is because syntax defines “what words go where?”, while semantics than “what words go together”. Obviously, in a model where word order is discarded, the many syntactic relations between words cannot be captured properly. For instance, while most words occur"
N15-1142,P12-1092,0,0.0570707,"yer,awb}@cs.cmu.edu isabel.trancoso@inesc-id.pt Abstract in particular the “skip-gram” and the “continuous bag-of-words” (CBOW) models. These two models make different independence and conditioning assumptions; however, both models discard word order information in how they account for context. Thus, embeddings built using these models have been shown to capture semantic information between words, and pre-training using these models has been shown to lead to major improvements in many tasks (Collobert et al., 2011). While more sophisticated approaches have been proposed (Dhillon et al., 2011; Huang et al., 2012; Faruqui and Dyer, 2014; Levy and Goldberg, 2014; Yang and Eisenstein, 2015), Word2Vec remains a popular choice due to their efficiency and simplicity. We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging"
N15-1142,D13-1176,0,0.00968706,"riginal models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models. 1 Introduction Word representations learned from neural language models have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of the most widely used tools for building word vectors are the models described in (Mikolov et"
N15-1142,D14-1108,1,0.588959,"re suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models. 1 Introduction Word representations learned from neural language models have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of the most widely use"
N15-1142,P14-2050,0,0.0354569,".pt Abstract in particular the “skip-gram” and the “continuous bag-of-words” (CBOW) models. These two models make different independence and conditioning assumptions; however, both models discard word order information in how they account for context. Thus, embeddings built using these models have been shown to capture semantic information between words, and pre-training using these models has been shown to lead to major improvements in many tasks (Collobert et al., 2011). While more sophisticated approaches have been proposed (Dhillon et al., 2011; Huang et al., 2012; Faruqui and Dyer, 2014; Levy and Goldberg, 2014; Yang and Eisenstein, 2015), Word2Vec remains a popular choice due to their efficiency and simplicity. We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models"
N15-1142,P14-1140,0,0.0252753,"n issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models. 1 Introduction Word representations learned from neural language models have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of the most widely used tools for building word vectors are the"
N15-1142,N13-1039,1,0.692184,"Missing"
N15-1142,P10-1040,0,0.185776,"posed models. 1 Introduction Word representations learned from neural language models have been shown to improve many NLP tasks, such as part-of-speech tagging (Collobert et al., 2011), dependency parsing (Chen and Manning, 2014; Kong et al., 2014) and machine translation (Liu et al., 2014; Kalchbrenner and Blunsom, 2013; Devlin et al., 2014; Sutskever et al., 2014). These low-dimensional representations are learned as parameters in a language model and trained to maximize the likelihood of a large corpus of raw text. They are then incorporated as features along side hand-engineered features (Turian et al., 2010), or used to initialize the parameters of neural networks targeting tasks for which substantially less training data is available (Hinton and Salakhutdinov, 2012; Erhan et al., 2010; Guo et al., 2014). One of the most widely used tools for building word vectors are the models described in (Mikolov et al., 2013), implemented in the Word2Vec tool, However, as these models are insensitive to word order, embeddings built using these models are suboptimal for tasks involving syntax, such as part-ofspeech tagging or dependency parsing. This is because syntax defines “what words go where?”, while sem"
N15-1142,N15-1069,0,0.0165027,"r the “skip-gram” and the “continuous bag-of-words” (CBOW) models. These two models make different independence and conditioning assumptions; however, both models discard word order information in how they account for context. Thus, embeddings built using these models have been shown to capture semantic information between words, and pre-training using these models has been shown to lead to major improvements in many tasks (Collobert et al., 2011). While more sophisticated approaches have been proposed (Dhillon et al., 2011; Huang et al., 2012; Faruqui and Dyer, 2014; Levy and Goldberg, 2014; Yang and Eisenstein, 2015), Word2Vec remains a popular choice due to their efficiency and simplicity. We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models. 1 Introduction Word repres"
N16-1161,P14-2131,0,0.011684,"e tense vowels—a feature based on the presence of tense vowels is uninformative and that (2) a significant minority of languages make a distinction between tense and lax vowels—a feature based on whether languages display a minimal difference of this kind would be more useful. 4 Applications of Phonetic Vectors Learned continuous word representations—word vectors—are an important by-product of neural LMs, and these are used as features in numerous NLP applications, including chunking (Turian et al., 2010), part-of-speech tagging (Ling et al., 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al., 2014), and sentiment analysis (Socher et al., 2013; Wang et al., 2015). We evaluate phone vectors learned by Polyglot LMs in two downstream applications that rely on phonology: modeling lexical borrowing (§4.1) and speech synthesis (§4.2). 4.1 Lexical borrowing Lexical borrowing is the adoption of words from another language, that inevitably happens when speakers of different languages communicate for a long period of time (Thomason and Kaufman, 2001). Borrowed words—also called loan1360 words—constitute 10–"
N16-1161,P15-1033,1,0.113206,"Missing"
N16-1161,E14-1049,1,0.21174,") that polyglot phonetic feature representations are of higher quality than those learned monolingually. 1 Introduction Nearly all existing language model (LM) architectures are designed to model one language at a time. This is unsurprising considering the historical importance of count-based models in which every surface form of a word is a separately modeled entity (English cat and Spanish gato would not likely benefit from sharing counts). However, recent models that use distributed representations—in particular models that share representations across languages (Hermann and Blunsom, 2014; Faruqui and Dyer, 2014; Huang et al., 2015; Lu et al., 2015, inter alia)—suggest universal models applicable to multiple languages are a possibility. This paper takes a Exploration of polyglot language models at the sentence level—the traditional domain of language modeling—requires dealing with a massive event space (i.e., the union of words across many languages). To work in a more tractable domain, we evaluate our model on phone-based language modeling, the modeling sequences of sounds, rather than words. We choose this domain since a common assumption of many theories of phonology is that all spoken languages c"
N16-1161,D14-1012,0,0.0184753,"Missing"
N16-1161,D15-1127,0,0.0128799,"feature representations are of higher quality than those learned monolingually. 1 Introduction Nearly all existing language model (LM) architectures are designed to model one language at a time. This is unsurprising considering the historical importance of count-based models in which every surface form of a word is a separately modeled entity (English cat and Spanish gato would not likely benefit from sharing counts). However, recent models that use distributed representations—in particular models that share representations across languages (Hermann and Blunsom, 2014; Faruqui and Dyer, 2014; Huang et al., 2015; Lu et al., 2015, inter alia)—suggest universal models applicable to multiple languages are a possibility. This paper takes a Exploration of polyglot language models at the sentence level—the traditional domain of language modeling—requires dealing with a massive event space (i.e., the union of words across many languages). To work in a more tractable domain, we evaluate our model on phone-based language modeling, the modeling sequences of sounds, rather than words. We choose this domain since a common assumption of many theories of phonology is that all spoken languages construct words from"
N16-1161,D13-1196,0,0.0422633,"at (1) all languages have tense vowels—a feature based on the presence of tense vowels is uninformative and that (2) a significant minority of languages make a distinction between tense and lax vowels—a feature based on whether languages display a minimal difference of this kind would be more useful. 4 Applications of Phonetic Vectors Learned continuous word representations—word vectors—are an important by-product of neural LMs, and these are used as features in numerous NLP applications, including chunking (Turian et al., 2010), part-of-speech tagging (Ling et al., 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al., 2014), and sentiment analysis (Socher et al., 2013; Wang et al., 2015). We evaluate phone vectors learned by Polyglot LMs in two downstream applications that rely on phonology: modeling lexical borrowing (§4.1) and speech synthesis (§4.2). 4.1 Lexical borrowing Lexical borrowing is the adoption of words from another language, that inevitably happens when speakers of different languages communicate for a long period of time (Thomason and Kaufman, 2001). Borrowed words—also called loan1360"
N16-1161,L16-1529,1,0.829863,"learned distributed representations with dimensions of a hand-crafted linguistic matrix. Alignments are induced via correlating columns in the distributed and the linguistic matrices. To analyze the content of the distributed matrix, annotations from the linguistic matrix are projected via the maximally-correlated alignments. We constructed a phonological matrix in which 5,059 rows are IPA phones and 21 columns are boolean indicators of universal phonological properties, e.g. consonant, voiced, labial.5 We the projected annotations from the linguistic matrix and 5 This matrix is described in Littell et al. (2016) and is available at https://github.com/dmort27/panphon/. 1364 manually examined aligned dimensions in the phone vectors from §5.3 (trained on six languages). In the maximally-correlated columns—corresponding to linguistic features long, consonant, nasalized—we examined phones with highest coefficients. These &gt; were: [5:, U:, i:, O:, E:] for long; [v, ñ, dZ, d, f, j, &gt; ts, N] for consonant; and [˜O, ˜E, A˜, œ] ˜ for nasalized. Clearly, the learned representation discover standard phonological features. Moreover, these top-ranked sounds are not grouped by a single language, e.g., &gt; /dZ/ is pres"
N16-1161,N15-1028,0,0.0136804,"ions are of higher quality than those learned monolingually. 1 Introduction Nearly all existing language model (LM) architectures are designed to model one language at a time. This is unsurprising considering the historical importance of count-based models in which every surface form of a word is a separately modeled entity (English cat and Spanish gato would not likely benefit from sharing counts). However, recent models that use distributed representations—in particular models that share representations across languages (Hermann and Blunsom, 2014; Faruqui and Dyer, 2014; Huang et al., 2015; Lu et al., 2015, inter alia)—suggest universal models applicable to multiple languages are a possibility. This paper takes a Exploration of polyglot language models at the sentence level—the traditional domain of language modeling—requires dealing with a massive event space (i.e., the union of words across many languages). To work in a more tractable domain, we evaluate our model on phone-based language modeling, the modeling sequences of sounds, rather than words. We choose this domain since a common assumption of many theories of phonology is that all spoken languages construct words from a finite inventor"
N16-1161,W11-2124,0,0.0106161,"gful related groupings across languages. 6 Related Work Multilingual language models. Interpolation of monolingual LMs is an alternative to obtain a multilingual model (Harbeck et al., 1997; Weng et al., 1997). However, interpolated models still require a trained model per language, and do not allow parameter sharing at training time. Bilingual language models trained on concatenated corpora were explored mainly in speech recognition (Ward et al., 1998; Wang et al., 2002; Fügen et al., 2003). Adaptations have been proposed to apply language models in bilingual settings in machine translation (Niehues et al., 2011) and code switching (Adel et al., 2013). These approaches, however, require adaptation to every pair of languages, and an adapted model cannot be applied to more than two languages. Independently, Ammar et al. (2016) used a different polyglot architecture for multilingual dependency parsing. This work has also confirmed the utility of polyglot architectures in leveraging multilinguality. Multimodal neural language models. Multimodal language modeling is integrating image/video modalities in text LMs. Our work is inspired by the neural multimodal LMs (Kiros and Salakhutdinov, 2013; Kiros et al."
N16-1161,qian-etal-2010-python,0,0.0593655,"Missing"
N16-1161,D13-1170,0,0.00194071,"Missing"
N16-1161,P15-2021,1,0.840243,"Missing"
N16-1161,D15-1243,1,0.588955,"with hand-crafted features. We found that using both feature sets added no value, suggesting that learned phone vectors are capturing information that is equivalent to the hand-engineered vectors. 5.5 Qualitative analysis of vectors Phone vectors learned by Polyglot LMs are mere sequences of real numbers. An interesting question is whether these vectors capture linguistic (phonological) qualities of phones they are encoding. To analyze to what extent our vectors capture linguistic properties of phones, we use the QVEC—a tool to quantify and interpret linguistic content of vector space models (Tsvetkov et al., 2015). The tool aligns dimensions in a matrix of learned distributed representations with dimensions of a hand-crafted linguistic matrix. Alignments are induced via correlating columns in the distributed and the linguistic matrices. To analyze the content of the distributed matrix, annotations from the linguistic matrix are projected via the maximally-correlated alignments. We constructed a phonological matrix in which 5,059 rows are IPA phones and 21 columns are boolean indicators of universal phonological properties, e.g. consonant, voiced, labial.5 We the projected annotations from the linguisti"
N16-1161,P10-1040,0,0.0233197,"nd /U/ in “bit” and “book.” Only through linguistic analysis does it become evident that (1) all languages have tense vowels—a feature based on the presence of tense vowels is uninformative and that (2) a significant minority of languages make a distinction between tense and lax vowels—a feature based on whether languages display a minimal difference of this kind would be more useful. 4 Applications of Phonetic Vectors Learned continuous word representations—word vectors—are an important by-product of neural LMs, and these are used as features in numerous NLP applications, including chunking (Turian et al., 2010), part-of-speech tagging (Ling et al., 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al., 2014), and sentiment analysis (Socher et al., 2013; Wang et al., 2015). We evaluate phone vectors learned by Polyglot LMs in two downstream applications that rely on phonology: modeling lexical borrowing (§4.1) and speech synthesis (§4.2). 4.1 Lexical borrowing Lexical borrowing is the adoption of words from another language, that inevitably happens when speakers of different languages communicate for"
N16-1161,P15-1130,0,0.00692841,"Missing"
N16-1161,P15-1113,0,0.0360795,"Missing"
N16-1161,P13-2037,0,\N,Missing
N19-1062,W03-0419,0,\N,Missing
N19-1062,W19-3621,0,\N,Missing
N19-1062,N19-1061,0,\N,Missing
N19-1062,D17-1323,0,\N,Missing
N19-1377,P17-2021,0,0.0921387,"rders. (Zhang et al., 2016) developed a top-down neural architecture for language model that alternates between four LSTM decoders according to given dependency relations. (Ford et al., 2018) proposed a two-stage language model, of which the first stage is a language model that generates templates, and the second stage is a translation model that fills in the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitly generating tree structures (Wang et al., 2018; G¯u et al., 2018). Regarding neural architectures for tree generation in the field of natural language processing, (Dong and Lapata, 2016) and (Yin and Neubig, 2017) use a single decoder with parentfeeding mechanism to generate logical forms and programming codes. (G¯u et al., 2018) applied the doubly-recurrent neural networks of (AlvarezMelis and Jaakkola, 2016) with attention mechan"
N19-1377,W05-0909,0,0.0286169,"Missing"
N19-1377,P16-1004,0,0.0292531,"n the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitly generating tree structures (Wang et al., 2018; G¯u et al., 2018). Regarding neural architectures for tree generation in the field of natural language processing, (Dong and Lapata, 2016) and (Yin and Neubig, 2017) use a single decoder with parentfeeding mechanism to generate logical forms and programming codes. (G¯u et al., 2018) applied the doubly-recurrent neural networks of (AlvarezMelis and Jaakkola, 2016) with attention mechanism to machine translation. Their model uses two decoders, of which one memorizes the ancestors, and the other remembers the siblings. (Wang et al., 2018) also uses two decoders, but one for generating words and the other for generating syntax trees. In the domain of dialog response generation, the use of syntactic structures is under-studied. (Mou"
N19-1377,N16-1024,0,0.024458,"of sentences and finishes the rest in forward and backward directions. (Mou et al., 2016) and (Li and Sun, 2018) start with one or two predicted keywords and generate the rest of sentences in a similar fashion. Others incorporate tree structures without syntactic relations and categories. (Zhou et al., 2018) canonicalizes the dependency structures of sentences into ternary trees, and generate only the words top-down. Yet another line of work aim to model the full syntactic trees. (G¯u et al., 2018) generates phrase structures and part-of-speech tags along with words for machine translation. (Dyer et al., 2016) generates shiftreduce action sequences of context-free grammars in addition to words for language model and parsing. But words are still generated in left-to-right order in their approaches. In the domain of dialog, we believe language generation can benefit from alternative orders, for the same reasons argued earlier. On the other hand, in human conversations, the structure of utterances usually correspond with dialog states (e.g., wh-noun or wh-adverb phrases are more 3762 Proceedings of NAACL-HLT 2019, pages 3762–3771 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Co"
N19-1377,P17-2012,0,0.0184261,"ration through alternative orders. (Zhang et al., 2016) developed a top-down neural architecture for language model that alternates between four LSTM decoders according to given dependency relations. (Ford et al., 2018) proposed a two-stage language model, of which the first stage is a language model that generates templates, and the second stage is a translation model that fills in the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitly generating tree structures (Wang et al., 2018; G¯u et al., 2018). Regarding neural architectures for tree generation in the field of natural language processing, (Dong and Lapata, 2016) and (Yin and Neubig, 2017) use a single decoder with parentfeeding mechanism to generate logical forms and programming codes. (G¯u et al., 2018) applied the doubly-recurrent neural networks of (AlvarezMelis and Jaak"
N19-1377,D18-1324,0,0.0214274,"ed to convert dependency trees to ternary trees, but ignore the type of dependency relations. In other words, they modelled on trees of which the nodes and edges have no labels. The key difference between their approach and ours is that we generate syntax trees with labels, and word choices are also constrained by the labels. 2 3 Related Work Recent years has seen works in language model and generation through alternative orders. (Zhang et al., 2016) developed a top-down neural architecture for language model that alternates between four LSTM decoders according to given dependency relations. (Ford et al., 2018) proposed a two-stage language model, of which the first stage is a language model that generates templates, and the second stage is a translation model that fills in the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitl"
N19-1377,D18-1037,0,0.0302744,"Missing"
N19-1377,P18-1132,0,0.0456788,"Missing"
N19-1377,D18-1071,0,0.0832527,"that human may first generate the abstract representation of the things to say, and then linearize them into sentences (Dell et al., 1999). Therefore, it is appealing to consider language generation in alternative orders. This poses a greater challenge because a mechanism in extra to word generation is needed for deciding the position of each word. Some recent works adopt a syntax-free approach to address this problem. (Mehri and Sigal, 2018) proposed a middleout decoder that starts from the middle of sentences and finishes the rest in forward and backward directions. (Mou et al., 2016) and (Li and Sun, 2018) start with one or two predicted keywords and generate the rest of sentences in a similar fashion. Others incorporate tree structures without syntactic relations and categories. (Zhou et al., 2018) canonicalizes the dependency structures of sentences into ternary trees, and generate only the words top-down. Yet another line of work aim to model the full syntactic trees. (G¯u et al., 2018) generates phrase structures and part-of-speech tags along with words for machine translation. (Dyer et al., 2016) generates shiftreduce action sequences of context-free grammars in addition to words for langu"
N19-1377,W04-1013,0,0.0135672,"Missing"
N19-1377,D16-1230,0,0.0405943,"Missing"
N19-1377,C16-1316,0,0.16744,"cs studies also suggest that human may first generate the abstract representation of the things to say, and then linearize them into sentences (Dell et al., 1999). Therefore, it is appealing to consider language generation in alternative orders. This poses a greater challenge because a mechanism in extra to word generation is needed for deciding the position of each word. Some recent works adopt a syntax-free approach to address this problem. (Mehri and Sigal, 2018) proposed a middleout decoder that starts from the middle of sentences and finishes the rest in forward and backward directions. (Mou et al., 2016) and (Li and Sun, 2018) start with one or two predicted keywords and generate the rest of sentences in a similar fashion. Others incorporate tree structures without syntactic relations and categories. (Zhou et al., 2018) canonicalizes the dependency structures of sentences into ternary trees, and generate only the words top-down. Yet another line of work aim to model the full syntactic trees. (G¯u et al., 2018) generates phrase structures and part-of-speech tags along with words for machine translation. (Dyer et al., 2016) generates shiftreduce action sequences of context-free grammars in addi"
N19-1377,P02-1040,0,0.109529,"Missing"
N19-1377,E17-2025,0,0.0148984,"encoder are shown in the graph. The inputs to Lg is a sequence of labels, rules of parents, and tree depths (only labels are shown). Ls and La are used for predicting the word for DT. Ls and Lg are used for predicting the rule for DT. “RULE: DT” indicates DT will be a leaf node since the number of symbols is 1. In this tree, words are generated in the order: daughter - I - have - a. tion by σ. Ew ∈ R|W |×dw and Er ∈ R|P |×dr are embedding matrices for words, labels, and rules. Aw ∈ Rnw ×dw and Ar ∈ Rnp ×dr are weight matrices (nw , np are the dimensions of input neurons). We use weight tying (Press and Wolf, 2017) to limit the search space for parameters. Word prediction. To decode for wk , we use the the hidden states of surface decoder Ls and ancestor decoder La . If vk is a heir, then ( 1 P (wk |nk , Hk ) = 0 wk = wp(k) wk 6= wp(k) Otherwise, the probability of wk is given by: P (wk |nk , Hk ) = σ(tanh([hs (k); ha (k); c(k)] Aw )EwT ) At decoding time, we impose an additional constraint that wk be a valid word for label nk , to enforce grammaticality. This is estimated from the co-occurrence of wk and nk in the tagged training corpus. We only use those words whose frequency of co-occurrence with the"
N19-1377,N16-1035,0,0.180734,"to generate complete syntactic trees, while be flexible about word generation order at the same time, the use of lexicalized grammar becomes a natural choice. proposed to convert dependency trees to ternary trees, but ignore the type of dependency relations. In other words, they modelled on trees of which the nodes and edges have no labels. The key difference between their approach and ours is that we generate syntax trees with labels, and word choices are also constrained by the labels. 2 3 Related Work Recent years has seen works in language model and generation through alternative orders. (Zhang et al., 2016) developed a top-down neural architecture for language model that alternates between four LSTM decoders according to given dependency relations. (Ford et al., 2018) proposed a two-stage language model, of which the first stage is a language model that generates templates, and the second stage is a translation model that fills in the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017)"
N19-1377,D18-1509,0,0.456155,"model, of which the first stage is a language model that generates templates, and the second stage is a translation model that fills in the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitly generating tree structures (Wang et al., 2018; G¯u et al., 2018). Regarding neural architectures for tree generation in the field of natural language processing, (Dong and Lapata, 2016) and (Yin and Neubig, 2017) use a single decoder with parentfeeding mechanism to generate logical forms and programming codes. (G¯u et al., 2018) applied the doubly-recurrent neural networks of (AlvarezMelis and Jaakkola, 2016) with attention mechanism to machine translation. Their model uses two decoders, of which one memorizes the ancestors, and the other remembers the siblings. (Wang et al., 2018) also uses two decoders, but one for generating words and"
N19-1377,P17-1065,0,0.0206171,"e for language model that alternates between four LSTM decoders according to given dependency relations. (Ford et al., 2018) proposed a two-stage language model, of which the first stage is a language model that generates templates, and the second stage is a translation model that fills in the blanks. Word generation order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitly generating tree structures (Wang et al., 2018; G¯u et al., 2018). Regarding neural architectures for tree generation in the field of natural language processing, (Dong and Lapata, 2016) and (Yin and Neubig, 2017) use a single decoder with parentfeeding mechanism to generate logical forms and programming codes. (G¯u et al., 2018) applied the doubly-recurrent neural networks of (AlvarezMelis and Jaakkola, 2016) with attention mechanism to machine translation. Their model uses two decoder"
N19-1377,P17-1041,0,0.361089,"n order varies with the choice of words that are generated at different stages. Language generation with tree structures has been explored more thoroughly for neural machine translation. (Eriguchi et al., 2017) and (Aharoni and Goldberg, 2017) generate CFG trees in bracketed form. (Wu et al., 2017) generates the sequence of transitions to form dependency trees. More recent works have focused on explicitly generating tree structures (Wang et al., 2018; G¯u et al., 2018). Regarding neural architectures for tree generation in the field of natural language processing, (Dong and Lapata, 2016) and (Yin and Neubig, 2017) use a single decoder with parentfeeding mechanism to generate logical forms and programming codes. (G¯u et al., 2018) applied the doubly-recurrent neural networks of (AlvarezMelis and Jaakkola, 2016) with attention mechanism to machine translation. Their model uses two decoders, of which one memorizes the ancestors, and the other remembers the siblings. (Wang et al., 2018) also uses two decoders, but one for generating words and the other for generating syntax trees. In the domain of dialog response generation, the use of syntactic structures is under-studied. (Mou et al., 2016) and (Li and S"
N19-1377,P18-1205,0,0.0146341,"8 5.64 Depend. 7.70 7.07 7.82 6.99 6.23 Content 6.25 7.03 7.77 7.29 6.62 Standard Dependency Content Frequency Seq2seq 3.682 4.015 4.115 4.088 Ours N/A 3.964 3.865 3.827 Table 3: Perplexities. Table 1: Average absolute positions of different type of words. tion are much less frequent. 1 2 3 4 5 Stand. .0262 .0149 .0147 .0133 .0134 Depend. .0095 .0274 .0116 .0145 .0131 Freq. .0002 .0238 .0156 .0147 .0146 5.3 Table 2: Average frequency of first five words in different generation orders. 5 5.1 Experiments and Analysis Data We evaluate our model for dialog response generation on Persona dataset ((Zhang et al., 2018)). Each person is give a list of persona descriptions in simple sentences, and they are required to converse according to the given persona. We use last 3 utterances for each response as source. We prepend persona descriptions to source. We use global attention over persona descriptions to compute context vectors. During pre-processing, we truncate all trailing punctuations. 5.2 Positional Statistics We measure how early do each type of words appear in different generation orders – standard leftto-right order, dependency-based lexicalization (as in Stanford parser), and content-based lexicaliz"
nallasamy-etal-2008-nineoneone,W03-2118,0,\N,Missing
nallasamy-etal-2008-nineoneone,W06-3711,0,\N,Missing
nallasamy-etal-2008-nineoneone,H01-1007,0,\N,Missing
P13-1018,2005.iwslt-1.8,0,0.0958689,"Missing"
P13-1018,C10-2010,0,0.0480398,"Missing"
P13-1018,J93-2003,0,0.0313653,"Missing"
P13-1018,W06-1008,0,0.429388,"Missing"
P13-1018,P11-2008,0,0.0238097,"Missing"
P13-1018,W12-3153,0,0.264353,"Missing"
P13-1018,N03-1017,0,0.0156335,"Missing"
P13-1018,P08-1113,0,0.141099,"Missing"
P13-1018,P03-1021,0,0.0199252,"Missing"
P13-1018,P02-1040,0,0.105883,"Missing"
P13-1018,W12-3152,0,0.0549925,"Missing"
P13-1018,J03-3002,0,0.404661,"Missing"
P13-1018,N10-1063,0,0.0989051,"Missing"
P13-1018,N12-1079,0,0.229942,"Missing"
P13-1018,C10-1124,0,0.0203108,"Missing"
P13-1018,2005.mtsummit-papers.11,0,0.147745,"Missing"
P13-1018,C96-2141,0,0.295961,"Missing"
P13-1018,I08-2120,0,0.398573,"Missing"
P13-1018,2005.eamt-1.37,0,0.138002,"Missing"
P13-1018,N12-1006,0,0.0533017,"Missing"
P13-1018,N03-1031,0,\N,Missing
P15-2105,P11-1038,0,0.0195409,"ical variants in Twitter (e.g., “cats vs. catz”). While variants tend to have the same meaning as their standardized form, the proposed model does not have this information and will not be able to generalize properly. For instance, if the term ”John” is labelled as keyword in the training set, the model would not be able to extract ”Jooohn” as keyword as it is in a different word form. One way to adThe corpus is submitted as supplementary material. 638 dress this would be using a normalization system either built using hand engineered rules (Gouws et al., 2011) or trained using labelled data (Han and Baldwin, 2011; Chrupała, 2014). However, these systems are generally limited as these need supervision and cannot scale to new data or data in other languages. Instead, we will used unsupervised methods that leverage large amounts of unannotated data. We used two popular methods for this purpose: Brown Clustering and Continuous Word Vectors. uments, such as a news article, contain approximately 3-5 keywords, so extracting 3 keywords per document is a reasonable option. However, this would not work in Twitter, since the number of keywords can be arbitrary small. In fact, many tweets contain less than three"
P15-2105,C10-2042,0,0.0355775,"selecting keywords that are chosen by at least three annotators. We also divided the 1827 tweets into 1000 training samples, 327 development samples and 500 test samples, using the splits as in (Gimpel et al., 2011). Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including ne"
P15-2105,P12-1092,0,0.0163423,"11010, share the first three nodes in the hierarchically 110. Sharing more tree nodes tends to translate into better similarity between words within the clusters. Thus, a word a 11001 cluster is simultaneously in clusters 1, 11, 110, 1100 and 11001, and a feature can be extracted for each cluster. In our experiments, we used the dataset with 1,000 Brown clusters made available by Owoputi et al. (Owoputi et al., 2013)2 . 4.1.2 Continuous Word Vectors Word representations learned from neural language models are another way to learn more generalizable features for words (Collobert et al., 2011; Huang et al., 2012). In these models, a hidden layer is defined that maps words into a continuous vector. The parameters of this hidden layer are estimated by maximizing a goal function, such as the likelihood of each word predicting surrounding words (Mikolov et al., 2013; Ling et al., 2015). In our work, we used the structured skip-ngram goal function proposed in (Ling et al., 2015) and for each word we extracted its respective word vector as features. 5 Experiments Experiments are performed on the annotated dataset using the train, development and test splits defined in Section 3. As baselines, we reported re"
P15-2105,P14-2111,0,0.0188732,"r (e.g., “cats vs. catz”). While variants tend to have the same meaning as their standardized form, the proposed model does not have this information and will not be able to generalize properly. For instance, if the term ”John” is labelled as keyword in the training set, the model would not be able to extract ”Jooohn” as keyword as it is in a different word form. One way to adThe corpus is submitted as supplementary material. 638 dress this would be using a normalization system either built using hand engineered rules (Gouws et al., 2011) or trained using labelled data (Han and Baldwin, 2011; Chrupała, 2014). However, these systems are generally limited as these need supervision and cannot scale to new data or data in other languages. Instead, we will used unsupervised methods that leverage large amounts of unannotated data. We used two popular methods for this purpose: Brown Clustering and Continuous Word Vectors. uments, such as a news article, contain approximately 3-5 keywords, so extracting 3 keywords per document is a reasonable option. However, this would not work in Twitter, since the number of keywords can be arbitrary small. In fact, many tweets contain less than three words, in which c"
P15-2105,W12-3153,0,0.0173412,"tugal {luis.marujo,wang.ling,isabel.trancoso,david.matos,joao.neto}@inesc-id.pt {cdyer,awb,anatoleg,jgc}@cs.cmu.edu, Abstract These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: In this paper, we build a corpus of tweets from Twitter annotated with keywords using crowdsourcing methods. We i"
P15-2105,P13-1018,1,0.272005,"wang.ling,isabel.trancoso,david.matos,joao.neto}@inesc-id.pt {cdyer,awb,anatoleg,jgc}@cs.cmu.edu, Abstract These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: In this paper, we build a corpus of tweets from Twitter annotated with keywords using crowdsourcing methods. We identify key differen"
P15-2105,N15-1142,1,0.664689,"racted for each cluster. In our experiments, we used the dataset with 1,000 Brown clusters made available by Owoputi et al. (Owoputi et al., 2013)2 . 4.1.2 Continuous Word Vectors Word representations learned from neural language models are another way to learn more generalizable features for words (Collobert et al., 2011; Huang et al., 2012). In these models, a hidden layer is defined that maps words into a continuous vector. The parameters of this hidden layer are estimated by maximizing a goal function, such as the likelihood of each word predicting surrounding words (Mikolov et al., 2013; Ling et al., 2015). In our work, we used the structured skip-ngram goal function proposed in (Ling et al., 2015) and for each word we extracted its respective word vector as features. 5 Experiments Experiments are performed on the annotated dataset using the train, development and test splits defined in Section 3. As baselines, we reported results using a TF-IDF, the default MAUI toolkit, and our own implementation of (Li et al., 2010) framework. In all cases the IDF component was computed over a collection of 52 million tweets. Results are reported on rows 1 and 2 in Table 1, respectively. The parameter k (col"
P15-2105,W08-1404,0,0.00839334,"e frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., ¨ ur et al., 2005), 2013), Text Categorization (Ozg¨ Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keyword extraction system (Marujo et al., 2011b; Marujo et al., 2013) for this domain by learning additional features in a"
P15-2105,N13-1039,1,0.474503,"Missing"
P15-2105,D10-1036,0,0.0132353,"l et al., 2011). Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised key"
P15-2105,D11-1141,0,0.0220653,"Missing"
P15-2105,marujo-etal-2012-supervised,1,0.940917,"ihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time Facebook status updates or posts did not contained either hashtags or user mentions. The size of Facebook posts is frequently longer than tweets and has less abbreviations since it is not limited by number of character as in tweets. 3 4 There are many methods that have been proposed for keyword extraction. TF-IDF is one of the simplest approaches for this end (Salt"
P15-2105,N10-1101,0,0.0485415,"ly 26-31, 2015. 2015 Association for Computational Linguistics 2 Related Work formation (e.g., retweet). The annotations of each annotator are combined by selecting keywords that are chosen by at least three annotators. We also divided the 1827 tweets into 1000 training samples, 327 development samples and 500 test samples, using the splits as in (Gimpel et al., 2011). Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and fi"
P15-2105,W04-3252,0,\N,Missing
P15-2105,W11-2210,0,\N,Missing
P15-2105,P11-1039,0,\N,Missing
P15-2105,P11-2008,0,\N,Missing
P15-2105,C12-1047,0,\N,Missing
P18-1080,D18-1549,0,0.0291297,"et al. (2017) learn a representation which is styleagnostic, using adversarial training of the autoencoder. Our work is also closely-related to a problem of paraphrase generation (Madnani and Dorr, 2010; Dong et al., 2017), including methods relying on (phrase-based) back-translation (Ganitkevitch et al., 2011; Ganitkevitch and Callison-Burch, 2014). More recently, Mallinson et al. (2017) and Wieting et al. (2017) showed how neural backtranslation can be used to generate paraphrases. An additional related line of research is machine translation with non-parallel data. Lample et al. (2018) and Artetxe et al. (2018) have proposed sophisticated methods for unsupervised machine translation. These methods could in principle be used for style transfer as well. 7 Measuring the separation of style from content is hard, even for humans. It depends on the task and the context of the utterance within its discourse. Ultimately we must evaluate our style transfer within some down-stream task where our style transfer has its intended use but we achieve the same task completion criteria. Acknowledgments This work was funded by a fellowship from Robert Bosch, and in part by the National Science Foundation through awar"
P18-1080,D16-1120,0,0.0208493,"Missing"
P18-1080,W15-3001,0,0.00627194,"slation quality. The BLEU scores achieved for English–French MT system is 32.52 and for French–English MT system is 31.11; these are strong translation systems. We deliberately chose a European language close to English for which massive amounts of parallel data are available and translation quality is high, to concentrate on the style generation, rather than improving a translation system. 5 Translation data. We trained an English– French neural machine translation system and a French–English back-translation system. We used data from Workshop in Statistical Machine Translation 2015 (WMT15) (Bojar et al., 2015) to train our translation models. We used the French– English data from the Europarl v7 corpus, the news commentary v10 corpus and the common crawl corpus from WMT15. Data were tokenized using the Moses tokenizer (Koehn et al., 2007). Approximately 5.4M English–French parallel sentences were used for training. A vocabulary size of 100K was used to train the translation systems. 5.1 Style Transfer Accuracy We measure the accuracy of style transfer for the generated sentences using a pre-trained style classifier (§2.2.1). The classifier is trained on data that is not used for training our style"
P18-1080,P07-2045,0,0.0111895,"Missing"
P18-1080,D17-1091,0,0.00433603,"style transfer accuracy. In the task of sentiment modification, the BST model preserved meaning worse than the baseline, on the expense of being better at style transfer. We note, however, that the sentiment modification task is not particularly well-suited for evaluating style transfer: it is particularly hard (if not impossible) to disentangle the sentiment of a sentence from its proposi873 et al. (2017) learn a representation which is styleagnostic, using adversarial training of the autoencoder. Our work is also closely-related to a problem of paraphrase generation (Madnani and Dorr, 2010; Dong et al., 2017), including methods relying on (phrase-based) back-translation (Ganitkevitch et al., 2011; Ganitkevitch and Callison-Burch, 2014). More recently, Mallinson et al. (2017) and Wieting et al. (2017) showed how neural backtranslation can be used to generate paraphrases. An additional related line of research is machine translation with non-parallel data. Lample et al. (2018) and Artetxe et al. (2018) have proposed sophisticated methods for unsupervised machine translation. These methods could in principle be used for style transfer as well. 7 Measuring the separation of style from content is hard,"
P18-1080,N18-1169,0,0.402683,") explore two models for style transfer. The first approach uses multiple decoders for each type of style. In the second approach, style embeddings are used to augment the encoded representations, so that only one decoder needs to be learned to generate outputs in different styles. Style transfer is evaluated on scientific paper titles and newspaper tiles, and sentiment in reviews. This method is different from ours in that we use machine translation to create a strong latent state from which multiple decoders can be trained for each style. We also propose a different human evaluation scheme. Li et al. (2018) first extract words or phrases associated with the original style of the sentence, delete them from the original sentence and then replace them with new phrases associated with the target style. They then use a neural model to fluently combine these into a final output. Junbo BST 2.81 2.87 3.18 2.91 3.11 2.62 Table 6: Fluency of the generated sentences. BST outperforms the baseline overall. It is interesting to note that BST generates significantly more fluent longer sentences than the baseline model. Since the average length of sentences was higher for the gender experiment, BST notably outp"
P18-1080,ganitkevitch-callison-burch-2014-multilingual,0,0.0254638,"e baseline, on the expense of being better at style transfer. We note, however, that the sentiment modification task is not particularly well-suited for evaluating style transfer: it is particularly hard (if not impossible) to disentangle the sentiment of a sentence from its proposi873 et al. (2017) learn a representation which is styleagnostic, using adversarial training of the autoencoder. Our work is also closely-related to a problem of paraphrase generation (Madnani and Dorr, 2010; Dong et al., 2017), including methods relying on (phrase-based) back-translation (Ganitkevitch et al., 2011; Ganitkevitch and Callison-Burch, 2014). More recently, Mallinson et al. (2017) and Wieting et al. (2017) showed how neural backtranslation can be used to generate paraphrases. An additional related line of research is machine translation with non-parallel data. Lample et al. (2018) and Artetxe et al. (2018) have proposed sophisticated methods for unsupervised machine translation. These methods could in principle be used for style transfer as well. 7 Measuring the separation of style from content is hard, even for humans. It depends on the task and the context of the utterance within its discourse. Ultimately we must evaluate our s"
P18-1080,P16-1094,0,0.0281791,"fer and in manual evaluation of meaning preservation and fluency. 1 Introduction Intelligent, situation-aware applications must produce naturalistic outputs, lexicalizing the same meaning differently, depending upon the environment. This is particularly relevant for language generation tasks such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy and Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al., 2017; Kiddon et al., 2016). In conversational agents (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2016), for example, modulating the politeness style, to sound natural depending upon a situation: at a party with friends “Shut up! the video is starting!”, or in a professional setting “Please be quiet, the video will begin shortly.”. 866 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 866–876 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sentence is back-translated. Then, separate style-spe"
P18-1080,D11-1108,0,0.0120753,"Missing"
P18-1080,D15-1166,0,0.00638663,"Missing"
P18-1080,J10-3003,0,0.00894614,"he other to improve the style transfer accuracy. In the task of sentiment modification, the BST model preserved meaning worse than the baseline, on the expense of being better at style transfer. We note, however, that the sentiment modification task is not particularly well-suited for evaluating style transfer: it is particularly hard (if not impossible) to disentangle the sentiment of a sentence from its proposi873 et al. (2017) learn a representation which is styleagnostic, using adversarial training of the autoencoder. Our work is also closely-related to a problem of paraphrase generation (Madnani and Dorr, 2010; Dong et al., 2017), including methods relying on (phrase-based) back-translation (Ganitkevitch et al., 2011; Ganitkevitch and Callison-Burch, 2014). More recently, Mallinson et al. (2017) and Wieting et al. (2017) showed how neural backtranslation can be used to generate paraphrases. An additional related line of research is machine translation with non-parallel data. Lample et al. (2018) and Artetxe et al. (2018) have proposed sophisticated methods for unsupervised machine translation. These methods could in principle be used for style transfer as well. 7 Measuring the separation of style f"
P18-1080,E17-1083,0,0.00725164,"nsfer. We note, however, that the sentiment modification task is not particularly well-suited for evaluating style transfer: it is particularly hard (if not impossible) to disentangle the sentiment of a sentence from its proposi873 et al. (2017) learn a representation which is styleagnostic, using adversarial training of the autoencoder. Our work is also closely-related to a problem of paraphrase generation (Madnani and Dorr, 2010; Dong et al., 2017), including methods relying on (phrase-based) back-translation (Ganitkevitch et al., 2011; Ganitkevitch and Callison-Burch, 2014). More recently, Mallinson et al. (2017) and Wieting et al. (2017) showed how neural backtranslation can be used to generate paraphrases. An additional related line of research is machine translation with non-parallel data. Lample et al. (2018) and Artetxe et al. (2018) have proposed sophisticated methods for unsupervised machine translation. These methods could in principle be used for style transfer as well. 7 Measuring the separation of style from content is hard, even for humans. It depends on the task and the context of the utterance within its discourse. Ultimately we must evaluate our style transfer within some down-stream ta"
P18-1080,W15-4302,0,0.0221033,"scenarios, however, when these attributes need to be modulated or obfuscated. For example, some users may wish to preserve their anonymity online, for personal security concerns (Jardine, 2016), or to reduce stereotype threat (Spencer et al., 1999). Modulating authors’ attributes while preserving meaning of sentences can also help generate demographically-balanced training data for a variety of downstream applications. Moreover, prior work has shown that the quality of language identification and POS tagging degrades significantly on African American Vernacular English (Blodgett et al., 2016; Jørgensen et al., 2015); YouTube’s automatic captions have higher error rates for women and speakers from Scotland (Rudinger et al., 2017). Synthesizing balanced training data—using style transfer techniques—is a plausible way to alleviate bias present in existing NLP technologies. We thus focus on two tasks that have practical and social-good applications, and also accurate style classifiers. To position our method with respect to prior work, we employ a third task of sentiment transfer, which was used in two stateof-the-art approaches to style transfer (Hu et al., 2017; Shen et al., 2017). We describe the three ta"
P18-1080,J16-3007,0,0.00777154,"Missing"
P18-1080,D17-1299,0,0.0210476,"rnegie Mellon University, Pittsburgh, PA, USA {sprabhum,ytsvetko,rsalakhu,awb}@cs.cmu.edu Abstract These goals have motivated a considerable amount of recent research efforts focused at “controlled” language generation—aiming at separating the semantic content of what is said from the stylistic dimensions of how it is said. These include approaches relying on heuristic substitutions, deletions, and insertions to modulate demographic properties of a writer (Reddy and Knight, 2016), integrating stylistic and demographic speaker traits in statistical machine translation (Rabinovich et al., 2016; Niu et al., 2017), and deep generative models controlling for a particular stylistic aspect, e.g., politeness (Sennrich et al., 2016), sentiment, or tense (Hu et al., 2017; Shen et al., 2017). The latter approaches to style transfer, while more powerful and flexible than heuristic methods, have yet to show that in addition to transferring style they effectively preserve meaning of input sentences. This paper introduces a novel approach to transferring style of a sentence while better preserving its meaning. We hypothesize—relying on the study of Rabinovich et al. (2016) who showed that author characteristics a"
P18-1080,P02-1040,0,0.121219,"Missing"
P18-1080,D16-1032,0,0.0114178,"te-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency. 1 Introduction Intelligent, situation-aware applications must produce naturalistic outputs, lexicalizing the same meaning differently, depending upon the environment. This is particularly relevant for language generation tasks such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy and Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al., 2017; Kiddon et al., 2016). In conversational agents (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2016), for example, modulating the politeness style, to sound natural depending upon a situation: at a party with friends “Shut up! the video is starting!”, or in a professional setting “Please be quiet, the video will begin shortly.”. 866 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 866–876 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics Figure 1: Style transfer pipeline: to rephrase a"
P18-1080,W16-5603,0,0.112113,"e attention vector to replace unknown characters (UNK) using the copy mechanism in (See et al., 2017). t Lrecon (θ G ; x) = EqE (z|x) [log pgen (x|z)] ¯ s )) exp(score(ht , h at = P ¯ s0 exp(score(ht , hs0 ) (7) where Lrecon is given by Eq. (5), Lclass is given by Eq (2) and λc is a balancing parameter. 869 Style gender political sentiment social categories, types of bias, and in multi-class settings. Gender. In sociolinguistics, gender is known to be one of the most important social categories driving language choice (Eckert and McConnellGinet, 2003; Lakoff and Bucholtz, 2004; Coates, 2015). Reddy and Knight (2016) proposed a heuristic-based method to obfuscate gender of a writer. This method uses statistical association measures to identify gender-salient words and substitute them with synonyms typically of the opposite gender. This simple approach produces highly fluent, meaning-preserving sentences, but does not allow for more general rephrasing of sentence beyond single-word substitutions. In our work, we adopt this task of transferring the author’s gender and adapt it to our experimental settings. We used Reddy and Knight’s (2016) dataset of reviews from Yelp annotated for two genders corresponding"
P18-1080,D11-1054,0,0.00561696,"we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency. 1 Introduction Intelligent, situation-aware applications must produce naturalistic outputs, lexicalizing the same meaning differently, depending upon the environment. This is particularly relevant for language generation tasks such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy and Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al., 2017; Kiddon et al., 2016). In conversational agents (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2016), for example, modulating the politeness style, to sound natural depending upon a situation: at a party with friends “Shut up! the video is starting!”, or in a professional setting “Please be quiet, the video will begin shortly.”. 866 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 866–876 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characterist"
P18-1080,W17-1609,0,0.00971283,"Missing"
P18-1080,P17-1099,0,0.0112191,"t propagation from the discriminators to the generator. Instead, following Hu et al. (2017) we use a continuous approximation based on softmax, along with the temperature parameter which anneals the softmax to the discrete case as training proceeds. To create a continuous representation of the output of the generative model which will be given as an input to the classifier, we use: z = E(x) = qE (z|x) (8) ¯ s are all where ht is the current target state and h source states. While generating sentences, we use the attention vector to replace unknown characters (UNK) using the copy mechanism in (See et al., 2017). t Lrecon (θ G ; x) = EqE (z|x) [log pgen (x|z)] ¯ s )) exp(score(ht , h at = P ¯ s0 exp(score(ht , hs0 ) (7) where Lrecon is given by Eq. (5), Lclass is given by Eq (2) and λc is a balancing parameter. 869 Style gender political sentiment social categories, types of bias, and in multi-class settings. Gender. In sociolinguistics, gender is known to be one of the most important social categories driving language choice (Eckert and McConnellGinet, 2003; Lakoff and Bucholtz, 2004; Coates, 2015). Reddy and Knight (2016) proposed a heuristic-based method to obfuscate gender of a writer. This metho"
P18-1080,N16-1005,0,0.0377154,"have motivated a considerable amount of recent research efforts focused at “controlled” language generation—aiming at separating the semantic content of what is said from the stylistic dimensions of how it is said. These include approaches relying on heuristic substitutions, deletions, and insertions to modulate demographic properties of a writer (Reddy and Knight, 2016), integrating stylistic and demographic speaker traits in statistical machine translation (Rabinovich et al., 2016; Niu et al., 2017), and deep generative models controlling for a particular stylistic aspect, e.g., politeness (Sennrich et al., 2016), sentiment, or tense (Hu et al., 2017; Shen et al., 2017). The latter approaches to style transfer, while more powerful and flexible than heuristic methods, have yet to show that in addition to transferring style they effectively preserve meaning of input sentences. This paper introduces a novel approach to transferring style of a sentence while better preserving its meaning. We hypothesize—relying on the study of Rabinovich et al. (2016) who showed that author characteristics are significantly obfuscated by both manual and automatic machine translation—that grounding in back-translation is a"
P18-1080,N15-1020,0,0.0044291,"both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency. 1 Introduction Intelligent, situation-aware applications must produce naturalistic outputs, lexicalizing the same meaning differently, depending upon the environment. This is particularly relevant for language generation tasks such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy and Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al., 2017; Kiddon et al., 2016). In conversational agents (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2016), for example, modulating the politeness style, to sound natural depending upon a situation: at a party with friends “Shut up! the video is starting!”, or in a professional setting “Please be quiet, the video will begin shortly.”. 866 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 866–876 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sentence is b"
P18-1080,L18-1445,1,0.810618,"lp review, a style transfer model will generate a similar review but with an opposite sentiment. We used Shen et al.’s (2017) corpus of reviews from Yelp. They have followed the standard practice of labeling the reviews with rating of higher than three as positive and less than three as negative. They have also split the reviews to sentences and assumed that the sentence has the same sentiment as the review. Political slant. Our second dataset is comprised of top-level comments on Facebook posts from all 412 current members of the United States Senate and House who have public Facebook pages (Voigt et al., 2018).3 Only top-level comments that directly respond to the post are included. Every comment to a Congressperson is labeled with the Congressperson’s party affiliation: democratic or republican. Topic and sentiment in these comments reveal commenter’s political slant. For example, defund them all, especially when it comes to the illegal immigrants . and thank u james, praying for all the work u do . are republican, whereas on behalf of the hard-working nh public school teachers- thank you ! and we need more strong voices like yours fighting for gun control . Dataset statistics. We summarize below"
P18-1080,E17-1042,0,0.00513337,"ompared to two state-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency. 1 Introduction Intelligent, situation-aware applications must produce naturalistic outputs, lexicalizing the same meaning differently, depending upon the environment. This is particularly relevant for language generation tasks such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy and Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al., 2017; Kiddon et al., 2016). In conversational agents (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2016), for example, modulating the politeness style, to sound natural depending upon a situation: at a party with friends “Shut up! the video is starting!”, or in a professional setting “Please be quiet, the video will begin shortly.”. 866 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 866–876 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics Figure 1: Style transfer p"
P18-1080,D17-1026,0,0.0143475,"t the sentiment modification task is not particularly well-suited for evaluating style transfer: it is particularly hard (if not impossible) to disentangle the sentiment of a sentence from its proposi873 et al. (2017) learn a representation which is styleagnostic, using adversarial training of the autoencoder. Our work is also closely-related to a problem of paraphrase generation (Madnani and Dorr, 2010; Dong et al., 2017), including methods relying on (phrase-based) back-translation (Ganitkevitch et al., 2011; Ganitkevitch and Callison-Burch, 2014). More recently, Mallinson et al. (2017) and Wieting et al. (2017) showed how neural backtranslation can be used to generate paraphrases. An additional related line of research is machine translation with non-parallel data. Lample et al. (2018) and Artetxe et al. (2018) have proposed sophisticated methods for unsupervised machine translation. These methods could in principle be used for style transfer as well. 7 Measuring the separation of style from content is hard, even for humans. It depends on the task and the context of the utterance within its discourse. Ultimately we must evaluate our style transfer within some down-stream task where our style transfe"
P18-1080,W11-2107,0,\N,Missing
P19-1005,D18-1297,0,0.114892,"evious models and combining these models. The idea has been recently revived and extended to generative models and image generation, which also suffers from diversity problem (Tolstikhin et al., 2017; Grover and Ermon, 2018). In computer vision, the state-of-the-art models tend to generate a few categories of objects all the time and ignore the rest, known as the problem of “missing modes”. Boosting has been shown to significantly improve the coverage of image generation models. For language generation, given the prior success with data re-weighting and bootstrap approach (Zhang et al., 2017; Liu et al., 2018), we believe dialog response generation may benefit from boosting as well. In this work, we designed a principled framework of boosting response generation, based on the recently developed theory of boosting generative models. Moreover, we combined boosting with different training and/or decoding paradigms, and empirically show that boosting can invariably improve them, in both quantitative and Neural models have become one of the most important approaches to dialog response generation. However, they still tend to generate the most common and generic responses in the corpus all the time. To ad"
P19-1005,P02-1040,0,0.104222,"f 0.001. All model parameters including word embeddings are randomly initialized between −0.1 and 0.1. In addition to the base models mentioned before, we investigate the combination of RAML and MMI, in which models are trained with RAML and decoded with MMI. 40 (a) BLEU (b) ROUGE-L (c) Cosine Similarity (d) Inertia (e) Number of unigrams (f) Number of trigrams Figure 1: Quantitative results. X-axis is for iteration and y-axis for metrics. The numbers at iteration 1 represent the base models. 4.1 Quantitative Evaluation ber of unigrams. We employ two standard word-overlap-based metrics, BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004). We also performed embedding-based evaluation. We embed the responses using the word averaging approach by (Arora et al., 2016), and measure the cosine similarity of the embeddings of generated responses and true responses. To measure the diversity of the responses, we perform k-means clustering on their embeddings with 10 clusters, and measure the inertia. The larger inertia indicates more diversity. We also show statistics on number of distinct n-grams. As can be seen in Figure 1, the general trend of boosting is that performance drastically improves up to the third mo"
P19-1005,D17-1235,0,0.0681897,"Missing"
P19-1005,P10-1076,0,0.0163178,"ts by penalizing those with overly frequent responses or by emphasizing high-quality responses. (Serban et al., 2017; Zhao et al., 2017) introduced stochastic latent variables into their models to capture discourse information on an inter-utterance level. (Shao et al., 2017) experimented with a novel segment-based training and decoding paradigm to help mitigate the problem of redundancy and contradiction. Yet another type of approach has not been investigated in the literature in the context of response generation – boosting and ensembling, despite having been studied for machine translation (Xiao et al., 2010; Zhang et al., 2017). Being a long established machine learning method (Freund and Schapire, 1997), the process typically involves iteratively training multiple models on reweighted instances according to the error of the previous models and combining these models. The idea has been recently revived and extended to generative models and image generation, which also suffers from diversity problem (Tolstikhin et al., 2017; Grover and Ermon, 2018). In computer vision, the state-of-the-art models tend to generate a few categories of objects all the time and ignore the rest, known as the problem o"
P19-1005,D17-1065,0,0.0661518,"“dullresponse” problem (Li et al., 2015). Various research attempts have been made to improve the diversity of responses generated by sequence-tosequence models. One line of research investigate alternatives to maximum likelihood learning and decoding, which is believed to be the main cause of monotonicity. (Li et al., 2015) employed a decoding objective based on mutual information between contexts and responses; (Li et al., 2017a) used reinforcement learning techniques for training the decoder to generate responses that maximize pre-defined rewards instead of perplexities; (Li et al., 2017b; Xu et al., 2017) adopted adversarial learning, in which a generator is trained to deceive a discriminator that tries to differentiate between generated responses and human responses. Beside changing training and decoding objectives, 38 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 38–43 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics qualitative evaluation. 2 the distance of models’ density estimate and the true distribution is decreasing, that is, Preliminaries DKL (P ||Qt ) ≤ DKL (P ||Qt−1 ) For standard sequence-to"
P19-1005,I17-2046,0,0.020015,"ose with overly frequent responses or by emphasizing high-quality responses. (Serban et al., 2017; Zhao et al., 2017) introduced stochastic latent variables into their models to capture discourse information on an inter-utterance level. (Shao et al., 2017) experimented with a novel segment-based training and decoding paradigm to help mitigate the problem of redundancy and contradiction. Yet another type of approach has not been investigated in the literature in the context of response generation – boosting and ensembling, despite having been studied for machine translation (Xiao et al., 2010; Zhang et al., 2017). Being a long established machine learning method (Freund and Schapire, 1997), the process typically involves iteratively training multiple models on reweighted instances according to the error of the previous models and combining these models. The idea has been recently revived and extended to generative models and image generation, which also suffers from diversity problem (Tolstikhin et al., 2017; Grover and Ermon, 2018). In computer vision, the state-of-the-art models tend to generate a few categories of objects all the time and ignore the rest, known as the problem of “missing modes”. Bo"
P19-1005,P18-1205,0,0.107475,"Missing"
P19-1005,P17-1061,0,0.0444804,"Missing"
P19-1179,D16-1263,0,0.0182219,"fixed during training. Framelevel features yield significantly longer, more sparsely-represented sequences than their text equivalents, and so speech models stand to benefit from learning compressed input representations. Previous works have reduced sequence lengths to make training more tractable through fixed-length downsampling. However, phonemes are variable lengths. Other work has shown promising results using phonemic representations and unsupervised term discovery from variable length sequences in MT and other domains, but as discrete units (Wilkinson et al., 2016; Bansal et al., 2017; Adams et al., 2016; Kamper et al., 2016; Dalmia et al., 2018b; Chung and Glass, 2018). Inspired by these works, we explore higher-level continuous speech embeddings for end-to-end speech translation. Specifically, we use alignment methods to generate phoneme labels, and average consecutive frames with the same label to create phonemelike feature vectors from variable numbers of frames. We use the Fisher Spanish-English and low-resource Mboshi-French datasets. We compare performance on the full Fisher dataset to smaller subsets as in Bansal et al. (2018b). As it is not possible to train a high-performing recogni"
P19-1179,N18-1008,0,0.0885352,"slation input is represented has been shown to impact performance as well as how much data the model requires to train (Sennrich et al., 2016; Salesky et al., 2018; Cherry et al., 2018). The current standard approach for textbased translation is to segment words into subword units as a preprocessing step (Sennrich et al., 2016). Clustering common character sequences increases frequency of units in data and improves generalization to new word forms and rare words. End-to-end speech-to-text models are showing competitive results (Weiss et al., 2017; Bansal et al., 2018a,b; B´erard et al., 2018; Anastasopoulos and Chiang, 2018), but so far have not compared different ways to represent speech input. Unlike text, where discrete trainable embeddings are typically used, speech models typically use continuous features extracted from sliding windows (frames), held fixed during training. Framelevel features yield significantly longer, more sparsely-represented sequences than their text equivalents, and so speech models stand to benefit from learning compressed input representations. Previous works have reduced sequence lengths to make training more tractable through fixed-length downsampling. However, phonemes are variable"
P19-1179,E17-2076,0,0.149675,"Missing"
P19-1179,D18-1461,0,0.0410066,"Missing"
P19-1179,D15-1166,0,0.0306334,"Missing"
P19-1179,W18-1818,1,0.849048,"hours of speech split into training and development sets of 4616 and 500 utterances respectively. This corpus does not have a designated test set, so as in Bansal et al. (2018b) we removed 200 randomly sampled utterances from training for development data and use the designated development set as test. 5 Model Architecture As in Bansal et al. (2018a), we use a sequenceto-sequence architecture inspired by Weiss et al. but modified to train within available resources; specifically, all models may be trained in less than 5 days on one GPU. We build an encoderdecoder model with attention in xnmt (Neubig et al., 2018) with 512 hidden units throughout. We Datasets 5.1 Results Baseline We first compare our model to previously reported end-to-end neural speech translation results on the Fisher Spanish-English task using frame-level features. Table 1 shows our results on the full training set with comparisons to Weiss et al. (2017) and Bansal et al. (2018a). Weiss et al.’s model is 1836 Weiss et al. Bansal et al. Ours dev test dev test dev test BLEU 46.5 47.3 29.5 29.4 32.4 33.7 Table 1: Single task end-to-end speech translation BLEU scores on full dataset. significantly deeper than ours, with 4 more encoder l"
P19-1179,N18-1031,0,0.0474859,"Missing"
P19-1179,2013.iwslt-papers.14,0,0.165851,"for ASR and use the same training procedure, detailed in Appendix A. We use an MLP attention with 1 hidden layer with 128 units and 64-dimensional target embeddings, though we use only 1 decoder hidden layer as opposed to 3 or 4 in previous works. All models use the same target preprocessing as previous work on this dataset: lowercasing and removing punctuation aside from apostrophes. 4 Spanish-English. We use the Fisher Spanish speech corpus (Graff et al.), which consists of 160 hours of telephone speech in multiple Spanish dialects split into 138K utterances, translated via crowdsourcing by Post et al. (2013). We use the standard dev and test sets, each with ∼4k utterances. We do not use dev2. Four reference translations are used to score dev and test. Mboshi-French. Mboshi is a Bantu language spoken in the Republic of Congo with ∼160k speakers. We use the Mboshi-French parallel corpus (Godard et al., 2017) for our low-resource setting, which contains &lt;5 hours of speech split into training and development sets of 4616 and 500 utterances respectively. This corpus does not have a designated test set, so as in Bansal et al. (2018b) we removed 200 randomly sampled utterances from training for developm"
P19-1179,P16-1162,0,0.0676653,"Missing"
P19-1606,D16-1032,0,0.0381036,"rarchical multi task approach to perform structure aware generation. Comprehending Food: Recent times have seen large scale datasets in food, such as Recipe1M (Marin et al., 2018), Food-101 (Bossard et al., 2014).Food recognition (Arora et al., 2019) addresses understanding food from a vision perspective. Salvador et al. (2018) worked on generating cooking instructions by inferring ingredients from an image. Zhou et al. (2018) proposed a method to generate procedure segments for YouCook2 data. In NLP domain, this is studied as generating procedural text by including ingredients as checklists (Kiddon et al., 2016) or treating the recipe as a flow graph (Mori et al., 2014). Our work is at the intersection of two modalities (language and vision) by generating procedural text for recipes from a sequence of images. (Bosselut et al., 2017) worked on reasoning non-mentioned causal effects thereby improving the understanding and generation of procedural text for cooking recipes. This is done by dynamically tracking entities by modeling actions using state transformers. Visual Story Telling: Research at the intersection of language and vision is accelerating with tasks like image captioning (Hossain et al., 20"
P19-1606,P18-1082,0,0.0352561,"ated to phases of procedural text as described in the following sections. Planning while writing content: A major challenge faced by neural text generation (Lu et al., 2018) while generating long sequences is the inability to maintain structure, contravening the coherence of the overall generated text. This aspect was also observed in various tasks like summarization (Liu et al., 2018), story generation (Fan et al., 2019). Pre-selecting content and planning to generate accordingly was explored by Puduppully et al. (2018) and Lukin et al. (2015) in contrast to generate as you proceed paradigm. Fan et al. (2018) adapt a hierarchical approach to generate a premise and then stories to improve coherence and fluency. Yao et al. (2018) experimented with static and dynamic schema to realize the entire storyline before generating. However, in this work we propose a hierarchical multi task approach to perform structure aware generation. Comprehending Food: Recent times have seen large scale datasets in food, such as Recipe1M (Marin et al., 2018), Food-101 (Bossard et al., 2014).Food recognition (Arora et al., 2019) addresses understanding food from a vision perspective. Salvador et al. (2018) worked on gener"
P19-1606,W15-4627,0,0.0252274,"epresentations explicitly. These specialized set of events are correlated to phases of procedural text as described in the following sections. Planning while writing content: A major challenge faced by neural text generation (Lu et al., 2018) while generating long sequences is the inability to maintain structure, contravening the coherence of the overall generated text. This aspect was also observed in various tasks like summarization (Liu et al., 2018), story generation (Fan et al., 2019). Pre-selecting content and planning to generate accordingly was explored by Puduppully et al. (2018) and Lukin et al. (2015) in contrast to generate as you proceed paradigm. Fan et al. (2018) adapt a hierarchical approach to generate a premise and then stories to improve coherence and fluency. Yao et al. (2018) experimented with static and dynamic schema to realize the entire storyline before generating. However, in this work we propose a hierarchical multi task approach to perform structure aware generation. Comprehending Food: Recent times have seen large scale datasets in food, such as Recipe1M (Marin et al., 2018), Food-101 (Bossard et al., 2014).Food recognition (Arora et al., 2019) addresses understanding foo"
P19-1606,P19-1254,0,0.106845,"Missing"
P19-1606,D18-1117,0,0.0934197,"ation of procedural text for cooking recipes. This is done by dynamically tracking entities by modeling actions using state transformers. Visual Story Telling: Research at the intersection of language and vision is accelerating with tasks like image captioning (Hossain et al., 2019), visual question answering (Wu et al., 2017), visual dialog (Das et al., 2017; Mostafazadeh et al., 2017; De Vries et al., 2017; de Vries et al., 2018). ViST (Huang et al., 2016) is a sequential vision to language task demonstrating differences between descriptions in isolation and stories in sequences. Similarly, Gella et al. (2018) created VideoStory dataset from videos on social media with the task of generating a multi-sentence story captions for them. Smilevski et al. (2018) proposed a late fusion based model for ViST challenge. Kim et al. (2018) attained the highest scores on human readability in this task by attending to both global and local contexts. We use this as our baseline model and propose two techniques on top of this baseline to impose structure needed for procedural text. 3 Data Description We identified two how-to blogs from: instructables.comand snapguide.com, comprising stepwise instructions (images a"
P19-1606,mori-etal-2014-flow,0,0.0703972,"ration. Comprehending Food: Recent times have seen large scale datasets in food, such as Recipe1M (Marin et al., 2018), Food-101 (Bossard et al., 2014).Food recognition (Arora et al., 2019) addresses understanding food from a vision perspective. Salvador et al. (2018) worked on generating cooking instructions by inferring ingredients from an image. Zhou et al. (2018) proposed a method to generate procedure segments for YouCook2 data. In NLP domain, this is studied as generating procedural text by including ingredients as checklists (Kiddon et al., 2016) or treating the recipe as a flow graph (Mori et al., 2014). Our work is at the intersection of two modalities (language and vision) by generating procedural text for recipes from a sequence of images. (Bosselut et al., 2017) worked on reasoning non-mentioned causal effects thereby improving the understanding and generation of procedural text for cooking recipes. This is done by dynamically tracking entities by modeling actions using state transformers. Visual Story Telling: Research at the intersection of language and vision is accelerating with tasks like image captioning (Hossain et al., 2019), visual question answering (Wu et al., 2017), visual di"
P19-1606,I17-1047,0,0.0300203,"ersection of two modalities (language and vision) by generating procedural text for recipes from a sequence of images. (Bosselut et al., 2017) worked on reasoning non-mentioned causal effects thereby improving the understanding and generation of procedural text for cooking recipes. This is done by dynamically tracking entities by modeling actions using state transformers. Visual Story Telling: Research at the intersection of language and vision is accelerating with tasks like image captioning (Hossain et al., 2019), visual question answering (Wu et al., 2017), visual dialog (Das et al., 2017; Mostafazadeh et al., 2017; De Vries et al., 2017; de Vries et al., 2018). ViST (Huang et al., 2016) is a sequential vision to language task demonstrating differences between descriptions in isolation and stories in sequences. Similarly, Gella et al. (2018) created VideoStory dataset from videos on social media with the task of generating a multi-sentence story captions for them. Smilevski et al. (2018) proposed a late fusion based model for ViST challenge. Kim et al. (2018) attained the highest scores on human readability in this task by attending to both global and local contexts. We use this as our baseline model an"
P19-1606,N18-1049,0,0.0230175,"work does not deal with multiple phases being a part of a single step). Phases may be ‘listing ingredients’, ‘baking’, ‘garnishing’ etc., The key idea of the SSiD model is to incorporate the sequence of phases in the decoder to impose structure during text generation There are two sources of supervision to drive the model: (1) multimodal dataset M = {I, T} from Section 3, (2) unimodal textual recipes2 U to learn phase sequences. Finer phases are learnt using clustering followed by an FSM. Clustering: K-Means clustering is performed on the sentence embeddings with compositional ngram features (Pagliardini et al., 2018) on each step of the recipe in U. Aligning with our intu6042 2 www.ffts.com/recipes.htm ition, when k is 3, it is observed that these clusters roughly indicate categories of desserts, drinks and main course foods (pizza, quesadilla etc,). However, we need to find out finer categories of the phases corresponding to the phases in the recipes. We use k-means clustering to obtain the categories of these phases. We experimented with different number of phases P as shown in Table 2. For example, let an example recipe comprise of 4 steps i.e, a sequence of 4 images. At this point, each recipe can be"
P19-1606,P02-1040,0,0.104097,"l need: 5 pounds of Preheat oven to 450 F. Mix dry Place a mat on the baking pan chicken wings,  cup all purpose ingredients in the dry ziplock bag. and spread butter evenly on it. flour,  tsp salt, 2 tsp of paprika, melted butter, silicon mat, baking pan. Figure 3: Comparison of generated storyboards for Easy Oven Baked Crispy Chicken Wings Models Glocal SSiD (hard phases) SSiD (hard states) SSiD (soft phases) SSiL (soft phases) BLEU 10.74 11.49 11.93 13.91 16.38 METEOR 0.25 0.24 0.25 0.29 0.31 ROUGE-L 0.31 0.31 0.31 0.32 0.34 Table 3: Evaluation of storyboarding recipes 2. The BLEU score (Papineni et al., 2002) is the highest when P is 40 and S is 100. Fixing these values, we compare the models proposed in Table 3. The models with hard phases and hard states are not as stable as the one with soft phases since backprop affects the impact of the scaffolded phases. Upon manual inspection, a key observation is that for SSiD model, most of the recipes followed a similar structure. It seemed to be conditioned on a global structure learnt from all recipes rather than the current input. However, SSiL model seems to generate recipe that is conditioned on the structure of that particular example. Human Evalua"
W02-0711,A94-1016,1,\N,Missing
W02-0711,C96-1030,1,\N,Missing
W02-0711,frederking-etal-2002-field,1,\N,Missing
W08-1509,H01-1007,0,0.0773097,"Missing"
W08-1509,W03-2118,0,\N,Missing
W08-1509,W06-3711,0,\N,Missing
W08-1509,nallasamy-etal-2008-nineoneone,1,\N,Missing
W09-3950,P01-1066,0,\N,Missing
W09-3950,P08-5002,1,\N,Missing
W10-4318,D08-1040,0,0.0454809,"Missing"
W11-2002,2007.sigdial-1.23,1,\N,Missing
W12-1603,W08-0105,1,0.870302,"Tickle-Degnen and Rosenthal (1990) model provides a starting point by outlining the components of rapport, including the finding that positivity decreases over the course of a relationship. The popularity of this model, however, has not diminished the disproportionate attention that positivity and politeness receive in analyses of rapport (Brown and Levinson, 1978), including in the vast majority of computational approaches to rapport-building in dialogue (Stronks et al., 2002; Johnson and Rizzo, 2004; Bickmore and Picard, 2005; Gratch et al., 2006; McLaren et al., 2007; Cassell et al., 2007; Baker et al., 2008; Bickmore et al., 2011). The creation and expression of rapport is complex, and can also be signaled through negative, or impolite, exchanges (Straehle, 1993; Watts, 2003; SpencerOatey, 2008) that communicate affection and relationship security among intimates who can flout common social norms (Culpeper, 2011; Kienpointner, 1997). However, it is an open question as to whether such rudeness is likely to impress a new student on the first day of class. We must better understand how and when impoliteness and other negative dialogue moves can contribute to the development and expression of the ra"
W12-1603,W07-1906,1,0.946194,"predictive power of our models under various settings, and compare our sparse models with standard non-sparse solutions. Our experiments demonstrate that our models are more accurate than non-sparse models quantitatively, and that teens use unexpected kinds of language to do relationship work such as signaling rapport, but friends and strangers, tutors and tutees, carry out this work in quite different ways from one another. 1 Introduction and Related Work Rapport, the harmonious synchrony between interlocutors, has numerous benefits for a range of dialogue types, including direction giving (Cassell et al., 2007) or contributing to patient recovery (Vowles and Thompson, 2012). In peer tutoring, an educational paradigm in which students of similar ability tutor one another, friendship among tutors and tutees leads to better learning (Gartner et al., 1971). With the burgeoning use of spoken dialogue systems in education, understanding the process by which two humans build and signal rapport during learning becomes a vital step for implementing spoken dialogue systems (SDSs) that can initiate (and, as importantly, maintain) a successful relationship with students over time. However, implementing a tutori"
W12-1603,W11-2003,0,0.061362,"Missing"
W12-1603,P04-1045,0,0.0392667,"ons of Lasso and ridge estimators, and enforces composite penalty. In addition to the model comparisons, by varying the different sizes of feature windows (number of turns in the dialogue history), we empirically show that our proposed sparse log-linear model is flexible, enabling the model to capture long-range dependency. This approach also allows us to extend previous work on speaker state prediction. Although speaker state prediction has attracted much attention in the dialogue research community, most studies have focused on the analysis of anger, frustration, and other classic emotions (Litman and Forbes-Riley, 2004; Liscombe et al., 2005; Devillers and Vidrascu, 2006; Ai et al., 2006; Grimm et al., 2007; Gupta and Nitendra., 2007; Metallinou et al., 2011). Recently, Wang and Hirschberg (2011) proposed a hierarchical model that detects level of interest of speakers in dialogue, using a multistream prediction feedback technique. However, to the best of our knowledge, we are among the first to study the problem of automatic impoliteness and positivity prediction in dialogue. Because our ultimate goal is to build an SDS that responds to users’ language use over time, the features from the user’s target turn"
W12-1603,D11-1139,0,0.0500211,"MLE training method not only produces dense models, but may also overestimates lower frequency features that might be unreliable signals and overfit to a particular set of speakers. In recent studies on speaker state prediction that use lexical features, it has been shown that MLE estimators demonstrate large performance gaps between non-overlapping speaker datasets (Jeon et al., 2010; Wang et al., 2012a). On the other hand, recent studies on `1 /`2 based group penalty for evaluating dialogue systems (Gonz´alez-Brenes and Mostow, 2011), structured sparsity for linguistic structure prediction (Martins et al., 2011), and discovering historical legal opinions with a sparse mixed-effects latent variable model (Wang et al., 2012b) have all shown concrete benefits of modeling sparsity in languagerelated predictive tasks. We therefore apply sparsitysensitive models that can prevent less frequent features from overfitting. We start with the `1 regularized Lasso (Tibshirani, 1994) model, since, compared to other covariance matrix based sparse models, such as sparse Principal Component Analysis (PCA) and sparse Canonical Correlation Analysis (CCA), the Lasso model is straightforward and requires fewer computing"
W12-1603,W11-2018,1,0.838614,"gue history), we empirically show that our proposed sparse log-linear model is flexible, enabling the model to capture long-range dependency. This approach also allows us to extend previous work on speaker state prediction. Although speaker state prediction has attracted much attention in the dialogue research community, most studies have focused on the analysis of anger, frustration, and other classic emotions (Litman and Forbes-Riley, 2004; Liscombe et al., 2005; Devillers and Vidrascu, 2006; Ai et al., 2006; Grimm et al., 2007; Gupta and Nitendra., 2007; Metallinou et al., 2011). Recently, Wang and Hirschberg (2011) proposed a hierarchical model that detects level of interest of speakers in dialogue, using a multistream prediction feedback technique. However, to the best of our knowledge, we are among the first to study the problem of automatic impoliteness and positivity prediction in dialogue. Because our ultimate goal is to build an SDS that responds to users’ language use over time, the features from the user’s target turn that the model is aiming to predict are not observable, which renders the task more difficult than previous speaker state detection tasks. Our main contributions are three-fold: (1"
W12-1603,C10-1129,1,0.79665,"actually explainin urself..”) (Kienpointner, 1997). 3.2 Automated Features To compare the performance between what could be automatically extracted from dialogue and hand annotation, we extracted 2,872 unigram and 12,016 bigram features from the text corpus. Using the Stanford PoS tagger4 with its attached model, we also extracted 46 common part-of-speech tags from the text. In addition to the above lexical and syntactic features, we automatically extracted the capitalization features[Ca] that have at least one full word (eg. “CALM DOWN”) (Chovanec, 2009). Since a recent text prediction task (Wang and McKeown, 2010) observed benefits from modeling punctuation features[P], we extracted the expressive punctuation that included at least one exclamation point or more than one question-mark (eg. “I don’t get it?!??!”) (Crystal, 2001). We used a smiley dictionary5 to extract the emoticons[E] that convey emotional states (S´anchez et al., 2006) from text. 4 Sparse Log-Linear Models We formulate our impoliteness and positivity prediction problems as binary classifications. To do this, ˆ First, we we estimate the label yˆt ∼ Bernoulli(θ). introduce a standard log-linear parametrization6 to our predictive tasks: P"
W12-1603,P12-1078,1,0.839762,"atively rarely in data of this sort. Training discriminative models with maximum likelihood estimators (MLE) on such datasets usually results in assigning too much weight on less frequent signals. This standard MLE training method not only produces dense models, but may also overestimates lower frequency features that might be unreliable signals and overfit to a particular set of speakers. In recent studies on speaker state prediction that use lexical features, it has been shown that MLE estimators demonstrate large performance gaps between non-overlapping speaker datasets (Jeon et al., 2010; Wang et al., 2012a). On the other hand, recent studies on `1 /`2 based group penalty for evaluating dialogue systems (Gonz´alez-Brenes and Mostow, 2011), structured sparsity for linguistic structure prediction (Martins et al., 2011), and discovering historical legal opinions with a sparse mixed-effects latent variable model (Wang et al., 2012b) have all shown concrete benefits of modeling sparsity in languagerelated predictive tasks. We therefore apply sparsitysensitive models that can prevent less frequent features from overfitting. We start with the `1 regularized Lasso (Tibshirani, 1994) model, since, compa"
W12-1810,N07-4008,0,\N,Missing
W13-4007,W08-0105,1,0.712529,"extracted for each of the split channel recordings. The “INTERSPEECH 2010 Paralinguistic Challenge Feature Set” in the openSMILE toolkit (Schuller et al., 2012) was used as our basic acoustic feature set. For spectral features, Mel Spectrum and LSP were excluded due to the possible overlap with 3.3 Dyadic Features (DF) All of the features discussed above are low-level acoustic and visual features, extracted with 53 respect to individual participants. While individual behavior may index friendship state, we posit that patterns of interaction will be more effective. For example, prior research (Baker et al., 2008) suggests that the number and length of conversational turns (Cassell et al., 2007), presence of mutual smiles and non-mutual smiles (Prepin et al., 2012), mutual gaze and nonmutual gaze (Nakano et al., 2010), as well as posture shifting (Cassell, et al., 2001; TickleDegnen & Rosenthal, 1990), are important features to investigate in dyadic data. While other features such as gestures and mutual pitch shift may also play a role in indexing relationship state, these are not yet a part of the dyadic features we address here. 3.3.1 Number and Average Conversational Turns Length OKAO vision toolkit"
W13-4007,W07-1906,1,0.911717,"ases. In fact, Ogan et al. (2012) gave evidence that the use of playful rudeness between friends during peer tutoring correlates to greater learning. This leads to an associated challenge of spoken dialogue system development: creating systems that can develop social ties, and increase rapport with the user over repeated interactions to maximize beneficial outcomes. While little work has addressed automatic detection, some prior work has addressed the problem of emitting signals to build rapport in dialogue and agent systems (Stronks et al., 2002; Bickmore & Picard, 2005; Gratch et al., 2006; Cassell et al., 2007; Bickmore et al., 2011), and we turn to this research for what cues might be important in rapport. The majority of this prior work, however, has addressed harmony – or instant rapport – rather than rapport over time. For those systems that have addressed friendship or the growth of rapport, most commonly the number of interactions has been used as a meter of relationship progression, instigating changes in the dialogue system as the social odometer scrolls onward (Cassell & Bickmore, 2003; Vardoulakis et al., 2012). Counting the times a dyad has interacted is a crude approximation of a relati"
W13-4007,P03-1070,1,0.490091,"described above were all significantly different between friends and strangers (although gaze down was simply a trend, at p<.08). The following features were also important to the model, but did not show significance in the ANOVA, perhaps because of their sparse nature in our data. MFCC (Mel-Frequency Cepstral Coefficients) was associated with strangers and the similar audio feature of voicing was associated with friends. Both of these features have been described as approximating speech style – voicing, for example, may indicate more backchannels, such as “uh huh” and “hmm” (Ward, 2006). In Nakano et al. (2003), listener gaze at the speaker is interpreted as evidence of nonunderstanding. We found similar results whereby non-friends were more likely to engage in nonmutual gaze – looking at one another when the other person was not looking back. Mutual smile did not distinguish between friends and nonfriends, while non-mutual smile, on the other hand, provided indicative strength, in spite of its sparse nature, for friendship. This may relate to our prior work (Ogan et al., 2012) which found significant teasing and other behavior whereby friends appear comfortable enjoying themselves at the expense of"
W13-4007,W12-1603,1,0.83419,"Missing"
W13-4065,W13-4065,1,0.108389,"Missing"
W13-4065,P03-1031,0,0.0719917,"chedule information to present to the user. Most commercial systems use hand-crafted heuristics for state tracking, selecting the SLU result with the highest confidence score, and discarding alternatives. In contrast, statistical approaches compute scores for many hypotheses for the dialog state (Figure 1). By exploiting correlations between turns and information from external data sources – such as maps, bus timetables, or models of past dialogs – statistical approaches can overcome some SLU errors. Numerous techniques for dialog state tracking have been proposed, including heuristic scores (Higashinaka et al., 2003), Bayesian networks (Paek and Horvitz, 2000; Williams and Young, 2007), kernel density estimators (Ma et al., 2012), and discriminative models (Bohus and Rudnicky, 2006). Techniques have been fielded which scale to realistically sized dialog problems and operate in real time (Young et al., 2010; Thomson and Young, 2010; Williams, 2010; Mehta et al., 2010). In end-to-end dialog systems, dialog state tracking has been shown to improve overall system performance (Young et al., 2010; Thomson and Young, 2010). Despite this progress, direct comparisons between methods have not been possible because"
W13-4065,W12-1624,1,0.737828,"g the SLU result with the highest confidence score, and discarding alternatives. In contrast, statistical approaches compute scores for many hypotheses for the dialog state (Figure 1). By exploiting correlations between turns and information from external data sources – such as maps, bus timetables, or models of past dialogs – statistical approaches can overcome some SLU errors. Numerous techniques for dialog state tracking have been proposed, including heuristic scores (Higashinaka et al., 2003), Bayesian networks (Paek and Horvitz, 2000; Williams and Young, 2007), kernel density estimators (Ma et al., 2012), and discriminative models (Bohus and Rudnicky, 2006). Techniques have been fielded which scale to realistically sized dialog problems and operate in real time (Young et al., 2010; Thomson and Young, 2010; Williams, 2010; Mehta et al., 2010). In end-to-end dialog systems, dialog state tracking has been shown to improve overall system performance (Young et al., 2010; Thomson and Young, 2010). Despite this progress, direct comparisons between methods have not been possible because past studies use different domains and system components, for speech recognition, spoken language understanding, di"
W13-4065,W10-4306,1,0.810327,"on from external data sources – such as maps, bus timetables, or models of past dialogs – statistical approaches can overcome some SLU errors. Numerous techniques for dialog state tracking have been proposed, including heuristic scores (Higashinaka et al., 2003), Bayesian networks (Paek and Horvitz, 2000; Williams and Young, 2007), kernel density estimators (Ma et al., 2012), and discriminative models (Bohus and Rudnicky, 2006). Techniques have been fielded which scale to realistically sized dialog problems and operate in real time (Young et al., 2010; Thomson and Young, 2010; Williams, 2010; Mehta et al., 2010). In end-to-end dialog systems, dialog state tracking has been shown to improve overall system performance (Young et al., 2010; Thomson and Young, 2010). Despite this progress, direct comparisons between methods have not been possible because past studies use different domains and system components, for speech recognition, spoken language understanding, dialog control, etc. Moreover, there is little agreement on how to evaluate dialog state tracking. Together these issues limit progress in this research area. The Dialog State Tracking Challenge (DSTC) provides a first common testbed and evalua"
W14-3356,W10-0710,0,0.132945,"Missing"
W14-3356,2005.iwslt-1.8,0,0.0947835,"Missing"
W14-3356,P05-1074,0,0.156435,"Missing"
W14-3356,P11-1061,0,0.0567147,"Missing"
W14-3356,P91-1023,0,0.724078,"Missing"
W14-3356,1992.tmi-1.9,0,0.36141,"Missing"
W14-3356,W12-3134,0,0.0268465,"Missing"
W14-3356,2012.amta-papers.7,0,0.0943115,"Missing"
W14-3356,W11-2123,0,0.0200324,"Missing"
W14-3356,W12-3153,0,0.0696685,"Missing"
W14-3356,P07-2045,1,0.0120714,"Missing"
W14-3356,P13-1018,1,0.81692,"Missing"
W14-3356,I11-1125,0,0.0609802,"Missing"
W14-3356,J05-4003,0,0.186489,"Missing"
W14-3356,P03-1058,0,0.0964326,"Missing"
W14-3356,P03-1021,0,0.0602179,"Missing"
W14-3356,P02-1040,0,0.108513,"Missing"
W14-3356,W12-3152,0,0.0723752,"Missing"
W14-3356,J03-3002,0,0.372304,"Missing"
W14-3356,N10-1113,0,0.0352934,"Missing"
W14-3356,N10-1063,0,0.0896412,"Missing"
W14-3356,P11-1122,0,0.0870956,"Missing"
W14-3356,J93-1004,0,\N,Missing
W14-3356,W13-2201,0,\N,Missing
W15-4606,C08-2003,0,0.0262797,"ng due to the degradation in quality of the dialog when overlapping speech is produced in the wrong place. For this, a traditional SDS often uses a simplified turn-taking model with rigid turn taking. They only respond when users have finished speaking. Thus past research has mostly focused on end-of-turn detection, finding the end of the user utterance as quickly as possible while minimizing the chance of wrongly interrupting the users. We refer here to the interruption issue as false cut-ins (FCs). Recent research in incremental dialog processing promises more flexible turn-taking behavior (Atterer et al., 2008; Breslin et al., 2013). Here, the automatic speech recognizer (ASR) and natural language understanding (NLU) incrementally 2 Related Work and Limitations This work is closely related to end-of-turn detection and incremental processing (IP) dialog systems. There are several methods for detecting the endof-turn. Raux (2008) built a decision tree for final pause duration using ASR and NLU features. At runtime, the system first dynamically chooses the final pause duration threshold based on the dialog state and then predicts end-of-turn if final pause duration is longer than that threshold. Other"
W15-4606,W13-4065,1,0.920039,"Missing"
W15-4606,W08-0101,1,0.800182,"n speed of response (Raux and Eske42 Proceedings of the SIGDIAL 2015 Conference, pages 42–50, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics responding, as shown on Figure 1: nazi, 2009). Another approach examined prosodic and semantic features such as pitch and speaking rate in human-human conversation for turn-yielding cues (Gravano, 2009). The key limitation of those methods is that the decision made by the end-of-turn detector is treated as a “hard” decision, obliging developers to compromise in a tradeoff between response latency and FC rate (Raux and Eskenazi, 2008). Although adding more complex prosodic and semantic features can improve the performance of the detector, it also increases computation cost and requires significant knowledge of the SDS, which can limit the accessibility for non-expert developers. For IP, Kim (2014) has demonstrated the possibility of learning turn-taking from human dialogs using inverse reinforcement learning. Other work has focused on incremental NLU (DeVault et al., 2009), showing that the correct interpretation of users’ meaning can be predicted before end-of-turn. Another topic is modeling user and system barge-in. Self"
W15-4606,N09-1071,1,0.902828,"Missing"
W15-4606,W13-4063,0,0.0636466,"Missing"
W15-4606,W09-3902,0,0.283743,"Missing"
W15-4630,2007.sigdial-1.23,1,0.765828,"2013 to the REAL workshop on June 21, 2014, and beyond, this paper traces how REAL was managed, the proposals we received, what happened at the workshop, what follow up we have had and how we measure success. Introduction 2 Motivation Speech and spoken dialog researchers often note that whereas industry has access to a wealth of ecologically valid speech data, the academic community lags far behind. The lag in quantity of data can impede research on system evaluation and in training the machine learning (ML) system components. This chasm can be filled by using recruited subjects. But studies (Ai et al., 2007) have found that the resulting data does not resemble real user data. Paid users follow the rules, but are usuThis paper describes the REAL Challenge (REAL), including the motivations for the challenge and preliminary results from the first year and prospects for the near future. The ultimate goal of REAL is to bring about a steady stream of data from real users talking to spoken dialogue systems, that can be used for academic research. The immediate goal of the first year of REAL is to bring together high school and undergraduate students, who have fresh ideas of how people will 209 Proceedin"
W16-3608,W15-4652,1,0.642075,"t al., 2014)) and asking the user to explain missing words. (Schmidt et al., 2015). In this paper, we propose a set of strategies that actively deal with both user engagement and system response appropriateness. 2 3 Related Work Many experiments have shown that an agent reacting to a user’s behavior or internal state leads to better user experience. In an in-car navigation setting, a system that reacts to the user’s cognitive load was shown to have better user experience (Kousidis et al., 2014). In a direction giving setting, a system that reacts to user’s attention was shown to be preferred (Yu et al., 2015a). In a tutoring setting, a system that reacts to the user’s disengagement resulted in better learning gain (ForbesRiley and Litman, 2012). In task-oriented systems users have a concrete reason to interact with the system. However, in a non-task-oriented setting, user engagement is the sole reason for the user to stay in the conversation, making it an ideal situation for engagement study. In this paper, we focus on making the system reactive to user engagement in real time in an everyday chatting setting. In human-human conversations, engagement has been studied extensively. Engagement is con"
W16-3608,P12-3007,0,0.019759,"Missing"
W16-3608,W12-1630,0,0.0338049,"Missing"
W16-3608,C14-1088,0,0.0189675,"xpert in a Wizard-of-Oz setting, it is the first step towards a fully automated engagement reactive system. Previously very little research addressed reactive systems due to the difficulty of modeling the users and the lack of audiovisual data. We also make the audiovisual data along with the annotations available. ily, making users have the interest to continue is critical. A lot of conversational strategies have been proposed in previous work to avoid generating incoherent utterances in non-task-oriented conversations, such as introducing topics, (e.g. “Let’s talk about favorite foods!” in (Higashinaka et al., 2014)) and asking the user to explain missing words. (Schmidt et al., 2015). In this paper, we propose a set of strategies that actively deal with both user engagement and system response appropriateness. 2 3 Related Work Many experiments have shown that an agent reacting to a user’s behavior or internal state leads to better user experience. In an in-car navigation setting, a system that reacts to the user’s cognitive load was shown to have better user experience (Kousidis et al., 2014). In a direction giving setting, a system that reacts to user’s attention was shown to be preferred (Yu et al., 2"
W16-3608,D11-1054,0,0.116176,"Missing"
W16-3647,poggi-etal-2010-types,0,0.0462645,"Missing"
W16-3647,D13-1066,0,0.006697,"Missing"
W16-3647,W12-1603,1,0.81165,"an online community by leveraging cross-entropy value, or the deviation of word sequences predicted by the language model and their usage by the user. Another kind of social norm violation was examined by (Riloff et al., 2013), who developed a classifier to identify a specific type of sarcasm in tweets. They utilized a bootstrapping algorithm to automatically extract lists of positive sentiment phrases and negative situation phrases from given sarcastic tweets, which were in turn leveraged to recognize sarcasm in an SVM classifier. Experimental results showed the adequacy of their approach. (Wang et al., 2012) investigated the different social functions of language as used by friends or strangers in teen peer-tutoring dialogs. This work was able to successfully predict impoliteness and positivity in the next turn of the dialog. Their success with both annotated and automatically extracted features suggests that a dialog system will be able to employ similar analyses to signal relationships with users. Other work, such as (Danescu-Niculescu-Mizil et al., 2013a) has developed computational frameworks to automatically classify requests along a scale of politeness. Politeness strategies such as request"
W16-3647,D15-1199,0,0.015607,"l., 2010), and towards more accurate computational models of human interaction that will need to underlie those new kinds of intelligent tutors. Dialog systems that can recognize and use conversational strategies such as self-disclosure, reference to shared experience, and violation of social norms, are also part of a new genre of dialog system that departs from the rigid repetitive natural language generation templates of the olden days, and that can learn to speak with style. It is conceivable that contemporary corpus-based approaches to NLG that introduce stylistic variation into a dialog (Wen et al., 2015) may one day learn on the user’s own conversational style, and entrain to it. In a system like that, real-time recognition of conversational strategies like that demonstrated here could play an essential role. References Arthur Aron, Edward Melinat, Elaine N Aron, Robert Darrin Vallone, and Renee J Bator. 1997. The experimental generation of interpersonal closeness: A procedure and some preliminary findings. Personality and Social Psychology Bulletin, 23(4):363–377. Albert Bandura. 1994. Self-efficacy. Wiley Online Library. 3 sociallyawarerobotassistant.net 389 http://articulab.hcii.cs.cmu.edu"
W16-3647,W13-4007,1,0.0622007,"nomena, which relies on verbal, visual and vocal content to automatically recognize conversational strategies. Our models are trained on a peer tutoring corpus, which gives us the opportunity to look at conversational strategies as they are used in both a task and social context. 3 Study Context Reciprocal peer tutoring data was collected from 12 American English-speaking dyads (6 friends and 6 strangers; 6 boys and 6 girls), with a mean age of 13 years, who interacted for 5 hourly sessions over as many weeks (a total of 60 sessions, and 5400 minutes of data), tutoring one another in algebra (Yu et al., 2013). Each session began with a period of getting to know one another, after which the first tutoring period started, followed by another small social interlude, a second tutoring period with role reversal between the tutor and tutee, and then the final social time. Prior work demonstrates that peer tutoring is an effective paradigm that results in student learning (Sharpley et al., 1983), making this an effective context to study dyadic interaction with a concrete task outcome. Our student-student data, in addition, demonstrates that a tremendous amount of rapport-building takes place during the"
W16-3647,W13-4032,0,\N,Missing
W16-3647,W16-3628,1,\N,Missing
W16-3649,P12-3007,0,0.00946686,"ction Non-task-oriented conversational systems do not have a stated goal to work towards. Nevertheless, they are useful for many purposes, such as keeping elderly people company and helping second language learners improve conversation and communication skills. More importantly, they can be combined with task-oriented systems to act as a transition smoother or a rapport builder for complex tasks that require user cooperation. There are a variety of methods to generate responses for nontask-oriented systems, such as machine translation (Ritter et al., 2011), retrieval-based response selection (Banchs and Li, 2012), and sequence-tosequence recurrent neural network (Vinyals and Le, 2015). However, these systems still produce utterances that are incoherent or inappropriate from time to time. To tackle this problem, we propose a set of conversational strategies, such as switching topics, to avoid possible inappropriate responses (breakdowns). After we have a set of strategies, which strategy to perform according to Reinforcement learning was introduced to the dialog community two decades ago (Biermann and Long, 1996) and has mainly been used in task-oriented systems (Singh et al., 1999). Researchers have p"
W16-3649,C14-1088,0,0.0167215,"omputable. Perplexity of the language model is an automatically computable metric but is hard to interpret (Vinyals and Le, 2015). In this paper, we propose three metrics: turn-level appropriateness, conversational depth and information gain, which access both the local and the global conversation quality of a non-task-oriented conversation. Information Related Work Many generic conversational strategies have been proposed in previous work to avoid generating incoherent utterances in non-task-oriented conversations, such as introducing new topics (e.g. “Let’s talk about favorite foods!” ) in (Higashinaka et al., 2014), asking the user to explain missing words (e.g. “What is SIGDIAL?”) (Maria Schmidt and Waibel, 2015). In this paper, we propose a set of generic strategies that are inspired by previous work, and test their usability on human users. No researcher has investigated thoroughly on which strategy to use in different conversational contexts. Compared to task-oriented dialog systems, non1 www.cmuticktock.org 405 when the posterior probability of the generated response is higher than a certain threshold. gain is automatically quantifiable. We use supervised machine learning methods to built automatic"
W16-3649,P98-2219,0,0.189651,"ign a dialog system that takes actions to maximize some measure of system reward, such as task completion rate or dialog length. The difficulty of such modeling lies in the state representation. Representing the dialog by the entire history is often neither feasible nor 404 Proceedings of the SIGDIAL 2016 Conference, pages 404–412, c Los Angeles, USA, 13-15 September 2016. 2016 Association for Computational Linguistics conceptually useful, and the so-called belief state approach is not possible, since we do not even know what features are required to represent the belief state. Previous work (Walker et al., 1998) has largely dealt with this issue by imposing prior limitations on the features used to represent the approximate state. In this paper, instead of focusing on task-oriented systems, we apply reinforcement learning to design a policy to select designed conversation strategies in a non-task-oriented dialog systems. Unlike task-oriented dialog systems, non-task-oriented systems have no specific goal that guides the interaction. Consequently, evaluation metrics that are traditionally used for reward design, such as task completion rate, are no longer appropriate. The state design in reinforcement"
W16-3649,W10-4339,0,0.0220514,"e more varied conversation history, which are thus harder to formulate as a mathematical problem. In this work, we propose a method to use statistical findings in conversational study to constrain the dialog history space and to use reinforcement learning for statistical policy learning in a non-task-oriented conversation setting. To date, reinforcement learning is mainly used for learning dialogue policies for slot-filling taskoriented applications such as bus information search (Lee and Eskenazi, 2012), restaurant recommendations (Jurˇc´ıcˇ ek et al., 2012), and sightseeing recommendations (Misu et al., 2010). Reinforcement learning is also used for some more complex systems, such as learning negotiation policies (Georgila and Traum, 2011) and tutoring (Chi et al., 2011). Reinforcement learning is also used in question-answering systems (Misu et al., 2012). Question-answering systems are very similar to non-task-oriented systems except that they do not consider dialog context in generating responses. They have pre-existing questions that the user is expected to go through, which limits the content space of the dialog. Reinforcement learning has also been applied to a non-task-oriented system for d"
W16-3649,W12-1611,0,0.0134265,"ing for statistical policy learning in a non-task-oriented conversation setting. To date, reinforcement learning is mainly used for learning dialogue policies for slot-filling taskoriented applications such as bus information search (Lee and Eskenazi, 2012), restaurant recommendations (Jurˇc´ıcˇ ek et al., 2012), and sightseeing recommendations (Misu et al., 2010). Reinforcement learning is also used for some more complex systems, such as learning negotiation policies (Georgila and Traum, 2011) and tutoring (Chi et al., 2011). Reinforcement learning is also used in question-answering systems (Misu et al., 2012). Question-answering systems are very similar to non-task-oriented systems except that they do not consider dialog context in generating responses. They have pre-existing questions that the user is expected to go through, which limits the content space of the dialog. Reinforcement learning has also been applied to a non-task-oriented system for deciding which sub-system to choose to generate a system utterance (Shibata et al., 2014). In this paper, we used reinforcement learning to learn a policy to sequentially decide which conversational strategy to use to avoid possible system breakdowns. T"
W16-3649,D11-1054,0,0.00767479,"he local and global quality of the conversation. 1 Introduction Non-task-oriented conversational systems do not have a stated goal to work towards. Nevertheless, they are useful for many purposes, such as keeping elderly people company and helping second language learners improve conversation and communication skills. More importantly, they can be combined with task-oriented systems to act as a transition smoother or a rapport builder for complex tasks that require user cooperation. There are a variety of methods to generate responses for nontask-oriented systems, such as machine translation (Ritter et al., 2011), retrieval-based response selection (Banchs and Li, 2012), and sequence-tosequence recurrent neural network (Vinyals and Le, 2015). However, these systems still produce utterances that are incoherent or inappropriate from time to time. To tackle this problem, we propose a set of conversational strategies, such as switching topics, to avoid possible inappropriate responses (breakdowns). After we have a set of strategies, which strategy to perform according to Reinforcement learning was introduced to the dialog community two decades ago (Biermann and Long, 1996) and has mainly been used in task"
W17-2908,W12-2105,0,0.377903,"the aforementioned theoretical principles and their correlation with influence. We attempt to extend the prior computational efforts on social influence, by using insights from the Social Sciences. Influence can be defined and operationalized in different settings. A majority of computational work on interpersonal influence focuses on the analysis of social networks that employ probabilistic methods to analyze and maximize the flow of influence in these networks. There have been recent efforts in understanding influence in social media conversations with the aim of finding influential people (Biran et al., 2012; Quercia et al., 2011; Rosenthal and McKeown, 2016). We investigate what we can learn from language about influence from informal interactions where there is no explicit motivation to influence others. We look at user interactions in a social networking website for people interested in knitting, weaving, crocheting and fiber arts called Ravelry 1 , which is a large DIY online community with tens of thousands of sub-communities within it. In the following sections we talk about prior work on social influence and the approaches taken to study it. We describe our dataset and the task setup that"
W17-2908,W16-5604,0,0.173046,"and their correlation with influence. We attempt to extend the prior computational efforts on social influence, by using insights from the Social Sciences. Influence can be defined and operationalized in different settings. A majority of computational work on interpersonal influence focuses on the analysis of social networks that employ probabilistic methods to analyze and maximize the flow of influence in these networks. There have been recent efforts in understanding influence in social media conversations with the aim of finding influential people (Biran et al., 2012; Quercia et al., 2011; Rosenthal and McKeown, 2016). We investigate what we can learn from language about influence from informal interactions where there is no explicit motivation to influence others. We look at user interactions in a social networking website for people interested in knitting, weaving, crocheting and fiber arts called Ravelry 1 , which is a large DIY online community with tens of thousands of sub-communities within it. In the following sections we talk about prior work on social influence and the approaches taken to study it. We describe our dataset and the task setup that allows us to measure influence. We give an overview"
W17-2908,D16-1178,0,0.109749,"heir study of social influence research, Cialdini and Goldstein (2002) identify six basic principles that govern how one person might influence another. They are: liking, reciprocation, consistency, scarcity, social validation and authority. These principles control how influence plays out in different social situations. The above mentioned principles constitute a solid basis for most of the work in this domain. Prior computational approaches for understanding influence, have primarily focused on influence as an explicit intention of the people involved (Tan et al., 2016a; Biran et al., 2012; Sim et al., 2016). ∗ Institute for Software Research Carnegie Mellon University Pittsburgh, PA 15213. 2 Related Work There has been a substantial amount of computational work on modeling and detecting influence that can be broadly divided in two categories: ‘In1 Both authors contributed equally to this work. https://www.ravelry.com/ 53 Proceedings of the Second Workshop on Natural Language Processing and Computational Social Science, pages 53–62, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics seed nodes) that would maximize the diffusion or the spread of influence. Chen et"
W18-3211,P13-2037,0,0.0481614,"Missing"
W18-3211,C82-1023,0,0.604902,"2000; Bullock and Toribio, 2009). Typically one language (the matrix language) provides the grammatical structure for CS text and words from another language (the embedded language) are inserted. However, CS data is challenging to obtain because this phenomenon is usually observed in informal settings. Data obtained from online sources is often noisy because of spelling, script, morphological, and grammatical variations. ∗ 2 Related Work The increased reach of Internet and social media has led to proliferation of noisy CS data where earlier computational frameworks for codeswitching, such as Joshi (1982); Goyal et al. (2003); Sinha and Thakur (2005); Solorio and Liu (2008a,b), are not readily applicable. In recent times, the community has focused on developThese authors contributed equally 92 Proceedings of The Third Workshop on Computational Approaches to Code-Switching, pages 92–97 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013,"
W18-3211,P17-2009,0,0.0171077,"92 Proceedings of The Third Workshop on Computational Approaches to Code-Switching, pages 92–97 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers by Vyas et al. (2014); Jamatia et al. (2015); C¸etino˘glu and C ¸ o¨ ltekin (2016), automatic language identification by Jurgens et al. (2017); King and Abney (2013); Rijhwani et al. (2017); Jhamtani et al. (2014), prediction of code-switch points by Das and Gamb¨ack (2014), sentiment analysis by Rudra et al. (2016) and also certain meta level studies that include understanding metrics to characterize code-mixing Patro et al. (2017); Guzm´an et al. (2017). The idea of including language identifier vectors on the input and/or output side has become fairly common for other tasks as well, e.g. in Johnson et al. (2016) for machine translation, ¨ Ammar et al. (2016) for parsing, or Ostling and Tiedemann (2016) for language modeling. 2.1"
W18-3211,W16-5801,0,0.270628,"Missing"
W18-3211,D14-1098,0,0.258474,"Missing"
W18-3211,W14-5152,0,0.0515709,"Missing"
W18-3211,H94-1020,0,0.133129,"Missing"
W18-3211,D08-1102,0,0.163739,"he matrix language) provides the grammatical structure for CS text and words from another language (the embedded language) are inserted. However, CS data is challenging to obtain because this phenomenon is usually observed in informal settings. Data obtained from online sources is often noisy because of spelling, script, morphological, and grammatical variations. ∗ 2 Related Work The increased reach of Internet and social media has led to proliferation of noisy CS data where earlier computational frameworks for codeswitching, such as Joshi (1982); Goyal et al. (2003); Sinha and Thakur (2005); Solorio and Liu (2008a,b), are not readily applicable. In recent times, the community has focused on developThese authors contributed equally 92 Proceedings of The Third Workshop on Computational Approaches to Code-Switching, pages 92–97 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers b"
W18-3211,D08-1110,0,0.0805566,"he matrix language) provides the grammatical structure for CS text and words from another language (the embedded language) are inserted. However, CS data is challenging to obtain because this phenomenon is usually observed in informal settings. Data obtained from online sources is often noisy because of spelling, script, morphological, and grammatical variations. ∗ 2 Related Work The increased reach of Internet and social media has led to proliferation of noisy CS data where earlier computational frameworks for codeswitching, such as Joshi (1982); Goyal et al. (2003); Sinha and Thakur (2005); Solorio and Liu (2008a,b), are not readily applicable. In recent times, the community has focused on developThese authors contributed equally 92 Proceedings of The Third Workshop on Computational Approaches to Code-Switching, pages 92–97 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers b"
W18-3211,D14-1105,0,0.0381671,"b), are not readily applicable. In recent times, the community has focused on developThese authors contributed equally 92 Proceedings of The Third Workshop on Computational Approaches to Code-Switching, pages 92–97 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers by Vyas et al. (2014); Jamatia et al. (2015); C¸etino˘glu and C ¸ o¨ ltekin (2016), automatic language identification by Jurgens et al. (2017); King and Abney (2013); Rijhwani et al. (2017); Jhamtani et al. (2014), prediction of code-switch points by Das and Gamb¨ack (2014), sentiment analysis by Rudra et al. (2016) and also certain meta level studies that include understanding metrics to characterize code-mixing Patro et al. (2017); Guzm´an et al. (2017). The idea of including language identifier vectors on the input and/or output side has become fairly common for other tasks as well, e.g. in Johnson et al. (2016"
W18-3211,D17-1240,0,0.491003,"s Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers by Vyas et al. (2014); Jamatia et al. (2015); C¸etino˘glu and C ¸ o¨ ltekin (2016), automatic language identification by Jurgens et al. (2017); King and Abney (2013); Rijhwani et al. (2017); Jhamtani et al. (2014), prediction of code-switch points by Das and Gamb¨ack (2014), sentiment analysis by Rudra et al. (2016) and also certain meta level studies that include understanding metrics to characterize code-mixing Patro et al. (2017); Guzm´an et al. (2017). The idea of including language identifier vectors on the input and/or output side has become fairly common for other tasks as well, e.g. in Johnson et al. (2016) for machine translation, ¨ Ammar et al. (2016) for parsing, or Ostling and Tiedemann (2016) for language modeling. 2.1 Train 35513 18.90 0.8892 0.6635 0.3304 35,769 276,552 553,866 Dev 11839 17.58 0.8905 0.6639 0.3314 18,053 125,108 219,098 Test 11837 18.22 0.8914 0.6641 0.3312 19,330 130,947 229,967 Table 1: Hinglish Data Statistics 3 Data Analysis Curating a reasonable dataset for CS text is an important cha"
W18-3211,P17-1180,0,0.225321,"tational Approaches to Code-Switching, pages 92–97 c Melbourne, Australia, July 19, 2018. 2018 Association for Computational Linguistics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers by Vyas et al. (2014); Jamatia et al. (2015); C¸etino˘glu and C ¸ o¨ ltekin (2016), automatic language identification by Jurgens et al. (2017); King and Abney (2013); Rijhwani et al. (2017); Jhamtani et al. (2014), prediction of code-switch points by Das and Gamb¨ack (2014), sentiment analysis by Rudra et al. (2016) and also certain meta level studies that include understanding metrics to characterize code-mixing Patro et al. (2017); Guzm´an et al. (2017). The idea of including language identifier vectors on the input and/or output side has become fairly common for other tasks as well, e.g. in Johnson et al. (2016) for machine translation, ¨ Ammar et al. (2016) for parsing, or Ostling and Tiedemann (2016) for language modeling. 2.1 Train 35513 18.90 0.8892 0.6635 0.3304 35,769 2"
W18-3211,D16-1121,0,0.0872219,"stics Criteria # Sentences Avg Length of Sentences Multilingual Index Language Entropy Integration Index Unique Unigrams Unique Bigrams Unique Trigrams ing a variety of NLP tools for CS data such language models by Li and Fung (2013, 2014); Adel et al. (2015, 2013a,b); Garg et al. (2017), POS taggers by Vyas et al. (2014); Jamatia et al. (2015); C¸etino˘glu and C ¸ o¨ ltekin (2016), automatic language identification by Jurgens et al. (2017); King and Abney (2013); Rijhwani et al. (2017); Jhamtani et al. (2014), prediction of code-switch points by Das and Gamb¨ack (2014), sentiment analysis by Rudra et al. (2016) and also certain meta level studies that include understanding metrics to characterize code-mixing Patro et al. (2017); Guzm´an et al. (2017). The idea of including language identifier vectors on the input and/or output side has become fairly common for other tasks as well, e.g. in Johnson et al. (2016) for machine translation, ¨ Ammar et al. (2016) for parsing, or Ostling and Tiedemann (2016) for language modeling. 2.1 Train 35513 18.90 0.8892 0.6635 0.3304 35,769 276,552 553,866 Dev 11839 17.58 0.8905 0.6639 0.3314 18,053 125,108 219,098 Test 11837 18.22 0.8914 0.6641 0.3312 19,330 130,947"
W18-3217,W18-3219,0,0.0715085,"Missing"
W18-3217,P05-1045,0,0.104704,"Missing"
W18-3217,W17-4419,0,0.26543,"mbeddings with a CRF layer to attain alongside benchmarking several NLP tasks including NER. Lample et al. (2016) achieves the state-of-the-art performance on 4 languages by training models based on BiLSTM and CRF by using word representations from unannotated text and character representations from annotated text. This work has been extended to transfer settings by Bharadwaj et al. (2016) to multiple languages by representing word sequences in IPA. Huang et al. (2015) use a BiLSTM with a CRF layer in addition to making use of explicit spelling and context features along with word embeddings. Aguilar et al. (2017) use a character level CNN followed by a word level Bi-LSTM in a multi-task learning setting and also emphasize the importance of gazetteer lists for the task. Multilingual NER on informal text in Twitter was also studied by Etter et al. (2013). Zirikly and Diab (2015) 3 Data Analysis Code-switching is more prominently observed in informal communication which is observed in social media platforms. Hence the organizers of the shared task (Aguilar et al., 2018) have provided us with English-Spanish (ENG-SPA) and ArabicEnglish (MSA-EGY) tweets. In this section, we present an overlap analysis of t"
W18-3217,D16-1153,0,0.108521,"rdClass Distribution Learning. Passos et al. (2014) were among the first to use a neural network to learn word embeddings that leverage information from related lexicon to perform NER. Collobert et al. (2011) used convolution for embeddings with a CRF layer to attain alongside benchmarking several NLP tasks including NER. Lample et al. (2016) achieves the state-of-the-art performance on 4 languages by training models based on BiLSTM and CRF by using word representations from unannotated text and character representations from annotated text. This work has been extended to transfer settings by Bharadwaj et al. (2016) to multiple languages by representing word sequences in IPA. Huang et al. (2015) use a BiLSTM with a CRF layer in addition to making use of explicit spelling and context features along with word embeddings. Aguilar et al. (2017) use a character level CNN followed by a word level Bi-LSTM in a multi-task learning setting and also emphasize the importance of gazetteer lists for the task. Multilingual NER on informal text in Twitter was also studied by Etter et al. (2013). Zirikly and Diab (2015) 3 Data Analysis Code-switching is more prominently observed in informal communication which is observ"
W18-3217,N16-1030,0,0.0524804,"tly been emerging as effective techniques to perform the task. This is owed to the substantial reduction of manual expense in building hand-crafted features for each language. Qi et al. (2009) leverages unannotated sentences to improve supervised classification tasks using WordClass Distribution Learning. Passos et al. (2014) were among the first to use a neural network to learn word embeddings that leverage information from related lexicon to perform NER. Collobert et al. (2011) used convolution for embeddings with a CRF layer to attain alongside benchmarking several NLP tasks including NER. Lample et al. (2016) achieves the state-of-the-art performance on 4 languages by training models based on BiLSTM and CRF by using word representations from unannotated text and character representations from annotated text. This work has been extended to transfer settings by Bharadwaj et al. (2016) to multiple languages by representing word sequences in IPA. Huang et al. (2015) use a BiLSTM with a CRF layer in addition to making use of explicit spelling and context features along with word embeddings. Aguilar et al. (2017) use a character level CNN followed by a word level Bi-LSTM in a multi-task learning setting"
W18-3217,W02-2004,0,0.275841,"Missing"
W18-3217,W14-1609,0,0.0237725,"and Sekine, 2007) is available with regard to this. In this section we focus and present a comprehensive overview of the techniques that lay motivations to our models and experiments. While traditionally hand crafted features are reliably used (Carreras et al., 2002), neural models have recently been emerging as effective techniques to perform the task. This is owed to the substantial reduction of manual expense in building hand-crafted features for each language. Qi et al. (2009) leverages unannotated sentences to improve supervised classification tasks using WordClass Distribution Learning. Passos et al. (2014) were among the first to use a neural network to learn word embeddings that leverage information from related lexicon to perform NER. Collobert et al. (2011) used convolution for embeddings with a CRF layer to attain alongside benchmarking several NLP tasks including NER. Lample et al. (2016) achieves the state-of-the-art performance on 4 languages by training models based on BiLSTM and CRF by using word representations from unannotated text and character representations from annotated text. This work has been extended to transfer settings by Bharadwaj et al. (2016) to multiple languages by re"
W18-3217,D11-1141,0,0.367658,"Missing"
W18-3217,J14-2008,0,0.0258029,"Missing"
W18-3217,W03-0419,0,0.460077,"Missing"
W18-3217,W16-2705,0,0.0311154,"Missing"
W18-3217,W15-1524,0,0.0411739,"Missing"
W18-5028,W10-0719,0,0.0470991,"Missing"
W18-5030,D14-1213,0,0.0313634,"Missing"
W18-5030,W15-4616,0,0.0288877,"ional strategies such as praise (Fogg and Nass, 1997; Zhao et al., 2016) at a large scale in spoken-dialog systems. In the future, one could imagine dialog agents that reason over both social strategies and their magnitude, conditioned on user behavior, in service of their conversational goals. Bak et al., 2014; De Choudhury and De, 2014). Bickmore et al. (2009) study the effect of machine ‘backstories’ in dialog, and find that users rate their interactions to be more enjoyable when the dialog system has a backstory. Zhao et al. (2016) identify self-disclosure in peer tutoring between humans. Han et al. (2015); Meguro et al. (2010) identify self-disclosure as a user intention in a natural language understanding system. Oscar J. Romero (2017) use self-disclosure as one strategy amongst others to build a socially-aware conversational agent. Higashinaka et al. (2008) study if users self-disclose on topics they like rather than ones they don’t, with a focus on text-based chat rather than spoken dialog. Similarly, Lee and Choi (2017) study the relation between self-disclosure and liking for a movie recommendation system, using a Wizard-of-Oz approach instead of constructing a dialog agent. Perhaps close"
W18-5030,C10-1086,0,0.034412,"ch as praise (Fogg and Nass, 1997; Zhao et al., 2016) at a large scale in spoken-dialog systems. In the future, one could imagine dialog agents that reason over both social strategies and their magnitude, conditioned on user behavior, in service of their conversational goals. Bak et al., 2014; De Choudhury and De, 2014). Bickmore et al. (2009) study the effect of machine ‘backstories’ in dialog, and find that users rate their interactions to be more enjoyable when the dialog system has a backstory. Zhao et al. (2016) identify self-disclosure in peer tutoring between humans. Han et al. (2015); Meguro et al. (2010) identify self-disclosure as a user intention in a natural language understanding system. Oscar J. Romero (2017) use self-disclosure as one strategy amongst others to build a socially-aware conversational agent. Higashinaka et al. (2008) study if users self-disclose on topics they like rather than ones they don’t, with a focus on text-based chat rather than spoken dialog. Similarly, Lee and Choi (2017) study the relation between self-disclosure and liking for a movie recommendation system, using a Wizard-of-Oz approach instead of constructing a dialog agent. Perhaps closest to our work is the"
W18-5030,W16-3647,1,0.801577,"ven in human-machine dialog, with far-reaching implications for chatbots in a variety of domains including education, negotiation and social dialog. 1 Figure 1: Excerpt dialog from conversation between a user and our dialog agent1 . H represents user utterance and M represents machine dialog. rapport, of connecting and having common ground with another human being is one of the fundamental aspects of good human conversation. Maintaining conversational harmony has shown to be effective in several domains such as education (Ogan et al., 2012; Sinha and Cassell, 2015a,b; Frisby and Martin, 2010; Zhao et al., 2016) and negotiation (Drolet and Morris, 2000; Nadler, 2003, 2004). Self-disclosure is the conversational act of disclosing information about oneself to others. We consider the definition of self-disclosure within the theoretical framework of social penetration theory, where it is defined as the voluntary sharing of opinions, thoughts, beliefs, experiences, preferences, values and personal history (Altman and Taylor, 1973). The effect of self-disclosure has been well-studied in the psychology community, in particular it’s ability to induce reciprocity in dyadic interaction (Jourard, 1971; Derlega"
W18-5708,E17-2004,0,0.0257644,"ts for each dataset and each model are highlighted. 5.3 Main Results may require heavy external resources, which can be difficult to apply across multiple languages and domains. Recently, there has been a surging interest in adversarial training (Goodfellow et al., 2014). For text data, one class of methods generate adversarial examples by moving word embeddings along the opposite direction of the gradient of loss functions (Wu et al., 2017; Yasunaga et al., 2017), hence small perturbation in the continuous space of word vectors. Another class of methods aim to create genuinely new examples. (Li et al., 2017) adds syntactic and semantic variations to training data based on grammar rules and thesaurus. (Xie et al., 2017) add noises to data by blanking out or substituting words for language modeling. (Yang et al., 2017) adopt a seq2seq model (Sutskever et al., 2014) to generate questions based on paragraphs and answers into their generative adversarial framework. One main difference between these methods and our approach is that, while adversarial training only manipulates training data, we in addition apply transformations to data at test time to help prediction. This is closer to (Dong et al., 201"
W18-5708,W15-4640,0,0.537116,"Example 2: Customer Customer Agent Agent 在(there) 吗(?) 看看(look at) 此(this) 款(one) 在的(I’m here) 亲(dear) 亲(dear)，请(please) 发(send) 链接(link) Table 3: Example chat snippets from Frames. The first message has two sentences. The second message is a conditional complex sentence. Example 2 of Table 1 after Permutation: Example 1 of Table 2 after Permutation: Customer A Example 1: Customer A Agent 在(there) 吗(?) 在的(I’m here) 亲(dear) 看看(look at) 此(this) 款(one) 亲(dear)，请(please) 发(send) 链接(link) Customer Agent Customer Agent Table 1: Example chat snippets for broken continuity. The first example is from (Lowe et al., 2015). Burner’s message is responding to Old, and Kuja’s last message is replying to Taru. The second example is from Taobao, where the third message is responding to the first message, and the fourth message to the second message. Customer A Sorry, I cannot find any trips leaving from Gotham City. Could you suggest another nearby departure city? Would any packages to Mos Eisley be available, if I increase my budget to $2500? There are no trips available to Mos Eisley. 这(this) 款(one) 我(I) 穿(wear) 什么(what) 码(size) 160高(tall)，107 斤(0.5kg) 重(heavy) 亲(dear) 如果(if) 喜欢(like) 宽松(loose) 点的就(then) 可以(can) 选"
W18-5708,D11-1054,0,0.049477,"or the response selection task, it is so far unclear to what extent word order is important. This problem is perplexed by the following language phenomena we observed from existing chat data: Introduction Building machines that are capable of conversing like humans is one of the primary goals of artificial intelligence. Extensive manual labor is typically required by traditional rule-based systems, limiting the scalability of such systems across multiple domains. With the success of machine learning, the quest of building data-driven dialog systems has come into focus over the past few years (Ritter et al., 2011). Existing approaches in this area can be categorized into generation-based methods and retrieval-based methods. While generation-based methods are still far from reliably generating informative responses, retrieval-based methods have the advantage of fluency and groundedness, since they select responses from existing data. We concentrate on retrieval-based methods in this paper, though we believe the proposed techniques could also improve generation-based models. While current state-of-the-art results for dialog models are achieved by deep learning approaches, the performance of neural models"
W18-5708,W17-5526,0,0.154394,"Missing"
W18-5708,D17-1091,0,0.161678,"Li et al., 2017) adds syntactic and semantic variations to training data based on grammar rules and thesaurus. (Xie et al., 2017) add noises to data by blanking out or substituting words for language modeling. (Yang et al., 2017) adopt a seq2seq model (Sutskever et al., 2014) to generate questions based on paragraphs and answers into their generative adversarial framework. One main difference between these methods and our approach is that, while adversarial training only manipulates training data, we in addition apply transformations to data at test time to help prediction. This is closer to (Dong et al., 2017) in spirit. Table 6 shows the performance of LSTM-DE, HRE-DE, and SMN on 4 different datasets under different types of augmentation. For each fullscale dataset, nearly all models gain around 1 to 3 points with one of the proposed data augmentation methods. Permutation works best for LSTMDE, less so for HRE-DE, and has almost no effect on SMN. This is probably because HRE-DE and SMN have an utterance-level recurrent component which makes them better at capturing long range dependencies. Permutation 1 does not improve on Frames dataset for any model. This might be that Frames has perfect turn-ta"
W18-5708,P08-1095,0,0.0105124,"antage of fluency and groundedness, since they select responses from existing data. We concentrate on retrieval-based methods in this paper, though we believe the proposed techniques could also improve generation-based models. While current state-of-the-art results for dialog models are achieved by deep learning approaches, the performance of neural models largely depends on the amount of training data. However, acquiring conversational data can be difficult at times. On the other hand, even with thousands of data 1. Broken continuity. Simultaneous conversations happen in multi-party dialogs (Elsner and Charniak, 2008) very often, resulting in some utterances not responding to their immediately preceding ones. Even in conversations between only two people, continuity may still break due to one person switch topic before the other responds. See Table 1 for examples. 2. Mixed turn-taking behavior. People can give multiple utterances before the other respond. Usually, these consecutive messages from same person form arguments that are in parallel (by ’argument’ we mean text spans that form discourse relations with each other), and their orderings are not that important. We found this to be very common in onlin"
W18-5708,D17-1187,0,0.0604681,"Missing"
W18-5708,P17-2090,0,0.0199526,"LSTM-DE with data augmentation outperforms HRE-DE on some of the datasets. SMN gains even more with flipping than in full-scale setting. 6 Related Work Data augmentation has been widely adopted in computer vision and speech recognition (Krizhevsky et al., 2012; Ko et al., 2015). In image processing, label-preserving transformations such as tilting and flipping are used, but in NLP, finding such transformations that exactly preserve meanings is difficult. Language data is discrete in nature, and minor perturbation may change the meaning. Most commonly used techniques include word substitution (Fadaee et al., 2017) and paraphrasing (Dong et al., 2017). These methods 7 Conclusion We proposed a general method to improve dialog response selection through manipulating existing data that can be applied to different models. Our results show that for both open-domain and task-oriented dialogues, and for both English and Chinese languages, at least one of the proposed augmentation methods is effective, and the chance that they hurt is rare. We have deliberately chosen 56 a diverse set of domains and models to test this on to try to understand the contribution of data augmentation. Thus even when working on new"
W18-5708,P18-1027,0,0.0286128,"vailable data for training to improve the generalization ability of models. We investigate two data augmentation proxies, permutation and flipping, for neural dialog response selection task on various models over multiple datasets, including both Chinese and English languages. Different from standard data augmentation techniques, our method combines the original and synthesized data for prediction. Empirical results show that our approach can gain 1 to 3 recall-at-1 points over baseline models in both full-scale and small-scale settings. 1 2 Data Augmentation Recent studies (Adi et al., 2016; Khandelwal et al., 2018) have shown that recurrent neural networks (RNN), especially long-short term memory networks (LSTM), are sensitive to word order when encoding contextual information. However, for the response selection task, it is so far unclear to what extent word order is important. This problem is perplexed by the following language phenomena we observed from existing chat data: Introduction Building machines that are capable of conversing like humans is one of the primary goals of artificial intelligence. Extensive manual labor is typically required by traditional rule-based systems, limiting the scalabil"
W18-5708,P17-1096,0,0.031068,"g interest in adversarial training (Goodfellow et al., 2014). For text data, one class of methods generate adversarial examples by moving word embeddings along the opposite direction of the gradient of loss functions (Wu et al., 2017; Yasunaga et al., 2017), hence small perturbation in the continuous space of word vectors. Another class of methods aim to create genuinely new examples. (Li et al., 2017) adds syntactic and semantic variations to training data based on grammar rules and thesaurus. (Xie et al., 2017) add noises to data by blanking out or substituting words for language modeling. (Yang et al., 2017) adopt a seq2seq model (Sutskever et al., 2014) to generate questions based on paragraphs and answers into their generative adversarial framework. One main difference between these methods and our approach is that, while adversarial training only manipulates training data, we in addition apply transformations to data at test time to help prediction. This is closer to (Dong et al., 2017) in spirit. Table 6 shows the performance of LSTM-DE, HRE-DE, and SMN on 4 different datasets under different types of augmentation. For each fullscale dataset, nearly all models gain around 1 to 3 points with o"
W18-5708,D16-1036,0,0.0366875,"Missing"
W19-2108,D18-1305,0,0.0216186,"s for the unsupervised task, suggesting it is ready for immediate application in social science research. Alongside these results, we also introduce a real-world corpus of over 423,000 debates from Wikipedia, preprocessed and released under an open source license. 2 2.1 2.2 Prior Work on Wikipedia We situate our study in a corpus of Wikipedia data. Ours is far from the first work in this domain, with hundreds of papers published over the last two decades (Mesgari et al., 2015). Large corpora of user discussions on Wikipedia have previously been collected for NLP (Prabhakaran and Rambow, 2016; Hua et al., 2018), though most study discussion in the general case rather than in decision-making contexts. We specifically study Articles for Deletion debates (hereafter, AfD). In this setting, editors nominate pages for debate that they believe should be removed from the wiki, and other editors debate whether to keep or delete the page. Other reviews of deletion discussions were published during Wikipedia’s peak almost a decade ago (Taraborelli and Ciampaglia, 2010; Lam et al., 2010; Geiger and Ford, 2011); since then, only a handful of studies have evaluated this domain, mostly in the context of argument s"
W19-2108,D14-1162,0,0.0826665,"direct Other 5-Label Vote Final 54.9 64.0 28.5 20.5 3.6 3.1 3.8 5.9 9.3 6.5 2-Label Vote Final 62.3 73.0 37.7 27.0 Bag-of-words models struggle in classification tasks for short texts, where sparsity is a significant problem. The most effective recent solution to this has been word embeddings, where words are represented not as a single feature but as dense vectors learned from large unsupervised corpora. This allows similar words to have approximately similar representations, and effectively manages sparsity. In our experiments we test a widely-used and effective word embedding model, GloVe (Pennington et al., 2014), set to the maximum of 300 dimensions and represented as φGloV e (c). The newest word embedding models are contextual. Rather than encoding a word’s semantics as a static high-dimensional vector, these models adjust the representation of words based on the words they appear near at classification time. This approach, combined with extensive pretraining, has led to improvements on numerous tasks. We use the most effective model to date, the BERTBASE model from Devlin et al. (2018) with 768-dimensional embeddings φBERT (c). This model was already trained on Wikipedia texts (and other sources),"
W19-2108,W04-1013,0,0.0117247,"2 7.2 Further Validation of Impact Measures Daniel J Beal, Robin R Cohen, Michael J Burke, and Christy L McLendon. 2003. Cohesion and performance in groups: A meta-analytic clarification of construct relations. Journal of applied psychology, 88(6):989. Our work evaluating impact as a metric, using downstream interpretation tasks as a measure of success, is preliminary. Prior work in the NLP community has developed evaluation metrics hand-in-hand with human input, aiming for high correlation with their judgments (cf. Papineni et al. (2002); Banerjee and Lavie (2005) in machine translation, and Lin (2004) in summarization). This is a natural next step for this work. Once validated, impact assessment has immediate applications. Distinguishing the impact of individuals will enable deeper process analysis of the impact of diversity on teams (Bear and Williams Woolley, 2011), the interplay between individual participants and the process of resolving conflicts or disputes (Jehn et al., 1999), and the granular habits that lead to effective outcomes. These habits are often process-oriented, smallscale, and not adequately captured by survey or demographic variables (Riedl and Williams Woolley, 2017),"
W19-2108,J13-2002,0,0.014216,"f impact, based on probabilities learned from outcome prediction, again does not require any explicit labeling on the level of individuals or turns. 6.1 Impact(ci ) i=0 l∈L N X N X Evaluation The prior two tasks were supervised, with labeled outcomes that could be measured for performance accuracy. Impact assessment has no specific ground truth to compare against. In this scenario, other NLP research has provided justifications for a mix of quantitative and qualitative evaluations, as well as validation with human annotators and evaluation based on performance improvement in downstream tasks (Louis and Nenkova, 2013; Yang, 2019). We present a mix of qualitative analysis and downstream tasks, while leaving room for future validation studies. 6.1.2 Application: Long-term Roles We can also use outcome prediction to measure the role specific users play over time. By summing influence across all discussions, we find users who have had a disproportionate impact on the AfD process over Wikipedia’s lifespan. Ranked highly, we find users like TenPoundHammer - a user influential enough to spawn an eponymous and wellcited policy essay9 , “TenPoundHammer’s Law.” The most impactful posts typically occur early in deba"
W19-2108,W14-2117,0,0.0270232,"te’s policy and practice. Background Prior Work on Groups Group discussion data is commonly used in NLP research. Datasets include the multiparty inperson group work of the AMI meeting corpus (McCowan et al., 2005) and the pair task-based dialogues in the MapTask corpora (Anderson et al., 1991; Bard et al., 1996). A range of core tasks have improved based on these corpora, including diarization (Anguera et al., 2012), laughter detection (Petridis and Pantic, 2008), and summarization (Riedhammer et al., 2010). In online contexts, group debates have been analyzed for tasks like argument mining (Mao et al., 2014) and stance classification (Sobhani et al., 2015), among others. Outside of NLP venues, though, most studies of groups and organizations do not perform sophisticated text mining or analysis. Methods vary; some research focuses on fuzzy logic or economic agent modeling (see P´erez et al. (2018) for a recent systematic review), while others focus on social factors, network analysis, and the interactive aspects of teams (see Levine et al. (1993); Hackman (2011)). Here we do not address open-ended discussions, focusing on task-based debates where multiple people participate, a fixed set of options"
W19-2108,D17-1213,0,0.0346502,"Missing"
W19-2108,W15-0509,0,0.0498278,"rk on Groups Group discussion data is commonly used in NLP research. Datasets include the multiparty inperson group work of the AMI meeting corpus (McCowan et al., 2005) and the pair task-based dialogues in the MapTask corpora (Anderson et al., 1991; Bard et al., 1996). A range of core tasks have improved based on these corpora, including diarization (Anguera et al., 2012), laughter detection (Petridis and Pantic, 2008), and summarization (Riedhammer et al., 2010). In online contexts, group debates have been analyzed for tasks like argument mining (Mao et al., 2014) and stance classification (Sobhani et al., 2015), among others. Outside of NLP venues, though, most studies of groups and organizations do not perform sophisticated text mining or analysis. Methods vary; some research focuses on fuzzy logic or economic agent modeling (see P´erez et al. (2018) for a recent systematic review), while others focus on social factors, network analysis, and the interactive aspects of teams (see Levine et al. (1993); Hackman (2011)). Here we do not address open-ended discussions, focusing on task-based debates where multiple people participate, a fixed set of options are available, and there is no gold standard “co"
W19-2108,J00-3003,0,0.149561,"Missing"
W19-2108,H05-1044,0,0.0085389,"ed, see Appendix A. 3.3 4 Turn-Level Stance Classification In most other collaborative team decision-making contexts, opinions are expressed but explicit stances are latent. Because of the unique format of Wikipedia discussions, those stances are easily extracted from “‘bolded”’ votes. We use this as a test case for building supervised classifiers which elicit participant stance based on their statements alone. All bolded text is masked from rationales and models must predict what vote is associated with a given rationale. Similar tasks have been effective in labeling turns in prose text (see Wilson et al. (2005) and other work with their MPQA corpus), open-ended group dialogues (Stolcke et al., 2000; Mu et al., 2012), and in stance classification for more openended social media (Sobhani et al., 2015); here we apply the task to contributions in a structured group decision-making context. Fundamentally this is a test of how closely the Wikipedia domain hews to other decision-making contexts. If rationales are not sufficient to predict Language Representations We consider three representations of language. First, we extract standard binary unigram bag-ofwords features φBoW (c). These were the standard r"
W19-3402,N18-2121,0,0.0224259,"these classifiers. Here is an overview of the differences in the six models that we describe next. mation improves the dialogues which is measured by next utterance prediction. In these works, the gold value of the target response was known. For our work, we do not have gold values of stories in different personas. Hence we leverage annotated data from a different task and transfer that knowledge to steer our generation process. Multimodal domain: With the interplay between visual and textual modalities, an obvious downstream application for persona based text generation is image captioning. Chandrasekaran et al. (2018) worked on generating witty captions for images by both retrieving and generating with an encoder-decoder architecture. This work used external resources to gather a list of words that are related to puns from web which the decoder attempts to generate conditioned on phonological similarity. Wang and Wen (2015) studied the statistical correlation of words associated with specific memes. These ideas have also recently penetrated into visual dialog setting. Shuster et al. (2018) have collected a grounded conversational dataset with 202k dialogs where humans are asked to portray a personality in"
W19-3402,P19-1606,1,0.809995,"ing Workshop, pages 11–21 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics scriptions of images in isolation (image captions) and stories in sequences. The baseline model that we are leveraging to generate personality conditioned story generation is based on the model proposed by Kim et al. (2018) for the visual story telling challenge. Another simple yet effective technique is late fusion model by Smilevski et al. (2018). In addition to static images, Gella et al. (2018) have also collected a dataset of describing stories from videos uploaded on social media. Chandu et al. (2019) recently introduced a dataset for generating textual cooking recipes from a sequence of images and proposed two models to incorporate structure in procedural text generation from images. of large scale persona annotated stories. We address this by transferring knowledge from annotated data in dialog domain to the storytelling domain. We base our visual story generator model on Kim et al. (2018) and propose multiple techniques to induce the personalities in the latent representations of both the encoder and the decoder. The goal of our work is to learn the mapping between the latent representa"
W19-3402,P18-1082,0,0.0298329,"ation Khyathi Raghavi Chandu ∗, Shrimai Prabhumoye ∗, Ruslan Salakhutdinov, Alan W Black Language Technologies Institute, Carnegie Mellon University Pittsburgh, PA, USA {kchandu, sprabhum, rsalakhu, awb}@cs.cmu.edu Abstract generative storytelling has gained traction only recently. Recent research has focused on challenges in generating longer documents (Wiseman et al., 2017; Lau and Baldwin, 2016) as well as on predicting the next events in the story (Martin et al., 2018). Contemporary research has focused on using deep generative models to capture high-level plots and structures in stories (Fan et al., 2018). Recent years have also seen some work hinging on the event structures and scripts (Mostafazadeh et al., 2016; Rishes et al., 2013; Peng et al., 2018). Generating an appropriate ending of a story was also studied by Guan et al. (2018) and Sharma et al. (2018). Research on generating stories from a sequence of images is anew (Peng et al., 2018; Lukin et al., 2018; Kim et al., 2018; Hsu et al., 2018; Gonzalez-Rico and Fuentes-Pineda, 2018). Cavazza et al. (2009) have stressed the importance of expressing emotions in the believability of the automated storytelling system. Adapting a personality"
W19-3402,W16-1609,0,0.0520212,"Missing"
W19-3402,P16-1094,0,0.0375746,"e style transfer in text with non-parallel data (Hu et al., 2017; Shen et al., 2017; Li et al., 2018). Some of this work has also focused on transferring author attributes (Prabhumoye et al., 2018), transferring multiple attributes (Lample et al., 2019; Logeswaran et al., 2018) and collecting parallel dataset for formality (Rao and Tetreault, 2018). Although our work can be viewed as another facet of style transfer, we have strong grounding of the stories in the sequence of images. Persona Based Dialog: Persona based generation of responses has been studied by NLP community in dialog domain. (Li et al., 2016) encoded personas of individuals in contextualized embeddings that capture the background information and style to maintain consistency in the responses given. The embeddings for the speaker information are learnt jointly with the word embeddings. Following this work, (Zhou et al., 2018) proposed Emotional Chatting Machine that generates responses in an emotional tone in addition to conditioning the content. The key difference between former and latter work is that the latter captures dynamic change in emotion as the conversation proceeds, while the user persona remains the same in the former"
W19-3402,D18-1117,0,0.0309305,"o its timeline, neural ∗ Both authors contributed equally to this work. 11 Proceedings of the Second Storytelling Workshop, pages 11–21 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics scriptions of images in isolation (image captions) and stories in sequences. The baseline model that we are leveraging to generate personality conditioned story generation is based on the model proposed by Kim et al. (2018) for the visual story telling challenge. Another simple yet effective technique is late fusion model by Smilevski et al. (2018). In addition to static images, Gella et al. (2018) have also collected a dataset of describing stories from videos uploaded on social media. Chandu et al. (2019) recently introduced a dataset for generating textual cooking recipes from a sequence of images and proposed two models to incorporate structure in procedural text generation from images. of large scale persona annotated stories. We address this by transferring knowledge from annotated data in dialog domain to the storytelling domain. We base our visual story generator model on Kim et al. (2018) and propose multiple techniques to induce the personalities in the latent representations"
W19-3402,N18-1169,0,0.0834676,"Missing"
W19-3402,W18-1503,0,0.0305742,"et al., 2017; Lau and Baldwin, 2016) as well as on predicting the next events in the story (Martin et al., 2018). Contemporary research has focused on using deep generative models to capture high-level plots and structures in stories (Fan et al., 2018). Recent years have also seen some work hinging on the event structures and scripts (Mostafazadeh et al., 2016; Rishes et al., 2013; Peng et al., 2018). Generating an appropriate ending of a story was also studied by Guan et al. (2018) and Sharma et al. (2018). Research on generating stories from a sequence of images is anew (Peng et al., 2018; Lukin et al., 2018; Kim et al., 2018; Hsu et al., 2018; Gonzalez-Rico and Fuentes-Pineda, 2018). Cavazza et al. (2009) have stressed the importance of expressing emotions in the believability of the automated storytelling system. Adapting a personality trait hence becomes crucial to capture and maintain interest of the audience. Associating the narrative to a personality instigates a sense of empathy and relatedness. Although there has been research in generating persona based dialog responses and generating stylistic sentences (Shuster et al., 2018; Fu et al., 2018; Prabhumoye et al., 2018; Shen et al., 2017),"
W19-3402,N15-1039,0,0.0205171,"ce we leverage annotated data from a different task and transfer that knowledge to steer our generation process. Multimodal domain: With the interplay between visual and textual modalities, an obvious downstream application for persona based text generation is image captioning. Chandrasekaran et al. (2018) worked on generating witty captions for images by both retrieving and generating with an encoder-decoder architecture. This work used external resources to gather a list of words that are related to puns from web which the decoder attempts to generate conditioned on phonological similarity. Wang and Wen (2015) studied the statistical correlation of words associated with specific memes. These ideas have also recently penetrated into visual dialog setting. Shuster et al. (2018) have collected a grounded conversational dataset with 202k dialogs where humans are asked to portray a personality in the collection process. They have also set up various baselines with different techniques to fuse the modalities including multimodal sum combiner and multimodal attention combiner. We use this dataset to learn personas which are adapted to our storytelling model. 3 1. The baseline model (Glocal) is a sequence"
W19-3402,I17-1047,0,0.0233191,"onversation proceeds, while the user persona remains the same in the former case. (Zhang et al., 2018) release a huge dataset of conversations conditioned on the persona of the two people interacting. This work shows that conditioning on the profile inforRelated Work Visual Story Telling: Last decade witnessed enormous interest in research at the intersection of multiple modalities, especially vision and language. Mature efforts in image captioning (Hossain et al., 2019) paved way into more advanced tasks like visual question answering (Wu et al., 2017) and visual dialog (Das et al., 2017) , (Mostafazadeh et al., 2017). As an obvious next step from single shot image captioning lies the task of describing a sequence of images which are related to one another to form a story like narrative. This task was introduced as visual story telling by Huang et al. (2016), differentiating de12 the target personality type. We build generative models such that they are able to generate stories in the specified target personality type from the images. In this section, we first briefly describe classifiers that are trained discriminatively to identify each of the personalities and then move on to the story generation models"
W19-3402,W16-1007,0,0.0162559,"nologies Institute, Carnegie Mellon University Pittsburgh, PA, USA {kchandu, sprabhum, rsalakhu, awb}@cs.cmu.edu Abstract generative storytelling has gained traction only recently. Recent research has focused on challenges in generating longer documents (Wiseman et al., 2017; Lau and Baldwin, 2016) as well as on predicting the next events in the story (Martin et al., 2018). Contemporary research has focused on using deep generative models to capture high-level plots and structures in stories (Fan et al., 2018). Recent years have also seen some work hinging on the event structures and scripts (Mostafazadeh et al., 2016; Rishes et al., 2013; Peng et al., 2018). Generating an appropriate ending of a story was also studied by Guan et al. (2018) and Sharma et al. (2018). Research on generating stories from a sequence of images is anew (Peng et al., 2018; Lukin et al., 2018; Kim et al., 2018; Hsu et al., 2018; Gonzalez-Rico and Fuentes-Pineda, 2018). Cavazza et al. (2009) have stressed the importance of expressing emotions in the believability of the automated storytelling system. Adapting a personality trait hence becomes crucial to capture and maintain interest of the audience. Associating the narrative to a p"
W19-3402,W18-1505,0,0.0240943,"ittsburgh, PA, USA {kchandu, sprabhum, rsalakhu, awb}@cs.cmu.edu Abstract generative storytelling has gained traction only recently. Recent research has focused on challenges in generating longer documents (Wiseman et al., 2017; Lau and Baldwin, 2016) as well as on predicting the next events in the story (Martin et al., 2018). Contemporary research has focused on using deep generative models to capture high-level plots and structures in stories (Fan et al., 2018). Recent years have also seen some work hinging on the event structures and scripts (Mostafazadeh et al., 2016; Rishes et al., 2013; Peng et al., 2018). Generating an appropriate ending of a story was also studied by Guan et al. (2018) and Sharma et al. (2018). Research on generating stories from a sequence of images is anew (Peng et al., 2018; Lukin et al., 2018; Kim et al., 2018; Hsu et al., 2018; Gonzalez-Rico and Fuentes-Pineda, 2018). Cavazza et al. (2009) have stressed the importance of expressing emotions in the believability of the automated storytelling system. Adapting a personality trait hence becomes crucial to capture and maintain interest of the audience. Associating the narrative to a personality instigates a sense of empathy"
W19-3402,P18-1205,0,0.0405602,"d personas of individuals in contextualized embeddings that capture the background information and style to maintain consistency in the responses given. The embeddings for the speaker information are learnt jointly with the word embeddings. Following this work, (Zhou et al., 2018) proposed Emotional Chatting Machine that generates responses in an emotional tone in addition to conditioning the content. The key difference between former and latter work is that the latter captures dynamic change in emotion as the conversation proceeds, while the user persona remains the same in the former case. (Zhang et al., 2018) release a huge dataset of conversations conditioned on the persona of the two people interacting. This work shows that conditioning on the profile inforRelated Work Visual Story Telling: Last decade witnessed enormous interest in research at the intersection of multiple modalities, especially vision and language. Mature efforts in image captioning (Hossain et al., 2019) paved way into more advanced tasks like visual question answering (Wu et al., 2017) and visual dialog (Das et al., 2017) , (Mostafazadeh et al., 2017). As an obvious next step from single shot image captioning lies the task of"
W19-3402,P18-1080,1,0.927089,"anew (Peng et al., 2018; Lukin et al., 2018; Kim et al., 2018; Hsu et al., 2018; Gonzalez-Rico and Fuentes-Pineda, 2018). Cavazza et al. (2009) have stressed the importance of expressing emotions in the believability of the automated storytelling system. Adapting a personality trait hence becomes crucial to capture and maintain interest of the audience. Associating the narrative to a personality instigates a sense of empathy and relatedness. Although there has been research in generating persona based dialog responses and generating stylistic sentences (Shuster et al., 2018; Fu et al., 2018; Prabhumoye et al., 2018; Shen et al., 2017), generating persona based stories with different personality types narrating them has been unexplored. In this paper, we focus on generating a story from a sequence of images as if the agent belongs to a particular personality type. In specific, we choose to perform experimentations on visual story telling (Huang et al., 2016). This paper introduces a novel approach to generating visual stories in five different personality types. A key challenge to this end is the lack Visual storytelling is the task of generating stories based on a sequence of images. Inspired by the rec"
W19-3402,N18-1012,0,0.0609398,"nnotated data in the dialog domain to guide the generative models to a specified target personality. 2 Style Transfer: One line of research that is closely related to our task is style transfer in text. Recently generative models have gained popularity in attempting to solve style transfer in text with non-parallel data (Hu et al., 2017; Shen et al., 2017; Li et al., 2018). Some of this work has also focused on transferring author attributes (Prabhumoye et al., 2018), transferring multiple attributes (Lample et al., 2019; Logeswaran et al., 2018) and collecting parallel dataset for formality (Rao and Tetreault, 2018). Although our work can be viewed as another facet of style transfer, we have strong grounding of the stories in the sequence of images. Persona Based Dialog: Persona based generation of responses has been studied by NLP community in dialog domain. (Li et al., 2016) encoded personas of individuals in contextualized embeddings that capture the background information and style to maintain consistency in the responses given. The embeddings for the speaker information are learnt jointly with the word embeddings. Following this work, (Zhou et al., 2018) proposed Emotional Chatting Machine that gene"
W19-3402,P18-2119,0,0.0301925,"d traction only recently. Recent research has focused on challenges in generating longer documents (Wiseman et al., 2017; Lau and Baldwin, 2016) as well as on predicting the next events in the story (Martin et al., 2018). Contemporary research has focused on using deep generative models to capture high-level plots and structures in stories (Fan et al., 2018). Recent years have also seen some work hinging on the event structures and scripts (Mostafazadeh et al., 2016; Rishes et al., 2013; Peng et al., 2018). Generating an appropriate ending of a story was also studied by Guan et al. (2018) and Sharma et al. (2018). Research on generating stories from a sequence of images is anew (Peng et al., 2018; Lukin et al., 2018; Kim et al., 2018; Hsu et al., 2018; Gonzalez-Rico and Fuentes-Pineda, 2018). Cavazza et al. (2009) have stressed the importance of expressing emotions in the believability of the automated storytelling system. Adapting a personality trait hence becomes crucial to capture and maintain interest of the audience. Associating the narrative to a personality instigates a sense of empathy and relatedness. Although there has been research in generating persona based dialog responses and generating"
W19-3402,W04-1013,0,\N,Missing
W19-3402,D17-1239,0,\N,Missing
W19-3413,N18-1204,0,0.052177,"Missing"
W19-3413,W18-1505,0,0.0320071,"making our codebase open source 1 . 2 Related Work There has been a surge in recent years to tackle the problem of story generation. One common theme is to employ the advances in deep learning for the task. Jain et al. (2017) use Seq2Seq models (Sutskever et al., 2014) to generate stories from descriptions of images. Huang et al. (2018) leverage hierarchical decoding where a high-level decoder constructs a plan by generating a topic and a low-level decoder generates Recent works have also made advances in controllable generation of text based on constraints to make the outputs more specific. Peng et al. (2018) have a conditional embedding matrix for valence to control the ending of the story. Hu et al. (2017b) have a toggle vector to introduce constraint on the output of text generation models using Variational Auto Encoders(Doersch, 2016). Generating diverse responses based on conditioning has been done 1 https://github.com/witerforcing/WriterForcing 118 of the encoder hidden states, known as the context vector(c t ): extensively in the field of dialogue systems. Xing et al. (2016); Zhou et al. (2018); Zhang et al. (2018) propose conditioning techniques by using emotion and persona while generatin"
W19-3413,P17-1099,0,0.0518686,"tor p. p is a vector with length equal to the length of the story context, and the value of every element j is equal to score of the keyphrase to which the word w j belongs. In all the four model variants described next, we incorporate the score vector p to encourage the model to condition on the keyphrases. We use this new context vector to calculate our probabilities over the words as described in equation 4. 4.1.3 Coverage Loss This is a variant which implicitly encourages the model to pay attention to all words present in the context. We adapt the attention coverage based loss proposed by See et al. (2017). It also helps in avoiding repeated attention across different timesteps while decoding. Due to this constraint, the model should focus on different words in the story and generate outputs conditioned on these words. The loss function which is presented in the paper is : X ¡ ¢ ¡ ¢ losst = − log P w t∗ + λ min a it , si (10) 4.1.1 Keyphrase Addition In a Seq2Seq model with attention, for every timestep t during decoding, the model generates a distribution a it which is the weight given for a given source context word w i . In this variant, the model is provided an additional keyphrase attentio"
W19-3413,N16-1014,0,0.133465,"imilar way by including ""commonsense knowledge"" from ConceptNet as well. Several prior work focus on generating more coherent stories. Clark et al. (2018) model entity representations explicitly by combining it with representations of the previous sentence and Martin et al. (2018) model events representations and then generate natural language sentences from those events (event2sentence). Li et al. (2018) use adversarial training to help the model generate more reasonable endings. 1. Use conditionals such as emotions, sentiments, keywords, etc. that work as factors to condition the output on (Li et al., 2016b; Hu et al., 2017a). When the models focus on these conditionals given as additional input features, they tend to generate outputs which are more relevant and specific to the conditionals, which leads to less generic outputs. In our models, we use the keyphrases present in the story context as conditionals. 2. Modify the decoding procedure (Vijayakumar et al., 2018) with beam search or other variants, or the loss of the decoder (Baheti et al., 2018; Li et al., 2016a) to encourage the model to generate more diverse outputs. Our proposed model uses the ITF loss function suggested by Nakamura et"
W19-3413,D17-1235,0,0.0224806,"et al., 2018; Li et al., 2016a) to encourage the model to generate more diverse outputs. Our proposed model uses the ITF loss function suggested by Nakamura et al. (2018) to encourage the decoder to produce more interesting outputs. A common problem with such neural approaches in general is that the generated text is very ""safe and boring"". There has been a lot of recent efforts towards generating diverse outputs in problems such as dialogue systems, image captioning, story generation, etc., in order to alleviate the safe or boring text generation problem. Methods include using self-attention Shao et al. (2017), Reinforcement Learning (Li et al., 2017), GANs etc. Xu et al. (2018) proposed a method called Diversity-Promoting Generative Adversarial Network, which assigns low reward for repeatedly generated text and high reward for novel and fluent text using a language model based discriminator. Li et al. (2016a) propose a Maximum Mutual Information (MMI) objective function and show that this objective function leads to a decrease in the proportion of generic response sequences. Nakamura et al. (2018) propose another loss function for the same objective. In our models we experiment with their loss fun"
W19-3413,P16-1094,0,0.187062,"imilar way by including ""commonsense knowledge"" from ConceptNet as well. Several prior work focus on generating more coherent stories. Clark et al. (2018) model entity representations explicitly by combining it with representations of the previous sentence and Martin et al. (2018) model events representations and then generate natural language sentences from those events (event2sentence). Li et al. (2018) use adversarial training to help the model generate more reasonable endings. 1. Use conditionals such as emotions, sentiments, keywords, etc. that work as factors to condition the output on (Li et al., 2016b; Hu et al., 2017a). When the models focus on these conditionals given as additional input features, they tend to generate outputs which are more relevant and specific to the conditionals, which leads to less generic outputs. In our models, we use the keyphrases present in the story context as conditionals. 2. Modify the decoding procedure (Vijayakumar et al., 2018) with beam search or other variants, or the loss of the decoder (Baheti et al., 2018; Li et al., 2016a) to encourage the model to generate more diverse outputs. Our proposed model uses the ITF loss function suggested by Nakamura et"
W19-3413,D17-1230,0,0.0233173,"the model to generate more diverse outputs. Our proposed model uses the ITF loss function suggested by Nakamura et al. (2018) to encourage the decoder to produce more interesting outputs. A common problem with such neural approaches in general is that the generated text is very ""safe and boring"". There has been a lot of recent efforts towards generating diverse outputs in problems such as dialogue systems, image captioning, story generation, etc., in order to alleviate the safe or boring text generation problem. Methods include using self-attention Shao et al. (2017), Reinforcement Learning (Li et al., 2017), GANs etc. Xu et al. (2018) proposed a method called Diversity-Promoting Generative Adversarial Network, which assigns low reward for repeatedly generated text and high reward for novel and fluent text using a language model based discriminator. Li et al. (2016a) propose a Maximum Mutual Information (MMI) objective function and show that this objective function leads to a decrease in the proportion of generic response sequences. Nakamura et al. (2018) propose another loss function for the same objective. In our models we experiment with their loss function and observe similar effects. We show"
W19-3413,C18-1088,0,0.0202017,"ntal encoding (IE) scheme and perform one hop reasoning over the ConceptNet graph ConceptNet in order to augment the representation of words in the sentences. Chen et al. (2018) also tackle the problem in a similar way by including ""commonsense knowledge"" from ConceptNet as well. Several prior work focus on generating more coherent stories. Clark et al. (2018) model entity representations explicitly by combining it with representations of the previous sentence and Martin et al. (2018) model events representations and then generate natural language sentences from those events (event2sentence). Li et al. (2018) use adversarial training to help the model generate more reasonable endings. 1. Use conditionals such as emotions, sentiments, keywords, etc. that work as factors to condition the output on (Li et al., 2016b; Hu et al., 2017a). When the models focus on these conditionals given as additional input features, they tend to generate outputs which are more relevant and specific to the conditionals, which leads to less generic outputs. In our models, we use the keyphrases present in the story context as conditionals. 2. Modify the decoding procedure (Vijayakumar et al., 2018) with beam search or oth"
W19-3413,D18-1428,0,0.0191831,"diverse outputs. Our proposed model uses the ITF loss function suggested by Nakamura et al. (2018) to encourage the decoder to produce more interesting outputs. A common problem with such neural approaches in general is that the generated text is very ""safe and boring"". There has been a lot of recent efforts towards generating diverse outputs in problems such as dialogue systems, image captioning, story generation, etc., in order to alleviate the safe or boring text generation problem. Methods include using self-attention Shao et al. (2017), Reinforcement Learning (Li et al., 2017), GANs etc. Xu et al. (2018) proposed a method called Diversity-Promoting Generative Adversarial Network, which assigns low reward for repeatedly generated text and high reward for novel and fluent text using a language model based discriminator. Li et al. (2016a) propose a Maximum Mutual Information (MMI) objective function and show that this objective function leads to a decrease in the proportion of generic response sequences. Nakamura et al. (2018) propose another loss function for the same objective. In our models we experiment with their loss function and observe similar effects. We show that our proposed models ca"
W19-3413,P18-1205,0,0.0195041,"le generation of text based on constraints to make the outputs more specific. Peng et al. (2018) have a conditional embedding matrix for valence to control the ending of the story. Hu et al. (2017b) have a toggle vector to introduce constraint on the output of text generation models using Variational Auto Encoders(Doersch, 2016). Generating diverse responses based on conditioning has been done 1 https://github.com/witerforcing/WriterForcing 118 of the encoder hidden states, known as the context vector(c t ): extensively in the field of dialogue systems. Xing et al. (2016); Zhou et al. (2018); Zhang et al. (2018) propose conditioning techniques by using emotion and persona while generating responses. Conditioned generation has also been studied in the field of story generation to plan and write (Yao et al., 2018; Huang et al., 2018) stories. In this work, we focus on generating more diverse and interesting endings for stories by introducing conditioning on keyphrases present in the story context and encouraging infrequent words in the outputs by modifying the training objective, thus leading to more interesting story endings. ct = i =1 a it h ienc (3) This context vector is then concatenated with the"
W19-3413,W17-0906,0,\N,Missing
W19-3413,P18-1082,0,\N,Missing
W19-3413,D18-1431,0,\N,Missing
W19-3637,P15-1073,0,\N,Missing
W19-3637,P16-2096,0,\N,Missing
W19-3637,W17-1613,0,\N,Missing
W19-3637,W17-1603,0,\N,Missing
W19-3637,W17-1607,0,\N,Missing
W19-3823,P17-2009,1,0.888237,"Missing"
W19-3823,N18-1021,0,0.0771121,"Missing"
W19-3823,W19-3805,0,0.151803,"Missing"
W19-3823,D14-1162,0,0.0899417,"el using various stimuli presented in Caliskan et al. (2017). Next, we investigate the effect of a specific type of bias in a specific downstream task: gender bias in BERT and its effect on the task of Gendered Pronoun Resolution (GPR) (Webster et al., 2018). We show that the bias in GPR is highly correlated with our measure of bias (§4). Finally, we highlight the potential negative impacts of using BERT in downstream real world applications (§5). The code and data used in this work are publicly Introduction Type-level word embedding models, including word2vec and GloVe (Mikolov et al., 2013; Pennington et al., 2014), have been shown to exhibit social biases present in human-generated training data (Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018; Manzini et al., 2019). These embeddings are then used in a plethora of downstream applications, which perpetuate and further amplify stereotypes (Zhao et al., 2017; Leino et al., 2019). To reveal and quantify corpuslevel biases is word embeddings, Bolukbasi et al. (2016) used the word analogy task (Mikolov et al., 2013). For example, they showed that gendered male word embeddings like he, man are associated with higher-status jobs like computer"
W19-3823,N18-1202,0,0.445347,"al., 2019). These embeddings are then used in a plethora of downstream applications, which perpetuate and further amplify stereotypes (Zhao et al., 2017; Leino et al., 2019). To reveal and quantify corpuslevel biases is word embeddings, Bolukbasi et al. (2016) used the word analogy task (Mikolov et al., 2013). For example, they showed that gendered male word embeddings like he, man are associated with higher-status jobs like computer programmer and doctor, whereas gendered words like she or woman are associated with homemaker and nurse. Contextual word embedding models, such as ELMo and BERT (Peters et al., 2018; Devlin et al., 2019) have become increasingly common, replacing traditional type-level embeddings and attaining new state of the art results in the majority of 166 Proceedings of the 1st Workshop on Gender Bias in Natural Language Processing, pages 166–172 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics available.1 2 We refer to this normalized measure of association as the increased log probability score and the difference between the increased log probability scores for two targets (e.g. he/she) as log probability bias score which we use as measure of bias"
W19-3823,N18-2002,0,0.15874,"Missing"
W19-3823,N19-1423,0,0.31247,"eddings are then used in a plethora of downstream applications, which perpetuate and further amplify stereotypes (Zhao et al., 2017; Leino et al., 2019). To reveal and quantify corpuslevel biases is word embeddings, Bolukbasi et al. (2016) used the word analogy task (Mikolov et al., 2013). For example, they showed that gendered male word embeddings like he, man are associated with higher-status jobs like computer programmer and doctor, whereas gendered words like she or woman are associated with homemaker and nurse. Contextual word embedding models, such as ELMo and BERT (Peters et al., 2018; Devlin et al., 2019) have become increasingly common, replacing traditional type-level embeddings and attaining new state of the art results in the majority of 166 Proceedings of the 1st Workshop on Gender Bias in Natural Language Processing, pages 166–172 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics available.1 2 We refer to this normalized measure of association as the increased log probability score and the difference between the increased log probability scores for two targets (e.g. he/she) as log probability bias score which we use as measure of bias. Although this approa"
W19-3823,P19-1243,1,0.850794,"and BERT, but there was no clear indication of bias. Rather, they observed counterintuitive behavior like vastly different p-values for results concerning gender. Along similar lines, Basta et al. (2019) noted that contextual word-embeddings are less biased than traditional word-embeddings. Yet, biases like gender are propagated heavily in downstream tasks. For instance, Zhao et al. (2019) showed that ELMo exhibits gender bias for certain professions. As a result, female entities are predicted less accurately than male entities for certain occupation words, in the coreference resolution task. Field and Tsvetkov (2019) revealed biases in ELMo embeddings that limit their applicability across data domains. Motivated by these recent findings, our work proposes a new method to expose and measure bias in contextualized word embeddings, specifically BERT. As opposed to previ• Positive and Negative Traits Dataset8 - Contains a collection of 234 and 292 adjectives considered “positive” and “negative” traits, respectively. • O*NET 23.2 technology skills9 Contains 17649 unique skills for 27660 jobs, which are posted online Discussion We used the following two templates to measure gender bias: • “TARGET is ATTRIBUTE”,"
W19-3823,D17-1323,0,0.363156,"asure of bias (§4). Finally, we highlight the potential negative impacts of using BERT in downstream real world applications (§5). The code and data used in this work are publicly Introduction Type-level word embedding models, including word2vec and GloVe (Mikolov et al., 2013; Pennington et al., 2014), have been shown to exhibit social biases present in human-generated training data (Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018; Manzini et al., 2019). These embeddings are then used in a plethora of downstream applications, which perpetuate and further amplify stereotypes (Zhao et al., 2017; Leino et al., 2019). To reveal and quantify corpuslevel biases is word embeddings, Bolukbasi et al. (2016) used the word analogy task (Mikolov et al., 2013). For example, they showed that gendered male word embeddings like he, man are associated with higher-status jobs like computer programmer and doctor, whereas gendered words like she or woman are associated with homemaker and nurse. Contextual word embedding models, such as ELMo and BERT (Peters et al., 2018; Devlin et al., 2019) have become increasingly common, replacing traditional type-level embeddings and attaining new state of the ar"
W19-3823,D18-1521,0,0.0750372,"e if the pronoun belongs to A, B or neither. The MLP layer uses a single hidden layer with 31 dimensions, a dropout of 0.6 and L2 regularization with weight 0.1. 5 Real World Implications In previous sections, we discussed that BERT has human-like biases, which are propagated to downstream tasks. In this section, we discuss another potential negative impact of using BERT in a downstream model. Given that three quarters of US employers now use social media for recruiting job candidates (Segal, 2014), many applications are filtered using job recommendation systems and other AI-powered services. Zhao et al. (2018) Results Although the number of male pronouns associated with no entities in the training data is 5 https://github.com/ google-research-datasets/gap-coreference 6 https://www.kaggle.com/mateiionita/ taming-the-bert-a-baseline 169 discussed that resume filtering systems are biased when the model has strong association between gender and certain professions. Similarly, certain gender-stereotyped attributes have been strongly associated with occupational salary and prestige (Glick, 1991). Using our proposed method, we investigate the gender bias in BERT embeddingss for certain occupation and skil"
W19-3823,N19-1064,0,\N,Missing
W19-4446,W18-5421,0,0.0344561,"Missing"
W19-4446,P16-2096,0,0.0714964,"Gebru, 2018). Fairness work in NLP has focused particularly in dense semantic representations at the lexical or sentence level. In learned embeddings of meaning, bias exists along race and gender lines (Caliskan et al., 2017; Garg et al., 2018) and is passed downstream, producing biased outcomes for tasks like coreference resolution (Zhao et al., 2018a), sentiment analysis (Kiritchenko and Mohammad, 2018), search (Romanov et al., 2019), and dialogue systems (Voigt et al., 2018; Henderson et al., 2018). Research beyond metrics, analyzing the broader social impact of biased NLP, has also begun (Hovy and Spruit, 2016). 3 Equity in Education Research Machine learning research in general tends to focus on recent publication; to counteract this and set a longer-term context, in the following section we explain the historical background on learning science research that considers socio-cultural dimensions of learning and their implications for equity, work that motivates our recommendations for technologists building educational interventions. 3.1 Sociocultural and Critical Perspectives While much of the earliest work on learning science was purely behaviorist, the field’s expansion into sociocultural factors"
W19-4446,W17-1605,0,0.229227,"Missing"
W19-4446,J93-2004,0,0.0748839,"hey need help on, in their “zone of proximal development” (Hammond and Gibbons, 2005). This work also acknowledged the connection between formal school education and informal education in the world (Scribner and Cole, 1973), and introduced the idea of learning as a social process in which students build identity (Wenger, 2010). This conceptual framework now dominate the scientific discourse on sociocultural research in edtech systems (Aleven et al., 2016). Many of these problems stem from training data selection; models trained on standard written professional English, like the Penn Treebank (Marcus et al., 1993), fail to transfer to other writing styles, especially online where research suggests that NLP performance is degraded for underrepresented language groups, like African American English (Petrov and McDonald, 2012; Blodgett et al., 2017). Early work on “de-biasing” NLP has begun, seeking to reduce the amplification of bias in dense word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017, 2018b); but early results still leave room for improvement (Gonen and Goldberg, 2019). Accounting for dialects and other language variation has been moderately more successful, with examples in speech recog"
W19-4446,W17-1603,0,0.165443,"Missing"
W19-4446,W17-1604,0,0.166084,"Missing"
W19-4446,W17-1607,0,0.251042,"Missing"
W19-4446,W18-0501,0,0.0198866,"Missing"
W19-4446,W12-2016,0,0.0226586,"07) and to provide narrowly targeted support for Autistic students (Nojavanasghari et al., 2017) and deaf students (Scassellati et al., 2018). When these pedagogical agents are used with students, regardless of if they play the role of tutors, coaches, or peers (Baylor and Kim, 2005), representation matters. Decisions for agents’ appearance, language, and behavior may impact learners’ perceptions of the cultural identity of the agents (Haake and Gulz, 2008), and may impact learners perceptions of their own belongingness 447 2014). But to date, work has primarily focused on factoid assessment (Mostow and Jang, 2012; Zesch and Melamud, 2014; Wojatzki et al., 2016). This is an opportunity for future equitable NLP research at the intersection of ITS agents and reading comprehension. Additionally, coaching teachers to perform these dialogues has potential to fill in gaps in professional development and preservice training (Gerritsen et al., 2018), further incentivizing development of culturally responsive reading comprehension. treats cultural knowledge instead as an asset, and allows students to build on what they know. This extends to technologies used in the everyday lives, homes, and communities of stud"
W19-4446,W18-5431,0,0.0263448,"Missing"
W19-4446,W14-1701,0,0.0404109,"Missing"
W19-4446,W18-0506,0,0.0583823,"Missing"
W19-4446,D16-1159,0,0.0545161,"Missing"
W19-4446,L18-1445,0,0.0189572,"disproportionate error from facial recognition for dark skin tones, particularly among individuals identifying as female (Buolamwini and Gebru, 2018). Fairness work in NLP has focused particularly in dense semantic representations at the lexical or sentence level. In learned embeddings of meaning, bias exists along race and gender lines (Caliskan et al., 2017; Garg et al., 2018) and is passed downstream, producing biased outcomes for tasks like coreference resolution (Zhao et al., 2018a), sentiment analysis (Kiritchenko and Mohammad, 2018), search (Romanov et al., 2019), and dialogue systems (Voigt et al., 2018; Henderson et al., 2018). Research beyond metrics, analyzing the broader social impact of biased NLP, has also begun (Hovy and Spruit, 2016). 3 Equity in Education Research Machine learning research in general tends to focus on recent publication; to counteract this and set a longer-term context, in the following section we explain the historical background on learning science research that considers socio-cultural dimensions of learning and their implications for equity, work that motivates our recommendations for technologists building educational interventions. 3.1 Sociocultural and Critic"
W19-4446,D13-1187,0,0.045017,"Missing"
W19-4446,W18-5430,0,0.0421157,"Missing"
W19-4446,E14-3004,0,0.0121195,"voice and language (Gerosa et al., 2009) and are used to improve students’ early reading skills (Mostow et al., 2003), or for speech-based vocabulary practice (Kumar et al., 2012). Yet these systems are often unable to generate questions for texts from nonstandard linguistic groups (e.g. with the syntactic and morphological transformations in African-American English (Siegel, 2001)). Systems today may also fail to recognize speech from students speaking certain dialects or accents, though progress in recognition for marginalized language variation is improving rapidly (Blodgett et al., 2016; Stewart, 2014; Jørgensen et al., 2015). After basic literacy skills are acquired, NLP tools for language understanding are widely used to generate reading comprehension questions (Heilman and Smith, 2010). NLP is also used in related tasks like the measurement of readability (Aluisio et al., 2010; Vajjala and Meurers, 2012), and generation of simplified texts to differentiate homework based on student ability (Xu et al., 2015). But from a pedagogy perspective, content from these systems may be inappropriate - for instance, the questions generated are often factual rather than encouraging critical thinking"
W19-4446,W12-2019,0,0.0306886,"syntactic and morphological transformations in African-American English (Siegel, 2001)). Systems today may also fail to recognize speech from students speaking certain dialects or accents, though progress in recognition for marginalized language variation is improving rapidly (Blodgett et al., 2016; Stewart, 2014; Jørgensen et al., 2015). After basic literacy skills are acquired, NLP tools for language understanding are widely used to generate reading comprehension questions (Heilman and Smith, 2010). NLP is also used in related tasks like the measurement of readability (Aluisio et al., 2010; Vajjala and Meurers, 2012), and generation of simplified texts to differentiate homework based on student ability (Xu et al., 2015). But from a pedagogy perspective, content from these systems may be inappropriate - for instance, the questions generated are often factual rather than encouraging critical thinking (Rickford, 2001). This format does not measure student skills equally across cultures, and particularly under-reports progress in students of color, who tend to thrive when assessed through naturalistic narrative (Fagundes et al., 1998). In pursuit of more reliable automated assessment, comprehension tasks may"
W19-4446,W14-1817,0,0.0221921,"owly targeted support for Autistic students (Nojavanasghari et al., 2017) and deaf students (Scassellati et al., 2018). When these pedagogical agents are used with students, regardless of if they play the role of tutors, coaches, or peers (Baylor and Kim, 2005), representation matters. Decisions for agents’ appearance, language, and behavior may impact learners’ perceptions of the cultural identity of the agents (Haake and Gulz, 2008), and may impact learners perceptions of their own belongingness 447 2014). But to date, work has primarily focused on factoid assessment (Mostow and Jang, 2012; Zesch and Melamud, 2014; Wojatzki et al., 2016). This is an opportunity for future equitable NLP research at the intersection of ITS agents and reading comprehension. Additionally, coaching teachers to perform these dialogues has potential to fill in gaps in professional development and preservice training (Gerritsen et al., 2018), further incentivizing development of culturally responsive reading comprehension. treats cultural knowledge instead as an asset, and allows students to build on what they know. This extends to technologies used in the everyday lives, homes, and communities of students - influencing their"
W19-4446,D17-1323,0,0.0742572,"n sociocultural research in edtech systems (Aleven et al., 2016). Many of these problems stem from training data selection; models trained on standard written professional English, like the Penn Treebank (Marcus et al., 1993), fail to transfer to other writing styles, especially online where research suggests that NLP performance is degraded for underrepresented language groups, like African American English (Petrov and McDonald, 2012; Blodgett et al., 2017). Early work on “de-biasing” NLP has begun, seeking to reduce the amplification of bias in dense word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017, 2018b); but early results still leave room for improvement (Gonen and Goldberg, 2019). Accounting for dialects and other language variation has been moderately more successful, with examples in speech recognition (Kraljic et al., 2008), parsing (Gimpel et al., 2011), and classification (Jurgens et al., 2017). There are many open questions. Chouldechova (2017) and Corbett-Davies and Goel (2018) work to even define fairness, giving several proposals; 445 chine learning research. Unlike fairness literature in computer science venues, these works explicitly describe existing practices as based i"
W19-4446,N18-2003,0,0.0221454,"concrete real-world outcomes, like racial bias in recidivism prediction in judicial hearings (Corbett-Davies et al., 2017), or disproportionate error from facial recognition for dark skin tones, particularly among individuals identifying as female (Buolamwini and Gebru, 2018). Fairness work in NLP has focused particularly in dense semantic representations at the lexical or sentence level. In learned embeddings of meaning, bias exists along race and gender lines (Caliskan et al., 2017; Garg et al., 2018) and is passed downstream, producing biased outcomes for tasks like coreference resolution (Zhao et al., 2018a), sentiment analysis (Kiritchenko and Mohammad, 2018), search (Romanov et al., 2019), and dialogue systems (Voigt et al., 2018; Henderson et al., 2018). Research beyond metrics, analyzing the broader social impact of biased NLP, has also begun (Hovy and Spruit, 2016). 3 Equity in Education Research Machine learning research in general tends to focus on recent publication; to counteract this and set a longer-term context, in the following section we explain the historical background on learning science research that considers socio-cultural dimensions of learning and their implications for eq"
W19-4446,W16-0519,0,0.0196131,"Autistic students (Nojavanasghari et al., 2017) and deaf students (Scassellati et al., 2018). When these pedagogical agents are used with students, regardless of if they play the role of tutors, coaches, or peers (Baylor and Kim, 2005), representation matters. Decisions for agents’ appearance, language, and behavior may impact learners’ perceptions of the cultural identity of the agents (Haake and Gulz, 2008), and may impact learners perceptions of their own belongingness 447 2014). But to date, work has primarily focused on factoid assessment (Mostow and Jang, 2012; Zesch and Melamud, 2014; Wojatzki et al., 2016). This is an opportunity for future equitable NLP research at the intersection of ITS agents and reading comprehension. Additionally, coaching teachers to perform these dialogues has potential to fill in gaps in professional development and preservice training (Gerritsen et al., 2018), further incentivizing development of culturally responsive reading comprehension. treats cultural knowledge instead as an asset, and allows students to build on what they know. This extends to technologies used in the everyday lives, homes, and communities of students - influencing their ability to impact studen"
W19-4446,D18-1521,0,0.0420938,"concrete real-world outcomes, like racial bias in recidivism prediction in judicial hearings (Corbett-Davies et al., 2017), or disproportionate error from facial recognition for dark skin tones, particularly among individuals identifying as female (Buolamwini and Gebru, 2018). Fairness work in NLP has focused particularly in dense semantic representations at the lexical or sentence level. In learned embeddings of meaning, bias exists along race and gender lines (Caliskan et al., 2017; Garg et al., 2018) and is passed downstream, producing biased outcomes for tasks like coreference resolution (Zhao et al., 2018a), sentiment analysis (Kiritchenko and Mohammad, 2018), search (Romanov et al., 2019), and dialogue systems (Voigt et al., 2018; Henderson et al., 2018). Research beyond metrics, analyzing the broader social impact of biased NLP, has also begun (Hovy and Spruit, 2016). 3 Equity in Education Research Machine learning research in general tends to focus on recent publication; to counteract this and set a longer-term context, in the following section we explain the historical background on learning science research that considers socio-cultural dimensions of learning and their implications for eq"
W19-4446,Q15-1021,0,0.0226314,"l to recognize speech from students speaking certain dialects or accents, though progress in recognition for marginalized language variation is improving rapidly (Blodgett et al., 2016; Stewart, 2014; Jørgensen et al., 2015). After basic literacy skills are acquired, NLP tools for language understanding are widely used to generate reading comprehension questions (Heilman and Smith, 2010). NLP is also used in related tasks like the measurement of readability (Aluisio et al., 2010; Vajjala and Meurers, 2012), and generation of simplified texts to differentiate homework based on student ability (Xu et al., 2015). But from a pedagogy perspective, content from these systems may be inappropriate - for instance, the questions generated are often factual rather than encouraging critical thinking (Rickford, 2001). This format does not measure student skills equally across cultures, and particularly under-reports progress in students of color, who tend to thrive when assessed through naturalistic narrative (Fagundes et al., 1998). In pursuit of more reliable automated assessment, comprehension tasks may also fail to prioritize growth in student ability. Struggling readers understand texts more effectively w"
W19-5943,D16-1127,0,0.0608071,"Missing"
W19-5943,P13-1025,0,0.0750882,"Missing"
W19-5943,W14-3348,0,0.00909931,"ays to operationalize and quantify these abstract principles. In Table 1, we list our actionable tactics motivated by various negotiation principles. To detect these tactics from turns, we use a mix of learned classifiers2 for turn-level tactics (e.g., propose prices) and regular expression rules for lexical tactics (e.g., use polite words). To create the training set for learning tactic predictors, we randomly selected 200 dialogs and annotated them with tactics.3 The detectors use the following features: (1) the number of words overlapping with the product description; (2) the METEOR score (Denkowski and Lavie, 2014) of the turn given the product description as reference; (3) the cosine distance between the turn embedding and the product description embedding.4 For “Address buyer’s concerns”, we additionally include lexical features indicating a question (e.g.,“why”, “how”, “does”) from the immediate previous buyer’s turns. Table 2 summarizes the number pf training examples and prediction accuracies for each learned classifier. For lexical tactics, we have the following rules: Product Listing: Product Description Listing Price 2 3 Coach: Predict Strategies Select Optimal Strategies 3 2 4 5 Realize Strateg"
W19-5943,W15-4621,0,0.0605219,"Missing"
W19-5943,P17-1162,1,0.900787,"Missing"
W19-5943,D18-1256,1,0.672956,"nd predicts the best tactics to use in the next turn to achieve a higher final price. The seller has the freedom to choose whether to use the recommended tactics. 3 Approach We define a set of diverse tactics S from past study on negotiation in behavioral economics, including both high-level dialog acts (e.g., hpropose a pricei, hdescribe the producti) and low-level lexical features (e.g. huse hedge wordsi). Given the negotiation scenario and the dialog history, the coach takes the following steps (Figure 3) to generate suggestions: Problem Statement We follow the CraigslistBargain setting of He et al. (2018), where a buyer and a seller negotiate the price of an item for sale. The negotiation scenario is based on listings scraped from craigslist. com, including product description, product photos (if available), and the listing price. In addi1. The tactics detectors map each turn to a set of tactics in S. 2. The tactics predictor predicts the set of possible tactics in the next turn given the dia368 offer free delivery). Therefore, we develop datadriven ways to operationalize and quantify these abstract principles. In Table 1, we list our actionable tactics motivated by various negotiation princip"
W19-5943,D17-1259,0,0.0863509,"Missing"
W19-5943,P16-1094,0,0.0288899,"Missing"
W19-5943,W13-4016,0,\N,Missing
