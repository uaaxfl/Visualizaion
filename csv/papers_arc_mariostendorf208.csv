2021.emnlp-main.140,{DIALKI}: Knowledge Identification in Conversational Systems through Dialogue-Document Contextualization,2021,-1,-1,4,0,7957,zeqiu wu,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,Identifying relevant knowledge to be used in conversational systems that are grounded in long documents is critical to effective response generation. We introduce a knowledge identification model that leverages the document structure to provide dialogue-contextualized passage encodings and better locate knowledge relevant to the conversation. An auxiliary loss captures the history of dialogue-document connections. We demonstrate the effectiveness of our model on two document-grounded conversational datasets and provide analyses showing generalization to unseen documents and long dialogue contexts.
2021.emnlp-main.404,Dialogue State Tracking with a Language Model using Schema-Driven Prompting,2021,-1,-1,3,0,9552,chiahsuan lee,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Task-oriented conversational systems often use dialogue state tracking to represent the user{'}s intentions, which involves filling in values of pre-defined slots. Many approaches have been proposed, often using task-specific architectures with special-purpose classifiers. Recently, good results have been obtained using more general architectures based on pretrained language models. Here, we introduce a new variation of the language modeling approach that uses schema-driven prompting to provide task-aware history encoding that is used for both categorical and non-categorical slots. We further improve performance by augmenting the prompting with schema descriptions, a naturally occurring source of in-domain knowledge. Our purely generative system achieves state-of-the-art performance on MultiWOZ 2.2 and achieves competitive performance on two other benchmarks: MultiWOZ 2.1 and M2M. The data and code will be available at https://github.com/chiahsuan156/DST-as-Prompting."
2021.eacl-main.253,Representations for Question Answering from Documents with Tables and Text,2021,-1,-1,3,1,9759,vicky zayats,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Tables in web documents are pervasive and can be directly used to answer many of the queries searched on the web, motivating their integration in question answering. Very often information presented in tables is succinct and hard to interpret with standard language representations. On the other hand, tables often appear within textual context, such as an article describing the table. Using the information from an article as additional context can potentially enrich table representations. In this work we aim to improve question answering from tables by refining table representations based on information from surrounding text. We also present an effective method to combine text and table-based predictions for question answering from full documents, obtaining significant improvements on the Natural Questions dataset (Kwiatkowski et al., 2019)."
W19-4450,Automated Essay Scoring with Discourse-Aware Neural Models,2019,0,0,4,1,24221,farah nadeem,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"Automated essay scoring systems typically rely on hand-crafted features to predict essay quality, but such systems are limited by the cost of feature engineering. Neural networks offer an alternative to feature engineering, but they typically require more annotated data. This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays. Experiments on three essay scoring tasks show benefits from all three strategies in different combinations, with simpler architectures being more effective when less training data is available."
N19-1008,Giving Attention to the Unexpected: Using Prosody Innovations in Disfluency Detection,2019,33,2,2,1,9759,vicky zayats,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Disfluencies in spontaneous speech are known to be associated with prosodic disruptions. However, most algorithms for disfluency detection use only word transcripts. Integrating prosodic cues has proved difficult because of the many sources of variability affecting the acoustic correlates. This paper introduces a new approach to extracting acoustic-prosodic cues using text-based distributional prediction of acoustic cues to derive vector z-score features (innovations). We explore both early and late fusion techniques for integrating text and prosody, showing gains over a high-accuracy text-only model."
N19-1284,A Dynamic Speaker Model for Conversational Interactions,2019,0,0,3,1,3499,hao cheng,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Individual differences in speakers are reflected in their language use as well as in their interests and opinions. Characterizing these differences can be useful in human-computer interaction, as well as analysis of human-human conversations. In this work, we introduce a neural model for learning a dynamically updated speaker embedding in a conversational context. Initial model training is unsupervised, using context-sensitive language generation as an objective, with the context being the conversation history. Further fine-tuning can leverage task-dependent supervised training. The learned neural representation of speakers is shown to be useful for content ranking in a socialbot and dialog act prediction in human-human conversations."
N19-1308,A general framework for information extraction using dynamic span graphs,2019,0,11,5,1,25654,yi luan,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We introduce a general framework for several information extraction tasks that share span representations using dynamically constructed span graphs. The graphs are dynamically constructed by selecting the most confident entity spans and linking these nodes with confidence-weighted relation types and coreferences. The dynamic span graph allow coreference and relation type confidences to propagate through the graph to iteratively refine the span representations. This is unlike previous multi-task frameworks for information extraction in which the only interaction between tasks is in the shared first-layer LSTM. Our framework significantly outperforms state-of-the-art on multiple information extraction tasks across multiple datasets reflecting different domains. We further observe that the span enumeration approach is good at detecting nested span entities, with significant F1 score improvement on the ACE dataset."
W18-0505,Estimating Linguistic Complexity for Science Texts,2018,0,1,2,1,24221,farah nadeem,Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"Evaluation of text difficulty is important both for downstream tasks like text simplification, and for supporting educators in classrooms. Existing work on automated text complexity analysis uses linear models with engineered knowledge-driven features as inputs. While this offers interpretability, these models have lower accuracy for shorter texts. Traditional readability metrics have the additional drawback of not generalizing to informational texts such as science. We propose a neural approach, training on science and other informational texts, to mitigate both problems. Our results show that neural methods outperform knowledge-based linear models for short texts, and have the capacity to generalize to genres not present in the training data."
S18-1125,The {UWNLP} system at {S}em{E}val-2018 Task 7: Neural Relation Extraction Model with Selectively Incorporated Concept Embeddings,2018,0,8,2,1,25654,yi luan,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes our submission for SemEval 2018 Task 7 shared task on semantic relation extraction and classification in scientific papers. Our model is based on the end-to-end relation extraction model of (Miwa and Bansal, 2016) with several enhancements such as character-level encoding attention mechanism on selecting pretrained concept candidate embeddings. Our official submission ranked the second in relation classification task (Subtask 1.1 and Subtask 2 Senerio 2), and the first in the relation extraction task (Subtask 2 Scenario 1)."
Q18-1009,Conversation Modeling on {R}eddit Using a Graph-Structured {LSTM},2018,0,19,2,1,28933,victoria zayats,Transactions of the Association for Computational Linguistics,0,"This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM (long-short term memory) which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments."
Q18-1035,Low-Rank {RNN} Adaptation for Context-Aware Language Modeling,2018,2,7,2,1,4431,aaron jaech,Transactions of the Association for Computational Linguistics,0,"A context-aware language model uses location, user and/or domain metadata (context) to adapt its predictions. In neural language models, context information is typically represented as an embedding and it is given to the RNN as an additional input, which has been shown to be useful in many applications. We introduce a more powerful mechanism for using context to adapt an RNN by letting the context vector control a low-rank transformation of the recurrent layer weight matrix. Experiments show that allowing a greater fraction of the model parameters to be adjusted has benefits in terms of perplexity and classification for several different types of context."
P18-2111,Personalized Language Model for Query Auto-Completion,2018,0,3,2,1,4431,aaron jaech,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Query auto-completion is a search engine feature whereby the system suggests completed queries as the user types. Recently, the use of a recurrent neural network language model was suggested as a method of generating query completions. We show how an adaptable language model can be used to generate personalized completions and how the model can use online updating to make predictions for users not seen during training. The personalized predictions are significantly better than a baseline that uses no user information."
N18-5020,Sounding Board: A User-Centric and Content-Driven Social Chatbot,2018,0,13,8,1,3929,hao fang,Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"We present Sounding Board, a social chatbot that won the 2017 Amazon Alexa Prize. The system architecture consists of several components including spoken language processing, dialogue management, language generation, and content management, with emphasis on user-centric and content-driven design. We also share insights gained from large-scale online logs based on 160,000 conversations with real-world users."
N18-2094,Community Member Retrieval on Social Media Using Textual Information,2018,0,0,3,1,4431,aaron jaech,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,This paper addresses the problem of community membership detection using only text features in a scenario where a small number of positive labeled examples defines the community. The solution introduces an unsupervised proxy task for learning user embeddings: user re-identification. Experiments with 16 different communities show that the resulting embeddings are more effective for community membership identification than common unsupervised representations.
N18-1007,Parsing Speech: a Neural Approach to Integrating Lexical and Acoustic-Prosodic Information,2018,0,11,6,1,10371,trang tran,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"In conversational speech, the acoustic signal provides cues that help listeners disambiguate difficult parses. For automatically parsing spoken utterances, we introduce a model that integrates transcribed text and acoustic-prosodic features using a convolutional neural network over energy and pitch trajectories coupled with an attention-based recurrent neural network that accepts text and prosodic features. We find that different types of acoustic-prosodic features are individually helpful, and together give statistically significant improvements in parse and disfluency detection F1 scores over a strong text-only baseline. For this study with known sentence boundaries, error analyses show that the main benefit of acoustic-prosodic features is in sentences with disfluencies, attachment decisions are most improved, and transcription errors obscure gains from prosody."
D18-1360,"Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",2018,36,2,3,1,25654,yi luan,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called SciIE with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature."
W17-5036,Language Based Mapping of Science Assessment Items to Skills,2017,8,1,2,1,24221,farah nadeem,Proceedings of the 12th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"Knowledge of the association between assessment questions and the skills required to solve them is necessary for analysis of student learning. This association, often represented as a Q-matrix, is either hand-labeled by domain experts or learned as latent variables given a large student response data set. As a means of automating the match to formal standards, this paper uses neural text classification methods, leveraging the language in the standards documents to identify online text for a proxy training task. Experiments involve identifying the topic and crosscutting concepts of middle school science questions leveraging multi-task training. Results show that it is possible to automatically build a Q-matrix without student response data and using a modest number of hand-labeled questions."
D17-1243,A Factored Neural Network Model for Characterizing Online Discussions in Vector Space,2017,10,4,3,1,3499,hao cheng,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We develop a novel factored neural model that learns comment embeddings in an unsupervised way leveraging the structure of distributional context in online discussion forums. The model links different context with related language factors in the embedding space, providing a way to interpret the factored embeddings. Evaluated on a community endorsement prediction task using a large collection of topic-varying Reddit discussions, the factored embeddings consistently achieve improvement over other text representations. Qualitative analysis shows that the model captures community style and topic, as well as response trigger patterns."
D17-1279,Scientific Information Extraction with Semi-supervised Neural Tagging,2017,31,15,2,1,25654,yi luan,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"This paper addresses the problem of extracting keyphrases from scientific articles and categorizing them as corresponding to a task, process, or material. We cast the problem as sequence tagging and introduce semi-supervised methods to a neural tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unannotated articles. Both inductive and transductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task."
W16-6209,Learning Latent Local Conversation Modes for Predicting Comment Endorsement in Online Discussions,2016,0,1,3,1,3929,hao fang,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,None
W16-6212,Hierarchical Character-Word Models for Language Identification,2016,26,6,4,1,4431,aaron jaech,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,"Social media messages' brevity and unconventional spelling pose a challenge to language identification. We introduce a hierarchical model that learns character and contextualized word-level representations for language identification. Our method performs well against strong base- lines, and can also reveal code-switching."
W16-5807,A Neural Model for Language Identification in Code-Switched Tweets,2016,0,10,3,1,4431,aaron jaech,Proceedings of the Second Workshop on Computational Approaches to Code Switching,0,None
P16-1153,Deep Reinforcement Learning with a Natural Language Action Space,2016,22,45,7,0,34517,ji he,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"This paper introduces a novel architecture for reinforcement learning with deep neural networks designed to handle state and action spaces characterized by natural language, as found in text-based games. Termed a deep reinforcement relevance network (DRRN), the architecture represents action and state spaces with separate embedding vectors, which are combined with an interaction function to approximate the Q-function in reinforcement learning. We evaluate the DRRN on two popular text games, showing superior performance over other deep Qlearning architectures. Experiments with paraphrased action descriptions show that the model is extracting meaning rather than simply memorizing strings of text."
N16-1079,Phonological Pun-derstanding,2016,14,11,3,1,4431,aaron jaech,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
D16-1108,Characterizing the Language of Online Communities and its Relation to Community Reception,2016,16,10,2,1,10371,trang tran,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,"This work investigates style and topic aspects of language in online communities: looking at both utility as an identifier of the community and correlation with community reception of content. Style is characterized using a hybrid word and part-of-speech tag n-gram language model, while topic is represented using Latent Dirichlet Allocation. Experiments with several Reddit forums show that style is a better indicator of community identity than topic, even for communities organized around specific topics. Further, there is a positive correlation between the community reception to a contribution and the style similarity to that community, but not so for topic similarity."
D16-1189,Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular {R}eddit Threads,2016,37,3,2,0,34517,ji he,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,"We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial, natural language action space. A specified number of discussion threads predicted to be popular are recommended, chosen from a fixed window of recent comments to track. Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub-actions. The proposed model, which represents dependence between sub-actions through a bi-directional LSTM, gives the best performance across different experimental configurations and domains, and it also generalizes well with varying numbers of recommendation requests."
W15-3003,Data Selection With Fewer Words,2015,19,3,4,0,18812,amittai axelrod,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"We present a method that improves data selection by combining a hybrid word/part-of-speech representation for corpora, with the idea of distinguishing between rare and frequent events. We validate our approach using data selection for machine translation, and show that it maintains or improves BLEU and TER translation scores while substantially improving vocabulary coverage and reducing data selection model size. Paradoxically, the coverage improvement is achieved by abstracting away over 97% of the total training corpus vocabulary using simple part-of-speech tags during the data selection process."
N15-1022,Aligning Sentences from Standard {W}ikipedia to {S}imple {W}ikipedia,2015,31,34,3,0,37639,william hwang,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This work improves monolingual sentence alignment for text simplification, specifically for text in standard and simple Wikipedia. We introduce a method that improves over past efforts by using a greedy (vs. ordered) search over the document and a word-level semantic similarity score based on Wiktionary (vs. WordNet) that also accounts for structural similarity through syntactic dependencies. Experiments show improved performance on a hand-aligned set, with the largest gain coming from structural similarity. Resulting datasets of manually and automatically aligned sentence pairs are made available."
N15-1161,{U}nediting: Detecting Disfluencies Without Careful Transcripts,2015,20,1,2,1,28933,victoria zayats,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Speech transcripts often only capture semantic content, omitting disfluencies that can be useful for analyzing social dynamics of a discussion. This work describes steps in building a model that can recover a large fraction of locations where disfluencies were present, by transforming carefully annotated text to match the standard transcription style, introducing a two-stage model for handling different types of disfluencies, and applying semi-supervised learning. Experiments show improvement in disfluency detection on Supreme Court oral arguments, nearly 23% improvement in F1."
D15-1085,Open-Domain Name Error Detection using a Multi-Task {RNN},2015,26,15,3,1,3499,hao cheng,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Out-of-vocabulary name errors in speech recognition create significant problems for downstream language processing, but the fact that they are rare poses challenges for automatic detection, particularly in an open-domain scenario. To address this problem, a multi-task recurrent neural network language model for sentence-level name detection is proposed for use in combination with out-of-vocabulary word detection. The sentence-level model is also effective for leveraging external text data. Experiments show a 26% improvement in name-error detection F-score over a system using n-gram lexical features."
D15-1239,Talking to the crowd: What do people react to in online discussions?,2015,15,8,4,1,4431,aaron jaech,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"This paper addresses the question of how language use affects community reaction to comments in online discussion forums, and the relative importance of the message vs. the messenger. A new comment ranking task is proposed based on community annotated karma in Reddit discussions, which controls for topic and timing of comments. Experimental work with discussion threads from six subreddits shows that the importance of different types of language features varies with the community of interest."
D15-1240,What Your Username Says About You,2015,13,1,2,1,4431,aaron jaech,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Usernames are ubiquitous on the Internet, and they are often suggestive of user demographics. This work looks at the degree to which gender and language can be inferred from a username alone by making use of unsupervised morphology induction to decompose usernames into sub-units. Experimental results on the two tasks demonstrate the effectiveness of the proposed morphological features compared to a character n-gram baseline."
N13-1085,Atypical Prosodic Structure as an Indicator of Reading Level and Text Difficulty,2013,16,1,2,1,825,julie medero,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Automatic assessment of reading ability builds on applying speech recognition tools to oral reading, measuring words correct per minute. This work looks at more fine-grained analysis that accounts for effects of prosodic context using a large corpus of read speech from a literacy study. Experiments show that lower-level readers tend to produce relatively more lengthening on words that are not likely to be final in a prosodic phrase, i.e. in less appropriate locations. The results have implications for automatic assessment of text difficulty in that locations of atypical prosodic lengthening are indicative of difficult lexical items and syntactic constructions."
W11-0706,Detecting Forum Authority Claims in Online Discussions,2011,18,13,3,0,5982,alex marin,Proceedings of the Workshop on Language in Social Media ({LSM} 2011),0,"This paper explores the problem of detecting sentence-level forum authority claims in online discussions. Using a maximum entropy model, we explore a variety of strategies for extracting lexical features in a sparse training scenario, comparing knowledge- and data-driven methods (and combinations). The augmentation of lexical features with parse context is also investigated. We find that certain markup features perform remarkably well alone, but are outperformed by data-driven selection of lexical features augmented with parse context."
W11-0707,Annotating Social Acts: Authority Claims and Alignment Moves in {W}ikipedia Talk Pages,2011,-1,-1,8,0,11448,emily bender,Proceedings of the Workshop on Language in Social Media ({LSM} 2011),0,None
P11-2021,Question Detection in Spoken Conversations Using Textual Conversations,2011,26,11,2,0,44604,anna margolis,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"We investigate the use of textual Internet conversations for detecting questions in spoken conversations. We compare the text-trained model with models trained on manually-labeled, domain-matched spoken utterances with and without prosodic features. Overall, the text-trained model achieves over 90% of the performance (measured in Area Under the Curve) of the domain-matched model including prosodic features, but does especially poorly on declarative questions. We describe efforts to utilize unlabeled spoken utterances and prosodic features via domain adaptation."
W10-2607,Domain Adaptation with Unlabeled Data for Dialog Act Tagging,2010,24,17,3,0,44604,anna margolis,Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing,0,"We investigate the classification of utterances into high-level dialog act categories using word-based features, under conditions where the train and test data differ by genre and/or language. We handle the cross-language cases with machine translation of the test utterances. We analyze and compare two feature-based approaches to using unlabeled data in adaptation: restriction to a shared feature set, and an implementation of Blitzer et al. 's Structural Correspondence Learning. Both methods lead to increased detection of backchannels in the cross-language cases by utilizing correlations between backchannel words and utterance length."
N10-1101,Automatic Generation of Personalized Annotation Tags for {T}witter Users,2010,11,99,3,0,3772,wei wu,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,This paper introduces a system designed for automatically generating personalized annotation tags to label Twitter user's interests and concerns. We applied TFIDF ranking and TextRank to extract keywords from Twitter messages to tag the user. The user tagging precision we obtained is comparable to the precision of keyword extraction from web pages for content-targeted advertising.
N10-1108,Extracting Phrase Patterns with Minimum Redundancy for Unsupervised Speaker Role Classification,2010,8,10,4,0,44384,bin zhang,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper addresses the problem of learning phrase patterns for unsupervised speaker role classification. Phrase patterns are automatically extracted from large corpora, and redundant patterns are removed via a graph pruning algorithm. In experiments on English and Mandarin talk shows, the use of phrase patterns results in an increase of role classification accuracy over n-gram lexical features, and more compact phrase pattern lists are obtained due to the redundancy removal."
N09-2044,Classifying Factored Genres with Part-of-Speech Histograms,2009,11,7,4,0,22697,sergey feldman,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"This work addresses the problem of genre classification of text and speech transcripts, with the goal of handling genres not seen in training. Two frameworks employing different statistics on word/POS histograms with a PCA transform are examined: a single model for each genre and a factored representation of genre. The impact of the two frameworks on the classification of training-matched and new genres is discussed. Results show that the factored models allow for a finer-grained representation of genre and can more accurately characterize genres not seen in training."
W08-0124,Modeling Vocal Interaction for Text-Independent Participant Characterization in Multi-Party Conversation,2008,16,52,2,0.952381,23770,kornel laskowski,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"An important task in automatic conversation understanding is the inference of social structure governing participant behavior. We explore the dependence between several social dimensions, including assigned role, gender, and seniority, and a set of low-level features descriptive of talkspurt deployment in a multiparticipant context. Experiments conducted on two large, publicly available meeting corpora suggest that our features are quite useful in predicting these dimensions, excepting gender. The classification experiments we present exhibit a relative error rate reduction of 37% to 67% compared to choosing the majority class."
N07-2017,i{ROVER}: Improving System Combination with Classification,2007,12,24,3,1,45790,dustin hillard,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"We present an improved system combination technique, iROVER, Our approach obtains significant improvements over ROVER, and is consistently better across varying numbers of component systems. A classifier is trained on features from the system lattices, and selects the final word hypothesis by learning cues to choose the system that is most likely to be correct at each word location. This approach achieves the best result published to date on the TC-STAR 2006 English speech recognition evaluation set."
2007.sigdial-1.33,Modeling Vocal Interaction for Text-Independent Classification of Conversation Type,2007,21,14,2,0.952381,23770,kornel laskowski,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We describe a system for conversation type classification which relies exclusively on multi-participant vocal activity patterns. Using a variation on a well-studied model from stochastic dynamics, we extract features which represent the transition probabilities that characterize the evolution of participant interaction. We also show how vocal interaction can be modeled between specific participant pairs. We apply the proposed system to the task of classifying meeting types in a large multi-party meeting corpus, and achieve a three-way classification accuracy of 84%. This represents a relative error reduction of more than 50% over a baseline which uses only individual speaker times (i.e. no interaction dynamics). Random guessing on this data yields an accuracy of 43%."
2007.sigdial-1.38,Problem-Sensitive Response Generation in Human-Robot Dialogs,2007,-1,-1,2,0,49396,petra gieselmann,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,None
N06-2014,Agreement/Disagreement Classification: Exploiting Unlabeled Data using Contrast Classifiers,2006,10,29,3,0,50063,sangyun hahn,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"Several semi-supervised learning methods have been proposed to leverage unlabeled data, but imbalanced class distributions in the data set can hurt the performance of most algorithms. In this paper, we adapt the new approach of contrast classifiers for semi-supervised learning. This enables us to exploit large amounts of unlabeled data with a skewed distribution. In experiments on a speech act (agreement/disagreement) classification problem, we achieve better results than other semi-supervised methods. We also obtain performance comparable to the best results reported so far on this task and outperform systems with equivalent feature sets."
roark-etal-2006-sparseval,{SP}arseval: Evaluation Metrics for Parsing Speech,2006,12,36,8,0,4293,brian roark,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"While both spoken and written language processing stand to benefit from parsing, the standard Parseval metrics (Black et al., 1991) and their canonical implementation (Sekine and Collins, 1997) are only useful for text. The Parseval metrics are undefined when the words input to the parser do not match the words in the gold standard parse tree exactly, and word errors are unavoidable with automatic speech recognition (ASR) systems. To fill this gap, we have developed a publicly available tool for scoring parses that implements a variety of metrics which can handle mismatches in words and segmentations, including: alignment-based bracket evaluation, alignment-based dependency evaluation, and a dependency evaluation that does not require alignment. We describe the different metrics, how to use the tool, and the outcome of an extensive set of experiments on the sensitivity."
P05-1054,A Quantitative Analysis of Lexical Differences Between Genders in Telephone Conversations,2005,9,29,2,0,50903,constantinos boulis,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"In this work, we provide an empirical analysis of differences in word use between genders in telephone conversations, which complements the considerable body of work in sociolinguistics concerned with gender linguistic differences. Experiments are performed on a large speech corpus of roughly 12000 conversations. We employ machine learning techniques to automatically categorize the gender of each speaker given only the transcript of his/her speech, achieving 92% accuracy. An analysis of the most characteristic words for each gender is also presented. Experiments reveal that the gender of one conversation side influences lexical use of the other side. A surprising result is that we were able to classify male-only vs. female-only conversations with almost perfect accuracy."
P05-1065,Reading Level Assessment Using Support Vector Machines and Statistical Language Models,2005,19,217,2,0,50907,sarah schwarm,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"Reading proficiency is a fundamental component of language competency. However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers. This task can be addressed with natural language processing technology to assess reading level. Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models. In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level."
H05-1030,Effective Use of Prosody in Parsing Conversational Speech,2005,20,36,5,0,50144,jeremy kahn,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"We identify a set of prosodic cues for parsing conversational speech and show how such features can be effectively incorporated into a statistical parsing model. On the Switchboard corpus of conversational speech, the system achieves improved parse accuracy over a state-of-the-art system which uses only lexical and syntactic features. Since removal of edit regions is known to improve downstream parse accuracy, we explore alternatives for edit detection and show that PCFGs are not competitive with more specialized techniques."
N04-4032,Parsing Conversational Speech Using Enhanced Segmentation,2004,8,26,2,0,50144,jeremy kahn,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"The lack of sentence boundaries and presence of disfluencies pose difficulties for parsing conversational speech. This work investigates the effects of automatically detecting these phenomena on a probabilistic parser's performance. We demonstrate that a state-of-the-art segmenter, relative to a pause-based segmenter, gives more than 45% of the possible error reduction in parser performance, and that presentation of interruption points to the parser improves performance over using sentence boundaries alone."
N04-1018,Detecting Structural Metadata with Decision Trees and Transformation-Based Learning,2004,14,35,3,0,51893,joungbum kim,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,"Abstract : The regular occurrence of disfluencies is a distinguishing characteristic of spontaneous speech. Detecting and removing such disfluencies can substantially improve the usefulness of spontaneous speech transcripts. This paper presents a system that detects various types of disfluences and other structural information with cues obtained from lexical and prosodic information sources. Specifically, combinations of decision trees and language models are used to predict sentence ends and interruption points and given these events transformation based learning is used to detect edit disfluencies and conversational fillers. Results are reported on human and automatic transcripts of conversational telephone speech."
W03-0703,Directions For Multi-Party Human-Computer Interaction Research,2003,10,3,2,0,3723,katrin kirchhoff,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Research Directions in Dialogue Processing,0,"Research on dialog systems has so far concentrated on interactions between a single user and a machine. In this paper we identify novel research directions arising from multi-party human computer interaction, i.e. scenarios where several human participants interact with a dialog system."
N03-2003,Getting More Mileage from Web Text Sources for Conversational Speech Language Modeling using Class-Dependent Mixtures,2003,16,130,2,0,7924,ivan bulyko,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Short Papers,0,"Sources of training data suitable for language modeling of conversational speech are limited. In this paper, we show how training data can be supplemented with text from the web filtered to match the style and/or topic of the target recognition task, but also that it is possible to get bigger performance gains from the data by using class-dependent interpolation of N-grams."
N03-2012,Detection Of Agreement vs. Disagreement In Meetings: Training With Unlabeled Data,2003,10,141,2,1,45790,dustin hillard,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Short Papers,0,"To support summarization of automatically transcribed meetings, we introduce a classifier to recognize agreement or disagreement utterances, utilizing both word-based and prosodic cues. We show that hand-labeling efforts can be minimized by using unsupervised training on a large unlabeled data set combined with supervised training on a small amount of data. For ASR transcripts with over 45% WER, the system recovers nearly 80% of agree/disagree utterances with a confusion rate of only 3%."
H01-1034,Improving Information Extraction by Modeling Errors in Speech Recognizer Output,2001,5,21,2,0,51834,david palmer,Proceedings of the First International Conference on Human Language Technology Research,0,"In this paper we describe a technique for improving the performance of an information extraction system for speech data by explicitly modeling the errors in the recognizer output. The approach combines a statistical model of named entity states with a lattice representation of hypothesized words and errors annotated with recognition confidence scores. Additional refinements include the use of multiple error types, improved confidence estimation, and multipass processing. In combination, these techniques improve named entity recognition performance over a text-based baseline by 28%."
H94-1014,Language Modeling with Sentence-Level Mixtures,1994,16,47,2,0,55897,rukmini iyer,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"This paper introduces a simple mixture language model that attempts to capture long distance constraints in a sentence or paragraph. The model is an m-component mixture of trigram models. The models were constructed using a 5K vocabulary and trained using a 76 million word Wall Street Journal text corpus. Using the BU recognition system, experiments show a 7% improvement in recognition accuracy with the mixture trigram models as compared to using a trigram model."
H94-1092,Segment-Based Acoustic Models for Continuous Speech Recognition,1994,0,0,1,1,8900,mari ostendorf,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"The goal of this project is to develop improved statistical models for speaker-independent recognition of continuous speech, together with efficient search algorithms appropriate for use with these models. The current work on acoustic modeling is focussed on: stochastic, segment-based models that capture the time correlation of a sequence of observations (feature vectors) that correspond to a phoneme; hierarchical stochastic models that capture higher level intra-utterance correlation; and multi-pass search algorithms for implementing these more complex models. In addition, we have extended the effort on models of high order statistical dependence to language modeling. This research has been jointly sponsored by ARPA and NSF under NSF grant IRI-8902124 and by ARPA and ONR under ONR grant N00014-92-J-1778."
H93-1020,On the Use of Tied-Mixture Distributions,1993,18,9,2,0,56783,owen kimball,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"Tied-mixture (or semi-continuous) distributions are an important tool for acoustic modeling, used in many high-performance speech recognition systems today. This paper provides a survey of the work in this area, outlining the different options available for tied mixture modeling, introducing algorithms for reducing training time, and providing experimental results assessing the trade-offs for speaker-independent recognition on the Resource Management task. Additionally, we describe an extension of tied mixtures to segment-level distributions."
H93-1082,Evaluating the Use of Prosodic Information in Speech Recognition and Understanding,1993,-1,-1,1,1,8900,mari ostendorf,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,None
H93-1083,Segment-Based Acoustic Models for Continuous Speech Recognition,1993,0,0,1,1,8900,mari ostendorf,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,None
H92-1038,Recognition Using Classification and Segmentation Scoring,1992,10,1,2,0,56783,owen kimball,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,"Traditional statistical speech recognition systems typically make strong assumptions about the independence of observation frames and generally do not make use of segmental information. In contrast, when the segmentation is known, existing classifiers can readily accommodate segmental information in the decision process. We describe an approach to connected word recognition that allows the use of segmental information through an explicit decomposition of the recognition criterion into classification and segmentation scoring. Preliminary experiments are presented, demonstrating that the proposed framework, using fixed length sequences of cepstral feature vectors for classification of individual phonemes, performs comparably to more traditional recognition approaches that use the entire observation sequence. We expect that performance gain can be obtained using this structure with additional, more general features."
H92-1093,Weight Estimation for {N}-Best Rescoring,1992,5,10,2,0,57036,ashvin kannan,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,This paper describes recent improvements in the weight estimation technique for sentence hypothesis rescoring using the N-Best formalism. Mismatches between training and test data are also explored.
H92-1099,Evaluating the Use of Prosodic Information in Speech Recognition and Understanding,1992,-1,-1,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,None
H92-1100,Segment-Based Acoustic Models with Multi-level Search Algorithms for Continuous Speech Recognition,1992,-1,-1,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,None
H91-1038,Session 6: Demonstrations and Videotapes of Speech and Natural Language Technologies,1991,0,0,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"Harvey Silverman, from Brown, showed a video illustrating signal and noise separation using microphone arrays. Such algorithms can improve speech recognition performance in noisy environments and free the user from the close-talking microphone. Not surprisingly, algorithm performance in a realistic environment with reverberation noise is not as good as the theory predicts, and much research remains in this area."
H91-1073,The Use of Prosody in Syntactic Disambiguation,1991,20,13,2,0,54006,patti price,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"Prosodic structure and syntactic structure are not identical; neither are they unrelated. Knowing when and how the two eorrespoud could yield better quality speech synthesis, could aid in the disambiguation of competing syntactic hypotheses in speech understanding, and could lead to a more comprehensive view of human speech processing. In a set of experiments involving 35 pairs of phonetically similar sentences representing seven types of structural contrasts, the perceptual evidence shows that some, but not all, of the pairs can be disambiguated on the basis of prosodie differences. The phonological evidence relates the disambiguation primarily to boundary phenomena, although prominences sometimes play a role. Finally, phonetic analyses describing the attributes of these phonological markers indicate the importance of both absolute and relative measures."
H91-1082,Evaluating the Use of Prosodic Information in Speech Recognition and Understanding,1991,-1,-1,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,None
H91-1083,Segment-Based Acoustic Models with Multi-level Search Algorithms for Continuous Speech Recognition,1991,-1,-1,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,None
H90-1081,Evaluating the Use of Prosodic Information in Speech Recognition and Understanding,1990,0,2,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The goal of this project is to investigate the use of different levels of prosodic information in speech recognition and understanding. In particular, the current focus of the work is the use of prosodic phrase boundary information in parsing. The research involves determining a representation of prosodic information suitable for use in a speech understanding system, developing reliable algorithms for detection of the prosodic cues in speech, investigating architectures for integrating prosodic cues in a parser, and evaluating the potential improvements of prosody in the context of the SRI Spoken Language System. This research is sponsored jointly by DARPA and NSF."
H90-1082,Segment-Based Acoustic Models with Multi-level Search Algorithms for Continuous Speech Recognition,1990,0,0,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The goal of this project is to develop improved acoustic models for speaker-independent recognition of continuous speech, together with efficient search algorithms appropriate for use with these models. The current work on acoustic modelling is focussed on stochastic, segment-based models that capture the time correlation of a sequence of observations (feature vectors) that correspond to a phoneme. Since the use of segment models is computationally complex, we will also investigate multi-level, iterative algorithms to achieve a more efficient search. Furthermore, these algorithms will provide a formalism for incorporating higher-order information. This research is jointly sponsored by DARPA and NSF."
H89-2061,Evaluating the Use of Prosodic Information in Speech Recognition and Understanding,1989,-1,-1,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,None
H89-2062,Segment-Based Acoustic Models with Multi-level Search Algorithms for Continuous Speech Recognition,1989,-1,-1,1,1,8900,mari ostendorf,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,None
