2020.lrec-1.421,Related Works in the {L}inguistic {D}ata {C}onsortium Catalog,2020,-1,-1,2,0,17559,daniel jaquette,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Defining relations between language resources provides an archive with the ability to better serve its users. This paper covers the development and implementation of a Related Works addition to the Linguistic Data Consortium{'}s (LDC) catalog. The authors go step-by-step through the development of the Related Works schema, implementation of the software and database changes, and data entry of the relations. The Related Work schema involved developing of a set of controlled terms for relations based on previous work and other schema. Software and database changes consisted of both front and back end interface additions, along with modification and additions to the LDC Catalog database tables. Data entry consisted of two parts: seed data from previous work and 2019 language resources, and ongoing legacy population. Previous work in this area is discussed as well as overview information about the LDC Catalog. A list of the full LDC Related Works terms is included with brief explanations."
2020.lrec-1.423,A Progress Report on Activities at the {L}inguistic {D}ata {C}onsortium Benefitting the {LREC} Community,2020,-1,-1,1,1,17560,christopher cieri,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This latest in a series of Linguistic Data Consortium (LDC) progress reports to the LREC community does not describe any single language resource, evaluation campaign or technology but sketches the activities, since the last report, of a data center devoted to supporting the work of LREC attendees among other research communities. Specifically, we describe 96 new corpora released in 2018-2020 to date, a new technology evaluation campaign, ongoing activities to support multiple common task human language technology programs, and innovations to advance the methodology of language data collection and annotation."
2020.lr4sshoc-1.8,Stretching Disciplinary Boundaries in Language Resource Development and Use: a {L}inguistic {D}ata {C}onsortium Position Paper,2020,-1,-1,1,1,17560,christopher cieri,Proceedings of the Workshop about Language Resources for the SSH Cloud,0,"Given the persistent gap between demand and supply, the impetus to reuse language resources is great. Researchers benefit from building upon the work of others including reusing data, tools and methodology. Such reuse should always consider the original intent of the language resource and how that impacts potential reanalysis. When the reuse crosses disciplinary boundaries, the re-user also needs to consider how research standards that differ between social science and humanities on the one hand and human language technologies on the other might lead to differences in unspoken assumptions. Data centers that aim to support multiple research communities have a responsibility to build bridges across disciplinary divides by sharing data in all directions, encouraging re-use and re-sharing and engaging directly in research that improves methodologies."
2020.cllrd-1.1,{L}anguage{ARC}: Developing Language Resources Through Citizen Linguistics,2020,-1,-1,2,0,17563,james fiumara,Proceedings of the LREC 2020 Workshop on ``Citizen Linguistics in Language Resource Development'',0,"This paper introduces the citizen science platform, LanguageARC, developed within the NIEUW (Novel Incentives and Workflows) project supported by the National Science Foundation under Grant No. 1730377. LanguageARC is a community-oriented online platform bringing together researchers and {``}citizen linguists{''} with the shared goal of contributing to linguistic research and language technology development. Like other Citizen Science platforms and projects, LanguageARC harnesses the power and efforts of volunteers who are motivated by the incentives of contributing to science, learning and discovery, and belonging to a community dedicated to social improvement. Citizen linguists contribute language data and judgments by participating in research tasks such as classifying regional accents from audio clips, recording audio of picture descriptions and answering personality questionnaires to create baseline data for NLP research into autism and neurodegenerative conditions. Researchers can create projects on Language ARC without any coding or HTML required using our Project Builder Toolkit."
2020.cllrd-1.8,{L}anguage{ARC} - a tutorial,2020,-1,-1,1,1,17560,christopher cieri,Proceedings of the LREC 2020 Workshop on ``Citizen Linguistics in Language Resource Development'',0,LanguageARC is a portal that offers citizen linguists opportunities to contribute to language related research. It also provides researchers with infrastructure for easily creating data collection and annotation tasks on the portal and potentially connecting with contributors. This document describes LanguageARC{'}s main features and operation for researchers interested in creating new projects and or using the resulting data.
L18-1024,Introducing {NIEUW}: Novel Incentives and Workflows for Eliciting Linguistic Data,2018,0,0,1,1,17560,christopher cieri,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1516,From {`}Solved Problems{'} to New Challenges: A Report on {LDC} Activities,2018,0,0,1,1,17560,christopher cieri,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W16-0308,Exploring Autism Spectrum Disorders Using {HLT},2016,7,7,4,0,24556,julia parishmorris,Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology,0,None
L16-1073,The Language Application Grid and Galaxy,2016,0,0,5,0,16303,nancy ide,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The NSF-SI2-funded LAPPS Grid project is a collaborative effort among Brandeis University, Vassar College, Carnegie-Mellon University (CMU), and the Linguistic Data Consortium (LDC), which has developed an open, web-based infrastructure through which resources can be easily accessed and within which tailored language services can be efficiently composed, evaluated, disseminated and consumed by researchers, developers, and students across a wide variety of disciplines. The LAPPS Grid project recently adopted Galaxy (Giardine et al., 2005), a robust, well-developed, and well-supported front end for workflow configuration, management, and persistence. Galaxy allows data inputs and processing steps to be selected from graphical menus, and results are displayed in intuitive plots and summaries that encourage interactive workflows and the exploration of hypotheses. The Galaxy workflow engine provides significant advantages for deploying pipelines of LAPPS Grid web services, including not only means to create and deploy locally-run and even customized versions of the LAPPS Grid as well as running the LAPPS Grid in the cloud, but also access to a huge array of statistical and visualization tools that have been developed for use in genomics research."
L16-1255,Trends in {HLT} Research: A Survey of {LDC}{'}s Data Scholarship Program,2016,0,0,2,0.925926,17561,denise dipersio,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Since its inception in 2010, the Linguistic Data Consortium{'}s data scholarship program has awarded no cost grants in data to 64 recipients from 26 countries. A survey of the twelve cycles to date â two awards each in the Fall and Spring semesters from Fall 2010 through Spring 2016 â yields an interesting view into graduate program research trends in human language technology and related fields and the particular data sets deemed important to support that research. The survey also reveals regions in which such activity appears to be on a rise, including in Arabic-speaking regions and portions of the Americas and Asia."
L16-1333,Building Language Resources for Exploring Autism Spectrum Disorders,2016,19,4,2,0,24556,julia parishmorris,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Autism spectrum disorder (ASD) is a complex neurodevelopmental condition that would benefit from low-cost and reliable improvements to screening and diagnosis. Human language technologies (HLTs) provide one possible route to automating a series of subjective decisions that currently inform {``}Gold Standard{''} diagnosis based on clinical judgment. In this paper, we describe a new resource to support this goal, comprised of 100 20-minute semi-structured English language samples labeled with child age, sex, IQ, autism symptom severity, and diagnostic classification. We assess the feasibility of digitizing and processing sensitive clinical samples for data sharing, and identify areas of difficulty. Using the methods described here, we propose to join forces with researchers and clinicians throughout the world to establish an international repository of annotated language samples from individuals with ASD and related disorders. This project has the potential to improve the lives of individuals with ASD and their families by identifying linguistic features that could improve remote screening, inform personalized intervention, and promote advancements in clinically-oriented HLTs."
L16-1396,Data Management Plans and Data Centers,2016,0,0,2,0.925926,17561,denise dipersio,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Data management plans, data sharing plans and the like are now required by funders worldwide as part of research proposals. Concerned with promoting the notion of open scientific data, funders view such plans as the framework for satisfying the generally accepted requirements for data generated in funded research projects, among them that it be accessible, usable, standardized to the degree possible, secure and stable. This paper examines the origins of data management plans, their requirements and issues they raise for data centers and HLT resource development in general."
L16-1720,Selection Criteria for Low Resource Language Programs,2016,5,6,1,1,17560,christopher cieri,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper documents and describes the criteria used to select languages for study within programs that include low resource languages whether given that label or another similar one. It focuses on five US common task, Human Language Technology research and development programs in which the authors have provided information or consulting related to the choice of language. The paper does not describe the actual selection process which is the responsibility of program management and highly specific to a program{'}s individual goals and context. Instead it concentrates on the data and criteria that have been considered relevant previously with the thought that future program managers and their consultants may adapt these and apply them with different prioritization to future programs."
W14-5211,Intellectual Property Rights Management with Web Service Grids,2014,6,3,1,1,17560,christopher cieri,Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for {HLT},0,"This paper enumerates the ways in which configurations of web services may complicate issues of licensing language resources, whether data or tools. It details specific licensing challenges within the context of the US Language Application (LAPPS) Grid, sketches a solution under development and highlights ways in which that approach may be extended for other web service configurations."
cieri-etal-2014-new,New Directions for Language Resource Development and Distribution,2014,12,2,1,1,17560,christopher cieri,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Despite the growth in the number of linguistic data centers around the world, their accomplishments and expansions and the advances they have help enable, the language resources that exist are a small fraction of those required to meet the goals of Human Language Technologies (HLT) for the worldÂs languages and the promises they offer: broad access to knowledge, direct communication across language boundaries and engagement in a global community. Using the Linguistic Data Consortium as a focus case, this paper sketches the progress of data centers, summarizes recent activities and then turns to several issues that have received inadequate attention and proposes some new approaches to their resolution."
ide-etal-2014-language,The Language Application Grid,2014,19,32,3,0,16303,nancy ide,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Language Application (LAPPS) Grid project is establishing a framework that enables language service discovery, composition, and reuse and promotes sustainability, manageability, usability, and interoperability of natural language Processing (NLP) components. It is based on the service-oriented architecture (SOA), a more recent, web-oriented version of the ÂpipelineÂ architecture that has long been used in NLP for sequencing loosely-coupled linguistic analyses. The LAPPS Grid provides access to basic NLP processing tools and resources and enables pipelining such tools to create custom NLP applications, as well as composite services such as question answering and machine translation together with language resources such as mono- and multi-lingual corpora and lexicons that support NLP. The transformative aspect of the LAPPS Grid is that it orchestrates access to and deployment of language resources and processing functions available from servers around the globe and enables users to add their own language resources, services, and even service grids to satisfy their particular needs."
mariani-etal-2014-facing,Facing the Identification Problem in Language-Related Scientific Data Analysis.,2014,5,4,2,0,29836,joseph mariani,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes the problems that must be addressed when studying large amounts of data over time which require entity normalization applied not to the usual genres of news or political speech, but to the genre of academic discourse about language resources, technologies and sciences. It reports on the normalization processes that had to be applied to produce data usable for computing statistics in three past studies on the LRE Map, the ISCA Archive and the LDC Bibliography. It shows the need for human expertise during normalization and the necessity to adapt the work to the study objectives. It investigates possible improvements for reducing the workload necessary to produce comparable results. Through this paper, we show the necessity to define and agree on international persistent and unique identifiers."
labropoulou-etal-2014-developing,Developing a Framework for Describing Relations among Language Resources,2014,8,0,2,0,11086,penny labropoulou,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we study relations holding between language resources as implemented in activities concerned with their documentation. We envision the term Âlanguage resourcesÂ with an inclusive definition covering datasets (corpora, lexica, ontologies, grammars, etc.), tools (including web services, workflows, platforms etc.), related publications and documentation, specifications and guidelines. However, the scope of the paper is limited to relations holding for datasets and tools. The study fosuses on the META-SHARE infrastructure and the Linguistic Data Consortium and takes into account the ISOcat DCR relations. Based on this study, we propose a taxonomy of relations, discuss their semantics and provide specifications for their use in order to cater for semantic interoperability. Issues of granularity, redundancy in codification, naming conventions and semantics of the relations are presented."
ahtaridis-etal-2012-ldc,{LDC} Language Resource Database: Building a Bibliographic Database,2012,1,2,2,0,43264,eleftheria ahtaridis,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The Linguistic Data Consortium (LDC) creates and provides language resources (LRs) including data, tools and specifications. In order to assess the impact of these LRs and to support both LR users and authors, LDC is collecting metadata about and URLs for research papers that introduce, describe, critique, extend or rely upon LDC LRs. Current collection efforts focus on papers published in journals and conference proceedings that are available online. To date, nearly 300, or over half of the LRs LDC distributes have been searched for extensively and almost 8000 research papers about these LRs have been documented. This paper discusses the issues with collecting references and includes preliminary analysis of those results. The remaining goals of the project are also outlined."
cieri-etal-2012-twenty,Twenty Years of Language Resource Development and Distribution: A Progress Report on {LDC} Activities,2012,11,1,1,1,17560,christopher cieri,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"On the Linguistic Data Consortium's (LDC) 20th anniversary, this paper describes the changes to the language resource landscape over the past two decades, how LDC has adjusted its practice to adapt to them and how the business model continues to grow. Specifically, we will discuss LDC's evolving roles and changes in the sizes and types of LDC language resources (LR) as well as the data they include and the annotations of that data. We will also discuss adaptations of the LDC business model and the sponsored projects it supports."
liu-etal-2010-large,A Very Large Scale {M}andarin {C}hinese Broadcast Corpus for {GALE} Project,2010,0,0,7,0,875,yi liu,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we present the design, collection, transcription and analysis of a Mandarin Chinese Broadcast Collection of over 3000 hours. The data was collected by Hong Kong University of Science and Technology (HKUST) in China on a cable TV and satellite transmission platform established in support of the DARPA Global Autonomous Language Exploitation (GALE) program. The collection includes broadcast news (BN) and broadcast conversation (BC) including talk shows, roundtable discussions, call-in shows, editorials and other conversational programs that focus on news and current events. HKUST also collects detailed information about all recorded programs. A subset of BC and BN recordings are manually transcribed with standard Chinese characters in UTF-8 encoding, using specific mark-ups for a small set of spontaneous and conversational speech phenomena. The collection is among the largest and first of its kind for Mandarin Chinese Broadcast speech, providing abundant and diverse samples for Mandarin speech recognition and other application-dependent tasks, such as spontaneous speech processing and recognition, topic detection, information retrieval, and speaker recognition. HKUST{\^a}ÂÂs acoustic analysis of 500 hours of the speech and transcripts demonstrates the positive impact this data could have on system performance."
brandschain-etal-2010-greybeard,Greybeard Longitudinal Speech Study,2010,0,3,3,1,46295,linda brandschain,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The Greybeard Project was designed so as to enable research in speaker recognition using data that have been collected over a long period of time. Since 1994, LDC has been collecting speech samples for use in research and evaluations. By mining our earlier collections we assembled a list of subjects who had participated in multiple studies. These participants were then contacted and asked to take part in the Greybeard Project. The only constraint was that the participants must have made numerous calls in prior studies and the calls had to be a minimum of two years old. The archived data was sorted by participant and subsequent calls were added to their files. This is the first longitudinal study of its kind. The resulting corpus contains multiple calls for each participant that span anywhere from two to 12 years in time. It is our hope that these data will enable speaker recognition researchers to explore the effects of aging on voice."
cieri-etal-2010-road,A Road Map for Interoperable Language Resource Metadata,2010,0,5,1,1,17560,christopher cieri,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"LRs remain expensive to create and thus rare relative to demand across languages and technology types. The accidental re-creation of an LR that already exists is a nearly unforgivable waste of scarce resources that is unfortunately not so easy to avoid. The number of catalogs the HLT researcher must search, with their different formats, make it possible to overlook an existing resource. This paper sketches the sources of this problem and outlines a proposal to rectify along with a new vision of LR cataloging that will to facilitates the documentation and exploitation of a much wider range of LRs than previously considered."
cieri-liberman-2010-adapting,Adapting to Trends in Language Resource Development: A Progress Report on {LDC} Activities,2010,4,1,1,1,17560,christopher cieri,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes changing needs among the communities that exploit language resources and recent LDC activities and publications that support those needs by providing greater volumes of data and associated resources in a growing inventory of languages with ever more sophisticated annotation. Specifically, it covers the evolving role of data centers with specific emphasis on the LDC, the publications released by the LDC in the two years since our last report and the sponsored research programs that provide LRs initially to participants in those programs but eventually to the larger HLT research communities and beyond."
W09-3408,Basic Language Resources for Diverse {A}sian Languages: A Streamlined Approach for Resource Creation,2009,2,3,3,0,46212,heather simpson,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"The REFLEX-LCTL (Research on English and Foreign Language Exploitation-Less Commonly Taught Languages) program, sponsored by the United States government, was an effort in simultaneous creation of basic language resources and technologies for under-resourced languages, with the aim to enrich sparse areas in language technology resources and encourage new research. We were tasked to produce basic language resources for 8 Asian languages: Bengali, Pashto, Punjabi, Tamil, Tagalog, Thai, Urdu and Uzbek, and 5 languages from Europe and Africa, and distribute them to research and development also funded by the program. This paper will discuss the streamlined approach to language resource development we designed to support simultaneous creation of multiple resources for multiple languages."
reed-etal-2008-linguistic,"The {L}inguistic {D}ata {C}onsortium Member Survey: Purpose, Execution and Results",2008,2,0,3,0,43367,marian reed,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The Linguistic Data Consortium (LDC) seeks to provide its members with quality linguistic resources and services. In order to pursue these ideals and to remain current, LDC monitors the needs and sentiments of its communities. One mechanism LDC uses to generate feedback on consortium and resource issues is the LDC Member Survey. The survey allows LDC Members and nonmembers to provide LDC with valuable insight into their own unique circumstances, their current and future data needs and their views on LDCÂs role in meeting them. When the 2006 Survey was found to be a useful tool for communicating with the Consortium membership, a 2007 Survey was organized and administered. As a result of the surveys, LDC has confirmed that it has made a positive impact on the community and has identified ways to improve the quality of service and the diversity of monthly offerings. Many respondents recommended ways to improve LDCÂs functions, ordering mechanism and webpage. Some of these comments have inspired changes to LDCÂs operation and strategy."
cieri-liberman-2008-15,15 Years of Language Resource Creation and Sharing: a Progress Report on {LDC} Activities,2008,1,5,1,1,17560,christopher cieri,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper, the fifth in a series of biennial progress reports, reviews the activities of the Linguistic Data Consortium with particular emphasis on general trends in the language resource landscape and on changes that distinguish the two years since LDCÂs last report at LREC from the preceding 8 years. After providing a perspective on the current landscape of language resources, the paper goes on to describe our vision of the role of LDC within the research communities it serves before sketching briefly specific publications and resources creations projects that have been the focus our attention since the last report."
cieri-etal-2008-bridging,"Bridging the Gap between Linguists and Technology Developers: Large-Scale, Sociolinguistic Annotation for Dialect and Speaker Recognition",2008,4,3,1,1,17560,christopher cieri,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Recent years have seen increased interest within the speaker recognition community in high-level features including, for example, lexical choice, idiomatic expressions or syntactic structures. The promise of speaker recognition in forensic applications drives development toward systems robust to channel differences by selecting features inherently robust to channel difference. Within the language recognition community, there is growing interest in differentiating not only languages but also mutually intelligible dialects of a single language. Decades of research in dialectology suggest that high-level features can enable systems to cluster speakers according to the dialects they speak. The Phanotics (Phonetic Annotation of Typicality in Conversational Speech) project seeks to identify high-level features characteristic of American dialects, annotate a corpus for these features, use the data to dialect recognition systems and also use the categorization to create better models for speaker recognition. The data, once published, should be useful to other developers of speaker and dialect recognition systems and to dialectologists and sociolinguists. We expect the methods will generalize well beyond the speakers, dialects, and languages discussed here and should, if successful, provide a model for how linguists and technology developers can collaborate in the future for the benefit of both groups and toward a deeper understanding of how languages vary and change."
brandschain-etal-2008-speaker,Speaker Recognition: Building the Mixer 4 and 5 Corpora,2008,3,6,2,1,46295,linda brandschain,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The original Mixer corpus was designed to satisfy developing commercial and forensic needs. The resulting Mixer corpora, Phases 1 through 5, have evolved to support and increasing variety of research tasks, including multilingual and cross-channel recognition. The Mixer Phases 4 and 5 corpora feature a wider variety of channels and greater variation in the situations under which the speech is recorded. This paper focuses on the plans, progress and results of Mixer 4 and 5."
2007.mtsummit-aptme.4,Linguistic resources in support of various evaluation metrics,2007,-1,-1,1,1,17560,christopher cieri,Proceedings of the Workshop on Automatic procedures in MT evaluation,0,None
cieri-etal-2006-mixer,"The Mixer and Transcript Reading Corpora: Resources for Multilingual, Crosschannel Speaker Recognition Research",2006,3,22,1,1,17560,christopher cieri,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes the planning and creation of the Mixer and Transcript Reading corpora, their properties and yields, and reports on the lessons learned during their development."
cieri-liberman-2006-data,More Data and Tools for More Languages and Research Areas: A Progress Report on {LDC} Activities,2006,5,5,1,1,17560,christopher cieri,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This presentation reports on recent progress the Linguistic Data Consortium has made in addressing the needs of multiple research communities by collecting, annotating and distributing, simplifying access and developing standards and tools. Specifically, it describes new trends in publication, a sample of recent projects and significant improvements to LDC Online that improve access to LDC data especially for those with limited computing support."
strassel-etal-2006-integrated,Integrated Linguistic Resources for Language Exploitation Technologies,2006,3,9,2,0.571429,14744,stephanie strassel,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Linguistic Data Consortium has recently embarked on an effort to create integrated linguistic resources and related infrastructure for language exploitation technologies within the DARPA GALE (Global Autonomous Language Exploitation) Program. GALE targets an end-to-end system consisting of three major engines: Transcription, Translation and Distillation. Multilingual speech or text from a variety of genres is taken as input and English text is given as output, with information of interest presented in an integrated and consolidated fashion to the end user. GALE's goals require a quantum leap in the performance of human language technology, while also demanding solutions that are more intelligent, more robust, more adaptable, more efficient and more integrated. LDC has responded to this challenge with a comprehensive approach to linguistic resource development designed to support GALE's research and evaluation needs and to provide lasting resources for the larger Human Language Technology community."
ma-cieri-2006-corpus,Corpus Support for Machine Translation at {LDC},2006,11,17,2,0,37104,xiaoyi ma,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes LDC's efforts in collecting, creating and processing different types of linguistic data, including lexicons, parallel text, multiple translation corpora, and human assessment of translation quality, to support the research and development in Machine Translation. Through a combination of different procedures and core technologies, the LDC was able to create very large, high quality, and cost-efficient corpora, which have contributed significantly to recent advances in Machine Translation. Multiple translation corpora and human assessment together facilitate, validate and improve automatic evaluation metrics, which are vital to the development of MT systems. The Bilingual Internet Text Search (BITS) and Champollion sentence aligner enable the finding and processing of large quantities of parallel text. All specifications and tools used by LDC and described in the paper are or will be available to the general public."
maeda-etal-2006-low,Low-cost Customized Speech Corpus Creation for Speech Technology Applications,2006,4,0,2,0.5,46240,kazuaki maeda,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Speech technology applications, such as speech recognition, speech synthesis, and speech dialog systems, often require corpora based on highly customized specifications. Existing corpora available to the community, such as TIMIT and other corpora distributed by LDC and ELDA, do not always meet the requirements of such applications. In such cases, the developers need to create their own corpora. The creation of a highly customized speech corpus, however, could be a very expensive and time-consuming task, especially for small organizations. It requires multidisciplinary expertise in linguistics, management and engineering as it involves subtasks such as the corpus design, human subject recruitment, recording, quality assurance, and in some cases, segmentation, transcription and annotation. This paper describes LDC's recent involvement in the creation of a low-cost yet highly-customized speech corpus for a commercial organization under a novel data creation and licensing model, which benefits both the particular data requester and the general linguistic data user community."
macwhinney-etal-2004-talkbank,{T}alkbank: Building an Open Unified Multimodal Database of Communicative Interaction,2004,3,11,3,0,34440,brian macwhinney,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The goal of the TalkBank project (http://talkbank.org) is to support data-sharing and direct, community-wide access to naturalistic recordings and transcripts of human and animal communication. Toward this end, we have constructed a web accessible database of transcripts linked to audio and video media within fields such as conversation analysis, classroom discourse, animal communication, gesture, meetings, second language acquisition, first language acquisition, bilingualism, tutoring, and legal oral argumentation. We discuss how we have taken discrepant databases from dozens of individual projects and merged them together into a well-structured uniform database in which transcripts can be opened online through browsers, allowing direct multimedia playback. To achieve translation across corpora, we have defined a general XML schema. The validity of this schema is checked by bidirectional conversion from alternative input formats to XML and back. The resultant transcripts are then linked to hinted media and XSLT is used to format web readable browsable multimedia transcripts playable through SMIL. A parallel pathway is used to support collaborative commentary and publication of PDF linked to media through special issues of journals in the relevant fields."
cieri-etal-2004-fisher,The Fisher Corpus: a Resource for the Next Generations of Speech-to-Text,2004,1,278,1,1,17560,christopher cieri,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes, within the context of the DARPA EARS program, the design and implementation of the Fisher protocol for collecting conversational telephone speech which has yielded more than 16,000 English conversations. It also discusses the Quick Transcription specification that allowed 2000 hours of Fisher audio to be transcribed in less than one year. Fisher data is already in use within the DARPA EARS programs and will be published via the Linguistic Data Consortium for general use beginning in 2004."
cieri-etal-2004-mixer,"The Mixer Corpus of Multilingual, Multichannel Speaker Recognition Data",2004,12,32,1,1,17560,christopher cieri,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Abstract : This paper describes efforts to create corpora to support and evaluate systems that perform speaker recognition where channel and language may vary. Beyond the ongoing evaluation of speaker recognition systems, these corpora are aimed at the bilingual and cross channel dimensions. We report on specific data collection efforts at the Linguistic Data Consortium and the research ongoing at the US Federal Bureau of Investigation and MIT Lincoln Laboratories. We cover the design and requirements, the collections and final properties of the corpus integrating discussions of the data preparation, research, technology development and evaluation on a grand scale."
cieri-liberman-2004-progress,A Progress Report from the {L}inguistic {D}ata {C}onsortium: Recent Activities in Resource Creation and Distribution and the Development of Tools and Standards,2004,3,2,1,1,17560,christopher cieri,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper described recent activities of the Linguistic Data Consortium in the collection, annotation and distribution of language data the developments of tools and standards for using that data, the creation of metadata to facilitate the search for linguistic resources."
cieri-liberman-2002-language,Language Resource Creation and Distribution at the {L}inguistic {D}ata {C}onsortium: A Progress Report,2002,8,0,1,1,17560,christopher cieri,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
cieri-liberman-2002-tides,{TIDES} Language Resources: A Resource Map for Translingual Information Access,2002,7,7,1,1,17560,christopher cieri,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
cieri-strassel-2002-dasl,The {DASL} Project: a Case Study in Data Re-Annotation and Re-Use,2002,6,0,1,1,17560,christopher cieri,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
W01-1514,"Annotation Graphs and Servers and Multi-Modal Resources: Infrastructure for Interdisciplinary Education, Research and Development",2001,8,7,1,1,17560,christopher cieri,Proceedings of the {ACL} 2001 Workshop on Sharing Tools and Resources,0,"Annotation graphs and annotation servers offer infrastructure to support the analysis of human language resources in the form of time-series data such as text, audio and video. This paper outlines areas of common need among empirical linguists and computational linguists. After reviewing examples of data and tools used or under development for each of several areas, it proposes a common framework for future tool development, data annotation and resource sharing based upon annotation graphs and servers."
cieri-liberman-2000-issues,Issues in Corpus Creation and Distribution: The Evolution of the {L}inguistic {D}ata {C}onsortium,2000,7,7,1,1,17560,christopher cieri,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,None
cieri-etal-2000-large,"Large, Multilingual, Broadcast News Corpora for Cooperative Research in Topic Detection and Tracking: The {TDT}-2 and {TDT}-3 Corpus Efforts",2000,4,18,1,1,17560,christopher cieri,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"This paper describes the creation and content two corpora, TDT-2 and TDT-3, created for the DARPA sponsored Topic Detection and Tracking project. The research goal in the TDT program is to create the core technology of a news understanding system that can process multilingual news content categorizing individual stories according to the topic(s) they describe. The research tasks include segmentation of the news streams into individual stories, detection of new topics, identification of the first story to discuss any topic, tracking of all stories on selected topics and detection of links among stories discussing the same topics. The corpora contain English and Chinese broadcast television and radio, newswires, and text from web sites devoted to news. For each source there are texts or text intermediaries; for the broadcast stories the audio is also available. Each broadcast is also segment to show start and end times of all news stories. LDC staff have defined news topics in the corpora and annotated each story to indicate its relevance to each topic. The end products are massive, richly annotated corpora available to support research and development in information retrieval, topic detection and tracking, information extraction message understanding directly or after additional annotation. This paper will describe the corpora created for TDT including sources, collection processes, formats, topic selection and definition, annotation, distribution and project management for large corpora."
strassel-etal-2000-quality,Quality Control in Large Annotation Projects Involving Multiple Judges: The Case of the {TDT} Corpora,2000,3,11,4,0,14744,stephanie strassel,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The Linguistic Data Consortium at the University of Pennsylvania has recently been engaged in the creation of large-scale annotated corpora of broadcast news materials in support of the ongoing Topic Detection and Tracking (TDT) research project. The TDT corpora were designed to support three basic research tasks: segmentation, topic detection, and topic tracking in newswire, television and radio sources from English and Mandarin Chinese. The most recent TDT corpus, TDT3, added two tasks, story link and first story detection. Annotation of the TDT corpora involved a large staff of annotators who produced millions of human judgements. As with any large corpus creation effort, quality assurance and inter-annotator consistency were a major concern. This paper reports the quality control measures adopted by the LDC during the creation of the TDT corpora, presents techniques that were utilized to evaluate and improve the consistency of human annotators for all annotation tasks, and discusses aspects of project administration that were designed to enhance annotation consistency."
