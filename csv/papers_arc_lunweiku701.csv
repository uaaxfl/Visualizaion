2021.naacl-main.295,Beyond Fair Pay: Ethical Implications of {NLP} Crowdsourcing,2021,-1,-1,4,1,4122,boaz shmueli,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"The use of crowdworkers in NLP research is growing rapidly, in tandem with the exponential increase in research production in machine learning and AI. Ethical discussion regarding the use of crowdworkers within the NLP research community is typically confined in scope to issues related to labor conditions such as fair pay. We draw attention to the lack of ethical considerations related to the various tasks performed by workers, including labeling, evaluation, and production. We find that the Final Rule, the common ethical framework used by researchers, did not anticipate the use of online crowdsourcing platforms for data collection, resulting in gaps between the spirit and practice of human-subjects ethics in NLP research. We enumerate common scenarios where crowdworkers performing NLP tasks are at risk of harm. We thus recommend that researchers evaluate these risks by considering the three ethical principles set up by the Belmont Report. We also clarify some common misconceptions regarding the Institutional Review Board (IRB) application. We hope this paper will serve to reopen the discussion within our community regarding the ethical use of crowdworkers."
2021.findings-acl.390,Plot and Rework: Modeling Storylines for Visual Storytelling,2021,-1,-1,4,0,8408,chiyang hsu,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.370,Lying Through One{'}s Teeth: A Study on Verbal Leakage Cues,2021,-1,-1,2,0,9468,minhsuan yeh,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Although many studies use the LIWC lexicon to show the existence of verbal leakage cues in lie detection datasets, none mention how verbal leakage cues are influenced by means of data collection, or the impact thereof on the performance of models. In this paper, we study verbal leakage cues to understand the effect of the data construction method on their significance, and examine the relationship between such cues and models{'} validity. The LIWC word-category dominance scores of seven lie detection datasets are used to show that audio statements and lie-based annotations indicate a greater number of strong verbal leakage cue categories. Moreover, we evaluate the validity of state-of-the-art lie detection models with cross- and in-dataset testing. Results show that in both types of testing, models trained on a dataset with more strong verbal leakage cue categories{---}as opposed to only a greater number of strong cues{---}yield superior results, suggesting that verbal leakage cues are a key factor for selecting lie detection datasets."
2021.acl-short.50,"Happy Dance, Slow Clap: {Using} Reaction {GIFs} to Predict Induced Affect on {Twitter}",2021,-1,-1,3,1,4122,boaz shmueli,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Datasets with induced emotion labels are scarce but of utmost importance for many NLP tasks. We present a new, automated method for collecting texts along with their induced reaction labels. The method exploits the online use of reaction GIFs, which capture complex affective states. We show how to augment the data with induced emotion and induced sentiment labels. We use our method to create and publish ReactionGIF, a first-of-its-kind affective dataset of 30K tweets. We provide baselines for three new tasks, including induced sentiment prediction and multilabel classification of induced emotions. Our method and dataset open new research opportunities in emotion detection and affective computing."
2021.acl-demo.42,Stretch-{VST}: Getting Flexible With Visual Stories,2021,-1,-1,5,0,8408,chiyang hsu,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations,0,"In visual storytelling, a short story is generated based on a given image sequence. Despite years of work, most visual storytelling models remain limited in terms of the generated stories{'} fixed length: most models produce stories with exactly five sentences because five-sentence stories dominate the training data. The fix-length stories carry limited details and provide ambiguous textual information to the readers. Therefore, we propose to {``}stretch{''} the stories, which create the potential to present in-depth visual details. This paper presents Stretch-VST, a visual storytelling framework that enables the generation of prolonged stories by adding appropriate knowledge, which is selected by the proposed scoring function. We propose a length-controlled Transformer to generate long stories. This model introduces novel positional encoding methods to maintain story quality with lengthy inputs. Experiments confirm that long stories are generated without deteriorating the quality. The human evaluation further shows that Stretch-VST can provide better focus and detail when stories are prolonged compared to state of the art. We create a webpage to demonstrate our prolonged capability."
2020.emnlp-main.201,{R}eactive {S}upervision: {A} {N}ew {M}ethod for {C}ollecting {S}arcasm {D}ata,2020,-1,-1,2,1,4122,boaz shmueli,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Sarcasm detection is an important task in affective computing, requiring large amounts of labeled data. We introduce reactive supervision, a novel data collection method that utilizes the dynamics of online conversations to overcome the limitations of existing data collection techniques. We use the new method to create and release a first-of-its-kind large dataset of tweets with sarcasm perspective labels and new contextual features. The dataset is expected to advance sarcasm detection research. Our method can be adapted to other affective computing domains, thus opening up new research opportunities."
2020.emnlp-main.312,Assessing the Helpfulness of Learning Materials with Inference-Based Learner-Like Agent,2020,-1,-1,5,0,20349,yunhsuan jen,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Many English-as-a-second language learners have trouble using near-synonym words (e.g., small vs.little; briefly vs.shortly) correctly, and often look for example sentences to learn how two nearly synonymous terms differ. Prior work uses hand-crafted scores to recommend sentences but has difficulty in adopting such scores to all the near-synonyms as near-synonyms differ in various ways. We notice that the helpfulness of the learning material would reflect on the learners{'} performance. Thus, we propose the inference-based learner-like agent to mimic learner behavior and identify good learning materials by examining the agent{'}s performance. To enable the agent to behave like a learner, we leverage entailment modeling{'}s capability of inferring answers from the provided materials. Experimental results show that the proposed agent is equipped with good learner-like behavior to achieve the best performance in both fill-in-the-blank (FITB) and good example sentence selection tasks. We further conduct a classroom user study with college ESL learners. The results of the user study show that the proposed agent can find out example sentences that help students learn more easily and efficiently. Compared to other models, the proposed agent improves the score of more than 17{\%} of students after learning."
W19-4447,From Receptive to Productive: Learning to Use Confusing Words through Automatically Selected Example Sentences,2019,36,0,4,1,3904,chiehyang huang,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"Knowing how to use words appropriately has been a key to improving language proficiency. Previous studies typically discuss how students learn receptively to select the correct candidate from a set of confusing words in the fill-in-the-blank task where specific context is given. In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task: sentence translation. We leverage the GiveMe-Example system, which suggests example sentences for each confusing word, to achieve this goal. In this study, students learn to differentiate the confusing words by reading the example sentences, and then choose the appropriate word(s) to complete the sentence translation task. Results show students made substantial progress in terms of sentence structure. In addition, highly proficient students better managed to learn confusing words. In view of the influence of the first language on learners, we further propose an effective approach to improve the quality of the suggested sentences."
N19-1031,{UH}op: An Unrestricted-Hop Relation Extraction Framework for Knowledge-Based Question Answering,2019,0,1,5,0,26068,ziyuan chen,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"In relation extraction for knowledge-based question answering, searching from one entity to another entity via a single relation is called {``}one hop{''}. In related work, an exhaustive search from all one-hop relations, two-hop relations, and so on to the max-hop relations in the knowledge graph is necessary but expensive. Therefore, the number of hops is generally restricted to two or three. In this paper, we propose UHop, an unrestricted-hop framework which relaxes this restriction by use of a transition-based search framework to replace the relation-chain-based search one. We conduct experiments on conventional 1- and 2-hop questions as well as lengthy questions, including datasets such as WebQSP, PathQuestion, and Grid World. Results show that the proposed framework enables the ability to halt, works well with state-of-the-art models, achieves competitive performance without exhaustive searches, and opens the performance gap for long relation paths."
W18-3505,{S}ocial{NLP} 2018 {E}motion{X} Challenge Overview: Recognizing Emotions in Dialogues,2018,0,8,2,0,8384,chaochun hsu,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,0,"This paper describes an overview of the Dialogue Emotion Recognition Challenge, EmotionX, at the Sixth SocialNLP Workshop, which recognizes the emotion of each utterance in dialogues. This challenge offers the EmotionLines dataset as the experimental materials. The EmotionLines dataset contains conversations from Friends TV show transcripts (Friends) and real chatting logs (EmotionPush), where every dialogue utterance is labeled with emotions. Organizers provide baseline results. 18 teams registered in this challenge and 5 of them submitted their results successfully. The best team achieves the unweighted accuracy 62.48 and 62.5 on EmotionPush and Friends, respectively. In this paper we present the task definition, test collection, the evaluation results of the groups that participated in this challenge, and their approach."
L18-1252,{E}motion{L}ines: An Emotion Corpus of Multi-Party Conversations,2018,12,18,5,0,8384,chaochun hsu,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Feeling emotion is a critical characteristic to distinguish people from machines. Among all the multi-modal resources for emotion detection, textual datasets are those containing the least additional information in addition to semantics, and hence are adopted widely for testing the developed systems. However, most of the textual emotional datasets consist of emotion labels of only individual words, sentences or documents, which makes it challenging to discuss the contextual flow of emotions. In this paper, we introduce EmotionLines, the first dataset with emotions labeling on all utterances in each dialogue only based on their textual content. Dialogues in EmotionLines are collected from Friends TV scripts and private Facebook messenger dialogues. Then one of seven emotions, six Ekman's basic emotions plus the neutral emotion, is labeled on each utterance by 5 Amazon MTurkers. A total of 29,245 utterances from 2,000 dialogues are labeled in EmotionLines. We also provide several strong baselines for emotion detection models on EmotionLines in this paper."
I17-4017,{NLPSA} at {IJCNLP}-2017 Task 2: Imagine Scenario: Leveraging Supportive Images for Dimensional Sentiment Analysis,2017,0,0,3,0,32812,szumin chen,"Proceedings of the {IJCNLP} 2017, Shared Tasks",0,"Categorical sentiment classification has drawn much attention in the field of NLP, while less work has been conducted for dimensional sentiment analysis (DSA). Recent works for DSA utilize either word embedding, knowledge base features, or bilingual language resources. In this paper, we propose our model for IJCNLP 2017 Dimensional Sentiment Analysis for Chinese Phrases shared task. Our model incorporates word embedding as well as image features, attempting to simulate human{'}s imaging behavior toward sentiment analysis. Though the performance is not comparable to others in the end, we conduct several experiments with possible reasons discussed, and analyze the drawbacks of our model."
I17-1012,Enabling Transitivity for Lexical Inference on {C}hinese Verbs Using Probabilistic Soft Logic,2017,20,0,2,0,32892,weichung wang,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"To learn more knowledge, enabling transitivity is a vital step for lexical inference. However, most of the lexical inference models with good performance are for nouns or noun phrases, which cannot be directly applied to the inference on events or states. In this paper, we construct the largest Chinese verb lexical inference dataset containing 18,029 verb pairs, where for each pair one of four inference relations are annotated. We further build a probabilistic soft logic (PSL) model to infer verb lexicons using the logic language. With PSL, we easily enable transitivity in two layers, the observed layer and the feature layer, which are included in the knowledge base. We further discuss the effect of transitives within and between these layers. Results show the performance of the proposed PSL model can be improved at least 3.5{\%} (relative) when the transitivity is enabled. Furthermore, experiments show that enabling transitivity in the observed layer benefits the most."
D17-2013,{M}ood{S}wipe: A Soft Keyboard that Suggests {M}essage{B}ased on User-Specified Emotions,2017,0,1,7,1,3904,chiehyang huang,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,"We present MoodSwipe, a soft keyboard that suggests text messages given the user-specified emotions utilizing the real dialog data. The aim of MoodSwipe is to create a convenient user interface to enjoy the technology of emotion classification and text suggestion, and at the same time to collect labeled data automatically for developing more advanced technologies. While users select the MoodSwipe keyboard, they can type as usual but sense the emotion conveyed by their text and receive suggestions for their message as a benefit. In MoodSwipe, the detected emotions serve as the medium for suggested texts, where viewing the latter is the incentive to correcting the former. We conduct several experiments to show the superiority of the emotion classification models trained on the dialog data, and further to verify good emotion cues are important context for text suggestion."
W16-3910,Whose Nickname is This? Recognizing Politicians from Their Aliases,2016,20,1,6,0,32892,weichung wang,Proceedings of the 2nd Workshop on Noisy User-generated Text ({WNUT}),0,"Using aliases to refer to public figures is one way to make fun of people, to express sarcasm, or even to sidestep legal issues when expressing opinions on social media. However, linking an alias back to the real name is difficult, as it entails phonemic, graphemic, and semantic challenges. In this paper, we propose a phonemic-based approach and inject semantic information to align aliases with politicians{'} Chinese formal names. The proposed approach creates an HMM model for each name to model its phonemes and takes into account document-level pairwise mutual information to capture the semantic relations to the alias. In this work we also introduce two new datasets consisting of 167 phonemic pairs and 279 mixed pairs of aliases and formal names. Experimental results show that the proposed approach models both phonemic and semantic information and outperforms previous work on both the phonemic and mixed datasets with the best top-1 accuracies of 0.78 and 0.59 respectively."
L16-1428,{ANTUSD}: A Large {C}hinese Sentiment Dictionary,2016,4,6,2,0,35173,shihming wang,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper introduces the augmented NTU sentiment dictionary, abbreviated as ANTUSD, which is constructed by collecting sentiment stats of words in several sentiment annotation work. A total of 26,021 words were collected in ANTUSD. For each word, the CopeOpi numerical sentiment score and the number of positive annotation, neutral annotation, negative annotation, non-opinionated annotation, and not-a-word annotation are provided. Words and their sentiment information in ANTUSD have been linked to the Chinese ontology E-HowNet to provide rich semantic information. We demonstrate the usage of ANTUSD in polarity classification of words, and the results show that a superior f-score 98.21 is achieved, which supports the usefulness of the ANTUSD. ANTUSD can be freely obtained through application from NLPSA lab, Academia Sinica: http://academiasinicanlplab.github.io/"
C16-3002,"{C}hinese Textual Sentiment Analysis: Datasets, Resources and Tools",2016,10,0,1,1,4125,lunwei ku,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Tutorial Abstracts",0,"The rapid accumulation of data in social media (in million and billion scales) has imposed great challenges in information extraction, knowledge discovery, and data mining, and texts bearing sentiment and opinions are one of the major categories of user generated data in social media. Sentiment analysis is the main technology to quickly capture what people think from these text data, and is a research direction with immediate practical value in {`}big data{'} era. Learning such techniques will allow data miners to perform advanced mining tasks considering real sentiment and opinions expressed by users in additional to the statistics calculated from the physical actions (such as viewing or purchasing records) user perform, which facilitates the development of real-world applications. However, the situation that most tools are limited to the English language might stop academic or industrial people from doing research or products which cover a wider scope of data, retrieving information from people who speak different languages, or developing applications for worldwide users. More specifically, sentiment analysis determines the polarities and strength of the sentiment-bearing expressions, and it has been an important and attractive research area. In the past decade, resources and tools have been developed for sentiment analysis in order to provide subsequent vital applications, such as product reviews, reputation management, call center robots, automatic public survey, etc. However, most of these resources are for the English language. Being the key to the understanding of business and government issues, sentiment analysis resources and tools are required for other major languages, e.g., Chinese. In this tutorial, audience can learn the skills for retrieving sentiment from texts in another major language, Chinese, to overcome this obstacle. The goal of this tutorial is to introduce the proposed sentiment analysis technologies and datasets in the literature, and give the audience the opportunities to use resources and tools to process Chinese texts from the very basic preprocessing, i.e., word segmentation and part of speech tagging, to sentiment analysis, i.e., applying sentiment dictionaries and obtaining sentiment scores, through step-by-step instructions and a hand-on practice. The basic processing tools are from CKIP Participants can download these resources, use them and solve the problems they encounter in this tutorial. This tutorial will begin from some background knowledge of sentiment analysis, such as how sentiment are categorized, where to find available corpora and which models are commonly applied, especially for the Chinese language. Then a set of basic Chinese text processing tools for word segmentation, tagging and parsing will be introduced for the preparation of mining sentiment and opinions. After bringing the idea of how to pre-process the Chinese language to the audience, I will describe our work on compositional Chinese sentiment analysis from words to sentences, and an application on social media text (Facebook) as an example. All our involved and recently developed related resources, including Chinese Morphological Dataset, Augmented NTU Sentiment Dictionary (aug-NTUSD), E-hownet with sentiment information, Chinese Opinion Treebank, and the CopeOpi Sentiment Scorer, will also be introduced and distributed in this tutorial. The tutorial will end by a hands-on session of how to use these materials and tools to process Chinese sentiment. Content Details, Materials, and Program please refer to the tutorial URL: \url{http://www.lunweiku.com/}"
C16-2030,{S}ensing Emotions in Text Messages: An Application and Deployment Study of {E}motion{P}ush,2016,22,0,5,0,35173,shihming wang,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"Instant messaging and push notifications play important roles in modern digital life. To enable robust sense-making and rich context awareness in computer mediated communications, we introduce EmotionPush, a system that automatically conveys the emotion of received text with a colored push notification on mobile devices. EmotionPush is powered by state-of-the-art emotion classifiers and is deployed for Facebook Messenger clients on Android. The study showed that the system is able to help users prioritize interactions."
C16-2057,{W}ord{F}orce: Visualizing Controversial Words in Debates,2016,8,3,3,1,6981,weifan chen,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"This paper presents WordForce, a system powered by the state of the art neural network model to visualize the learned user-dependent word embeddings from each post according to the post content and its engaged users. It generates the scatter plots to show the force of a word, i.e., whether the semantics of word embeddings from posts of different stances are clearly separated from the aspect of this controversial word. In addition, WordForce provides the dispersion and the distance of word embeddings from posts of different stance groups, and proposes the most controversial words accordingly to show clues to what people argue about in a debate."
C16-2063,Automatically Suggesting Example Sentences of Near-Synonyms for Language Learners,2016,8,1,3,1,3904,chiehyang huang,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"In this paper, we propose GiveMeExample that ranks example sentences according to their capacity of demonstrating the differences among English and Chinese near-synonyms for language learners. The difficulty of the example sentences is automatically detected. Furthermore, the usage models of the near-synonyms are built by the GMM and Bi-LSTM models to suggest the best elaborative sentences. Experiments show the good performance both in the fill-in-the-blank test and on the manually labeled gold data, that is, the built models can select the appropriate words for the given context and vice versa."
C16-1154,{UTCNN}: a Deep Learning Model of Stance Classification on Social Media Text,2016,0,16,2,1,6981,weifan chen,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Most neural network models for document classification on social media focus on text information to the neglect of other information on these platforms. In this paper, we classify post stance on social media channels and develop UTCNN, a neural network model that incorporates user tastes, topic tastes, and user comments on posts. UTCNN not only works on social media texts, but also analyzes texts in forums and message boards. Experiments performed on Chinese Facebook data and English online debate forum data show that UTCNN achieves a 0.755 macro average f-score for supportive, neutral, and unsupportive stance classes on Facebook data, which is significantly better than models in which either user, topic, or comment information is withheld. This model design greatly mitigates the lack of data for the minor class. In addition, UTCNN yields a 0.842 accuracy on English online debate forum data, which also significantly outperforms results from previous work, showing that UTCNN performs well regardless of language or platform."
W15-0617,Embarrassed or Awkward? Ranking Emotion Synonyms for {ESL} Learners{'} Appropriate Wording,2015,30,0,3,1,6981,weifan chen,Proceedings of the Tenth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We introduce a novel framework based on the probabilistic model for emotion wording assistance. The example sentences from the online dictionary, Vocabulary.com are utilized as the training data; and the writings in a designed ESLxe2x80x99s writing task are the testing corpus. The emotion events are captured by extracting patterns of the example sentences. Our approach learns the joint probability of contextual emotion events and the emotion words from the training corpus. After extracting patterns in the testing corpus, we then aggregate their probabilities to suggest the emotion word that describes the ESLxe2x80x99s context most appropriately. We evaluate the proposed approach by the NDCG@5 of the suggested words for the writings in the testing corpus. The experiment result shows our approach can more appropriately suggest the emotion words compared to SVM, PMI and two representative on-line reference tools, PIGAI and Thesaurus.com."
P15-4009,A Dual-Layer Semantic Role Labeling System,2015,27,2,1,1,4125,lunwei ku,Proceedings of {ACL}-{IJCNLP} 2015 System Demonstrations,0,We describe a well-performed semantic role labeling system that further extracts concepts (smaller semantic expressions) from unstructured natural language sentences language independently. A dual-layer semantic role labeling (SRL) system is built using Chinese Treebank and Propbank data. Contextual information is incorporated while labeling the predicate arguments to achieve better performance. Experimental results show that the proposed approach is superior to CoNLL 2009 best systems and comparable to the state of the art with the advantage that it requires no feature engineering process. Concepts are further extracted according to templates formulated by the labeled semantic roles to serve as features in other NLP tasks to provide semantically related cues and potentially help in related research problems. We also show that it is easy to generate a different language version of this system by actually building an English system which performs satisfactory.
O15-3001,Designing a Tag-Based Statistical Math Word Problem Solver with Reasoning and Explanation,2015,45,4,7,0,10585,yichung lin,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 20, Number 2, {D}ecember 2015 - Special Issue on Selected Papers from {ROCLING} {XXVII}",0,"This paper proposes a tag-based statistical framework to solve math word problems with understanding and reasoning. It analyzes the body and question texts into their associated tag-based logic forms, and then performs inference on them. Comparing to those rule-based approaches, the proposed statistical approach alleviates rules coverage and ambiguity resolution problems, and our tag-based approach also provides the flexibility of handling various kinds of related questions with the same body logic form. On the other hand, comparing to those purely statistical approaches, the proposed approach is more robust to the irrelevant information and could more accurately provide the answer. The major contributions of our work are: (1) proposing a tag-based logic representation such that the system is less sensitive to the irrelevant information and could provide answer more precisely; (2) proposing a unified statistical framework for performing reasoning from the given text."
W14-5905,A Rule-Based Approach to Aspect Extraction from Product Reviews,2014,22,115,3,0,1536,soujanya poria,Proceedings of the Second Workshop on Natural Language Processing for Social Media ({S}ocial{NLP}),0,"Sentiment analysis is a rapidly growing research field that has attracted both academia and industry because of the challenging research problems it poses and the potential benefits it can provide in many real life applications. Aspect-based opinion mining, in particular, is one of the fundamental challenges within this research field. In this work, we aim to solve the problem of aspect extraction from product reviews by proposing a novel rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both explicit and implicit aspects. Two popular review datasets were used for evaluating the system against state-of-the-art aspect extraction techniques, obtaining higher detection accuracy for both datasets."
P14-5001,Cross-Lingual Information to the Rescue in Keyword Extraction,2014,15,1,4,0.685613,33416,chungchi huang,Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We introduce a method that extracts keywords in a language with the help of the other. In our approach, we bridge and fuse conventionally irrelevant word statistics in languages. The method involves estimating preferences for keywords w.r.t. domain topics and generating cross-lingual bridges for word statistics integration. At run-time, we transform parallel articles into word graphs, build cross-lingual edges, and exploit PageRank with word keyness information for keyword extraction. We present the system, BiKEA , that applies the method to keyword analysis. Experiments show that keyword extraction benefits from PageRank, globally learned keyword preferences, and cross-lingual word statistics interaction which respects language diversity."
I13-1117,Interest Analysis using {P}age{R}ank and Social Interaction Content,2013,13,0,2,0.685613,33416,chungchi huang,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We introduce a method for learning to predict reader interest. In our approach, social interaction content and both syntactic and semantic features of words are utilized. The proposed method involves estimating topical interest preferences and determining the informativity between articles and their social content. In interest prediction, we integrate articlesxe2x80x99 quality social feedback representing readersxe2x80x99 opinions into articles to get information which may identify readersxe2x80x99 interests. In addition, semantic aware PageRank is used to find reader interest with the help of word interestingness scores. Evaluations show that PageRank benefits from proposed features and interest preferences inferred across articles. Moreover, results conclude that social interaction content and the proposed selection process help to accurately cover more span of reader interest."
P12-3017,Demonstration of {I}llu{M}e: Creating Ambient According to Instant Message Logs,2012,12,3,1,1,4125,lunwei ku,Proceedings of the {ACL} 2012 System Demonstrations,0,"We present IlluMe, a software tool pack which creates a personalized ambient using the music and lighting. IlluMe includes an emotion analysis software, the small space ambient lighting, and a multimedia controller. The software analyzes emotional changes from instant message logs and corresponds the detected emotion to the best sound and light settings. The ambient lighting can sparkle with different forms of light and the smart phone can broadcast music respectively according to different atmosphere. All settings can be modified by the multimedia controller at any time and the new settings will be feedback to the emotion analysis software. The IlluMe system, equipped with the learning function, provides a link between residential situation and personal emotion. It works in a Chinese chatting environment to illustrate the language technology in life."
I11-1039,Predicting Opinion Dependency Relations for Opinion Analysis,2011,17,5,1,1,4125,lunwei ku,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Syntactic structures have been good features for opinion analysis, but it is not easy to use them. To find these features by supervised learning methods, correct syntactic labels are indispensible. Two possible sources to acquire syntactic structures are parsing trees and dependency trees. For the annotation processing, parsing trees are more readable for annotators, while dependency trees are easier to use by programs. To use syntactic structures as features, this paper tried to annotate on human friendly materials and transform these annotations to the corresponding machine friendly materials. We annotated the gold answers of opinion syntactic structures on the parsing tree from Chinese Treebank, and then proposed methods to find their corresponding dependency relations on the dependency trees generated from the same sentence. With these relations, we could train a model to annotate opinion dependency relations automatically to provide an opinion dependency parser, which is language independent if language resources are incorporated. Experiment results show that the annotated syntactic structures and their corresponding dependency relations improve at least 8% of the performance of opinion analysis."
ku-etal-2010-construction,Construction of a {C}hinese Opinion Treebank,2010,7,1,1,1,4125,lunwei ku,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we base on the syntactic structural Chinese Treebank corpus, construct the Chinese Opinon Treebank for the research of opinion analysis. We introduce the tagging scheme and develop a tagging tool for constructing this corpus. Annotated samples are described. Information including opinions (yes or no), their polarities (positive, neutral or negative), types (expression, status, or action), is defined and annotated. In addition, five structure trios are introduced according to the linguistic relations between two Chinese words. Four of them that are possibly related to opinions are also annotated in the constructed corpus to provide the linguistic cues. The number of opinion sentences together with the number of their polarities, opinion types, and trio types are calculated. These statistics are compared and discussed. To know the quality of the annotations in this corpus, the kappa values of the annotations are calculated. The substantial agreement between annotations ensures the applicability and reliability of the constructed corpus."
huang-etal-2010-predicting,Predicting Morphological Types of {C}hinese Bi-Character Words by Machine Learning Approaches,2010,5,1,2,0.224359,720,tinghao huang,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presented an overview of Chinese bi-character wordsÂ morphological types, and proposed a set of features for machine learning approaches to predict these types based on composite charactersÂ information. First, eight morphological types were defined, and 6,500 Chinese bi-character words were annotated with these types. After pre-processing, 6,178 words were selected to construct a corpus named Reduced Set. We analyzed Reduced Set and conducted the inter-annotator agreement test. The average kappa value of 0.67 indicates a substantial agreement. Second, Bi-character wordsÂ morphological types are considered strongly related with the composite charactersÂ parts of speech in this paper, so we proposed a set of features which can simply be extracted from dictionaries to indicate the charactersÂ ÂtendencyÂ of parts of speech. Finally, we used these features and adopted three machine learning algorithms, SVM, CRF, and Na{\""\i}ve Bayes, to predict the morphological types. On the average, the best algorithm CRF achieved 75{\%} of the annotatorsÂ performance."
O09-6003,Identification of Opinion Holders,2009,18,4,1,1,4125,lunwei ku,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 14, Number 4, {D}ecember 2009",0,"Opinion holder identification aims to extract entities that express opinions in sentences. In this paper, opinion holder identification is divided into two subtasks: author's opinion recognition and opinion holder labeling. Support vector machine (SVM) is adopted to recognize author's opinions, and conditional random field algorithm (CRF) is utilized to label opinion holders. New features are proposed for both methods. Our method achieves an f-score of 0.734 in the NTCIR7 MOAT task on the Traditional Chinese side, which is the best performance among results of machine learning methods proposed by participants, and also it is close to the best performance of this task. In addition, inconsistent annotations of opinion holders are analyzed, along with the best way to utilize the training instances with inconsistent annotations being proposed."
O09-1008,"æè¦ææè\
è¾¨è­ä¹ç ç©¶ (A Study on Identification of Opinion Holders) [In {C}hinese]",2009,0,0,2,0,37390,chiaying lee,Proceedings of the 21st Conference on Computational Linguistics and Speech Processing,0,None
D09-1131,Using Morphological and Syntactic Structures for {C}hinese Opinion Analysis,2009,19,48,1,1,4125,lunwei ku,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper employs morphological structures and relations between sentence segments for opinion analysis on words and sentences. Chinese words are classified into eight morphological types by two proposed classifiers, CRF classifier and SVM classifier. Experiments show that the injection of morphological information improves the performance of the word polarity detection. To utilize syntactic structures, we annotate structural trios to represent relations between sentence segments. Experiments show that considering structural trios is useful for sentence opinion analysis. The best f-score achieves 0.77 for opinion word extraction, 0.62 for opinion word polarity detection, 0.80 for opinion sentence extraction, and 0.54 for opinion sentence polarity detection."
O08-5003,Question Analysis and Answer Passage Retrieval for Opinion Question Answering Systems,2008,16,9,1,1,4125,lunwei ku,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 13, Number 3, September 2008: Special Issue on Selected Papers from {ROCLING} {XIX}",0,"Question answering systems provide an elegant way for people to access an underlying knowledge base. However, people are interested in not only factual questions, but also opinions. This paper deals with question analysis and answer passage retrieval in opinion QA systems. For question analysis, six opinion question types are defined. A two-layered framework utilizing two question type classifiers is proposed. Algorithms for these two classifiers are described. The performance achieves 87.8% in general question classification and 92.5% in opinion question classification. The question focus is detected to form a query for the information retrieval system and the question polarity is detected to retain relevant sentences which have the same polarity as the question. For answer passage retrieval, three components are introduced. Relevant sentences retrieved are further identified as to whether the focus (Focus Detection) is in a scope of opinion (Opinion Scope Identification) or not, and, if yes, whether the polarity of the scope and the polarity of the question (Polarity Detection) match with each other. The best model achieves an F-measure of 40.59% by adopting partial match for relevance detection at the level of meaningful unit. With relevance issues removed, the F-measure of the best model boosts up to 84.96%."
P07-2023,Test Collection Selection and Gold Standard Generation for a Multiply-Annotated Opinion Corpus,2007,3,15,1,1,4125,lunwei ku,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"Opinion analysis is an important research topic in recent years. However, there are no common methods to create evaluation corpora. This paper introduces a method for developing opinion corpora involving multiple annotators. The characteristics of the created corpus are discussed, and the methodologies to select more consistent testing collections and their corresponding gold standards are proposed. Under the gold standards, an opinion extraction system is evaluated. The experiment results show some interesting phenomena."
O07-1013,Question Analysis and Answer Passage Retrieval for Opinion Question Answering Systems,2007,0,10,1,1,4125,lunwei ku,Proceedings of the 19th Conference on Computational Linguistics and Speech Processing,0,None
ku-etal-2006-tagging,Tagging Heterogeneous Evaluation Corpora for Opinionated Tasks,2006,12,20,1,1,4125,lunwei ku,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Opinion retrieval aims to tell if a document is positive, neutral or negative on a given topic. Opinion extraction further identifies the supportive and the non-supportive evidence of a document. To evaluate the performance of technologies for opinionated tasks, a suitable corpus is necessary. This paper defines the annotations for opinionated materials. Heterogeneous experimental materials are annotated, and the agreements among annotators are analyzed. How human can monitor opinions of the whole is also examined. The corpus can be employed to opinion extraction, opinion summarization, opinion tracking and opinionated question answering."
