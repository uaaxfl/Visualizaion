2020.lrec-1.395,A Multilingual Evaluation Dataset for Monolingual Word Sense Alignment,2020,-1,-1,5,0,6137,sina ahmadi,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Aligning senses across resources and languages is a challenging task with beneficial applications in the field of natural language processing and electronic lexicography. In this paper, we describe our efforts in manually aligning monolingual dictionaries. The alignment is carried out at sense-level for various resources in 15 languages. Moreover, senses are annotated with possible semantic relationships such as broadness, narrowness, relatedness, and equivalence. In comparison to previous datasets for this task, this dataset covers a wide range of languages and resources and focuses on the more challenging task of linking general-purpose language. We believe that our data will pave the way for further advances in alignment and evaluation of word senses by creating new solutions, particularly those notoriously requiring data such as neural networks. Our resources are publicly available at https://github.com/elexis-eu/MWSA."
2020.lr4sshoc-1.2,Social Sciences and Humanities Pathway Towards the {E}uropean Open Science Cloud,2020,-1,-1,2,0,18393,francesca donato,Proceedings of the Workshop about Language Resources for the SSH Cloud,0,"The paper presents a journey, which starts from various social sciences and humanities (SSH) Research Infrastructures in Europe and arrives at the comprehensive {``}ecosystem of infrastructures{''}, namely the European Open Science Cloud (EOSC). We will highlight how the SSH Open Science infrastructures contribute to the goal of establishing the EOSC. First, through the example of OPERAS, the European Research Infrastructure for Open Scholarly Communication in the SSH, to see how its services are conceived to be part of the EOSC and to address the communities{'} needs. The next two sections highlight collaboration practices between partners in Europe to build the SSH component of the EOSC and a SSH discovery platform, as a service of OPERAS and the EOSC. The last two sections will focus on an implementation network dedicated to SSH data fairification."
2020.lr4sshoc-1.6,{LR}4{SSHOC}: The Future of Language Resources in the Context of the Social Sciences and Humanities Open Cloud,2020,-1,-1,3,0,18402,daan broeder,Proceedings of the Workshop about Language Resources for the SSH Cloud,0,This paper outlines the future of language resources and identifies their potential contribution for creating and sustaining the social sciences and humanities (SSH) component of the European Open Science Cloud (EOSC).
L18-1088,The {LREC} Workshops Map,2018,0,0,3,0.77987,29604,roberto bartolini,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1694,One Language to rule them all: modelling Morphological Patterns in a Large Scale {I}talian Lexicon with {SWRL},2018,0,0,4,0.9965,17440,fahad khan,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W16-4022,Tools and Instruments for Building and Querying Diachronic Computational Lexica,2016,11,1,3,1,17440,fahad khan,Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities ({LT}4{DH}),0,"This article describes work on enabling the addition of temporal information to senses of words in linguistic linked open data lexica based on the lemonDia model. Our contribution in this article is twofold. On the one hand, we demonstrate how lemonDia enables the querying of diachronic lexical datasets using OWL-oriented Semantic Web based technologies. On the other hand, we present a preliminary version of an interactive interface intended to help users in creating lexical datasets that model meaning change over time."
L16-1150,"Al Qamus al Muhit, a Medieval {A}rabic Lexicon in {LMF}",2016,3,0,3,0,30164,ouafae nahli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper describes the conversion into LMF, a standard lexicographic digital format of {`}al-q{\=a}m{\=u}s al-muá¸¥{\=\i}á¹­, a Medieval Arabic lexicon. The lexicon is first described, then all the steps required for the conversion are illustrated. The work is will produce a useful lexicographic resource for Arabic NLP, but is also interesting per se, to study the implications of adapting the LMF model to the Arabic language. Some reflections are offered as to the status of roots with respect to previously suggested representations. In particular, roots are, in our opinion are to be not treated as lexical entries, but modeled as lexical metadata for classifying and identifying lexical entries. In this manner, each root connects all entries that are derived from it."
L16-1401,{LREC} as a Graph: People and Resources in a Network,2016,0,1,3,0.593176,29721,riccardo gratta,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This proposal describes a new way to visualise resources in the LREMap, a community-built repository of language resource descriptions and uses. The LREMap is represented as a force-directed graph, where resources, papers and authors are nodes. The analysis of the visual representation of the underlying graph is used to study how the community gathers around LRs and how LRs are used in research."
bizzoni-etal-2014-making,The Making of {A}ncient {G}reek {W}ord{N}et,2014,21,3,5,0,2627,yuri bizzoni,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes the process of creation and review of a new lexico-semantic resource for the classical studies: AncientGreekWordNet. The candidate sets of synonyms (synsets) are extracted from Greek-English dictionaries, on the assumption that Greek words translated by the same English word or phrase have a high probability of being synonyms or at least semantically closely related. The process of validation and the web interface developed to edit and query the resource are described in detail. The lexical coverage of Ancient Greek WordNet is illustrated and the accuracy is evaluated. Finally, scenarios for exploiting the resource are discussed."
moneglia-etal-2014-imagact,The {IMAGACT} Visual Ontology. An Extendable Multilingual Infrastructure for the representation of lexical encoding of Action,2014,7,2,6,1,18935,massimo moneglia,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Action verbs have many meanings, covering actions in different ontological types. Moreover, each language categorizes action in its own way. One verb can refer to many different actions and one action can be identified by more than one verb. The range of variations within and across languages is largely unknown, causing trouble for natural language processing tasks. IMAGACT is a corpus-based ontology of action concepts, derived from English and Italian spontaneous speech corpora, which makes use of the universal language of images to identify the different action types extended by verbs referring to action in English, Italian, Chinese and Spanish. This paper presents the infrastructure and the various linguistic information the user can derive from it. IMAGACT makes explicit the variation of meaning of action verbs within one language and allows comparisons of verb variations within and across languages. Because the action concepts are represented with videos, extension into new languages beyond those presently implemented in IMAGACT is done using competence-based judgments by mother-tongue informants without intense lexicographic work involving underdetermined semantic description"
rehm-etal-2014-strategic,"The Strategic Impact of {META}-{NET} on the Regional, National and International Level",2014,47,2,26,0,60,georg rehm,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This article provides an overview of the dissemination work carried out in META-NET from 2010 until early 2014; we describe its impact on the regional, national and international level, mainly with regard to politics and the situation of funding for LT topics. This paper documents the initiativeÂs work throughout Europe in order to boost progress and innovation in our field."
frontini-etal-2014-polysemy,Polysemy Index for Nouns: an Experiment on {I}talian using the {PAROLE} {SIMPLE} {CLIPS} Lexical Database,2014,12,1,4,1,19254,francesca frontini,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"An experiment is presented to induce a set of polysemous basic type alternations (such as Animal-Food, or Building-Institution) by deriving them from the sense alternations found in an existing lexical resource. The paper builds on previous work and applies those results to the Italian lexicon PAROLE SIMPLE CLIPS. The new results show how the set of frequent type alternations that can be induced from the lexicon is partly different from the set of polysemy relations selected and explicitely applied by lexicographers when building it. The analysis of mismatches shows that frequent type alternations do not always correpond to prototypical polysemy relations, nevertheless the proposed methodology represents a useful tool offered to lexicographers to systematically check for possible gaps in their resource."
pallotti-etal-2014-presenting,Presenting a system of human-machine interaction for performing map tasks.,2014,11,0,4,0,39713,gabriele pallotti,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"A system for human machine interaction is presented, that offers second language learners of Italian the possibility of assessing their competence by performing a map task, namely by guiding the a virtual follower through a map with written instructions in natural language. The underlying natural language processing algorithm is described, and the map authoring infrastructure is presented."
bartolini-etal-2014-synsets,From Synsets to Videos: Enriching {I}tal{W}ord{N}et Multimodally,2014,16,3,5,0.77987,29604,roberto bartolini,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The paper describes the multimodal enrichment of ItalWordNet action verbsÂ entries by means of an automatic mapping with an ontology of action types instantiated by video scenes (ImagAct). The two resources present important differences as well as interesting complementary features, such that a mapping of these two resources can lead to a an enrichment of IWN, through the connection between synsets and videos apt to illustrate the meaning described by glosses. Here, we describe an approach inspired by ontology matching methods for the automatic mapping of ImagAct video scened onto ItalWordNet sense. The experiments described in the paper are conducted on Italian, but the same methodology can be extended to other languages for which WordNets have been created, since ImagAct is done also for English, Chinese and Spanish. This source of multimodal information can be exploited to design second language learning tools, as well as for language grounding in video action recognition and potentially for robotics."
W13-5409,{G}enerative {L}exicon Theory and Linguistic Linked Open Data,2013,-1,-1,4,1,17440,fahad khan,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
W13-5410,Disambiguation of Basic Action Types through Nouns{'} Telic Qualia,2013,11,2,5,0,1876,irene russo,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
W12-5106,"Verb interpretation for basic action types: annotation, ontology induction and creation of prototypical scenes",2012,6,4,5,1,19254,francesca frontini,Proceedings of the 3rd Workshop on Cognitive Aspects of the Lexicon,0,"In the last 20 years dictionaries and lexicographic resources such as WordNet have started to be enriched with multimodal content. Short videos depicting basic actions support the userxe2x80x99s need (especially in second language acquisition) to fully understand the range of applicability of verbs. The IMAGACT project has among its results a repository of action verbs ontologically organised around prototypical action scenes in the form of both video recordings and 3D animations. The creation of the IMAGACT ontology, which consists in deriving action types from corpus instances of action verbs, intra and cross linguistically validating them and producing the prototypical scenes thereof, is the preliminary step for the creation of a resouce that users can browse by verb, learning how to match different action prototypes with the correct verbs in the target language. The mapping of IMAGACT types onto WordNet synsets allows for a mutual enrichment of both resources. Interpretazione dei verbi per tipi azionali di base: annotazione, induzione di ontologia e creazione di scene prototipiche Negli ultimi venti anni dizionari e risorse lessicografiche come WordNet sono stati arricchiti con contenuto multimediale. Brevi video in grado di rappresentare azioni di base supportano i bisogni degli utenti (in particolar modo per quanto riguarda l' acquisizione della seconda lingua) nel comprendere l' ambito di applicabilita dei verbi. Il progetto IMAGACT ha tra i suoi risultati una base di dati di verbi d'azione ontologicamente organizzati e raffiguranti scene che riproducono azioni prototipiche sottoforma di registrazioni video e animazioni 3D. La creazione dell' ontologia IMAGACT che consiste nella derivazione di tipi azionali da istanze di verbi d'azione estratte da un corpus, nella loro validazione intra e crosslinguisticamente e nella conseguente produzione di scene prototipiche, e il passaggio preliminare per la creazione di una risorsa che gli utenti possono consultare partendo dal verbo, imparando come alllineare differenti prototipi d'azione con il verbo corretto nella lingua da apprendere. Il mapping dei tipi di IMAGACT sui synsets di WordNet consente un arricchimento reciproco di entrambe le risorse."
moneglia-etal-2012-imagact,The {IMAGACT} Cross-linguistic Ontology of Action. A new infrastructure for natural language disambiguation,2012,12,5,2,1,18935,massimo moneglia,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Action verbs, which are highly frequent in speech, cause disambiguation problems that are relevant to Language Technologies. This is a consequence of the peculiar way each natural language categorizes Action i.e. it is a consequence of semantic factors. Action verbs are frequently ÂgeneralÂ, since they extend productively to actions belonging to different ontological types. Moreover, each language categorizes action in its own way and therefore the cross-linguistic reference to everyday activities is puzzling. This paper briefly sketches the IMAGACT project, which aims at setting up a cross-linguistic Ontology of Action for grounding disambiguation tasks in this crucial area of the lexicon. The project derives information on the actual variation of action verbs in English and Italian from spontaneous speech corpora, where references to action are high in frequency. Crucially it makes use of the universal language of images to identify action types, avoiding the underdeterminacy of semantic definitions. Action concept entries are implemented as prototypic scenes; this will make it easier to extend the Ontology to other languages."
soria-etal-2012-flarenet,The {FL}a{R}e{N}et Strategic Language Resource Agenda,2012,1,6,5,0.704586,30233,claudia soria,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The FLaReNet Strategic Agenda highlights the most pressing needs for the sector of Language Resources and Technologies and presents a set of recommendations for its development and progress in Europe, as issued from a three-year consultation of the FLaReNet European project. The FLaReNet recommendations are organised around nine dimensions: a) documentation b) interoperability c) availability, sharing and distribution d) coverage, quality and adequacy e) sustainability f) recognition g) development h) infrastructure and i) international cooperation. As such, they cover a broad range of topics and activities, spanning over production and use of language resources, licensing, maintenance and preservation issues, infrastructures for language resources, resource identification and sharing, evaluation and validation, interoperability and policy issues. The intended recipients belong to a large set of players and stakeholders in Language Resources and Technology, ranging from individuals to research and education institutions, to policy-makers, funding agencies, SMEs and large companies, service and media providers. The main goal of these recommendations is to serve as an instrument to support stakeholders in planning for and addressing the urgencies of the Language Resources and Technologies of the future."
gavrilidou-etal-2012-meta,The {META}-{SHARE} Metadata Schema for the Description of Language Resources,2012,4,24,6,1,39961,maria gavrilidou,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents a metadata model for the description of language resources proposed in the framework of the META-SHARE infrastructure, aiming to cover both datasets and tools/technologies used for their processing. It places the model in the overall framework of metadata models, describes the basic principles and features of the model, elaborates on the distinction between minimal and maximal versions thereof, briefly presents the integrated environment supporting the LRs description and search and retrieval processes and concludes with work to be done in the future for the improvement of the model."
W11-3306,Interoperability Framework: The {FL}a{R}e{N}et Action Plan Proposal,2011,-1,-1,2,0,18003,nicoletta calzolari,"Proceedings of the Workshop on Language Resources, Technology and Services in the Sharing Paradigm",0,None
W11-3311,A Metadata Schema for the Description of Language Resources ({LR}s),2011,0,0,4,1,39961,maria gavrilidou,"Proceedings of the Workshop on Language Resources, Technology and Services in the Sharing Paradigm",0,None
W10-3301,{KYOTO}: an open platform for mining facts,2010,13,14,5,0.359361,5469,piek vossen,Proceedings of the 6th Workshop on {O}ntologies and {L}exical {R}esources,0,"This document describes an open text-mining system that was developed for the Asian-European project KYOTO. The KYOTO system uses an open text representation format and a central ontology to enable extraction of knowledge and facts from large volumes of text in many different languages. We implemented a semantic tagging approach that performs off-line reasoning. Mining of facts and knowledge is achieved through a flexible pattern matching module that can work in much the same way for different languages, can handle efficiently large volumes of documents and is not restricted to a specific domain. We applied the system to an English database on estuaries."
S10-1013,{S}em{E}val-2010 Task 17: All-Words Word Sense Disambiguation on a Specific Domain,2010,17,46,6,0,8824,eneko agirre,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Domain portability and adaptation of NLP components and Word Sense Disambiguation systems present new challenges. The difficulties found by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledge-based WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. This task presented all-words datasets on the environment domain for WSD in four languages (Chinese, Dutch, English, Italian). 11 teams participated, with supervised and knowledge-based systems, mainly in the English dataset. The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora. The most successful approaches used some sort of supervision in the form of hand-tagged examples from the domain."
S10-1093,{K}yoto: An Integrated System for Specific Domain {WSD},2010,10,2,6,0,13429,aitor soroa,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This document describes the preliminary release of the integrated Kyoto system for specific domain WSD. The system uses concept miners (Tybots) to extract domain-related terms and produces a domain-related thesaurus, followed by knowledge-based WSD based on wordnet graphs (UKB). The resulting system can be applied to any language with a lexical knowledge base, and is based on publicly available software and resources. Our participation in Semeval task #17 focused on producing running systems for all languages in the task, and we attained good results in all except Chinese. Due to the pressure of the time-constraints in the competition, the system is still under development, and we expect results to improve in the near future."
savas-etal-2010-lmf,An {LMF}-based Web Service for Accessing {W}ord{N}et-type Semantic Lexicons,2010,14,6,3,0,46223,bora savas,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes a Web service for accessing WordNet-type semantic lexicons. The central idea behind the service design is: given a query, the primary functionality of lexicon access is to present a partial lexicon by extracting the relevant part of the target lexicon. Based on this idea, we implemented the system as a RESTful Web service whose input query is specified by the access URI and whose output is presented in a standardized XML data format. LMF, an ISO standard for modeling lexicons, plays the most prominent role: the access URI pattern basically reflects the lexicon structure as defined by LMF; the access results are rendered based on Wordnet-LMF, which is a version of LMF XML-serialization. The Web service currently provides accesses to Princeton WordNet, Japanese WordNet, as well as the EDR Electronic Dictionary as a trial. To accommodate the EDR dictionary within the same framework, we modeled it also as a WordNet-type semantic lexicon. This paper thus argues possible alternatives to model innately bilingual/multilingual lexicons like EDR with LMF, and proposes possible revisions to Wordnet-LMF."
attia-etal-2010-automatically,An Automatically Built Named Entity Lexicon for {A}rabic,2010,21,26,4,0,24071,mohammed attia,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We have adapted and extended the automatic Multilingual, Interoperable Named Entity Lexicon approach to Arabic, using Arabic WordNet (AWN) and Arabic Wikipedia (AWK). First, we extract AWNÂs instantiable nouns and identify the corresponding categories and hyponym subcategories in AWK. Then, we exploit Wikipedia inter-lingual links to locate correspondences between articles in ten different languages in order to identify Named Entities (NEs). We apply keyword search on AWK abstracts to provide for Arabic articles that do not have a correspondence in any of the other languages. In addition, we perform a post-processing step to fetch further NEs from AWK not reachable through AWN. Finally, we investigate diacritization using matching with geonames databases, MADA-TOKAN tools and different heuristics for restoring vowel marks of Arabic NEs. Using this methodology, we have extracted approximately 45,000 Arabic NEs and built, to the best of our knowledge, the largest, most mature and well-structured Arabic NE lexical resource to date. We have stored and organised this lexicon following the LMF ISO standard. We conduct a quantitative and qualitative evaluation against a manually annotated gold standard and achieve precision scores from 95.83{\%} (with 66.13{\%} recall) to 99.31{\%} (with 61.45{\%} recall) according to different values of a threshold."
W09-3421,Query Expansion using {LMF}-Compliant Lexical Resources,2009,8,4,4,0,301,takenobu tokunaga,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper reports prototype multilingual query expansion system relying on LMF compliant lexical resources. The system is one of the deliverables of a three-year project aiming at establishing an international standard for language resources which is applicable to Asian languages. Our important contributions to ISO 24613, standard Lexical Markup Framework (LMF) include its robustness to deal with Asian languages, and its applicability to cross-lingual query tasks, as illustrated by the prototype introduced in this paper."
toral-etal-2008-named,Named Entity {W}ord{N}et,2008,9,37,3,0.652174,9426,antonio toral,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents the automatic extension of Princeton WordNet with Named Entities (NEs). This new resource is called Named Entity WordNet. Our method maps the noun is-a hierarchy of WordNet to Wikipedia categories, identifies the NEs present in the latter and extracts different information from them such as written variants, definitions, etc. This information is inserted into a NE repository. A module that converts from this generic repository to the WordNet specific format has been developed. The paper explores different aspects of our methodology such as the treatment of polysemous terms, the identification of hyponyms within the Wikipedia categorization system, the identification of Wikipedia articles which are NEs and the design of a NE repository compliant with the LMF ISO standard. So far, this procedure enriches WordNet with 310,742 NEs and 381,043 Âinstance ofÂ relations."
quochi-etal-2008-lexicon,A lexicon for biology and bioinformatics: the {BOOTS}trep experience.,2008,10,11,2,0.525794,30234,valeria quochi,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper describes the design, implementation and population of a lexical resource for biology and bioinformatics (the BioLexicon) developed within an ongoing European project. The aim of this project is text-based knowledge harvesting for support to information extraction and text mining in the biomedical domain. The BioLexicon is a large-scale lexical-terminological resource encoding different information types in one single integrated resource. In the design of the resource we follow the ISO/DIS 24613 ÂLexical Mark-up FrameworkÂ standard, which ensures reusability of the information encoded and easy exchange of both data and architecture. The design of the resource also takes into account the needs of our text mining partners who automatically extract syntactic and semantic information from texts and feed it to the lexicon. The present contribution first describes in detail the model of the BioLexicon along its three main layers: morphology, syntax and semantics; then, it briefly describes the database implementation of the model and the population strategy followed within the project, together with an example. The BioLexicon database in fact comes equipped with automatic uploading procedures based on a common exchange XML format, which guarantees that the lexicon can be properly populated with data coming from different sources."
vossen-etal-2008-kyoto,"{KYOTO}: a System for Mining, Structuring and Distributing Knowledge across Languages and Cultures",2008,32,44,10,0.359361,5469,piek vossen,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We outline work performed within the framework of a current EC project. The goal is to construct a language-independent information system for a specific domain (environment/ecology/biodiversity) anchored in a language-independent ontology that is linked to wordnets in seven languages. For each language, information extraction and identification of lexicalized concepts with ontological entries is carried out by text miners (ÂKybotsÂ). The mapping of language-specific lexemes to the ontology allows for crosslinguistic identification and translation of equivalent terms. The infrastructure developed within this project enables long-range knowledge sharing and transfer across many languages and cultures, addressing the need for global and uniform transition of knowledge beyond the specific domains addressed here."
tokunaga-etal-2008-adapting,Adapting International Standard for {A}sian Language Technologies,2008,8,6,6,0,301,takenobu tokunaga,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Corpus-based approaches and statistical approaches have been the main stream of natural language processing research for the past two decades. Language resources play a key role in such approaches, but there is an insufficient amount of language resources in many Asian languages. In this situation, standardisation of language resources would be of great help in developing resources in new languages. This paper presents the latest development efforts of our project which aims at creating a common standard for Asian language resources that is compatible with an international standard. In particular, the paper focuses on i) lexical specification and data categories relevant for building multilingual lexical resources for Asian languages; ii) a core upper-layer ontology needed for ensuring multilingual interoperability and iii) the evaluation platform used to test the entire architectural framework."
del-gratta-etal-2008-ufra,{UFRA}: a {UIMA}-based Approach to Federated Language Resource Architecture,2008,9,0,4,0.425407,29721,riccardo gratta,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper we address the issue of developing an interoperable infrastructure for language resources and technologies. In our approach, called UFRA, we extend the Federate Database Architecture System adding typical functionalities caming from UIMA. In this way, we capitalize the advantages of a federated architecture, such as autonomy, heterogeneity and distribution of components, monitored by a central authority responsible for checking both the integration of components and user rights on performing different tasks. We use the UIMA approach to manage and define one common front-end, enabling users and clients to query, retrieve and use language resources and technologies. The purpose of this paper is to show how UIMA leads from a Federated Database Architecture to a Federated Resource Architecture, adding to a registry of available components both static resources such as lexicons and corpora and dynamic ones such as tools and general purpose language technologies. At the end of the paper, we present a case-study that adopts this framework to integrate the SIMPLE lexicon and TIMEML annotation guidelines to tag natural language texts."
hayashi-etal-2008-ontologizing,Ontologizing Lexicon Access Functions based on an {LMF}-based Lexicon Taxonomy,2008,5,2,3,0.833333,18065,yoshihiko hayashi,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper discusses ontologization of lexicon access functions in the context of a service-oriented language infrastructure, such as the Language Grid. In such a language infrastructure, an access function to a lexical resource, embodied as an atomic Web service, plays a crucially important role in composing a composite Web service tailored to a userÂs specific requirement. To facilitate the composition process involving service discovery, planning and invocation, the language infrastructure should be ontology-based; hence the ontologization of a range of lexicon functions is highly required. In a service-oriented environment, lexical resources however can be classified from a service-oriented perspective rather than from a lexicographically motivated standard. Hence to address the issue of interoperability, the taxonomy for lexical resources should be ground to principled and shared lexicon ontology. To do this, we have ontologized the standardized lexicon modeling framework LMF, and utilized it as a foundation to stipulate the service-oriented lexicon taxonomy and the corresponding ontology for lexicon access functions. This paper also examines a possible solution to fill the gap between the ontological descriptions and the actual Web service API by adopting a W3C recommendation SAWSDL, with which Web service descriptions can be linked with the domain ontology."
W06-1001,Lexical Markup Framework ({LMF}) for {NLP} Multilingual Resources,2006,7,17,5,0,29837,gil francopoulo,Proceedings of the Workshop on Multilingual Language Resources and Interoperability,0,"Optimizing the production, maintenance and extension of lexical resources is one the crucial aspects impacting Natural Language Processing (NLP). A second aspect involves optimizing the process leading to their integration in applications. With this respect, we believe that the production of a consensual specification on multilingual lexicons can be a useful aid for the various NLP actors. Within ISO, one purpose of LMF (ISO-24613) is to define a standard for lexicons that covers multilingual data."
W06-1003,Towards Agent-based Cross-Lingual Interoperability of Distributed Lexical Resources,2006,9,6,5,0.704586,30233,claudia soria,Proceedings of the Workshop on Multilingual Language Resources and Interoperability,0,"In this paper we present an application fostering the integration and interoperability of computational lexicons, focusing on the particular case of mutual linking and cross-lingual enrichment of two wordnets, the ItalWordNet and Sinica BOW lexicons. This is intended as a case-study investigating the needs and requirements of semi-automatic integration and interoperability of lexical resources."
P06-4003,{L}e{XF}low: A System for Cross-Fertilization of Computational Lexicons,2006,3,3,4,0,39295,maurizio tesconi,Proceedings of the {COLING}/{ACL} 2006 Interactive Presentation Sessions,0,"This demo presents LeXFlow, a work-flow management system for cross-fertilization of computational lexicons. Borrowing from techniques used in the domain of document workflows, we model the activity of lexicon management as a set of workflow types, where lexical entries move across agents in the process of being dynamically updated. A prototype of LeXFlow has been implemented with extensive use of XML technologies (XSLT, XPath, XForms, SVG) and open-source tools (Cocoon, Tomcat, MySQL). LeXFlow is a web-based application that enables the cooperative and distributed management of computational lexicons."
P06-2106,Infrastructure for Standardization of {A}sian Language Resources,2006,10,18,5,0,301,takenobu tokunaga,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"As an area of great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least three strong advantages: to increase the competitive edge of Asian countries, to bring Asian countries to closer to their western counterparts, and to bring more cohesion among Asian countries. To achieve this goal, we have launched a two year project to create a common standard for Asian language resources. The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upper-layer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach."
monachini-etal-2006-unified,Unified Lexicon and Unified Morphosyntactic Specifications for Written and Spoken {I}talian,2006,8,3,1,1,17451,monica monachini,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The goal of this paper is (1) to illustrate a specific procedure for merging different monolingual lexicons, focussing on techniques for detecting and mapping equivalent lexical entries, and (2) to sketch a production model that enables one to obtain lexical resources via unification of existing data. We describe the creation of a Unified Lexicon (UL) from a common sample of the Italian PAROLE-SIMPLE-CLIPS phonological lexicon and of the Italian LCSTAR pronunciation lexicon. We expand previous experiments carried out at ILC-CNR: based on a detailed mechanism for mapping grammatical classifications of candidate UL entries, a consensual set of Unified Morphosyntactic Specifications (UMS) shared by lexica for the written and spoken areas is proposed. The impact of the UL on cross-validation issues is analysed: by looking into conflicts, mismatches and diverging classifications can be detected in both resources. The work presented is in line with the activities promoted by ELRA towards the development of methods for packaging new language resources by combining independently created resources, and was carried out as part of the ELRA Production Committee activities. ELRA aims to exploit the UL experience to carry out such merging activities for resources available on the ELRA catalogue in order to fulfill the users' needs."
soria-etal-2006-moving,Moving to dynamic computational lexicons with {L}e{XF}low,2006,9,4,6,0.704586,30233,claudia soria,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper we present LeXFlow, a web application framework where lexicons already expressed in standardised format semi-automatically interact by reciprocally enriching themselves. LeXFlow is intended for, on the one hand, paving the way to the development of dynamic multi-source lexicons; and on the other, for fostering the adoption of standards. Borrowing from techniques used in the domain of document workflows, we model the activity of lexicon management as a particular case of workflow instance, where lexical entries move across agents and become dynamically updated. To this end, we have designed a lexical flow (LF) corresponding to the scenario where an entry of a lexicon A becomes enriched via basically two steps. First, by virtue of being mapped onto a corresponding entry belonging to a lexicon B, the entry(LA) inherits the semantic relations available in lexicon B. Second, by resorting to an automatic application that acquires information about semantic relations from corpora, the relations acquired are integrated into the entry and proposed to the human encoder. As a result of the lexical flow, in addition, for each starting lexical entry(LA) mapped onto a corresponding entry(LB) the flow produces a new entry representing the merging of the original two."
gavrilidou-etal-2006-language,Language Resources Production Models: the Case of the {INTERA} Multilingual Corpus and Terminology,2006,9,2,6,1,39961,maria gavrilidou,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper reports on the multilingual Language Resources (MLRs), i.e. parallel corpora and terminological lexicons for less widely digitally available languages, that have been developed in the INTERA project and the methodology adopted for their production. Special emphasis is given to the reality factors that have influenced the MLRs development approach and their final constitution. Building on the experience gained in the project, a production model has been elaborated, suggesting ways and techniques that can be exploited in order to improve LRs production taking into account realistic issues."
francopoulo-etal-2006-lexical,Lexical Markup Framework ({LMF}),2006,3,123,4,0,29837,gil francopoulo,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Optimizing the production, maintenance and extension of lexical resources is one the crucial aspects impacting Natural Language Processing (NLP). A second aspect involves optimizing the process leading to their integration in applications. With this respect, we believe that the production of a consensual specification on lexicons can be a useful aid for the various NLP actors. Within ISO, the purpose of LMF is to define a standard for lexicons. LMF is a model that provides a common standardized framework for the construction of NLP lexicons. The goals of LMF are to provide a common model for the creation and use of lexical resources, to manage the exchange of data between and among these resources, and to enable the merging of large number of individual electronic resources to form extensive global electronic resources. In this paper, we describe the work in progress within the sub-group ISO-TC37/SC4/WG4. Various experts from a lot of countries have been consulted in order to take into account best practices in a lot of languages for (we hope) all kinds of NLP lexicons."
calzolari-etal-2006-next,Next Generation Language Resources using Grid,2006,2,0,8,0,50477,federico calzolari,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents a case study concerning the challenges and requirements posed by next generation language resources, realized as an overall model of open, distributed and collaborative language infrastructure. If a sort of Ânew paradigmÂ for language resource sharing is required, we think that the emerging and still evolving technology connected to Grid computing is a very interesting and suitable one for a concrete realization of this vision. Given the current limitations of Grid computing, it is very important to test the new environment on basic language analysis tools, in order to get the feeling of what are the potentialities and possible limitations connected to its use in NLP. For this reason, we have done some experiments on a module of the Linguistic Miner, i.e. the extraction of linguistic patterns from restricted domain corpora. The Grid environment has produced the expected results (reduction of the processing time, huge storage capacity, data redundancy) without any additional cost for the final user."
calzolari-etal-2004-enabler,"{ENABLER} Thematic Network of National Projects: Technical, Strategic and Political Issues of {LR}s",2004,2,6,9,0,18003,nicoletta calzolari,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper we present general strategies concerning Language Resources (LRs) xe2x80x93 Written, Spoken and, recently, Multimodal xe2x80x93 as developed within the ENABLER Thematic Network. LRs are a central component of the so-called xe2x80x9clinguistic infrastructurexe2x80x9d (the other key element being Evaluation), necessary for the development of any Human Language Technology (HLT) application. They play a critical role, as horizontal technology, in different emerging areas of FP6, and have been recognized as a priority within a number of national projects around Europe and world-wide. The availability of LRs is also a xe2x80x9csensitivexe2x80x9d issue, touching directly the sphere of linguistic and cultural identity, but also with economical, societal and political implications. This is going to be even more true in the new Europe with 25 languages on a par. Introduction After considering the strategic and infrastructural role of Language Resources (LRs) within any Human Language Technology (HLT) application (section 1), we focus on the main issues discussed within the ENABLER (European National Activities for Basic Language Resources) Thematic Network (section 2): the survey of LRs, interoperability and multilinguality, open access to LRs, validation methodologies for LRs, industrial and basic requirements. Finally, few recommendations are provided towards the design of general strategies and an overall coordination for the field of LRs (section 3). 1. The Strategic Role of LRs Language Resources (LRs) xe2x80x93 Written, Spoken and, recently, Multimodal xe2x80x93 are a central and strategic component of the so-called xe2x80x9clinguistic infrastructurexe2x80x9d (the other key element being Evaluation), necessary for the development of any Human Language Technology (HLT) application and product. The availability of adequate LRs for as many languages as possible is a pre-requisite for the development of a truly multilingual Information Society. They play a critical role, as horizontal technology, in different areas of the 6 Framework Programme, and have been recognized as a priority within a number of national projects around Europe. The availability of LRs is also a xe2x80x9csensitivexe2x80x9d issue, touching directly the sphere of linguistic and cultural identity, but also with economical, societal and political implications. This is going to be even more true in the new Europe with 25 languages on a par. The ENABLER Thematic Network of HLT National Projects in European countries xe2x80x93 an EC funded IST project, designed and started by Antonio Zampolli, with a clear strategic vision for the field of LRs xe2x80x93 is the first broad European initiative which has the mission of explicitly considering together the technical, organizational, strategic and political issues of LRs. In ENABLER these various aspects are put together in a coherent framework, to set up mediumand long-term set of priorities (both technical and strategic) and to promote these at the national and international levels. Moreover, ENABLER has recognized the importance to promote actions aiming at integrating the different resource types, until now developed independently, and xe2x80x93 as a consequence xe2x80x93 at promoting the cooperation between the communities of Speech, Text and Multimodality. In the following we briefly highlight the main issues tackled by ENABLER on the different layers. 2. The Main Issues 2.1. The Survey of LRs The ENABLER Consortium conducted the Survey of LRs to get a global picture of the situation on LRs, in order to be able to compare the various conditions that hold across different languages and xe2x80x93 on this basis xe2x80x93 to suggest more"
fersoe-monachini-2004-elra,{ELRA} Validation Methodology and Standard Promotion for Linguistic Resources,2004,3,6,2,0,41888,hanne fersoe,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes the results of work made for ELRA during 2003-2004. It describes the methodology for validation of written language resources (WLRs), specifically lexica, which has been developed for ELRA and tested on a few resources in the ELRA catalogue. It discusses the importance of key issues in lexicon creation and validation such as the adoption of standards for the coding of linguistic content and the importance of documentation. It reports on the experience gained from applying the methodology to lexical resources in the ELRA catalogue arguing that the checks must be reasonable, informative, on a suitable level of detail, and generic. It proposes a set of basic elements to be included in future discussions on establishing standards for lexicon resources. In conclusion it sketches the work to be undertaken in 2004 to promote validation and the adoption of standards."
monachini-etal-2004-unifying,Unifying Lexicons in view of a Phonological and Morphological Lexical {DB},2004,4,4,1,1,17451,monica monachini,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The present work falls in the line of activities promoted by the European Languguage Resource Association (ELRA) Production Committee (PCom) and raises issues in methods, procedures and tools for the reusability, creation, and management of Language Resources. A two-fold purpose lies behind this experiment. The first aim is to investigate the feasibility, define methods and procedures for combining two Italian lexical resources that have incompatible formats and complementary information into a Unified Lexicon (UL). The adopted strategy and the procedures appointed are described together with the driving criterion of the merging task, where a balance between human and computational efforts is pursued. The coverage of the UL has been maximized, by making use of simple and fast matching procedures. The second aim is to exploit this newly obtained resource for implementing the phonological and morphological layers of the CLIPS lexical database. Implementing these new layers and linking them with the already exisitng syntactic and semantic layers is not a trivial task. The constraints imposed by the model, the impact at the architectural level and the solution adopted in order to make the whole database xe2x80x98speakxe2x80x99 efficiently are presented. Advantages vs. disadvantages are discussed. 1. Background and Motivations The work described here raises issues in methods, procedures and tools for the reusability, creation, and management of Language Resources (LRs) and has been performed under the aegis of the European Language Resources Association (ELRA). ELRA is one of the major driving force and catalyst of a series of activities linked to LRs for the Human Language Technology sector. In the last years, one of its missions has been the production of LRs, fostered also via the packaging and customisation of already existing resources (www.elra.info). The present work falls in this line of activities promoted, specifically, by the ELRA Production Committee (PCom). The idea behind the work is to conduct an experiment with a twofold purpose. From a purely methodological perspective, the aim is to investigate the feasibility, define methods and procedures for pooling and unifying two independently created Italian lexical resources into a Unified Lexicon (UL). This allows to combine two sources containing complementary information and incompatible formats at reasonable costs in terms of human efforts and computational techniques. From a concrete point of view, the experiment offers as a positive side-effect the possibility to exploit the new obtained resource for enriching an already existing lexicon with further linguistic modules. The implementation of a phonological and a morphological layer within the CLIPS architecture (Ruimy et al., 2002; Ruimy et al., 2003), a relational database which already contains the syntactic and semantic levels, is not a trivial task. The constraints imposed by the CLIPS model have interesting architectural impacts and force some implementation choices, in order to make the whole database xe2x80x98speakxe2x80x99 efficiently. The paper mirrors this bipartition: two separate sections are dedicated, respectively, to the description of the Unified Lexicon experiment and the implementation of the phonological and morphological lexical layers. 2. The Unified Lexicon Experiment Literature reports about some different approaches and methods for creating large-scale resources by combining already available sources. The trend is generally towards a semi-automatic approach. Chan and Wu (1999) present an intuitive and computationally not heavy method to merge lexicons that have incompatible Part-of-Speech categories: the merging is done via a set of mapping rules that compare each other the tags of those lemmas shared by both lexicons. Skoumalova (2001), embracing this trend, discusses the solutions adopted to combine existing resources with different formats to obtain an electronic syntactic lexicon of Czech: an automatic procedure of conversion from the source dictionary to the proposed format is appointed where, nevertheless, an amount of post-editing effort is required. Such exercises teach that the adopted methodologies and the consequent results strongly depend on (i) the aims of the task and (ii) the intrinsic characteristics of the resources involved. Moreover, the properties of the language are another noticeable variable which comes into play. All these factors constitute, hence, a barrier to the creation of a standard protocol for this by then consolidated orientation in resource building. As a consequence, everyone tends to develop the best suited strategies and ad-hoc procedures, where, generally, a balance between computational and human efforts is pursued. This is also the driving criterion of the UL experiment proposed here, where incompatibilities and differences contained in the sources have been surmounted, trying to maximize the coverage of the UL with reasonable human efforts and not heavy nor sophisticated computational techniques, by a simple and fast matching procedure."
bertagna-etal-2004-content,Content Interoperability of Lexical Resources: Open Issues and {``}{MILE}{''} Perspectives,2004,4,13,3,0.694444,48220,francesca bertagna,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The paper tackles the issue of content interoperability among lexical resources, by presenting an experiment of mapping differently conceived lexicons, FrameNet and NOMLEX, onto MILE (Multilingual ISLE Lexical Entry), a meta-entry for the encoding of multilingual lexical information, acting as a general schema of shared and common lexical objects. The aim is to (i) raise problems and (ii) test the expressive potentialities of MILE as a standard environment for Computational Lexicons."
ruimy-etal-2002-clips,"{CLIPS}, a Multi-level {I}talian Computational Lexicon: a Glimpse to Data",2002,12,22,2,0,48459,nilda ruimy,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"CLIPS is a multi-layered Italian computational lexicon based on the PAROLE-SIMPLE model. In this paper we briefly recall the main characteristics of the model and devote our attention to issues emerging from the encoding of large quantities of data, especially in relation to those types of syntactic and semantic information specific to our lexicon and that reflect innovative features of the underlying model. At syntactic level, we show how alternating structures may be encoded in a linguistically more elegant way by using framesets. We illustrate the connection between syntactic and semantic information, and show how the SIMPLE Italian lexicon approach to predicate selection has been refined in CLIPS. At semantic level, we illustrate the richness of information types encoded in a word sense description and the way such a wealth of data can be exploited. We stress in particular the expressive power of the Extended Qualia Structure yet mentioning some of its problematic aspects. We show that queries on qualia relations allow to retrieve lexical collocates, to extract domain specific information, semantic networks, and help interpreting modifying PPs in complex nominals. Finally, we show that features, which cut across the type hierarchy, have a stronger expressive power with respect to semantic types in identifying selectional preferences."
bel-etal-2000-simple,{SIMPLE}: A General Framework for the Development of Multilingual Lexicons,2000,7,156,6,0,17513,nuria bel,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The project LE-SIMPLE is an innovative attempt of building harmonized syntactic-semantic lexicons for twelve European languages, aimed at use in different Human Language Technology applications. SIMPLE provides a general design model for the encoding of a large amount of semantic information, spanning from ontological typing, to argument structure and terminology. SIMPLE thus provides a general framework for resource development, where state-of-the-art results in lexical semantics are coupled with the needs of Language Engineering applications accessing semantic information."
