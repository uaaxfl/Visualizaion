2020.lrec-1.797,aggarwal-etal-2012-twins,1,0.748116,"TEM) in children between the ages of 7 and 14. They are question answering characters, but unlike SGTs Blackwell and Star, the response is a whole dialogue sequence, potentially involving interchange from both characters, rather than a single character turn. There are two types of users for the Twins: demonstrators, who are museum staff members, using head-mounted microphones, and museum visitors, who use a Shure 522 table-top mounted microphone (Traum et al., 2012). Speech was collected at the Museum of Science in Boston from 2009 to 2011. More on analysis of the museum data can be found in (Aggarwal et al., 2012). The following utterances illustrate a segment of a dialogue between a museum visitor and the Twins: Museum visitor Hello. Figure 1: A screenshot of the ASR testing app. Ada Hey there! Grace How can we help you? 4. Museum visitor Who are you? Grace Could you say that again? User Who are you named after? Ada Our namesakes are Ada Lovelace and Grace Hopper. Grace Yeah, they may be old fashioned names. But both are from the most modern computing women of their time. The utterances collected from user sessions in the domains described above were transcribed manually to create a separate corpus fo"
2020.lrec-1.797,burger-etal-2006-competitive,0,0.139927,"Missing"
2020.lrec-1.797,W06-1303,1,0.799119,"he shooting? Doctor Perez Captain, we need medical supplies in order to run the clinic downtown. Amani So you want to talk about the man who did the shooting? I have heard that he is called Saif. Cadet Do you know where he lives? Amani You are asking for a lot of information. If you expect me to tell you that you must offer me secrecy. Cadet I will keep this a secret. Amani You have assured me of secrecy. I believe he hides on the second floor of Assad’s shop. I know he is in there but when I go in the shop I don’t see him. And I have no idea where he is now. 3.3. SGT Blackwell SGT Blackwell (Leuski et al., 2006b) is a questionanswering character who answers general questions about the Army, himself, and his technology. Speech comes from visitors to the Cooper-Hewitt Museum in New York from December 2006 to March 2007, who interacted with SGT Blackwell at his booth as part of the National Design Triennial exhibition (Robinson et al., 2008). SGT Blackwell is designed to answer independent questions, like SGT Star. However, the questions collected from sessions with SGT Blackwell come from the general public, and not from trained handlers as was the case with the questions collected from sessions with"
2020.lrec-1.797,W13-4064,1,0.633667,"main-specific acoustic and/or language models. • The possibility for training on individual speakers, and the amount of available user-specific training data. The evaluation described in this paper is targeted to ASR consumers and potential consumers with limited experience in ASR. We use state-of-the-art ASR systems that have been developed both in industry and academia, and our focus is on employing out-of-the-box acoustic and language models, i.e., we do not train domain-specific models. This is our third large-scale ASR evaluation using corpora from a variety of domains (Yao et al., 2010; Morbini et al., 2013). Compared to our previous evaluations, we see a large improvement in ASR performance, which illustrates the significant progress that has recently been made in ASR technology, especially with the use of deep learning techniques. However, there are domains where interactions take place under noisy conditions and that require special vocabulary and language models. In these domains we will see that current state-of-the-art speech recognizers perform poorly. Furthermore, the performance of a specific ASR system can vary significantly depending on the domain. The remainder of the paper describes"
2020.lrec-1.797,robinson-etal-2008-ask,1,0.692313,"crecy. Cadet I will keep this a secret. Amani You have assured me of secrecy. I believe he hides on the second floor of Assad’s shop. I know he is in there but when I go in the shop I don’t see him. And I have no idea where he is now. 3.3. SGT Blackwell SGT Blackwell (Leuski et al., 2006b) is a questionanswering character who answers general questions about the Army, himself, and his technology. Speech comes from visitors to the Cooper-Hewitt Museum in New York from December 2006 to March 2007, who interacted with SGT Blackwell at his booth as part of the National Design Triennial exhibition (Robinson et al., 2008). SGT Blackwell is designed to answer independent questions, like SGT Star. However, the questions collected from sessions with SGT Blackwell come from the general public, and not from trained handlers as was the case with the questions collected from sessions with SGT Star. The museum exhibit listed a set of about five sample questions, but visitors were free to ask anything they wanted. The following utterances illustrate a segment of a dialogue between a museum visitor and SGT Blackwell: Doctor Perez We can’t take sides. Trainee Would you be willing to move downtown? Elder Al Hassan We woul"
2020.lrec-1.797,yao-etal-2010-practical,1,0.442037,"ain by building domain-specific acoustic and/or language models. • The possibility for training on individual speakers, and the amount of available user-specific training data. The evaluation described in this paper is targeted to ASR consumers and potential consumers with limited experience in ASR. We use state-of-the-art ASR systems that have been developed both in industry and academia, and our focus is on employing out-of-the-box acoustic and language models, i.e., we do not train domain-specific models. This is our third large-scale ASR evaluation using corpora from a variety of domains (Yao et al., 2010; Morbini et al., 2013). Compared to our previous evaluations, we see a large improvement in ASR performance, which illustrates the significant progress that has recently been made in ASR technology, especially with the use of deep learning techniques. However, there are domains where interactions take place under noisy conditions and that require special vocabulary and language models. In these domains we will see that current state-of-the-art speech recognizers perform poorly. Furthermore, the performance of a specific ASR system can vary significantly depending on the domain. The remainder"
2020.lrec-1.91,P09-1099,0,0.0281269,"learning (RL) is a very popular approach to learning dialogue policies from data or simulated users (SUs) (Jurˇc´ıcˇ ek et al., 2012). In RL, a typical reward function is for the system to earn a number of points for a fully or partially successful dialogue, and subtract a penalty per system turn to ensure that the learned dialogue policies will not favor lengthy and tedious dialogues (Henderson et al., 2008). Note however that longer dialogue lengths are not necessarily indicative of poor dialogue quality but depending on the task they may actually indicate user engagement and satisfaction (Foster et al., 2009). Schatzmann et al. (2006) present an overview of metrics that have been proposed in the literature for measuring the quality of SUs used for training and evaluating dialogue policies. The action generated by the SU is compared against the user action in a human-human or humansystem reference corpus (in the same dialogue context), and measures such as precision, recall, accuracy, and perplexity are used (Schatzmann et al., 2005; Georgila et al., 2005; Georgila et al., 2006; Pietquin and Hastie, 2013). Also, to take into account the fact that SU actions are generated based on a probability dist"
2020.lrec-1.91,P15-2073,0,0.0237073,"erlap similarity metrics such as BLEU, METEOR, and ROUGE (originally employed in machine translation and summarization) are widely used for measuring chatbot dialogue quality. However, BLEU, METEOR, and ROUGE suffer from the same problems as the aforementioned SU evaluation metrics. In fact it has been shown that BLEU, METEOR, and ROUGE do not correlate well with human judgements of dialogue quality (Liu et al., 2016). Discriminative BLEU, a variation of BLEU where reference strings are scored for quality by human raters, was found to correlate better with human judgements than standard BLEU (Galley et al., 2015). To address the issues with BLEU, METEOR, and ROUGE, next utterance classification was introduced as a method for evaluating chatbots (Lowe et al., 2016), but the proposed metric recall@k is very similar to the recall metric previously used for evaluating SUs, and consequently has the same limitations. Also, topic-based metrics for chatbot evaluation (topic breadth and topic depth) were found to correlate well with human judgements (Guo et al., 2017). 3. Wizard of Oz Data Collection We built a GUI-based environment for our Wizard of Oz (WOz) data collection (Gordon et al., 2019). A human Wiza"
2020.lrec-1.91,J08-4002,1,0.80145,"imized by controlling the factors that affect it. In the example above, user satisfaction can be optimized by increasing task success, and minimizing dialogue length and speech recognition errors. Reinforcement learning (RL) is a very popular approach to learning dialogue policies from data or simulated users (SUs) (Jurˇc´ıcˇ ek et al., 2012). In RL, a typical reward function is for the system to earn a number of points for a fully or partially successful dialogue, and subtract a penalty per system turn to ensure that the learned dialogue policies will not favor lengthy and tedious dialogues (Henderson et al., 2008). Note however that longer dialogue lengths are not necessarily indicative of poor dialogue quality but depending on the task they may actually indicate user engagement and satisfaction (Foster et al., 2009). Schatzmann et al. (2006) present an overview of metrics that have been proposed in the literature for measuring the quality of SUs used for training and evaluating dialogue policies. The action generated by the SU is compared against the user action in a human-human or humansystem reference corpus (in the same dialogue context), and measures such as precision, recall, accuracy, and perple"
2020.lrec-1.91,D16-1230,0,0.0227334,"responses can be much more meaningful, which has led to the development of coding schemes for response appropriateness in such cases (Traum et al., 2004; Robinson et al., 2010). Currently, word-overlap similarity metrics such as BLEU, METEOR, and ROUGE (originally employed in machine translation and summarization) are widely used for measuring chatbot dialogue quality. However, BLEU, METEOR, and ROUGE suffer from the same problems as the aforementioned SU evaluation metrics. In fact it has been shown that BLEU, METEOR, and ROUGE do not correlate well with human judgements of dialogue quality (Liu et al., 2016). Discriminative BLEU, a variation of BLEU where reference strings are scored for quality by human raters, was found to correlate better with human judgements than standard BLEU (Galley et al., 2015). To address the issues with BLEU, METEOR, and ROUGE, next utterance classification was introduced as a method for evaluating chatbots (Lowe et al., 2016), but the proposed metric recall@k is very similar to the recall metric previously used for evaluating SUs, and consequently has the same limitations. Also, topic-based metrics for chatbot evaluation (topic breadth and topic depth) were found to c"
2020.lrec-1.91,W16-3634,0,0.0182117,"t dialogue quality. However, BLEU, METEOR, and ROUGE suffer from the same problems as the aforementioned SU evaluation metrics. In fact it has been shown that BLEU, METEOR, and ROUGE do not correlate well with human judgements of dialogue quality (Liu et al., 2016). Discriminative BLEU, a variation of BLEU where reference strings are scored for quality by human raters, was found to correlate better with human judgements than standard BLEU (Galley et al., 2015). To address the issues with BLEU, METEOR, and ROUGE, next utterance classification was introduced as a method for evaluating chatbots (Lowe et al., 2016), but the proposed metric recall@k is very similar to the recall metric previously used for evaluating SUs, and consequently has the same limitations. Also, topic-based metrics for chatbot evaluation (topic breadth and topic depth) were found to correlate well with human judgements (Guo et al., 2017). 3. Wizard of Oz Data Collection We built a GUI-based environment for our Wizard of Oz (WOz) data collection (Gordon et al., 2019). A human Wizard plays the role of the system by pressing buttons in a GUI. Each button corresponds to a Wizard action which is then transformed into a sentence (throug"
2020.lrec-1.91,W12-1611,1,0.785959,"l., 2006). However, these metrics can be problematic because if a SU action is not the same as the user action in the reference corpus, this does not necessarily mean that it is a poor action. Also, once a user or system response deviates from the corresponding action in the reference corpus, the remaining dialogue will unfold in an entirely different way than the fixed dialogue in the reference corpus, which will make further comparisons meaningless. In non-task-oriented dialogue systems (e.g., chatbots) developing robust evaluation metrics can be even harder than for task-oriented dialogue (Misu et al., 2012). Here it is not clear what success means and task-specific objective metrics are not appropriate. Instead subjective evaluations for appropriateness of responses can be much more meaningful, which has led to the development of coding schemes for response appropriateness in such cases (Traum et al., 2004; Robinson et al., 2010). Currently, word-overlap similarity metrics such as BLEU, METEOR, and ROUGE (originally employed in machine translation and summarization) are widely used for measuring chatbot dialogue quality. However, BLEU, METEOR, and ROUGE suffer from the same problems as the afore"
2020.lrec-1.91,W09-3901,1,0.741973,"s, also in the IoT domain. 2. Related Work Hastie (2012) presents an overview of evaluation frameworks and metrics that have been proposed in the literature for measuring the quality of human-system dialogue interaction, mainly for task-oriented dialogue systems. Some of these metrics are subjective (e.g., user satisfaction, perceived task completion, etc.), while others are objective (e.g., word error rate, dialogue length, etc.). Objective measures can be calculated from the interaction logs while subjective assessments can be collected via surveys and questionnaires (Hone and Graham, 2000; Paksima et al., 2009). PARADISE is perhaps the most well-known framework for evaluating dialogue systems, and an attempt to automate the evaluation process (Walker et al., 2000). PARADISE seeks to optimize a desired quality such as user satisfaction by formulating it as a linear combination of a variety of metrics, such as task success and dialogue cost (e.g., dialogue length, speech recognition errors, etc.). The contribution of each factor is determined by weights calculated via linear regression. The advantage of this method is that once a desired quality has been formulated as a realistic evaluation function,"
2020.lrec-1.91,robinson-etal-2010-dialogues,1,0.719854,"old in an entirely different way than the fixed dialogue in the reference corpus, which will make further comparisons meaningless. In non-task-oriented dialogue systems (e.g., chatbots) developing robust evaluation metrics can be even harder than for task-oriented dialogue (Misu et al., 2012). Here it is not clear what success means and task-specific objective metrics are not appropriate. Instead subjective evaluations for appropriateness of responses can be much more meaningful, which has led to the development of coding schemes for response appropriateness in such cases (Traum et al., 2004; Robinson et al., 2010). Currently, word-overlap similarity metrics such as BLEU, METEOR, and ROUGE (originally employed in machine translation and summarization) are widely used for measuring chatbot dialogue quality. However, BLEU, METEOR, and ROUGE suffer from the same problems as the aforementioned SU evaluation metrics. In fact it has been shown that BLEU, METEOR, and ROUGE do not correlate well with human judgements of dialogue quality (Liu et al., 2016). Discriminative BLEU, a variation of BLEU where reference strings are scored for quality by human raters, was found to correlate better with human judgements"
2020.lrec-1.91,2005.sigdial-1.6,1,0.516421,"that longer dialogue lengths are not necessarily indicative of poor dialogue quality but depending on the task they may actually indicate user engagement and satisfaction (Foster et al., 2009). Schatzmann et al. (2006) present an overview of metrics that have been proposed in the literature for measuring the quality of SUs used for training and evaluating dialogue policies. The action generated by the SU is compared against the user action in a human-human or humansystem reference corpus (in the same dialogue context), and measures such as precision, recall, accuracy, and perplexity are used (Schatzmann et al., 2005; Georgila et al., 2005; Georgila et al., 2006; Pietquin and Hastie, 2013). Also, to take into account the fact that SU actions are generated based on a probability distribution, expected precision, expected recall, and expected accuracy are used (Georgila et al., 2006). However, these metrics can be problematic because if a SU action is not the same as the user action in the reference corpus, this does not necessarily mean that it is a poor action. Also, once a user or system response deviates from the corresponding action in the reference corpus, the remaining dialogue will unfold in an enti"
2020.lrec-1.91,traum-etal-2004-evaluation,1,0.60556,"ng dialogue will unfold in an entirely different way than the fixed dialogue in the reference corpus, which will make further comparisons meaningless. In non-task-oriented dialogue systems (e.g., chatbots) developing robust evaluation metrics can be even harder than for task-oriented dialogue (Misu et al., 2012). Here it is not clear what success means and task-specific objective metrics are not appropriate. Instead subjective evaluations for appropriateness of responses can be much more meaningful, which has led to the development of coding schemes for response appropriateness in such cases (Traum et al., 2004; Robinson et al., 2010). Currently, word-overlap similarity metrics such as BLEU, METEOR, and ROUGE (originally employed in machine translation and summarization) are widely used for measuring chatbot dialogue quality. However, BLEU, METEOR, and ROUGE suffer from the same problems as the aforementioned SU evaluation metrics. In fact it has been shown that BLEU, METEOR, and ROUGE do not correlate well with human judgements of dialogue quality (Liu et al., 2016). Discriminative BLEU, a variation of BLEU where reference strings are scored for quality by human raters, was found to correlate bette"
E06-2009,W03-2123,1,0.88171,"Missing"
E06-2009,C00-1073,0,0.023374,"trics combined with a fixed penalty for dialogue length (see (Henderson et al., 2005)). This agent can be called whenever the system has to decide on the next dialogue move. In the original hand-coded system this decision is made by way of a dialogue plan (using the “deliberate” solvable). The RL agent can be used to drive the entire dialogue policy, or can be called only in certain circumstances. This makes it usable for whole dialogue strategies, but also, if desired, it can be targetted only on specific dialogue management decisions (e.g. implicit vs. explicit confirmation, as was done by (Litman et al., 2000)). One important research issue is that of tranferring learnt strategies between domains. We learnt a strategy for the C OMMUNICATOR flight booking dialogues (Lemon et al., 2005; Henderson et al., 2005), but this is generated by rather different scenarios than the in-car dialogues. However, both are “slot-filling” or information-seeking applications. We defined a mapping (described below) between the states and actions of both systems, in order to construct an interface between the learnt policies for C OMMUNICATOR and the in-car baseline system. 5.2 Mapping between COMMUNICATOR and the In-car"
georgila-etal-2008-fully,moller-etal-2008-corpus,1,\N,Missing
georgila-etal-2008-fully,cucchiarini-etal-2006-jasmin,0,\N,Missing
georgila-etal-2012-practical,W10-4318,1,\N,Missing
J08-4002,W03-2123,1,0.704684,"2005; Georgila et al., submitted) to assign Speech Acts and Tasks to the user utterances, and to compute state representations for each point in the dialogue (i.e., after every utterance). Although we annotated the whole 2000 and 2001 corpora, because we need the results of user questionnaires (as discussed subsequently), we only make use of the 2001 data for the experiments reported here. The 2001 data has eight systems, 1,683 dialogues, and 125,388 total states, two thirds of which result from system actions and one third from user actions. The annotation system is implemented using DIPPER (Bos et al. 2003) and OAA (Cheyer and Martin 2001), using several OAA agents (see Georgila, Lemon, and Henderson, 2005, and Georgila et al., submitted, for more details). Following the ISU approach, we represented states using Information States, which are feature structures intended to record all the information about the preceding portion of the dialogue that is relevant to making dialogue management decisions. An example of some of the types of information recorded in an Information State is shown in Figure 1, including ﬁlled slots, conﬁrmed slots, and previous speech acts. Given this corpus, we need to lea"
J08-4002,P06-1024,1,0.840119,"Missing"
J08-4002,P04-1044,1,0.798229,"Missing"
J08-4002,P06-2085,1,0.919667,"y of the states of information slots (e.g., destination city ﬁlled with high conﬁdence) in the application (Goddeau and Pineau 2000; Levin, Pieraccini, and Eckert 2000; Singh et al. 2000a, 2000b, 2002; Young 2000; Schefﬂer and Young 2002; Williams, Poupart, and Young 2005a, 2005b; Williams and Young 2005; Pietquin and Dutoit 2006b), with perhaps some additional low-level information (such as acoustic features [Pietquin 2004]). Only recently have researchers experimented with using enriched representations of dialogue context (Gabsdil and Lemon 2004; Lemon et al. 2005; Frampton and Lemon 2006; Rieser and Lemon 2006c), as we do in this article. From this work it is known that adding context features leads to better dialogue strategies, compared to, for example, simply using the status of ﬁlled or conﬁrmed information slots as has been studied in all prior work (Frampton and Lemon 2006). In this article we explore methods for scalable, tractable learning when using all the available context features. Reinforcement Learning requires estimating how good different actions will be in different dialogue contexts. Because most previous work has only differentiated between a small number of possible dialogue con"
J08-4002,2005.sigdial-1.6,1,0.727657,"learning approaches is the extent to which they train on data from simulated users of different kinds, rather than train on data gathered from real user interactions (as is done in this article). Simulated users are generally preferred due to the much smaller development effort involved, and the fact that trialand-error training with humans is tedious for the users. However, the issues of how to construct and then evaluate simulated users are open problems. Clearly there is a dependency between the accuracy of the simulation used for training and the eventual dialogue policy that is learned (Schatzmann et al. 2005). Current research attempts to develop metrics for user simulation that are predictive of the overall quality of the ﬁnal learned dialogue policy (Schatzmann, Georgila, and Young 2005; Schatzmann et al. 2005; Georgila, Henderson, and Lemon 2005; Georgila, Henderson, and Lemon 2006; Rieser and Lemon 2006a; Schatzmann et al. 2006; Williams 2007). Furthermore, several approaches use simple probabilistic simulations encoded by hand, using intuitions about reasonable user behaviors (e.g., Pietquin 2004; Frampton and Lemon 2005; Pietquin and Dutoit 2006a), whereas other work (e.g., Schefﬂer and Youn"
J08-4002,H01-1015,0,0.0687517,"portion of the dialogue that is relevant to making dialogue management decisions. An example of some of the types of information recorded in our Information States is shown in Figure 1, including ﬁlled slots, conﬁrmed slots, and previous speech acts. Previous work has raised the question of whether dialogue management policies can be learned (Levin and Pieraccini 1997) for systems that have only a limited view of the dialogue context, for example, not including prior speech act history (see the following). One prominent representation of the set of possible system actions is the DATE scheme (Walker and Passonneau 2001). In particular, this representation is used in the C OMMUNICATOR corpus annotation (Walker, Passonneau, and Boland 2001), discussed herein. The DATE scheme classiﬁes system actions in terms of their Conversational Domain, Speech Act, and Task. For example, one possible system action is about task, Figure 1 Example ﬁelds from an Information State annotation. User-provided information is in square brackets. 489 Computational Linguistics Volume 34, Number 4 request info, dest city, which corresponds to a system utterance such as What is your destination city? The speciﬁc instantiation of this"
J08-4002,P98-2219,0,0.0208242,"Missing"
J08-4002,P01-1066,0,0.149979,"olicy that is different from that used to generate the data (called “off-policy” learning), but these methods have been found not to work well with linear function approximation (Sutton and Barto 1998). They also do not solve the problem of straying from the region of state space that has been observed in the data, discussed subsequently. 491 Computational Linguistics Volume 34, Number 4 1.2 The COMMUNICATOR Domain and Data Annotation To empirically evaluate our proposed learning method, we apply it to the C OMMU NICATOR domain using the C OMMUNICATOR corpora. The C OMMUNICATOR corpora (2000 [Walker et al. 2001] and 2001 [Walker et al. 2002b]) consist of human–machine dialogues (approximately 2,300 dialogues in total). The users always try to book a ﬂight, but they may also try to select a hotel or car rental. The dialogues are primarily “slotﬁlling” dialogues, with some information being presented to the user after the system thinks it has ﬁlled (or conﬁrmed) the relevant slots. These corpora have been previously annotated using the DATE scheme, for the Conversational Domain, Speech Act, and Task of each system utterance (Walker and Passonneau 2001; Walker, Passonneau, and Boland 2001). In addition"
J08-4002,2005.sigdial-1.4,0,0.152387,"Missing"
J08-4002,W03-2111,0,0.256834,"Missing"
J08-4002,P00-1013,0,\N,Missing
J08-4002,C98-2214,0,\N,Missing
J08-4002,E06-2009,1,\N,Missing
L18-1683,P16-1170,0,0.0764105,"rovide a crowd-sourcing methodology to offload complex annotation between expert users and novice users and evaluate them. This is particularly useful for creating a sizable corpus. 2. Related Work Recently, there has been a lot of work on applications that combine vision and language, e.g., understanding and generating image descriptions (Kulkarni et al., 2013), identifying visual reference in the presence of distractors (Paetzel et al., 2015; de Vries et al., 2016), visual question answering (Antol et al., 2015), visual storytelling (Huang et al., 2016), generating questions about an image (Mostafazadeh et al., 2016), and question-answer interactions grounded on information shown in an image (Mostafazadeh et al., 2017). Current image and language corpora typically consist of digital photographs paired with crowd-sourced captions (Lin et al., 2014; Krishna et al., 2017), or in some cases with questions related to those images (Mostafazadeh et al., 2016). Much of the work above is relevant to the problem at hand. For example, understanding image descriptions is crucial for interpreting the requests quoted above, as all of them contain image descriptions (my wedding dress; my dog’s eyes; the people in the ba"
L18-1683,I17-1047,0,0.0714646,"and evaluate them. This is particularly useful for creating a sizable corpus. 2. Related Work Recently, there has been a lot of work on applications that combine vision and language, e.g., understanding and generating image descriptions (Kulkarni et al., 2013), identifying visual reference in the presence of distractors (Paetzel et al., 2015; de Vries et al., 2016), visual question answering (Antol et al., 2015), visual storytelling (Huang et al., 2016), generating questions about an image (Mostafazadeh et al., 2016), and question-answer interactions grounded on information shown in an image (Mostafazadeh et al., 2017). Current image and language corpora typically consist of digital photographs paired with crowd-sourced captions (Lin et al., 2014; Krishna et al., 2017), or in some cases with questions related to those images (Mostafazadeh et al., 2016). Much of the work above is relevant to the problem at hand. For example, understanding image descriptions is crucial for interpreting the requests quoted above, as all of them contain image descriptions (my wedding dress; my dog’s eyes; the people in the background; my ex). However, to our knowledge, no work has yet attempted to tackle the specific task of au"
L18-1683,W15-4610,1,0.637423,"reference to objects in the images. Second, a framework for understanding these natural language instructions and mapping them to actionable computer commands. Finally, we provide a crowd-sourcing methodology to offload complex annotation between expert users and novice users and evaluate them. This is particularly useful for creating a sizable corpus. 2. Related Work Recently, there has been a lot of work on applications that combine vision and language, e.g., understanding and generating image descriptions (Kulkarni et al., 2013), identifying visual reference in the presence of distractors (Paetzel et al., 2015; de Vries et al., 2016), visual question answering (Antol et al., 2015), visual storytelling (Huang et al., 2016), generating questions about an image (Mostafazadeh et al., 2016), and question-answer interactions grounded on information shown in an image (Mostafazadeh et al., 2017). Current image and language corpora typically consist of digital photographs paired with crowd-sourced captions (Lin et al., 2014; Krishna et al., 2017), or in some cases with questions related to those images (Mostafazadeh et al., 2016). Much of the work above is relevant to the problem at hand. For example, under"
L18-1683,W15-4622,0,0.098124,"Missing"
N09-2028,J99-4003,0,0.145259,"how that by using ILP we can improve the performance of our models with negligible cost in processing time. The less training data is available the larger the improvement due to ILP. 1 Introduction Speech disfluencies (also known as speech repairs) occur frequently in spontaneous speech and can pose difficulties to natural language processing (NLP) since most NLP tools (e.g. parsers, part-of-speech taggers, information extraction modules) are traditionally trained on written language. Speech disfluencies can be divided into three intervals, the reparandum, the editing term and the correction (Heeman and Allen, 1999; Liu et al., 2006). (it was) * (you know) it was set In the above example, “it was” is the reparandum, “you know” is the editing term and the remaining sentence is the correction. The asterisk marks the interruption point at which the speaker halts the original utterance in order to start the repair. The editing term is optional and consists of one or more filled pauses (e.g. uh, uh-huh) or discourse markers (e.g. you know, so). Some researchers include 109 editing terms in the definition of disfluencies. Here we focus only on detecting repetitions (the speaker repeats some part of the uttera"
N09-2028,W04-2401,0,0.0162851,"s from the speech recognition output. In this paper we propose a novel framework for speech disfluency detection based on Integer Linear Programming (ILP). With Linear Programming (LP) problems the goal is to optimize a linear objective function subject to linear equality and linear inequality constraints. When some or all the variables of the objective function and the constraints are non-negative integers, LP becomes ILP. ILP has recently attracted much attention in NLP. It has been applied to several problems including sentence compression (Clarke and Lapata, 2008) and relation extraction (Roth and Yih, 2004). Some of these methods (e.g. (Roth and Yih, 2004)) follow the two-stage approach of first hypothesizing a list of possible answers using a classifier and then selecting the best answer by applying ILP. We have adopted this twostage approach and applied it to speech disfluency detection. In the first stage we use state-of-the-art techProceedings of NAACL HLT 2009: Short Papers, pages 109–112, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics niques for speech disfluency detection, in particular, Hidden-Event Language Models (HELMs) (Stolcke and Shriberg, 1996), Max"
N16-3007,2005.sigdial-1.14,0,0.0452554,"The dialogue management logic is designed to deal with instances where the classifier cannot identify a good direct response. During training, NPCEditor calculates a response threshold based on the classifier’s confidence in the appropriateness of selected responses; at runtime, if the confidence for a selected response falls below the predetermined threshold, that response is replaced with an “off-topic” utterance that asks the user to repeat the question or takes initiative and changes the topic (Leuski et al., 2006); such failure to return a direct response, also called non-understanding (Bohus and Rudnicky, 2005), is usually preferred over returning an inappropriate one (misunderstanding). The current system uses a five-stage off-topic selection algorithm which is an extension of that presented in Artstein et al. (2009). Figure 1 shows a sample dialogue illustrating the handling of nonunderstanding. 33 User Hello Pinchas, how are you? Las Vegas how are you Pinchas Can you just repeat that? User Hello Pinchas, can you hear me? how thick is can you hear me Pinchas I can hear you, yeah. User Pinchas, can you tell me how old you are? Vegas can you tell me how old you are Pinchas I was born in nineteen thi"
N16-3007,W06-1303,1,0.539718,"tion-response pairs, which identifies the most appropriate response to new (unseen) user input. The dialogue management logic is designed to deal with instances where the classifier cannot identify a good direct response. During training, NPCEditor calculates a response threshold based on the classifier’s confidence in the appropriateness of selected responses; at runtime, if the confidence for a selected response falls below the predetermined threshold, that response is replaced with an “off-topic” utterance that asks the user to repeat the question or takes initiative and changes the topic (Leuski et al., 2006); such failure to return a direct response, also called non-understanding (Bohus and Rudnicky, 2005), is usually preferred over returning an inappropriate one (misunderstanding). The current system uses a five-stage off-topic selection algorithm which is an extension of that presented in Artstein et al. (2009). Figure 1 shows a sample dialogue illustrating the handling of nonunderstanding. 33 User Hello Pinchas, how are you? Las Vegas how are you Pinchas Can you just repeat that? User Hello Pinchas, can you hear me? how thick is can you hear me Pinchas I can hear you, yeah. User Pinchas, can y"
N16-3007,W15-4629,1,0.824999,"ciation for Computational Linguistics 2 Technical details In the New Dimensions in Testimony prototype, users talk to a persistent representation of a Holocaust survivor presented on a video screen, and a computer algorithm selects and plays individual video clips of the survivor in response to user utterances. The result is much like an ordinary conversation between the user and the survivor. The system has been described in detail in previous publications, covering the proof of concept (Artstein et al., 2014), the content elicitation process (Artstein et al., 2015), the language processing (Traum et al., 2015a), the full prototype (Traum et al., 2015b), and ethical considerations (Artstein and Silver, 2016). Here we give a brief description of the language processing technology and the system’s runtime components. 2.1 Language processing At the heart of the runtime computer system is a response classifier and dialogue management component called NPCEditor (Leuski and Traum, 2011), which selects a response to each user utterance. NPCEditor combines the functions of Natural Language Understanding (NLU) and Dialogue Management – understanding the utterance text and selecting an appropriate response."
P08-2013,georgila-etal-2008-fully,1,0.87922,"(Czaja and Lee, 2007) that present challenges for user modelling. To our knowledge no one so far has built statistical user simulation models for older people. The only statistical spoken dialogue system for older people we are aware of is Nursebot, an early application of statistical methods (POMDPs) within the context of a medication reminder system (Roy et al., 2000). In this study, we build SUs for both younger and older adults using n-grams. Our data comes from a fully annotated corpus of 447 interactions of older and younger users with a Wizard-of-Oz (WoZ) appointment scheduling system (Georgila et al., 2008). We then evaluate these models using standard metrics (Schatzmann et al., 2005; Georgila et al., 2006) and compare our findings with the results of statistical corpus analysis. The novelty of our work lies in two areas. First, to the best of our knowledge this is the first time that statistical SUs have been built for the increasingly important population of older users. Secondly, a general (but as yet untested) assumption in this field is that current SUs are “enough like” real users for training good policies, and that testing system performance in simulated dialogues is an accurate indicat"
P08-2013,2005.sigdial-1.6,1,0.939881,"good predictor of the behaviour of different types of users, which provides evidence for the validity of current user simulation evaluation metrics. 1 Introduction Using machine learning to induce dialogue management policies requires large amounts of training data, and thus it is typically not feasible to build such models solely with data from real users. Instead, data from real users is used to build simulated users (SUs), who then interact with the system as often as needed. In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Schatzmann et al., 2005; Georgila et al., 2006). Furthermore, SUs are critical for evaluating candidate dialogue policies. To date, several techniques for building SUs have been investigated and metrics for evaluating their quality have been proposed (Schatzmann et al., 2005; Georgila et al., 2006). However, to our knowledge, no one has tried to build user simulations for different populations of real users and measure whether results from evaluating the quality of those simulations agree with what is known about those particular types of real users, extracted from other studies of those populations. This is presuma"
P14-1047,P08-1071,0,0.0302999,"hen the dialogue policy can be learned by having the system interact with the SU for a large number of dialogues (usually thousands of dialogues). Depending on the application, building a realistic SU can be just as difficult as building a good dialogue policy. Furthermore, it is not clear what constitutes a good SU for dialogue policy learning. Should the SU resemble real user behavior as closely as possible, or should it exhibit some degree of randomness to explore a variety of interaction patterns? Despite much research on the issue, these are still open questions (Schatzmann et al., 2006; Ai and Litman, 2008; Pietquin and Hastie, 2013). In the second approach, no SUs are required. Instead the dialogue policy is learned directly from a corpus of human-human or human-machine dialogues. For example, Henderson et al. (2008) used a combination of RL and supervised learning to learn a dialogue policy in a flight reservation domain, whereas Li et al. (2009) used Least-Squares Policy Iteration (Lagoudakis and Parr, 2003), an RL-based technique that can learn directly from corpora, in a voice dialer application. However, collecting such corpora is not trivial, especially in new domains. Typically, data ar"
P14-1047,W10-4321,1,0.707826,"Missing"
P14-1047,W13-4016,1,0.924299,"rk Most research in RL for dialogue management has been done in the framework of slot-filling applications such as restaurant recommendations (Lemon et al., 2006; Thomson and Young, 2010; Gaˇsi´c et al., 2012; Daubigney et al., 2012), flight reservations (Henderson et al., 2008), sightseeing recommendations (Misu et al., 2010), appointment scheduling (Georgila et al., 2010), etc. RL has also been applied to question-answering (Misu et al., 2012), tutoring domains (Tetreault and Litman, 2008; Chi et al., 2011), and learning negotiation dialogue policies (Heeman, 2009; Georgila and Traum, 2011; Georgila, 2013). As mentioned in section 1, there are three main approaches to the problem of learning dialogue policies using RL. In the first approach, a SU is hand-crafted or learned from a small corpus of human-human or human-machine dialogues. Then the dialogue policy can be learned by having the system interact with the SU for a large number of dialogues (usually thousands of dialogues). Depending on the application, building a realistic SU can be just as difficult as building a good dialogue policy. Furthermore, it is not clear what constitutes a good SU for dialogue policy learning. Should the SU res"
P14-1047,J08-4002,1,0.320034,"cies in complex dialogue scenarios. This ability of multi-agent RL can also have important implications for learning via live interaction with human users. Imagine a system that learns to change its strategy as it realizes that a particular user is no longer a novice user, or that a user no longer cares about five star restaurants. Related Work Most research in RL for dialogue management has been done in the framework of slot-filling applications such as restaurant recommendations (Lemon et al., 2006; Thomson and Young, 2010; Gaˇsi´c et al., 2012; Daubigney et al., 2012), flight reservations (Henderson et al., 2008), sightseeing recommendations (Misu et al., 2010), appointment scheduling (Georgila et al., 2010), etc. RL has also been applied to question-answering (Misu et al., 2012), tutoring domains (Tetreault and Litman, 2008; Chi et al., 2011), and learning negotiation dialogue policies (Heeman, 2009; Georgila and Traum, 2011; Georgila, 2013). As mentioned in section 1, there are three main approaches to the problem of learning dialogue policies using RL. In the first approach, a SU is hand-crafted or learned from a small corpus of human-human or human-machine dialogues. Then the dialogue policy can b"
P14-1047,H05-1127,0,0.532687,"dialogue policies (not just choices at specific points in the dialogue) via live interaction with human users has become possible with the use of Gaussian processes (Engel et al., 2005; Rasmussen and Williams, 2006). Typically learning a dialogue policy is a slow process requiring thousands of dialogues, hence the need for SUs. Gaussian processes have been shown to speed up learning. This fact together with easy access to a large number of human users through crowd-sourcing has allowed dialogue policy learning via live interaction with human users (Gaˇsi´c et al., 2011; Gaˇsi´c et al., 2013). English and Heeman (2005) were the first in the dialogue community to explore the idea of concurrent learning of dialogue policies. However, English and Heeman (2005) did not use multiagent RL but only standard single-agent RL, in particular an on-policy Monte Carlo method (Sutton and Barto, 1998). But single-agent RL techniques are not well suited for concurrent learning where each agent is trained against a continuously changing environment. Indeed, English and Heeman (2005) reported problems with convergence. Chandramohan et al. (2012) proposed a framework for co-adaptation of the dialogue policy and the SU using s"
P14-1047,N13-2013,0,0.0113492,"ts prevent us from providing an exhaustive list of previous work on using RL for dialogue management. Thus below we focus only on research that is directly related to our work, specifically research on concurrent learning of the policies of multiple agents, and the application of RL to negotiation domains. So far research on RL in the dialogue community has focused on using single-agent RL techniques where the stationary environment is the user. Most approaches assume that the user goal is fixed and that the behavior of the user is rational. Other approaches account for changes in user goals (Ma, 2013). In either case, one can build a user simulation model that is the average of different user behaviors or learn a policy from a corpus that contains a variety of interaction patterns, and thus safely assume that single-agent RL techniques will work. However, in the latter case if the behavior of the user changes significantly over time then the assumption that the environment is stationary will no longer hold. With regard to using RL for learning negotiation policies, the amount of research that has been performed is very limited compared to slot-filling. English and Heeman (2005) learned neg"
P14-1047,W10-4339,0,0.151152,"lti-agent RL can also have important implications for learning via live interaction with human users. Imagine a system that learns to change its strategy as it realizes that a particular user is no longer a novice user, or that a user no longer cares about five star restaurants. Related Work Most research in RL for dialogue management has been done in the framework of slot-filling applications such as restaurant recommendations (Lemon et al., 2006; Thomson and Young, 2010; Gaˇsi´c et al., 2012; Daubigney et al., 2012), flight reservations (Henderson et al., 2008), sightseeing recommendations (Misu et al., 2010), appointment scheduling (Georgila et al., 2010), etc. RL has also been applied to question-answering (Misu et al., 2012), tutoring domains (Tetreault and Litman, 2008; Chi et al., 2011), and learning negotiation dialogue policies (Heeman, 2009; Georgila and Traum, 2011; Georgila, 2013). As mentioned in section 1, there are three main approaches to the problem of learning dialogue policies using RL. In the first approach, a SU is hand-crafted or learned from a small corpus of human-human or human-machine dialogues. Then the dialogue policy can be learned by having the system interact with the"
P14-1047,W12-1611,1,0.525806,"at learns to change its strategy as it realizes that a particular user is no longer a novice user, or that a user no longer cares about five star restaurants. Related Work Most research in RL for dialogue management has been done in the framework of slot-filling applications such as restaurant recommendations (Lemon et al., 2006; Thomson and Young, 2010; Gaˇsi´c et al., 2012; Daubigney et al., 2012), flight reservations (Henderson et al., 2008), sightseeing recommendations (Misu et al., 2010), appointment scheduling (Georgila et al., 2010), etc. RL has also been applied to question-answering (Misu et al., 2012), tutoring domains (Tetreault and Litman, 2008; Chi et al., 2011), and learning negotiation dialogue policies (Heeman, 2009; Georgila and Traum, 2011; Georgila, 2013). As mentioned in section 1, there are three main approaches to the problem of learning dialogue policies using RL. In the first approach, a SU is hand-crafted or learned from a small corpus of human-human or human-machine dialogues. Then the dialogue policy can be learned by having the system interact with the SU for a large number of dialogues (usually thousands of dialogues). Depending on the application, building a realistic S"
P14-1047,W11-2813,0,\N,Missing
W09-3901,P04-1009,0,0.60479,"is important for several reasons: (1) to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (Polifroni et al., 2003; Chung, 2004; Demberg and Moore, 2006; Polifroni and Walker, 2008). Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an “overhearer” methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts Introduction Spoken dialogue systems (SDS) that help users find a desired option (e.g., flight, restaurant, movie) from the set of options satisfying their constraints typically present options sequentially, ordered along a default dimension (e.g., by price or departure time). An example i"
W09-3901,E06-1009,1,0.722326,"porary dining area, with simple floral displays and leather seating. It serves Indian cuisine. It is located in the city centre. The average price is £24 per person. Recent work on information presentation in dialogue systems combines user modelling (UM) and stepwise refinement through clustering and summarisation (SR) in the UMSR approach. An evaluation in which participants rated dialogue transcripts showed that UMSR presents complex trade-offs understandably, provides users with a good overview of their options, and increases users’ confidence that all relevant options have been presented (Demberg and Moore, 2006). In this paper, we evaluate the effectiveness of the UMSR approach in a more realistic setting, by incorporating this information presentation technique into a full endto-end dialogue system in the city information domain, and comparing it with the traditional approach of presenting information sequentially. Our results suggest that despite complications associated with a real dialogue system setting, the UMSR model retains its advantages. 1 Number 2: Saffrani’s decor is modern, the dining room wee, though the menu is enormous, and the atmosphere charming. It offers new Indian dishes never be"
W09-3901,J08-4002,1,0.918965,"formation about price range. M: Okay tell me about the ones in Boston. S: I have found 401 restaurants in Boston. There are 29 choices for cuisine. M: Do you have any that serve seafood? S: I have found 19 seafood restaurants. They are predominantly in Back Bay, the North End, South Boston and the South End. 3 The TownInfo System The TownInfo SDS was developed as part of the EC project TALK (Lemon et al., 2006). Users can search for hotels, bars and restaurants in an artificial town. The system supports two dialogue strategies, one hand-crafted and another learnt using Reinforcement Learning (Henderson et al., 2008). For the current experiment we used the hand-crafted strategy. Natural language understanding is performed using a keyword-based parser and natural language generation is based on templates. The information presentation is sequential. An example is given in Fig. 1, taken from the modified version of TownInfo for the current experiment. Although the original TownInfo system supported speech input and speech output, here we use text input/output to make sure that our results are not influenced by poor recognition accuracy or intelligibility due to poor speech synthesis. Of course, as we mention"
W09-3901,E06-2009,1,0.920615,"tion sequentially. Our results suggest that despite complications associated with a real dialogue system setting, the UMSR model retains its advantages. 1 Number 2: Saffrani’s decor is modern, the dining room wee, though the menu is enormous, and the atmosphere charming. It offers new Indian dishes never before seen in Edinburgh. It serves Indian, seafood cuisine. It is located in the city centre. The average price is £28 per person. Number 3: Britannia Spice . . . Figure 1: Example of sequential information presentation in the city information domain (modified version of the TownInfo system (Lemon et al., 2006)). and reduced user satisfaction. Thus a major challenge in the development of SDS is to improve information presentation algorithms. This is important for several reasons: (1) to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. R"
W09-3901,P08-1055,0,0.0728398,"to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (Polifroni et al., 2003; Chung, 2004; Demberg and Moore, 2006; Polifroni and Walker, 2008). Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an “overhearer” methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts Introduction Spoken dialogue systems (SDS) that help users find a desired option (e.g., flight, restaurant, movie) from the set of options satisfying their constraints typically present options sequentially, ordered along a default dimension (e.g., by price or departure time). An example is shown in Fig. 1. The user can then navigate through"
W09-3901,P01-1066,0,0.215684,"ntation in the city information domain (modified version of the TownInfo system (Lemon et al., 2006)). and reduced user satisfaction. Thus a major challenge in the development of SDS is to improve information presentation algorithms. This is important for several reasons: (1) to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (Polifroni et al., 2003; Chung, 2004; Demberg and Moore, 2006; Polifroni and Walker, 2008). Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an “overhearer” methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts Introduction Spoken dialogue systems (SDS) that help users f"
W10-4321,E09-1078,0,0.068512,"Missing"
W10-4321,W09-3916,0,\N,Missing
W10-4321,P06-1024,0,\N,Missing
W10-4321,P09-2005,0,\N,Missing
W10-4321,P08-2013,1,\N,Missing
W10-4343,N09-2028,1,0.948212,"s speak, may provide valuable information about the speaker’s cognitive state, and can be critical for successful turn-taking (Shriberg, 2005). Speech disfluencies have been the subject of much research in the field of spoken language processing, e.g. (Ginzburg et al., 2007). Speech disfluencies can be divided into three intervals, the reparandum, the editing term, and the correction (Heeman and Allen, 1999; Liu et al., 2006). In the example below, “it left” is the reparandum (the part that will be repaired), “I mean” is the editing term, and “it came” is the correction: In our previous work (Georgila, 2009), we proposed a novel two-stage technique for speech disfluency detection based on Integer Linear Programming (ILP). ILP has been applied successfully to several NLP problems, e.g. (Clarke and Lapata, 2008). In the first stage of our method, we trained state-of-the-art classifiers for speech disfluency detection, in particular, HiddenEvent Language Models (HELMs) (Stolcke and Shriberg, 1996), Maximum Entropy (ME) models (Ratnaparkhi, 1998), and Conditional Random Fields (CRFs) (Lafferty et al., 2001). Then in the second stage and during testing, each classifier proposed possible labels which w"
W10-4343,J99-4003,0,0.0576025,"ge processing (NLP) since most NLP tools (e.g. parsers and part-of-speech taggers) are traditionally trained on written language. However, speech disfluencies are not noise. They are an integral part of how humans speak, may provide valuable information about the speaker’s cognitive state, and can be critical for successful turn-taking (Shriberg, 2005). Speech disfluencies have been the subject of much research in the field of spoken language processing, e.g. (Ginzburg et al., 2007). Speech disfluencies can be divided into three intervals, the reparandum, the editing term, and the correction (Heeman and Allen, 1999; Liu et al., 2006). In the example below, “it left” is the reparandum (the part that will be repaired), “I mean” is the editing term, and “it came” is the correction: In our previous work (Georgila, 2009), we proposed a novel two-stage technique for speech disfluency detection based on Integer Linear Programming (ILP). ILP has been applied successfully to several NLP problems, e.g. (Clarke and Lapata, 2008). In the first stage of our method, we trained state-of-the-art classifiers for speech disfluency detection, in particular, HiddenEvent Language Models (HELMs) (Stolcke and Shriberg, 1996),"
W10-4343,W00-1308,0,0.0146514,", IP, IE and O respectively. Given the above definitions, the ILP problem formulation can be as follows: PN max[ i=1 [PBE (i)CBE (i) + PBE−IP (i)CBE−IP (i) +PIP (i)CIP (i) + PIE (i)CIE (i) + PO (i)CO (i)]] (1) subject to constraints, e.g.: CBE (i) + CBE−IP (i) + CIP (i) + CIE (i) +CO (i) = 1 ∀i ∈ (1, ..., N ) 4 Experiments For building the CRF model we use the CRF++ toolkit (available from sourceforge). We used only lexical features, i.e. words and part-ofspeech (POS) tags. Switchboard includes POS information but to annotate the Rapport corpus with POS labels we used the Stanford POS tagger (Toutanova and Manning, 2000). We experimented with different sets of features and we achieved the best results with the following setup (i is the location of the word or POS in the sentence): Our word features are hwi i, hwi+1 i, hwi−1 , wi i, hwi , wi+1 i, hwi−2 , wi−1 , wi i, hwi , wi+1 , wi+2 i. Our POS features have the same structure as the word features. For ILP we use the lp solve software also available from sourceforge. We train on Switchboard and test on the Rapport corpus. For evaluating the performance of our models we use standard metrics proposed in the literature, i.e. Precision, Recall, F-score, and NIST"
W11-2030,bunt-2006-dimensions,0,0.0317849,"r arguments that appeal to emotions. On the other hand, people from Eastern collectivistic cultures are more likely to use arguments in which the beneficiary is not themselves. Furthermore, Arab cultures tend to favor more indirect ways of argumentation and expression (Koch, 1983; Zaharna, 1995). ∗ Now at the University of Texas at San Antonio. In order to analyze negotiation in detail, including aspects such as persuasion, negotiation, and crosscultural differences, we have developed a novel annotation scheme. General purpose annotation schemes such as DAMSL (Core and Allen, 1997) and DIT++ (Bunt, 2006) represent moves in the dialogue but do not capture enough details of the interaction to distinguish between different styles of persuasion and argumentation, especially cross-cultural differences. Our goal for developing this coding scheme is two-fold. First, we aim to fill the gap in the literature of cross-cultural argumentation and persuasion. To our knowledge this is the first annotation scheme designed specifically for coding cross-cultural argumentation and persuasion strategies. Previous work on cross-cultural negotiation, e.g. Brett and Gelfand (2006), has not focused on argumentation"
W11-2030,J87-1002,0,0.173196,"science (Sidner, 1994; Ros´e and Torrey, 2004). Our specific focus is on the role of argumentation and per272 Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 272–278, c Portland, Oregon, June 17-18, 2011. 2011 Association for Computational Linguistics suasion. Sycara (1990) studied the role of argumentation in negotiation with regard to the role of arguments in changing the decision process of the interlocutor. Most attempts have focused on studying the structure of argumentation and persuasion, often using formal logic (Cohen, 1987; Prakken, 2008). Dung (1995) showed that argumentation can be viewed as a special form of logic programming with negation as failure. An argumentation scheme is defined as a structure or template for forming an argument. Schemes are necessary for identifying arguments, finding missing premises, analyzing arguments, and evaluating arguments (Pollock, 1995; Katzav and Reed, 2004; Walton et al., 2008). Recently, there has been some work on using machine learning techniques for automatically interpreting (George et al., 2007) and generating arguments (Zukerman, 2001). Note also the work of Piwek"
W12-1611,aggarwal-etal-2012-twins,1,0.77528,"e though) and do not have the objective of reducing the search space and retrieving results from a database of e.g. restaurants, flights, etc. Thus examples of question-answering 84 Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 84–93, c Seoul, South Korea, 5-6 July 2012. 2012 Association for Computational Linguistics characters can be virtual interviewees (that can answer questions, e.g. about an incident), virtual scientists (that can answer general science-related questions), and so forth. For our experiments we use a corpus (Aggarwal et al., 2012) of interactions of real users with two virtual characters, the Twins, that serve as guides at the Museum of Science in Boston (Swartout et al., 2010). The role of these virtual characters is to entertain and educate the museum visitors. They can answer queries about themselves and their technology, generally about science, as well as questions related to the exhibits of the museum. An example interaction between a museum visitor and the Twins is shown in Figure 1. The dialogue policy of the Twins was arbitrarily hand-crafted (see section 7 for details) and many other policies are possible (in"
W12-1611,P08-1071,0,0.194347,"Creative Technologies, Playa Vista, CA, USA teruhisa.misu@nict.go.jp, {kgeorgila,leuski,traum}@ict.usc.edu Abstract of thousands of dialogues to achieve good performance. Because it is very difficult to collect such a large number of dialogues with real users, instead, simulated users (SUs), i.e. models that simulate the behavior of real users, are employed (Georgila et al., 2006). Through the interaction between the system and the SUs thousands of dialogues can be generated and used for learning. A good SU should be able to replicate the behavior of a real user in the same dialogue context (Ai and Litman, 2008). We use Reinforcement Learning (RL) to learn question-answering dialogue policies for a real-world application. We analyze a corpus of interactions of museum visitors with two virtual characters that serve as guides at the Museum of Science in Boston, in order to build a realistic model of user behavior when interacting with these characters. A simulated user is built based on this model and used for learning the dialogue policy of the virtual characters using RL. Our learned policy outperforms two baselines (including the original dialogue policy that was used for collecting the corpus) in a"
W12-1611,W10-4321,1,0.687146,"Missing"
W12-1611,W06-1303,1,0.673927,"capabilities, e.g. (J¨onsson et al., 2004; op den Akker et al., 2005; Varges et al., 2009). Most of these systems are designed for information extraction from structured or unstructured databases in closed or open domains. One could think of them as adding dialogue capabilities to standard question-answering systems such as the ones used in the TREC question-answering track (Voorhees, 2001). Other work has focused on a different type of question-answering dialogue, i.e. question-answering dialogues that follow the form of an interview and that can be used, for example, for training purposes (Leuski et al., 2006; Gandhe et al., 2009). But none of these systems uses RL. To our knowledge no one has used RL for learning policies for question-answering systems as defined in section 1. Note that Rieser and Lemon (2009) used RL for question-answering, but in their case, question-answering refers to asking for information about songs and artists in an mp3 database, which is very much like a slot-filling task, i.e. the system has to fill a number of slots (e.g. name of band, etc.) in order to query a database of songs and present the right information to the user. As discussed in section 1 our task is rather"
W12-1611,W10-4339,1,0.405154,"Dialogue Challenge. tion 2 we present related work. Section 3 provides a brief introduction to RL and section 4 describes our corpus. Then in section 5 we explain how we built our SU from the corpus, and in section 6 we describe our learning methodology. Section 7 presents our evaluation results. Finally section 8 presents some discussion and ideas for future work together with our conclusion. 2 Related Work To date, RL has mainly been used for learning dialogue policies for slot-filling applications such as restaurant recommendations (Jurˇc´ıcˇ ek et al., 2012), sightseeing recommendations (Misu et al., 2010), appointment scheduling (Georgila et al., 2010), etc., largely ignoring other types of dialogue. Recently there have been some experiments on applying RL to the more difficult problem of learning negotiation policies (Heeman, 2009; Georgila and Traum, 2011a; Georgila and Traum, 2011b). Also, RL has been applied to tutoring domains (Tetreault and Litman, 2008; Chi et al., 2011). There has been a lot of work on developing question-answering systems with dialogue capabilities, e.g. (J¨onsson et al., 2004; op den Akker et al., 2005; Varges et al., 2009). Most of these systems are designed for inf"
W13-4016,W10-4322,0,0.0167226,"des on what dialogue move (also called action) the system should make given the dialogue context (also called dialogue state). Building hand-crafted policies is a hard task, and there is no guarantee that the resulting policies will be optimal. This issue has motivated the dialogue community to use statistical methods for automatically learning dialogue policies, the most popular of which is Reinforcement Learning (RL) (Szepesv´ari, 2010). To date, RL has been used mainly for learning dialogue policies for slot-filling applications such as restaurant recommendations (Williams and Young, 2007; Chandramohan et al., 2010; Jurˇc´ıcˇ ek et al., 2012; Gaˇsi´c et al., 2012), flight 112 Proceedings of the SIGDIAL 2013 Conference, pages 112–116, c Metz, France, 22-24 August 2013. 2013 Association for Computational Linguistics 2 Reinforcement Learning Food type Thai Italian Mexican Day of the week Friday Saturday Sunday Reinforcement Learning (RL) is a machine learning technique used to learn the policy of an agent (Szepesv´ari, 2010). RL is used in the framework of Markov Decision Processes (MDPs) (Szepesv´ari, 2010) or Partially Observable Markov Decision Processes (Williams and Young, 2007). In this paper we use"
W13-4016,W10-4339,0,0.249494,"Missing"
W13-4016,W12-1611,1,0.865372,"Missing"
W13-4016,W10-4321,1,0.62257,"Missing"
W13-4016,J08-4002,1,0.905257,"Missing"
W13-4016,W10-4324,0,0.0615,"Missing"
W13-4016,H05-1127,0,\N,Missing
W13-4016,C14-1161,0,\N,Missing
W13-4016,P14-1047,1,\N,Missing
W13-4016,W14-4308,0,\N,Missing
W13-4032,baccianella-etal-2010-sentiwordnet,0,0.0040804,"tuting a single turn. While this simple scheme does not provide a detailed treatment of relevant phenomena such as overlapping speech, backchannels, and the interactive process of negotiating the turn in dialogue (Yang and Heeman, 2010), it provides a conceptually simple model for the definition of features for aggregate statistical analysis. 4.2 Valence features for user speech Features (e)(g) are meant to explore the idea that distressed users might use more negative or less positive vocabulary than non-distressed subjects. As an exploratory approach to this topic, we used SentiWordNet 3.0 (Baccianella and Sebastiani, 2010), a lexical sentiment dictionary, to assign valence to individual words spoken by users in our study. The dictionary contains approximately 117,000 entries. In general, each word w may appear in multiple entries, corresponding to different parts of speech and word senses. To assign a single valence score v(w) to each word in the dictionary, in our features we compute the average score across all parts of speech and word senses: Context-independent feature analysis We begin by analyzing a set of shallow features which we describe as context-independent, as they apply to user speech segments ind"
W13-4032,D12-1004,0,0.0145618,"3–202, c Metz, France, 22-24 August 2013. 2013 Association for Computational Linguistics Heeman et al. (2010) observed differences in children with autism in how long they pause before speaking and in their use of fillers, acknowledgments, and discourse markers. Some of these features are similar to those studied here, but looked at children communicating with clinicians rather than a virtual human dialogue system. Recent work on machine classification has demonstrated the ability to discriminate between schizophrenic patients and healthy controls based on transcriptions of spoken narratives (Hong et al., 2012), and to predict patient adherence to medical treatment from word-level features of dialogue transcripts (Howes et al., 2012). Automatic speech recognition and word alignment has also been shown to give good results in scoring narrative recall tests for identification of cognitive impairment (Prud’hommeaux and Roark, 2011; Lehr et al., 2012). Figure 1: Ellie. communicative behavior of patients with specific psychological disorders such as depression. In this section, we briefly summarize some closely related work. Most work has observed the behavior of patients in human-human interactions, suc"
W13-4032,W12-1610,0,0.0311906,"rences in children with autism in how long they pause before speaking and in their use of fillers, acknowledgments, and discourse markers. Some of these features are similar to those studied here, but looked at children communicating with clinicians rather than a virtual human dialogue system. Recent work on machine classification has demonstrated the ability to discriminate between schizophrenic patients and healthy controls based on transcriptions of spoken narratives (Hong et al., 2012), and to predict patient adherence to medical treatment from word-level features of dialogue transcripts (Howes et al., 2012). Automatic speech recognition and word alignment has also been shown to give good results in scoring narrative recall tests for identification of cognitive impairment (Prud’hommeaux and Roark, 2011; Lehr et al., 2012). Figure 1: Ellie. communicative behavior of patients with specific psychological disorders such as depression. In this section, we briefly summarize some closely related work. Most work has observed the behavior of patients in human-human interactions, such as clinical interviews and doctor-patient interactions. PTSD is generally less well studied than depression. Examples of th"
W13-4032,J11-2001,0,0.0104219,"context-independent, as they apply to user speech segments independently of what the system has recently said. Most of these are features that apply to many or all user speech segments. We describe our context-independent features in Section 4.2.1, and present our results for these features in Section 4.2.2. 4.2.1 v(w) = P e∈E(w) PosScoree (w) |E(w)| − NegScoree (w) where E(w) is the set of entries for the word w, PosScoree (w) is the positive score for w in entry e, and NegScoree (w) is the negative score for w in entry e. This is similar to the “averaging across senses” method described in Taboada et al. (2011). We use several different measures of the valence of each speech segment with transcript t = hw1 , ..., wn i. We compute the min, mean, and max valence of each transcript: Context-independent features We summarize our context-independent features in Figure 2. Speaking rate and onset times Based on previous clinical observations related to slowed speech and increased onset time for depressed individuals (Section 2), we defined features for speaking rate and onset time of user speech segments. We quantify the speaking rate of a user speech segment hs, e, ti, where t = hw1 , ..., wN i, as N/(e −"
W13-4032,W10-4346,0,\N,Missing
W13-4032,wittenburg-etal-2006-elan,0,\N,Missing
W14-4334,baccianella-etal-2010-sentiwordnet,0,0.00639605,"understanding of user speech. SimSensei Kiosk currently uses 4 statistically trained utterance classifiers to capture different aspects of user utterance meaning. The first NLU classifier identifies generic dialogue act types, including statements, yes-no questions, wh-questions, yes and no answers, and several others. This classifier is trained using the Switchboard DAMSL corpus (Jurafsky et al., 1997) using a maximum entropy model. The second NLU classifier assigns positive, negative, or neutral valence to utterances, in order to guide Ellie’s expression of empathy. We use SentiWordNet 3.0 (Baccianella et al., 2010), a lexical sentiment dictionary, to assign valence to individual words spoken by users (as recognized by the ASR); the valence assigned to an utterance is based primarily on the mean valence scores of Opening Rapport Building Phase What are some things you really like about LA? (top level question) I love the weather, I love the palm trees, I love the beaches, there’s a lot to do here. Ellie Diagnostic Phase Have you noticed any changes in your behavior or thoughts lately? (top level question) User Yes. Ellie Can you tell me about that? (continuation prompt) User I’m having a lot more nightma"
W14-4334,W13-4032,1,0.849274,"ss conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD) (DeVault et al., 2014). SimSensei Kiosk has two main functions – a virtual human called Ellie (pictured in Figure 1), who converses with a user in a spoken, semi-structured interview, and a multimodal perception system which analyzes the user’s behavior in real time to identify indicators of psychological distress. The system has been designed and developed over two years using a series of face-toface, Wizard-of-Oz, and automated system studies involving more than 350 human participants (Scherer et al., 2013; DeVault et al., 2013; DeVault et al., 2014). Agent design has been guided by two overarching goals: (1) the agent should make 254 Proceedings of the SIGDIAL 2014 Conference, pages 254–256, c Philadelphia, U.S.A., 18-20 June 2014. 2014 Association for Computational Linguistics gine. The perception system analyzes audio and video in real time to identify features such as head position, gaze direction, smile intensity, and voice quality. DeVault et al. (2014) provides details on all the agent’s modules. 2 2.1 Ellie User Overview of Dialogue Processing ASR and NLU components Unlike many task-oriented dialogue domains"
W15-4605,W14-4308,0,0.0697525,"alists, collectivists, and altruists). The domain was negotiation between a florist and a grocer who had to agree on the temperature of a shared retail space. Georgila (2013) used RL to learn the dialog system policy in a two-issue negotiation domain where two participants (the user and the system) organize a party, and need to decide on both the day that the party will take place and the type of food that will be served. Also, Heeman (2009) modeled negotiation dialog for a furniture layout task, and Paruchuri et al. (2009) modeled negotiation dialog between a seller and buyer. More recently, Efstathiou and Lemon (2014) focused on non-cooperative aspects of trading dialog, and Georgila et al. (2014) used multi-agent RL to learn negotiation policies in a resource allocation scenario. Finally, Hiraoka et al. (2014) applied RL to the problem of learning cooperative persuasive policies using framing, and Nouri et al. (2012) learned models for cultural decision-making in a simple negotiation game (the Ultimatum Game). In contrast to typical 2 Reinforcement Learning Reinforcement learning (RL) is a machine learning technique for learning the policy of an agent 1 Note that there is some previous work on using RL to"
W15-4605,W10-4321,1,0.654188,"Missing"
W15-4605,P14-1047,1,0.927285,"Institute for Creative Technologies nouri@ict.usc.edu traum@ict.usc.edu Satoshi Nakamura Nara Institute of Science and Technology s-nakamura@is.naist.jp Abstract party. Trading dialogs can be considered as a kind of negotiation, in which participants use various tactics to try to reach an agreement. It is common to have dialogs that may involve multiple offers or even multiple trades. In this way, trading dialogs are different from other sorts of negotiation in which a single decision (possibly about multiple issues) is considered, for example partitioning a set of items (Nouri et al., 2013; Georgila et al., 2014). Another difference between trading dialogs and partitioning dialogs is what happens when a deal is not made. In partitioning dialogs, if an agreement is not reached, then participants get nothing, so there is a very strong incentive to reach a deal, which allows pressure and can result in a “chicken game”, where people give up value in order to avoid a total loss. By contrast, in trading dialogs, if no deal is made, participants stick with the status quo. Competitive two-party trading dialogs may result in a kind of stasis, where the wealthier party will pass up mutually beneficial deals, in"
W15-4605,W13-4016,1,0.842785,"mine a number of strategies for this game, including random, simple, and complex 32 Proceedings of the SIGDIAL 2015 Conference, pages 32–41, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics hand-crafted strategies, as well as several reinforcement learning (RL) (Sutton and Barto, 1998) algorithms, and examine performance with different numbers and kinds of opponents. slot-filling dialog systems, in these negotiation dialogs, the dialog system is rewarded based on the achievement of its own goals rather than those of its interlocutor. For example, in Georgila (2013), the dialog system gets a higher reward when its party plan is accepted by the other participant. Note that in all of the previous work mentioned above, the focus was on negotiation dialog between two participants only, ignoring cases where negotiation takes place between more than two interlocutors. However, in the real world, multiparty negotiation is quite common. In this paper, as a first study on multi-party negotiation, we apply RL to a multi-party trading scenario where the dialog system (learner) trades with one, two, or three other agents. We experiment with different RL algorithms a"
W15-4605,C14-1161,1,0.625159,"system policy in a two-issue negotiation domain where two participants (the user and the system) organize a party, and need to decide on both the day that the party will take place and the type of food that will be served. Also, Heeman (2009) modeled negotiation dialog for a furniture layout task, and Paruchuri et al. (2009) modeled negotiation dialog between a seller and buyer. More recently, Efstathiou and Lemon (2014) focused on non-cooperative aspects of trading dialog, and Georgila et al. (2014) used multi-agent RL to learn negotiation policies in a resource allocation scenario. Finally, Hiraoka et al. (2014) applied RL to the problem of learning cooperative persuasive policies using framing, and Nouri et al. (2012) learned models for cultural decision-making in a simple negotiation game (the Ultimatum Game). In contrast to typical 2 Reinforcement Learning Reinforcement learning (RL) is a machine learning technique for learning the policy of an agent 1 Note that there is some previous work on using RL to learn negotiation policies among more than two participants. For example, Mayya et al. (2011) and Zou et al. (2014) used multi-agent RL to learn the negotiation policies of sellers and buyers in a"
W15-4605,W11-2001,0,\N,Missing
W15-4613,georgila-etal-2012-practical,1,0.860385,"s. The evocative intention of an utterance is the behavior of the addressee that a speaker intends to evoke (Allwood, 1976; Allwood, 1995). In the case of the guessing game, a clue is given to evoke the expression of a target word. We ascertain a voice’s evocative function potential (EVP) by calculating the ratio of targets that a clue evokes from listeners. Each participant listens to many consecutive clues uttered with the same voice (extended continuous exposure). Our participants are recruited using the Amazon Mechanical Turk (AMT) service2 in the same fashion as in (Wolters et al., 2010; Georgila et al., 2012). To the best of our knowledge, our work is the first to systematically attempt to validate or disprove the hypotheses mentioned above, and compare the results of human transcriptions to ASR results in order to determine whether or not the latter can be used as an automatic intelligibility test for TTS system evaluations. This is also a first important step towards 2 speech synthesis evaluation in a full dialogue context. Finally, this is the first time that a systematic evaluation is conducted on a voice’s EVP. The rest of the paper is organized as follows. First, we discuss previous work in"
W15-4613,paetzel-etal-2014-multimodal,0,0.0291574,"under specific conditions” “a blank to talk too much” Example Usage “taxi” Word Relation “a mixture containing two or more blank elements or blank and nonblank elements Definition usually fused together or dissolving into each other when molten” “elephants may look alike to you and me, but the shapes of their blank flaps and their Example Usage tusks set them apart” “um not video but” Word Relation Target Word WordNet Bomb Dictionary.com Human Tendency Cab WordNet Metal Dictionary.com Ear Human Audio corpus which contains audio and video recordings of human pairs playing a word guessing game (Paetzel et al., 2014). We only used clues that were able to elicit at least one correct guess in a previous study designed to measure clue effectiveness (Pincus et al., 2014). Some example clues used in this experiment, their source, their type, and the target word they intend to evoke can be found in Table 1. Each of the 54 clues was synthesized in each of the voices. We categorized the 54 clues into 3 main clue types: a definition type which provided a definition of the target word, an example usage type which is generally a commonly used sentence that contains the word, and a word relation type which refers to"
W15-4621,W14-4308,0,0.0489368,"Missing"
W15-4621,H05-1127,0,0.0338819,"Schatzmann and Young, 2009) in information providing tasks. Introduction Negotiation is a process in which two or more parties participate in order to reach a joint decision. Negotiators have goals and preferences, and follow a negotiation policy or strategy to accomplish their goals. There has been a lot of work on building automated agents for negotiation in the communities of autonomous agents and game theory. Lin and Kraus (2010) present a quite comprehensive survey on automated agents designed to negotiate with humans. Below we focus only on research that is directly related to our work. English and Heeman (2005) and Heeman (2009) applied reinforcement learning (RL) to a furniture layout negotiation task. Georgila and Traum (2011) learned argumentation policies against users of different cultural norms in a oneissue negotiation scenario. Then Georgila (2013) Both the agenda-based and the RL policies are designed to work for a variety of goals, preferences, and negotiation moves, even under conditions that are very different from the conditions that the agents have experienced before. We vary the goals of the agents, how easy it is for the agents to be persuaded, whether they have enough arguments to a"
W15-4621,P14-1047,1,0.899685,"ssue Negotiation Dialogue Policies Alexandros Papangelis Human-Computer Interaction Institute Carnegie Mellon University Pittsburgh, PA 15213, USA apapa@cs.cmu.edu Abstract learned argumentation policies in a two-issue negotiation scenario. These policies were trained for some initial conditions, and they could perform well only when they were tested under similar conditions. More recently, Efstathiou and Lemon (2014) learned negotiation behaviors for a noncooperative trading game (the Settlers of Catan). Again, in Efstathiou and Lemon (2014)’s work, the initial settings were always the same. Georgila et al. (2014) used multi-agent RL to learn negotiation policies in a resource allocation scenario. They compared single-agent RL vs. multi-agent RL and they did not deal with argumentation, nor did they allow for a variety of initial conditions. Finally, Hiraoka et al. (2014) applied RL to the problem of learning cooperative persuasive policies using framing. Due to the complexity of negotiation tasks, none of the above works dealt with speech recognition or understanding errors. We use reinforcement learning (RL) to learn a multi-issue negotiation dialogue policy. For training and evaluation, we build a h"
W15-4621,W13-4016,1,0.701705,"o accomplish their goals. There has been a lot of work on building automated agents for negotiation in the communities of autonomous agents and game theory. Lin and Kraus (2010) present a quite comprehensive survey on automated agents designed to negotiate with humans. Below we focus only on research that is directly related to our work. English and Heeman (2005) and Heeman (2009) applied reinforcement learning (RL) to a furniture layout negotiation task. Georgila and Traum (2011) learned argumentation policies against users of different cultural norms in a oneissue negotiation scenario. Then Georgila (2013) Both the agenda-based and the RL policies are designed to work for a variety of goals, preferences, and negotiation moves, even under conditions that are very different from the conditions that the agents have experienced before. We vary the goals of the agents, how easy it is for the agents to be persuaded, whether they have enough arguments to accomplish their goals (i.e., shift their partners’ preferences), and the importance of each issue for each agent. We evaluate our two models by having them negotiate against each other under various settings. We also ask human raters to rate 154 Proc"
W15-4621,C14-1161,0,0.0113624,"ined for some initial conditions, and they could perform well only when they were tested under similar conditions. More recently, Efstathiou and Lemon (2014) learned negotiation behaviors for a noncooperative trading game (the Settlers of Catan). Again, in Efstathiou and Lemon (2014)’s work, the initial settings were always the same. Georgila et al. (2014) used multi-agent RL to learn negotiation policies in a resource allocation scenario. They compared single-agent RL vs. multi-agent RL and they did not deal with argumentation, nor did they allow for a variety of initial conditions. Finally, Hiraoka et al. (2014) applied RL to the problem of learning cooperative persuasive policies using framing. Due to the complexity of negotiation tasks, none of the above works dealt with speech recognition or understanding errors. We use reinforcement learning (RL) to learn a multi-issue negotiation dialogue policy. For training and evaluation, we build a hand-crafted agenda-based policy, which serves as the negotiation partner of the RL policy. Both the agendabased and the RL policies are designed to work for a large variety of negotiation settings, and perform well against negotiation partners whose behavior has"
W15-4629,W11-2037,1,0.936015,"Missing"
W15-4629,2005.sigdial-1.14,0,0.146605,"sed on the classifier’s confidence in the appropriateness of selected responses: this threshold finds an optimal balance between false positives (inappropriate responses above threshold) and false negatives (appropriate responses below threshold) in the training data. At runtime, if the confidence for a selected response falls below the predetermined threshold, that response is replaced with an “off-topic” utterance that asks the user to repeat the question or takes initiative and changes the topic (Leuski et al., 2006); such failure to return a direct response, also called non-understanding (Bohus and Rudnicky, 2005), is usually preferred over returning an inappropriate one (misunderstanding). is also above the threshold, Pinchas will respond with the lower ranked response. If the only responses above threshold are among the recently used then Pinchas will choose one of them, since repetition is considered preferable to responding with an off-topic or inappropriate statement. 3.5 Data collection The development process consisted of several stages: preliminary planning and question gathering, initial recording of survivor statements, Wizard of Oz studies using the recorded statements to identify gaps in th"
W15-4629,W06-1303,1,\N,Missing
W15-4629,W10-4345,1,\N,Missing
W17-5539,W13-4042,0,0.122753,"ntroduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increase task success (Kim et al., 2014; Khouzaimi et al., 2015; Dethlefs et al., 2016)."
W17-5539,W10-4342,0,0.101449,"and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increase task success (Kim et al., 2014; Khouzaimi et al., 2015; Dethlefs et al., 2016). We apply RL to the problem of incremental dialogue policy learning in the context of a fast-paced dialogue game. We use a corpus of real user data for both training and testing. We compare the policies learned by RL with a high"
W17-5539,D12-1008,0,0.240948,"sights which can inform the creation of an even better rule-based policy. 1 Introduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increa"
W17-5539,W12-1509,0,0.0202967,"sights which can inform the creation of an even better rule-based policy. 1 Introduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increa"
W17-5539,W15-4643,0,0.399484,"Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increase task success (Kim et al., 2014; Khouzaimi et al., 2015; Dethlefs et al., 2016). We apply RL to the problem of incremental dialogue policy learning in the context of a fast-paced dialogue game. We use a corpus of real user data for both training and testing. We compare the policies learned by RL with a high performance baseline policy which uses parameterized rules (whose parameters have been optimized using real user data) and has a carefully designed rule (CDR) structure. From now on, we will refer to this baseline as the CDR baseline. Our contributions are as follows: We provide an RL method for incremental dialogue processing based on simplist"
W17-5539,W16-3632,1,0.862238,"rementality. We can observe that the game conversation involves rapid exchanges with frequent overlaps. Each episode (dialogue exchange for each TI) typically begins with the Director describing the TI and ends with the Matcher acknowledging the TI selection with the AssertIdentified (As-I) DA (e.g., “got it”) or As-S (skipping action) DA (e.g., “let’s move on to the next image”). The Director then requests the next TI and the game continues until time runs out. Sometimes the Matcher may interrupt the Director with questions or other illocutionary acts. A complete list of DAs can be found in (Manuvinakurike et al., 2016). In this paper, we are interested in modeling incrementality for DAs related to TI selection by the Matcher. As-I is the most common DA used by the human Matchers. As-S was not frequently used by the human Matchers but is used by the baseline matcher agent to give up on the current TI and proceed to the next TI to try to increase the total points scored. Further distinctions between As-I and As-S are made in Section 2.2. The most common DA generated by the Director was D-T (Describe-Target). 2.2 Eve The baseline agent called Eve (Paetzel et al., 2015) was developed to play the role of the Mat"
W17-5539,W15-4610,1,0.620383,"tal spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increase task success (Kim et al., 2014; Khouzaimi et al., 2015; Dethlefs et al., 2016). We apply RL to the prob"
W17-5539,W09-3905,0,0.0855335,"better, and show that understanding the RL policy can provide valuable insights which can inform the creation of an even better rule-based policy. 1 Introduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate"
W17-5539,W13-4063,0,0.115054,"Missing"
W17-5539,P10-1019,0,0.0227831,"nderstanding the RL policy can provide valuable insights which can inform the creation of an even better rule-based policy. 1 Introduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to im"
W17-5539,W12-1638,0,0.0184441,"e creation of an even better rule-based policy. 1 Introduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in), stay silent, or generate backchannels in order to improve the responsiveness of the SDS or increase task success (Kim et al."
W17-5539,E09-1085,0,0.0391003,"where the RL policy performs better, and show that understanding the RL policy can provide valuable insights which can inform the creation of an even better rule-based policy. 1 Introduction Building incremental spoken dialogue systems (SDSs) has recently attracted much attention. One reason for this is that incremental dialogue processing allows for increased responsiveness, which in turn improves task efficiency and user satisfaction. Incrementality in dialogue has been studied in the context of turn-taking, predicting the next user utterances/actions, and generating fast system responses (Skantze and Schlangen, 2009; Schlangen et al., 2009; Selfridge and Heeman, 2010; DeVault et al., 2011; Dethlefs et al., 2012a,b; Selfridge et al., 2012, 2013; Hastie et al., 2013; Baumann and Schlangen, 2013; Paetzel et al., 2015). Over the years researchers have tried a variety of approaches to incremental dialogue processing. One such approach is using rules whose parameters may be optimized using real user data (Buß et al., 2010; Ghigi et al., 2014; Paetzel et al., 2015). Reinforcement Learning (RL) is another method that has been used to learn policies regarding when the system should interrupt the user (barge-in),"
W17-5539,W13-4026,0,\N,Missing
W17-5539,paetzel-etal-2014-multimodal,1,\N,Missing
W18-4701,E09-1022,0,0.0174719,"lso involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Fin"
W18-4701,N16-1147,0,0.0178558,"nvolving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 201"
W18-4701,P10-1128,0,0.0270435,"rlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) re"
W18-4701,P02-1048,0,0.161474,"is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) recently introduced a corpus containing one-shot image editing instructions. 3 Data The task of image editing"
W18-4701,D14-1086,0,0.0765644,"ersation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has"
W18-4701,P15-1029,0,0.0167866,"the role of a future dialogue system). We introduce a novel annotation scheme for this task, and discuss challenging sub-tasks in this domain. Conversational image editing combines spoken language, dialogue, and computer vision, and our real-world domain extends the literature on domains that are at the intersection of language and computer vision. We will publicly release our corpus in the near future. 2 Related Work Conversation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whe"
W18-4701,W16-3630,0,0.0131278,"m). We introduce a novel annotation scheme for this task, and discuss challenging sub-tasks in this domain. Conversational image editing combines spoken language, dialogue, and computer vision, and our real-world domain extends the literature on domains that are at the intersection of language and computer vision. We will publicly release our corpus in the near future. 2 Related Work Conversation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond im"
W18-4701,W17-5539,1,0.843575,"resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the fo"
W18-4701,L18-1683,1,0.883106,"Missing"
W18-4701,W18-5033,1,0.93435,"le completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) recently introduced a corpus containing one-shot image editing instructions. 3 Data The task of image editing is challenging for the following reasons: (i) The user needs to understand whether changes applied to a given image fit the target narrative or not. (ii) Image editing is a time consuming task. The user typically experiments with various features often undoing, redoing, altering in increments, or even completely removing previously performed edits before settling on the final image edit. (iii) The users may know at an abstract level what changes they want to perform, but be unaware"
W18-4701,I17-1047,0,0.0261199,"al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal inter"
W18-4701,paetzel-etal-2014-multimodal,0,0.0225781,"f visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context o"
W18-4701,W15-4610,0,0.0243606,"incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al."
W18-4701,P16-1115,0,0.0126772,"logue, and computer vision, and our real-world domain extends the literature on domains that are at the intersection of language and computer vision. We will publicly release our corpus in the near future. 2 Related Work Conversation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied"
W18-4701,stoia-etal-2008-scare,0,0.0374439,"Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the im"
W18-4701,tokunaga-etal-2012-rex,0,0.0131817,"yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) recently introduced a corp"
W18-4701,W15-4622,0,0.0162603,"Update requests (IER-U) are refinements to a previous request (users often request updates until the target is achieved). Revert requests (IER-R) occur when users want to undo the changes done to the image until a certain point. Compare requests (IER-C) occur when users want to compare the current version of the image to a previous version (before the most recent changes took place). The image edit requests IER-N and IER-U are labeled further with action and entity labels, which specify the nature of the edit request (the use of actions and entities is inspired by the intents and entities of Williams et al. (2015)). These labels serve as an intermediary language to map a user’s utterance to executable commands that can be carried out in an image editing program. Actions are a predefined list of 18 functions common to most 4 Segments Dialogue Act Action Attribute Loc/Obj Mod/Val uh make the tree brighter like a 100 nope too much O IER-N IER-U COM-D Adjust Adjust - brightness brightness - tree tree - 100 - perfect let’s work on sharpness COM-L IER-N Adjust sharpness - - Table 2: Example annotations of dialogue acts, actions, and entities. Dialogue Act IER-N IER-U IER-R IER-C COM-L COM-D COM-I RQR QF QIA"
W18-4707,W02-0109,0,0.0207766,"fier. 4 Experiments We performed machine learning experiments to automatically predict the annotation labels in our corpus. We build a separate classifier for SOC, POC, and “other” labels (3 classifiers in total). This is because these labels are annotated independent of one another. Each classifier could output one of the corresponding labels or a “null” label. We use logistic regression in Weka (Hall et al., 2009), and since no prior work exists a majority baseline for comparison. The data were preprocessed before the classification was performed. We used the NLTK toolkit for lemmatization (Loper and Bird, 2002) and removed stop words. The features that we used were just words. We report the results on 10-fold cross validation performed on the user sentences. We predict the labels in two separate experiments: (i) “unsegmented” and (ii) “segmented”. For both settings we use the same set of features. In the “unsegmented” version, we predict the classification labels using the complete sentences. Each complete sentence is forwarded to the 3 classifiers and each classifier outputs one of its corresponding labels or the “null” label. For the “segmented” approach we segment the sentences and use each segme"
W18-4707,bunt-etal-2012-iso,0,\N,Missing
W18-4711,P15-2017,0,0.0330276,"swering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 2012; Kulkarni et al., 2013; Socher et al., 2014; Vinyals et al., 2015; Devlin et al., 2015). Annotation of spatial information including objects and their spatial relations in real-world images has been studied in detail for developing the ISO-Space annotation scheme (Pustejovsky et al., 2011; Pustejovsky and Yocum, 2014). The semantics of spatial language have also been studied in detail; see for example Varzi (2007) and Bateman et al. (2010). The focus of our work is not on the study of spatial semantics but rather on the task of target location identification using simplistic annotations. The goal of this work is to study user descriptions in an “end-of-taxi” ride scenario which"
W18-4711,W17-5506,0,0.0305373,"ace annotation scheme (Pustejovsky et al., 2011; Pustejovsky and Yocum, 2014). The semantics of spatial language have also been studied in detail; see for example Varzi (2007) and Bateman et al. (2010). The focus of our work is not on the study of spatial semantics but rather on the task of target location identification using simplistic annotations. The goal of this work is to study user descriptions in an “end-of-taxi” ride scenario which involves studying language and vision in a situated environment. Related to our work, Lemon et al. (2006) built a dialogue system for an in-car domain and Eric et al. (2017) studied dialogues with regard to helping a driver navigate to a specific location. However, these works did not specifically study the interaction and combination of the vision and language modalities in a situated in-car environment. Our work contributes to the literature with a corpus combining the language and vision modalities in a situated environment. We extract the embedded representations of descriptions generated from the users and use them for the task of reference resolution by comparing them to similar embeddings extracted for the object ground truth labels. We also discuss r✓ ann"
W18-4711,N16-1147,0,0.0324925,"lving vision and language has attracted much interest. The task of reference resolution is one such example. This task typically involves identification of one of the objects referred to in a set of similar distractors through dialogue (Clark and Wilkes-Gibbs, 1986; Kennington and Schlangen, 2015; Paetzel et al., 2015; de Vries et al., 2017; Manuvinakurike et al., 2017). Other tasks that combine language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 2012; Kulkarni et al., 2013; Socher et al., 2014; Vinyals et al., 2015; Devlin et al., 2015). Annotation of spatial information including objects and their spatial relations in real-world images has been studied in detail for developing the ISO-Spac"
W18-4711,P15-1029,0,0.146712,"off in front of the cop car”. The green arrow shows the direction of motion of the taxi. 2 Related Work There is a strong relation between the language and vision modalities, and the information in the vision modality influences the associated spoken language (Tanenhaus et al., 1995). In recent times, automating various tasks involving vision and language has attracted much interest. The task of reference resolution is one such example. This task typically involves identification of one of the objects referred to in a set of similar distractors through dialogue (Clark and Wilkes-Gibbs, 1986; Kennington and Schlangen, 2015; Paetzel et al., 2015; de Vries et al., 2017; Manuvinakurike et al., 2017). Other tasks that combine language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural lan"
W18-4711,E06-2009,1,0.639737,"eal-world images has been studied in detail for developing the ISO-Space annotation scheme (Pustejovsky et al., 2011; Pustejovsky and Yocum, 2014). The semantics of spatial language have also been studied in detail; see for example Varzi (2007) and Bateman et al. (2010). The focus of our work is not on the study of spatial semantics but rather on the task of target location identification using simplistic annotations. The goal of this work is to study user descriptions in an “end-of-taxi” ride scenario which involves studying language and vision in a situated environment. Related to our work, Lemon et al. (2006) built a dialogue system for an in-car domain and Eric et al. (2017) studied dialogues with regard to helping a driver navigate to a specific location. However, these works did not specifically study the interaction and combination of the vision and language modalities in a situated in-car environment. Our work contributes to the literature with a corpus combining the language and vision modalities in a situated environment. We extract the embedded representations of descriptions generated from the users and use them for the task of reference resolution by comparing them to similar embeddings"
W18-4711,W16-3630,0,0.0168886,"the embedded representations of descriptions generated from the users and use them for the task of reference resolution by comparing them to similar embeddings extracted for the object ground truth labels. We also discuss r✓ annotations that can be used to understand directional relations using the outputs of the reference resolution module, which is a particularly novel feature 99 of our annotation scheme. Note that in prior work, reference resolution is performed using models that understand the meaning of words using classifiers trained with visual features (Kennington and Schlangen, 2015; Manuvinakurike et al., 2016). 3 Data Collection We use the crowd-sourcing paradigm1 to collect user descriptions instructing a taxi to stop at a given location (we will refer to this location as the “target location”). The Amazon Mechanical Turk users (called turkers) are shown an image (similar to Figure 2 or Figure 3) and are asked to imagine a scenario where they are in a taxi about to reach their destination. As they approach their destination they need to instruct the taxi driver in natural language to stop at the bright red cross. The turkers needed to provide at least three unique descriptions. Only native English"
W18-4711,W17-5539,1,0.846859,"of the taxi. 2 Related Work There is a strong relation between the language and vision modalities, and the information in the vision modality influences the associated spoken language (Tanenhaus et al., 1995). In recent times, automating various tasks involving vision and language has attracted much interest. The task of reference resolution is one such example. This task typically involves identification of one of the objects referred to in a set of similar distractors through dialogue (Clark and Wilkes-Gibbs, 1986; Kennington and Schlangen, 2015; Paetzel et al., 2015; de Vries et al., 2017; Manuvinakurike et al., 2017). Other tasks that combine language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 20"
W18-4711,L18-1683,1,0.88608,"Missing"
W18-4711,W18-5033,1,0.790393,"The task of reference resolution is one such example. This task typically involves identification of one of the objects referred to in a set of similar distractors through dialogue (Clark and Wilkes-Gibbs, 1986; Kennington and Schlangen, 2015; Paetzel et al., 2015; de Vries et al., 2017; Manuvinakurike et al., 2017). Other tasks that combine language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 2012; Kulkarni et al., 2013; Socher et al., 2014; Vinyals et al., 2015; Devlin et al., 2015). Annotation of spatial information including objects and their spatial relations in real-world images has been studied in detail for developing the ISO-Space annotation scheme (Pustejovsky et al., 2011; Pustejovsky and"
W18-4711,E12-1076,0,0.0431391,"urike et al., 2017). Other tasks that combine language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 2012; Kulkarni et al., 2013; Socher et al., 2014; Vinyals et al., 2015; Devlin et al., 2015). Annotation of spatial information including objects and their spatial relations in real-world images has been studied in detail for developing the ISO-Space annotation scheme (Pustejovsky et al., 2011; Pustejovsky and Yocum, 2014). The semantics of spatial language have also been studied in detail; see for example Varzi (2007) and Bateman et al. (2010). The focus of our work is not on the study of spatial semantics but rather on the task of target location identification using simplistic annotations. The"
W18-4711,P16-1170,0,0.0593805,"Missing"
W18-4711,W15-4610,0,0.0266784,"he green arrow shows the direction of motion of the taxi. 2 Related Work There is a strong relation between the language and vision modalities, and the information in the vision modality influences the associated spoken language (Tanenhaus et al., 1995). In recent times, automating various tasks involving vision and language has attracted much interest. The task of reference resolution is one such example. This task typically involves identification of one of the objects referred to in a set of similar distractors through dialogue (Clark and Wilkes-Gibbs, 1986; Kennington and Schlangen, 2015; Paetzel et al., 2015; de Vries et al., 2017; Manuvinakurike et al., 2017). Other tasks that combine language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this ve"
W18-4711,N18-1049,0,0.0434186,"Missing"
W18-4711,pustejovsky-yocum-2014-image,0,0.0285769,"ike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 2012; Kulkarni et al., 2013; Socher et al., 2014; Vinyals et al., 2015; Devlin et al., 2015). Annotation of spatial information including objects and their spatial relations in real-world images has been studied in detail for developing the ISO-Space annotation scheme (Pustejovsky et al., 2011; Pustejovsky and Yocum, 2014). The semantics of spatial language have also been studied in detail; see for example Varzi (2007) and Bateman et al. (2010). The focus of our work is not on the study of spatial semantics but rather on the task of target location identification using simplistic annotations. The goal of this work is to study user descriptions in an “end-of-taxi” ride scenario which involves studying language and vision in a situated environment. Related to our work, Lemon et al. (2006) built a dialogue system for an in-car domain and Eric et al. (2017) studied dialogues with regard to helping a driver navigate"
W18-4711,Q14-1017,0,0.0422279,"language and vision are: visual question answering which requires answering questions about an image (Antol et al., 2015), a related question generation task (Mostafazadeh et al., 2016), storytelling (Huang et al., 2016), and conversational image editing (Manuvinakurike et al., 2018a; Manuvinakurike et al., 2018b). Furthermore, other relevant approaches are automatic image captioning and retrieval by using neural networks to map the image into a dense vector, and then conditioning a neural language model on this vector to produce an output string (Mitchell et al., 2012; Kulkarni et al., 2013; Socher et al., 2014; Vinyals et al., 2015; Devlin et al., 2015). Annotation of spatial information including objects and their spatial relations in real-world images has been studied in detail for developing the ISO-Space annotation scheme (Pustejovsky et al., 2011; Pustejovsky and Yocum, 2014). The semantics of spatial language have also been studied in detail; see for example Varzi (2007) and Bateman et al. (2010). The focus of our work is not on the study of spatial semantics but rather on the task of target location identification using simplistic annotations. The goal of this work is to study user descripti"
W18-5033,N16-1147,0,0.336152,"Missing"
W18-5033,N16-1037,0,0.0605698,"n the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al.,"
W18-5033,W13-3214,0,0.0296417,"adeh et al. (2017) extended this work to natural language question and response generation in the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et a"
W18-5033,P15-1029,0,0.127401,"sed on real user data. Each image was Related Work Combining computer vision and language is a topic that has recently drawn much attention. 285 tion and prediction of utterance meaning, while Manuvinakurike et al. (2016b) and Petukhova and Bunt (2014) built models for incremental dialogue act recognition. associated with certain descriptions and the game worked for a specific data set of images without actually using computer vision. Manuvinakurike et al. (2016a) developed a model for incremental understanding of the described scenes among a set of complex configurations of geometric shapes. Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features. Huang et al. (2016) built a data set of sequential images with corresponding descriptions that could potentially be used for the task of visual storytelling. Mostafazadeh et al. (2016) introduced the task of “visual question generation” where the system generates natural language questions when given an image, and then Mostafazadeh et al. (2017) extended this work to natural language question and response generation in the context of image"
W18-5033,W13-4042,0,0.026956,"u, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015). Recently Skantze (2017) presented a general continuous model of turn-taking based on LSTMs. Most related to our work, DeVault et al. (2011) built models for incremental interpreta3 Data We use a Wizard of Oz setup to collect a dialogue corpus in our image edit domain. The Wizard-user conversational session is set up over Skype and the conversation recorded on the Wizard’s system. The screen share feature is enabled on the Wizard’s screen so that the user can see in real time the changes requested. There ar"
W18-5033,C16-1189,0,0.0330376,"language question and response generation in the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; S"
W18-5033,Q17-1010,0,0.019052,"of commonly occurring dialogue acts, actions, and entities. Utterance 1 add a vignette since it’s also encircled better 2 can we go down to fifteen on that 3 go back to .5 4 actually let’s revert back 5 can you compare for me before and after 6 I like it leave it there please 7 no I don’t like this color Tag IER-N 6.1 We convert the words into vector representations to train our deep learning models (and a variation of the random forests). We use out-of-thebox word vectors available in the form of GloVe embeddings (Pennington et al., 2014) (trained with Wikipedia data), or we employ fastText (Bojanowski et al., 2017) to construct embeddings using the data from the Visual Genome image region description phrases, the dialogue training set collected during this experiment, and other data related to image editing that we have collected (image edit requests out of a dialogue context). From now on these embeddings trained with fastText will be referred to as “trained embeddings”. As we can see in Table 4, for models E (LSTMs) and I (CNNs) we use word embeddings trained with fastText on the aforementioned data sets. The Vanilla LSTM (model D) does not use GloVe or trained embeddings, i.e., there is no dimensiona"
W18-5033,W15-4643,0,0.0342771,"Missing"
W18-5033,D12-1008,0,0.0323739,"Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015). Recently Skantze (2017) presented a general continuous model of turn-taking based on LSTMs. Most related to our work, DeVault et al. (2011) built models for incremental interpreta3 Data We use a Wizard of Oz setup to collect a dialogue corpus in our image edit domain. The Wizard-user conversational session is set up over Skype and the conversation recorded on the Wizard’s system. The screen share feature is enabled on the Wizard’s screen so that the user can see in real time th"
W18-5033,N16-1062,0,0.0223863,"hile Manuvinakurike et al. (2016b) and Petukhova and Bunt (2014) built models for incremental dialogue act recognition. associated with certain descriptions and the game worked for a specific data set of images without actually using computer vision. Manuvinakurike et al. (2016a) developed a model for incremental understanding of the described scenes among a set of complex configurations of geometric shapes. Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features. Huang et al. (2016) built a data set of sequential images with corresponding descriptions that could potentially be used for the task of visual storytelling. Mostafazadeh et al. (2016) introduced the task of “visual question generation” where the system generates natural language questions when given an image, and then Mostafazadeh et al. (2017) extended this work to natural language question and response generation in the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizatio"
W18-5033,W17-5530,0,0.0122664,"dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015). Recently Skantze (2017) presented a general continuous model of turn-ta"
W18-5033,C16-1185,0,0.0244276,"work to natural language question and response generation in the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann"
W18-5033,W15-4610,1,0.770321,"ing” task. Here the goal is to provide a natural language answer, given an image and a natural language question about the image. Convolutional neural networks (CNNs) were employed for encoding the images (Krizhevsky et al., 2012). This was later modeled as a dialogue-based question-answering task in Das et al. (2017). These works used images from the MS COCO data set. de Vries et al. (2017) introduced “GuessWhat?!”, a two-player game where the goal is to find an unknown object in a rich image scene by asking a series of questions. They used images from MS COCO and CNNs for image recognition. Paetzel et al. (2015) built an incremental dialogue system called “Eve”, which could guess the correct image, out of a set of possible candidates, based on descriptions given by a human. The system was shown to perform nearly as well as humans. Then in the same domain, Manuvinakurike et al. (2017) used reinforcement learning to learn an incremental dialogue policy, which outperformed the high performance baseline policy of Paetzel et al. (2015) in offline simulations based on real user data. Each image was Related Work Combining computer vision and language is a topic that has recently drawn much attention. 285 ti"
W18-5033,N18-1049,0,0.0432174,"can see in Table 4, for models E (LSTMs) and I (CNNs) we use word embeddings trained with fastText on the aforementioned data sets. The Vanilla LSTM (model D) does not use GloVe or trained embeddings, i.e., there is no dimensionality reduction. Model H (CNN) uses GloVe embeddings. The vectors used in this work (both GloVe and trained embeddings) have a dimension of 50. For trained embeddings, the vectors were constructed using skipgrams over 50 epochs with a learning rate of 0.5. Recent advancements in creating a vector representation for a sentence were also evaluated. We used the Sent2Vec (Pagliardini et al., 2018) toolkit to get a vector representation of the sentence and then used these vectors as features for models G and J. Note that LSTMs are sequential models where every word needs a vector representation and thus we could not use Sent2Vec. IER-U IER-U IER-R IER-C COM-L COM-D Table 3: Examples of some of the most commonly occurring dialogue acts in our corpus. Not only is this more efficient but also more natural. The human Wizard can begin to take action even before the utterance completion, e.g., in utterance 1 the Wizard clicks the “vignette” feature in the tool before the user has finished utt"
W18-5033,D14-1162,0,0.0814878,"e brightness tree brightness tree sharpness - Value 100 50 - Table 2: Examples of commonly occurring dialogue acts, actions, and entities. Utterance 1 add a vignette since it’s also encircled better 2 can we go down to fifteen on that 3 go back to .5 4 actually let’s revert back 5 can you compare for me before and after 6 I like it leave it there please 7 no I don’t like this color Tag IER-N 6.1 We convert the words into vector representations to train our deep learning models (and a variation of the random forests). We use out-of-thebox word vectors available in the form of GloVe embeddings (Pennington et al., 2014) (trained with Wikipedia data), or we employ fastText (Bojanowski et al., 2017) to construct embeddings using the data from the Visual Genome image region description phrases, the dialogue training set collected during this experiment, and other data related to image editing that we have collected (image edit requests out of a dialogue context). From now on these embeddings trained with fastText will be referred to as “trained embeddings”. As we can see in Table 4, for models E (LSTMs) and I (CNNs) we use word embeddings trained with fastText on the aforementioned data sets. The Vanilla LSTM ("
W18-5033,L18-1683,1,0.583791,"Missing"
W18-5033,W09-3905,0,0.0394657,"memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015). Recently Skantze (2017) presented a general continuous model of turn-taking based on LSTMs. Most related to our work, DeVault et al. (2011) built models for incremental interpreta3 Data We use a Wizard of Oz setup to collect a dialogue corpus in our image edit domain. The Wizard-user conversational session is set up over Skype and the conversation recorded on the Wizard’s system. The screen share feature is enabled on the Wiza"
W18-5033,W17-5539,1,0.793603,"ased question-answering task in Das et al. (2017). These works used images from the MS COCO data set. de Vries et al. (2017) introduced “GuessWhat?!”, a two-player game where the goal is to find an unknown object in a rich image scene by asking a series of questions. They used images from MS COCO and CNNs for image recognition. Paetzel et al. (2015) built an incremental dialogue system called “Eve”, which could guess the correct image, out of a set of possible candidates, based on descriptions given by a human. The system was shown to perform nearly as well as humans. Then in the same domain, Manuvinakurike et al. (2017) used reinforcement learning to learn an incremental dialogue policy, which outperformed the high performance baseline policy of Paetzel et al. (2015) in offline simulations based on real user data. Each image was Related Work Combining computer vision and language is a topic that has recently drawn much attention. 285 tion and prediction of utterance meaning, while Manuvinakurike et al. (2016b) and Petukhova and Bunt (2014) built models for incremental dialogue act recognition. associated with certain descriptions and the game worked for a specific data set of images without actually using co"
W18-5033,W16-3630,1,0.62526,"Eve”, which could guess the correct image, out of a set of possible candidates, based on descriptions given by a human. The system was shown to perform nearly as well as humans. Then in the same domain, Manuvinakurike et al. (2017) used reinforcement learning to learn an incremental dialogue policy, which outperformed the high performance baseline policy of Paetzel et al. (2015) in offline simulations based on real user data. Each image was Related Work Combining computer vision and language is a topic that has recently drawn much attention. 285 tion and prediction of utterance meaning, while Manuvinakurike et al. (2016b) and Petukhova and Bunt (2014) built models for incremental dialogue act recognition. associated with certain descriptions and the game worked for a specific data set of images without actually using computer vision. Manuvinakurike et al. (2016a) developed a model for incremental understanding of the described scenes among a set of complex configurations of geometric shapes. Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features. Huang et al. (2016) built a data"
W18-5033,W13-4063,0,0.030657,"6; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015). Recently Skantze (2017) presented a general continuous model of turn-taking based on LSTMs. Most related to our work, DeVault et al. (2011) built models for incremental interpreta3 Data We use a Wizard of Oz setup to collect a dialogue corpus in our image edit domain. The Wizard-user conversational session is set up over Skype and the conversation recorded on the Wizard’s system. The screen share feature is enabled on the Wizard’s screen so that the user can see in real time the changes requested. There are no time constraints, a"
W18-5033,W16-3632,1,0.859604,"Eve”, which could guess the correct image, out of a set of possible candidates, based on descriptions given by a human. The system was shown to perform nearly as well as humans. Then in the same domain, Manuvinakurike et al. (2017) used reinforcement learning to learn an incremental dialogue policy, which outperformed the high performance baseline policy of Paetzel et al. (2015) in offline simulations based on real user data. Each image was Related Work Combining computer vision and language is a topic that has recently drawn much attention. 285 tion and prediction of utterance meaning, while Manuvinakurike et al. (2016b) and Petukhova and Bunt (2014) built models for incremental dialogue act recognition. associated with certain descriptions and the game worked for a specific data set of images without actually using computer vision. Manuvinakurike et al. (2016a) developed a model for incremental understanding of the described scenes among a set of complex configurations of geometric shapes. Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features. Huang et al. (2016) built a data"
W18-5033,W17-5527,0,0.0136096,"urs are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015). Recently Skantze (2017) presented a general continuous model of turn-taking based on LSTMs. Most related to our work, DeVault et al. (2011) built models for incremental interpreta3 Data We use a Wizard of Oz setup to collect a dialogue corpus in our image edit domain. The Wizard-user conversational session is set up over Skype and the conversation recorded on the Wizard’s system. The screen share feature is enabled on the Wizard’s screen so that the user can see in real time the changes requested. There are no time constraints, and the Wizard and the user can talk freely until the user is happy with the changes perf"
W18-5033,E12-1076,0,0.172729,"of number of words (or time) is explicitly measured. DeVault et al. (2011) measured the stability of natural language understanding results as a function of time but did not explicitly measure savings in terms of number of words or time. 2 Yao et al. (2010) is an example of a work relying on manual input. They developed a semiautomatic method for parsing images from the Internet to build visual knowledge representation graphs. On the other hand, the following works did not rely on manual annotations. Feng and Lapata (2013) generated captions from news articles and their corresponding images. Mitchell et al. (2012) and Kulkarni et al. (2013) built systems for understanding and generating image descriptions. Due to space constraints, below we focus on work that combines computer vision or visual references (enabled through manual annotations) and language in the context of a dialogue task, which is most relevant to our work. Antol et al. (2015) introduced the “visual question answering” task. Here the goal is to provide a natural language answer, given an image and a natural language question about the image. Convolutional neural networks (CNNs) were employed for encoding the images (Krizhevsky et al., 2"
W18-5033,P17-2083,0,0.0185615,"image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017). The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets. However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do. Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 20"
W18-5033,I17-1047,0,0.0444592,"tanding of the described scenes among a set of complex configurations of geometric shapes. Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features. Huang et al. (2016) built a data set of sequential images with corresponding descriptions that could potentially be used for the task of visual storytelling. Mostafazadeh et al. (2016) introduced the task of “visual question generation” where the system generates natural language questions when given an image, and then Mostafazadeh et al. (2017) extended this work to natural language question and response generation in the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act detection that employs deep learning. People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and B"
W18-5033,P16-1170,0,0.0562369,"nd the game worked for a specific data set of images without actually using computer vision. Manuvinakurike et al. (2016a) developed a model for incremental understanding of the described scenes among a set of complex configurations of geometric shapes. Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features. Huang et al. (2016) built a data set of sequential images with corresponding descriptions that could potentially be used for the task of visual storytelling. Mostafazadeh et al. (2016) introduced the task of “visual question generation” where the system generates natural language questions when given an image, and then Mostafazadeh et al. (2017) extended this work to natural language question and response generation in the context of image-grounded conversations. Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017). The problem of intent recognition or dialogue act detection has been extensively studied. Below we focus on recent work on dialogue act dete"
yao-etal-2010-practical,W06-1303,1,\N,Missing
yao-etal-2010-practical,burger-etal-2006-competitive,0,\N,Missing
yao-etal-2010-practical,robinson-etal-2008-ask,1,\N,Missing
