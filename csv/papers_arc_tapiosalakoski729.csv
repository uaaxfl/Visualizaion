W19-6204,Is Multilingual {BERT} Fluent in Language Generation?,2019,6,5,3,0,2649,samuel ronnqvist,Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing,0,"The multilingual BERT model is trained on 104 languages and meant to serve as a universal language model and tool for encoding sentences. We explore how well the model performs on several languages across several tasks: a diagnostic classification probing the embeddings for a particular syntactic property, a cloze task testing the language modelling ability to fill in gaps in a sentence, and a natural language generation task testing for the ability to produce coherent text fitting a given context. We find that the currently available multilingual BERT model is clearly inferior to the monolingual counterparts, and cannot in many cases serve as a substitute for a well-trained monolingual model. We find that the English and German models perform well at generation, whereas the multilingual model is lacking, in particular, for Nordic languages. The code of the experiments in the paper is available at: https://github.com/TurkuNLP/bert-eval"
W19-6114,An Unsupervised Query Rewriting Approach Using N-gram Co-occurrence Statistics to Find Similar Phrases in Large Text Corpora,2019,0,0,8,1,23682,hans moen,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"We present our work towards developing a system that should find, in a large text corpus, contiguous phrases expressing similar meaning as a query phrase of arbitrary length. Depending on the use case, this task can be seen as a form of (phrase-level) query rewriting. The suggested approach works in a generative manner, is unsupervised and uses a combination of a semantic word n-gram model, a statistical language model and a document search engine. A central component is a distributional semantic model containing word n-grams vectors (or embeddings) which models semantic similarities between n-grams of different order. As data we use a large corpus of PubMed abstracts. The presented experiment is based on manual evaluation of extracted phrases for arbitrary queries provided by a group of evaluators. The results indicate that the proposed approach is promising and that the use of distributional semantic models trained with uni-, bi- and trigrams seems to work better than a more traditional unigram model."
W19-6125,Template-free Data-to-Text Generation of {F}innish Sports News,2019,24,0,4,0.971267,2608,jenna kanerva,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"News articles such as sports game reports are often thought to closely follow the underlying game statistics, but in practice they contain a notable amount of background knowledge, interpretation, insight into the game, and quotes that are not present in the official statistics. This poses a challenge for automated data-to-text news generation with real-world news corpora as training data. We report on the development of a corpus of Finnish ice hockey news, edited to be suitable for training of end-to-end news generation methods, as well as demonstrate generation of text, which was judged by journalists to be relatively close to a viable product. The new dataset and system source code are available for research purposes."
W18-5611,Evaluation of a Prototype System that Automatically Assigns Subject Headings to Nursing Narratives Using Recurrent Neural Network,2018,0,0,6,1,23682,hans moen,Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,0,"We present our initial evaluation of a prototype system designed to assist nurses in assigning subject headings to nursing narratives {--} written in the context of documenting patient care in hospitals. Currently nurses may need to memorize several hundred subject headings from standardized nursing terminologies when structuring and assigning the right section/subject headings to their text. Our aim is to allow nurses to write in a narrative manner without having to plan and structure the text with respect to sections and subject headings, instead the system should assist with the assignment of subject headings and restructuring afterwards. We hypothesize that this could reduce the time and effort needed for nursing documentation in hospitals. A central component of the system is a text classification model based on a long short-term memory (LSTM) recurrent neural network architecture, trained on a large data set of nursing notes. A simple Web-based interface has been implemented for user interaction. To evaluate the system, three nurses write a set of artificial nursing shift notes in a fully unstructured narrative manner, without planning for or consider the use of sections and subject headings. These are then fed to the system which assigns subject headings to each sentence and then groups them into paragraphs. Manual evaluation is conducted by a group of nurses. The results show that about 70{\%} of the sentences are assigned to correct subject headings. The nurses believe that such a system can be of great help in making nursing documentation in hospitals easier and less time consuming. Finally, various measures and approaches for improving the system are discussed."
W18-2311,Biomedical Event Extraction Using Convolutional Neural Networks and Dependency Parsing,2018,0,12,2,1,28457,jari bjorne,Proceedings of the {B}io{NLP} 2018 workshop,0,"Event and relation extraction are central tasks in biomedical text mining. Where relation extraction concerns the detection of semantic connections between pairs of entities, event extraction expands this concept with the addition of trigger words, multiple arguments and nested events, in order to more accurately model the diversity of natural language. In this work we develop a convolutional neural network that can be used for both event and relation extraction. We use a linear representation of the input text, where information is encoded with various vector space embeddings. Most notably, we encode the parse graph into this linear space using dependency path embeddings. We integrate our neural network into the open source Turku Event Extraction System (TEES) framework. Using this system, our machine learning model can be easily applied to a large set of corpora from e.g. the BioNLP, DDI Extraction and BioCreative shared tasks. We evaluate our system on 12 different event, relation and NER corpora, showing good generalizability to many tasks and achieving improved performance on several corpora."
K18-2013,{T}urku Neural Parser Pipeline: An End-to-End System for the {C}o{NLL} 2018 Shared Task,2018,0,10,5,0.971267,2608,jenna kanerva,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"In this paper we describe the TurkuNLP entry at the CoNLL 2018 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. Compared to the last year, this year the shared task includes two new main metrics to measure the morphological tagging and lemmatization accuracies in addition to syntactic trees. Basing our motivation into these new metrics, we developed an end-to-end parsing pipeline especially focusing on developing a novel and state-of-the-art component for lemmatization. Our system reached the highest aggregate ranking on three main metrics out of 26 teams by achieving 1st place on metric involving lemmatization, and 2nd on both morphological tagging and parsing."
W17-2310,End-to-End System for Bacteria Habitat Extraction,2017,16,6,5,1,31930,farrokh mehryary,{B}io{NLP} 2017,0,"We introduce an end-to-end system capable of named-entity detection, normalization and relation extraction for extracting information about bacteria and their habitats from biomedical literature. Our system is based on deep learning, CRF classifiers and vector space models. We train and evaluate the system on the BioNLP 2016 Shared Task Bacteria Biotope data. The official evaluation shows that the joint performance of our entity detection and relation extraction models outperforms the winning team of the Shared Task by 19pp on F1-score, establishing a new top score for the task. We also achieve state-of-the-art results in the normalization task. Our system is open source and freely available at \url{https://github.com/TurkuNLP/BHE}."
W17-2347,Detecting mentions of pain and acute confusion in {F}innish clinical text,2017,-1,-1,5,1,23682,hans moen,{B}io{NLP} 2017,0,"We study and compare two different approaches to the task of automatic assignment of predefined classes to clinical free-text narratives. In the first approach this is treated as a traditional mention-level named-entity recognition task, while the second approach treats it as a sentence-level multi-label classification task. Performance comparison across these two approaches is conducted in the form of sentence-level evaluation and state-of-the-art methods for both approaches are evaluated. The experiments are done on two data sets consisting of Finnish clinical text, manually annotated with respect to the topics pain and acute confusion. Our results suggest that the mention-level named-entity recognition approach outperforms sentence-level classification overall, but the latter approach still manages to achieve the best prediction scores on several annotation classes."
W17-0510,"Applying {BLAST} to Text Reuse Detection in {F}innish Newspapers and Journals, 1771-1910",2017,-1,-1,4,0,32145,aleksi vesanto,Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Processing Historical Language,0,None
W17-0218,Creating register sub-corpora for the {F}innish {I}nternet Parsebank,2017,12,0,4,1,2652,veronika laippala,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0249,A System for Identifying and Exploring Text Repetition in Large Historical Document Corpora,2017,4,1,5,0,32145,aleksi vesanto,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W16-3009,Deep Learning with Minimal Training Data: {T}urku{NLP} Entry in the {B}io{NLP} Shared Task 2016,2016,0,20,4,1,31930,farrokh mehryary,Proceedings of the 4th {B}io{NLP} Shared Task Workshop,0,None
W16-2913,Syntactic analyses and named entity recognition for {P}ub{M}ed and {P}ub{M}ed Central {---} up-to-the-minute,2016,21,8,3,1,26510,kai hakala,Proceedings of the 15th Workshop on Biomedical Natural Language Processing,0,"Although advanced text mining methods specifically adapted to the biomedical domain are continuously being developed, their applications on large scale have been scarce. One of the main reasons for this is the lack of computational resources and workforce required for processing large text corpora. In this paper we present a publicly available resource distributing preprocessed biomedical literature including sentence splitting, tokenization, part-of-speech tagging, syntactic parses and named entity recognition. The aim of this work is to support the future development of largescale text mining resources by eliminating the time consuming but necessary preprocessing steps. This resource covers the whole of PubMed and PubMed Central Open Access section, currently containing 26M abstracts and 1.4M full articles, constituting over 388M analyzed sentences. The resource is based on a fully automated pipeline, guaranteeing that the distributed data is always up-to-date. The resource is available at https://turkunlp. github.io/pubmed_parses/."
S16-1142,{UTU} at {S}em{E}val-2016 Task 10: Binary Classification for Expression Detection ({BCED}),2016,9,0,2,1,28457,jari bjorne,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"The SemEval 2016 DiMSUM Shared Task concerns the detection of minimal semantic units from text and prediction of their coarse lexical categories known as supersenses. Our approach is to define this task as a binary classification problem approachable by straightforward machine learning methods. We start by detecting semantic units by matching text spans against several large dictionaries, including the English WordNet, expressions derived from the Yelp Academic Dataset and concepts from the English Wikipedia, generating a set of potential supersenses for each matched span. For each potential supersense and text span pair a binary machine learning example is defined. We classify these examples using an ensemble method, taking as the final predicted supersense the one with the highest confidence score. Our system achieves good performance on the supersense classification task but has limited performance for detection of multi-word semantic units. We show that the task of supersense prediction can be effectively defined as a binary classification task."
W15-1815,Towards the Classification of the {F}innish {I}nternet Parsebank: Detecting Translations and Informality,2015,22,0,5,1,2652,veronika laippala,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper presents the first results on detecting informality, machine and human translations in the Finnish Internet Parsebank, a project developing a large-scale, web-based corpus with full morphological and syntactic analyses. The paper aims at classifying the Parsebank according to these criteria, as well as studying the linguistic characteristics of the classes. The features used include both lexical and morpho-syntactic properties, such as syntactic n-grams. The results are practically applicable, with an AUC range of 85xe2x80x9085% for the human, 98% for the machine translated texts and 73% for the informal texts. While word-based classification performs well for the indomain experiments, delexicalized methods with morpho-syntactic features prove to be more tolerant to variation caused by genre or source language. In addition, the results show that the features used in the classification provide interesting pointers for further, more detailed studies on the linguistic characteristics of these texts."
W14-1118,Care Episode Retrieval,2014,18,4,5,1,23682,hans moen,Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi),0,"The documentation of a care episode consists of clinical notes concerning patient care, concluded with a discharge summary. Care episodes are stored electronically and used throughout the health care sector by patients, administrators and professionals from different areas, primarily for clinical purposes, but also for secondary purposes such as decision support and research. A common use case is, given a xe2x80x93 possibly unfinished xe2x80x93 care episode, to retrieve the most similar care episodes among the records. This paper presents several methods for information retrieval, focusing on care episode retrieval, based on textual similarity, where similarity is measured through domain-specific modelling of the distributional semantics of words. Models include variants of random indexing and a semantic neural network model called word2vec. A novel method is introduced that utilizes the ICD-10 codes attached to care episodes to better induce domain-specificity in the semantic model. We report on an experimental evaluation of care episode retrieval that circumvents the lack of human judgements regarding episode relevance by exploiting (1) ICD10 codes of care episodes and (2) semantic similarity between their discharge summaries. Results suggest that several of the methods proposed outperform a state-ofthe art search engine (Lucene) on the retrieval task."
W13-5609,Towards a Dependency-Based {P}rop{B}ank of General {F}innish,2013,20,5,8,1,39309,katri haverinen,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"In this work, we present the first results of a project aiming at a Finnish Proposition Bank, an annotated corpus of semantic roles. The annotation is based on an existing treebank of Finnish, the Turku Dependency Treebank, annotated using the well-known Stanford Dependency scheme. We describe the use of the dependency treebank for PropBanking purposes and show that both annotation layers present in the treebank are highly useful for the annotation of semantic roles. We also discuss the specific features of Finnish influencing the development of a PropBank as well as the methods employed in the annotation, and finally, we present preliminary evaluation of the annotation quality."
W13-5626,Building a Large Automatically Parsed Corpus of {F}innish,2013,9,1,7,0.666667,2610,filip ginter,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"We describe the methods and resources used to build FinnTreeBank-3, a 76.4 million token corpus of Finnish with automatically produced morphological and dependency syntax analyses. Starting from a definition of the target dependency scheme, we show how existing resources are transformed to conform to this definition and subsequently used to develop a parsing pipeline capable of processing a large-scale corpus. An independent formal evaluation demonstrates high accuracy of both morphological and syntactic annotation layers. The parsed corpus is freely available within the FIN-CLARIN infrastructure project."
W13-3728,Predicting Conjunct Propagation and Other Extended {S}tanford Dependencies,2013,27,7,4,0,40504,jenna nyblom,Proceedings of the Second International Conference on Dependency Linguistics ({D}ep{L}ing 2013),0,"In this work, we present a data-driven method to enhance syntax trees with additional dependencies as defined in the wellknown Stanford Dependencies scheme, so as to give more information about the structure of the sentence. This hybrid method utilizes both machine learning and a rule-based approach, and achieves a performance of 93.1% in F1-score, as evaluated using an existing treebank of Finnish. The resulting tool will be integrated into an existing Finnish parser and made publicly available at the address http://bionlp.utu.fi/."
W13-2003,{TEES} 2.1: Automated Annotation Scheme Learning in the {B}io{NLP} 2013 Shared Task,2013,24,65,2,1,28457,jari bjorne,Proceedings of the {B}io{NLP} Shared Task 2013 Workshop,0,"We participate in the BioNLP 2013 Shared Task with Turku Event Extraction System (TEES) version 2.1. TEES is a support vector machine (SVM) based text mining system for the extraction of events and relations from natural language texts. In version 2.1 we introduce an automated annotation scheme learning system, which derives task-specific event rules and constraints from the training data, and uses these to automatically adapt the system for new corpora with no additional programming required. TEES 2.1 is shown to have good generalizability and good performance across the BioNLP 2013 task corpora, achieving first place in four out of eight tasks."
W13-2004,{EVEX} in {ST}{'}13: Application of a large-scale text mining resource to event extraction and network construction,2013,17,27,3,1,26510,kai hakala,Proceedings of the {B}io{NLP} Shared Task 2013 Workshop,0,"During the past few years, several novel text mining algorithms have been developed in the context of the BioNLP Shared Tasks on Event Extraction. These algorithms typically aim at extracting biomolecular interactions from text by inspecting only the context of one sentence. However, when humans interpret biomolecular research articles, they usually build upon extensive background knowledge of their favorite genes and pathways. To make such world knowledge available to a text mining algorithm, it could first be applied to all available literature to subsequently make a more informed decision on which predictions are consistent with the current known data. In this paper, we introduce our participation in the latest Shared Task using the largescale text mining resource EVEX which we previously implemented using state-ofthe-art algorithms, and which was applied to the whole of PubMed and PubMed Central. We participated in the Genia Event Extraction (GE) and Gene Regulation Network (GRN) tasks, ranking first in the former and fifth in the latter."
S13-2108,{UT}urku: Drug Named Entity Recognition and Drug-Drug Interaction Extraction Using {SVM} Classification and Domain Knowledge,2013,18,45,3,1,28457,jari bjorne,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"The DDIExtraction 2013 task in the SemEval conference concerns the detection of drug names and statements of drug-drug interactions (DDI) from text. Extraction of DDIs is important for providing up-to-date knowledge on adverse interactions between coadministered drugs. We apply the machine learning based Turku Event Extraction System to both tasks. We evaluate three feature sets, syntactic features derived from deep parsing, enhanced optionally with features derived from DrugBank or from both DrugBank and MetaMap. TEES achieves F-scores of 60% for the drug name recognition task and 59% for the DDI extraction task."
W12-2410,"{P}ub{M}ed-Scale Event Extraction for Post-Translational Modifications, Epigenetics and Protein Structural Relations",2012,35,10,8,1,28457,jari bjorne,{B}io{NLP}: Proceedings of the 2012 Workshop on Biomedical Natural Language Processing,0,"Recent efforts in biomolecular event extraction have mainly focused on core event types involving genes and proteins, such as gene expression, protein-protein interactions, and protein catabolism. The BioNLP'11 Shared Task extended the event extraction approach to sub-protein events and relations in the Epigenetics and Post-translational Modifications (EPI) and Protein Relations (REL) tasks. In this study, we apply the Turku Event Extraction System, the best-performing system for these tasks, to all PubMed abstracts and all available PMC full-text articles, extracting 1.4M EPI events and 2.2M REL relations from 21M abstracts and 372K articles. We introduce several entity normalization algorithms for genes, proteins, protein complexes and protein components, aiming to uniquely identify these biological entities. This normalization effort allows direct mapping of the extracted events and relations with post-translational modifications from UniProt, epigenetics from PubMeth, functional domains from InterPro and macromolecular structures from PDB. The extraction of such detailed protein information provides a unique text mining dataset, offering the opportunity to further deepen the information provided by existing PubMed-scale event extraction efforts. The methods and data introduced in this study are freely available from bionlp.utu.fi."
W11-1828,Generalizing Biomedical Event Extraction,2011,20,97,2,1,28457,jari bjorne,Proceedings of {B}io{NLP} Shared Task 2011 Workshop,0,"We present a system for extracting biomedical events (detailed descriptions of biomolecular interactions) from research articles. This system was developed for the BioNLP'11 Shared Task and extends our BioNLP'09 Shared Task winning Turku Event Extraction System. It uses support vector machines to first detect event-defining words, followed by detection of their relationships. The theme of the BioNLP'11 Shared Task is generalization, extending event extraction to varied biomedical domains. Our current system successfully predicts events for every domain case introduced in the BioNLP'11 Shared Task, being the only system to participate in all eight tasks and all of their subtasks, with best performance in four tasks."
W11-0204,{EVEX}: A {P}ub{M}ed-Scale Resource for Homology-Based Generalization of Text Mining Predictions,2011,21,31,4,1,40987,sofie landeghem,Proceedings of {B}io{NLP} 2011 Workshop,0,"In comparative genomics, functional annotations are transferred from one organism to another relying on sequence similarity. With more than 20 million citations in PubMed, text mining provides the ideal tool for generating additional large-scale homology-based predictions. To this end, we have refined a recent dataset of biomolecular events extracted from text, and integrated these predictions with records from public gene databases. Accounting for lexical variation of gene symbols, we have implemented a disambiguation algorithm that uniquely links the arguments of 11.2 million biomolecular events to well-defined gene families, providing interesting opportunities for query expansion and hypothesis generation. The resulting MySQL database, including all 19.2 million original events as well as their homology-based variants, is publicly available at http://bionlp.utu.fi/."
W10-1904,Scaling up Biomedical Event Extraction to the Entire {P}ub{M}ed,2010,20,27,5,1,28457,jari bjorne,Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,0,"We present the first full-scale event extraction experiment covering the titles and abstracts of all PubMed citations. Extraction is performed using a pipeline composed of state-of-the-art methods: the BANNER named entity recognizer, the McClosky-Charniak domain-adapted parser, and the Turku Event Extraction System. We analyze the statistical properties of the resulting dataset and present evaluations of the core event extraction as well as negation and speculation detection components of the system. Further, we study in detail the set of extracted events relevant to the apoptosis pathway to gain insight into the biological relevance of the result. The dataset, consisting of 19.2 million occurrences of 4.5 million unique events, is freely available for use in research at http://bionlp.utu.fi/."
W10-1914,Reconstruction of Semantic Relationships from Their Projections in Biomolecular Domain,2010,26,4,3,0,45366,juho heimonen,Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,0,"The extraction of nested, semantically rich relationships of biological entities has recently gained popularity in the biomedical text mining community. To move toward this objective, a method is proposed for reconstructing original semantic relationship graphs from projections, where each node and edge is mapped to the representative of its equivalence class, by determining the relationship argument combinations that represent real relationships. It generalises the limited postprocessing step of the method of Bjorne et al. (2010) and hence extends this extraction method to arbitrarily deep relationships with unrestricted primary argument combinations. The viability of the method is shown by successfully extracting nested relationships in BioInfer and the corpus of the BioNLP'09 Shared Task on Event Extraction. The reported results, to the best of our knowledge, are the first for the nested relationships in BioInfer on a task in which only named entities are given."
W10-1819,Dependency-Based {P}rop{B}anking of Clinical {F}innish,2010,16,11,5,1,39309,katri haverinen,Proceedings of the Fourth Linguistic Annotation Workshop,0,"In this paper, we present a PropBank of clinical Finnish, an annotated corpus of verbal propositions and arguments. The clinical PropBank is created on top of a previously existing dependency treebank annotated in the Stanford Dependency (SD) scheme and covers 90% of all verb occurrences in the treebank.n n We establish that the PropBank scheme is applicable to clinical Finnish as well as compatible with the SD scheme, with an overwhelming proportion of arguments being governed by the verb. This allows argument candidates to be restricted to direct verb dependents, substantially simplifying the PropBank construction.n n The clinical Finnish PropBank is freely available at the address http://bionlp.utu.fi."
W09-4605,Learning to Extract Biological Event and Relation Graphs,2009,24,5,5,1,28457,jari bjorne,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"While the overwhelming majority of information extraction efforts in the biomedical domain have focused on the extraction of simple binary interactions between named entity pairs, some recently published corpora provide complex, nested and typed event annotations that aim to accurately capture the diversity of biological relationships. We present the first machine learning approach for extracting such relationships, utilizing both a graph kernel and a novel, task-specific feature set. We show that relationships can be predicted with 77% F-score, or 83% if their type and direction is disregarded. Using both gold standard and generated parses, we determine the impact of parsing on extraction performance. Finally, we convert our predicted complex relationships to binary interactions, recovering binary annotation with 62% F-score, relating the new method to the large body of work available on binary interactions."
W09-4611,Parsing Clinical {F}innish: Experiments with Rule-Based and Statistical Dependency Parsers,2009,15,9,4,1,39309,katri haverinen,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"In this paper, we present a new syntactically annotated corpus consisting of daily notes from an intensive care unit in a Finnish hospital. Using the corpus, we perform experiments with both rule-based and statistical parsers. We apply an existing rule-based parser specifically developed for this clinical language and create a set of conversion rules for transforming the constituency scheme of this parser into the dependency scheme of the corpus. The statistical parser is induced from the corpus using the MaltParser system. We find that even with a modestly-sized corpus, the statistical parser achieves results comparable to those previously reported on a number of languages using considerably larger corpora. The accurate constituency-to-dependency conversion improves the applicability of the rule-based parser by inferring grammatical roles, thus deepening its analyses."
W09-1402,Extracting Complex Biological Events with Rich Graph-Based Feature Sets,2009,17,163,6,1,28457,jari bjorne,Proceedings of the {B}io{NLP} 2009 Workshop Companion Volume for Shared Task,0,"We describe a system for extracting complex events among genes and proteins from biomedical literature, developed in context of the BioNLP'09 Shared Task on Event Extraction. For each event, its text trigger, class, and arguments are extracted. In contrast to the prevailing approaches in the domain, events can be arguments of other events, resulting in a nested structure that better captures the underlying biological statements. We divide the task into independent steps which we approach as machine learning problems. We define a wide array of features and in particular make extensive use of dependency parse graphs. A rule-based post-processing step is used to refine the output in accordance with the restrictions of the extraction task. In the shared task evaluation, the system achieved an F-score of 51.95% on the primary task, the best performance among the participants."
W08-0601,A Graph Kernel for Protein-Protein Interaction Extraction,2008,24,72,6,0,47007,antti airola,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,"In this paper, we propose a graph kernel based approach for the automated extraction of protein-protein interactions (PPI) from scientific literature. In contrast to earlier approaches to PPI extraction, the introduced all-dependency-paths kernel has the capability to consider full, general dependency graphs. We evaluate the proposed method across five publicly available PPI corpora providing the most comprehensive evaluation done for a machine learning based PPI-extraction system. Our method is shown to achieve state-of-the-art performance with respect to comparable evaluations, achieving 56.4 F-score and 84.8 AUC on the AImed corpus. Further, we identify several pitfalls that can make evaluations of PPI-extraction systems incomparable, or even invalid. These include incorrect cross-validation strategies and problems related to comparing F-score results achieved on different evaluation resources."
W07-2423,Utterance-Initial Duration of {F}innish Non-Plosive Consonants,2007,11,0,5,0,48888,tuomo saarni,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,"We have investigated utterance-initial duration of non-plosive consonants in two qualitatively different Finnish speech corpora. The goal has been to identify any possible lengthening or shortening effects the domain edge (here, the beginning of an utterance) might have on segmental duration. Duration was observed at phone level. The results indicate that cases of lengthening, shortening, and absence of any effect all occur. Those are determined by the speech sounds phonemic identity, and the results were similar in both corpora. For instance /s/ and /r/ are lengthened while /j/ and /m/ are shortened. Contrasted with previous research on various languages, the phonetic universality associated with final lengthening does not apply for initial duration processes."
W07-2462,Role of Different Spectral Attributes in Vowel Categorization: the Case of {U}dmurt,2007,-1,-1,4,0,48912,janne savela,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,None
W07-1004,On the unification of syntactic annotations under the {S}tanford dependency scheme: A case study on {B}io{I}nfer and {GENIA},2007,19,29,6,1,2607,sampo pyysalo,"Biological, translational, and clinical language processing",0,"Several incompatible syntactic annotation schemes are currently used by parsers and corpora in biomedical information extraction. The recently introduced Stanford dependency scheme has been suggested to be a suitable unifying syntax formalism. In this paper, we present a step towards such unification by creating a conversion from the Link Grammar to the Stanford scheme. Further, we create a version of the BioInfer corpus with syntactic annotation in this scheme. We present an application-oriented evaluation of the transformation and assess the suitability of the scheme and our conversion to the unification of the syntactic annotations of BioInfer and the GENIA Treebank.n n We find that a highly reliable conversion is both feasible to create and practical, increasing the applicability of both the parser and the corpus to information extraction."
W06-3605,A Probabilistic Search for the Best Solution Among Partially Completed Candidates,2006,-1,-1,3,0,2610,filip ginter,Proceedings of the Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing,0,None
W04-1203,Analysis of Link Grammar on Biomedical Dependency Corpus Targeted at Protein-Protein Interactions,2004,9,35,6,0,2607,sampo pyysalo,Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications ({NLPBA}/{B}io{NLP}),0,"In this paper, we present an evaluation of the Link Grammar parser on a corpus consisting of sentences describing protein-protein interactions. We introduce the notion of an interaction subgraph, which is the subgraph of a dependency graph expressing a protein-protein interaction. We measure the performance of the parser for recovery of dependencies, fully correct linkages and interaction subgraphs. We analyze the causes of parser failure and report specific causes of error, and identify potential modifications to the grammar to address the identified issues. We also report and discuss the effect of an extension to the dictionary of the parser."
