2021.naacl-main.48,Implicitly Abusive Language {--} What does it actually look like and why are we not getting there?,2021,-1,-1,1,1,3381,michael wiegand,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Abusive language detection is an emerging field in natural language processing which has received a large amount of attention recently. Still the success of automatic detection is limited. Particularly, the detection of implicitly abusive language, i.e. abusive language that is not conveyed by abusive words (e.g. dumbass or scum), is not working well. In this position paper, we explain why existing datasets make learning implicit abuse difficult and what needs to be changed in the design of such datasets. Arguing for a divide-and-conquer strategy, we present a list of subtypes of implicitly abusive language and formulate research tasks and questions for future research."
2021.germeval-1.1,"Overview of the {G}erm{E}val 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",2021,-1,-1,4,0,70,julian risch,"Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",0,"We present the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. This shared task comprises three binary classification subtasks with the goal to identify: toxic comments, engaging comments, and comments that include indications of a need for fact-checking, here referred to as fact-claiming comments. Building on the two previous GermEval shared tasks on the identification of offensive language in 2018 and 2019, we extend this year{'}s task definition to meet the demand of moderators and community managers to also highlight comments that foster respectful communication, encourage in-depth discussions, and check facts that lines of arguments rely on. The dataset comprises 4,188 posts extracted from the Facebook page of a German political talk show of a national public television broadcaster. A theoretical framework and additional reliability tests during the data annotation process ensure particularly high data quality. The shared task had 15 participating teams submitting 31 runs for the subtask on toxic comments, 25 runs for the subtask on engaging comments, and 31 for the subtask on fact-claiming comments. The shared task website can be found at https://germeval2021toxic.github.io/SharedTask/."
2021.eacl-main.27,Implicitly Abusive Comparisons {--} A New Dataset and Linguistic Analysis,2021,-1,-1,1,1,3381,michael wiegand,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,We examine the task of detecting implicitly abusive comparisons (e.g. {``}Your hair looks like you have been electrocuted{''}). Implicitly abusive comparisons are abusive comparisons in which abusive words (e.g. {``}dumbass{''} or {``}scum{''}) are absent. We detail the process of creating a novel dataset for this task via crowdsourcing that includes several measures to obtain a sufficiently representative and unbiased set of comparisons. We also present classification experiments that include a range of linguistic features that help us better understand the mechanisms underlying abusive comparisons.
2021.eacl-main.28,Exploiting Emojis for Abusive Language Detection,2021,-1,-1,1,1,3381,michael wiegand,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"We propose to use abusive emojis, such as the {``}middle finger{''} or {``}face vomiting{''}, as a proxy for learning a lexicon of abusive words. Since it represents extralinguistic information, a single emoji can co-occur with different forms of explicitly abusive utterances. We show that our approach generates a lexicon that offers the same performance in cross-domain classification of abusive microposts as the most advanced lexicon induction method. Such an approach, in contrast, is dependent on manually annotated seed words and expensive lexical resources for bootstrapping (e.g. WordNet). We demonstrate that the same emojis can also be effectively used in languages other than English. Finally, we also show that emojis can be exploited for classifying mentions of ambiguous words, such as {``}fuck{''} and {``}bitch{''}, into generally abusive and just profane usages."
2020.lrec-1.606,Doctor Who? Framing Through Names and Titles in {G}erman,2020,-1,-1,4,1,17870,esther berg,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Entity framing is the selection of aspects of an entity to promote a particular viewpoint towards that entity. We investigate entity framing of political figures through the use of names and titles in German online discourse, enhancing current research in entity framing through titling and naming that concentrates on English only. We collect tweets that mention prominent German politicians and annotate them for stance. We find that the formality of naming in these tweets correlates positively with their stance. This confirms sociolinguistic observations that naming and titling can have a status-indicating function and suggests that this function is dominant in German tweets mentioning political figures. We also find that this status-indicating function is much weaker in tweets from users that are politically left-leaning than in tweets by right-leaning users. This is in line with observations from moral psychology that left-leaning and right-leaning users assign different importance to maintaining social hierarchies."
2020.lrec-1.616,Enhancing a Lexicon of Polarity Shifters through the Supervised Classification of Shifting Directions,2020,-1,-1,2,1,14816,marc schulder,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The sentiment polarity of an expression (whether it is perceived as positive, negative or neutral) can be influenced by a number of phenomena, foremost among them negation. Apart from closed-class negation words like {``}no{''}, {``}not{''} or {``}without{''}, negation can also be caused by so-called polarity shifters. These are content words, such as verbs, nouns or adjectives, that shift polarities in their opposite direction, e.g. {``}abandoned{''} in {``}abandoned hope{''} or {``}alleviate{''} in {``}alleviate pain{''}. Many polarity shifters can affect both positive and negative polar expressions, shifting them towards the opposing polarity. However, other shifters are restricted to a single shifting direction. {``}Recoup{''} shifts negative to positive in {``}recoup your losses{''}, but does not affect the positive polarity of {``}fortune{''} in {``}recoup a fortune{''}. Existing polarity shifter lexica only specify whether a word can, in general, cause shifting, but they do not specify when this is limited to one shifting direction. To address this issue we introduce a supervised classifier that determines the shifting direction of shifters. This classifier uses both resource-driven features, such as WordNet relations, and data-driven features like in-context polarity conflicts. Using this classifier we enhance the largest available polarity shifter lexicon."
W19-2101,Not My President: How Names and Titles Frame Political Figures,2019,-1,-1,4,1,17870,esther berg,Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science,0,"Naming and titling have been discussed in sociolinguistics as markers of status or solidarity. However, these functions have not been studied on a larger scale or for social media data. We collect a corpus of tweets mentioning presidents of six G20 countries by various naming forms. We show that naming variation relates to stance towards the president in a way that is suggestive of a framing effect mediated by respectfulness. This confirms sociolinguistic theory of naming and titling as markers of status."
N19-1060,{D}etection of {A}busive {L}anguage: the {P}roblem of {B}iased {D}atasets,2019,0,15,1,1,3381,michael wiegand,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,We discuss the impact of data bias on abusive language detection. We show that classification scores on popular datasets reported in previous work are much lower under realistic settings in which this bias is reduced. Such biases are most notably observed on datasets that are created by focused sampling instead of random sampling. Datasets with a higher proportion of implicit abuse are more affected than datasets with a lower proportion.
N19-1211,{D}etecting {D}erogatory {C}ompounds {--} {A}n {U}nsupervised {A}pproach,2019,0,0,1,1,3381,michael wiegand,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,We examine the new task of detecting derogatory compounds (e.g. {``}curry muncher{''}). Derogatory compounds are much more difficult to detect than derogatory unigrams (e.g. {``}idiot{''}) since they are more sparsely represented in lexical resources previously found effective for this task (e.g. Wiktionary). We propose an unsupervised classification approach that incorporates linguistic properties of compounds. It mostly depends on a simple distributional representation. We compare our approach against previously established methods proposed for extracting derogatory unigrams.
N18-1095,Inducing a Lexicon of Abusive Words {--} a Feature-Based Approach,2018,0,3,1,1,3381,michael wiegand,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,We address the detection of abusive words. The task is to identify such words among a set of negative polar expressions. We propose novel features employing information from both corpora and lexical resources. These features are calibrated on a small manually annotated base lexicon which we use to produce a large lexicon. We show that the word-level information we learn cannot be equally derived from a large dataset of annotated microposts. We demonstrate the effectiveness of our (domain-independent) lexicon in the cross-domain detection of abusive microposts.
L18-1097,Disambiguation of Verbal Shifters,2018,0,0,1,1,3381,michael wiegand,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1222,Introducing a Lexicon of Verbal Polarity Shifters for {E}nglish,2018,0,1,2,1,14816,marc schulder,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1213,Automatically Creating a Lexicon of Verbal Polarity Shifters: Mono- and Cross-lingual Methods for {G}erman,2018,0,0,2,1,14816,marc schulder,Proceedings of the 27th International Conference on Computational Linguistics,0,"In this paper we use methods for creating a large lexicon of verbal polarity shifters and apply them to German. Polarity shifters are content words that can move the polarity of a phrase towards its opposite, such as the verb {``}abandon{''} in {``}abandon all hope{''}. This is similar to how negation words like {``}not{''} can influence polarity. Both shifters and negation are required for high precision sentiment analysis. Lists of negation words are available for many languages, but the only language for which a sizable lexicon of verbal polarity shifters exists is English. This lexicon was created by bootstrapping a sample of annotated verbs with a supervised classifier that uses a set of data- and resource-driven features. We reproduce and adapt this approach to create a German lexicon of verbal polarity shifters. Thereby, we confirm that the approach works for multiple languages. We further improve classification by leveraging cross-lingual information from the English shifter lexicon. Using this improved approach, we bootstrap a large number of German verbal polarity shifters, reducing the annotation effort drastically. The resulting German lexicon of verbal polarity shifters is made publicly available."
C18-1325,Distinguishing affixoid formations from compounds,2018,0,0,2,0,3382,josef ruppenhofer,Proceedings of the 27th International Conference on Computational Linguistics,0,"We study German affixoids, a type of morpheme in between affixes and free stems. Several properties have been associated with them {--} increased productivity; a bleached semantics, which is often evaluative and/or intensifying and thus of relevance to sentiment analysis; and the existence of a free morpheme counterpart {--} but not been validated empirically. In experiments on a new data set that we make available, we put these key assumptions from the morphological literature to the test and show that despite the fact that affixoids generate many low-frequency formations, we can classify these as affixoid or non-affixoid instances with a best F1-score of 74{\%}."
W17-1101,A Survey on Hate Speech Detection using Natural Language Processing,2017,26,140,2,0,29435,anna schmidt,Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media,0,"This paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing. Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing. We also discuss limits of those approaches."
ruppenhofer-etal-2017-evaluating,Evaluating the morphological compositionality of polarity,2017,16,1,3,0.283427,3382,josef ruppenhofer,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Unknown words are a challenge for any NLP task, including sentiment analysis. Here, we evaluate the extent to which sentiment polarity of complex words can be predicted based on their morphological make-up. We do this on German as it has very productive processes of derivation and compounding and many German hapax words, which are likely to bear sentiment, are morphologically complex. We present results of supervised classification experiments on new datasets with morphological parses and polarity annotations."
I17-1063,Towards Bootstrapping a Polarity Shifter Lexicon using Linguistic Features,2017,34,4,2,1,14816,marc schulder,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"We present a major step towards the creation of the first high-coverage lexicon of polarity shifters. In this work, we bootstrap a lexicon of verbs by exploiting various linguistic features. Polarity shifters, such as {``}abandon{''}, are similar to negations (e.g. {``}not{''}) in that they move the polarity of a phrase towards its inverse, as in {``}abandon all hope{''}. While there exist lists of negation words, creating comprehensive lists of polarity shifters is far more challenging due to their sheer number. On a sample of manually annotated verbs we examine a variety of linguistic features for this task. Then we build a supervised classifier to increase coverage. We show that this approach drastically reduces the annotation effort while ensuring a high-precision lexicon. We also show that our acquired knowledge of verbal polarity shifters improves phrase-level sentiment analysis."
N16-1092,Separating Actor-View from Speaker-View Opinion Expressions using Linguistic Features,2016,20,0,1,1,3381,michael wiegand,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We examine different features and classifiers for the categorization of opinion words into actor and speaker view. To our knowledge, this is the first comprehensive work to address sentiment views on the word level taking into consideration opinion verbs, nouns and adjectives. We consider many high-level features requiring only few labeled training data. A detailed feature analysis produces linguistic insights into the nature of sentiment views. We also examine how far global constraints between different opinion words help to increase classification performance. Finally, we show that our (prior) word-level annotation correlates with contextual sentiment views."
N16-1094,Opinion Holder and Target Extraction on Opinion Compounds {--} A Linguistic Approach,2016,42,5,1,1,3381,michael wiegand,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present an approach to the new task of opinion holder and target extraction on opinion compounds. Opinion compounds (e.g. user rating or victim support) are noun compounds whose head is an opinion noun. We do not only examine features known to be effective for noun compound analysis, such as paraphrases and semantic classes of heads and modifiers, but also propose novel features tailored to this new task. Among them, we examine paraphrases that jointly consider holders and targets, a verb detour in which noun heads are replaced by related verbs, a global head constraint allowing inferencing between different compounds, and the categorization of the sentiment view that the head conveys."
W15-2921,Opinion Holder and Target Extraction for Verb-based Opinion Predicates {--} The Problem is Not Solved,2015,30,1,1,1,3381,michael wiegand,"Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,We offer a critical review of the current state of opinion role extraction involving opinion verbs. We argue that neither the currently available lexical resources nor the manually annotated text corpora are sufficient to appropriately study this task. We introduce a new corpus focusing on opinion roles of opinion verbs from the Subjectivity Lexicon and show potential benefits of this corpus. We also demonstrate that state-of-the-art classifiers perform rather poorly on this new dataset compared to the standard dataset for the task showing that there still remains significant research to be done.
R15-1071,Ordering adverbs by their scaling effect on adjective intensity,2015,26,5,4,0.4346,3382,josef ruppenhofer,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"In recent years, theoretical and computational linguistics has paid much attention to linguistic items that form scales. In NLP, much research has focused on ordering adjectives by intensity (tiny < small). Here, we address the task of automatically ordering English adverbs by their intensifying or diminishing effect on adjectives (e.g. extremely small < very small). We experiment with 4 different methods: 1) using the association strength between adverbs and adjectives; 2) exploiting scalar patterns (such as not only X but Y); 3) using the metadata of product reviews; 4) clustering. The method that performs best is based on the use of metadata and ranks adverbs by their scaling factor relative to unmodified adjectives."
K15-1022,Opinion Holder and Target Extraction based on the Induction of Verbal Categories,2015,40,7,1,1,3381,michael wiegand,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"We present an approach for opinion role induction for verbal predicates. Our model rests on the assumption that opinion verbs can be divided into three different types where each type is associated with a characteristic mapping between semantic roles and opinion holders and targets. In several experiments, we demonstrate the relevance of those three categories for the task. We show that verbs can easily be categorized with semi-supervised graphbased clustering and some appropriate similarity metric. The seeds are obtained through linguistic diagnostics. We evaluate our approach against a new manually-compiled opinion role lexicon and perform in-context classification."
E14-4023,Comparing methods for deriving intensity scores for adjectives,2014,22,9,2,0.4346,3382,josef ruppenhofer,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"We compare several different corpusbased and lexicon-based methods for the scalar ordering of adjectives. Among them, we examine for the first time a lowresource approach based on distinctivecollexeme analysis that just requires a small predefined set of adverbial modifiers. While previous work on adjective intensity mostly assumes one single scale for all adjectives, we group adjectives into different scales which is more faithful to human perception. We also apply the methods to both polar and non-polar adjectives, showing that not all methods are equally suitable for both types of adjectives."
E14-1071,Automatic Food Categorization from Large Unlabeled Corpora and Its Impact on Relation Extraction,2014,33,4,1,1,3381,michael wiegand,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present a weakly-supervised induction method to assign semantic information to food items. We consider two tasks of categorizations being food-type classification and the distinction of whether a food item is composite or not. The categorizations are induced by a graph-based algorithm applied on a large unlabeled domain-specific corpus. We show that the usage of a domain-specific corpus is vital. We do not only outperform a manually designed open-domain ontology but also prove the usefulness of these categorizations in relation extraction, outperforming state-of-the-art features that include syntactic information and Brown clustering."
C14-1216,Separating Brands from Types: an Investigation of Different Features for the Food Domain,2014,26,1,1,1,3381,michael wiegand,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We examine the task of separating types from brands in the food domain. Framing the problem as a ranking task, we convert simple textual features extracted from a domain-specific corpus into a ranker without the need of labeled training data. Such method should rank brands (e.g. sprite) higher than types (e.g. lemonade). Apart from that, we also exploit knowledge induced by semisupervised graph-based clustering for two different purposes. On the one hand, we produce an auxiliary categorization of food items according to the Food Guide Pyramid, and assume that a food item is a type when it belongs to a category unlikely to contain brands. On the other hand, we directly model the task of brand detection using seeds provided by the output of the textual ranking features. We also harness Wikipedia articles as an additional knowledge source."
W13-1108,Towards the Detection of Reliable Food-Health Relationships,2013,27,5,1,1,3381,michael wiegand,Proceedings of the Workshop on Language Analysis in Social Media,0,"We investigate the task of detecting reliable statements about food-health relationships from natural language texts. For that purpose, we created a specially annotated web corpus from forum entries discussing the healthiness of certain food items. We examine a set of task-specific features (mostly) based on linguistic insights that are instrumental in finding utterances that are commonly perceived as reliable. These features are incorporated in a supervised classifier and compared against standard features that are widely used for various tasks in natural language processing, such as bag of words, part-of speech and syntactic parse information."
N13-1059,Predicative Adjectives: An Unsupervised Criterion to Extract Subjective Adjectives,2013,10,2,1,1,3381,michael wiegand,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We examine predicative adjectives as an unsupervised criterion to extract subjective adjectives. We do not only compare this criterion with a weakly supervised extraction method but also with gradable adjectives, i.e. another highly subjective subset of adjectives that can be extracted in an unsupervised fashion. In order to prove the robustness of this extraction method, we will evaluate the extraction with the help of two different state-of-the-art sentiment lexicons (as a gold standard)."
I13-1003,Towards Contextual Healthiness Classification of Food Items - A Linguistic Approach,2013,25,3,1,1,3381,michael wiegand,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We explore the feasibility of contextual healthiness classification of food items. We present a detailed analysis of the linguistic phenomena that need to be taken into consideration for this task based on a specially annotated corpus extracted from web forum entries. For automatic classification, we compare a supervised classifier and rule-based classification. Beyond linguistically motivated features that include sentiment information we also consider the prior healthiness of food items."
clematide-etal-2012-mlsa,{MLSA} {---} A Multi-layered Reference Corpus for {G}erman Sentiment Analysis,2012,16,20,8,0,1321,simon clematide,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we describe MLSA, a publicly available multi-layered reference corpus for German-language sentiment analysis. The construction of the corpus is based on the manual annotation of 270 German-language sentences considering three different layers of granularity. The sentence-layer annotation, as the most coarse-grained annotation, focuses on aspects of objectivity, subjectivity and the overall polarity of the respective sentences. Layer 2 is concerned with polarity on the word- and phrase-level, annotating both subjective and factual language. The annotations on Layer 3 focus on the expression-level, denoting frames of private states such as objective and direct speech events. These three layers and their respective annotations are intended to be fully independent of each other. At the same time, exploring for and discovering interactions that may exist between different layers should also be possible. The reliability of the respective annotations was assessed using the average pairwise agreement and Fleiss' multi-rater measures. We believe that MLSA is a beneficial resource for sentiment analysis research, algorithms and applications that focus on the German language."
wiegand-etal-2012-gold,A Gold Standard for Relation Extraction in the Food Domain,2012,15,10,1,1,3381,michael wiegand,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present a gold standard for semantic relation extraction in the food domain for German. The relation types that we address are motivated by scenarios for which IT applications present a commercial potential, such as virtual customer advice in which a virtual agent assists a customer in a supermarket in finding those products that satisfy their needs best. Moreover, we focus on those relation types that can be extracted from natural language text corpora, ideally content from the internet, such as web forums, that are easy to retrieve. A typical relation type that meets these requirements are pairs of food items that are usually consumed together. Such a relation type could be used by a virtual agent to suggest additional products available in a shop that would potentially complement the items a customer has already in their shopping cart. Our gold standard comprises structural data, i.e. relation tables, which encode relation instances. These tables are vital in order to evaluate natural language processing systems that extract those relations."
E12-1033,Generalization Methods for In-Domain and Cross-Domain Opinion Holder Extraction,2012,32,8,1,1,3381,michael wiegand,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper, we compare three different generalization methods for in-domain and cross-domain opinion holder extraction being simple unsupervised word clustering, an induction method inspired by distant supervision and the usage of lexical resources. The generalization methods are incorporated into diverse classifiers. We show that generalization causes significant improvements and that the impact of improvement depends on the type of classifier and on how much training and test data differ from each other. We also address the less common case of opinion holders being realized in patient position and suggest approaches including a novel (linguistically-informed) extraction method how to detect those opinion holders without labeled training data as standard datasets contain too few instances of this type."
W11-4635,Convolution Kernels for Subjectivity Detection,2011,-1,-1,1,1,3381,michael wiegand,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,None
W11-4004,The Role of Predicates in Opinion Holder Extraction,2011,-1,-1,1,1,3381,michael wiegand,Proceedings of the {RANLP} 2011 Workshop on Information Extraction and Knowledge Acquisition,0,None
R11-1039,Prototypical Opinion Holders: What We can Learn from Experts and Analysts,2011,18,4,1,1,3381,michael wiegand,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"In order to automatically extract opinion holders, we propose to harness the contexts of prototypical opinion holders, i.e. common nouns, such as experts or analysts, that describe particular groups of people whose profession or occupation is to form and express opinions towards specific items. We assess their effectiveness in supervised learning where these contexts are regarded as labeled training data and in rule-based classification which uses predicates that frequently co-occur with mentions of the prototypical opinion holders. Finally, we also examine in how far knowledge gained from these contexts can compensate the lack of large amounts of labeled training data in supervised learning by considering various amounts of actually labeled training sets."
W10-3111,A survey on the role of negation in sentiment analysis,2010,23,144,1,1,3381,michael wiegand,Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,0,"This paper presents a survey on the role of negation in sentiment analysis. Negation is a very common linguistic construction that affects polarity and, therefore, needs to be taken into consideration in sentiment analysis.n n We will present various computational approaches modeling negation in sentiment analysis. We will, in particular, focus on aspects, such as level of representation used for sentiment analysis, negation word detection and scope of negation. We will also discuss limits and challenges of negation modeling on that task."
N10-1121,Convolution Kernels for Opinion Holder Extraction,2010,24,38,1,1,3381,michael wiegand,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Opinion holder extraction is one of the important subtasks in sentiment analysis. The effective detection of an opinion holder depends on the consideration of various cues on various levels of representation, though they are hard to formulate explicitly as features. In this work, we propose to use convolution kernels for that task which identify meaningful fragments of sequences or trees by themselves. We not only investigate how different levels of information can be effectively combined in different kernels but also examine how the scope of these kernels should be chosen. In general relation extraction, the two candidate entities thought to be involved in a relation are commonly chosen to be the boundaries of sequences and trees. The definition of boundaries in opinion holder extraction, however, is less straightforward since there might be several expressions beside the candidate opinion holder to be eligible for being a boundary."
wiegand-klakow-2010-predictive,Predictive Features for Detecting Indefinite Polar Sentences,2010,14,0,1,1,3381,michael wiegand,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In recent years, text classification in sentiment analysis has mostly focused on two types of classification, the distinction between objective and subjective text, i.e. subjectivity detection, and the distinction between positive and negative subjective text, i.e. polarity classification. So far, there has been little work examining the distinction between definite polar subjectivity and indefinite polar subjectivity. While the former are utterances which can be categorized as either positive or negative, the latter cannot be categorized as either of these two categories. This paper presents a small set of domain independent features to detect indefinite polar sentences. The features reflect the linguistic structure underlying these types of utterances. We give evidence for the effectiveness of these features by incorporating them into an unsupervised rule-based classifier for sentence-level analysis and compare its performance with supervised machine learning classifiers, i.e. Support Vector Machines (SVMs) and Nearest Neighbor Classifier (kNN). The data used for the experiments are web-reviews collected from three different domains."
W09-4628,Predictive Features in Semi-Supervised Learning for Polarity Classification and the Role of Adjectives,2009,18,3,1,1,3381,michael wiegand,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"In opinion mining, there has been only very little work investigating semi-supervised machine learning on document-level polarity classification. We show that semi-supervised learning performs significantly better than supervised learning when only few labeled data are available. Semi-supervised polarity classifiers rely on a predictive feature set. (Semi-)Manually built polarity lexicons are one option but they are expensive to obtain and do not necessarily work in an unknown domain. We show that extracting frequently occurring adjectives & adverbs of an unlabeled set of in-domain documents is an inexpensive alternative which works equally well throughout different domains."
wiegand-etal-2008-cost,Cost-Sensitive Learning in Answer Extraction,2008,7,1,1,1,3381,michael wiegand,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"One problem of data-driven answer extraction in open-domain factoid question answering is that the class distribution of labeled training data is fairly imbalanced. In an ordinary training set, there are far more incorrect answers than correct answers. The class-imbalance is, thus, inherent to the classification task. It has a deteriorating effect on the performance of classifiers trained by standard machine learning algorithms. They usually have a heavy bias towards the majority class, i.e. the class which occurs most often in the training set. In this paper, we propose a method to tackle class imbalance by applying some form of cost-sensitive learning which is preferable to sampling. We present a simple but effective way of estimating the misclassification costs on the basis of class distribution. This approach offers three benefits. Firstly, it maintains the distribution of the classes of the labeled training data. Secondly, this form of meta-learning can be applied to a wide range of common learning algorithms. Thirdly, this approach can be easily implemented with the help of state-of-the-art machine learning software."
