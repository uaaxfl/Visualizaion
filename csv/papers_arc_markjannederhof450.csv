2021.motra-1.10,Automatic Classification of Human Translation and Machine Translation: A Study from the Perspective of Lexical Diversity,2021,-1,-1,2,0,5268,yingxue fu,Proceedings for the First Workshop on Modelling Translation: Translatology in the Digital Age,0,None
2021.eacl-main.193,Calculating the optimal step of arc-eager parsing for non-projective trees,2021,-1,-1,1,1,5269,markjan nederhof,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"It is shown that the optimal next step of an arc-eager parser relative to a non-projective dependency structure can be calculated in cubic time, solving an open problem in parsing theory. Applications are in training of parsers by means of a {`}dynamic oracle{'}."
W19-3109,Regular transductions with {MCFG} input syntax,2019,0,0,1,1,5269,markjan nederhof,Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing,0,We show that regular transductions for which the input part is generated by some multiple context-free grammar can be simulated by synchronous multiple context-free grammars. We prove that synchronous multiple context-free grammars are strictly more powerful than this combination of regular transductions and multiple context-free grammars.
Q19-1018,Calculating the Optimal Step in Shift-Reduce Dependency Parsing: From Cubic to Linear Time,2019,4,0,1,1,5269,markjan nederhof,Transactions of the Association for Computational Linguistics,0,"We present a new cubic-time algorithm to calculate the optimal next step in shift-reduce dependency parsing, relative to ground truth, commonly referred to as dynamic oracle. Unlike existing algorithms, it is applicable if the training corpus contains non-projective structures. We then show that for a projective training corpus, the time complexity can be improved from cubic to linear."
J17-3001,Hybrid Grammars for Parsing of Discontinuous Phrase Structures and Non-Projective Dependency Structures,2017,93,1,2,0,18860,kilian gebhardt,Computational Linguistics,0,"We explore the concept of hybrid grammars, which formalize and generalize a range of existing frameworks for dealing with discontinuous syntactic structures. Covered are both discontinuous phrase structures and non-projective dependency structures. Technically, hybrid grammars are related to synchronous grammars, where one grammar component generates linear structures and another generates hierarchical structures. By coupling lexical elements of both components together, discontinuous structures result. Several types of hybrid grammars are characterized. We also discuss grammar induction from treebanks. The main advantage over existing frameworks is the ability of hybrid grammars to separate discontinuity of the desired structures from time complexity of parsing. This permits exploration of a large variety of parsing algorithms for discontinuous structures, with different properties. This is confirmed by the reported experimental results, which show a wide variety of running time, accuracy, and frequency of parse failures."
W16-2403,Transition-based dependency parsing as latent-variable constituent parsing,2016,49,1,1,1,5269,markjan nederhof,Proceedings of the {SIGFSM} Workshop on Statistical {NLP} and Weighted Automata,0,"We provide a theoretical argument that a common form of projective transitionbased dependency parsing is less powerful than constituent parsing using latent variables. The argument is a proof that, under reasonable assumptions, a transition-based dependency parser can be converted to a latent-variable context-free grammar producing equivalent structures."
W16-2340,{DTED}: Evaluation of Machine Translation Structure Using Dependency Parsing and Tree Edit Distance,2016,27,2,2,0,33892,martin mccaffery,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"We present DTED, a submission to the WMT 2016 Metrics Task using structural information generated by dependency parsing and evaluated using tree edit distances. In this paper we apply this system to translations produced during WMT 2015, and compare our scores with human rankings from that year. We find moderate correlations, despite the human judgements being based on all aspects of the sentences while our metric is based only on word order."
P16-1106,A short proof that O{\\_}2 is an {MCFL},2016,7,0,1,1,5269,markjan nederhof,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
W15-4804,Count-based State Merging for Probabilistic Regular Tree Grammars,2015,11,0,2,0,33878,toni dietze,"Proceedings of the 12th International Conference on Finite-State Methods and Natural Language Processing 2015 ({FSMNLP} 2015 D{\\\u}sseldorf)""",0,"We present an approach to obtain language models from a tree corpus using probabilistic regular tree grammars (prtg). Starting with a prtg only generating trees from the corpus, the prtg is generalized step by step by merging nonterminals. We focus on bottom-up deterministic prtg to simplify the calculations."
W15-4810,A Probabilistic Model of {A}ncient {E}gyptian Writing,2015,0,1,1,1,5269,markjan nederhof,"Proceedings of the 12th International Conference on Finite-State Methods and Natural Language Processing 2015 ({FSMNLP} 2015 D{\\\u}sseldorf)""",0,None
E14-1036,Deterministic Parsing using {PCFG}s,2014,35,2,1,1,5269,markjan nederhof,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,We propose the design of deterministic constituent parsers that choose parser actions according to the probabilities of parses of a given probabilistic context-free grammar. Several variants are presented. One of these deterministically constructs a parse structure while postponing commitment to labels. We investigate theoretical time complexities and report experiments.
C14-1130,Hybrid Grammars for Discontinuous Parsing,2014,44,5,1,1,5269,markjan nederhof,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We introduce the concept of hybrid grammars, which are extensions of synchronous grammars, obtained by coupling of lexical elements. One part of a hybrid grammar generates linear structures, another generates hierarchical structures, and together they generate discontinuous structures. This formalizes and generalizes some existing mechanisms for dealing with discontinuous phrase structures and non-projective dependency structures. Moreover, it allows us to separate the degree of discontinuity from the time complexity of parsing."
W12-4607,Synchronous Context-Free Tree Grammars,2012,28,8,1,1,5269,markjan nederhof,Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+11),0,"We consider pairs of context-free tree grammars combined through synchronous rewriting. The resulting formalism is at least as powerful as synchronous tree adjoining grammars and linear, nondeleting macro tree transducers, while the parsing complexity remains polynomial. Its power is subsumed by context-free hypergraph grammars. The new formalism has an alternative characterization in terms of bimorphisms. An advantage over synchronous variants of linear context-free rewriting systems is the ability to specify tree-to-tree transductions."
W11-4401,Intersection for Weighted Formalisms,2011,10,0,1,1,5269,markjan nederhof,Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing,0,"The paradigm of parsing as intersection has been used throughout the literature to obtain elegant and general solutions to numerous problems involving grammars and automata. The paradigm has its origins in (Bar-Hillel et al., 1964), where a general construction was used to prove closure of context-free languages under intersection with regular languages. It was pointed out by (Lang, 1994) that such a construction isolates the parsing problem from the recognition problem. The latter can be solved by a reduction of the outcome of intersection.n n The paradigm has been extended in various ways, by considering more powerful formalisms, such as tree adjoining grammars (Vijay-Shanker and Weir, 1993), simple RCGs (Bertsch and Nederhof, 2001), tree grammars (Nederhof, 2009), and probabilistic extensions of grammatical formalisms (Nederhof and Satta, 2003). Different applications have been identified, such as computation of distances between languages (Nederhof and Satta, 2008), and parameter estimation of probabilistic models (Nederhof, 2005).n n The lecture will focus on another application, namely the computation of prefix probabilities (Nederhof and Satta, 2011c) and infix probabilities (Nederhof and Satta, 2011a) and will address novel generalisations to linear context-free rewriting systems (Nederhof and Satta, 2011b)."
W11-2903,Tree Parsing with Synchronous {T}ree-{A}djoining {G}rammars,2011,48,6,2,0,41469,matthias buchse,Proceedings of the 12th International Conference on Parsing Technologies,0,"Restricting the input or the output of a grammar-induced translation to a given set of trees plays an important role in statistical machine translation. The problem for practical systems is to find a compact (and in particular, finite) representation of said restriction. For the class of synchronous tree-adjoining grammars, partial solutions to this problem have been described, some being restricted to the unweighted case, some to the monolingual case. We introduce a formulation of this class of grammars which is effectively closed under input and output restrictions to regular tree languages, i.e., the restricted translations can again be represented by grammars. Moreover, we present an algorithm that constructs these grammars for input and output restriction, which is inspired by Earley's algorithm."
W11-2919,Prefix Probabilities for Linear Context-Free Rewriting Systems,2011,33,1,1,1,5269,markjan nederhof,Proceedings of the 12th International Conference on Parsing Technologies,0,"We present a novel method for the computation of prefix probabilities for linear context-free rewriting systems. Our approach streamlines previous procedures to compute prefix probabilities for context-free grammars, synchronous context-free grammars and tree adjoining grammars. In addition, the methodology is general enough to be used for a wider range of problems involving, for example, several prefixes."
W11-2928,Parsing of Partially Bracketed Structures for Parse Selection,2011,15,0,1,1,5269,markjan nederhof,Proceedings of the 12th International Conference on Parsing Technologies,0,"We consider the problem of parsing a sentence that is partially annotated with information about where phrases start and end. The application domain is interactive parse selection with probabilistic grammars. It is explained that the main obstacle is spurious ambiguity. The proposed solution is first described in terms of appropriately constrained synchronous grammars, and then in terms of a computational model for parsing. Experiments show the feasibility for a practical grammar."
P11-1047,Prefix Probability for Probabilistic Synchronous Context-Free Grammars,2011,19,4,1,1,5269,markjan nederhof,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present a method for the computation of prefix probabilities for synchronous context-free grammars. Our framework is fairly general and relies on the combination of a simple, novel grammar transformation and standard techniques to bring grammars into normal forms."
J11-4009,Splittability of Bilexical Context-Free Grammars is Undecidable,2011,10,0,1,1,5269,markjan nederhof,Computational Linguistics,0,"Bilexical context-free grammars (2-LCFGs) have proved to be accurate models for statistical natural language parsing. Existing dynamic programming algorithms used to parse sentences under these models have running time of O(xc3xa2xcbx86xc2xa3wxc3xa2xcbx86xc2xa34), where w is the input string.n n A 2-LCFG is splittable if the left arguments of a lexical head are always independent of the right arguments, and vice versa. When a 2-LCFGs is splittable, parsing time can be asymptotically improved to O(xc3xa2xcbx86xc2xa3wxc3xa2xcbx86xc2xa33). Testing this property is therefore of central interest to parsing efficiency. In this article, however, we show the negative result that splittability of 2-LCFGs is undecidable."
D11-1112,Computation of Infix Probabilities for Probabilistic Context-Free Grammars,2011,25,8,1,1,5269,markjan nederhof,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"The notion of infix probability has been introduced in the literature as a generalization of the notion of prefix (or initial substring) probability, motivated by applications in speech recognition and word error correction. For the case where a probabilistic context-free grammar is used as language model, methods for the computation of infix probabilities have been presented in the literature, based on various simplifying assumptions. Here we present a solution that applies to the problem in its full generality."
W10-2505,Transforming Lexica as Trees,2010,10,0,1,1,5269,markjan nederhof,Proceedings of the 2010 Workshop on Applications of Tree Automata in Natural Language Processing,0,"We investigate the problem of structurally changing lexica, while preserving the information. We present a type of lexicon transformation that is complete on an interesting class of lexica. Our work is motivated by the problem of merging one or more lexica into one lexicon. Lexica, lexicon schemas, and lexicon transformations are all seen as particular kinds of trees."
W09-3802,Weighted parsing of trees,2009,27,6,1,1,5269,markjan nederhof,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We show how parsing of trees can be formalized in terms of the intersection of two tree languages. The focus is on weighted regular tree grammars and weighted tree adjoining grammars. Potential applications are discussed, such as parameter estimation across formalisms."
N06-1044,Estimation of Consistent Probabilistic Context-free Grammars,2006,14,12,1,1,5269,markjan nederhof,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"We consider several empirical estimators for probabilistic context-free grammars, and show that the estimated grammars have the so-called consistency property, under the most general conditions. Our estimators include the widely applied expectation maximization method, used to estimate probabilistic context-free grammars on the basis of unannotated corpora. This solves a problem left open in the literature, since for this method the consistency property has been shown only under restrictive assumptions on the rules of the source grammar."
kemps-snijders-etal-2006-lexus,"{LEXUS}, a web-based tool for manipulating lexical resources lexicon",2006,0,0,2,0,35127,marc kempssnijders,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"LEXUS provides a flexible framework for the maintaining lexical structure and content. It is the first implementation of the Lexical Markup Framework model currently being developed at ISO TC37/SC4. Amongst its capabilities are the possibility to create lexicon structures, manipulate content and use of typed relations. Integration of well established Data Category Registries is supported to further promote interoperability by allowing access to well established linguistic concepts. Advanced linguistic functionality is offered to assist users in cross lexica operations such as search and comparison and merging of lexica. To enable use within various user groups the look and feel of each lexicon may be customized. In the near future more functionality will be added including integration with other tools accessing lexical content."
J05-2002,A General Technique to Train Language Models on Language Models,2005,19,21,1,1,5269,markjan nederhof,Computational Linguistics,0,"We show that under certain conditions, a language model can be trained on the basis of a second language model. The main instance of the technique trains a finite automaton on the basis of a probabilistic context-free grammar, such that the Kullback-Leibler distance between grammar and trained automaton is provably minimal. This is a substantial generalization of an existing algorithm to train an n-gram model on the basis of a probabilistic context-free grammar."
P04-1069,Probabilistic Parsing Strategies,2004,26,5,1,1,5269,markjan nederhof,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,We present new results on the relation between context-free parsing strategies and their probabilistic counter-parts. We provide a necessary condition and a sufficient condition for the probabilistic extension of parsing strategies. These results generalize existing results in the literature that were obtained by considering parsing strategies in isolation.
P04-1070,An Alternative Method of Training Probabilistic {LR} Parsers,2004,26,3,1,1,5269,markjan nederhof,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"We discuss existing approaches to train LR parsers, which have been used for statistical resolution of structural ambiguity. These approaches are nonoptimal, in the sense that a collection of probability distributions cannot be obtained. In particular, some probability distributions expressible in terms of a context-free grammar cannot be expressed in terms of the LR parser constructed from that grammar, under the restrictions of the existing approaches to training of LR parsers. We present an alternative way of training that is provably optimal, and that allows all probability distributions expressible in the context-free grammar to be carried over to the LR parser. We also demonstrate empirically that this kind of training can be effectively applied on a large treebank."
C04-1011,{K}ullback-{L}eibler Distance between Probabilistic Context-Free Grammars and Probabilistic Finite Automata,2004,18,10,1,1,5269,markjan nederhof,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"We consider the problem of computing the Kullback-Leibler distance, also called the relative entropy, between a probabilistic context-free grammar and a probabilistic finite automaton. We show that there is a closed-form (analytical) solution for one part of the Kullback-Leibler distance, viz. the cross-entropy. We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata."
W03-3016,Probabilistic Parsing as Intersection,2003,0,38,1,1,5269,markjan nederhof,Proceedings of the Eighth International Conference on Parsing Technologies,0,"We show that a well-known algorithm to compute the intersection of a context-fre language and a regular language can be extended to apply to a probabilistic context-free grammar and a probabilistic finite automaton, provided the two probabilistic models are combined through multiplication. The result is a probabilistic context-free grammar that contains joint information about the original grammar and automaton."
W03-3020,Partially Ordered Multiset Context-free Grammars and Free-word-order Parsing,2003,10,5,1,1,5269,markjan nederhof,Proceedings of the Eighth International Conference on Parsing Technologies,0,"We present a new formalism, partially ordered multiset context-free grammars (poms-CFG), along with an Earley-style parsing algorithm. The formalism, which can be thought of as a generalization of context-free grammars with partially ordered right-hand sides, is of interest in its own right, and also as infrastructure for obtaining tighter complexity bounds for more expressive context-free formalisms intended to express free or multiple word-order, such as ID/LP grammars. We reduce ID/LP grammars to poms-grammars, thereby getting finer-grained bounds on the parsing complexity of ID/LP grammars. We argue that in practice, the width of attested ID/LP grammars is small, yielding effectively polynomial time complexity for ID/LP grammar parsing."
J03-1006,Squibs and Discussions: Weighted Deductive Parsing and {K}nuth{'}s Algorithm,2003,25,56,1,1,5269,markjan nederhof,Computational Linguistics,0,We discuss weighted deductive parsing and consider the problem of finding the derivation with the lowest weight. We show that Knuth's generalization of Dijkstra's algorithm for the shortest-path problem offers a general method to solve this problem. Our approach is modular in the sense that Knuth's algorithm is formulated independently from the weighted deduction system.
P02-1015,Parsing non-recursive {CFG}s,2002,5,13,1,1,5269,markjan nederhof,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We consider the problem of parsing non-recursive context-free grammars, i.e., context-free grammars that generate finite languages. In natural language processing, this problem arises in several areas of application, including natural language generation, speech recognition and machine translation. We present two tabular algorithms for parsing of non-recursive context-free grammars, and show that they perform well in practical settings, despite the fact that this problem is PSPACE-complete."
W01-1807,On the Complexity of Some Extensions of {RCG} Parsing,2001,0,24,2,0,53740,eberhard bertsch,Proceedings of the Seventh International Workshop on Parsing Technologies,0,None
W01-1404,Approximating Context-Free by Rational Transduction for Example-Based {MT},2001,13,2,1,1,5269,markjan nederhof,Proceedings of the {ACL} 2001 Workshop on Data-Driven Methods in Machine Translation,0,"Existing studies show that a weighted context-free transduction of reasonable quality can be effectively learned from examples. This paper investigates the approximation of such transduction by means of weighted rational transduction. The advantage is increased processing speed, which benefits real-time applications involving spoken language."
J00-1003,Practical Experiments with Regular Approximation of Context-Free Languages,2000,31,86,1,1,5269,markjan nederhof,Computational Linguistics,0,"Several methods are discussed that construct a finite automaton given a context-free grammar, including both methods that lead to subsets and those that lead to supersets of the original context-free language. Some of these methods of regular approximation are new, and some others are presented here in a more refined form with respect to existing literature. Practical experiments with the different methods of regular approximation are performed for spoken-language input: hypotheses from a speech recognizer are filtered through a finite automaton."
A00-2036,Left-To-Right Parsing and Bilexical Context-Free Grammars,2000,27,4,1,1,5269,markjan nederhof,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We compare the asymptotic time complexity of left-to-right and bidirectional parsing techniques for bilexical context-free grammars, a grammar formalism that is an abstraction of language models used in several state-of-the-art real-world parsers. We provide evidence that left-to-right parsing cannot be realised within acceptable time-bounds if the so called correct-prefix property is to be ensured. Our evidence is based on complexity results for the representation of regular languages."
J99-3002,The Computational Complexity of the Correct-Prefix Property for {TAG}s,1999,16,23,1,1,5269,markjan nederhof,Computational Linguistics,0,"A new upper bound is presented for the computational complexity of the parsing problem for TAGs, under the constraint that input is read from left to right in such a way that errors in the input are observed as soon as possible, which is called the correct-prefix property. The former upper bound, O(n9), is now improved to O(n6), which is the same as that of practical parsing algorithms for TAGs without the additional constraint of the correct-prefix property."
W98-1302,Context-Free Parsing through Regular Approximation,1998,17,16,1,1,5269,markjan nederhof,Finite State Methods in Natural Language Processing,0,"We show that context-free parsing can be realised by a 2-phase process, relying on an approximated context-free grammar. In the first phase a finite transducer performs parsing according to the approximation. In the second phase, the approximated parses are refined according to the original grammar."
W98-0130,Prefix probabilities for linear indexed grammars,1998,2,0,1,1,5269,markjan nederhof,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
P98-2156,An Alternative {LR} Algorithm for {TAG}s,1998,8,11,1,1,5269,markjan nederhof,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"We present a new LR algorithm for tree-adjoining grammars. It is an alternative to an existing algorithm that is shown to be incorrect. Furthermore, the new algorithm is much simpler, being very close to traditional LR parsing for context-free grammars. The construction of derived trees and the computation of features also become straightforward."
P98-2157,Prefix Probabilities from Stochastic Free Adjoining Grammars,1998,9,5,1,1,5269,markjan nederhof,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"Language models for speech recognition typically use a probability model of the form Pr(an/a1, a2, .... an-1 Stochastic grammars, on the other hand, are typically used to assign structure to utterances. A language model of the above form is constructed from such grammars by computing the prefix probability xe2x88x91wexcfx83* Pr(a1 ...anw), where w represents all possible terminations of the prefix a1 ... an. The main result in this paper is an algorithm to compute such prefix probabilities given a stochastic Tree Adjoining Grammar (TAG). The algorithm achieves the required computation in O(n 6) time. The probability of sub-derivations that do not derive any words in the prefix, but contribute structurally to its derivation, are precomputed to achieve termination. This algorithm enables existing corpus-based estimation techniques for stochastic TAGs to be used for language modelling."
C98-2151,An alternative {LR} algorithm for {TAG}s,1998,8,11,1,1,5269,markjan nederhof,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"We present a new LR algorithm for tree-adjoining grammars. It is an alternative to an existing algorithm that is shown to be incorrect. Furthermore, the new algorithm is much simpler, being very close to traditional LR parsing for context-free grammars. The construction of derived trees and the computation of features also become straightforward."
C98-2152,Prefix Probabilities from Stochastic {T}ree {A}djoining {G}rammars,1998,8,2,1,1,5269,markjan nederhof,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"Language models for speech recognition typically use a probability model of the form Pr(a_n | a_1, a_2, ..., a_{n-1}). Stochastic grammars, on the other hand, are typically used to assign structure to utterances. A language model of the above form is constructed from such grammars by computing the prefix probability Sum_{w in Sigma*} Pr(a_1 ... a_n w), where w represents all possible terminations of the prefix a_1 ... a_n. The main result in this paper is an algorithm to compute such prefix probabilities given a stochastic Tree Adjoining Grammar (TAG). The algorithm achieves the required computation in O(n^6) time. The probability of subderivations that do not derive any words in the prefix, but contribute structurally to its derivation, are precomputed to achieve termination. This algorithm enables existing corpus-based estimation techniques for stochastic TAGs to be used for language modelling."
W97-0614,Grammatical analysis in the {OVIS} spoken-dialogue system,1997,12,10,1,1,5269,markjan nederhof,Interactive Spoken Dialog Systems: Bringing Speech and {NLP} Together in Real Applications,0,"We argue that grammatical processing is a viable alternative to concept spotting for processing spoken input in a practical dialogue system. We discuss the structure of the grammar, the properties of the parser, and a method for achieving robustness. We discuss test results suggesting that grammatical processing allows fast and accurate processing of spoken input."
1997.iwpt-1.19,Regular Approximations of {CFL}s: A Grammatical View,1997,-1,-1,1,1,5269,markjan nederhof,Proceedings of the Fifth International Workshop on Parsing Technologies,0,We show that for each context-free grammar a new grammar can be constructed that generates a regular language. This construction differs from existing methods of approximation in that use of a pushdown automaton is avoided . This allows better insight into how the generated language is affected. The new method is also more attractive from a computational viewpoint.
P96-1032,Efficient Tabular {LR} Parsing,1996,19,10,1,1,5269,markjan nederhof,34th Annual Meeting of the Association for Computational Linguistics,1,"We give a new treatment of tabular LR parsing, which is an alternative to Tomita's generalized LR algorithm. The advantage is twofold. Firstly, our treatment is conceptually more attractive because it uses simpler concepts, such as grammar transformations and standard tabulation techniques also know as chart parsing. Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced."
P94-1017,An Optimal Tabular Parsing Algorithm,1994,17,15,1,1,5269,markjan nederhof,32nd Annual Meeting of the Association for Computational Linguistics,1,"In this paper we relate a number of parsing algorithms which have been developed in very different areas of parsing theory, and which include deterministic algorithms, tabular algorithms, and a parallel algorithm. We show that these algorithms are based on the same underlying ideas.By relating existing ideas, we hope to provide an opportunity to improve some algorithms based on features of others. A second purpose of this paper is to answer a question which has come up in the area of tabular parsing, namely how to obtain a parsing algorithm with the property that the table will contain as little entries as possible, but without the possibility that two entries represent the same subderivation."
P94-1029,An Extended Theory of Head-Driven Parsing,1994,13,8,1,1,5269,markjan nederhof,32nd Annual Meeting of the Association for Computational Linguistics,1,"We show that more head-driven parsing algorithms can be formulated than those occurring in the existing literature. These algorithms are inspired by a family of left-to-right parsing algorithms from a recent publication. We further introduce a more advanced notion of head-driven parsing which allows more detailed specification of the processing order of non-head elements in the right-hand side. We develop a parsing algorithm for this strategy, based on LR parsing techniques."
E93-1036,Generalized Left-Corner Parsing,1993,31,32,1,1,5269,markjan nederhof,Sixth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We show how techniques known from generalized LR parsing can be applied to left-corner parsing. The resulting parsing algorithm for context-free grammars has some advantages over generalized LR parsing: the sizes and generation times of the parsers are smaller, the produced output is more compact, and the basic parsing technique can more easily be adapted to arbitary context-free grammars.The algorithm can be seen as an optimization of algorithms known from existing literature. A strong advantage of our presentation is that it makes explicit the role of left-corner parsing in these algorithms."
1993.iwpt-1.16,Increasing the Applicability of {LR} Parsing,1993,-1,-1,1,1,5269,markjan nederhof,Proceedings of the Third International Workshop on Parsing Technologies,0,"In this paper we describe a phenomenon present in some context-free grammars, called \textit{hidden left recursion}. We show that ordinary LR parsing according to hidden left-recursive grammars is not possible and we indicate a range of solutions to this problem. One of these solutions is a new parsing technique, which is a variant of traditional LR parsing. This new parsing technique can be used both with and without lookahead and the nondeterminism can be realized using backtracking or using a graph-structured stack."
