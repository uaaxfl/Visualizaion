2020.acl-main.622,P14-1005,0,0.173467,"Missing"
2020.acl-main.622,P15-1136,0,0.111435,"al., 2015; Lee et al., 2017) that learn to select the antecedent of each anaphoric mention. Our CorefQA model is essentially a mention-ranking model, but we identify coreference using question answering. 2.2 Formalizing NLP Tasks as question answering Machine reading comprehension is a general and extensible task form. Many tasks in natural language processing can be framed as reading comprehension while abstracting away the taskspecific modeling constraints. McCann et al. (2018) introduced the decaNLP challenge, which converts a set of 10 core tasks in NLP to reading comprehension. He et al. (2015) showed that semantic role labeling annotations could be solicited by using question-answer pairs to represent the predicate-argument structure. Levy et al. (2017) reduced relation extraction to answering simple reading comprehension questions, yielding models that generalize better in the 6954 Mention Proposal Module I was hired to do some Christmas music, and it was just “Jingle Bells” and I brought my cat with me to the studio, and I was working on the song and the cat jumped up into the record booth and started meowing along, meowing to me. Question: I … my cat … I was hired to do some Chr"
2020.acl-main.622,P16-1061,0,0.339673,"Missing"
2020.acl-main.622,D19-1606,0,0.259787,"he output layer of contextualization, span prediction requires a more thorough and deeper examination of the lexical, semantic and syntactic cues within the context, which will potentially lead to better performance. Moreover, the proposed question answering formulation allows us to take advantage of existing question answering datasets. Coreference annotation is expensive, cumbersome and often requires linguistic expertise from annotators. Under the proposed formulation, the coreference resolution has the same format as the existing question answering datasets (Rajpurkar et al., 2016a, 2018; Dasigi et al., 2019a). Those datasets can thus readily be used for data augmentation. We show that pre-training on existing question answering datasets improves the model’s generalization and 2 This is an illustration of the question formulation. The actual operation is described in Section 3.4. transferability, leading to additional performance boost. Experiments show that the proposed framework significantly outperforms previous models on two widely-used datasets. Specifically, we achieve new state-of-the-art scores of 83.1 (+3.5) on the CoNLL-2012 benchmark and 87.5 (+2.5) on the GAP benchmark. 2 2.1 Related"
2020.acl-main.622,P19-1386,0,0.0110556,"ed at inference time, whereas our model does not need that assumption – it jointly trains the mention proposal model and the coreference resolution model in an end-to-end manner. 2.3 Data Augmentation Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models. Data augmentation techniques have been explored in various fields such as question answering (Talmor and Berant, 2019), text classification (Kobayashi, 2018) and dialogue language understanding (Hou et al., 2018). In coreference resolution, Zhao et al. (2018); Emami et al. (2019); Zhao et al. (2019) focused on debiasing the gender bias problem; Aralikatte et al. (2019) explored the effectiveness of joint modeling of ellipsis and coreference resolution. To the best of our knowledge, we are the first to use existing question answering datasets as data augmentation for coreference resolution. 3 Model In this section, we describe our CorefQA model in detail. The overall architecture is illustrated in Figure 2. 3.1 Notations Given a sequence of input tokens X = {x1 , x2 , ..., xn } in a document, where n denotes the length of the document. N = n ∗ (n + 1)/2 denotes the num"
2020.acl-main.622,D15-1076,0,0.0387119,"iseman et al., 2015; Lee et al., 2017) that learn to select the antecedent of each anaphoric mention. Our CorefQA model is essentially a mention-ranking model, but we identify coreference using question answering. 2.2 Formalizing NLP Tasks as question answering Machine reading comprehension is a general and extensible task form. Many tasks in natural language processing can be framed as reading comprehension while abstracting away the taskspecific modeling constraints. McCann et al. (2018) introduced the decaNLP challenge, which converts a set of 10 core tasks in NLP to reading comprehension. He et al. (2015) showed that semantic role labeling annotations could be solicited by using question-answer pairs to represent the predicate-argument structure. Levy et al. (2017) reduced relation extraction to answering simple reading comprehension questions, yielding models that generalize better in the 6954 Mention Proposal Module I was hired to do some Christmas music, and it was just “Jingle Bells” and I brought my cat with me to the studio, and I was working on the song and the cat jumped up into the record booth and started meowing along, meowing to me. Question: I … my cat … I was hired to do some Chr"
2020.acl-main.622,C18-1105,0,0.0248802,"odels are built under the assumption that gold mentions are provided at inference time, whereas our model does not need that assumption – it jointly trains the mention proposal model and the coreference resolution model in an end-to-end manner. 2.3 Data Augmentation Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models. Data augmentation techniques have been explored in various fields such as question answering (Talmor and Berant, 2019), text classification (Kobayashi, 2018) and dialogue language understanding (Hou et al., 2018). In coreference resolution, Zhao et al. (2018); Emami et al. (2019); Zhao et al. (2019) focused on debiasing the gender bias problem; Aralikatte et al. (2019) explored the effectiveness of joint modeling of ellipsis and coreference resolution. To the best of our knowledge, we are the first to use existing question answering datasets as data augmentation for coreference resolution. 3 Model In this section, we describe our CorefQA model in detail. The overall architecture is illustrated in Figure 2. 3.1 Notations Given a sequence of input tokens X = {x1 , x2 , ..., xn } in a document, where n d"
2020.acl-main.622,2020.tacl-1.5,0,0.178945,"Missing"
2020.acl-main.622,D19-1588,0,0.416343,"Missing"
2020.acl-main.622,P19-1066,0,0.275848,"nt mentions; and (3) A plethora of existing question answering datasets can be used for data augmentation to improve the model’s generalization capability. Experiments demonstrate significant performance boost over previous models, with 83.1 (+3.5) F1 score on the CoNLL-2012 benchmark and 87.5 (+2.5) F1 score on the GAP benchmark. 1 1 Figure 1: An illustration of the paradigm shift from coreference resolution to query-based span prediction. Spans with the same format represent coreferent mentions. Introduction Recent coreference resolution systems (Lee et al., 2017, 2018; Zhang et al., 2018a; Kantor and Globerson, 2019) consider all text spans in a document as potential mentions and learn to find an antecedent for each possible mention. There are two key issues with this paradigm, in terms of task formalization and the algorithm. At the task formalization level, mentions left out at the mention proposal stage can never be recovered since the downstream module only operates on the proposed mentions. Existing models often suffer from mention proposal (Zhang et al., 1 https://github.com/ShannonAI/CorefQA 2018a). The coreference datasets can only provide a weak signal for spans that correspond to entity mentions"
2020.acl-main.622,N18-2072,0,0.0158034,"fits of training joint models for these tasks. Their models are built under the assumption that gold mentions are provided at inference time, whereas our model does not need that assumption – it jointly trains the mention proposal model and the coreference resolution model in an end-to-end manner. 2.3 Data Augmentation Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models. Data augmentation techniques have been explored in various fields such as question answering (Talmor and Berant, 2019), text classification (Kobayashi, 2018) and dialogue language understanding (Hou et al., 2018). In coreference resolution, Zhao et al. (2018); Emami et al. (2019); Zhao et al. (2019) focused on debiasing the gender bias problem; Aralikatte et al. (2019) explored the effectiveness of joint modeling of ellipsis and coreference resolution. To the best of our knowledge, we are the first to use existing question answering datasets as data augmentation for coreference resolution. 3 Model In this section, we describe our CorefQA model in detail. The overall architecture is illustrated in Figure 2. 3.1 Notations Given a sequence of input t"
2020.acl-main.622,D17-1018,0,0.0579966,"n of cues embedded in the context of coreferent mentions; and (3) A plethora of existing question answering datasets can be used for data augmentation to improve the model’s generalization capability. Experiments demonstrate significant performance boost over previous models, with 83.1 (+3.5) F1 score on the CoNLL-2012 benchmark and 87.5 (+2.5) F1 score on the GAP benchmark. 1 1 Figure 1: An illustration of the paradigm shift from coreference resolution to query-based span prediction. Spans with the same format represent coreferent mentions. Introduction Recent coreference resolution systems (Lee et al., 2017, 2018; Zhang et al., 2018a; Kantor and Globerson, 2019) consider all text spans in a document as potential mentions and learn to find an antecedent for each possible mention. There are two key issues with this paradigm, in terms of task formalization and the algorithm. At the task formalization level, mentions left out at the mention proposal stage can never be recovered since the downstream module only operates on the proposed mentions. Existing models often suffer from mention proposal (Zhang et al., 1 https://github.com/ShannonAI/CorefQA 2018a). The coreference datasets can only provide a"
2020.acl-main.622,N18-2108,0,0.768457,"ectly model the representation of real-world entities and (2) mention-ranking models (Durrett and Klein, 2013; Wiseman et al., 2015; Lee et al., 2017) that learn to select the antecedent of each anaphoric mention. Our CorefQA model is essentially a mention-ranking model, but we identify coreference using question answering. 2.2 Formalizing NLP Tasks as question answering Machine reading comprehension is a general and extensible task form. Many tasks in natural language processing can be framed as reading comprehension while abstracting away the taskspecific modeling constraints. McCann et al. (2018) introduced the decaNLP challenge, which converts a set of 10 core tasks in NLP to reading comprehension. He et al. (2015) showed that semantic role labeling annotations could be solicited by using question-answer pairs to represent the predicate-argument structure. Levy et al. (2017) reduced relation extraction to answering simple reading comprehension questions, yielding models that generalize better in the 6954 Mention Proposal Module I was hired to do some Christmas music, and it was just “Jingle Bells” and I brought my cat with me to the studio, and I was working on the song and the cat j"
2020.acl-main.622,K17-1034,0,0.0246564,"ut we identify coreference using question answering. 2.2 Formalizing NLP Tasks as question answering Machine reading comprehension is a general and extensible task form. Many tasks in natural language processing can be framed as reading comprehension while abstracting away the taskspecific modeling constraints. McCann et al. (2018) introduced the decaNLP challenge, which converts a set of 10 core tasks in NLP to reading comprehension. He et al. (2015) showed that semantic role labeling annotations could be solicited by using question-answer pairs to represent the predicate-argument structure. Levy et al. (2017) reduced relation extraction to answering simple reading comprehension questions, yielding models that generalize better in the 6954 Mention Proposal Module I was hired to do some Christmas music, and it was just “Jingle Bells” and I brought my cat with me to the studio, and I was working on the song and the cat jumped up into the record booth and started meowing along, meowing to me. Question: I … my cat … I was hired to do some Christmas music, and it was just “Jingle Bells” and I brought my cat with me to the studio, and I was working on the song and the cat jumped up into the record booth"
2020.acl-main.622,P16-1094,1,0.873523,"Missing"
2020.acl-main.622,P19-1129,1,0.879507,"to the studio, and I was working on the song and the cat jumped up into the record booth and started meowing along, meowing to me. Coreference Clusters [I, I, my, me, I, me] [my cat, the cat] [Jingle Bells, the song] Figure 2: The overall architecture of our CorefQA model. The input passage is first fed into the Mention Proposal Module 3.3 to obtain candidate mentions. Then the Mention Linking Module 3.4 is used to extract coreferent mentions from the passage for each proposed mention. The coreference clusters are obtained using the scores produced in the above two stages. zero-shot setting. Li et al. (2019a,b) cast the tasks of named entity extraction and relation extraction as a reading comprehension problem. In parallel to our work, Aralikatte et al. (2019) converted coreference and ellipsis resolution in a question answering format, and showed the benefits of training joint models for these tasks. Their models are built under the assumption that gold mentions are provided at inference time, whereas our model does not need that assumption – it jointly trains the mention proposal model and the coreference resolution model in an end-to-end manner. 2.3 Data Augmentation Data augmentation is a st"
2020.acl-main.622,H05-1004,0,0.0317466,"s. • EE + BERT-large (Kantor and Globerson, 2019) represents each mention in a cluster via an approximation of the sum of all mentions in the cluster. • c2f-coref + SpanBERT-large (Joshi et al., 2019a) focuses on pre-training span representations to better represent and predict spans of text. 4.3 Results on CoNLL-2012 Shared Task The English data of CoNLL-2012 shared task (Pradhan et al., 2012) contains 2,802/343/348 train/development/test documents in 7 different genres. The main evaluation is the average of three metrics – MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAFφ4 (Luo, 2005) on the test set according to the official CoNLL-2012 evaluation scripts 7 . 6 https://github.com/lessw2020/ Ranger-Deep-Learning-Optimizer 7 http://conll.cemantix.org/2012/ software.html We compare the CorefQA model with several baseline models in Table 1. Our CorefQA system achieves a huge performance boost over existing systems: With SpanBERT-base, it achieves an F1 score of 79.9, which already outperforms the previous SOTA model using SpanBERT-large by 0.3. With SpanBERT-large, it achieves an F1 score of 83.1, with a 3.5 performance boost over the previous SOTA system. 4.4 Results on GAP T"
2020.acl-main.622,D18-1298,0,0.0435821,"Missing"
2020.acl-main.622,D14-1162,0,0.0815855,"al = 10 and the maximum number of antecedents kept for each mention C = 50. The SpanBERT parameters are updated by the Adam optimizer (Kingma and Ba, 2015) with initial learning rate 1 × 10−5 and the task parameters are updated by the Range optimizer 6 with initial learning rate 2 × 10−4 . 4.2 Baselines We compare the CorefQA model with previous neural models that are trained end-to-end: • e2e-coref (Lee et al., 2017) is the first endto-end coreference system that learns which spans are entity mentions and how to best cluster them jointly. Their token representations are built upon the GLoVe (Pennington et al., 2014) and Turian (Turian et al., 2010) embeddings. • c2f-coref + ELMo (Lee et al., 2018) extends Lee et al. (2017) by combining a coarse-tofine pruning with a higher-order inference mechanism. Their representations are built upon ELMo embeddings (Peters et al., 2018). • c2f-coref + BERT-large(Joshi et al., 2019b) builds the c2f-coref system on top of BERT (Devlin et al., 2019) token representations. • EE + BERT-large (Kantor and Globerson, 2019) represents each mention in a cluster via an approximation of the sum of all mentions in the cluster. • c2f-coref + SpanBERT-large (Joshi et al., 2019a) foc"
2020.acl-main.622,N18-1202,0,0.0508539,"learning rate 2 × 10−4 . 4.2 Baselines We compare the CorefQA model with previous neural models that are trained end-to-end: • e2e-coref (Lee et al., 2017) is the first endto-end coreference system that learns which spans are entity mentions and how to best cluster them jointly. Their token representations are built upon the GLoVe (Pennington et al., 2014) and Turian (Turian et al., 2010) embeddings. • c2f-coref + ELMo (Lee et al., 2018) extends Lee et al. (2017) by combining a coarse-tofine pruning with a higher-order inference mechanism. Their representations are built upon ELMo embeddings (Peters et al., 2018). • c2f-coref + BERT-large(Joshi et al., 2019b) builds the c2f-coref system on top of BERT (Devlin et al., 2019) token representations. • EE + BERT-large (Kantor and Globerson, 2019) represents each mention in a cluster via an approximation of the sum of all mentions in the cluster. • c2f-coref + SpanBERT-large (Joshi et al., 2019a) focuses on pre-training span representations to better represent and predict spans of text. 4.3 Results on CoNLL-2012 Shared Task The English data of CoNLL-2012 shared task (Pradhan et al., 2012) contains 2,802/343/348 train/development/test documents in 7 differen"
2020.acl-main.622,W12-4501,0,0.750664,"Missing"
2020.acl-main.622,P18-2124,0,0.0574605,"Missing"
2020.acl-main.622,D16-1264,0,0.368547,"only superficially modeled at the output layer of contextualization, span prediction requires a more thorough and deeper examination of the lexical, semantic and syntactic cues within the context, which will potentially lead to better performance. Moreover, the proposed question answering formulation allows us to take advantage of existing question answering datasets. Coreference annotation is expensive, cumbersome and often requires linguistic expertise from annotators. Under the proposed formulation, the coreference resolution has the same format as the existing question answering datasets (Rajpurkar et al., 2016a, 2018; Dasigi et al., 2019a). Those datasets can thus readily be used for data augmentation. We show that pre-training on existing question answering datasets improves the model’s generalization and 2 This is an illustration of the question formulation. The actual operation is described in Section 3.4. transferability, leading to additional performance boost. Experiments show that the proposed framework significantly outperforms previous models on two widely-used datasets. Specifically, we achieve new state-of-the-art scores of 83.1 (+3.5) on the CoNLL-2012 benchmark and 87.5 (+2.5) on the G"
2020.acl-main.622,P19-1485,0,0.0128017,"question answering format, and showed the benefits of training joint models for these tasks. Their models are built under the assumption that gold mentions are provided at inference time, whereas our model does not need that assumption – it jointly trains the mention proposal model and the coreference resolution model in an end-to-end manner. 2.3 Data Augmentation Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models. Data augmentation techniques have been explored in various fields such as question answering (Talmor and Berant, 2019), text classification (Kobayashi, 2018) and dialogue language understanding (Hou et al., 2018). In coreference resolution, Zhao et al. (2018); Emami et al. (2019); Zhao et al. (2019) focused on debiasing the gender bias problem; Aralikatte et al. (2019) explored the effectiveness of joint modeling of ellipsis and coreference resolution. To the best of our knowledge, we are the first to use existing question answering datasets as data augmentation for coreference resolution. 3 Model In this section, we describe our CorefQA model in detail. The overall architecture is illustrated in Figure 2. 3."
2020.acl-main.622,P10-1040,0,0.0302167,"ecedents kept for each mention C = 50. The SpanBERT parameters are updated by the Adam optimizer (Kingma and Ba, 2015) with initial learning rate 1 × 10−5 and the task parameters are updated by the Range optimizer 6 with initial learning rate 2 × 10−4 . 4.2 Baselines We compare the CorefQA model with previous neural models that are trained end-to-end: • e2e-coref (Lee et al., 2017) is the first endto-end coreference system that learns which spans are entity mentions and how to best cluster them jointly. Their token representations are built upon the GLoVe (Pennington et al., 2014) and Turian (Turian et al., 2010) embeddings. • c2f-coref + ELMo (Lee et al., 2018) extends Lee et al. (2017) by combining a coarse-tofine pruning with a higher-order inference mechanism. Their representations are built upon ELMo embeddings (Peters et al., 2018). • c2f-coref + BERT-large(Joshi et al., 2019b) builds the c2f-coref system on top of BERT (Devlin et al., 2019) token representations. • EE + BERT-large (Kantor and Globerson, 2019) represents each mention in a cluster via an approximation of the sum of all mentions in the cluster. • c2f-coref + SpanBERT-large (Joshi et al., 2019a) focuses on pre-training span represe"
2020.acl-main.622,N18-2003,0,0.0236201,"mentions are provided at inference time, whereas our model does not need that assumption – it jointly trains the mention proposal model and the coreference resolution model in an end-to-end manner. 2.3 Data Augmentation Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models. Data augmentation techniques have been explored in various fields such as question answering (Talmor and Berant, 2019), text classification (Kobayashi, 2018) and dialogue language understanding (Hou et al., 2018). In coreference resolution, Zhao et al. (2018); Emami et al. (2019); Zhao et al. (2019) focused on debiasing the gender bias problem; Aralikatte et al. (2019) explored the effectiveness of joint modeling of ellipsis and coreference resolution. To the best of our knowledge, we are the first to use existing question answering datasets as data augmentation for coreference resolution. 3 Model In this section, we describe our CorefQA model in detail. The overall architecture is illustrated in Figure 2. 3.1 Notations Given a sequence of input tokens X = {x1 , x2 , ..., xn } in a document, where n denotes the length of the document. N = n ∗ (n +"
2020.acl-main.622,M95-1005,0,0.70145,"system on top of BERT (Devlin et al., 2019) token representations. • EE + BERT-large (Kantor and Globerson, 2019) represents each mention in a cluster via an approximation of the sum of all mentions in the cluster. • c2f-coref + SpanBERT-large (Joshi et al., 2019a) focuses on pre-training span representations to better represent and predict spans of text. 4.3 Results on CoNLL-2012 Shared Task The English data of CoNLL-2012 shared task (Pradhan et al., 2012) contains 2,802/343/348 train/development/test documents in 7 different genres. The main evaluation is the average of three metrics – MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAFφ4 (Luo, 2005) on the test set according to the official CoNLL-2012 evaluation scripts 7 . 6 https://github.com/lessw2020/ Ranger-Deep-Learning-Optimizer 7 http://conll.cemantix.org/2012/ software.html We compare the CorefQA model with several baseline models in Table 1. Our CorefQA system achieves a huge performance boost over existing systems: With SpanBERT-base, it achieves an F1 score of 79.9, which already outperforms the previous SOTA model using SpanBERT-large by 0.3. With SpanBERT-large, it achieves an F1 score of 83.1, with a 3.5 performance boo"
2020.acl-main.622,Q18-1042,0,0.0295395,"according to the official CoNLL-2012 evaluation scripts 7 . 6 https://github.com/lessw2020/ Ranger-Deep-Learning-Optimizer 7 http://conll.cemantix.org/2012/ software.html We compare the CorefQA model with several baseline models in Table 1. Our CorefQA system achieves a huge performance boost over existing systems: With SpanBERT-base, it achieves an F1 score of 79.9, which already outperforms the previous SOTA model using SpanBERT-large by 0.3. With SpanBERT-large, it achieves an F1 score of 83.1, with a 3.5 performance boost over the previous SOTA system. 4.4 Results on GAP The GAP dataset (Webster et al., 2018) is a gender-balanced dataset that targets the challenges of resolving naturally occurring ambiguous pronouns. It comprises 8,908 coreference-labeled pairs of (ambiguous pronoun, antecedent name) sampled from Wikipedia. We follow the protocols in Webster et al. (2018); Joshi et al. (2019b) and use the off-theshelf resolver trained on the CoNLL-2012 dataset to get the performance of the GAP dataset. Table 2 presents the results. We can see that the proposed CorefQA model achieves state-of-the-art performance on all metrics on the GAP dataset. 5 Ablation Study and Analysis We perform comprehensi"
2020.acl-main.622,N16-1114,0,0.241383,"Missing"
2020.acl-main.622,P15-1137,0,0.167055,"seman et al., 2016; Clark and Manning, 2015, 2016) rely on parsers and hand-engineered mention proposal algorithms. Recent work (Lee et al., 2017, 2018; Kantor and Globerson, 2019) tackled the problem in an end-to-end fashion by jointly detecting mentions and predicting coreferences. Based on how entity-level information is incorporated, they can be further categorized as (1) entity-level models (Bj¨orkelund and Kuhn, 2014; Clark and Manning, 2015, 2016; Wiseman et al., 2016) that directly model the representation of real-world entities and (2) mention-ranking models (Durrett and Klein, 2013; Wiseman et al., 2015; Lee et al., 2017) that learn to select the antecedent of each anaphoric mention. Our CorefQA model is essentially a mention-ranking model, but we identify coreference using question answering. 2.2 Formalizing NLP Tasks as question answering Machine reading comprehension is a general and extensible task form. Many tasks in natural language processing can be framed as reading comprehension while abstracting away the taskspecific modeling constraints. McCann et al. (2018) introduced the decaNLP challenge, which converts a set of 10 core tasks in NLP to reading comprehension. He et al. (2015) sh"
2020.acl-main.622,P18-2017,0,0.142461,"ectly model the representation of real-world entities and (2) mention-ranking models (Durrett and Klein, 2013; Wiseman et al., 2015; Lee et al., 2017) that learn to select the antecedent of each anaphoric mention. Our CorefQA model is essentially a mention-ranking model, but we identify coreference using question answering. 2.2 Formalizing NLP Tasks as question answering Machine reading comprehension is a general and extensible task form. Many tasks in natural language processing can be framed as reading comprehension while abstracting away the taskspecific modeling constraints. McCann et al. (2018) introduced the decaNLP challenge, which converts a set of 10 core tasks in NLP to reading comprehension. He et al. (2015) showed that semantic role labeling annotations could be solicited by using question-answer pairs to represent the predicate-argument structure. Levy et al. (2017) reduced relation extraction to answering simple reading comprehension questions, yielding models that generalize better in the 6954 Mention Proposal Module I was hired to do some Christmas music, and it was just “Jingle Bells” and I brought my cat with me to the studio, and I was working on the song and the cat j"
2020.acl-main.622,P18-1205,0,0.0389047,"Missing"
2020.acl-main.622,N19-1064,0,0.0214523,"Missing"
2020.emnlp-main.272,2021.ccl-1.108,0,0.133441,"Missing"
2020.emnlp-main.272,P15-1152,0,0.0416797,"aper are three-fold: (1) proposal of a knowledge selection module for applying pre-trained language models to the task of knowledge-grounded dialogue generation; (2) proposal of an unsupervised approach in which learning of knowledge selection and fine-tuning of the pre-trained model are conducted in a joint manner; and (3) empirical verification of the effectiveness of the proposed method on benchmarks of knowledge-grounded dialogue generation. 3378 2 Related Work Early work on end-to-end open domain dialogue generation is inspired by the research of machine translation (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Later, the vanilla encoderdecoder architecture is widely extended to improve diversity of responses (Li et al., 2015; Xing et al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is"
2020.emnlp-main.272,P19-1081,0,0.0228249,"t al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018). In this work, we study document-grounded dialogue generation. Rather than learning from scratch like most existing work, we take advantage of the pre-trained language models and achieve new stateof-the-art on the benchmarks of the task. Big, deep neural language models pre-trained on huge unlabeled text corpus have led to strong improvements on numerous"
2020.emnlp-main.272,I17-1047,0,0.0592179,"of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018). In this work, we study document-grounded dialogue generation. Rather than learning from scratch like most existing work, we take advantage of the pre-trained language models and achieve new stateof-the-art on the benchmarks of the task. Big, deep neural language models pre-trained on huge unlabeled text corpus have led to strong improvements on numerous natural language understanding and natural language generation benchmarks (Devlin et al., 2018; Yang et al., 2019; Liu et al., 2019; Radford et al., 2019; Song et al., 2019; Dong et al., 2019; Lewis"
2020.emnlp-main.272,N19-1035,0,0.0282509,"an learning from scratch like most existing work, we take advantage of the pre-trained language models and achieve new stateof-the-art on the benchmarks of the task. Big, deep neural language models pre-trained on huge unlabeled text corpus have led to strong improvements on numerous natural language understanding and natural language generation benchmarks (Devlin et al., 2018; Yang et al., 2019; Liu et al., 2019; Radford et al., 2019; Song et al., 2019; Dong et al., 2019; Lewis et al., 2019), and therefore are revolutionizing almost the full spectrum of NLP applications (Raffel et al., 2019; Sun et al., 2019b; Qiao et al., 2019; Zhang et al., 2019b; Lample and Conneau, 2019) and some interdisciplinary applications in NLP and computer vision (Lu et al., 2019; Su et al., 2019; Sun et al., 2019a). In the context of dialogue generation, by fine-tuning GPT-2 (Radford et al., 2019) in different sizes on social media data, recent work has (Zhang et al., 2019c; Wolf et al., 2019) shown promising progress on conversation engagement and commonsense questionanswering. In this work, we further explore the application of pre-training to the task of open domain dialogue generation by equipping the pre-trained"
2020.emnlp-main.272,D19-1194,0,0.0334788,"et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018). In this work, we study document-grounded dialogue generation. Rather than learning from scratch like most existing work, we take advantage of the pre-trained language models and achieve new stateof-the-art on the benchmarks of the task. Big, deep neural language models pre-trained on huge unlabeled text corpus have led to strong improvements on numerous natural language un"
2020.emnlp-main.272,P18-1204,0,0.0159904,"ialogue generation. 3378 2 Related Work Early work on end-to-end open domain dialogue generation is inspired by the research of machine translation (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Later, the vanilla encoderdecoder architecture is widely extended to improve diversity of responses (Li et al., 2015; Xing et al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018). In this work, we s"
2020.emnlp-main.272,P19-1538,1,0.866264,"the proposed method on benchmarks of knowledge-grounded dialogue generation. 3378 2 Related Work Early work on end-to-end open domain dialogue generation is inspired by the research of machine translation (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Later, the vanilla encoderdecoder architecture is widely extended to improve diversity of responses (Li et al., 2015; Xing et al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Sh"
2020.emnlp-main.272,P18-1205,0,0.0519876,"knowledge-grounded dialogue generation. 3378 2 Related Work Early work on end-to-end open domain dialogue generation is inspired by the research of machine translation (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Later, the vanilla encoderdecoder architecture is widely extended to improve diversity of responses (Li et al., 2015; Xing et al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018)"
2020.emnlp-main.272,P19-1499,0,0.294003,"pen domain dialogue generation. Prototypes ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn). Context I just discovered star trek and I really like watching star trek . Gene Roddenberry created it based upon science fiction and it is American media. ... If I remember Captain Kirk was not the original captain . The Star Trek Canon of the series an animated had 5 spin offs. I watched a little of the next generation but could not get into it like i did with the original show . Response These adventures went on but were short lived and six feature films. I think it’s worth it. such as DialoGPT (Zhang et al., 2019c) have exhibited compelling performance on generating responses that make sense under conversation contexts and at the same time carry specific content for keeping the conversation going. While the giant language models can memorize enough patterns in language during pre-training, they only capture “average” semantics of the data (Zhang et al., 2019c). As a result, responses could still be bland or inappropriate when specific knowledge is required, as illustrated by the example in Table 1. The other line is to ground dialogue generation by extra knowledge such as unstructured documents (Zhao"
2020.emnlp-main.272,P17-1061,0,0.0304824,"unsupervised approach in which learning of knowledge selection and fine-tuning of the pre-trained model are conducted in a joint manner; and (3) empirical verification of the effectiveness of the proposed method on benchmarks of knowledge-grounded dialogue generation. 3378 2 Related Work Early work on end-to-end open domain dialogue generation is inspired by the research of machine translation (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Later, the vanilla encoderdecoder architecture is widely extended to improve diversity of responses (Li et al., 2015; Xing et al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al.,"
2020.emnlp-main.272,D18-1076,0,0.166245,"d still be bland or inappropriate when specific knowledge is required, as illustrated by the example in Table 1. The other line is to ground dialogue generation by extra knowledge such as unstructured documents (Zhao et al., 2020). By the means, the documents (e.g., wiki articles) serve as content sources, and make a dialogue system knowledgeable regarding to a variety of concepts in discussion. However, collecting enough dialogues that are naturally grounded on documents for model training is not trivial. Although some benchmarks built upon crowd-sourcing have been released by recent papers (Zhou et al., 2018b; Dinan et al., 2019; Gopalakrishnan et al., 2019), the small training size 3377 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 3377–3390, c November 16–20, 2020. 2020 Association for Computational Linguistics makes the generation models generalize badly on unseen topics (Dinan et al., 2019) and the cost of building such data also prevents from transferring the techniques proved on the benchmarks to new domains and new languages. Encouraged by the results on pre-training for dialogue generation and knowledge-grounded dialogue generation, and moti"
2020.emnlp-main.272,P19-1362,0,0.409394,"pen domain dialogue generation. Prototypes ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn). Context I just discovered star trek and I really like watching star trek . Gene Roddenberry created it based upon science fiction and it is American media. ... If I remember Captain Kirk was not the original captain . The Star Trek Canon of the series an animated had 5 spin offs. I watched a little of the next generation but could not get into it like i did with the original show . Response These adventures went on but were short lived and six feature films. I think it’s worth it. such as DialoGPT (Zhang et al., 2019c) have exhibited compelling performance on generating responses that make sense under conversation contexts and at the same time carry specific content for keeping the conversation going. While the giant language models can memorize enough patterns in language during pre-training, they only capture “average” semantics of the data (Zhang et al., 2019c). As a result, responses could still be bland or inappropriate when specific knowledge is required, as illustrated by the example in Table 1. The other line is to ground dialogue generation by extra knowledge such as unstructured documents (Zhao"
2020.emnlp-main.272,P18-1102,0,0.0223918,"knowledge-grounded dialogue generation. 3378 2 Related Work Early work on end-to-end open domain dialogue generation is inspired by the research of machine translation (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Later, the vanilla encoderdecoder architecture is widely extended to improve diversity of responses (Li et al., 2015; Xing et al., 2017a; Zhao et al., 2017; Tao et al., 2018); to model the structure of conversation contexts (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018b). Recently, grounding dialogue generation by extra knowledge is emerging as an important step towards human-like conversational AI, where the knowledge could be obtained from knowledge graphs (Zhou et al., 2018a; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020), or extracted from visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018)"
2020.emnlp-main.279,N19-1423,0,0.0365764,"we augment the maximum likelihood estimation (MLE) in learning with objectives from four auxiliary tasks including word order recovery, utterance order recovery, masked word recovery, and masked utterance recovery. In the first two tasks, we predict the correct order of words and utterances from a random shuffle of words in an utterance and a random shuffle of utterances in a context respectively. The goal of the two tasks is to enhance understanding of the sequential dependency among words and utterances within a context. The other two tasks are inspired by the recent breakthrough from BERT (Devlin et al., 2019), in which we randomly mask a word in an utterance and an utterance in a context respectively, and predict the masked word and the masked utterance using the remaining words and utterances. The two tasks may encourage the learning process to pay more attention to semantics of words and utterances in their contexts, and help the learning process find better representations of words and utterances for the generation model. The auxiliary tasks and the MLE task share the encoder of the generation model. Through learning with multiple tasks, optimization for response generation and optimization for"
2020.emnlp-main.279,E17-1059,0,0.0245959,"faster decoding process. 1 Introduction As an important topic in conversational AI, opendomain human-machine conversation is gaining increasing attention from both academia and industry. A common approach to building such a system is to learn a response generation model within an encoder-decoder framework using neural sequence architectures (Sutskever et al., 2014; Vaswani et al., 2017). While the encoder-decoder framework has been successfully applied in various text generation tasks such as machine translation (Vaswani et al., 2017), summarization (Rush et al., 2015), paraphrase generation (Dong et al., 2017), etc., it has to deal with a unique challenge ∗ Corresponding author: Can Xu (caxu@microsoft.com). in the task of response generation: modeling conversation contexts. A conversation context often exhibits a hierarchical structure with dependency existing on both a word-level and an utterancelevel. Moreover, as indicated in (Xing et al., 2018; Zhang et al., 2019), information in a context is rather redundant for responding: commonly only a few words and utterances are useful for response generation, and the positions of the relevant words and utterances vary from case to case. To model the hie"
2020.emnlp-main.279,P02-1040,0,0.10655,"et al., 2011) in optimization with a learning rate 0.05 and a batch size 80/60/32 in DailyDialog/PERSONACHAT/Ubuntu. All models are tuned on the validation sets according to perplexity. We stop training if the perplexity does not drop in three consecutive epochs. The GlobalMaxStep T1 is set as 50k. The AuxTrainEpoch T2 is set as 30. The BatchNumPerEpoch N is 551/1595/124, 375 for DailyDialog/PERSONA-CHAT/Ubuntu. 4.4 Evaluation Metrics We evaluate the performance of the models in terms of response quality with both automatic metrics and human judgment. In automatic evaluation, besides BLEU-4 (Papineni et al., 2002) and perplexity (Sutskever et al., 2014), we follow (Serban et al., 2 https://github.com/hsgodhia/hred https://github.com/julianser/hed-dlgtruncated 4 https://github.com/LynetteXing1991/ HRAN 5 https://github.com/zhanghainan/ReCoSa 3477 3 Dataset Model PPL BLEU Distinct-1 Distinct-2 Average Greedy Extrema Parameter size Decoding speed DailyDialog HRED HRAN VHRED SSN ReCoSa Our Model 56.22 47.23 44.79 44.28 42.34 38.60 0.535 0.447 0.997 1.250 1.121 1.658 1.553 1.953 1.299 2.309 1.987 3.457 3.569 7.400 6.113 7.266 10.180 14.954 81.393 83.460 83.866 72.796 84.763 85.224 65.546 67.239 67.186 73.06"
2020.emnlp-main.279,D14-1162,0,0.0891008,"d structure instead of a recurrent structure, because the former is easier to parallelize than the latter, and thus can further enhance efficiency of the model in an online system. Encoder: we unfold all words in (U, R) into W = (w1 , . . . , wm , wm+1 , . . . , wm+t ), where m is the number of words in context U, and t is the number of words in response R. ∀i ∈ {1, . . . , m + t}, wi is represented by a summation of word embedding, position embedding, and segment embedding: B(wi ) = W E(wi ) + P E(wi ) + SE(wi ), (2) where W E(wi ) represents the word embedding of wi initialized using GloVe (Pennington et al., 2014), P E(wi ) is the position embedding of wi which is defined by P e(wi ), where e(wi ) is a one-hot vector with the only non-zero entry indicating the position of wi in W, and P ∈ Rd×Mp is a randomly initialized matrix with Mp an upper bound of the number of words in a dialogue. SE(wi ) is the segment embedding of wi defined similarly with the one-hot vector indicating the position of the utterance that contains wi . The embedding matrix QK > + M )V, Attention(Q, K, V ) = softmax( √ dk (4) where ⊕ refers to a concatenation operation, and M is given by ( 0, allow to attend, Mij = −∞, prevent fro"
2020.emnlp-main.279,W17-5004,0,0.0277571,"o leverage conversation context for multi-turn response generation, which represents a fundamental problem in dialogue generation. Different from the existing work that enhances the representation capability of models through neural architecture engineering, we turn to an orthogonal direction that we keep the generation model simple, and optimize the simple structure by learning with auxiliary tasks that encode context understanding. As a result, our model can provide high-quality responses at a low cost. Before us, there have been a few studies on learning a primary task with auxiliary ones (Rei and Yannakoudakis, 2017; Yu and Jiang, 2016; Ding et al., 2017; Trinh et al., 2018; Mehri et al., 2019; Wu et al., 2019). The work is unique in that through extensive empirical studies, we verified that a simple structure learned with auxiliary tasks can work as well as deep architectures in dialogue generation. 3 Approach We first formalize the problem in question, and then detail the model and the learning tasks. 3.1 Problem Formalization Suppose that we have a dataset D = {(Ui , Ri )}N i=1 , where Ui = (Ui,1 , . . . , Ui,n ) denotes a context with Ui,j the j-th utterance, and Ri is a response regarding to Ui . Th"
2020.emnlp-main.279,D15-1044,0,0.0677211,"dgment, and at the same time enjoys a much faster decoding process. 1 Introduction As an important topic in conversational AI, opendomain human-machine conversation is gaining increasing attention from both academia and industry. A common approach to building such a system is to learn a response generation model within an encoder-decoder framework using neural sequence architectures (Sutskever et al., 2014; Vaswani et al., 2017). While the encoder-decoder framework has been successfully applied in various text generation tasks such as machine translation (Vaswani et al., 2017), summarization (Rush et al., 2015), paraphrase generation (Dong et al., 2017), etc., it has to deal with a unique challenge ∗ Corresponding author: Can Xu (caxu@microsoft.com). in the task of response generation: modeling conversation contexts. A conversation context often exhibits a hierarchical structure with dependency existing on both a word-level and an utterancelevel. Moreover, as indicated in (Xing et al., 2018; Zhang et al., 2019), information in a context is rather redundant for responding: commonly only a few words and utterances are useful for response generation, and the positions of the relevant words and utteranc"
2020.emnlp-main.279,P19-1004,0,0.0451111,"Missing"
2020.emnlp-main.279,P15-1152,0,0.0787933,"an judgment. Moreover, with a parameter set even smaller than HRED, our model is 2x faster than ReCoSa in response decoding. Our contributions in the paper are three-fold: (1) proposal of balancing model complexity and model capability in multi-turn response generation; (2) proposal of four auxiliary learning tasks that transfer context understanding from modeling to learning; and (3) empirical verification of the effectiveness and the efficiency of the proposed model on three benchmarks. 2 Related Work End-to-end open-domain dialogue generation is built upon the encoder-decoder architecture (Shang et al., 2015; Vinyals and Le, 2015), and the vanilla sequence-to-sequence structure has been widely extended to address challenges such as generic responses (Li et al., 2015; Xing et al., 2017), context modeling (Serban et al., 2016, 2017; Xing et al., 2018; Zhang et al., 2019), and grounding by persona/emotion/knowledge (Li et al., 2016; Zhang et al., 2018; Zhou et al., 2018; Dinan et al., 2018). In this work, we study how to leverage conversation context for multi-turn response generation, which represents a fundamental problem in dialogue generation. Different from the existing work that enhances the r"
2020.emnlp-main.279,P19-1003,0,0.0248934,",3W2,1W2,2 W2,2 E2,mask Transformer Layer U1 Masked Utterance Recovery Ground U2 Truth Masked Word Recovery C2 Embedding Layer U3... U2 U3 c U4 U1 d Figure 2: Auxiliary tasks. For this task and the following ones, M in Equation (4) is defined as a zero matrix meaning that every pair of words can attend to each other in the context. wi , then, the loss of the tasks can be formulated as m 1X ¯ Lx = − I[wi∗ =[MASK]] log(p(wi |U)), k i=1 k= Masked content recovery: a major challenge in context understanding is the information omission problem (e.g., coreferences) that widely exists in utterances (Su et al., 2019). The challenge requires a model to connect semantically related words and utterances. Thus, we design masked content recovery tasks on both a word level and an utterance level to enhance the self-attention module in terms of awareness of the semantic connections. m X I[wi∗ =[MASK]], i=1 ¯ = softmax(Ws E(w∗ )), p(wi |U) i (15) where E(wi∗ ) is the representation of wi∗ obtained by passing U¯ through the encoder of the generation model, x ∈ {mwr, mur} indexes the two tasks, I[·] is an indicator function, and Ws is shared with Equation (6). 3.4 Learning Objective The full loss function is finall"
2020.emnlp-main.279,P16-1094,0,0.0227593,"context understanding from modeling to learning; and (3) empirical verification of the effectiveness and the efficiency of the proposed model on three benchmarks. 2 Related Work End-to-end open-domain dialogue generation is built upon the encoder-decoder architecture (Shang et al., 2015; Vinyals and Le, 2015), and the vanilla sequence-to-sequence structure has been widely extended to address challenges such as generic responses (Li et al., 2015; Xing et al., 2017), context modeling (Serban et al., 2016, 2017; Xing et al., 2018; Zhang et al., 2019), and grounding by persona/emotion/knowledge (Li et al., 2016; Zhang et al., 2018; Zhou et al., 2018; Dinan et al., 2018). In this work, we study how to leverage conversation context for multi-turn response generation, which represents a fundamental problem in dialogue generation. Different from the existing work that enhances the representation capability of models through neural architecture engineering, we turn to an orthogonal direction that we keep the generation model simple, and optimize the simple structure by learning with auxiliary tasks that encode context understanding. As a result, our model can provide high-quality responses at a low cost."
2020.emnlp-main.279,I17-1099,0,0.239047,"esentations of words and utterances for the generation model. The auxiliary tasks and the MLE task share the encoder of the generation model. Through learning with multiple tasks, optimization for response generation and optimization for context understanding are performed in a joint form. The context understanding related tasks can guide the MLE to achieve a better local optimum, and thus realize superior performance in response generation with a simple neural structure. We test the proposed approach with three benchmarks including the Ubuntu Dialogue Corpus (Lowe et al., 2015), DailyDialog (Li et al., 2017), and PERSONA-CHAT (Zhang et al., 2018). Evaluation results on all three datasets indicate that our model can significantly outperform state-of-the-art generation models in terms of both automatic evaluation and human judgment. Moreover, with a parameter set even smaller than HRED, our model is 2x faster than ReCoSa in response decoding. Our contributions in the paper are three-fold: (1) proposal of balancing model complexity and model capability in multi-turn response generation; (2) proposal of four auxiliary learning tasks that transfer context understanding from modeling to learning; and ("
2020.emnlp-main.279,W15-4640,0,0.13514,"learning process find better representations of words and utterances for the generation model. The auxiliary tasks and the MLE task share the encoder of the generation model. Through learning with multiple tasks, optimization for response generation and optimization for context understanding are performed in a joint form. The context understanding related tasks can guide the MLE to achieve a better local optimum, and thus realize superior performance in response generation with a simple neural structure. We test the proposed approach with three benchmarks including the Ubuntu Dialogue Corpus (Lowe et al., 2015), DailyDialog (Li et al., 2017), and PERSONA-CHAT (Zhang et al., 2018). Evaluation results on all three datasets indicate that our model can significantly outperform state-of-the-art generation models in terms of both automatic evaluation and human judgment. Moreover, with a parameter set even smaller than HRED, our model is 2x faster than ReCoSa in response decoding. Our contributions in the paper are three-fold: (1) proposal of balancing model complexity and model capability in multi-turn response generation; (2) proposal of four auxiliary learning tasks that transfer context understanding f"
2020.emnlp-main.279,P19-1373,0,0.0133647,"undamental problem in dialogue generation. Different from the existing work that enhances the representation capability of models through neural architecture engineering, we turn to an orthogonal direction that we keep the generation model simple, and optimize the simple structure by learning with auxiliary tasks that encode context understanding. As a result, our model can provide high-quality responses at a low cost. Before us, there have been a few studies on learning a primary task with auxiliary ones (Rei and Yannakoudakis, 2017; Yu and Jiang, 2016; Ding et al., 2017; Trinh et al., 2018; Mehri et al., 2019; Wu et al., 2019). The work is unique in that through extensive empirical studies, we verified that a simple structure learned with auxiliary tasks can work as well as deep architectures in dialogue generation. 3 Approach We first formalize the problem in question, and then detail the model and the learning tasks. 3.1 Problem Formalization Suppose that we have a dataset D = {(Ui , Ri )}N i=1 , where Ui = (Ui,1 , . . . , Ui,n ) denotes a context with Ui,j the j-th utterance, and Ri is a response regarding to Ui . The goal is to estimate a generation probability distribution P (R|U) from D, and"
2020.emnlp-main.279,P19-1375,0,0.218333,"n dialogue generation. Different from the existing work that enhances the representation capability of models through neural architecture engineering, we turn to an orthogonal direction that we keep the generation model simple, and optimize the simple structure by learning with auxiliary tasks that encode context understanding. As a result, our model can provide high-quality responses at a low cost. Before us, there have been a few studies on learning a primary task with auxiliary ones (Rei and Yannakoudakis, 2017; Yu and Jiang, 2016; Ding et al., 2017; Trinh et al., 2018; Mehri et al., 2019; Wu et al., 2019). The work is unique in that through extensive empirical studies, we verified that a simple structure learned with auxiliary tasks can work as well as deep architectures in dialogue generation. 3 Approach We first formalize the problem in question, and then detail the model and the learning tasks. 3.1 Problem Formalization Suppose that we have a dataset D = {(Ui , Ri )}N i=1 , where Ui = (Ui,1 , . . . , Ui,n ) denotes a context with Ui,j the j-th utterance, and Ri is a response regarding to Ui . The goal is to estimate a generation probability distribution P (R|U) from D, and thus, given a new"
2020.emnlp-main.279,D16-1023,0,0.0307318,"xt for multi-turn response generation, which represents a fundamental problem in dialogue generation. Different from the existing work that enhances the representation capability of models through neural architecture engineering, we turn to an orthogonal direction that we keep the generation model simple, and optimize the simple structure by learning with auxiliary tasks that encode context understanding. As a result, our model can provide high-quality responses at a low cost. Before us, there have been a few studies on learning a primary task with auxiliary ones (Rei and Yannakoudakis, 2017; Yu and Jiang, 2016; Ding et al., 2017; Trinh et al., 2018; Mehri et al., 2019; Wu et al., 2019). The work is unique in that through extensive empirical studies, we verified that a simple structure learned with auxiliary tasks can work as well as deep architectures in dialogue generation. 3 Approach We first formalize the problem in question, and then detail the model and the learning tasks. 3.1 Problem Formalization Suppose that we have a dataset D = {(Ui , Ri )}N i=1 , where Ui = (Ui,1 , . . . , Ui,n ) denotes a context with Ui,j the j-th utterance, and Ri is a response regarding to Ui . The goal is to estimat"
2020.emnlp-main.279,P19-1362,0,0.206319,"14; Vaswani et al., 2017). While the encoder-decoder framework has been successfully applied in various text generation tasks such as machine translation (Vaswani et al., 2017), summarization (Rush et al., 2015), paraphrase generation (Dong et al., 2017), etc., it has to deal with a unique challenge ∗ Corresponding author: Can Xu (caxu@microsoft.com). in the task of response generation: modeling conversation contexts. A conversation context often exhibits a hierarchical structure with dependency existing on both a word-level and an utterancelevel. Moreover, as indicated in (Xing et al., 2018; Zhang et al., 2019), information in a context is rather redundant for responding: commonly only a few words and utterances are useful for response generation, and the positions of the relevant words and utterances vary from case to case. To model the hierarchy of conversation contexts, hierarchical recurrent encoder-decoder (HRED) (Serban et al., 2016) extends the vanilla sequence-to-sequence model by a word-level encoder and an utterancelevel encoder. Later on, a hierarchical recurrent attention network (HRAN) (Xing et al., 2018) harnesses the decoder of the HRED model with wordlevel attention and utterance-lev"
2020.emnlp-main.279,P18-1205,0,0.185416,"for the generation model. The auxiliary tasks and the MLE task share the encoder of the generation model. Through learning with multiple tasks, optimization for response generation and optimization for context understanding are performed in a joint form. The context understanding related tasks can guide the MLE to achieve a better local optimum, and thus realize superior performance in response generation with a simple neural structure. We test the proposed approach with three benchmarks including the Ubuntu Dialogue Corpus (Lowe et al., 2015), DailyDialog (Li et al., 2017), and PERSONA-CHAT (Zhang et al., 2018). Evaluation results on all three datasets indicate that our model can significantly outperform state-of-the-art generation models in terms of both automatic evaluation and human judgment. Moreover, with a parameter set even smaller than HRED, our model is 2x faster than ReCoSa in response decoding. Our contributions in the paper are three-fold: (1) proposal of balancing model complexity and model capability in multi-turn response generation; (2) proposal of four auxiliary learning tasks that transfer context understanding from modeling to learning; and (3) empirical verification of the effect"
2020.emnlp-main.279,N16-1014,0,\N,Missing
2020.findings-emnlp.140,I17-2069,0,0.0165153,"g to separate “content” and “style” of text and manipulate the style to induce transfer at inference time (Li et al., 2018; Fu et al., 2018; John et al., 2019). However, some works show that the disentanglement cannot be met and is not necessary, and leverage techniques like reconstruction and back-translation introduced in unsupervised machine translation (Lample et al., 2018), transformer (Dai et al., 2019) to achieve unsupervised style transfer. Different from style transfer, stylized response generation requires that the response is coherent with its context and the content can be varied. Akama et al. (2017) first train a basic model on a large-scale dialogue corpus and then fine-tune the model with a small stylized corpus. Niu and Bansal (2018) propose three weakly-supervised methods to generate polite responses using non-parallel data. Gao et al. (2019) build a structured latent space sharing between conversation modeling and style transfer. However, limited by the sparsity of the latent space, it is difficult to balance the style and contextual coherence while sampling in the neighborhood of the latent code of context at inference time. Pretraining Methods have led remarkable success in variou"
2020.findings-emnlp.140,N19-1423,0,0.0215877,"nsal (2018) propose three weakly-supervised methods to generate polite responses using non-parallel data. Gao et al. (2019) build a structured latent space sharing between conversation modeling and style transfer. However, limited by the sparsity of the latent space, it is difficult to balance the style and contextual coherence while sampling in the neighborhood of the latent code of context at inference time. Pretraining Methods have led remarkable success in various NLP tasks which demonstrates its great capabilities in language understanding and text generation (Radford et al., 2018, 2019; Devlin et al., 2019; Yang et al., 2019; Liu et al., 2019; Conneau and Lample, 2019; Clark et al., 2020). Recently, the pretraining methods have also been used to tackle the key challenges in dialogue systems such as context representation (Mehri et al., 2019), response selection (Henderson and Su, 2019), knowledge-grounded response 1549 generation (Zhao et al., 2020) and personalized response generation (Zheng et al., 2019). In particular, the large-scale pre-trained open-domain dialogue systems (Zhang et al., 2019b; Adiwardana et al., 2020) make a large step towards human-like chatbot against previous works whi"
2020.findings-emnlp.140,D12-1139,0,0.0820403,"Missing"
2020.findings-emnlp.140,D19-1190,0,0.152941,"Missing"
2020.findings-emnlp.140,P16-1094,0,0.0422656,"ask and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised style transfer is learning to separate “content” and “style” of text and manipulate the style to induce transfer at inference time (Li et al., 2018; Fu et"
2020.findings-emnlp.140,N18-1169,0,0.130778,"Missing"
2020.findings-emnlp.140,I17-1061,0,0.297754,"tyle. Such research could facilitate developers to customize their dialogue systems in terms of response styles, and thus broaden applications of the systems, from a social companion (Shum et al., 2018) or a virtual assistant (Ram et al., 2018) to a variety of vertical scenarios such as customer service (requiring a polite style), virtual characters in games (requiring specific personas), assistants in specific domains (requiring domain knowledge), etc. Normally, a target style is specified by a non-conversational corpus (e.g., novels, news, blogs, etc.) apart from the paired dialogue corpus (Luan et al., 2017; Niu and Bansal, 2018; Gao et al., 2019). Thus, the major challenge of the task lies in the scarcity of paired data for learning the correspondence between conversation contexts and proper responses in the desired style, which is a key factor in success of the neural dialogue models developed so far. As a result, it is very likely that a response either digresses from the context of the current dialogue (Luan et al., 2017; Gao et al., 2019), or loses fidelity to the target style (Niu and Bansal, 2018). We consider addressing the challenge by taking advantage of the large scale pre-trained lan"
2020.findings-emnlp.140,P19-1373,0,0.0117602,"arsity of the latent space, it is difficult to balance the style and contextual coherence while sampling in the neighborhood of the latent code of context at inference time. Pretraining Methods have led remarkable success in various NLP tasks which demonstrates its great capabilities in language understanding and text generation (Radford et al., 2018, 2019; Devlin et al., 2019; Yang et al., 2019; Liu et al., 2019; Conneau and Lample, 2019; Clark et al., 2020). Recently, the pretraining methods have also been used to tackle the key challenges in dialogue systems such as context representation (Mehri et al., 2019), response selection (Henderson and Su, 2019), knowledge-grounded response 1549 generation (Zhao et al., 2020) and personalized response generation (Zheng et al., 2019). In particular, the large-scale pre-trained open-domain dialogue systems (Zhang et al., 2019b; Adiwardana et al., 2020) make a large step towards human-like chatbot against previous works which rely on complex frameworks developed over many years. On this basis, we propose to study the open-domain stylized response generation with pre-trained models in this work. 3 oxt+1 , Ht+1 = Transformer(ext , Ht ), Approach We employ Dialo"
2020.findings-emnlp.140,Q18-1027,0,0.423159,"could facilitate developers to customize their dialogue systems in terms of response styles, and thus broaden applications of the systems, from a social companion (Shum et al., 2018) or a virtual assistant (Ram et al., 2018) to a variety of vertical scenarios such as customer service (requiring a polite style), virtual characters in games (requiring specific personas), assistants in specific domains (requiring domain knowledge), etc. Normally, a target style is specified by a non-conversational corpus (e.g., novels, news, blogs, etc.) apart from the paired dialogue corpus (Luan et al., 2017; Niu and Bansal, 2018; Gao et al., 2019). Thus, the major challenge of the task lies in the scarcity of paired data for learning the correspondence between conversation contexts and proper responses in the desired style, which is a key factor in success of the neural dialogue models developed so far. As a result, it is very likely that a response either digresses from the context of the current dialogue (Luan et al., 2017; Gao et al., 2019), or loses fidelity to the target style (Niu and Bansal, 2018). We consider addressing the challenge by taking advantage of the large scale pre-trained language models. The basi"
2020.findings-emnlp.140,P02-1040,0,0.107114,"he validation/test sets, and each context has at least 4 responses. Task arXiv-style Holmes-style Training Dconv Dstyle Reddit arXiv 10,000,000 1,347,538 Reddit Holmes 10,000,000 38,309 Validation Test Dval Dtest arXiv-style Reddit 2,000 2,000 Holmes-style Reddit 2,000 2,000 Table 1: Tasks and datasets 5.2 Evaluation Methodology We compare different models with both automatic metrics and human judgment. Automatic Metrics. For automatic evaluation, we measure the quality of generated responses from three aspects: Style Consistency, Relevance, and Diversity. The relevance is measured with BLEU (Papineni et al., 2002) and Rouge (Lin, 2004) 7 . To evaluate diversity, we follow Li et al. (2015) and use Distinct-1 (Dist-1) and Distinct-2 (Dist-2) as metrics which are calculated as ratios of distinct unigrams and bigrams in responses, respectively. In terms of style consistency, existing work only measures the style intensity using classifiers (Gao et al., 2019). However, the style of text is an amalgam, and differences between two styles are reflected in multiple linguistic dimensions (Verma and Srinivasan, 2019). Thus, we propose to evaluate the style of response from three perspectives: (1) Intensity: we re"
2020.findings-emnlp.140,P12-1000,0,0.228947,"Missing"
2020.findings-emnlp.140,P15-1152,0,0.0460083,"re three-fold: (1) proposal of tackling the problem of stylized response generation with pre-trained language models; (2) proposal of a word-level objective and a sentence-level objective in fine-tuning of a pre-trained language model for the task; and (3) empirical verification of the effectiveness of the proposed method on public datasets. 2 Related Work Open-domain Dialogue Generation has received more and more attention in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020"
2020.findings-emnlp.140,P19-1538,1,0.806335,"n has received more and more attention in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised"
2020.findings-emnlp.140,P19-1362,0,0.105059,"ilability of huge amount of human conversations on social media, there has been significant progress on building open-domain dialogue systems with natural language generation techniques. Though neural generative models are notorious for replying with bland responses (Li et al., 2015), some very recent work demonstrates that response generation models learned with pre-training techniques (Radford et al., 2019) can effectively overcome the deficiency suffered by previous models and are capable of having smooth conversations with humans through reasonable and specific replies (Wolf et al., 2019; Zhang et al., 2019b). The compelling performance exhibited by the pre-trained dialogue models encourages us to explore more difficult yet important problems in conversational AI. In this work, we study stylized response generation, that is responses provided by a ∗ Corresponding Author model should not only be coherent with the conversation contexts, but also be consistent with a designated style. Such research could facilitate developers to customize their dialogue systems in terms of response styles, and thus broaden applications of the systems, from a social companion (Shum et al., 2018) or a virtual assista"
2020.findings-emnlp.140,P18-1102,0,0.0135858,"on in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised style transfer is learning to separate"
2020.findings-emnlp.140,P18-1205,0,0.0236017,"on in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised style transfer is learning to separate"
2020.findings-emnlp.140,P17-1061,0,0.0331139,"anguage model for the task; and (3) empirical verification of the effectiveness of the proposed method on public datasets. 2 Related Work Open-domain Dialogue Generation has received more and more attention in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad inte"
2021.acl-long.18,P15-1017,0,0.412395,"es serving as event arguments and classify the roles they play in an event, is a key step towards event extraction (EE). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sen"
2021.acl-long.18,W18-3027,0,0.0526075,"Missing"
2021.acl-long.18,N19-1423,0,0.102595,"in the corresponding sentence. On each decoding step, we feed the prediction results of the previously-processed entity into the recurrent unit to make prediction for the current entity. Since the predicted results of both left- and right-side entities can be potentially valuable information,we further incorporate a bidirectional decoding mechanism that integrates a forward decoding process and a backward decoding process effectively. 3.1 resentations as follows2 , H = (h1 , ..., hn ) = F (w1 , ..., wn ) where F (·) is the neural network to encode the sentence. In this paper, we select BERT (Devlin et al., 2019) as the encoder. Considering representation H does not contain event type information, which is essential for predicting argument roles. We append a special phrase denoting event type of t into each input sequence, such as “# ATTACK #”. 3.2 Decoder Different from traditional token-level Seq2Seq models, we use a bi-directional entity-level recurrent decoder (BERD) with a classifier to generate a sequence of argument roles entity by entity. BERD consists of a forward and backward recurrent decoder, which exploit the same recurrent unit architecture as follows. Encoder Given the sentence S = (w1"
2021.acl-long.18,2020.emnlp-main.49,0,0.0718894,"E). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction, which exploits the relationship of the target entity with oth"
2021.acl-long.18,N16-1034,0,0.382424,"arguments and classify the roles they play in an event, is a key step towards event extraction (EE). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one"
2021.acl-long.18,P15-2060,0,0.0167171,"s; RBPB (Sha et al., 2016) estimates whether two candidate argument belongs to one event or not, serving as constraints on a Beam-Search-based prediction algorithm. Generally, these works use the argument role type information of contextual entities as auxiliary supervision signals for training to refine input representation. However, one intuitive observation is that the argument role types can be utilized straightforwardly as semantically rich input features, like how we use entity type information. To verify this intuition, we conduct an experiment on ACE 2005 English corpus, in which CNN (Nguyen and Grishman, 2015) is utilized as a baseline. For an entity, we incorporate 210 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 210–219 August 1–6, 2021. ©2021 Association for Computational Linguistics the ground-truth roles of its contextual arguments into the baseline model’s input representation, obtaining model CNN(w. role type). As expected, CNN(w. role type) outperforms CNN significantly as shown in Table 11 . Model CNN CNN(w. role type) P 57.8 59.8 R 55.0 60.3 or previous entity recur"
2021.acl-long.18,D14-1162,0,0.0857797,"pirical results. 4.1.2 Hyperparameters We adopt BERT (Devlin et al., 2019) as encoder and the proposed bi-directional entity-level recurrent decoder as decoder for the experiment. The hyperparameters used in the experiment are listed. BERT. The hyperparameters of BERT are the same as the BERTBASE model4 . We use a dropout probability of 0.1 on all layers. Argument Feature Extractor. Dimensions of word embedding, position embedding, event type embedding and argument role embedding for each token are 100, 5, 5, 10 respectively. We utilize 300 convolution kernels with size 3. The glove embedding(Pennington et al., 2014) are utilized for initialization of word embedding5 . Training. Adam with learning rate of 6e-05, β1 = 214 4 5 https://github.com/google-research/bert https://nlp.stanford.edu/projects/glove/ Model DMBERT HMEAE BERT(Inter) BERT(Intra) BERD 0.9, β2 = 0.999, L2 weight decay of 0.01 and learning rate warmup of 0.1 is used for optimization. We set the training epochs and batch size to 40 and 30 respectively. Besides, we exploit a dropout with rate 0.5 on the concatenated feature representations. The loss weights α, β and γ are set to 1.0, 0.5 and 0.5 respectively. 4.2 R 57.4 56.6 57.1 61.2 61.5 F1"
2021.acl-long.18,P16-1116,0,0.129307,"by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction, which exploits the relationship of the target entity with others in the same event instance (Yu et al., 2011; Sha et al., 2016, 2018). We focus on the second paradigm in this paper. Despite their promising results, existing methods on capturing intra-event argument interaction suffer from two bottlenecks. (1) The argument role type information of contextual entities is underutilized. As two representative explorations, dBRNN (Sha et al., 2018) uses an intermediate tensor layer to capture latent interaction between candidate arguments; RBPB (Sha et al., 2016) estimates whether two candidate argument belongs to one event or not, serving as constraints on a Beam-Search-based prediction algorithm. Generally, these works"
2021.acl-long.18,N19-1105,0,0.211776,"s a key step towards event extraction (EE). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction, which exploits the"
2021.acl-long.18,D19-1584,0,0.168021,"s a key step towards event extraction (EE). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction, which exploits the"
2021.acl-long.18,C18-1330,1,0.890542,"Missing"
2021.acl-long.18,P19-1522,0,0.21187,"play in an event, is a key step towards event extraction (EE). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction,"
2021.acl-long.18,P11-1113,0,0.0459167,"y. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction, which exploits the relationship of the target entity with others in the same event instance (Yu et al., 2011; Sha et al., 2016, 2018). We focus on the second paradigm in this paper. Despite their promising results, existing methods on capturing intra-event argument interaction suffer from two bottlenecks. (1) The argument role type information of contextual entities is underutilized. As tw"
2021.acl-long.18,2020.acl-main.667,0,0.0298748,"event extraction (EE). For example, given that the word “fired” triggers an Attack event in the sentence “In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel” , EAE need to identify that “Baghdad”, “cameraman”, “American tank”, and “Palestine hotel” are arguments with Place, Target, Instrument, and Target as roles respectively. Recently, deep learning models have been widely applied to event argument extraction and † Corresponding authors. achieved significant progress(Chen et al., 2015; Nguyen et al., 2016; Sha et al., 2018; Yang et al., 2019; Wang et al., 2019b; Zhang et al., 2020; Du and Cardie, 2020). Many efforts have been devoted to improving EAE by better characterizing argument interaction, categorized into two paradigms. The first one, named inter-event argument interaction in this paper, concentrates on mining information of the target entity (candidate argument) in the context of other event instances (Yu et al., 2011; Nguyen et al., 2016), e.g., the evidence that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. The second one is intra-event argument interaction, which exploits the relationship of the"
2021.acl-long.18,Q19-1006,0,0.0641354,"Missing"
2021.acl-long.392,2020.findings-emnlp.264,0,0.0727962,"Missing"
2021.acl-long.392,2021.ccl-1.108,0,0.061744,"Missing"
2021.acl-long.392,2020.emnlp-main.342,0,0.0423972,"et al., 2014), DESM(Mitra et al., 2016) encode the query and document using their n-gram features or word embeddings independently and then compute their similarities. Recently, the dense retrieval approaches also tend to make use of the pre-trained language models. Sentence-BERT(Reimers and Gurevych, 2019) is a typical Bi-encoder model which encodes the text using BERT and calculates the similarity scores by the combination of several basic operations. Inspired by the interaction-based neural re-rankers, Khattab and Zaharia(2020) propose a later-interaction mechanism. Later on, some variants(Gao et al., 2020; Chen et al., 2020) are proposed. Xiong et al.(2020) identify that the negative samples during training may not be representative, lowering the training difficulty. Therefore, they propose a model to construct hard negative samples dynamically during training. 5055 Comparing to existing work, our work serves the first stage of document retrieval and presents a new method to generate document representations which borrows the clustering technique to generate pseudo query embeddings from documents. 3 Dense Document Retrieval In this section, we introduce the original Biencoder architecture and"
2021.acl-long.392,2020.findings-emnlp.63,0,0.0268253,"based on their relevance with the query. To retrieve the target documents efficiently, most existing work adopts a two-stage fashion which retrieves a subset of candidate documents from the whole corpus by a recall model and then re-rank them by a sophisticated ranking model. In the first stage, many approaches use traditional information retrieval methods including BM25 based on sparse bag-of-word representation. Since the recall of the first-stage model determines the upper bound of the ranking quality, there is lots of work focusing on improving the recall performance(Dai and Callan, 2019; Nogueira et al., 2020; Nogueira and Lin, 2020). ∗ These authors contributed equally. This work was done when the first author was an intern at Meituan. † Corresponding author. In contrast to the sparse representations, dense representations encoding semantic information can enhance the retrieval performance by overcoming the limitations like term mismatching. They are usually produced by neural encoders whose parameters are learnable. Recently, inspired by the great success of pre-trained language models like BERT/RoBERTa(Devlin et al., 2018; Liu et al., 2019) in NLP applications, the dense passage retriever is pr"
2021.acl-long.392,2020.emnlp-main.550,0,0.371593,"s done when the first author was an intern at Meituan. † Corresponding author. In contrast to the sparse representations, dense representations encoding semantic information can enhance the retrieval performance by overcoming the limitations like term mismatching. They are usually produced by neural encoders whose parameters are learnable. Recently, inspired by the great success of pre-trained language models like BERT/RoBERTa(Devlin et al., 2018; Liu et al., 2019) in NLP applications, the dense passage retriever is proposed which encodes the documents by fine-tuning the huge language models (Karpukhin et al., 2020) and achieves state-of-theart results benefiting from their powerful contextual semantic representative ability. Following the typical fine-tuning paradigm on many NLP tasks(Devlin et al., 2018), a BERT encoder usually takes the concatenation of the query and document text as input and performs a full selfattention across the input tokens. Such architecture is called Cross-encoder (Humeau et al., 2019). Although it can achieve better performance than other architectures, it is infeasible in the recall stage since it needs to recompute the representation of each document in the corpus once a ne"
2021.acl-long.392,D19-1410,0,0.023108,"he terms. DocT5query(Nogueira and Lin, 2020) augments the document with possible query terms which are generated by a sequence-to-sequence model. In contrast, the dense retrieval approaches map the text to continuous vectors which are mostly generated by neural networks. Models like DSSM(Huang et al., 2013),CLSM(Shen et al., 2014), DESM(Mitra et al., 2016) encode the query and document using their n-gram features or word embeddings independently and then compute their similarities. Recently, the dense retrieval approaches also tend to make use of the pre-trained language models. Sentence-BERT(Reimers and Gurevych, 2019) is a typical Bi-encoder model which encodes the text using BERT and calculates the similarity scores by the combination of several basic operations. Inspired by the interaction-based neural re-rankers, Khattab and Zaharia(2020) propose a later-interaction mechanism. Later on, some variants(Gao et al., 2020; Chen et al., 2020) are proposed. Xiong et al.(2020) identify that the negative samples during training may not be representative, lowering the training difficulty. Therefore, they propose a model to construct hard negative samples dynamically during training. 5055 Comparing to existing wor"
2021.acl-long.393,S15-2045,0,0.0503439,"Missing"
2021.acl-long.393,S14-2010,0,0.0481411,"Missing"
2021.acl-long.393,S16-1081,0,0.122938,"Missing"
2021.acl-long.393,S12-1051,0,0.0605372,"n to finetune it on the target dataset. • Joint training then unsupervised transfer (joint-unsup) We first train the model with the Ljoint on NLI dataset, then use Lcon to fine-tune it on the target dataset. 4 Experiments To verify the effectiveness of our proposed approach, we conduct experiments on Semantic Textual Similarity (STS) tasks under the unsupervised and supervised settings. 4.1 Setups Dataset Following previous works(Reimers and Gurevych, 2019; Li et al., 2020; Zhang et al., 2020), we evaluate our approach on multiple STS datasets, including STS tasks 2012 - 2016 (STS12 - STS16) (Agirre et al., 2012, 2013, 2014, 2015, 2016), STS benchmark (STSb) (Cer et al., 2017) and SICKRelatedness (SICK-R) (Marelli et al.). Each sample in these datasets contains a pair of sentences as well as a gold score between 0 and 5 to indicate their semantic similarity. For our unsupervised experiments, we mix the unlabeled texts from these datasets to fine-tune our model. We obtain all 7 datasets through the SentEval toolkit (Conneau and Kiela, 2018). The statistics is shown in Table 1. For supervised experiments, we use the combination of SNLI (570k samples) (Bowman et al., 2015) and MNLI (430k samples) (Willi"
2021.acl-long.393,S13-1004,0,0.063692,"Missing"
2021.acl-long.393,D15-1075,0,0.272023,"further incorporating with NLI supervision, our approach achieves new state-of-the-art performance. We also show the robustness of our approach in data scarcity scenarios and intuitive analysis of the transferred representations.3 2 2.1 Related Work Sentence Representation Learning Supervised Approaches Several works use supervised datasets for sentence representation learning. Conneau et al. (2017) finds the supervised Natural Language Inference (NLI) task is useful to train good sentence representations. They use a BiLSTM-based encoder and train it on two NLI datasets, Stanford NLI (SNLI) (Bowman et al., 2015) and Multi-Genre NLI (MNLI) (Williams et al., 2018). Universal Sentence Encoder (Cer et al., 2018) adopts a Transformer-based architecture and uses the SNLI dataset to augment the unsupervised training. SBERT (Reimers and Gurevych, 2019) proposes a siamese architecture with a shared BERT encoder and is also trained on SNLI and MNLI datasets. Self-supervised Objectives for Pre-training BERT (Devlin et al., 2019) proposes a bidirectional Transformer encoder for language model pre-training. It includes a sentence-level training objective, namely next sentence prediction (NSP), which predicts whet"
2021.acl-long.393,S17-2001,0,0.0241243,"rvised transfer (joint-unsup) We first train the model with the Ljoint on NLI dataset, then use Lcon to fine-tune it on the target dataset. 4 Experiments To verify the effectiveness of our proposed approach, we conduct experiments on Semantic Textual Similarity (STS) tasks under the unsupervised and supervised settings. 4.1 Setups Dataset Following previous works(Reimers and Gurevych, 2019; Li et al., 2020; Zhang et al., 2020), we evaluate our approach on multiple STS datasets, including STS tasks 2012 - 2016 (STS12 - STS16) (Agirre et al., 2012, 2013, 2014, 2015, 2016), STS benchmark (STSb) (Cer et al., 2017) and SICKRelatedness (SICK-R) (Marelli et al.). Each sample in these datasets contains a pair of sentences as well as a gold score between 0 and 5 to indicate their semantic similarity. For our unsupervised experiments, we mix the unlabeled texts from these datasets to fine-tune our model. We obtain all 7 datasets through the SentEval toolkit (Conneau and Kiela, 2018). The statistics is shown in Table 1. For supervised experiments, we use the combination of SNLI (570k samples) (Bowman et al., 2015) and MNLI (430k samples) (Williams et al., 2018) to train our model. In the joint training settin"
2021.acl-long.393,D18-2029,0,0.481591,"e on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios. 1 0.8 0.6 0.4 0.2 0.0 0.2 0.8 0.6 0.4 0.2 0.0 0.2 0 1 2 3 4 the gold similarity score 5 0 1 2 3 4 the gold similarity score 5 Figure 1: The correlation diagram between the gold similarity score (x-axis) and the model predicted cosine similarity score (y-axis) on the STS benchmark dataset. Introduction Sentence representation learning plays a vital role in natural language processing tasks (Kiros et al., 2015; Hill et al., 2016; Conneau et al., 2017; Cer et al., 2018). Good sentence representations benefit a wide range of downstream tasks, especially for computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many ∗ b) After applying our approach 1.0 the predicted cosine similarity the predicted cosine similarity 1.0 Work done during internship at Meituan Inc. The first two authors contribute equally. Weiran Xu is the corresponding author. downstream tasks with additional supervision. However, the native sentence represe"
2021.acl-long.393,L18-1269,0,0.0746388,"ks(Reimers and Gurevych, 2019; Li et al., 2020; Zhang et al., 2020), we evaluate our approach on multiple STS datasets, including STS tasks 2012 - 2016 (STS12 - STS16) (Agirre et al., 2012, 2013, 2014, 2015, 2016), STS benchmark (STSb) (Cer et al., 2017) and SICKRelatedness (SICK-R) (Marelli et al.). Each sample in these datasets contains a pair of sentences as well as a gold score between 0 and 5 to indicate their semantic similarity. For our unsupervised experiments, we mix the unlabeled texts from these datasets to fine-tune our model. We obtain all 7 datasets through the SentEval toolkit (Conneau and Kiela, 2018). The statistics is shown in Table 1. For supervised experiments, we use the combination of SNLI (570k samples) (Bowman et al., 2015) and MNLI (430k samples) (Williams et al., 2018) to train our model. In the joint training setting, the NLI texts are also used for contrastive objectives. Baselines To show our effectiveness on unsupervised sentence representation transfer, we mainly select BERT-flow (Li et al., 2020) for comparison, since it shares the same setting as our approach. For unsupervised comparison, we use the average of GloVe embeddings, the BERT-derived native embeddings, CLEAR (Wu"
2021.acl-long.393,D17-1070,0,0.459389,"eof-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios. 1 0.8 0.6 0.4 0.2 0.0 0.2 0.8 0.6 0.4 0.2 0.0 0.2 0 1 2 3 4 the gold similarity score 5 0 1 2 3 4 the gold similarity score 5 Figure 1: The correlation diagram between the gold similarity score (x-axis) and the model predicted cosine similarity score (y-axis) on the STS benchmark dataset. Introduction Sentence representation learning plays a vital role in natural language processing tasks (Kiros et al., 2015; Hill et al., 2016; Conneau et al., 2017; Cer et al., 2018). Good sentence representations benefit a wide range of downstream tasks, especially for computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many ∗ b) After applying our approach 1.0 the predicted cosine similarity the predicted cosine similarity 1.0 Work done during internship at Meituan Inc. The first two authors contribute equally. Weiran Xu is the corresponding author. downstream tasks with additional supervision. However, the nati"
2021.acl-long.393,N19-1423,0,0.055945,"supervised Natural Language Inference (NLI) task is useful to train good sentence representations. They use a BiLSTM-based encoder and train it on two NLI datasets, Stanford NLI (SNLI) (Bowman et al., 2015) and Multi-Genre NLI (MNLI) (Williams et al., 2018). Universal Sentence Encoder (Cer et al., 2018) adopts a Transformer-based architecture and uses the SNLI dataset to augment the unsupervised training. SBERT (Reimers and Gurevych, 2019) proposes a siamese architecture with a shared BERT encoder and is also trained on SNLI and MNLI datasets. Self-supervised Objectives for Pre-training BERT (Devlin et al., 2019) proposes a bidirectional Transformer encoder for language model pre-training. It includes a sentence-level training objective, namely next sentence prediction (NSP), which predicts whether two sentences are adjacent or not. However, NSP is proved to be weak and has little contribution to the final performance (Liu et al., 2019). After that, various self-supervised objectives are proposed for pre-training BERT-like sentence encoders. CrossThought (Wang et al., 2020) and CMLM (Yang et al., 2020) are two similar objectives that recover masked tokens in one sentence conditioned on the representat"
2021.acl-long.393,N16-1162,0,0.227872,"Missing"
2021.acl-long.393,2020.emnlp-main.120,0,0.117511,"ncoder for language model pre-training. It includes a sentence-level training objective, namely next sentence prediction (NSP), which predicts whether two sentences are adjacent or not. However, NSP is proved to be weak and has little contribution to the final performance (Liu et al., 2019). After that, various self-supervised objectives are proposed for pre-training BERT-like sentence encoders. CrossThought (Wang et al., 2020) and CMLM (Yang et al., 2020) are two similar objectives that recover masked tokens in one sentence conditioned on the representations of its contextual sentences. SLM (Lee et al., 2020) proposes an objective that reconstructs the correct sentence ordering given the shuffled sentences as the input. However, all these objectives need document-level corpus and are thus not applicable to downstream tasks with only short texts. Unsupervised Approaches BERT-flow (Li et al., 2020) proposes a flow-based approach that maps BERT embeddings to a standard Gaussian latent space, where embeddings are more suitable for comparison. However, this approach introduces 3 Our code is available at https://github.com/ yym6472/ConSERT. 5066 maximize agreement extra model structures and need special"
2021.acl-long.393,2020.emnlp-main.733,0,0.441315,"computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many ∗ b) After applying our approach 1.0 the predicted cosine similarity the predicted cosine similarity 1.0 Work done during internship at Meituan Inc. The first two authors contribute equally. Weiran Xu is the corresponding author. downstream tasks with additional supervision. However, the native sentence representations derived from BERT1 are proved to be of low-quality (Reimers and Gurevych, 2019; Li et al., 2020). As shown in Figure 1a, when directly adopt BERTbased sentence representations to semantic textual similarity (STS) tasks, almost all pairs of sentences achieved a similarity score between 0.6 to 1.0 , even if some pairs are regarded as completely unrelated by the human annotators. In other words, the BERT-derived native sentence representations are somehow collapsed (Chen and He, 2020), which means almost all sentences are mapped into a small area and therefore produce high similarity. Such phenomenon is also observed in several previous works (Gao et al., 2019; Wang et al., 2019; Li et al.,"
2021.acl-long.393,2021.ccl-1.108,0,0.103564,"Missing"
2021.acl-long.393,2020.emnlp-main.30,0,0.0347051,"Missing"
2021.acl-long.393,N18-1101,0,0.340152,"approach achieves new state-of-the-art performance. We also show the robustness of our approach in data scarcity scenarios and intuitive analysis of the transferred representations.3 2 2.1 Related Work Sentence Representation Learning Supervised Approaches Several works use supervised datasets for sentence representation learning. Conneau et al. (2017) finds the supervised Natural Language Inference (NLI) task is useful to train good sentence representations. They use a BiLSTM-based encoder and train it on two NLI datasets, Stanford NLI (SNLI) (Bowman et al., 2015) and Multi-Genre NLI (MNLI) (Williams et al., 2018). Universal Sentence Encoder (Cer et al., 2018) adopts a Transformer-based architecture and uses the SNLI dataset to augment the unsupervised training. SBERT (Reimers and Gurevych, 2019) proposes a siamese architecture with a shared BERT encoder and is also trained on SNLI and MNLI datasets. Self-supervised Objectives for Pre-training BERT (Devlin et al., 2019) proposes a bidirectional Transformer encoder for language model pre-training. It includes a sentence-level training objective, namely next sentence prediction (NSP), which predicts whether two sentences are adjacent or not. However, NSP"
2021.acl-long.393,2020.emnlp-main.124,0,0.832842,"ented versions for each image and make them close in the representation space. Such approaches can be regarded as the invariance modeling to the input samples. Chen et al. (2020a) proposes SimCLR, a simple framework for contrastive learning. They use the normalized temperature-scaled cross-entropy loss (NT-Xent) as the training loss, which is also called InfoNCE in the previous literature (Hjelm et al., 2018). Contrastive Learning for Textual Representation Learning Recently, contrastive learning has been widely applied in NLP tasks. Many works use it for language model pre-training. IS-BERT (Zhang et al., 2020) proposes to add 1-D convolutional neural network (CNN) layers on top of BERT and train the CNNs by maximizing the mutual information (MI) between the global sentence embedding and its corresponding local contexts embeddings. CERT (Fang and Xie, 2020) adopts a similar structure as MoCo (He et al., 2020) and uses back-translation for data augmentation. However, the momentum encoder needs extra memory and back-translation may produce false positives. BERT-CT (Carlsson et al., 2021) uses two individual encoders for contrastive learning, which also needs extra memory. Besides, they only sample 7 n"
2021.acl-long.393,D19-1410,0,0.350055,"tream tasks, especially for computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many ∗ b) After applying our approach 1.0 the predicted cosine similarity the predicted cosine similarity 1.0 Work done during internship at Meituan Inc. The first two authors contribute equally. Weiran Xu is the corresponding author. downstream tasks with additional supervision. However, the native sentence representations derived from BERT1 are proved to be of low-quality (Reimers and Gurevych, 2019; Li et al., 2020). As shown in Figure 1a, when directly adopt BERTbased sentence representations to semantic textual similarity (STS) tasks, almost all pairs of sentences achieved a similarity score between 0.6 to 1.0 , even if some pairs are regarded as completely unrelated by the human annotators. In other words, the BERT-derived native sentence representations are somehow collapsed (Chen and He, 2020), which means almost all sentences are mapped into a small area and therefore produce high similarity. Such phenomenon is also observed in several previous works (Gao et al., 2019; Wang et al."
2021.emnlp-main.296,D16-1147,0,0.158717,"ines, especially when the KB is incomplete. 1 Introduction Question Answering over Knowledge Base (KBQA) aims to find the answers to a natural language question given the structured knowledge base (KB) and is widely used in modern question answering and information retrieval systems. Traditional retrieval-based KBQA approaches typically build it as a pipeline system, including name entity recognization, entity linking, subgraph retrieval, and entity scoring. In recent years, with the help of deep representation learning, such approaches have achieved remarkable performance (Dong et al., 2015; Miller et al., 2016; Xu et al., 2016; Sun et al., 2018, 2019; Saxena et al., 2020; He et al., 2021). Correct Answer: NBA Most Improved Player Award √ Model Prediction: Lanier High School × CVT1 Monta Ellis NBA Most Improved Player Award Score: 0.59 CVT2 Lanier High School a) Shallow Matching: The model fails to interpret “career high points” as “honor” or “award”, but matched “high school” according to the surface similarity (the word “high”). Princess Margaret Question: what is the name of king george vi wife ? Correct Answer: Queen Elizabeth The Queen Mother Model Prediction: 1923-04-26 √ × Score: 0.05 Queen E"
2021.emnlp-main.296,D18-1455,0,0.0352503,"Missing"
2021.emnlp-main.296,P16-1220,0,0.0183228,"the KB is incomplete. 1 Introduction Question Answering over Knowledge Base (KBQA) aims to find the answers to a natural language question given the structured knowledge base (KB) and is widely used in modern question answering and information retrieval systems. Traditional retrieval-based KBQA approaches typically build it as a pipeline system, including name entity recognization, entity linking, subgraph retrieval, and entity scoring. In recent years, with the help of deep representation learning, such approaches have achieved remarkable performance (Dong et al., 2015; Miller et al., 2016; Xu et al., 2016; Sun et al., 2018, 2019; Saxena et al., 2020; He et al., 2021). Correct Answer: NBA Most Improved Player Award √ Model Prediction: Lanier High School × CVT1 Monta Ellis NBA Most Improved Player Award Score: 0.59 CVT2 Lanier High School a) Shallow Matching: The model fails to interpret “career high points” as “honor” or “award”, but matched “high school” according to the surface similarity (the word “high”). Princess Margaret Question: what is the name of king george vi wife ? Correct Answer: Queen Elizabeth The Queen Mother Model Prediction: 1923-04-26 √ × Score: 0.05 Queen Elizabeth The Quee"
2021.emnlp-main.296,P15-1128,0,0.0789627,"Missing"
2021.emnlp-main.315,D18-1316,0,0.0172934,"the Gaussian noise to produce multiple attack in NLP tasks has become an emerging remultinomial mixtures. After that, we aggregate search topic in recent years (Gao et al., 2018; Yang the candidate embeddings with the multinomial et al., 2020; Chen et al., 2020). Early works usumixtures to generate new embeddings (virtual data ally adopt heuristic rules to revise the input text for embeddings) to replace the original embedding of producing adversarial samples, including character “good”. There are two major advantages to our VDA ap- modification (Ebrahimi et al., 2018), synonyms replacement (Alzantot et al., 2018), word insertion proach. First, with the original token embeddings as the representation basis, the augmented embed- or deletion (Zhang et al., 2019). However, with the revolution of large-scale PLMs, these attack stratedings stay close to the existing embeddings, which avoids the unexpected drift of semantic space. Sec- gies can be defended (Jones et al., 2020; Gui et al., 2021; Zhou et al., 2020a) to some extent. To attack ond, with the injected Gaussian noise, we are able to generate diverse variations for augmentations. PLMs, TextFooler (Jin et al., 2020) designs an attack algorithm to rev"
2021.emnlp-main.315,2020.acl-main.777,0,0.0381119,"e which enhances the randomness of the augmenta- aspects. tions. As shown in Figure 1, for a target token 2.1 Adversarial Attack in NLP “good”, we first predict the substitution probabilities of candidate tokens via a masked language model, Inspired by the success in compute vision (Goodfellow et al., 2015; Kurakin et al., 2017), adversarial then inject the Gaussian noise to produce multiple attack in NLP tasks has become an emerging remultinomial mixtures. After that, we aggregate search topic in recent years (Gao et al., 2018; Yang the candidate embeddings with the multinomial et al., 2020; Chen et al., 2020). Early works usumixtures to generate new embeddings (virtual data ally adopt heuristic rules to revise the input text for embeddings) to replace the original embedding of producing adversarial samples, including character “good”. There are two major advantages to our VDA ap- modification (Ebrahimi et al., 2018), synonyms replacement (Alzantot et al., 2018), word insertion proach. First, with the original token embeddings as the representation basis, the augmented embed- or deletion (Zhang et al., 2019). However, with the revolution of large-scale PLMs, these attack stratedings stay close to t"
2021.emnlp-main.315,N19-1423,0,0.617017,"ty and flexibility is highly limited. ate the performance degradation under adverRecently, virtual adversarial training (Miyato sarial attacks. Our codes and data are publicly available at https://github.com/ et al., 2017; Madry et al., 2018) is applied to varRUCAIBox/VDA. ious NLP models for improving the performance and robustness (Zhu et al., 2020; Jiang et al., 2020), 1 Introduction which usually generates gradient-based perturbation on the embedding space as virtual adversarial Recently, pre-trained language models (PLMs) samples. However, it is hard to explicitly constrain such as BERT (Devlin et al., 2019) and the gradient-based perturbation within the same seRoBERTa (Liu et al., 2019) have achieved remarkmantic space as the original sample. In addition, unable success in various natural language processing like attacks in computer vision (Zheng et al., 2016; (NLP) tasks (Rajpurkar et al., 2016; Wang et al., Miyato et al., 2019), textual adversarial attacks are 2019; Zhou et al., 2020b). As a general and efdiscrete (e.g., word replacement) and are hard to fective approach, fine-tuning PLMs on specific be captured by gradient-based perturbations. datasets has become the mainstream paradigm for T"
2021.emnlp-main.315,I05-5002,0,0.0661587,"ed VDA framework. The best results in each group are highlighted in bold. • AG’s News (Zhang et al., 2015): a news-type classification dataset, containing 4 types of news: World, Sports, Business, and Science. • MR (Pang and Lee, 2005): a binary sentiment classification dataset based on movie reviews. Sentence-Pair Classification We also use two sentence-pair classification datasets for evaluation. • QNLI (Demszky et al., 2018): a questionanswering dataset consisting of question-paragraph pairs. The task is to determine whether the context sentence contains the answer to the question. • MRPC (Dolan and Brockett, 2005): a corpus of sentence pairs with human annotations about the semantic equivalence. training approach for fine-tuning PLMs, which adds gradient-based perturbations to token embeddings. We implement it on BERT-Base. • SMART (Jiang et al., 2020) is a robust and efficient computation framework for fine-tuning PLMs. Limited by the GPU resource, we can only implement the smooth-inducing adversarial regularization on BERT-Base but remove the Bregman Proximal Point Optimization. • SMix (Si et al., 2020) uses mixup on [CLS] tokens of the PLM to cover larger attack space. We implement it on BERT-Base."
2021.emnlp-main.315,P18-2006,0,0.0222167,"Kurakin et al., 2017), adversarial then inject the Gaussian noise to produce multiple attack in NLP tasks has become an emerging remultinomial mixtures. After that, we aggregate search topic in recent years (Gao et al., 2018; Yang the candidate embeddings with the multinomial et al., 2020; Chen et al., 2020). Early works usumixtures to generate new embeddings (virtual data ally adopt heuristic rules to revise the input text for embeddings) to replace the original embedding of producing adversarial samples, including character “good”. There are two major advantages to our VDA ap- modification (Ebrahimi et al., 2018), synonyms replacement (Alzantot et al., 2018), word insertion proach. First, with the original token embeddings as the representation basis, the augmented embed- or deletion (Zhang et al., 2019). However, with the revolution of large-scale PLMs, these attack stratedings stay close to the existing embeddings, which avoids the unexpected drift of semantic space. Sec- gies can be defended (Jones et al., 2020; Gui et al., 2021; Zhou et al., 2020a) to some extent. To attack ond, with the injected Gaussian noise, we are able to generate diverse variations for augmentations. PLMs, TextFooler (Jin et"
2021.emnlp-main.315,P17-2090,0,0.0302853,"we consider improving the put embeddings, it is agnostic to downstream tasks, robustness of PLMs against these adversarial attack methods via a new fine-tuning framework VDA. model architectures and learning strategies. To evaluate the effectiveness of our proposed VDA framework, we construct extensive experi- 2.2 Data Augmentation ments on six datasets. Results show that VDA can Data augmentation has been extensively studied boost the robustness of all the baseline models with- in NLP tasks for improving the robustness (Wang out performance degradation. We also find that our and Yang, 2015; Fadaee et al., 2017; Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works"
2021.emnlp-main.315,2021.acl-demo.41,0,0.0747825,"Missing"
2021.emnlp-main.315,2021.naacl-main.161,0,0.0365199,"u et al., 2020a) to some extent. To attack ond, with the injected Gaussian noise, we are able to generate diverse variations for augmentations. PLMs, TextFooler (Jin et al., 2020) designs an attack algorithm to revise the input data and queries In order to enhance the relevance with the given injected Gaussian noise, we further design a reg- the PLM several times to find important words for replacement, which greatly reduces the accuracy of ularized training strategy that guides the learning BERT. Following it, recent works (Li et al., 2020b; of the augmented virtual data towards the original He et al., 2021) continuously improve the quality predictions of PLMs. In this way, our approach has of the adversarial samples and the attack success considered both semantic relevance and sufficient diversity. Besides, since VDA only revises the in- ratio. In our approach, we consider improving the put embeddings, it is agnostic to downstream tasks, robustness of PLMs against these adversarial attack methods via a new fine-tuning framework VDA. model architectures and learning strategies. To evaluate the effectiveness of our proposed VDA framework, we construct extensive experi- 2.2 Data Augmentation ments"
2021.emnlp-main.315,C18-1105,0,0.0157111,"Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked language model with Gaussian noise to augment virtual examples for improving the robustness. our VDA is agnostic to downstream tasks, model architectures and learning strategies. 2.3 Virtual Adversarial Training To improve the robustness of neural networks against adversarial examples, virtual adversarial training (VAT) (Miyato et al"
2021.emnlp-main.315,D17-1215,0,0.19982,"rks (Schmidt et al., by small perturbations or intentional attacks. 2018; Yin et al., 2019; Jiang et al., 2020), a possiTo solve this issue, various data augmentable reason of the vulnerability is that these PLMs tion techniques are proposed to improve the do not generalize well on semantic neighborhood robustness of PLMs. However, it is still challenging to augment semantically relevant exaround each example in the representation space. amples with sufficient diversity. In this work, To solve this issue, adversarial data augmentation we present Virtual Data Augmentation (VDA), (ADA) methods (Jia and Liang, 2017; Wang and a general framework for robustly fine-tuning Bansal, 2018; Michel et al., 2019) have been proPLMs. Based on the original token embedposed by revising original data to augment attackdings, we construct a multinomial mixture for related data for training. However, due to the disaugmenting virtual data embeddings, where a crete nature of language, it is challenging to genmasked language model guarantees the semanerate semantically relevant and sufficiently diverse tic relevance and the Gaussian noise provides the augmentation diversity. Furthermore, a augmentations. Although attempts b"
2021.emnlp-main.315,2020.acl-main.197,0,0.0810086,"Missing"
2021.emnlp-main.315,2020.acl-main.245,0,0.0168752,"the input text for embeddings) to replace the original embedding of producing adversarial samples, including character “good”. There are two major advantages to our VDA ap- modification (Ebrahimi et al., 2018), synonyms replacement (Alzantot et al., 2018), word insertion proach. First, with the original token embeddings as the representation basis, the augmented embed- or deletion (Zhang et al., 2019). However, with the revolution of large-scale PLMs, these attack stratedings stay close to the existing embeddings, which avoids the unexpected drift of semantic space. Sec- gies can be defended (Jones et al., 2020; Gui et al., 2021; Zhou et al., 2020a) to some extent. To attack ond, with the injected Gaussian noise, we are able to generate diverse variations for augmentations. PLMs, TextFooler (Jin et al., 2020) designs an attack algorithm to revise the input data and queries In order to enhance the relevance with the given injected Gaussian noise, we further design a reg- the PLM several times to find important words for replacement, which greatly reduces the accuracy of ularized training strategy that guides the learning BERT. Following it, recent works (Li et al., 2020b; of the augmented virtual dat"
2021.emnlp-main.315,N18-2072,0,0.0193661,"at the embedding layer of PLMs. For the text classification task as an example task to adversarial training, continuous embeddings are illustrate our approach, where a set of n labeled easier to optimize and can encode more semantic texts {hxi , yi i} are available. Each labeled text variations than discrete tokens. The key idea of consists of a text xi and a label yi from the label set embedding augmentation is inspired by the word Y. We refer to the adversarial example generated replacement strategy in previous data augmentation from a text xi as adversarial text, denoted by x ˆi . methods (Kobayashi, 2018; Wei and Zou, 2019). The purpose of adversarial examples is to enhance Instead of selecting some tokens for replacement, the model robustness in resisting intentional data we use an augmented embedding to replace the perturbations or attacks. original contextual embedding of a specific token 3877 Input: Time is enough for test Generate Substitution Probability 0.50 Time 0.30 Day 0.15 Hours … … 0.50 test 0.30 evaluation 0.10 experiment … embeddings for augmentation. Such a strategy is also very efficient in practice, since it no longer performs the costly mask-and-completion operations for eac"
2021.emnlp-main.315,N19-1314,0,0.0906491,"9; Jiang et al., 2020), a possiTo solve this issue, various data augmentable reason of the vulnerability is that these PLMs tion techniques are proposed to improve the do not generalize well on semantic neighborhood robustness of PLMs. However, it is still challenging to augment semantically relevant exaround each example in the representation space. amples with sufficient diversity. In this work, To solve this issue, adversarial data augmentation we present Virtual Data Augmentation (VDA), (ADA) methods (Jia and Liang, 2017; Wang and a general framework for robustly fine-tuning Bansal, 2018; Michel et al., 2019) have been proPLMs. Based on the original token embedposed by revising original data to augment attackdings, we construct a multinomial mixture for related data for training. However, due to the disaugmenting virtual data embeddings, where a crete nature of language, it is challenging to genmasked language model guarantees the semanerate semantically relevant and sufficiently diverse tic relevance and the Gaussian noise provides the augmentation diversity. Furthermore, a augmentations. Although attempts by leveraging regularized training strategy is proposed to balexpert knowledge (Ren et al.,"
2021.emnlp-main.315,2021.naacl-main.400,0,0.0605639,"Missing"
2021.emnlp-main.315,D19-1570,0,0.13537,"een proPLMs. Based on the original token embedposed by revising original data to augment attackdings, we construct a multinomial mixture for related data for training. However, due to the disaugmenting virtual data embeddings, where a crete nature of language, it is challenging to genmasked language model guarantees the semanerate semantically relevant and sufficiently diverse tic relevance and the Gaussian noise provides the augmentation diversity. Furthermore, a augmentations. Although attempts by leveraging regularized training strategy is proposed to balexpert knowledge (Ren et al., 2019; Li et al., 2019b) ance the two aspects. Extensive experiments and victim models (Jin et al., 2020; Li et al., 2020b) on six datasets show that our approach is able have achieved better performance, their generalizto improve the robustness of PLMs and alleviability and flexibility is highly limited. ate the performance degradation under adverRecently, virtual adversarial training (Miyato sarial attacks. Our codes and data are publicly available at https://github.com/ et al., 2017; Madry et al., 2018) is applied to varRUCAIBox/VDA. ious NLP models for improving the performance and robustness (Zhu et al., 2020;"
2021.emnlp-main.315,2020.emnlp-main.500,0,0.210446,"s, we construct a multinomial mixture for related data for training. However, due to the disaugmenting virtual data embeddings, where a crete nature of language, it is challenging to genmasked language model guarantees the semanerate semantically relevant and sufficiently diverse tic relevance and the Gaussian noise provides the augmentation diversity. Furthermore, a augmentations. Although attempts by leveraging regularized training strategy is proposed to balexpert knowledge (Ren et al., 2019; Li et al., 2019b) ance the two aspects. Extensive experiments and victim models (Jin et al., 2020; Li et al., 2020b) on six datasets show that our approach is able have achieved better performance, their generalizto improve the robustness of PLMs and alleviability and flexibility is highly limited. ate the performance degradation under adverRecently, virtual adversarial training (Miyato sarial attacks. Our codes and data are publicly available at https://github.com/ et al., 2017; Madry et al., 2018) is applied to varRUCAIBox/VDA. ious NLP models for improving the performance and robustness (Zhu et al., 2020; Jiang et al., 2020), 1 Introduction which usually generates gradient-based perturbation on the emb"
2021.emnlp-main.315,2021.ccl-1.108,0,0.0759839,"Missing"
2021.emnlp-main.315,2020.acl-main.212,0,0.0181695,"tation ments on six datasets. Results show that VDA can Data augmentation has been extensively studied boost the robustness of all the baseline models with- in NLP tasks for improving the robustness (Wang out performance degradation. We also find that our and Yang, 2015; Fadaee et al., 2017; Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked language model with Gaussian noise to augmen"
2021.emnlp-main.315,P05-1015,0,0.0754541,"483 10.727 14.400 9.232 12.785 9.816 12.733 9.588 11.469 Perturb 20.291 22.775 20.266 21.557 20.514 23.386 21.842 20.874 27.128 24.310 Table 2: Main results on the sentence classification task. Ori Acc, Att acc, Q Num and Perturb denote the original accuracy, attack accuracy, query number and perturbed percentage per sample. “V DA ” denotes that the model is trained with our proposed VDA framework. The best results in each group are highlighted in bold. • AG’s News (Zhang et al., 2015): a news-type classification dataset, containing 4 types of news: World, Sports, Business, and Science. • MR (Pang and Lee, 2005): a binary sentiment classification dataset based on movie reviews. Sentence-Pair Classification We also use two sentence-pair classification datasets for evaluation. • QNLI (Demszky et al., 2018): a questionanswering dataset consisting of question-paragraph pairs. The task is to determine whether the context sentence contains the answer to the question. • MRPC (Dolan and Brockett, 2005): a corpus of sentence pairs with human annotations about the semantic equivalence. training approach for fine-tuning PLMs, which adds gradient-based perturbations to token embeddings. We implement it on BERT-B"
2021.emnlp-main.315,P19-1103,0,0.0287666,"al., 2019) have been proPLMs. Based on the original token embedposed by revising original data to augment attackdings, we construct a multinomial mixture for related data for training. However, due to the disaugmenting virtual data embeddings, where a crete nature of language, it is challenging to genmasked language model guarantees the semanerate semantically relevant and sufficiently diverse tic relevance and the Gaussian noise provides the augmentation diversity. Furthermore, a augmentations. Although attempts by leveraging regularized training strategy is proposed to balexpert knowledge (Ren et al., 2019; Li et al., 2019b) ance the two aspects. Extensive experiments and victim models (Jin et al., 2020; Li et al., 2020b) on six datasets show that our approach is able have achieved better performance, their generalizto improve the robustness of PLMs and alleviability and flexibility is highly limited. ate the performance degradation under adverRecently, virtual adversarial training (Miyato sarial attacks. Our codes and data are publicly available at https://github.com/ et al., 2017; Madry et al., 2018) is applied to varRUCAIBox/VDA. ious NLP models for improving the performance and robustness ("
2021.emnlp-main.315,P18-1079,0,0.0204922,"with- in NLP tasks for improving the robustness (Wang out performance degradation. We also find that our and Yang, 2015; Fadaee et al., 2017; Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked language model with Gaussian noise to augment virtual examples for improving the robustness. our VDA is agnostic to downstream tasks, model architectures and learning strategies. 2.3 Virtual Adversar"
2021.emnlp-main.315,2020.emnlp-main.495,0,0.0151728,"(Wang out performance degradation. We also find that our and Yang, 2015; Fadaee et al., 2017; Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked language model with Gaussian noise to augment virtual examples for improving the robustness. our VDA is agnostic to downstream tasks, model architectures and learning strategies. 2.3 Virtual Adversarial Training To improve the robustness of n"
2021.emnlp-main.315,D15-1306,0,0.0639418,"Missing"
2021.emnlp-main.315,N18-2091,0,0.100102,"construct extensive experi- 2.2 Data Augmentation ments on six datasets. Results show that VDA can Data augmentation has been extensively studied boost the robustness of all the baseline models with- in NLP tasks for improving the robustness (Wang out performance degradation. We also find that our and Yang, 2015; Fadaee et al., 2017; Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked langua"
2021.emnlp-main.315,D19-1670,0,0.262431,"that VDA can Data augmentation has been extensively studied boost the robustness of all the baseline models with- in NLP tasks for improving the robustness (Wang out performance degradation. We also find that our and Yang, 2015; Fadaee et al., 2017; Wei and approach can be further improved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked language model with Gaussian noise to augment virtual examples for improving the robustn"
2021.emnlp-main.315,P19-1559,0,0.0201152,"nt years (Gao et al., 2018; Yang the candidate embeddings with the multinomial et al., 2020; Chen et al., 2020). Early works usumixtures to generate new embeddings (virtual data ally adopt heuristic rules to revise the input text for embeddings) to replace the original embedding of producing adversarial samples, including character “good”. There are two major advantages to our VDA ap- modification (Ebrahimi et al., 2018), synonyms replacement (Alzantot et al., 2018), word insertion proach. First, with the original token embeddings as the representation basis, the augmented embed- or deletion (Zhang et al., 2019). However, with the revolution of large-scale PLMs, these attack stratedings stay close to the existing embeddings, which avoids the unexpected drift of semantic space. Sec- gies can be defended (Jones et al., 2020; Gui et al., 2021; Zhou et al., 2020a) to some extent. To attack ond, with the injected Gaussian noise, we are able to generate diverse variations for augmentations. PLMs, TextFooler (Jin et al., 2020) designs an attack algorithm to revise the input data and queries In order to enhance the relevance with the given injected Gaussian noise, we further design a reg- the PLM several tim"
2021.emnlp-main.315,D19-1192,1,0.829925,"roved by combining it Zou, 2019). Similar to adversarial attack, early with traditional adversarial data augmentation. works mostly try heuristic rules to revise the in3876 put data for augmentation, such as synonym replacement (Wang and Bansal, 2018), grammar induction (Min et al., 2020), word insert and delete (Wei and Zou, 2019). With the development of text generation techniques, back translation (Xie et al., 2020; Ribeiro et al., 2018) and variant autoencoder (Wang et al., 2020; Li et al., 2019c) are used to augment new data. Besides, a surge of works (Hou et al., 2018; Li et al., 2019a; Zhou et al., 2019) focus on augmentation for specific tasks with special rules or models. Although they perform well, these methods have lost the generality. In this paper, we propose a new data augmentation framework VDA that utilizes a masked language model with Gaussian noise to augment virtual examples for improving the robustness. our VDA is agnostic to downstream tasks, model architectures and learning strategies. 2.3 Virtual Adversarial Training To improve the robustness of neural networks against adversarial examples, virtual adversarial training (VAT) (Miyato et al., 2015; Kurakin et al., 2017; Qin et"
2021.emnlp-main.315,2020.coling-main.365,1,0.90304,"which usually generates gradient-based perturbation on the embedding space as virtual adversarial Recently, pre-trained language models (PLMs) samples. However, it is hard to explicitly constrain such as BERT (Devlin et al., 2019) and the gradient-based perturbation within the same seRoBERTa (Liu et al., 2019) have achieved remarkmantic space as the original sample. In addition, unable success in various natural language processing like attacks in computer vision (Zheng et al., 2016; (NLP) tasks (Rajpurkar et al., 2016; Wang et al., Miyato et al., 2019), textual adversarial attacks are 2019; Zhou et al., 2020b). As a general and efdiscrete (e.g., word replacement) and are hard to fective approach, fine-tuning PLMs on specific be captured by gradient-based perturbations. datasets has become the mainstream paradigm for To solve these challenges, we propose Virtual developing NLP applications. Despite the success, Data Augmentation (VDA), a robust and general researchers have found that PLMs can be easily framework for fine-tuning pre-trained models. Our fooled by adversarial attacks (Jin et al., 2020; Li idea is to generate data augmentations at the emet al., 2020b). Although encapsulated into a bla"
2021.findings-acl.440,D18-1547,0,0.0549098,"Missing"
2021.findings-acl.440,P19-1544,0,0.0386671,"Missing"
2021.findings-acl.440,N18-2118,0,0.0270071,"also propose a STM-based method to select source slots and their labeled data for training slot filling model for target slots. 3. Experimental results on several existing models and datasets show that this method brings consistent performance improvement for cross-domain slot filling. 2 Related work As a key component of dialog system, the slot filling task has been studied extensively. Traditional supervised learning methods have made great achievements with a large amount of labeled data (Liu and Lane; Mesnil et al., 2015; Hakkani-T¨ur et al., 2016; Kurata et al., 2016; Liu and Lane, 2016; Goo et al., 2018; E et al., 2019). However, there is little or even no labeled data for a new task, the cross-domain slot filling task which uses labeled data in source tasks to training model for target task is gaining increasing attention (Yazdani and Henderson, 2015; Bapna et al., 2017; Zhu and Yu, 2018; Lee and Jha, 2019; Shah et al., 2019; Liu et al., 2020; Zhu et al., 2020). There are mainly two streams of methods in previous work. The first is to establish implicit semantic alignment of the slot representations between the source task and the target task (Bapna et al., 2017; Lee and Jha, 2019; Shah et"
2021.findings-acl.440,D16-1223,0,0.0292935,"slots. The STM is model-agnostic. 2. We also propose a STM-based method to select source slots and their labeled data for training slot filling model for target slots. 3. Experimental results on several existing models and datasets show that this method brings consistent performance improvement for cross-domain slot filling. 2 Related work As a key component of dialog system, the slot filling task has been studied extensively. Traditional supervised learning methods have made great achievements with a large amount of labeled data (Liu and Lane; Mesnil et al., 2015; Hakkani-T¨ur et al., 2016; Kurata et al., 2016; Liu and Lane, 2016; Goo et al., 2018; E et al., 2019). However, there is little or even no labeled data for a new task, the cross-domain slot filling task which uses labeled data in source tasks to training model for target task is gaining increasing attention (Yazdani and Henderson, 2015; Bapna et al., 2017; Zhu and Yu, 2018; Lee and Jha, 2019; Shah et al., 2019; Liu et al., 2020; Zhu et al., 2020). There are mainly two streams of methods in previous work. The first is to establish implicit semantic alignment of the slot representations between the source task and the target task (Bapna et"
2021.findings-acl.440,2020.acl-main.3,0,0.325529,"How to train the slot filling model in the new task (target task) with the labeled data of one or more existing tasks (source tasks) is of great significance for the rapid expansion of the application of task-oriented dialog systems. Existing work can be mainly classified into two categories. The first is to establish implicit semantic alignment between slot representations of the source task and the target task, the model trained with the source task data is directly used for the target task (Bapna et al., 2017; Lee and Jha, 2019; Shah et al., 2019). The second is to use a twostage strategy (Liu et al., 2020), which treats all slot values as entities. First, it trains a generic entity recognition model using source task labeled data to identify all candidate slot values in the target task. Then, the candidate slot value is classified into the target task slot by comparing the similarity between its representation and the target task slot information. Most of the existing work has focused on building cross-task transferable models that leverage the association information between source tasks and target tasks, and the model is always trained using the labeled data of all the source tasks without di"
2021.findings-acl.440,D14-1162,0,0.0894745,"ained slot type classification, and uses slot descriptions in the second stage to help recognize unseen slots. Coach+TR A variant of Coach proposed by Liu et al. (2020), which further uses template regularization on the basis of Coach to improve the performance of the model on similar or the same slots, is the state-of-the-art model. 4.3 Implementation Details We deploy the proposed method on above slot filling models CT, RZT, Coach, and Coach+TR. β is set to 1. A two-layer BiLSTM (Schmidhuber and Hochreiter, 1997) model is used for selecting source slots for all models. 300 dimensions Glove (Pennington et al., 2014) vector is used for word embedding. The hidden layer dimension is set to 300, the learning rate is 0.001. We train the model 30 epochs and select the model with the best performance on the validation set as the final model. 4974 Model Data/Domain ↓ Training Setting → attraction hotel restaurant MWS taxi train Average F1 AddToPlaylist BookRestaurant GetWeather PlayMusic SNIPS RateBook SearchCreativeWork SearchScreeningEvent Average F1 ALL 74.52 58.81 69.93 51.61 80.78 67.13 38.82 27.54 46.45 32.86 14.54 39.79 13.83 30.55 CT STM1 84.99 47.73 63.47 69.32 79.66 69.03 41.95 31.17 53.03 23.09 15.39"
2021.findings-acl.440,P19-1547,0,0.221603,"ere is usually little or even no labeled data for a new task. How to train the slot filling model in the new task (target task) with the labeled data of one or more existing tasks (source tasks) is of great significance for the rapid expansion of the application of task-oriented dialog systems. Existing work can be mainly classified into two categories. The first is to establish implicit semantic alignment between slot representations of the source task and the target task, the model trained with the source task data is directly used for the target task (Bapna et al., 2017; Lee and Jha, 2019; Shah et al., 2019). The second is to use a twostage strategy (Liu et al., 2020), which treats all slot values as entities. First, it trains a generic entity recognition model using source task labeled data to identify all candidate slot values in the target task. Then, the candidate slot value is classified into the target task slot by comparing the similarity between its representation and the target task slot information. Most of the existing work has focused on building cross-task transferable models that leverage the association information between source tasks and target tasks, and the model is always trai"
2021.findings-acl.440,D15-1027,0,0.0304631,"e improvement for cross-domain slot filling. 2 Related work As a key component of dialog system, the slot filling task has been studied extensively. Traditional supervised learning methods have made great achievements with a large amount of labeled data (Liu and Lane; Mesnil et al., 2015; Hakkani-T¨ur et al., 2016; Kurata et al., 2016; Liu and Lane, 2016; Goo et al., 2018; E et al., 2019). However, there is little or even no labeled data for a new task, the cross-domain slot filling task which uses labeled data in source tasks to training model for target task is gaining increasing attention (Yazdani and Henderson, 2015; Bapna et al., 2017; Zhu and Yu, 2018; Lee and Jha, 2019; Shah et al., 2019; Liu et al., 2020; Zhu et al., 2020). There are mainly two streams of methods in previous work. The first is to establish implicit semantic alignment of the slot representations between the source task and the target task (Bapna et al., 2017; Lee and Jha, 2019; Shah et al., 2019; Liu et al., 2020). Bapna et al. (2017) proposed the Concept Tagging model (CT), which unified the slot filling model on the source tasks and the target task by combining the slot representations modeled by slot description information, and th"
2021.findings-acl.440,W18-5047,0,0.0126386,"lated work As a key component of dialog system, the slot filling task has been studied extensively. Traditional supervised learning methods have made great achievements with a large amount of labeled data (Liu and Lane; Mesnil et al., 2015; Hakkani-T¨ur et al., 2016; Kurata et al., 2016; Liu and Lane, 2016; Goo et al., 2018; E et al., 2019). However, there is little or even no labeled data for a new task, the cross-domain slot filling task which uses labeled data in source tasks to training model for target task is gaining increasing attention (Yazdani and Henderson, 2015; Bapna et al., 2017; Zhu and Yu, 2018; Lee and Jha, 2019; Shah et al., 2019; Liu et al., 2020; Zhu et al., 2020). There are mainly two streams of methods in previous work. The first is to establish implicit semantic alignment of the slot representations between the source task and the target task (Bapna et al., 2017; Lee and Jha, 2019; Shah et al., 2019; Liu et al., 2020). Bapna et al. (2017) proposed the Concept Tagging model (CT), which unified the slot filling model on the source tasks and the target task by combining the slot representations modeled by slot description information, and then conducting BIO 3-way classification"
2021.findings-emnlp.368,D19-1015,0,0.0628542,"Missing"
2021.findings-emnlp.368,D19-1410,0,0.0152577,"er of the corresponding dataset. Such warmup strategy increases learning rate linearly between the first and second dialogue labels reassignment until lrmax , then decreases proportionally. Raw feature based models. Using bag of words model (BOW) and TF-IDF feature to represent dialogues, and clustering with LDA (Blei et al., 2001), K-means and GMM algorithms respectively. Pretrained feature based models. Representing dialogues with the mean values of all utterance representations extracted from official pretrained SkipThought (Kiros et al., 2015), TODBert (Wu et al., 2020a) and SentenceBert (Reimers and Gurevych, 2019) models, then cluster with GMM. Deep clustering models. Four popular deep clustering models are adopted as strong baselines. DCN (Yang et al., 2017) used k-means clustering loss to learn clustering friendly representations. VaDE (Jiang et al., 2017) is a generative deep clustering model based on variational autoencoder. DEC (Xie et al., 2016) designed a clustering objective to guide the learning of the data representations. IDEC (Guo et al., 2017) is a modified version of DEC with a reconstruction loss to preserve local structure. We run 5 times continuously for all baselines, and then report"
2021.findings-emnlp.368,P19-1003,0,0.0273479,"atasets show that our model significantly outperformed strong baselines in all metrics1 . Figure 1: From top to down, the figure shows an example of in-dialogue discourse relation of utterances. From left to right, the figure shows an example of cross-dialogue similarity relation of utterances, the implicit task-related concepts information like &quot;informintent:search-house&quot; can be concluded from different dialogues by grouping the utterances with similar semantic. dialogues directly. The first difficulty is that coreference and information omission occur frequently 1 Introduction in dialogues (Su et al., 2019), which makes it harder Task-Oriented Dialogue Clustering (TODC) aims to build a good representation for utterances in dito group task-oriented dialogues into different clus- alogue than in normal text. The second difficulty ters according to their underlying tasks. Since each is that the task-related slot names and intents are cluster includes dialogues for one specific task, it scattered in each utterance implicitly and expressed therefore brings convenience for task induction and diversely. In most cases, only slots values are given definition. Especially for large unlabeled human- in dialo"
2021.findings-emnlp.368,2020.emnlp-main.66,0,0.146148,"posed dialogue representation method can capture more task-related information. In summary, the contributions of our paper are as follows: space and then directly fed into a clustering algorithm to cluster. In the recent years, owing to the development of deep learning, more and more deep clustering methods (Caron et al., 2018; Xie et al., 2016; Guo et al., 2017; Yang et al., 2017; Jiang et al., 2017) were proposed, which can obtain feature representations and cluster assignments simultaneously. Graph Neural Network Recently, there has been a surge of interest in Graph Neural Networks (GNNs) (Wu et al., 2020b) approaches for graph representation learning. Some GNN variants (Velickovic et al., 2018; Kipf and Welling, 2017) are proposed and also applied in dialogue related tasks. Chen et al. (2020) proposed Graph Attention Matching Network and Recurrent Graph Attention Network based on Graph Attention Network to encode utterances, schema graphs and previous dialogue states. Ghosal et al. (2019) proposed Dialogue Graph Convolutional Network based on Graph Convolutional Network (Kipf and Welling, 2017) to model inter and self-party dependency to improve context understanding. • We propose an unsuperv"
2021.findings-emnlp.368,2020.nlp4convai-1.13,0,0.0253496,"ning epochs maxep . The last dialogue clustering assignment is used as the final clustering results. The loss is defined by Eq.14, LJoint = Lud + β · Lucrl + Lcls (14) where β is loss coefficient. 5 5.1 Experiments Datasets In order to better evaluate the performance of different algorithms on TODC, we constructed three pubA two-stage training strategy including pre-training lic task-divided dialogue datasets based on Schemaand joint-training is employed for model training. Guided Dialogue (SGD) (Rastogi et al., 2020) and In the pre-training stage, learning the context-aware Multiwoz dataset (Zang et al., 2020). In both SGD utterance representation gi for each utterance with and Multiwoz datasets, we determine whether two 4342 4.7 Model Training Process Datasets SGD-S SGD-M Multiwoz-T Tasks Number Dialogues Number Dialogues Length(avg) 29 3925 15.57 59 4722 21.68 35 9695 13.94 Table 1: The statistics of the datasets. dialogues belong to the same dialogue task by judging whether the two dialogues contain the same set of active-intents. Finally, three datasets labeled by dialogue task are constructed: SGD-S includessingle domain dialogues of SGD dataset, SGDM includes multiple-domains dialogues of SGD"
2021.naacl-main.167,D19-1467,0,0.719682,"Missing"
2021.naacl-main.167,D19-1654,0,0.201754,"ce on ASAP. To make a fair comparison, we also perform ACSA experiments on a widely Aspect Category Sentiment Analysis. used SemEval-2014 restaurant review dataset (Pon- ACSA (Zhou et al., 2015; Movahedi et al., tiki et al., 2014). Since BERT (Devlin et al., 2019; Ruder et al., 2016; Hu et al., 2018) aims 2018) has achieved great success in several nat- to predict sentiment polarities on all aspect ural language understanding tasks including sen- categories mentioned in the text. The series of timent analysis (Xu et al., 2019; Sun et al., 2019; SemEval datasets consisting of user reviews from Jiang et al., 2019), we propose a joint model that e-commerce websites have been widely used and 2070 pushed forward related research (Wang et al., 2016; Ma et al., 2017; Xu et al., 2019; Sun et al., 2019; Jiang et al., 2019). The SemEval-2014 task-4 dataset (SE-ABSA14) (Pontiki et al., 2014) is composed of laptop and restaurant reviews. The restaurant subset includes 5 aspect categories (i.e., Food, Service, Price, Ambience and Anecdotes/Miscellaneous) and 4 polarity labels (i.e., Positive, Negative, Conflict and Neutral). The laptop subset is not suitable for ACSA. The SemEval-2015 task-12 dataset (SE-ABSA15)"
2021.naacl-main.167,D14-1181,0,0.00980001,"Missing"
2021.naacl-main.167,S14-2076,0,0.0421375,"Missing"
2021.naacl-main.167,C18-1079,0,0.0770828,"isplays a sample of 5-star rating to the coffee shop. In comparison to fine-grained aspect sentiment, the overall review rating is usually a coarse-grained synthesis of the opinions on multiple aspects. Rating pre1 https://www.taobao.com/ https://www.dianping.com/ 3 https://www.koubei.com/ ∗ 2 Equal contribution. † Corresponding author. 2069 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2069–2079 June 6–11, 2021. ©2021 Association for Computational Linguistics diction(RP) (Jin et al., 2016; Li et al., 2018; Wu et al., 2019a) which aims to predict the “seeing stars” of reviews also has wide applications. For example, to promise the aspect-based sentiment text-boxes accurate, unreliable reviews should be removed before ACSA algorithms are performed. Given a piece of user review, we can predict a rating for it based on the overall sentiment polarity underlying the text. We assume the predicted rating of the review should be consistent with its groundtruth rating as long as the review is reliable. If the predicted rating and the user rating of a review disagree with each other explicitly, the relia"
2021.naacl-main.167,D14-1162,0,0.0853255,"TM+Attn (Zhou et al., 2016), ATAE-LSTM (Wang et al., 2016) and CapsNet (Sabour et al., 2017). BERT-based models include vanilla BERT (Devlin et al., 2018), QABERT (Sun et al., 2019) and CapsNet-BERT (Jiang et al., 2019). Implementation Details of Experimental Models In terms of non-BERT-based models, we initialize their inputs with pre-trained embeddings. For Chinese ASAP, we utilize Jieba8 to segment Chinese texts and adopt Tencent Chinese word embeddings (Song et al., 2018) composed of 8, 000, 000 words. For English R ESTAURANT, we adopt 300-dimensional word embeddings pre-trained by Glove (Pennington et al., 2014). In terms of BERT-based models, we adopt the 12-layer Google BERT Base9 to encode the inputs. The batch sizes are set as 32 and 16 for nonBERT-based models and BERT-based models respectively. Adam optimizer (Kingma and Ba, 2014) is employed with β1 = 0.9 and β2 = 0.999. The maximum sequence length is set as 512. The number of epochs is set as 3. The learning rates are set as 0.001 and 0.00005 for non-BERT-based models and BERT-based models respectively. All the models are trained on a single NVIDIA Tesla 32G V100 Volta GPU. Evaluation Metrics Following the settings of R ESTAURANT, we adopt Ma"
2021.naacl-main.167,S15-2082,0,0.124377,"Missing"
2021.naacl-main.167,S14-2004,0,0.173979,"t al., 2016; Hu et al., 2018) aims 2018) has achieved great success in several nat- to predict sentiment polarities on all aspect ural language understanding tasks including sen- categories mentioned in the text. The series of timent analysis (Xu et al., 2019; Sun et al., 2019; SemEval datasets consisting of user reviews from Jiang et al., 2019), we propose a joint model that e-commerce websites have been widely used and 2070 pushed forward related research (Wang et al., 2016; Ma et al., 2017; Xu et al., 2019; Sun et al., 2019; Jiang et al., 2019). The SemEval-2014 task-4 dataset (SE-ABSA14) (Pontiki et al., 2014) is composed of laptop and restaurant reviews. The restaurant subset includes 5 aspect categories (i.e., Food, Service, Price, Ambience and Anecdotes/Miscellaneous) and 4 polarity labels (i.e., Positive, Negative, Conflict and Neutral). The laptop subset is not suitable for ACSA. The SemEval-2015 task-12 dataset (SE-ABSA15) (Pontiki et al., 2015) builds upon SE-ABSA14 and defines its aspect category as a combination of an entity type and an attribute type(e.g., Food#Style Options). The SemEval2016 task-5 dataset (SE-ABSA16) (Pontiki et al., 2016) extends SE-ABSA15 to new domains and new langua"
2021.naacl-main.167,S16-1002,0,0.0582738,"Missing"
2021.naacl-main.167,D16-1103,0,0.234028,"the performance of widely used models for ACSA and RP on ASAP. (3) We propose a joint learning model for ACSA and RP tasks. Our model achieves the best results both on ASAP and SemEval R ESTAURANT datasets. We implement several state-of-the-art (SOTA) baselines for ACSA and RP and evaluate their per2 Related Work and Datasets formance on ASAP. To make a fair comparison, we also perform ACSA experiments on a widely Aspect Category Sentiment Analysis. used SemEval-2014 restaurant review dataset (Pon- ACSA (Zhou et al., 2015; Movahedi et al., tiki et al., 2014). Since BERT (Devlin et al., 2019; Ruder et al., 2016; Hu et al., 2018) aims 2018) has achieved great success in several nat- to predict sentiment polarities on all aspect ural language understanding tasks including sen- categories mentioned in the text. The series of timent analysis (Xu et al., 2019; Sun et al., 2019; SemEval datasets consisting of user reviews from Jiang et al., 2019), we propose a joint model that e-commerce websites have been widely used and 2070 pushed forward related research (Wang et al., 2016; Ma et al., 2017; Xu et al., 2019; Sun et al., 2019; Jiang et al., 2019). The SemEval-2014 task-4 dataset (SE-ABSA14) (Pontiki et"
2021.naacl-main.167,I08-1040,0,0.0575472,"., 2015) builds upon SE-ABSA14 and defines its aspect category as a combination of an entity type and an attribute type(e.g., Food#Style Options). The SemEval2016 task-5 dataset (SE-ABSA16) (Pontiki et al., 2016) extends SE-ABSA15 to new domains and new languages other than English. MAMS (Jiang et al., 2019) tailors SE-ABSA14 to make it more challenging, in which each sentence contains at least two aspects with different sentiment polarities. Compared with the prosperity of English resources, high-quality Chinese datasets are not rich enough. “ChnSentiCorp” (Tan and Zhang, 2008), “IT168TEST” (Zagibalov and Carroll, 2008), “Weibo”4 , “CTB” (Li et al., 2014) are 4 popular Chinese datasets for general sentiment analysis. However, aspect category information is not annotated in these datasets. Zhao et al. (2014) presents two Chinese ABSA datasets for consumer electronics (mobile phones and cameras). Nevertheless, the two datasets only contain 400 documents (∼ 4000 sentences), in which each sentence only mentions one aspect category at most. BDCI5 automobile opinion mining and sentiment analysis dataset (Dai et al., 2019) contains 8, 290 user reviews in automobile industry with 10 predefined categories. Peng et al"
2021.naacl-main.167,P16-2034,0,0.0187687,"6 52, 225 7, 192 7, 026 498 94 1, 219 151 165 - 1, 258 166 173 - 5, 241 784 717 - 13, 362 1, 734 1, 867 - 15, 770 2, 105 2, 018 - 133, 721 27, 425 18, 176 3, 733 17, 523 3, 813 2150 822 645 215 and R ESTAURANT (Pontiki et al., 2014). Ablation studies are also conducted to probe the interactive influence between ACSA and RP. 5.1 ACSA Baseline Models We implement several ACSA baselines for comparison. According to the different structures of their encoders, these models are classified into Non-BERT based models or BERTbased models. Non-BERT based models include TextCNN (Kim, 2014), BiLSTM+Attn (Zhou et al., 2016), ATAE-LSTM (Wang et al., 2016) and CapsNet (Sabour et al., 2017). BERT-based models include vanilla BERT (Devlin et al., 2018), QABERT (Sun et al., 2019) and CapsNet-BERT (Jiang et al., 2019). Implementation Details of Experimental Models In terms of non-BERT-based models, we initialize their inputs with pre-trained embeddings. For Chinese ASAP, we utilize Jieba8 to segment Chinese texts and adopt Tencent Chinese word embeddings (Song et al., 2018) composed of 8, 000, 000 words. For English R ESTAURANT, we adopt 300-dimensional word embeddings pre-trained by Glove (Pennington et al., 2014). I"
2021.naacl-main.167,N18-2028,0,0.027291,"oders, these models are classified into Non-BERT based models or BERTbased models. Non-BERT based models include TextCNN (Kim, 2014), BiLSTM+Attn (Zhou et al., 2016), ATAE-LSTM (Wang et al., 2016) and CapsNet (Sabour et al., 2017). BERT-based models include vanilla BERT (Devlin et al., 2018), QABERT (Sun et al., 2019) and CapsNet-BERT (Jiang et al., 2019). Implementation Details of Experimental Models In terms of non-BERT-based models, we initialize their inputs with pre-trained embeddings. For Chinese ASAP, we utilize Jieba8 to segment Chinese texts and adopt Tencent Chinese word embeddings (Song et al., 2018) composed of 8, 000, 000 words. For English R ESTAURANT, we adopt 300-dimensional word embeddings pre-trained by Glove (Pennington et al., 2014). In terms of BERT-based models, we adopt the 12-layer Google BERT Base9 to encode the inputs. The batch sizes are set as 32 and 16 for nonBERT-based models and BERT-based models respectively. Adam optimizer (Kingma and Ba, 2014) is employed with β1 = 0.9 and β2 = 0.999. The maximum sequence length is set as 512. The number of epochs is set as 3. The learning rates are set as 0.001 and 0.00005 for non-BERT-based models and BERT-based models respectivel"
2021.naacl-main.167,N19-1035,0,0.569987,"CSA and RP and evaluate their per2 Related Work and Datasets formance on ASAP. To make a fair comparison, we also perform ACSA experiments on a widely Aspect Category Sentiment Analysis. used SemEval-2014 restaurant review dataset (Pon- ACSA (Zhou et al., 2015; Movahedi et al., tiki et al., 2014). Since BERT (Devlin et al., 2019; Ruder et al., 2016; Hu et al., 2018) aims 2018) has achieved great success in several nat- to predict sentiment polarities on all aspect ural language understanding tasks including sen- categories mentioned in the text. The series of timent analysis (Xu et al., 2019; Sun et al., 2019; SemEval datasets consisting of user reviews from Jiang et al., 2019), we propose a joint model that e-commerce websites have been widely used and 2070 pushed forward related research (Wang et al., 2016; Ma et al., 2017; Xu et al., 2019; Sun et al., 2019; Jiang et al., 2019). The SemEval-2014 task-4 dataset (SE-ABSA14) (Pontiki et al., 2014) is composed of laptop and restaurant reviews. The restaurant subset includes 5 aspect categories (i.e., Food, Service, Price, Ambience and Anecdotes/Miscellaneous) and 4 polarity labels (i.e., Positive, Negative, Conflict and Neutral). The laptop subset i"
2021.naacl-main.167,D16-1058,0,0.708859,"14 restaurant review dataset (Pon- ACSA (Zhou et al., 2015; Movahedi et al., tiki et al., 2014). Since BERT (Devlin et al., 2019; Ruder et al., 2016; Hu et al., 2018) aims 2018) has achieved great success in several nat- to predict sentiment polarities on all aspect ural language understanding tasks including sen- categories mentioned in the text. The series of timent analysis (Xu et al., 2019; Sun et al., 2019; SemEval datasets consisting of user reviews from Jiang et al., 2019), we propose a joint model that e-commerce websites have been widely used and 2070 pushed forward related research (Wang et al., 2016; Ma et al., 2017; Xu et al., 2019; Sun et al., 2019; Jiang et al., 2019). The SemEval-2014 task-4 dataset (SE-ABSA14) (Pontiki et al., 2014) is composed of laptop and restaurant reviews. The restaurant subset includes 5 aspect categories (i.e., Food, Service, Price, Ambience and Anecdotes/Miscellaneous) and 4 polarity labels (i.e., Positive, Negative, Conflict and Neutral). The laptop subset is not suitable for ACSA. The SemEval-2015 task-12 dataset (SE-ABSA15) (Pontiki et al., 2015) builds upon SE-ABSA14 and defines its aspect category as a combination of an entity type and an attribute type"
C16-1187,R13-1026,0,0.0312198,"need the information. Therefore, our effort is complementary to the existing work on response generation. It can keep the existing generation algorithms context-aware and improve their efficiency and robustness to noise. The task is challenging, as messages in a conversational environment are usually short and informal, and evidence that can indicate a message is context dependent is scarce. For example, on 3 million post-response pairs crawled from Weibo, the average length of messages is 4.65. On such short texts, classic NLP tools such as POS Tagger and Parser suffer from bad performance (Derczynski et al., 2013; Foster et al., 2011) and it is difficult to explicitly extract features that are discriminative on the two types of messages. More seriously, there are no large scale annotations available for building a supervised learning procedure. We consider leveraging the large amount of human-human conversation data available on the web to learn a message classifier. Our intuition is that a context dependent message has different linguistic context in different conversation sessions, therefore its responses could be more diverse on content than responses of a context independent message. To verify thi"
C16-1187,W11-2017,0,0.0295448,"proposal of learning weak supervision signals from responses of messages using large scale conversation data; 3) proposal of using an LSTM architecture to learn a message classifier; 4) empirical verification of the proposed method on human annotated data. 1991 2 Related Work Our work lies in the path of building chatbot systems with data-driven approaches. Differing from traditional dialogue systems (cf., (Young et al., 2013)) which rely on hand-crafted features and rules to generate reply sentences for specific applications such as voice dialling (Williams, 2008) and appointment scheduling (Janarthanam et al., 2011) etc., recent effort focuses on exploiting an end-to-end approach to learn a response generator from social conversation data for open domain dialogue (Koshinda et al., 2015; Higashinaka et al., 2016). For example, Ritter et al. (Ritter et al., 2011) employed a phrase-based machine translation model for response generation. In (Shang et al., 2015; Vinyals and Le, 2015), neural network architectures were proposed to learning response generators from one-round conversation data. Based on these work, Sordoni et al. (Sordoni et al., 2015b) incorporated linguistic context into the learning of respo"
C16-1187,D11-1054,0,0.254837,"ed method can significantly outperform baseline methods on accuracy of classification. 1 Introduction Together with the rapid growth of social media such as Twitter and Weibo, the amount of conversation data on the web has tremendously increased. This makes building open domain chatbot systems with data-driven approaches possible. To carry on reasonable conversations with humans, a chatbot system needs to generate proper response with regard to users’ messages. Recently, with the large amount of conversation data available, learning a response generator from data has drawn a lot of attention (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). A key step to coherent response generation is determining when to consider linguistic context of messages. Existing work on response generation, however, has overlooked this step. They either totally ignores linguistic context (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015) or simply considers context for every message (Sordoni et al., 2015b; Serban et al., 2015). The former case is easy to lead to irrelevant responses when users’ input messages rely on the context information in previous conversation turns, while the latter case is"
C16-1187,P15-1152,0,0.290145,"cantly outperform baseline methods on accuracy of classification. 1 Introduction Together with the rapid growth of social media such as Twitter and Weibo, the amount of conversation data on the web has tremendously increased. This makes building open domain chatbot systems with data-driven approaches possible. To carry on reasonable conversations with humans, a chatbot system needs to generate proper response with regard to users’ messages. Recently, with the large amount of conversation data available, learning a response generator from data has drawn a lot of attention (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). A key step to coherent response generation is determining when to consider linguistic context of messages. Existing work on response generation, however, has overlooked this step. They either totally ignores linguistic context (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015) or simply considers context for every message (Sordoni et al., 2015b; Serban et al., 2015). The former case is easy to lead to irrelevant responses when users’ input messages rely on the context information in previous conversation turns, while the latter case is costly (e.g., on mem"
C16-1187,N15-1020,0,0.139745,"eds to generate proper response with regard to users’ messages. Recently, with the large amount of conversation data available, learning a response generator from data has drawn a lot of attention (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). A key step to coherent response generation is determining when to consider linguistic context of messages. Existing work on response generation, however, has overlooked this step. They either totally ignores linguistic context (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015) or simply considers context for every message (Sordoni et al., 2015b; Serban et al., 2015). The former case is easy to lead to irrelevant responses when users’ input messages rely on the context information in previous conversation turns, while the latter case is costly (e.g., on memory and responding time) for building a real chatbot system and has the risk of bringing in noise to response generation especially when users want to end the current conversation topic and start a new one. According to our observation, there are two types of messages in a conversational environment. The first type is context dependent message, which means to reply to the message,"
C16-1187,P08-4001,0,0.0201772,"essages in a conversational environment; 2) proposal of learning weak supervision signals from responses of messages using large scale conversation data; 3) proposal of using an LSTM architecture to learn a message classifier; 4) empirical verification of the proposed method on human annotated data. 1991 2 Related Work Our work lies in the path of building chatbot systems with data-driven approaches. Differing from traditional dialogue systems (cf., (Young et al., 2013)) which rely on hand-crafted features and rules to generate reply sentences for specific applications such as voice dialling (Williams, 2008) and appointment scheduling (Janarthanam et al., 2011) etc., recent effort focuses on exploiting an end-to-end approach to learn a response generator from social conversation data for open domain dialogue (Koshinda et al., 2015; Higashinaka et al., 2016). For example, Ritter et al. (Ritter et al., 2011) employed a phrase-based machine translation model for response generation. In (Shang et al., 2015; Vinyals and Le, 2015), neural network architectures were proposed to learning response generators from one-round conversation data. Based on these work, Sordoni et al. (Sordoni et al., 2015b) inco"
C16-1187,P15-2041,0,0.0179695,"eration. In this paper, instead of studying how to incorporate context into response generation, we consider the problem that when we need context in the process. Our work can keep the existing generation algorithms context-aware and at the same time improve their efficiency and robustness. We employ a Recurrent Neural Network (RNN) architecture to learn a message classifier. RNN models (Elman, 1990), due to their capability of modeling sequences with arbitrary length, have been widely used in many natural language processing tasks such as language modeling (Mikolov et al., 2010) and tagging (Xu et al., 2015) etc. Recently, it is reported that Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Unit (GRU) (Cho et al., 2014) as two special RNN models which can capture long term dependencies in sequences outperform state of the art methods on tasks like machine translation (Sutskever et al., 2014) and response generation (Shang et al., 2015). In this paper, we apply the LSTM architecture to the task of context dependent message detection. We append LSTM with a two-layer feed-forward neural network, thus feature learning and model learning can be carried out simultane"
C18-1330,W17-2339,0,0.0495048,"ork models have also been used for the MLC task. Zhang and Zhou (2006) propose the BP-MLL that utilizes a fully-connected neural network and a pairwise ranking loss function. Nam et al. (2013) propose a neural network using cross-entropy loss instead of ranking loss. Benites and Sapozhnikova (2015) increase classification speed by adding an extra ART layer for clustering. Kurata et al. (2016) utilize word embeddings based on CNN to capture label correlations. Chen et al. (2017) propose to represent semantic information of text and model high-order label correlations by combining CNN with RNN. Baker and Korhonen (2017) initialize the final hidden layer with rows that map to co-occurrence of labels based on the CNN architecture to improve the performance of the model. Ma et al. (2018) propose to use the multi-label classification algorithm for machine translation to handle the situation where a sentence can be translated into more than one correct sentences. 5 Conclusions and Future Work In this paper, we propose to view the multi-label classification task as a sequence generation problem to model the correlations between labels. A sequence generation model with a novel decoder structure is proposed to impro"
C18-1330,D14-1181,0,0.00963567,"ines We compare our proposed methods with the following baselines: • Binary Relevance (BR) (Boutell et al., 2004) transforms the MLC task into multiple single-label classification problems by ignoring the correlations between labels. • Classifier Chains (CC) (Read et al., 2011) transforms the MLC task into a chain of binary classification problems and takes high-order label correlations into consideration. • Label Powerset (LP) (Tsoumakas and Katakis, 2006) transforms a multi-label problem to a multiclass problem with one multi-class classifier trained on all unique label combinations. • CNN (Kim, 2014) uses multiple convolution kernels to extract text features, which are then inputted to the linear transformation layer followed by a sigmoid function to output the probability distribution over the label space. The multi-label soft margin loss is optimized. • CNN-RNN (Chen et al., 2017) utilizes CNN and RNN to capture both the global and local textual semantics and model the label correlations. Following the previous work (Chen et al., 2017), we adopt the linear SVM as the base classifier in BR, CC and LP. We implement BR, CC and LP by means of Scikit-Multilearn (Szyma´nski, 2017), an opensou"
C18-1330,N16-1063,0,0.327329,"large datasets. Other methods such as ML-DT (Clare and King, 2001), Rank-SVM (Elisseeff and Weston, 2002), and ML-KNN (Zhang and Zhou, 2007) can only be used to capture the first or second order label correlations or are computationally intractable when high-order label correlations are considered. In recent years, neural networks have achieved great success in the field of NLP. Some neural network models have also been applied in the MLC task and achieved important progress. For instance, fully connected neural network with pairwise ranking loss function is utilized in Zhang and Zhou (2006). Kurata et al. (2016) propose to perform classification using the convolutional neural network (CNN). Chen et al. (2017) use CNN and recurrent neural network (RNN) to capture the semantic information of texts. However, they either neglect the correlations between labels or do not consider differences in the contributions of textual content when predicting labels. In this paper, inspired by the tremendous success of the sequence-to-sequence (Seq2Seq) model in machine translation (Bahdanau et al., 2014; Luong et al., 2015; Sun et al., 2017), abstractive summarization (Rush et al., 2015; Lin et al., 2018), style tran"
C18-1330,D15-1099,1,0.784573,"el data directly. Clare and King (2001) construct decision tree based on multi-label entropy to perform classification. Elisseeff and Weston (2002) optimize the empirical ranking loss by using maximum margin strategy and kernel tricks. Collective multi-label classifier (CML) (Ghamrawi and McCallum, 2005) adopts maximum entropy principle to deal with multi-label data by encoding label correlations as constraint conditions. Zhang and Zhou (2007) adopt k-nearest neighbor techniques to deal with multi-label data. F¨urnkranz et al. (2008) make ranking among labels by utilizing pairwise comparison. Li et al. (2015) propose a novel joint learning algorithm that allows the feedbacks to be propagated from the classifiers for latter labels to the classifier for the current label. Most methods, however, can only be used to capture the first or second order label correlations or are computationally intractable in considering high-order label correlations. Among ensemble methods, Tsoumakas et al. (2011) break the initial set of labels into a number of small random subsets and employ the LP algorithm to train a corresponding classifier. Szyma´nski et al. (2016) propose to construct a label co-occurrence graph a"
C18-1330,P18-2027,1,0.848082,"(2006). Kurata et al. (2016) propose to perform classification using the convolutional neural network (CNN). Chen et al. (2017) use CNN and recurrent neural network (RNN) to capture the semantic information of texts. However, they either neglect the correlations between labels or do not consider differences in the contributions of textual content when predicting labels. In this paper, inspired by the tremendous success of the sequence-to-sequence (Seq2Seq) model in machine translation (Bahdanau et al., 2014; Luong et al., 2015; Sun et al., 2017), abstractive summarization (Rush et al., 2015; Lin et al., 2018), style transfer (Shen et al., 2017; Xu et al., 2018) and other domains, we propose a sequence generation model with a novel decoder structure to solve the MLC task. The proposed sequence generation model consists of an encoder and a decoder with the attention 1 The datasets and code are available at https://github.com/lancopku/SGM This work is licenced under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 3915 Proceedings of the 27th International Conference on Computational Linguistics, pages 3915–3926 Santa Fe, New Mexi"
C18-1330,D15-1166,0,0.0436376,"cted neural network with pairwise ranking loss function is utilized in Zhang and Zhou (2006). Kurata et al. (2016) propose to perform classification using the convolutional neural network (CNN). Chen et al. (2017) use CNN and recurrent neural network (RNN) to capture the semantic information of texts. However, they either neglect the correlations between labels or do not consider differences in the contributions of textual content when predicting labels. In this paper, inspired by the tremendous success of the sequence-to-sequence (Seq2Seq) model in machine translation (Bahdanau et al., 2014; Luong et al., 2015; Sun et al., 2017), abstractive summarization (Rush et al., 2015; Lin et al., 2018), style transfer (Shen et al., 2017; Xu et al., 2018) and other domains, we propose a sequence generation model with a novel decoder structure to solve the MLC task. The proposed sequence generation model consists of an encoder and a decoder with the attention 1 The datasets and code are available at https://github.com/lancopku/SGM This work is licenced under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 3915 Proceedings of the 27th Inter"
C18-1330,P18-2053,1,0.840617,"m et al. (2013) propose a neural network using cross-entropy loss instead of ranking loss. Benites and Sapozhnikova (2015) increase classification speed by adding an extra ART layer for clustering. Kurata et al. (2016) utilize word embeddings based on CNN to capture label correlations. Chen et al. (2017) propose to represent semantic information of text and model high-order label correlations by combining CNN with RNN. Baker and Korhonen (2017) initialize the final hidden layer with rows that map to co-occurrence of labels based on the CNN architecture to improve the performance of the model. Ma et al. (2018) propose to use the multi-label classification algorithm for machine translation to handle the situation where a sentence can be translated into more than one correct sentences. 5 Conclusions and Future Work In this paper, we propose to view the multi-label classification task as a sequence generation problem to model the correlations between labels. A sequence generation model with a novel decoder structure is proposed to improve the performance of classification. Extensive experimental results show that the proposed methods outperform the baselines by a substantial margin. Further analysis o"
C18-1330,D15-1044,0,0.0499285,"d in Zhang and Zhou (2006). Kurata et al. (2016) propose to perform classification using the convolutional neural network (CNN). Chen et al. (2017) use CNN and recurrent neural network (RNN) to capture the semantic information of texts. However, they either neglect the correlations between labels or do not consider differences in the contributions of textual content when predicting labels. In this paper, inspired by the tremendous success of the sequence-to-sequence (Seq2Seq) model in machine translation (Bahdanau et al., 2014; Luong et al., 2015; Sun et al., 2017), abstractive summarization (Rush et al., 2015; Lin et al., 2018), style transfer (Shen et al., 2017; Xu et al., 2018) and other domains, we propose a sequence generation model with a novel decoder structure to solve the MLC task. The proposed sequence generation model consists of an encoder and a decoder with the attention 1 The datasets and code are available at https://github.com/lancopku/SGM This work is licenced under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 3915 Proceedings of the 27th International Conference on Computational Linguistics, pages 3915–3926"
C18-1330,D16-1137,0,0.0283203,"ity under the distribution yt−1 . yt−1 is the probability 3917 distribution over the label space L at time-step t − 1 and is computed as follows: ot = Wo f (Wd st + Vd ct ) (8) yt = sof tmax(ot + It ) (9) where Wo , Wd , and Vd are weight parameters, It ∈ RL is the mask vector that is used to prevent the decoder from predicting repeated labels, and f is a nonlinear activation function. ( −∞ if the label li has been predicted at previous t − 1 time steps. (It )i = 0 otherwise. (10) At the training stage, the loss function is the cross-entropy loss function. We employ the beam search algorithm (Wiseman and Rush, 2016) to find the top-ranked prediction path at inference time. The prediction paths ending with the eos are added to the candidate path set. 2.3 Global Embedding In the sequence generation model mentioned above, the embedding vector g(yt−1 ) in Equation (7) is the embedding of the label that has the highest probability under the distribution yt−1 . However, this calculation only takes advantage of the maximum value of yt−1 greedily. The proposed sequence generation model generates labels sequentially and predicts the next label conditioned on its previously predicted labels. Therefore, it is likel"
D18-1408,D15-1075,0,0.103344,"ormed at the phrase level instead of the sentence level, thus the memory consumption reduces rapidly as the number of phrases increases. Furthermore, a gated memory component is employed to refine word representations hierarchically by incorporating longer-term context dependencies. As a result, syntactic information can be integrated into the model without expensive recursion computation. At last, multi-dimensional attention is applied on the refined word representations to obtain the final sentence representation. Following Conneau et al. (2017), we trained our sentence encoder on the SNLI (Bowman et al., 2015) dataset, and evaluate the quality of the obtained universal sentence representations on a wide range of transfer tasks. The SNLI dataset is extremely suitable for training sentence encoders because it is the largest high-quality humanannotated dataset that involves reasoning about the semantic relationships within sentences. The main contributions of our work can be summarized as follows: • We propose the Phrase-level Self-Attention mechanism (PSA) for contextualization. The memory consumption can be reduced because self-attention is performed at the phrase level instead of the sentence level"
D18-1408,D16-1053,0,0.178075,"with itself. The output of the attention mechanism is a weighted sum of embeddings from all tokens for each token in the phrase: "" # l X exp (aij ) p˜i = pj (2) Pl k=1 exp (aik ) j=1 where means point-wise product. Note that the alignment score for each token pair is a vector rather than a scalar in the multi-dimensional attention. The final output of Phrase-level Self-Attention is obtained by comparing each input representation with its attention-weighted counterpart. We use a comparison function based on absolute difference and element-wise multiplication which was similar to Wang and Jiang (2016). This comparison function has the advantage of measuring the semantic similarity or relatedness of two sequences. ci = σ (W c [|pi − p˜i |; pi p˜i ] + bc ) where W c ∈ Rd×2d and ba ∈ Rd are parameters to be learned. ci is the representation for the i-th word in the phrase that captures local dependencies within the phrase. At last, we put together the Phrase-level SelfAttention results for non-overlapping phrases from the same phrase division of a sentence. For the t-th phrase division we can get C (t) = [c1 , . . . , cls ], the phrase-level self-attention results for the sentence from the t-"
D18-1408,L18-1269,0,0.0148144,"fied. Minibatch size is set to 16. The number of levels T is fixed to 3 in all of our experiments. The syntactic parse trees of SNLI are provided within the corpus. parse trees for all test corpus are produced by the Stanford PCFG Parser 3.5.2 (Klein and Manning, 2003), the same parser that produced parse trees for the SNLI dataset. To train the model, Adadelta optimizer (Zeiler, 2012) with a learning rate of 0.75 is used on the SNLI dataset. The dropout (Srivastava et al., 2014) rate and L2 regularization weight decay factor γ are set to 0.5 and 5e-5. To test the model, the SentEval toolkit (Conneau and Kiela, 2018) is used as the evaluation pipeline for fairer comparison. 3.2 Training Setting Natural language inference (NLI) is a fundamental task in the field of natural language processing that involves reasoning about the semantic relationship between two sentences, which makes it a suitable task to train sentence encoding models. We conduct experiments on the Stanford Natural Language Inference (SNLI) dataset (Bowman et al., 2015). The dataset has 570k human-annotated sentence pairs, each labeled with one of the following pre-defined relationships: Entailment (the premise entails the hypothesis), Cont"
D18-1408,D17-1070,0,0.240428,"lit into multiple phrases based on parse tree, selfattention is performed at the phrase level instead of the sentence level, thus the memory consumption reduces rapidly as the number of phrases increases. Furthermore, a gated memory component is employed to refine word representations hierarchically by incorporating longer-term context dependencies. As a result, syntactic information can be integrated into the model without expensive recursion computation. At last, multi-dimensional attention is applied on the refined word representations to obtain the final sentence representation. Following Conneau et al. (2017), we trained our sentence encoder on the SNLI (Bowman et al., 2015) dataset, and evaluate the quality of the obtained universal sentence representations on a wide range of transfer tasks. The SNLI dataset is extremely suitable for training sentence encoders because it is the largest high-quality humanannotated dataset that involves reasoning about the semantic relationships within sentences. The main contributions of our work can be summarized as follows: • We propose the Phrase-level Self-Attention mechanism (PSA) for contextualization. The memory consumption can be reduced because self-atten"
D18-1408,P82-1020,0,0.835639,"Missing"
D18-1408,P14-1062,0,0.0554781,"of NLP’s next challenges has become the hunt for universal sentence encoders. The goal is to learn a general-purpose sentence encoding model on a large corpus, which can be readily transferred to other tasks. The learned sentence representations are able to generalize to unseen combination of words, which makes them highly desirable for downstream NLP tasks, especially for those with relatively small datasets. Previous models for sentence encoding typically rely on Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Chung et al., 2014) or Convolutional Neural Networks (CNNs) (Kalchbrenner et al., 2014; dos Santos and Gatti, 2014; Kim, 2014; Mou et al., 2016) to produce context-aware representation. RNNs encode a sentence by reading words in sequential order, they are capable of learning long-term dependencies but are hard to parallelize and not time-efficient. CNNs focus on local or positioninvariant dependencies but do not perform well on many tasks (Shen et al., 2017). Fully attention-based neural networks have attracted wide interest recently, because they can model both dependencies while being more parallelizable and requiring significantly less time to train. Vaswani et al. (2017) pr"
D18-1408,D14-1181,0,0.00677435,"rsal sentence encoders. The goal is to learn a general-purpose sentence encoding model on a large corpus, which can be readily transferred to other tasks. The learned sentence representations are able to generalize to unseen combination of words, which makes them highly desirable for downstream NLP tasks, especially for those with relatively small datasets. Previous models for sentence encoding typically rely on Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Chung et al., 2014) or Convolutional Neural Networks (CNNs) (Kalchbrenner et al., 2014; dos Santos and Gatti, 2014; Kim, 2014; Mou et al., 2016) to produce context-aware representation. RNNs encode a sentence by reading words in sequential order, they are capable of learning long-term dependencies but are hard to parallelize and not time-efficient. CNNs focus on local or positioninvariant dependencies but do not perform well on many tasks (Shen et al., 2017). Fully attention-based neural networks have attracted wide interest recently, because they can model both dependencies while being more parallelizable and requiring significantly less time to train. Vaswani et al. (2017) proposed the multihead attention to proje"
D18-1408,P03-1054,0,0.0622152,"re hashed to one of 128 random embeddings initialized by uniform distribution between (-0.05, 0.05). All the word embeddings remain fixed during training. Hidden dimension d is set to 300. All other parameters are initialized with Glorot normal initialization (Glorot and Bengio, 2010). Activation function σ (·) is ELU (Clevert et al., 2015) if not specified. Minibatch size is set to 16. The number of levels T is fixed to 3 in all of our experiments. The syntactic parse trees of SNLI are provided within the corpus. parse trees for all test corpus are produced by the Stanford PCFG Parser 3.5.2 (Klein and Manning, 2003), the same parser that produced parse trees for the SNLI dataset. To train the model, Adadelta optimizer (Zeiler, 2012) with a learning rate of 0.75 is used on the SNLI dataset. The dropout (Srivastava et al., 2014) rate and L2 regularization weight decay factor γ are set to 0.5 and 5e-5. To test the model, the SentEval toolkit (Conneau and Kiela, 2018) is used as the evaluation pipeline for fairer comparison. 3.2 Training Setting Natural language inference (NLI) is a fundamental task in the field of natural language processing that involves reasoning about the semantic relationship between tw"
D18-1408,P16-2022,0,0.0834052,"ce encoders. The goal is to learn a general-purpose sentence encoding model on a large corpus, which can be readily transferred to other tasks. The learned sentence representations are able to generalize to unseen combination of words, which makes them highly desirable for downstream NLP tasks, especially for those with relatively small datasets. Previous models for sentence encoding typically rely on Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Chung et al., 2014) or Convolutional Neural Networks (CNNs) (Kalchbrenner et al., 2014; dos Santos and Gatti, 2014; Kim, 2014; Mou et al., 2016) to produce context-aware representation. RNNs encode a sentence by reading words in sequential order, they are capable of learning long-term dependencies but are hard to parallelize and not time-efficient. CNNs focus on local or positioninvariant dependencies but do not perform well on many tasks (Shen et al., 2017). Fully attention-based neural networks have attracted wide interest recently, because they can model both dependencies while being more parallelizable and requiring significantly less time to train. Vaswani et al. (2017) proposed the multihead attention to project a sentence to mu"
D18-1408,D15-1279,0,0.0762867,"us regarding the appropriate evaluations for universal sentence representations. To facilitate comparison, we use the same sentence evaluation tool as Conneau et al. (2017) to automate evaluation on all the tasks mentioned in this paper. The transfer tasks used in evaluation can be concluded in the following classes: sentence classification (MR, CR, MPQA, SUBJ, SST2, SST5, TREC), natural language inference (SICKE, SICK-R), semantic relatedness (STS14) and paraphrase detection (MRPC). Table 1 presents some statistics about the datasets 2 . 3.4 Model BiLSTM-Max AdaSent TBCNN DiSAN PSAN • TBCNN (Mou et al., 2015) is a tree-based CNN model where convolution is applied over the parse tree. 2 For further information on the datasets, please refer to Conneau et al. (2017). SNLI 84.5 83 .4 82.1 85.6 86.1 Micro 85.2 82.0 81.1 84.7 85.7 Macro 83.7 80.9 79.3 83.4 84.5 various sentence encoders. dim: the size of sentence representation. |θ|: the number of parameters. Test accuracies on SNLI, micro and macro averages of accuracies of dev set on transfer tasks are chosen as evaluation metrics. • DiSAN (Shen et al., 2017) is composed of a directional self-attention block with temporal order encoded, and a multi-di"
D18-1408,E17-1038,0,0.014888,"STM (Tai et al., 2015; Zhu et al., 2015) composed its hidden state from an input vector and the hidden states of arbitrarily many child units. In Tree-based CNN (Mou et al., 2015, 2016), a set of subtree feature detectors slide over the parse tree of a sentence, and a max-pooling layer is utilized to aggregate information along different parts of the tree. Apart from the models that use parse information, there have been several researches that aimed to learn the hierarchical latent structure of text by recursively composing words into sentence representation. Among them, neural tree indexer (Munkhdalai and Yu, 2017b) utilized LSTM or attentive node composition function to construct full n-ary tree for input text. Gumbel TreeLSTM (Choi et al., 2018) used Straight-Through Gumbel-Softmax estimator to decide the parent node among candidates dynamically. A major drawback of these models is that the recursion computation can be expensive and hard to be processed in batches. 6 Conclusion We propose the Phrase-level Self-Attention Networks (PSAN), a fully attention-based model that can utilize syntactic information for universal sentence encoding. By applying self-attention at the phrase level, we can filter ou"
D18-1408,E17-1002,0,0.0162227,"STM (Tai et al., 2015; Zhu et al., 2015) composed its hidden state from an input vector and the hidden states of arbitrarily many child units. In Tree-based CNN (Mou et al., 2015, 2016), a set of subtree feature detectors slide over the parse tree of a sentence, and a max-pooling layer is utilized to aggregate information along different parts of the tree. Apart from the models that use parse information, there have been several researches that aimed to learn the hierarchical latent structure of text by recursively composing words into sentence representation. Among them, neural tree indexer (Munkhdalai and Yu, 2017b) utilized LSTM or attentive node composition function to construct full n-ary tree for input text. Gumbel TreeLSTM (Choi et al., 2018) used Straight-Through Gumbel-Softmax estimator to decide the parent node among candidates dynamically. A major drawback of these models is that the recursion computation can be expensive and hard to be processed in batches. 6 Conclusion We propose the Phrase-level Self-Attention Networks (PSAN), a fully attention-based model that can utilize syntactic information for universal sentence encoding. By applying self-attention at the phrase level, we can filter ou"
D18-1408,W17-5308,0,0.237399,"al., 2014; dos Santos and Gatti, 2014; Kim, 2014; Mou et al., 2016) to produce context-aware representation. RNNs encode a sentence by reading words in sequential order, they are capable of learning long-term dependencies but are hard to parallelize and not time-efficient. CNNs focus on local or positioninvariant dependencies but do not perform well on many tasks (Shen et al., 2017). Fully attention-based neural networks have attracted wide interest recently, because they can model both dependencies while being more parallelizable and requiring significantly less time to train. Vaswani et al. (2017) proposed the multihead attention to project a sentence to multiple semantic subspaces, then apply self-attention in each subspace and concatenate the attention results. Shen et al. (2017) proposed the directional self-attention, they apply forward and backward masks to the alignment score matrix to encode temporal order information, and computed attention at feature level to select the features that can best describe the word’s meaning in given context. Effective as their models are, the memory required to store the alignment scores of all the token pairs grows quadratically with the sentence"
D18-1408,D16-1244,0,0.165817,"Missing"
D18-1408,D14-1162,0,0.0887343,"(T ) v= mi Pl j=1 exp (ej ) i=1 where W g , W m ∈ Rd×d and bg , bm ∈ Rd are parameters to be learned. After this step, the refined context-aware sentence representation is compressed into a fixed-length vector. 3 Experiments In this section, we conduct a plethora of experiments to study the effectiveness of the PSAN model. Following Conneau et al. (2017), we train our sentence encoder using the SNLI dataset, and evaluate it across a variety of NLP tasks including sentence classification, natural language inference and sentence textual similarity. 3.1 Model Configuration 300-dimensional GloVe (Pennington et al., 2014) word embeddings (Common Crawl, uncased) are used to represent words. Following Parikh et al. (2016), out-of-vocabulary words are hashed to one of 128 random embeddings initialized by uniform distribution between (-0.05, 0.05). All the word embeddings remain fixed during training. Hidden dimension d is set to 300. All other parameters are initialized with Glorot normal initialization (Glorot and Bengio, 2010). Activation function σ (·) is ELU (Clevert et al., 2015) if not specified. Minibatch size is set to 16. The number of levels T is fixed to 3 in all of our experiments. The syntactic parse"
D18-1408,C14-1008,0,0.0330506,"ecome the hunt for universal sentence encoders. The goal is to learn a general-purpose sentence encoding model on a large corpus, which can be readily transferred to other tasks. The learned sentence representations are able to generalize to unseen combination of words, which makes them highly desirable for downstream NLP tasks, especially for those with relatively small datasets. Previous models for sentence encoding typically rely on Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Chung et al., 2014) or Convolutional Neural Networks (CNNs) (Kalchbrenner et al., 2014; dos Santos and Gatti, 2014; Kim, 2014; Mou et al., 2016) to produce context-aware representation. RNNs encode a sentence by reading words in sequential order, they are capable of learning long-term dependencies but are hard to parallelize and not time-efficient. CNNs focus on local or positioninvariant dependencies but do not perform well on many tasks (Shen et al., 2017). Fully attention-based neural networks have attracted wide interest recently, because they can model both dependencies while being more parallelizable and requiring significantly less time to train. Vaswani et al. (2017) proposed the multihead attenti"
D18-1408,P15-1150,0,0.265044,"Missing"
D18-1408,D13-1170,0,0.0110736,"o encode temporal order information, and computed attention at feature level to select the features that can best describe the word’s meaning in given context. Effective as their models are, the memory required to store the alignment scores of all the token pairs grows quadratically with the sentence length. Furthermore, the syntactic property that is intrinsic to natural language is not considered at all. Language is inherently tree structured, and the meaning of a sentence comes largely from composing the meanings of subtrees (Chomsky, 1957). Previous syntactic tree-based sentence encoders (Socher et al., 2013; Tai et al., 2015) mainly rely on recursive networks. Although the composition3729 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3729–3738 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics ality can be explicitly modeled, their models need expensive recursion computation and are hard to be trained by batched gradient descent methods. In this paper, we propose the Phrase-level SelfAttention Networks (PSAN), for RNN/CNN-free sentence encoding, it inherits all the advantages of fully attention-based"
D19-1128,W15-4640,0,0.41228,"dely used random sampling strategy, although the first two strategies lead to performance drop, the latter two ones can bring consistent improvement to the performance of all the models on both benchmarks. 1 Introduction In this work, we study the problem of response selection as an approach to implementing a retrievalbased dialogue system (Ji et al., 2014; Wang et al., 2013). A key step in response selection is measuring the matching degree between a conversation context and a response candidate. Existing studies focus on constructing a matching model with sophisticated neural architectures (Lowe et al., 2015; Zhou et al., 2016; Yan et al., 2016; Wu et al., 2017; Zhang et al., 2018; Zhou et al., 2018; Tao et al., 2019), but pay little attention to how to effectively learn such architectures from data. On the one hand, it is well known that learning of complicated neural architectures requires large-scale high quality training data; on the other hand, since human labeling is expensive and exhausting, most of the existing work just adopts a simple heuristic to automatically build a training set where human responses are treated as positive examples and negative response candidates are randomly sampl"
D19-1128,W17-7301,0,0.123569,"ative sampling strategies have been studied in many machine learning tasks. In the computer vision fields, Faghri et al. (2017) studies hard negatives and introduces a simple change to common loss function on image-caption retrieval tasks. Guo et al. (2018) proposes a fast negative sampler which chooses negative examples that are most likely to meet the requirements of violation according to the latent factors of image. In natural language processing fields, Kotnis and Nastase (2017) analyses the impact of negative sampling strategies on the performance of link prediction in knowledge graphs. Saeidi et al. (2017) studies the affect of a tailored sample strategy on the performance of document retrieval task. Rao et al. (2016) uses three negative strategies to select the most informative negative samples on the pairwise ranking model for answer selection. Xu et al. (2015) introduces a straightforward negative sampling strategy to improve the assignment of subjects and objects on a convolution neural network. To our best knowledge, this is the first work to empirical study of negative sampling strategies for learning of matching models in multi-turn retrieval-based dialogue systems, which may enlighten f"
D19-1128,P19-1001,1,0.819447,"nes can bring consistent improvement to the performance of all the models on both benchmarks. 1 Introduction In this work, we study the problem of response selection as an approach to implementing a retrievalbased dialogue system (Ji et al., 2014; Wang et al., 2013). A key step in response selection is measuring the matching degree between a conversation context and a response candidate. Existing studies focus on constructing a matching model with sophisticated neural architectures (Lowe et al., 2015; Zhou et al., 2016; Yan et al., 2016; Wu et al., 2017; Zhang et al., 2018; Zhou et al., 2018; Tao et al., 2019), but pay little attention to how to effectively learn such architectures from data. On the one hand, it is well known that learning of complicated neural architectures requires large-scale high quality training data; on the other hand, since human labeling is expensive and exhausting, most of the existing work just adopts a simple heuristic to automatically build a training set where human responses are treated as positive examples and negative response candidates are randomly sampled. ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn). Such a training set might contain many false negatives"
D19-1128,D13-1096,0,0.350074,"ing models in learning, we consider four strategies including minimum sampling, maximum sampling, semi-hard sampling, and decay-hard sampling. Empirical studies on two benchmarks with three matching models indicate that compared with the widely used random sampling strategy, although the first two strategies lead to performance drop, the latter two ones can bring consistent improvement to the performance of all the models on both benchmarks. 1 Introduction In this work, we study the problem of response selection as an approach to implementing a retrievalbased dialogue system (Ji et al., 2014; Wang et al., 2013). A key step in response selection is measuring the matching degree between a conversation context and a response candidate. Existing studies focus on constructing a matching model with sophisticated neural architectures (Lowe et al., 2015; Zhou et al., 2016; Yan et al., 2016; Wu et al., 2017; Zhang et al., 2018; Zhou et al., 2018; Tao et al., 2019), but pay little attention to how to effectively learn such architectures from data. On the one hand, it is well known that learning of complicated neural architectures requires large-scale high quality training data; on the other hand, since human"
D19-1128,P18-2067,1,0.725816,"igh quality training data; on the other hand, since human labeling is expensive and exhausting, most of the existing work just adopts a simple heuristic to automatically build a training set where human responses are treated as positive examples and negative response candidates are randomly sampled. ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn). Such a training set might contain many false negatives and trivial true negatives that are very easy to distinguish from those true positives. As a result, models with advanced architectures can only reach sub-optimal performance after learning (Wu et al., 2018). In this paper, instead of configuring new architectures, we investigate how to improve the performance of existing matching models with a better learning method. A learning method usually involves choice of loss functions and construction of training data, and we are particularly interested in automatic training data construction, as data are often more crucial to the performance of models. The key problem in training data construction lies in how to properly choose negative examples, and our idea is that negative examples should adapt to the matching models at different learning stages. Fol"
D19-1128,P17-1046,1,0.961365,"wo strategies lead to performance drop, the latter two ones can bring consistent improvement to the performance of all the models on both benchmarks. 1 Introduction In this work, we study the problem of response selection as an approach to implementing a retrievalbased dialogue system (Ji et al., 2014; Wang et al., 2013). A key step in response selection is measuring the matching degree between a conversation context and a response candidate. Existing studies focus on constructing a matching model with sophisticated neural architectures (Lowe et al., 2015; Zhou et al., 2016; Yan et al., 2016; Wu et al., 2017; Zhang et al., 2018; Zhou et al., 2018; Tao et al., 2019), but pay little attention to how to effectively learn such architectures from data. On the one hand, it is well known that learning of complicated neural architectures requires large-scale high quality training data; on the other hand, since human labeling is expensive and exhausting, most of the existing work just adopts a simple heuristic to automatically build a training set where human responses are treated as positive examples and negative response candidates are randomly sampled. ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn"
D19-1128,D15-1062,1,0.889697,"Missing"
D19-1128,C18-1317,0,0.0686812,"d to performance drop, the latter two ones can bring consistent improvement to the performance of all the models on both benchmarks. 1 Introduction In this work, we study the problem of response selection as an approach to implementing a retrievalbased dialogue system (Ji et al., 2014; Wang et al., 2013). A key step in response selection is measuring the matching degree between a conversation context and a response candidate. Existing studies focus on constructing a matching model with sophisticated neural architectures (Lowe et al., 2015; Zhou et al., 2016; Yan et al., 2016; Wu et al., 2017; Zhang et al., 2018; Zhou et al., 2018; Tao et al., 2019), but pay little attention to how to effectively learn such architectures from data. On the one hand, it is well known that learning of complicated neural architectures requires large-scale high quality training data; on the other hand, since human labeling is expensive and exhausting, most of the existing work just adopts a simple heuristic to automatically build a training set where human responses are treated as positive examples and negative response candidates are randomly sampled. ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn). Such a training s"
D19-1128,D16-1036,1,0.902016,"Missing"
D19-1128,P18-1103,0,0.783361,"p, the latter two ones can bring consistent improvement to the performance of all the models on both benchmarks. 1 Introduction In this work, we study the problem of response selection as an approach to implementing a retrievalbased dialogue system (Ji et al., 2014; Wang et al., 2013). A key step in response selection is measuring the matching degree between a conversation context and a response candidate. Existing studies focus on constructing a matching model with sophisticated neural architectures (Lowe et al., 2015; Zhou et al., 2016; Yan et al., 2016; Wu et al., 2017; Zhang et al., 2018; Zhou et al., 2018; Tao et al., 2019), but pay little attention to how to effectively learn such architectures from data. On the one hand, it is well known that learning of complicated neural architectures requires large-scale high quality training data; on the other hand, since human labeling is expensive and exhausting, most of the existing work just adopts a simple heuristic to automatically build a training set where human responses are treated as positive examples and negative response candidates are randomly sampled. ∗ Corresponding author: Rui Yan (ruiyan@pku.edu.cn). Such a training set might contain ma"
D19-1197,W02-2211,0,0.0816066,"addition to model design, how to learn a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and"
D19-1197,D14-1179,0,0.0369536,"Missing"
D19-1197,D17-1090,0,0.0272895,"airs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open"
D19-1197,W04-0601,0,0.0708975,"del design, how to learn a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887"
D19-1197,W09-0613,0,0.0200496,"a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/To"
D19-1197,N18-1032,0,0.0159977,"also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data th"
D19-1197,D18-1398,0,0.0245753,"also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data th"
D19-1197,Q18-1031,0,0.0468518,"te the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), a"
D19-1197,N18-1093,0,0.073455,"asks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Zong, 2016) or backtranslation (Sennri"
D19-1197,W18-3401,0,0.076381,"arious natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Z"
D19-1197,D14-1181,0,0.00293569,"U hi + b), 1 n where v, b ∈ Rd2 , W, U ∈ Rd2 ×d2 are parameters. 4 Learning Approach Intuitively, we can estimate the parameters of the encoder-decoder and fine-tune the parameters of NHSMM by maximizing the likelihood of DP (i.e., MLE). However, since DP only contains a few pairs, the MLE approach may suffer from a dilemma: (1) if we stop training early, then both the template prior and the encoder-decoder are not X Si X log P (yi,t |yi,1:t−1 , Xi , Ti ). (3) (Xi ,Yi )∈DP t=1 Discriminator Update. The discriminator D is defined by a convolutional neural network (CNN) based binary classifier (Kim, 2014). D takes a message-response pair as input and outputs a score that indicates how likely the response is from humans. In the model, the message and the response are separately embedded as vectors by CNNs, and then the concatenation of the two vectors are fed to 1890 a 2-layer MLP to calculate the score. Let Yˆi be the response generated by G for Xi , then D is updated by maximizing the following objective: X log D(Xi , Yi ) + log(1 − D(Xi , Yˆi )) (Xi ,Yi )∈DP (4) Generator Update. The generator G is updated by the policy gradient method (Yu et al., 2017; Li et al., 2017). Let yˆ1:t be a parti"
D19-1197,P16-1094,0,0.142903,"e responses without any needs on rules, and have powered products in the industry such as Amazon Alexa (Ram et al., 2018) and Microsoft XiaoIce (Shum et al., 2018). State-of-the-art open domain response generation models are based on the encoder-decoder architecture (Vinyals and Le, 2015; Shang et al., 2015). On the one hand, with proper extensions to the vanilla structure, existing models now are able to naturally handle conversation contexts (Serban et al., 2016; Xing et al., 2018), and synthesize responses with various styles (Wang et al., 2017), emotions (Zhou et al., 2018), and personas (Li et al., 2016a). On the other hand, all the existing success of open domain response generation builds upon an assumption that the large scale of paired data (Shao et al., 2016) or conversation sessions (Sordoni et al., 2015) are available. In this work, we challenge this assumption by arguing that one cannot always obtain enough pairs or sessions for training a neural generation model. For example, although it has been indicated by existing work (Li et al., 2016b; Wang et al., 2018) that question asking in conversation can enhance user engagement, we find that in a public dataset1 with 5 million conversat"
D19-1197,D16-1127,0,0.261878,"e responses without any needs on rules, and have powered products in the industry such as Amazon Alexa (Ram et al., 2018) and Microsoft XiaoIce (Shum et al., 2018). State-of-the-art open domain response generation models are based on the encoder-decoder architecture (Vinyals and Le, 2015; Shang et al., 2015). On the one hand, with proper extensions to the vanilla structure, existing models now are able to naturally handle conversation contexts (Serban et al., 2016; Xing et al., 2018), and synthesize responses with various styles (Wang et al., 2017), emotions (Zhou et al., 2018), and personas (Li et al., 2016a). On the other hand, all the existing success of open domain response generation builds upon an assumption that the large scale of paired data (Shao et al., 2016) or conversation sessions (Sordoni et al., 2015) are available. In this work, we challenge this assumption by arguing that one cannot always obtain enough pairs or sessions for training a neural generation model. For example, although it has been indicated by existing work (Li et al., 2016b; Wang et al., 2018) that question asking in conversation can enhance user engagement, we find that in a public dataset1 with 5 million conversat"
D19-1197,D17-1230,0,0.0610089,"N) based binary classifier (Kim, 2014). D takes a message-response pair as input and outputs a score that indicates how likely the response is from humans. In the model, the message and the response are separately embedded as vectors by CNNs, and then the concatenation of the two vectors are fed to 1890 a 2-layer MLP to calculate the score. Let Yˆi be the response generated by G for Xi , then D is updated by maximizing the following objective: X log D(Xi , Yi ) + log(1 − D(Xi , Yˆi )) (Xi ,Yi )∈DP (4) Generator Update. The generator G is updated by the policy gradient method (Yu et al., 2017; Li et al., 2017). Let yˆ1:t be a partial response generated by G from beam search for message X until step t, then we adopt the Monte Carlo (MC) search method and sample N paths that supplement yˆ1:t as responses {Yˆi }N reward for i=1 . The intermediate 1 PN yˆ1:t is defined as Rt = N i=1 D(X, Yˆi ). The gradient for updating G is given by ∇J(θ) ≈ S X   ∇ log P (yˆt |ˆ y1:t−1 , X, T ) · Rt , t=1 (5) where θ represents the parameters of G, and T is a sampled template. To control the quality of MC search, we sample from top 50 most probable words at each step. The learning algorithm is summarized in Algorith"
D19-1197,D16-1230,0,0.0655554,"Missing"
D19-1197,P17-1103,0,0.0136973,"nslation, early work applies the sequence-to-sequence with attention model (Shang et al., 2015) to open domain response generation, and gets promising results. Later, the basic architecture is extended to suppress generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017); to model the structure of conversation contexts (Serban et al., 2016); and to incorporate different types of knowledge into generation (Li et al., 2016a; Zhou et al., 2018). In addition to model design, how to learn a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores"
D19-1197,P14-5010,0,0.00769277,"ed by softmax(W1 vjt + b1 ), where W1 ∈ RV ×d2 and b1 ∈ Rd2 are parameters with V the vacabulary size. Following Murphy (2002), the marginal distribution of Y can be obtained by the backward algorithm which is formulated as βt (i) , P (yt+1:S |qt = i) = K X βt∗ (j)A(i, j) j=1 βt∗ (j) , P (yt+1:S |qt+1 = j) D h i X = βt+d (j)P (d|j)P (yt+1:t+d |j, d) d=1 P (Y ) = K X β0∗ (j)P (q1 = j). j=1 (2) where qt is the hidden state of the t-th word in Y , and the base cases βS (i) = 1, ∀i ∈ {1, . . . , K}. Specifically, to learn more reasonable segmentations, we parsed every sentence by stanford parser (Manning et al., 2014) and forced NHSMM not to break syntactic elements such as VP and NP, etc. The parameters of the NHSMM are estimated by maximizing the log-likelihood of DU through backpropagation. 3.3 Response Generation with Template Prior We propose incorporating the templates parameterized by the NHSMM learned from DU into response generation as prior. Figure 1 illustrates the architecture of the generation model. In a nutshell, the model first samples a chain of states with duration as a template. The template specifies a segmentation of the response to generate. Then, the hidden representations of the seg"
D19-1197,P18-1123,0,0.0203065,"nto neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recog"
D19-1197,P02-1040,0,0.103659,"Missing"
D19-1197,N19-1263,0,0.0386244,"erpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskorie"
D19-1197,K18-1003,0,0.0246446,"rage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Zong, 2016) or backtranslation (Sennrich et al., 2015), we extract linguistic knowledge from the data as latent templates and use the templates"
D19-1197,P16-1009,0,0.092815,"Missing"
D19-1197,P15-1152,0,0.0762441,"Missing"
D19-1197,D13-1170,0,0.00714242,"Missing"
D19-1197,N15-1020,0,0.0669518,"Missing"
D19-1197,D17-1228,0,0.0378154,"Missing"
D19-1197,P18-1204,0,0.303312,"ntax of the unpaired data and then are used as prior in an encoder-decoder architecture for modeling the paired data. With the latent templates, the whole model is end-to-end learnable and can perform response generation in an explainable manner. To ensure the relevance of responses regarding input messages and at the same time make full use of the templates, we propose learning the generation model with an adversarial approach. Empirical studies are conducted on two tasks: question response generation and sentiment response generation. For the first task, we exploit the dataset published in (Wang et al., 2018) and augment the data with questions crawled from Zhihu4 . For the second task, we build a paired dataset from Twitter by filtering responses with an off-theshelf sentiment classifier and augment the dataset with tweets in positive sentiment extracted from a large scale tweet dataset published in (Cheng et al., 2010). Evaluation results on both auto3 The study in this work starts from response generation for single messages. One can easily extend the proposed approach to handle conversation history. 4 https://en.wikipedia.org/wiki/Zhihu matic metrics and human judgment indicate that with limit"
D19-1197,D18-1356,0,0.165961,"for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource probl"
D19-1197,D16-1160,0,0.0298367,"ow-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Zong, 2016) or backtranslation (Sennrich et al., 2015), we extract linguistic knowledge from the data as latent templates and use the templates as prior in generation. 3 Low-Resource Response Generation In this section, we first formalize the setting upon which we study low-resource response generation and then elaborate the model of response generation with paired and unpaired data, including how to learn latent templates from the unpaired data, and how to perform generation with the templ"
D19-1512,W18-5105,0,0.026626,"Missing"
D19-1512,W05-0909,0,0.132118,"t-TC, top 1 comment from beam search (beam size=5) is returned. GANN: the gated attention neural network proposed in (Zheng et al., 2018). The model is further improved by a generative adversarial net. We denote our model as “DeepCom” standing for “deep commenter”, as it is featured by a deep reading-commenting architecture. All baselines are implemented according to the details in the related papers and tuned on the validation sets. performance of different models with both automatic metrics and human judgment. In terms of automatic evaluation, we employ BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE (Lin, 2004), and CIDEr (Vedantam et al., 2015) as metrics on both data. Besides these metrics, Qin et al. (2018) propose human score weighted metrics including W-BLEU, WMETEOR, W-ROUGE and W-CIDEr. These metrics, however, requires human judgment on each comment in the test set. Thus, we only involve results w.r.t. these metrics in Tencent data. As Qin et al. (2018) do not publish their code for metric calculation, we employ a popular NLG evaluation project available at https://github.com/ Maluuba/nlg-eval, and modify the scripts with the scores provided in the data according to the for"
D19-1512,P17-1171,0,0.0176652,"ws articles before generation and perform endto-end learning that can jointly optimize the comprehension model and the generation model. Our model is partially inspired by the recent success of machine reading comprehension (MRC), whose prosperity can be attributed to an increase of publicly available large scale annotated datasets, such as SQuAD (Rajpurkar et al., 2016, 2018) and MS Marco (Nguyen et al., 2016) etc. A great number of models have been proposed to tackle the MRC challenges, including BiDAF (Seo et al., 2016), r-net (Wang et al., 2017), DCN (Xiong et al., 2016), Document Reader (Chen and Bordes, 2017), QANet (Yu et al., 2018), and s-net (Tan et al., 2018) etc. Our work can be viewed as an application of MRC to a new NLG task. The task aims to generate a comment for a news article, which is different from existing MRC tasks whose goal is to answer a question. Our learning method is also different from those in the MRC works. 3 3.1 Approach Problem Formalization Suppose we have a dataset D = {(Ti , Bi , Ci )}N i=1 , where the i-th triple (Ti , Bi , Ci ) consists of a news title Ti , a news body Bi , and a comment Ci . Our goal is to estimate a probability distribution P (C|T, B) from D, and"
D19-1512,W14-4012,0,0.0860529,"Missing"
D19-1512,E17-1059,0,0.0221742,"ree-folds: (1) proposal of “read-attend-comment” procedure for news comment generation with a reading network and a generation network; (2) joint optimization of the two networks with an end-to-end learning approach; and (3) empirical verification of the effectiveness of the proposed model on two datasets. 2 Related Work News comment generation is a sub-task of natural language generation (NLG). Among various NLG tasks, the task studied in this paper is most related to summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017) and product review generation (Tang et al., 2016; Dong et al., 2017). However, there is stark difference between news comment generation and the other two tasks: the input of our task is an unstructured document, while the input of product review generation is structured attributes of a product; and the output of our task is a comment which often extends the content of the input with additional information, while the output of summarization is a condensed version of the input that contains the main information from the original. Very recently, there 1 https://www.yahoo.com/news/ fifa-rankings-france-number-one-112047790. emerge some studies on news comment gen"
D19-1512,P14-5010,0,0.00242161,"ria presented in Table 3. All text in the data is tokenized by a Chinese word segmenter Jieba (https: //github.com/fxsjy/jieba). The average lengths of news titles, news bodies, and comments are 15 words, 554 words and 17 words respectively. In addition to the Chinese data, we also build another dataset by crawling news articles and the associated comments from Yahoo! News. Besides upvotes and categories, side information in Yahoo data also includes paragraph marks, WIKI-entities, downvotes, abusevotes, and sentiment tagged by Yahoo!. Text in the data is tokenized by Stanford CoreNLP pipline (Manning et al., 2014). As pre-processing, we filter out news articles shorter than 30 words in the body and comments shorter than 10 words or longer than 100 words. Then, we remove news articles with less than 5 comments. If the number of comments of an article exceeds 30, we only keep top 30 comments with the most upvotes. On average, news titles, news bodies, and comments contain 12 words, 578 words and 32 words respectively. More information about Yahoo data can be found in Appendix A. After the pre-processing, we randomly sample a training set, a validation set, and a test set from the remaining data, and make"
D19-1512,P02-1040,0,0.110304,"Att-TC). In Seq2seq, Att, and Att-TC, top 1 comment from beam search (beam size=5) is returned. GANN: the gated attention neural network proposed in (Zheng et al., 2018). The model is further improved by a generative adversarial net. We denote our model as “DeepCom” standing for “deep commenter”, as it is featured by a deep reading-commenting architecture. All baselines are implemented according to the details in the related papers and tuned on the validation sets. performance of different models with both automatic metrics and human judgment. In terms of automatic evaluation, we employ BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE (Lin, 2004), and CIDEr (Vedantam et al., 2015) as metrics on both data. Besides these metrics, Qin et al. (2018) propose human score weighted metrics including W-BLEU, WMETEOR, W-ROUGE and W-CIDEr. These metrics, however, requires human judgment on each comment in the test set. Thus, we only involve results w.r.t. these metrics in Tencent data. As Qin et al. (2018) do not publish their code for metric calculation, we employ a popular NLG evaluation project available at https://github.com/ Maluuba/nlg-eval, and modify the scripts with the scores provid"
D19-1512,P18-2124,0,0.025649,"Missing"
D19-1512,D16-1264,0,0.0273879,"rate news comments from news titles. The model is further improved by a generative adversarial net. Qin et al. (2018) publish a dataset with results of some basic models. Different from all the existing methods, we attempt to comprehend the entire news articles before generation and perform endto-end learning that can jointly optimize the comprehension model and the generation model. Our model is partially inspired by the recent success of machine reading comprehension (MRC), whose prosperity can be attributed to an increase of publicly available large scale annotated datasets, such as SQuAD (Rajpurkar et al., 2016, 2018) and MS Marco (Nguyen et al., 2016) etc. A great number of models have been proposed to tackle the MRC challenges, including BiDAF (Seo et al., 2016), r-net (Wang et al., 2017), DCN (Xiong et al., 2016), Document Reader (Chen and Bordes, 2017), QANet (Yu et al., 2018), and s-net (Tan et al., 2018) etc. Our work can be viewed as an application of MRC to a new NLG task. The task aims to generate a comment for a news article, which is different from existing MRC tasks whose goal is to answer a question. Our learning method is also different from those in the MRC works. 3 3.1 Approach Probl"
D19-1512,D15-1044,0,0.10392,"Missing"
D19-1512,P17-1099,0,0.0326474,"both automatic metrics and human judgment. Our contributions are three-folds: (1) proposal of “read-attend-comment” procedure for news comment generation with a reading network and a generation network; (2) joint optimization of the two networks with an end-to-end learning approach; and (3) empirical verification of the effectiveness of the proposed model on two datasets. 2 Related Work News comment generation is a sub-task of natural language generation (NLG). Among various NLG tasks, the task studied in this paper is most related to summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017) and product review generation (Tang et al., 2016; Dong et al., 2017). However, there is stark difference between news comment generation and the other two tasks: the input of our task is an unstructured document, while the input of product review generation is structured attributes of a product; and the output of our task is a comment which often extends the content of the input with additional information, while the output of summarization is a condensed version of the input that contains the main information from the original. Very recently, there 1 https://www.yahoo.com/news/ fifa-rankings"
D19-1512,P17-1018,0,0.0244754,"ll the existing methods, we attempt to comprehend the entire news articles before generation and perform endto-end learning that can jointly optimize the comprehension model and the generation model. Our model is partially inspired by the recent success of machine reading comprehension (MRC), whose prosperity can be attributed to an increase of publicly available large scale annotated datasets, such as SQuAD (Rajpurkar et al., 2016, 2018) and MS Marco (Nguyen et al., 2016) etc. A great number of models have been proposed to tackle the MRC challenges, including BiDAF (Seo et al., 2016), r-net (Wang et al., 2017), DCN (Xiong et al., 2016), Document Reader (Chen and Bordes, 2017), QANet (Yu et al., 2018), and s-net (Tan et al., 2018) etc. Our work can be viewed as an application of MRC to a new NLG task. The task aims to generate a comment for a news article, which is different from existing MRC tasks whose goal is to answer a question. Our learning method is also different from those in the MRC works. 3 3.1 Approach Problem Formalization Suppose we have a dataset D = {(Ti , Bi , Ci )}N i=1 , where the i-th triple (Ti , Bi , Ci ) consists of a news title Ti , a news body Bi , and a comment Ci . Our goa"
J19-1005,D14-1179,0,0.00774847,"Missing"
J19-1005,N16-1108,0,0.0585039,"Missing"
J19-1005,C14-1088,0,0.024067,"ry and recent progress of chatbots, and application of text matching techniques in other tasks. Together with the review of existing work, we clarify the connection and difference between these works and our work in this article. 2.1 Chatbots Research on chatbots goes back to the 1960s when ELIZA (Weizenbaum 1966), an early chatbot, was designed with a large number of handcrafted templates and heuristic rules. 167 Computational Linguistics Volume 45, Number 1 ELIZA needs huge human effort but can only return limited responses. To remedy this, researchers have developed data-driven approaches (Higashinaka et al. 2014). The idea behind data-driven approaches is to build a chatbot with the large amount of conversation data available on social media such as forums and microblogging services. Methods along this line can be categorized into retrieval-based and generation-based ones. Generation-based chatbots reply to a message with natural language generation techniques. Early work (Ritter, Cherry, and Dolan 2011) regards messages and responses as source language and target language, respectively, and learn a phrase-based statistical machine translation model to translate a message to a response. Recently, toge"
J19-1005,D14-1181,0,0.00313027,"tenates the complement of each utterance with the last input; and in “combined,” s0 is the union of the other heuristics. Let vo = un in all heuristics, then the matching model of DL2R can be reformulated as mdl2r (s, r) = o X 0 (r)) MLP( fdl2r (vi )  fdl2r (vo )) · MLP( fdl2r (vi )  fdl2r (6) i=1 ~ v,1 , . . . , where MLP(· ) is a multi-layer perceptron. ∀v ∈ {v1 , . . . , vo }, suppose that {w ~ v,nv } represent embedding vectors of the words in v, then fdl2r (v) is given by w ~ v,1 , . . . , w ~ v,nv ) fdl2r (v) = CNN Bi-LSTM(w  (7) where CNN(· ) is a convolutional neural network (CNN) (Kim 2014) and Bi-LSTM(· ) is a bi-directional recurrent neural network with LSTM units (Bi-LSTM) (Graves, Mohamed, and Hinton 2013). The output of Bi-LSTM(· ) is all the hidden states of the Bi-LSTM 0 model. fdl2r (· ) is defined in the same way with fdl2r (· ). In DL2R, hdl2r (· ) can be viewed as an identity function on {fdl2r (v1 ), . . . , fdl2r (vo )}. Note that in the paper of Yan, Song, and Wu (2016), the authors also assume that each response candidate is associated with an antecedent posting p. This assumption does not always hold in multi-turn 1 We borrow the operator from MATLAB. 171 Computa"
J19-1005,N16-1014,0,0.190493,"such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage o"
J19-1005,P16-1094,0,0.129481,"such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage o"
J19-1005,D16-1127,0,0.163683,"such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage o"
J19-1005,D17-1230,0,0.0612794,"Missing"
J19-1005,P16-1098,0,0.0602627,"Missing"
J19-1005,D16-1176,0,0.045887,"Missing"
J19-1005,W15-4640,0,0.0590687,"he responses from the chatbot may drift to the topic of “Shanghai” if the chatbot pays significant attention to these words. Therefore, it is crucial yet non-trivial to let the chatbot understand the important points in the context and leverage them in matching and at the same time circumvent noise. Second, there is a clear dependency between Turn-5 and Turn-2 in the context, and the order of utterances matters in response selection because there will be different proper responses if we exchange Turn-3 and Turn-5. Existing work, including the recurrent neural network architectures proposed by Lowe et al. (2015), the deep learning to respond architecture proposed by Yan, Song, and Wu (2016), and the multi-view architecture proposed by Zhou et al. (2016), may lose important information in context-response matching because they follow the same paradigm to perform matching, which suffers clear drawbacks. In fact, although these models have different structures, they can be interpreted with a unified framework: A context and a response are first individually represented as vectors, and then their matching score is computed with the vectors. The context representation includes two layers. The first layer"
J19-1005,C16-1316,0,0.0795782,"ooking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning inform"
J19-1005,D16-1244,0,0.0684532,"Missing"
J19-1005,D14-1162,0,0.0842034,"Missing"
J19-1005,D11-1054,0,0.223411,"Missing"
J19-1005,P15-1152,0,0.148006,"Missing"
J19-1005,N15-1020,0,0.0241211,"to response generation; Li et al. (2016a) proposed a maximum mutual information objective to improve diversity of generated responses; Xing et al. (2017) and Mou et al. (2016) introduced external knowledge into the sequence-to-sequence model; Wu et al. (2018b) proposed decoding a response from a dynamic vocabulary; Li et al. (2016b) incorporated persona information into the sequence-to-sequence model to enhance response consistency with speakers; and Zhou et al. (2018) explored how to generate emotional responses with a memory augmented sequence-to-sequence model. In multi-turn conversation, Sordoni et al. (2015) compressed a context to a vector with a multi-layer perceptron in response generation; Serban et al. (2016) extended the sequence-to-sequence model to a hierarchical encoder-decoder structure; and under this structure, they further proposed two variants including VHRED (Serban et al. 2017b) and MrRNN (Serban et al. 2017a) to introduce latent and explicit variables into the generation process. Xing et al. (2018) exploited a hierarchical attention mechanism to highlight the effect of important words and utterances in generation. Upon these methods, reinforcement learning technique (Li et al. 20"
J19-1005,voorhees-tice-2000-trec,0,0.489297,"n candidates (Rn @k) as evaluation metrics. Here the matching models are required to return k most likely responses, and Rn @k = 1 if the true response is among the k candidates. Rn @k will become larger when k gets larger or n gets smaller. Rn @k has bias when there are multiple true candidates for a context. Hence, on the Douban corpus, apart from Rn @ks, we also followed the convention of information retrieval and used mean average precision (MAP) (Baeza-Yates, Ribeiro-Neto et al. 182 Wu et al. A Sequential Matching Framework for Retrieval-Based Chatbots 1999), mean reciprocal rank (MRR) (Voorhees and Tice 2000), and precision at position 1 (P@1) as evaluation metrics, which are defined as follows PNr MAP = 1 |S| X MRR = 1 |S| X P@1 = 1 |S| X AP(si ) , where AP(si ) = j=0 s i ∈S rel(rtop1 , si ) k=0 PNr rel(rk ,si ) j · rel(rj , si ) j=0 rel(rj , si ) s i ∈S RR(si ) , where RR(si ) = Pj 1 ranki (35) (36) (37) s i ∈S where ranki refers to the position of the first relevant response to context si in the ranking list; rj refers to the response ranked at the j-th position; rel(rj , si ) = 1 if rj is an appropriate response to context si , otherwise rel(rj , si ) = 0; rtop1 is the response ranked at the t"
J19-1005,P16-1122,0,0.065619,"Missing"
J19-1005,D13-1096,0,0.0265043,"naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses. Although most existing work on retrieval-based chatbots s"
J19-1005,N16-1170,0,0.0400905,"Missing"
J19-1005,P18-2067,1,0.863206,"open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses. Although most existing work on retrieval-based chatbots studies response selection for single-turn conversation (Wang et al. 2013) in which conversation history is ignore"
J19-1005,P17-1046,1,0.592189,"and how they calculate the matching score with the two representations. The framework view unifies the existing models and indicates the common drawbacks they have: everything in the context is compressed to one or more fixed-length vectors before matching is conducted; and there is no interaction between the context and the response in the formation of their representations. The context is represented without enough supervision from the response, and so is the response. To overcome the drawbacks, we propose a sequential matching network (SMN) for context-response matching in our early work (Wu et al. 2017) where we construct Table 1 An example of multi-turn conversation. Turn-1 Turn-2 Turn-3 Turn-4 Turn-5 Context Human: How are you doing? ChatBot: I am going to hold a drum class in Shanghai. Anyone wants to join? The location is near Lujiazui. Human: Interesting! Do you have coaches who can help me practice drum? ChatBot: Of course. Human: Can I have a free first lesson? Response Candidates Response 1: Sure. Have you ever played drum before? X Response 2: What lessons do you want? 7 165 Computational Linguistics Volume 45, Number 1 a matching vector for each utterance–response pair through conv"
J19-1005,P15-1007,0,0.0606354,"Missing"
J19-1005,Q16-1019,0,0.0823372,"Missing"
J19-1005,D16-1036,0,0.133839,"2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses. Although most existing work on retrieval-based chatbots studies response selection for single-turn conversation (Wang et al. 2013) in which conversation h"
J19-1005,P16-1044,0,\N,Missing
N10-1101,W03-1028,0,0.0107781,"rom each individual user’s Twitter messages as his/her tags. Due to the lack of human generated annotations, we employ an unsupervised strategy. Related Work Research work related to Twitter message analysis includes a user sentiment study (Jansen et al., 2009) and information retrieval indexing. To our knowledge, no previously published research has yet addressed problems on tagging user’s personal interests from Twitter messages via keyword extraction, though several studies have looked at keyword extraction using other genres. For supervised keyword extraction, (Turney, 2000; Turney, 2003; Hulth, 2003; Yih et al., 2006; Liu et al., 2008) employed TFIDF or its variants with Part-of-Speech (POS), capitalization, phrase and sentence length, etc., as features to train keyword extraction models, and discriminative training is usually adopted. Yih et al. (2006) use logistic regression to extract keywords from web pages for content-targeted advertising, which has the most similar application to our work. However, due to the lack of human annotation on Twitter messages, we have to adopt an unsupervised strategy. For unsupervised keyword extraction, TFIDF ranking is a popular method, and its effect"
N10-1101,N09-1070,0,0.015018,"e length, etc., as features to train keyword extraction models, and discriminative training is usually adopted. Yih et al. (2006) use logistic regression to extract keywords from web pages for content-targeted advertising, which has the most similar application to our work. However, due to the lack of human annotation on Twitter messages, we have to adopt an unsupervised strategy. For unsupervised keyword extraction, TFIDF ranking is a popular method, and its effectiveness has been shown in (Hulth, 2003; Yih et al., 2006). TextRank and its variants (Mihalcea and Tarau, 2004; Wan et al., 2007; Liu et al., 2009) are graph-based text ranking models, which are derived from Google’s PageRank algorithm (Brin and Page, 1998). It outperforms TFIDF ranking on traditional keyword extraction tasks. However, previous work on both TFIDF ranking and TextRank has been done mainly on academic papers, spoken documents or 689 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 689–692, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics web pages, whose language style is more formal (or, less “conversational”) than that of Twitter m"
N10-1101,W00-1308,0,0.070287,"id candidate words for user tags. The second set includes 67 abbreviations of function words that usually form grammatical parts in a sentence, such as “im” (i’m), “abt” (about). Simply removing them will affect the POS tagging. Thus, the abbreviations in both these sets are replaced with the corresponding complete words or phrases. The third set includes 4576 phrase abbreviations that are usually separable parts of a sentence that do not directly indicate discussion topics, such as “lol” (laugh out loud), “clm” (cool like me), which are removed in this step. We apply the Stanford POS tagger (Toutanova and Manning, 2000) on Twitter messages, and only select nouns and adjectives as valid candidates for user tags. At the end of the preprocessing pipeline, the candidate words are processed with the rulebased Porter stemmer2 and stopwords are filtered using a publicly available list.3 1 www.noslang.com/dictionary tartarus.org/ martin/PorterStemmer/ 3 armandbrahaj.blog.al/2009/04/14/ list-of-english-stop-words/ 2 3.2 3.2.1 TFIDF ranking In the TFIDF ranking algorithm, messages from user u are put together as one document. The TFIDF value of word i from this user’s messages is computed as tf idfi,u ni,u U =P log( )"
N10-1101,P07-1070,0,0.00787739,"phrase and sentence length, etc., as features to train keyword extraction models, and discriminative training is usually adopted. Yih et al. (2006) use logistic regression to extract keywords from web pages for content-targeted advertising, which has the most similar application to our work. However, due to the lack of human annotation on Twitter messages, we have to adopt an unsupervised strategy. For unsupervised keyword extraction, TFIDF ranking is a popular method, and its effectiveness has been shown in (Hulth, 2003; Yih et al., 2006). TextRank and its variants (Mihalcea and Tarau, 2004; Wan et al., 2007; Liu et al., 2009) are graph-based text ranking models, which are derived from Google’s PageRank algorithm (Brin and Page, 1998). It outperforms TFIDF ranking on traditional keyword extraction tasks. However, previous work on both TFIDF ranking and TextRank has been done mainly on academic papers, spoken documents or 689 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 689–692, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics web pages, whose language style is more formal (or, less “conversational”) tha"
N10-1101,W04-3252,0,\N,Missing
N10-1108,P07-1011,0,0.0499809,"Missing"
N10-1108,N06-2021,0,\N,Missing
N15-1022,W03-1004,0,0.0768064,"Missing"
N15-1022,W03-0310,0,0.100888,"Missing"
N15-1022,P11-2117,0,0.57538,"Missing"
N15-1022,de-marneffe-etal-2006-generating,0,0.0513912,"Missing"
N15-1022,W04-3208,0,0.0543309,"Missing"
N15-1022,N13-1092,0,0.148358,"Missing"
N15-1022,D13-1029,1,0.821758,"Missing"
N15-1022,D14-1058,1,0.494388,"Missing"
N15-1022,P13-1151,0,0.0751078,"Missing"
N15-1022,D14-1043,1,0.798061,"Missing"
N15-1022,P03-1054,0,0.0453331,"Missing"
N15-1022,P14-5010,0,0.0053723,"Missing"
N15-1022,E09-1065,0,0.0331283,"Missing"
N15-1022,J05-4003,0,0.154675,"Missing"
N15-1022,E06-1021,0,0.127307,"Missing"
N15-1022,N10-1063,0,0.0263911,"Missing"
N15-1022,P12-1107,0,0.559583,"Missing"
N15-1022,N10-1056,0,\N,Missing
N15-1022,C10-1152,0,\N,Missing
N15-1022,P12-1091,0,\N,Missing
N15-1022,P94-1019,0,\N,Missing
N15-1022,W10-0406,0,\N,Missing
P17-1046,P16-1094,0,0.0461305,"Missing"
P17-1046,D13-1096,0,0.841801,"t neural network (RNN) which models relationships among utterances. The final matching score is calculated with the hidden states of the RNN. An empirical study on two public data sets shows that SMN can significantly outperform stateof-the-art methods for response selection in multi-turn conversation. 1 utterance 3 utterance 4 utterance 5 response 1 response 2 Table 1: An example of multi-turn conversation the current conversation from a repository with response selection algorithms. While most existing work on retrieval-based chatbots studies response selection for single-turn conversation (Wang et al., 2013) which only considers the last input message, we consider the problem in a multi-turn scenario. In a chatbot, multi-turn response selection takes a message and utterances in its previous turns as input and selects a response that is natural and relevant to the whole context. The key to response selection lies in inputresponse matching. Different from single-turn conversation, multi-turn conversation requires matching between a response and a conversation context in which one needs to consider not only the matching between the response and the input message but also matching between responses a"
P17-1046,W15-4640,0,0.747982,"urnResponseSelection Our contributions in this paper are three-folds: (1) the proposal of a new context based matching model for multi-turn response selection in retrieval-based chatbots; (2) the publication of a large human-labeled data set to research communities; (3) empirical verification of the effectiveness of the model on public data sets. the order of the utterances matters in response selection: exchanging the third utterance and the fifth utterance may lead to different responses. Existing work, however, either ignores relationships among utterances when concatenating them together (Lowe et al., 2015), or loses important information in context in the process of converting the whole context to a vector without enough supervision from responses (e.g., by a hierarchical RNN (Zhou et al., 2016)). We propose a sequential matching network (SMN), a new context based matching model that can tackle both challenges in an end-to-end way. The reason that existing models lose important information in the context is that they first represent the whole context as a vector and then match the context vector with a response vector. Thus, responses in these models connect with the context until the final ste"
P17-1046,C16-1063,0,0.0880695,"r matching in its hidden states in the chronological order of the utterances in context. It models relationships and dependencies among the utterances in a matching fashion and has the utterance order supervise the accumulation of pair matching. The matching degree of the context and the response is computed by a logit 2 Related Work Recently, building a chatbot with data driven approaches (Ritter et al., 2011; Ji et al., 2014) has drawn significant attention. Existing work along this line includes retrieval-based methods (Hu et al., 2014; Ji et al., 2014; Wang et al., 2015; Yan et al., 2016; Wu et al., 2016b; Zhou et al., 2016; Wu et al., 2016a) and generation-based methods (Shang et al., 2015; Serban et al., 2015; Vinyals and Le, 2015; Li et al., 2015, 2016; Xing et al., 497 Word Embedding GRU1 Segment Pairs Word Pairs GRU2 u1 .... v1 .... .... .... .... un1 .... h '1 .... vn 1 h 'n1 vn h 'n L( ) Score un r M1, M2 Convolution Utterance-Response Matching (First Layer) Pooling Matching Accumulation Matching Prediction (Second Layer) (Third Layer) Figure 1: Architecture of SMN SMN first decomposes context-response matching into several utterance-response pair matching and then all pairs matchin"
P17-1046,D11-1054,0,0.715416,"class” and “drum” in context are very important. Without them, one may find responses relevant to the message (i.e., the fifth utterance of the context) but nonsense in the context (e.g., “what lessons do you want?”). Second, the message highly depends on the second utterance in the context, and Introduction Conversational agents include task-oriented dialog systems and non-task-oriented chatbots. Dialog systems focus on helping people complete specific tasks in vertical domains (Young et al., 2010), while chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter et al., 2011). Existing work on building chatbots includes generation -based methods and retrieval-based methods. Retrieval based chatbots enjoy the advantage of informative and fluent responses, because they select a proper response for ∗ Context Human: How are you doing? ChatBot: I am going to hold a drum class in Shanghai. Anyone wants to join? The location is near Lujiazui. Human: Interesting! Do you have coaches who can help me practice drum? ChatBot: Of course. Human: Can I have a free first lesson? Response Candidates Sure. Have you ever played drum before? X What lessons do you want? 7 Correspondin"
P17-1046,P15-1152,0,0.0917506,"es of a recurrent neural network with GRU following the chronological order of the utterances in the context. The third layer calculates the final matching score with the hidden states of the second layer. 2016; Serban et al., 2016). Our work is a retrievalbased method, in which we study context-based response selection. Early studies of retrieval-based chatbots focus on response selection for single-turn conversation (Wang et al., 2013; Ji et al., 2014; Wang et al., 2015; Wu et al., 2016b). Recently, researchers have begun to pay attention to multi-turn conversation. For example, Lowe et al. (2015) match a response with the literal concatenation of context utterances. Yan et al. (2016) concatenate context utterances with the input message as reformulated queries and perform matching with a deep neural network architecture. Zhou et al. (2016) improve multi-turn response selection with a multi-view model including an utterance view and a word view. Our model is different in that it matches a response with each utterance at first and accumulates matching information instead of sentences by a GRU, thus useful information for matching can be sufficiently retained. 3 3.1 SMN enjoys several ad"
P17-1046,N16-1174,0,0.0161726,"how much information from the previous hidden state and the current input flows to the current hidden state, thus important matching vectors (corresponding to important utterances) can be accumulated while noise in the vectors can be filtered out. 3.5 − 4 With [h01 , . . . , h0n ], we define g(s, r) as (6) where W2 and b2 are parameters. We consider three parameterizations for L[h01 , . . . , h0n ]: (1) only the last hidden state is used. Then L[h01 , . . . , h0n ] = h0n . (2) the hidden states are combined. Then, L[h01 , . . . , h0n ] = Pn linearly 0 i=1 wi hi , where wi ∈ R. (3) we follow (Yang et al., 2016) and employ an attention mechanism to combine the hidden states. Then, L[h01 , . . . , h0n ] is defined as 5 ti = tanh(W1,1 hui ,nu + W1,2 h0i + b1 ), exp(t> i ts ) , > (exp(t i ts )) i n X αi h0i , L[h01 , . . . , h0n ] = αi = P i=1 [yi log(g(si , ri )) + (1 − yi )log(1 − g(si , ri ))] . (8) Response Candidate Retrieval In practice, a retrieval-based chatbot, to apply the matching approach to the response selection, one needs to retrieve a number of response candidates from an index beforehand. While candidate retrieval is not the focus of the paper, it is an important step in a real system."
P17-1046,D16-1036,0,0.784002,"he publication of a large human-labeled data set to research communities; (3) empirical verification of the effectiveness of the model on public data sets. the order of the utterances matters in response selection: exchanging the third utterance and the fifth utterance may lead to different responses. Existing work, however, either ignores relationships among utterances when concatenating them together (Lowe et al., 2015), or loses important information in context in the process of converting the whole context to a vector without enough supervision from responses (e.g., by a hierarchical RNN (Zhou et al., 2016)). We propose a sequential matching network (SMN), a new context based matching model that can tackle both challenges in an end-to-end way. The reason that existing models lose important information in the context is that they first represent the whole context as a vector and then match the context vector with a response vector. Thus, responses in these models connect with the context until the final step in matching. To avoid information loss, SMN matches a response with each utterance in the context at the beginning and encodes important information in each pair into a matching vector. The m"
P18-1162,P15-2113,0,0.390902,"ry words are set to zero. We use the Adam Optimizer (Kingma and Ba, 2014) for optimization with a first momentum coefficient of 0.9 and a second momentum coefficient of 0.999. We perform a small grid search over combinations of initial learning rate [1 × 10−6 , 3 × 10−6 , 1 × 10−5 ], L2 regularization parameter [1 × 10−7 , 3 × 10−7 , 1 × 10−6 ], and batch size [8, 16, 32]. We take the best configuration based on performance on the development set, and only evaluate that configuration on the test set. In order to mitigate the class imbalance problem, median frequency balancing Eigen and Fergus (2015) is used to reweight each class in the cross-entropy loss. Therefore, the rarer a class is in the training set, the larger weight it will get in the cross entropy loss. Early stopping is applied to mitigate the problem of overfitting. For the SemEval 2017 dataset, the conditional probability over the Good class is used to rank all the candidate answers. 5 Experimental Results In this section, we evaluate our QCN model on two community question answering datasets from SemEval shared tasks. 6 The SemEval 2017 dataset provides all the data from 2016 for training , and fresh data for testing, but"
P18-1162,P06-4018,0,0.0100513,"we adopt the F1 score and accuracy on two categories for evaluation. SemEval 2017 regards answer selection as a ranking task, which is closer to the application scenario. As a result, mean average precision (MAP) is used as an evaluation measure. For a perfect ranking, a system has to place all Good answers above the PotentiallyUseful and Bad answers. The latter two are not actually distinguished and are considered Bad in terms of evaluation. Additionally, standard classification measures like accuracy and F1 score are also reported. 4.3 Implementation Details We use the tokenizer from NLTK (Bird, 2006) to preprocess each sentence. All word embeddings in the sentence encoder layer are initialized with the 300-dimensional GloVe (Pennington et al., 2014) word vectors trained on the domainspecific unannotated corpus, and embeddings for out-of-vocabulary words are set to zero. We use the Adam Optimizer (Kingma and Ba, 2014) for optimization with a first momentum coefficient of 0.9 and a second momentum coefficient of 0.999. We perform a small grid search over combinations of initial learning rate [1 × 10−6 , 3 × 10−6 , 1 × 10−5 ], L2 regularization parameter [1 × 10−7 , 3 × 10−7 , 1 × 10−6 ], an"
P18-1162,S17-2045,1,0.847421,"Missing"
P18-1162,S16-1172,0,0.0630292,". The SemEval CQA tasks (Nakov et al., 2015, 2016, 2017) provide universal benchmark datasets for evaluating researches on this problem. Earlier work of answer selection in CQA relied heavily on feature engineering, linguistic tools, and external resource. Nakov et al. (2016) investigated a wide range of feature types including similarity features, content features, thread level/meta features, and automatically generated features for SemEval CQA models. Tran et al. (2015) studied the use of topic model based features and word vector representation based features in the answer re-ranking task. Filice et al. (2016) designed various heuristic features and thread-based features 1753 that can signal a good answer. Although achieving good performance, these methods rely heavily on feature engineering, which requires a large amount of manual work and domain expertise. Since answer selection is inherently a ranking task, a few recent researches proposed to use local features to make global ranking decision. BarrónCedeño et al. (2015) was the first work that applies structured prediction model on CQA answer selection task. Joty et al. (2016) approached the task with a global inference process to exploit the in"
P18-1162,S17-2053,0,0.128356,"fore, the rarer a class is in the training set, the larger weight it will get in the cross entropy loss. Early stopping is applied to mitigate the problem of overfitting. For the SemEval 2017 dataset, the conditional probability over the Good class is used to rank all the candidate answers. 5 Experimental Results In this section, we evaluate our QCN model on two community question answering datasets from SemEval shared tasks. 6 The SemEval 2017 dataset provides all the data from 2016 for training , and fresh data for testing, but it does not include a development set. Following previous work (Filice et al., 2017), we use the 2016 official test set as the development set. 5.1 SemEval 2015 Results Table 3 compares our model with the following baselines: 1750 Methods (1) JAIST (2) HITSZ-ICRC (3) Graph-cut (4) FCCRF (5) BGMN (6) CNN-LSTM-CRF (7) QCN Table 3: dataset. F1 78.96 76.52 80.55 81.50 77.23 82.22 83.91 Acc 79.10 76.11 79.80 80.50 78.40 82.24 85.65 Methods (1) KeLP (2) Beihang-MSRA (3) ECNU (4) LSTM (5) LSTM-subject-body (6) QCN Comparisons on the SemEval 2015 • JAIST (Tran et al., 2015): It used an SVM classifier to incorporate various kinds of features , including topic model based features and"
P18-1162,S15-2035,0,0.0173659,"development set. 5.1 SemEval 2015 Results Table 3 compares our model with the following baselines: 1750 Methods (1) JAIST (2) HITSZ-ICRC (3) Graph-cut (4) FCCRF (5) BGMN (6) CNN-LSTM-CRF (7) QCN Table 3: dataset. F1 78.96 76.52 80.55 81.50 77.23 82.22 83.91 Acc 79.10 76.11 79.80 80.50 78.40 82.24 85.65 Methods (1) KeLP (2) Beihang-MSRA (3) ECNU (4) LSTM (5) LSTM-subject-body (6) QCN Comparisons on the SemEval 2015 • JAIST (Tran et al., 2015): It used an SVM classifier to incorporate various kinds of features , including topic model based features and word vector representations. • HITSZ-ICRC (Hou et al., 2015): It proposed ensemble learning and hierarchical classification method to classify answers. • Graph-cut (Joty et al., 2015): It modeled the relationship between pairs of answers at any distance in the same question thread, based on the idea that similar answers should have similar labels. • FCCRF (Joty et al., 2016): It used locally learned classifiers to predict the label for each individual node, and applied fully connected CRF to make global inference. Table 4: dataset. MAP 88.43 88.24 86.72 86.32 87.11 88.51 F1 69.87 68.40 77.67 74.41 74.50 78.11 Acc 73.89 51.98 78.43 75.69 77.28 80.71 Com"
P18-1162,D15-1068,0,0.385032,"ry words are set to zero. We use the Adam Optimizer (Kingma and Ba, 2014) for optimization with a first momentum coefficient of 0.9 and a second momentum coefficient of 0.999. We perform a small grid search over combinations of initial learning rate [1 × 10−6 , 3 × 10−6 , 1 × 10−5 ], L2 regularization parameter [1 × 10−7 , 3 × 10−7 , 1 × 10−6 ], and batch size [8, 16, 32]. We take the best configuration based on performance on the development set, and only evaluate that configuration on the test set. In order to mitigate the class imbalance problem, median frequency balancing Eigen and Fergus (2015) is used to reweight each class in the cross-entropy loss. Therefore, the rarer a class is in the training set, the larger weight it will get in the cross entropy loss. Early stopping is applied to mitigate the problem of overfitting. For the SemEval 2017 dataset, the conditional probability over the Good class is used to rank all the candidate answers. 5 Experimental Results In this section, we evaluate our QCN model on two community question answering datasets from SemEval shared tasks. 6 The SemEval 2017 dataset provides all the data from 2016 for training , and fresh data for testing, but"
P18-1162,N16-1084,0,0.471171,"ordinary QA does not possess. First, a question includes both a subject that gives a brief summary of the question and a body that describes the question in detail. The questioners usually convey their main concern and key information in the question subject. Then, they provide more extensive details about the subject, seek help, or express gratitude in the question body. Second, the problem of redundancy and noise is prevalent in CQA (Zhang et al., 2017). Both questions and answers contain auxiliary sentences that do not provide meaningful information. Previous researches (Tran et al., 2015; Joty et al., 2016) usually treat each word equally in the question and answer representation. However, due to the redundancy and noise problem, only part of text from questions and answers is useful to determine the answer quality. To make things worse, they ignored the difference between question subject and body, and simply concatenated them as the question representation. Due to the subject-body relationship described above, this simple concatenation can aggravate the redundancy problem in the question. In this paper, we propose the Question Condensing Networks (QCN) to address these problems. In order to ut"
P18-1162,S17-2003,0,0.123451,"Missing"
P18-1162,S15-2047,0,0.104987,"ry words are set to zero. We use the Adam Optimizer (Kingma and Ba, 2014) for optimization with a first momentum coefficient of 0.9 and a second momentum coefficient of 0.999. We perform a small grid search over combinations of initial learning rate [1 × 10−6 , 3 × 10−6 , 1 × 10−5 ], L2 regularization parameter [1 × 10−7 , 3 × 10−7 , 1 × 10−6 ], and batch size [8, 16, 32]. We take the best configuration based on performance on the development set, and only evaluate that configuration on the test set. In order to mitigate the class imbalance problem, median frequency balancing Eigen and Fergus (2015) is used to reweight each class in the cross-entropy loss. Therefore, the rarer a class is in the training set, the larger weight it will get in the cross entropy loss. Early stopping is applied to mitigate the problem of overfitting. For the SemEval 2017 dataset, the conditional probability over the Good class is used to rank all the candidate answers. 5 Experimental Results In this section, we evaluate our QCN model on two community question answering datasets from SemEval shared tasks. 6 The SemEval 2017 dataset provides all the data from 2016 for training , and fresh data for testing, but"
P18-1162,S16-1083,0,0.253621,"estion representation using subject-body relationship. In most cases, the question subject can be seen as a summary containing key points of the question, the question body is relatively lengthy in that it needs to explain the key points and add more details about the posted question. We propose to cheat the question subject as the primary part of the question representation, and aggregate question body information from two perspectives: similarity and disparity with the question subject. To achieve this goal, we use an orthogonal decomposition strategy, which is first proposed by Wang et al. (2016), to decompose each question body embedding into a parallel component and an orthogonal compobi,j para = bjemb · siemb i s siemb · siemb emb j i,j bi,j orth = bemb − bpara (1) (2) All vectors in the above equations are of length d. Next we describe the process of aggregating the question body information based on the parallel component in detail. The same process can be applied to the orthogonal component, so at the end of the fusion gate we can obtain Sorth and Sorth respectively. The decomposed components are passed through a fully connected layer to compute the multi-dimensional attention w"
P18-1162,D14-1162,0,0.0811374,"S, B, C). 3 Proposed Model In this paper, we propose Question Condensing Networks (QCN) which is composed of the following modules. The overall architecture of our model is illustrated in Figure 1. 3 An implementation of our model is available at https: //github.com/pku-wuwei/QCN. 1747 ???? ???? ??????? ???? ???? ?????? ?????? MLP ???? ? ????????ℎ ???? ?r?? ? ???? ???? Figure 1: Architecture for Question Condensing Network (QCN). Each block represents a vector. 3.1 Word-Level Embedding nent based on every question subject embedding: Word-level embeddings are composed of two components: GloVe (Pennington et al., 2014) word vectors trained on the domain-specific unannotated corpus provided by the task 4 , and convolutional neural network-based character embeddings which are similar to (Kim et al., 2016). Web text in CQA forums differs largely from normalized text in terms of spelling and grammar, so specifically trained GloVe vectors can model word interactions more precisely. Character embedding has proven to be very useful for out-of-vocabulary (OOV) words, so it is especially suitable for noisy web text in CQA. We concatenate these two embedding vectors for every word to generate word-level embeddings Se"
P18-1162,S15-2038,0,0.3477,"istics of CQA that ordinary QA does not possess. First, a question includes both a subject that gives a brief summary of the question and a body that describes the question in detail. The questioners usually convey their main concern and key information in the question subject. Then, they provide more extensive details about the subject, seek help, or express gratitude in the question body. Second, the problem of redundancy and noise is prevalent in CQA (Zhang et al., 2017). Both questions and answers contain auxiliary sentences that do not provide meaningful information. Previous researches (Tran et al., 2015; Joty et al., 2016) usually treat each word equally in the question and answer representation. However, due to the redundancy and noise problem, only part of text from questions and answers is useful to determine the answer quality. To make things worse, they ignored the difference between question subject and body, and simply concatenated them as the question representation. Due to the subject-body relationship described above, this simple concatenation can aggravate the redundancy problem in the question. In this paper, we propose the Question Condensing Networks (QCN) to address these prob"
P18-1162,C16-1127,0,0.030014,"dense the question representation using subject-body relationship. In most cases, the question subject can be seen as a summary containing key points of the question, the question body is relatively lengthy in that it needs to explain the key points and add more details about the posted question. We propose to cheat the question subject as the primary part of the question representation, and aggregate question body information from two perspectives: similarity and disparity with the question subject. To achieve this goal, we use an orthogonal decomposition strategy, which is first proposed by Wang et al. (2016), to decompose each question body embedding into a parallel component and an orthogonal compobi,j para = bjemb · siemb i s siemb · siemb emb j i,j bi,j orth = bemb − bpara (1) (2) All vectors in the above equations are of length d. Next we describe the process of aggregating the question body information based on the parallel component in detail. The same process can be applied to the orthogonal component, so at the end of the fusion gate we can obtain Sorth and Sorth respectively. The decomposed components are passed through a fully connected layer to compute the multi-dimensional attention w"
P18-1162,S17-2060,0,0.0318471,"Missing"
P18-1162,C16-1117,0,0.0267716,"Missing"
P18-2067,N16-1014,0,0.0430232,"0.526 0.565 everything the same as our approach but replace D with a set constructed by random sampling, denoted as model+WSrand. Table 3 reports the results. We can conclude that both the weak supervision and the strategy of training data construction are important to the success of the proposed learning approach. Training data construction plays a more crucial role, because it involves more true positives and negatives with different semantic distances to the positives into learning. Does updating the Seq2Seq model help? It is well known that Seq2Seq models suffer from the “safe response” (Li et al., 2016a) problem, which may bias the weak supervision signals to high-frequency responses. Therefore, we attempt to iteratively optimize the Seq2Seq model and the matching model and check if the matching model can be further improved. Specifically, we update the Seq2Seq model every 20 mini-batches with the policy-based reinforcement learning approach proposed in (Li et al., 2016b). The reward is defined as the matching score of a context and a response given by the matching model. Unfortunately, we do not observe significant improvement on the matching model. The result is attributed to two factors:"
P18-2067,D16-1127,0,0.0988774,"0.526 0.565 everything the same as our approach but replace D with a set constructed by random sampling, denoted as model+WSrand. Table 3 reports the results. We can conclude that both the weak supervision and the strategy of training data construction are important to the success of the proposed learning approach. Training data construction plays a more crucial role, because it involves more true positives and negatives with different semantic distances to the positives into learning. Does updating the Seq2Seq model help? It is well known that Seq2Seq models suffer from the “safe response” (Li et al., 2016a) problem, which may bias the weak supervision signals to high-frequency responses. Therefore, we attempt to iteratively optimize the Seq2Seq model and the matching model and check if the matching model can be further improved. Specifically, we update the Seq2Seq model every 20 mini-batches with the policy-based reinforcement learning approach proposed in (Li et al., 2016b). The reward is defined as the matching score of a context and a response given by the matching model. Unfortunately, we do not observe significant improvement on the matching model. The result is attributed to two factors:"
P18-2067,W15-4640,0,0.598699,"significant improvements when they are learned with the proposed method. 1 Introduction Recently, more and more attention from both academia and industry is paying to building nontask-oriented chatbots that can naturally converse with humans on any open domain topics. Existing approaches can be categorized into generationbased methods (Shang et al., 2015; Vinyals and Le, 2015; Serban et al., 2016; Sordoni et al., 2015; Xing et al., 2017; Serban et al., 2017; Xing et al., 2018) which synthesize a response with natural language generation techniques, and retrievalbased methods (Hu et al., 2014; Lowe et al., 2015; Yan et al., 2016; Zhou et al., 2016; Wu et al., 2017) which select a response from a pre-built index. In this work, we study response selection for retrieval-based chatbots, not only because retrieval-based methods can return fluent and informative responses, but also because they have been successfully applied to many real products such as the social-bot XiaoIce from Microsoft (Shum et al., 2018) and the E-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017). ∗ 1 The model performs well on randomly sampled data, but badly on human labeled data. Corresponding Author 420 Proce"
P18-2067,D13-1096,0,0.46557,"sed approaches in the teacher-student framework (Dehghani et al., 2017a,b), as there are no labeled data in learning. 3 Implementation Details 3.2 Single-turn Response Selection Experiment settings: in the STC (stands for Short Text Conversation) data set, the task is to select a proper response for a post in Weibo2 . The training set contains 4.8 million post-response (true response) pairs. The test set consists of 422 posts with each one associated with around 30 responses labeled by human annotators in “good” and “bad”. In total, there are 12, 402 labeled pairs in the test data. Following (Wang et al., 2013, 2015), we combine the score from a matching model with TF-IDF based cosine similarity using RankSVM whose parameters are chosen by 5-fold cross validation. Precision at position 1 (P@1) is employed as an evaluation metric. In addition to the models compared on the data in the existing literatures, we also implement dual LSTM (Lowe et al., 2015) as a baseline. As case studies, we learn a dual LSTM and an CNN (Hu et al., 2014) with the proposed approach, and denote them as LSTM+WS (Weak Supervision) and CNN+WS, respectively. When constructing D, we build an index with the training data using L"
P18-2067,P17-1046,1,0.89116,"sion for Response Selection in Retrieval-based Chatbots † Yu Wu† , Wei Wu‡ , Zhoujun Li†∗, Ming Zhou♦ State Key Lab of Software Development Environment, Beihang University, Beijing, China † Authors are supported by AdeptMind Scholarship ♦ Microsoft Research, Beijing, China ‡ Microsoft Corporation, Beijing, China {wuyu,lizj}@buaa.edu.cn {wuwei,mingzhou}@microsoft.com Abstract A key step to response selection is measuring the matching degree between a response candidate and an input which is either a single message (Hu et al., 2014) or a conversational context consisting of multiple utterances (Wu et al., 2017). While existing research focuses on how to define a matching model with neural networks, little attention has been paid to how to learn such a model when few labeled data are available. In practice, because human labeling is expensive and exhausting, one cannot have large scale labeled data for model training. Thus, a common practice is to transform the matching problem to a classification problem with human responses as positive examples and randomly sampled ones as negative examples. This strategy, however, oversimplifies the learning problem, as most of the randomly sampled responses are e"
P18-2067,P15-1152,0,0.381248,"Missing"
P18-2067,N15-1020,0,0.100849,"Missing"
P18-2067,D16-1036,0,0.792114,"e learned with the proposed method. 1 Introduction Recently, more and more attention from both academia and industry is paying to building nontask-oriented chatbots that can naturally converse with humans on any open domain topics. Existing approaches can be categorized into generationbased methods (Shang et al., 2015; Vinyals and Le, 2015; Serban et al., 2016; Sordoni et al., 2015; Xing et al., 2017; Serban et al., 2017; Xing et al., 2018) which synthesize a response with natural language generation techniques, and retrievalbased methods (Hu et al., 2014; Lowe et al., 2015; Yan et al., 2016; Zhou et al., 2016; Wu et al., 2017) which select a response from a pre-built index. In this work, we study response selection for retrieval-based chatbots, not only because retrieval-based methods can return fluent and informative responses, but also because they have been successfully applied to many real products such as the social-bot XiaoIce from Microsoft (Shum et al., 2018) and the E-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017). ∗ 1 The model performs well on randomly sampled data, but badly on human labeled data. Corresponding Author 420 Proceedings of the 56th Annual Meeting of"
P19-1001,E17-1104,0,0.0356527,"on between c and r, and how to learn such a deep model from D. form. As far as we know, this is the first architecture that realizes deep interaction for multi-turn response selection. Encouraged by the big success of deep neural architectures such as Resnet (He et al., 2016) and inception (Szegedy et al., 2015) in computer vision, researchers have studied if they can achieve similar results with deep neural networks on NLP tasks. Although deep models have not yet brought breakthroughs to NLP as they do to computer vision, they have proven effective in a few tasks such as text classification (Conneau et al., 2017), natural language inference (Kim et al., 2018; Tay et al., 2018), and question answering (Tay et al., 2018; Kim et al., 2018), etc. In this work, we attempt to improve the accuracy of multi-turn response selection in retrieval-based dialogue systems by increasing the depth of context-response interaction in matching. Through extensive studies on benchmarks, we show that depth can bring significant improvement to model performance on the task. 3 4 Interaction-over-Interaction Network We define g(·, ·) as an interaction-over-interaction network (IoI). Figure 1 illustrates the architecture of Io"
P19-1001,P16-1094,0,0.0600994,"Missing"
P19-1001,D16-1127,0,0.0465592,"Missing"
P19-1001,D17-1230,0,0.0810916,"generation model estimated from a largescale conversation corpus (Serban et al., 2016; Li et al., 2017b). In this work, we study the problem of multi-turn response selection for retrievalbased dialogue systems where the input is a conversation context consisting of a sequence of utterances. Compared with generation-based methods, retrieval-based methods are superior in terms of response fluency and diversity, and thus have been widely applied in commercial chatbots such as the social bot XiaoIce (Shum et al., 2018) from Microsoft, and the e-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017a). A key step in multi-turn response selection is to measure the matching degree between a conversation context and a response candidate. Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al., 2018b) where matching signals in each utteranceresponse pair are distilled from their interaction based on their representations, and then are aggregated as a matching score. Although utteranceresponse interaction has proven to be crucial to the performance of the matching models (Wu et al., 2017), it is execute"
P19-1001,W15-4640,0,0.323161,"ses with specific personas or emotions (Li et al., 2016a; Zhang et al., 2018a; Zhou et al., 2018a); and to pursue better optimization strategies (Li et al., 2017b, 2016b). The second group learns a matching model of a human input and a response candidate for response selection. Along this line, the focus of research starts from single-turn response selection by setting the human input as a single message (Wang et al., 2013; Hu et al., 2014; Wang et al., 2015), and moves to context-response matching for multi-turn response selection recently. Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching model (Zhou et al., 2016), the sequential matching network (Wu et al., 2017, 2018b), and the deep attention matching network (Zhou et al., 2018b). Besides model design, some attention is also paid to the learning problem of matching models (Wu et al., 2018a). Our work belongs to the second group. The proposed interaction-over-interaction network is unique in that it performs matching by stacking multiple interaction blocks, and thus extends the shallow interaction in state-of-the-art methods to a deep We co"
P19-1001,D18-1479,0,0.0157468,"As far as we know, this is the first architecture that realizes deep interaction for multi-turn response selection. Encouraged by the big success of deep neural architectures such as Resnet (He et al., 2016) and inception (Szegedy et al., 2015) in computer vision, researchers have studied if they can achieve similar results with deep neural networks on NLP tasks. Although deep models have not yet brought breakthroughs to NLP as they do to computer vision, they have proven effective in a few tasks such as text classification (Conneau et al., 2017), natural language inference (Kim et al., 2018; Tay et al., 2018), and question answering (Tay et al., 2018; Kim et al., 2018), etc. In this work, we attempt to improve the accuracy of multi-turn response selection in retrieval-based dialogue systems by increasing the depth of context-response interaction in matching. Through extensive studies on benchmarks, we show that depth can bring significant improvement to model performance on the task. 3 4 Interaction-over-Interaction Network We define g(·, ·) as an interaction-over-interaction network (IoI). Figure 1 illustrates the architecture of IoI. The model pairs each utterance in a context with a response ca"
P19-1001,C16-1316,1,0.886108,"Missing"
P19-1001,D13-1096,0,0.300989,"Missing"
P19-1001,N18-1202,0,0.0568928,"Missing"
P19-1001,N16-1170,0,0.233766,"b), we directly copy the numbers from the paper. For the E-commerce data, Zhang et al. (2018b) report performance of all baselines except DAM. Thus, we copy all available numbers from the paper and implement DAM with the published code4 . In order to conduct statistical tests, we also run the code of DAM on the Ubuntu data and the Douban data. Baselines We compare IoI with the following models: Single-turn Matching Models: these models, including RNN (Lowe et al., 2015), CNN (Lowe et al., 2015), LSTM (Lowe et al., 2015), BiLSTM (Kadlec et al., 2015), MV-LSTM (Wan et al., 2016) and Match-LSTM (Wang and Jiang, 2016), perform context-response matching by concatenating all utterances in a context into a single long document and calculating a matching score between the document and a response candidate. Multi-View (Zhou et al., 2016): the model calculates matching degree between a context and a response candidate from both a word sequence view and an utterance sequence view. DL2R (Yan et al., 2016): the model first reformulates the last utterance with previous turns in a context with different approaches. A response candidate and the reformulated message are then represented by a composition of RNN and CNN."
P19-1001,P18-2067,1,0.930561,". Compared with generation-based methods, retrieval-based methods are superior in terms of response fluency and diversity, and thus have been widely applied in commercial chatbots such as the social bot XiaoIce (Shum et al., 2018) from Microsoft, and the e-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017a). A key step in multi-turn response selection is to measure the matching degree between a conversation context and a response candidate. Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al., 2018b) where matching signals in each utteranceresponse pair are distilled from their interaction based on their representations, and then are aggregated as a matching score. Although utteranceresponse interaction has proven to be crucial to the performance of the matching models (Wu et al., 2017), it is executed in a rather shallow manner where matching between an utterance and a response candidate is determined only by one step of interaction on each type or each layer of representations. In this paper, we attempt to move from shallow interaction to deep interaction, and consider context-respons"
P19-1001,P15-1152,0,0.108809,"Missing"
P19-1001,P18-1103,0,0.332465,"alogue systems where the input is a conversation context consisting of a sequence of utterances. Compared with generation-based methods, retrieval-based methods are superior in terms of response fluency and diversity, and thus have been widely applied in commercial chatbots such as the social bot XiaoIce (Shum et al., 2018) from Microsoft, and the e-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017a). A key step in multi-turn response selection is to measure the matching degree between a conversation context and a response candidate. Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al., 2018b) where matching signals in each utteranceresponse pair are distilled from their interaction based on their representations, and then are aggregated as a matching score. Although utteranceresponse interaction has proven to be crucial to the performance of the matching models (Wu et al., 2017), it is executed in a rather shallow manner where matching between an utterance and a response candidate is determined only by one step of interaction on each type or each layer of representations. In this paper,"
P19-1001,P17-1046,1,0.75996,"retrievalbased dialogue systems where the input is a conversation context consisting of a sequence of utterances. Compared with generation-based methods, retrieval-based methods are superior in terms of response fluency and diversity, and thus have been widely applied in commercial chatbots such as the social bot XiaoIce (Shum et al., 2018) from Microsoft, and the e-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017a). A key step in multi-turn response selection is to measure the matching degree between a conversation context and a response candidate. Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al., 2018b) where matching signals in each utteranceresponse pair are distilled from their interaction based on their representations, and then are aggregated as a matching score. Although utteranceresponse interaction has proven to be crucial to the performance of the matching models (Wu et al., 2017), it is executed in a rather shallow manner where matching between an utterance and a response candidate is determined only by one step of interaction on each type or each layer of representatio"
P19-1001,P18-1205,0,0.0768423,"Missing"
P19-1001,C18-1317,0,0.174548,"and the response candidate. 2 Related Work Existing methods for building an open-domain dialogue system can be categorized into two groups. The first group learns response generation models under an encoder-decoder framework. On top of the basic sequence-to-sequence with attention architecture (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al., 2016a; Zhang et al., 2018a; Zhou et al., 2018a); and to pursue better optimization strategies (Li et al., 2017b, 2016b). The second group learns a matching model of a human input and a response candidate for response selection. Along this line, the focus of research starts from single-turn response selection by setting the human input as a single message (Wang et al., 2013; Hu et al., 2014; Wang et al., 2015), and moves to context-response matching for multi-turn response selection recently. Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2"
P19-1001,P17-1061,0,0.0351046,"Missing"
P19-1001,D16-1036,1,0.905357,"Missing"
P19-1370,P16-1094,0,0.0315846,"nd δ to co-teaching. Experiments are conducted with DAM on the two data sets. 5 Related Work So far, methods used to build an open domain dialogue system can be divided into two categories. The first category utilize an encoderdecoder framework to learn response generation models. Since the basic sequence-to-sequence models (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018) tend to generate generic responses, extensions have been made to incorporate external knowledge into generation (Mou et al., 2016; Xing et al., 2017), and to generate responses with specific personas or emotions (Li et al., 2016; Zhang et al., 2018a; Zhou et al., 2018a). The second category design a discriminative model to measure the matching degree between a human input and a response candidate for response selection. At the beginning, research along this line assumes that the human input is a single message (Lu and Li, 2013; Wang et al., 2013; Hu et al., 2014; Wang et al., 2015). Recently, researchers begin to make use of conversation history in matching. Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching mod"
P19-1370,W15-4640,0,0.563357,"val-based systems are often superior to their generation-based counterparts on response fluency and diversity, are easy to evaluate, and have powered some real products such as the social bot XiaoIce from Microsoft (Shum et al., 2018), and the E-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017). A key problem in response selection is how to measure the matching degree between a conversation context (a message with several turns of conversation history) and a response candidate. Existing studies have paid tremendous effort to build a matching model with neural architectures (Lowe et al., 2015; Zhou et al., 2016; Wu et al., 2017; Zhou et al., 2018b), and advanced models such as the deep attention matching network (DAM) (Zhou et al., 2018b) have achieved impressive performance on benchmarks. In contrary to the progress on model architectures, there is little exploration on learning approaches of the models. On the one hand, neural matching models are becoming more and more complicated; on the other hand, all models are simply learned by distinguishing human responses from some automatically constructed negative response candidates (e.g., by random sampling). Although this heuristic"
P19-1370,C16-1316,1,0.851966,"ns on Douban 0.60 (b) 0.1 0.3 0.5 0.7 0.9 0.95 1.0 δ Data curriculum on ECD Figure 3: Effects of λ and δ to co-teaching. Experiments are conducted with DAM on the two data sets. 5 Related Work So far, methods used to build an open domain dialogue system can be divided into two categories. The first category utilize an encoderdecoder framework to learn response generation models. Since the basic sequence-to-sequence models (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018) tend to generate generic responses, extensions have been made to incorporate external knowledge into generation (Mou et al., 2016; Xing et al., 2017), and to generate responses with specific personas or emotions (Li et al., 2016; Zhang et al., 2018a; Zhou et al., 2018a). The second category design a discriminative model to measure the matching degree between a human input and a response candidate for response selection. At the beginning, research along this line assumes that the human input is a single message (Lu and Li, 2013; Wang et al., 2013; Hu et al., 2014; Wang et al., 2015). Recently, researchers begin to make use of conversation history in matching. Representative methods include the dual LSTM model (Lowe et al"
P19-1370,P15-1152,0,0.15213,"Missing"
P19-1370,N10-1116,0,0.0290891,"both the Douban data and the E-commerce data with SMN and DAM which achieves state-of-theart performance on benchmarks. Moreover, improvement to SMN on the Douban data from coteaching is bigger than that from weak supervision, when the ratio of the positive and the negative is 1:1 in training7 . Our work, in a broad sense, belongs to the effort on learning with noisy data. Previous studies including curriculum learning (CL) (Bengio et al., 2009) and self-paced learning (SPL) (Jiang et al., 2014, 2015) tackle the problem with heuristics, such as ordering data from easy instances to hard ones (Spitkovsky et al., 2010; Tsvetkov et al., 2016) and retaining training instances whose losses are smaller than a threshold (Jiang et al., 2015). Recently, Fan et al. (2018) propose a deep reinforcement learning framework in which a simple deep neural network is used to adaptively select and filter important data instances from the training data. Jiang et al. (2017) propose a MentorNet which learns a data-driven curriculum with a Student-Net to mitigate overfitting on corrupted labels. In parallel to curriculum learning, several studies explore sample weighting schemes where training samples are re-weighted according"
P19-1370,D19-1011,0,0.279741,"selection. At the beginning, research along this line assumes that the human input is a single message (Lu and Li, 2013; Wang et al., 2013; Hu et al., 2014; Wang et al., 2015). Recently, researchers begin to make use of conversation history in matching. Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching model (Zhou et al., 2016), the sequential matching network (Wu et al., 2017, 2018c), the deep attention matching network (Zhou et al., 2018b), and the multi-representation fusion network (Tao et al., 2019). Our work belongs to the second group. Rather than crafting a new model, we are interested in how to learn the existing models with a better approach. Probably the most related work is the weakly supervised learning approach proposed in Wu et al. (2018b). However, there is stark difference between our approach and the weak supervision approach: (1) weak supervision employs a static generative model to teach a discriminative model, while co-teaching dynamically lets two discriminative models teach each other and evolve together; (2) weak supervision needs pretraining a generative model with ex"
P19-1370,P16-1013,0,0.0575427,"Missing"
P19-1370,D13-1096,0,0.199215,"dels (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018) tend to generate generic responses, extensions have been made to incorporate external knowledge into generation (Mou et al., 2016; Xing et al., 2017), and to generate responses with specific personas or emotions (Li et al., 2016; Zhang et al., 2018a; Zhou et al., 2018a). The second category design a discriminative model to measure the matching degree between a human input and a response candidate for response selection. At the beginning, research along this line assumes that the human input is a single message (Lu and Li, 2013; Wang et al., 2013; Hu et al., 2014; Wang et al., 2015). Recently, researchers begin to make use of conversation history in matching. Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching model (Zhou et al., 2016), the sequential matching network (Wu et al., 2017, 2018c), the deep attention matching network (Zhou et al., 2018b), and the multi-representation fusion network (Tao et al., 2019). Our work belongs to the second group. Rather than crafting a new model, we are interested in how to learn the existing"
P19-1370,P18-2067,1,0.90322,"epresentative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching model (Zhou et al., 2016), the sequential matching network (Wu et al., 2017, 2018c), the deep attention matching network (Zhou et al., 2018b), and the multi-representation fusion network (Tao et al., 2019). Our work belongs to the second group. Rather than crafting a new model, we are interested in how to learn the existing models with a better approach. Probably the most related work is the weakly supervised learning approach proposed in Wu et al. (2018b). However, there is stark difference between our approach and the weak supervision approach: (1) weak supervision employs a static generative model to teach a discriminative model, while co-teaching dynamically lets two discriminative models teach each other and evolve together; (2) weak supervision needs pretraining a generative model with extra resources and pre-building an index for training data construction, while co-teaching does not have such request; and (3) in terms of multi-turn response selection, weak supervision is only tested on the Douban data with SMN and the multi-view match"
P19-1370,P17-1046,1,0.308055,"o their generation-based counterparts on response fluency and diversity, are easy to evaluate, and have powered some real products such as the social bot XiaoIce from Microsoft (Shum et al., 2018), and the E-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017). A key problem in response selection is how to measure the matching degree between a conversation context (a message with several turns of conversation history) and a response candidate. Existing studies have paid tremendous effort to build a matching model with neural architectures (Lowe et al., 2015; Zhou et al., 2016; Wu et al., 2017; Zhou et al., 2018b), and advanced models such as the deep attention matching network (DAM) (Zhou et al., 2018b) have achieved impressive performance on benchmarks. In contrary to the progress on model architectures, there is little exploration on learning approaches of the models. On the one hand, neural matching models are becoming more and more complicated; on the other hand, all models are simply learned by distinguishing human responses from some automatically constructed negative response candidates (e.g., by random sampling). Although this heuristic approach can avoid expensive and exh"
P19-1370,P18-1205,0,0.0536553,"Missing"
P19-1370,C18-1317,0,0.375056,"d negative responses are randomly sampled. The ratio of the positive and the negative is 1:1 in training and validation. In the test set, each context has 10 response candidates retrieved from an index whose appropriateness regarding to the context is judged by human annotators. The average number of positive responses per context is 1.18. Following Wu et al. (2017), we employ R10 @1, R10 @2, R10 @5, mean average precision (MAP), mean reciprocal rank (MRR), and precision at position 1 (P@1) as evaluation metrics. In addition to the Douban data, we also choose E-commerce Dialogue Corpus (ECD) (Zhang et al., 2018b) as an experimental data set. The data consists of real-world conversations between customers and customer service staff in Taobao4 , which is the largest e-commerce platform in China. There are 1 million context-response pairs in the training set, and 10 thousand pairs in both the validation set and the test set. Each context in the training set and the validation set corresponds to one positive response candidate and one negative response candidate, while in the test set, the number of response candidates per context is 10 with only one of them positive. In the released data, human respons"
P19-1370,D16-1036,1,0.925812,"Missing"
P19-1370,P18-1103,0,0.245472,"roach can generally and significantly improve the performance of existing matching models. 1 Introduction Human-machine conversation is a long-standing goal of artificial intelligence. Recently, building a dialogue system for open domain human-machine conversation is attracting more and more attention due to both availability of large-scale human conversation data and powerful models learned with neural networks. Existing methods are either retrieval-based or generation-based. Retrievalbased methods reply to a human input by selecting a proper response from a pre-built index (Ji et al., 2014; Zhou et al., 2018b; Yan and Zhao, 2018), while generation-based methods synthesize a response with a natural language model (Shang et al., 2015; Serban et al., 2017). In this ∗ † Equal Contribution. Corresponding author: Rui Yan (ruiyan@pku.edu.cn). work, we study the problem of response selection for retrieval-based dialogue systems, since retrieval-based systems are often superior to their generation-based counterparts on response fluency and diversity, are easy to evaluate, and have powered some real products such as the social bot XiaoIce from Microsoft (Shum et al., 2018), and the E-commerce assistant Ali"
P19-1538,P16-1154,0,0.0199524,"annotation scheme (Core and Allen, 1997). The dialogue act of a given response is obtained by the state-of-the-art dialogue act classifier in (Liu et al., 2017) learned from the Switchboard (SW) 1 Release 2 Corpus (Godfrey and Holliman, 1997). DA is a categorical variable. (3) Multiple Utterances (MU): if a response is made up of multiple utterances. We split a response as utterances according to “.”, “?” and “!”, and remove utterances that are less than 3 words. The variable is “true” if there are more than 1 utterance left, otherwise it is “false”. (4) Copy Ratio (CR): inspired by COPY-NET (Gu et al., 2016) which indicates that humans may repeat entity names or even long phrases in conversation, we incorporate a “copy mechanism” into our model by using copy ratio as a soft implementation of COPY-NET. We compute the ratio of unigrams shared by a message and its response (divided by the length of the response) with stop words and top 1000 most frequent words in training excluded. CR is a real-valued variable. (5) Specificity (S): 5421 following SC-Seq2Seq (Zhang et al., 2018b), we calculate normalized inverse word frequency as a specificity variable. The variable is real-valued. Among the five var"
P19-1538,P16-1094,0,0.444326,"n |Len: 8 |Copy: true |Utts: false |Spe: medium Is New York more expensive than California? Act: wh-question |Len: 17 |Copy: false |Utts: true |Spe: high Cool, sounds great! What is the tallest building in this city, Chrysler building? Act: statement |Len: 13 |Copy: false |Utts: true |Spe: low I don’t know what you are talking about. But it seems good. 2015; Shang et al., 2015). Although the architecture can naturally model the correspondence between a message and a response, and is easy to extend to handle conversation history (Serban et al., 2016; Xing et al., 2018) and various constraints (Li et al., 2016; Zhou et al., 2018), it is notorious for generating safe responses such as “I don’t know” and “me too” in practice. A plausible reason for the “safe response” issue is that there exists one-to-many relationship between messages and responses. One message could correspond to many valid responses and vice versa (Zhang et al., 2018a). The vanilla encoder-decoder architecture is prone to memorize high-frequency patterns in data, and thus tends to generate similar and trivial responses for different messages. A typical method for modeling the relationship between messages and responses is to intro"
P19-1538,D17-1231,0,0.0182494,"Other words are marked as “UNK”. 6.2 Meta-word Construction As a showcase of the framework of GTMNES2S, we consider the following variables as a metaword: (1) Response Length (RL): number of words and punctuation marks in a response. We restrict the range of the variable in {1, . . . , 25} (i.e., responses longer than 25 are normalized as 25), and treat it as a categorical variable. (2) Dialog Act (DA): we employ the 42 dialogue acts based on the DAMSL annotation scheme (Core and Allen, 1997). The dialogue act of a given response is obtained by the state-of-the-art dialogue act classifier in (Liu et al., 2017) learned from the Switchboard (SW) 1 Release 2 Corpus (Godfrey and Holliman, 1997). DA is a categorical variable. (3) Multiple Utterances (MU): if a response is made up of multiple utterances. We split a response as utterances according to “.”, “?” and “!”, and remove utterances that are less than 3 words. The variable is “true” if there are more than 1 utterance left, otherwise it is “false”. (4) Copy Ratio (CR): inspired by COPY-NET (Gu et al., 2016) which indicates that humans may repeat entity names or even long phrases in conversation, we incorporate a “copy mechanism” into our model by u"
P19-1538,C16-1316,0,0.100422,"en domain dialogues with multiple variables (a.k.a., meta-word); (2) proposal of a goal tracking memory network that naturally allows a meta-word to guide response generation; and (3) empirical verification of the effectiveness of the proposed model on two large-scale datasets. 2 Related Work Neural response generation models are built upon the encoder-decoder framework (Sutskever et al., 2014). Starting from the basic sequence-tosequence with attention architecture (Vinyals and Le, 2015; Shang et al., 2015), extensions under the framework have been made to combat the “safe response” problem (Mou et al., 2016; Tao et al., 2018); to model the hierarchy of conversation history (Serban et al., 2016, 2017; Xing et al., 2018); 5417 to generate responses with specific personas or emotions (Li et al., 2016; Zhou et al., 2018); and to speed up response decoding (Wu et al., 2018). In this work, we also aim to tackle the “safe response” problem, but in an explainable, controllable, and general way. Rather than learning with a different objective (e.g., (Li et al., 2015)), generation from latent variables (e.g., (Zhao et al., 2017)), or introducing extra content (e.g., (Xing et al., 2017)), we explicitly des"
P19-1538,P02-1040,0,0.105713,"Missing"
P19-1538,N18-1162,0,0.0145798,"too” in practice. A plausible reason for the “safe response” issue is that there exists one-to-many relationship between messages and responses. One message could correspond to many valid responses and vice versa (Zhang et al., 2018a). The vanilla encoder-decoder architecture is prone to memorize high-frequency patterns in data, and thus tends to generate similar and trivial responses for different messages. A typical method for modeling the relationship between messages and responses is to introduce latent variables into the encoder-decoder framework (Serban et al., 2017; Zhao et al., 2017; Park et al., 2018). It is, however, difficult to explain what relationship a latent variable represents, nor one can control responses to generate by manipulating the latent variable. Although a recent study (Zhao et al., 2018) replaces continuous latent variables with discrete ones, it still needs a lot of post human effort to explain the meaning of the variables. In this work, we aim to model the one-to-many relationship in open domain dialogues in an explainable and controllable way. Instead of using 5416 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5416–5426"
P19-1538,N19-1170,0,0.107004,"Our method allows developers to manipulate the generation process by playing with the meta-words and provides a general solution to response generation with specific attributes such as dialogue acts. Recently, controlling specific aspects in text generation is drawing increasing attention (Hu et al., 2017; Logeswaran et al., 2018). In the context of dialogue generation, Wang et al. (2017) propose steering response style and topic with human provided topic hints and fine-tuning on small scenting data; Zhang et al. (2018a) propose learning to control specificity of responses; and very recently, See et al. (2019) investigate how controllable attributes of responses affect human engagement with methods of conditional training and weighted decoding. Our work is different in that (1) rather than playing with a single variable like specificity or topics, our model simultaneously controls multiple variables and can take controlling with specificity or topics as special cases; and (2) we manage attribute expression in response generation with a principled approach rather than simple heuristics like in (See et al., 2019), and thus, our model can achieve better accuracy in terms of attribute expression in gen"
P19-1538,P15-1152,0,0.339271,"Missing"
P19-1538,D17-1228,0,0.0291419,"Missing"
P19-1538,P18-1102,0,0.521273,"about. But it seems good. 2015; Shang et al., 2015). Although the architecture can naturally model the correspondence between a message and a response, and is easy to extend to handle conversation history (Serban et al., 2016; Xing et al., 2018) and various constraints (Li et al., 2016; Zhou et al., 2018), it is notorious for generating safe responses such as “I don’t know” and “me too” in practice. A plausible reason for the “safe response” issue is that there exists one-to-many relationship between messages and responses. One message could correspond to many valid responses and vice versa (Zhang et al., 2018a). The vanilla encoder-decoder architecture is prone to memorize high-frequency patterns in data, and thus tends to generate similar and trivial responses for different messages. A typical method for modeling the relationship between messages and responses is to introduce latent variables into the encoder-decoder framework (Serban et al., 2017; Zhao et al., 2017; Park et al., 2018). It is, however, difficult to explain what relationship a latent variable represents, nor one can control responses to generate by manipulating the latent variable. Although a recent study (Zhao et al., 2018) repla"
P19-1538,P18-1101,0,0.0562862,"ersa (Zhang et al., 2018a). The vanilla encoder-decoder architecture is prone to memorize high-frequency patterns in data, and thus tends to generate similar and trivial responses for different messages. A typical method for modeling the relationship between messages and responses is to introduce latent variables into the encoder-decoder framework (Serban et al., 2017; Zhao et al., 2017; Park et al., 2018). It is, however, difficult to explain what relationship a latent variable represents, nor one can control responses to generate by manipulating the latent variable. Although a recent study (Zhao et al., 2018) replaces continuous latent variables with discrete ones, it still needs a lot of post human effort to explain the meaning of the variables. In this work, we aim to model the one-to-many relationship in open domain dialogues in an explainable and controllable way. Instead of using 5416 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5416–5426 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics latent variables, we consider explicitly representing the relationship between a message and a response with meta-wo"
P19-1538,P17-1061,0,0.2994,"don’t know” and “me too” in practice. A plausible reason for the “safe response” issue is that there exists one-to-many relationship between messages and responses. One message could correspond to many valid responses and vice versa (Zhang et al., 2018a). The vanilla encoder-decoder architecture is prone to memorize high-frequency patterns in data, and thus tends to generate similar and trivial responses for different messages. A typical method for modeling the relationship between messages and responses is to introduce latent variables into the encoder-decoder framework (Serban et al., 2017; Zhao et al., 2017; Park et al., 2018). It is, however, difficult to explain what relationship a latent variable represents, nor one can control responses to generate by manipulating the latent variable. Although a recent study (Zhao et al., 2018) replaces continuous latent variables with discrete ones, it still needs a lot of post human effort to explain the meaning of the variables. In this work, we aim to model the one-to-many relationship in open domain dialogues in an explainable and controllable way. Instead of using 5416 Proceedings of the 57th Annual Meeting of the Association for Computational Linguist"
P19-1600,D10-1049,0,0.0349147,"xt belongs to the data-to-text generation (Reiter and Dale, 2000). Many previous work (Barzilay and Lapata, 2005, 2006; Liang et al., 2009) treated the task as a pipelined systems, which viewed content selection and surface realization as two separate tasks. Duboue and McKeown (2002) proposed a clustering approach in the biography domain by scoring the semantic relevance of the text and paired knowledge base. In a similar vein, Barzilay and Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al."
P19-1600,H05-1042,0,0.206311,", although our model is able to cover much more comprehensive information than the previous models (Table 2 and 3). Some implicitly expressed (like if a person is retired or not) or rarely covered (like ‘spouse’ or ‘high school’) attributes in the source tables might still be ignored in the descriptions generated by our model. Furthermore, those pieces of information which need some form of inference across Related Work Data-to-text a language generation task to generate text for structured data. Table-to-text belongs to the data-to-text generation (Reiter and Dale, 2000). Many previous work (Barzilay and Lapata, 2005, 2006; Liang et al., 2009) treated the task as a pipelined systems, which viewed content selection and surface realization as two separate tasks. Duboue and McKeown (2002) proposed a clustering approach in the biography domain by scoring the semantic relevance of the text and paired knowledge base. In a similar vein, Barzilay and Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning t"
P19-1600,N06-1046,0,0.14018,"Missing"
P19-1600,E06-1032,0,0.0188045,"er the key points in the infoboxes, we also use information richness (Eq 5) as one of our automatic evaluation. ‘Hit at least 1 word’ for an attribute means that a biography has at least one overlapping word with the words (or their synonyms) in that attribute, which are lemmatized and filtered by a stop-words list like the way we get WB-filter in Sec 4.1. ‘HIT-1 coverage’ for an attribute is the ratio of the instances involving that attribute whose biographies ‘Hit at least 1 word’ in that attribute. Human Evaluation: Since automatic evaluations like BLEU may not be reliable for NLG systems (Callison-Burch et al., 2006; Reiter and Belz, 2009; Reiter, 2018). We use human evaluation which involves the generation fluency, coverage (how much given information in the infobox is mentioned in the related biography) and correctness (how much false or irrelevant information is mentioned in the biography). We firstly sampled 300 generated biographies from the generators for human evaluation. After that, we hired 3 thirdparty crowd-workers who are equipped with sufficient background knowledge to rank the given biographies. We present the generated descriptions to the annotators in a randomized order and ask them to be"
P19-1600,D18-2003,0,0.0145712,"ootball records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work some"
P19-1600,W02-2112,0,0.0655139,"vered (like ‘spouse’ or ‘high school’) attributes in the source tables might still be ignored in the descriptions generated by our model. Furthermore, those pieces of information which need some form of inference across Related Work Data-to-text a language generation task to generate text for structured data. Table-to-text belongs to the data-to-text generation (Reiter and Dale, 2000). Many previous work (Barzilay and Lapata, 2005, 2006; Liang et al., 2009) treated the task as a pipelined systems, which viewed content selection and surface realization as two separate tasks. Duboue and McKeown (2002) proposed a clustering approach in the biography domain by scoring the semantic relevance of the text and paired knowledge base. In a similar vein, Barzilay and Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Onto"
P19-1600,W13-0108,0,0.032971,"and surface realization as two separate tasks. Duboue and McKeown (2002) proposed a clustering approach in the biography domain by scoring the semantic relevance of the text and paired knowledge base. In a similar vein, Barzilay and Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey"
P19-1600,D18-1426,0,0.0208961,"led the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descripti"
P19-1600,E17-1060,0,0.201101,"(2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al. (2016); Tu et al. (2016); Liu et al. (2017a); Gong et al. (2018) in the sense that they emphasis easily ignored (usually less frequent) features or bits of information in the training procedure by smoothing or regularization. The greatest difference between our work and theirs is"
P19-1600,P13-2121,0,0.0111481,"r datasets (with or without force-attention module), respectively. We replace UNK tokens with the most relevant token in the source table according to the attention matrix (Jean et al., 2015). 4.4 Table 2: BLEU and ROUGE scores on the WIKIBIO and WB-filter datasets. The baselines with * are based on our implementation while the others are reported by their authors. Models with † are trained using the RL criterion specified in Sec 3.2.2 while the remaining models are trained using the maximum likelihood estimate (MLE). Baselines KN & Template KN: A template-based KneserNey (KN) language model (Heafield et al., 2013) The extracted template for Table 1 is “name 1 name 2 (born birthdate 1 · · · ”. During inference, the decoder is constrained to emit words from the vocabulary or the special tokens in the tables. Table NLM: Lebret et al. (2016) proposed a neural language model Table NLM taking the attribute information into consideration. Order-planning: Sha et al. (2018) proposed a link matrix to model the order for the attributevalue tuples while generating biographies. Struct-aware: Liu et al. (2018) proposed a structure-aware model using a modified LSTM unit and a specific attention mechanism to incorpora"
P19-1600,P82-1020,0,0.797622,"Missing"
P19-1600,N18-2098,0,0.0182192,"e verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al. (2016); Tu et al."
P19-1600,P15-1001,0,0.0141721,"a, 2014), respectively. We use Xavier initialization (Glorot and Bengio, 2010) for all the parameters in our model. The global constraint of force-attention (Eq 4) is adapted after 4 and 1.5 epochs of training to avoid hurting the primary loss for the WIKIBIO and WB-filter datasets, respectively. Before the richness-oriented reinforced training, the neural generator is pre-trained 8 and 4 epochs for the WIKIBIO and WB-filter datasets (with or without force-attention module), respectively. We replace UNK tokens with the most relevant token in the source table according to the attention matrix (Jean et al., 2015). 4.4 Table 2: BLEU and ROUGE scores on the WIKIBIO and WB-filter datasets. The baselines with * are based on our implementation while the others are reported by their authors. Models with † are trained using the RL criterion specified in Sec 3.2.2 while the remaining models are trained using the maximum likelihood estimate (MLE). Baselines KN & Template KN: A template-based KneserNey (KN) language model (Heafield et al., 2013) The extracted template for Table 1 is “name 1 name 2 (born birthdate 1 · · · ”. During inference, the decoder is constrained to emit words from the vocabulary or the sp"
P19-1600,P18-1154,0,0.0122378,"its of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al"
P19-1600,N18-2101,0,0.101198,"nd Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate"
P19-1600,D16-1032,0,0.0320047,"et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al. (2016); Tu et al. (2016); Liu et al. (2017a); Gong et al. (2018) in the sense that they emphasis easily ignored (usually less frequent) features or bits of information in the training procedure by smoothing or regularization. The greatest difference between our work and theirs is that our method is tailored for covering the key information embedded in the attributes (entries) of the key-value tables rather than single words or labels. Although the deficient score of Tu et al. (2016) in Table 2 has demonstrated that word-level coverage oriented methods may not still be suitable to the structured tabl"
P19-1600,D16-1128,0,0.0981335,"Missing"
P19-1600,C18-1089,0,0.0165885,"ey Attri.: A soccer player who plays as forward Groundless info: A Utah forward in the national team Less Informative: An American forward Table 1: An example for comprehensive generation. Suppose we only have two attribute-value tuples, the underlined content is groundless information not mentioned in source tables. Introduction Generating descriptions for the factual attributevalue tables has attracted widely interests among NLP researchers especially in a neural end-to-end fashion (e.g. Lebret et al. (2016); Liu et al. (2018); Sha et al. (2018); Bao et al. (2018); Puduppully et al. (2018); Li and Wan (2018); Nema et al. (2018)) as shown in Fig 1a. For broader potential applications in this field, we also simulate useroriented generation, whose goal is to provide comprehensive generation for the selected attributes according to particular user interests like Fig 1b. However, we find that previous models might miss key information and generate less informative and groundless content in its generated descriptions towards source tables. For example, in Table 1, the ‘missing key attribute’ case doesn’t mention where the player comes from (birthplace) while the ‘less informative’ one chooses American"
P19-1600,P09-1011,0,0.138946,"over much more comprehensive information than the previous models (Table 2 and 3). Some implicitly expressed (like if a person is retired or not) or rarely covered (like ‘spouse’ or ‘high school’) attributes in the source tables might still be ignored in the descriptions generated by our model. Furthermore, those pieces of information which need some form of inference across Related Work Data-to-text a language generation task to generate text for structured data. Table-to-text belongs to the data-to-text generation (Reiter and Dale, 2000). Many previous work (Barzilay and Lapata, 2005, 2006; Liang et al., 2009) treated the task as a pipelined systems, which viewed content selection and surface realization as two separate tasks. Duboue and McKeown (2002) proposed a clustering approach in the biography domain by scoring the semantic relevance of the text and paired knowledge base. In a similar vein, Barzilay and Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data a"
P19-1600,N19-1263,0,0.0153354,"al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al. (2016); Tu et al. (2016); Liu et al. (2017a); Gong et al. (20"
P19-1600,D17-1189,1,0.842031,"et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al. (2016); Tu et al. (2016); Liu et al"
P19-1600,W16-6624,0,0.0268522,"the text and paired knowledge base. In a similar vein, Barzilay and Lapata (2005) modeled the dependencies between the American football records and identified the bits of information to be verbalized. Liang et al. (2009); Angeli et al. (2010) extended the work of Barzilay and Lapata (2005) to soccer and weather domains by learning the alignment between data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repeti"
P19-1600,N16-1086,0,0.0618734,"ween data and text using hidden variable models. Androutsopoulos et al. (2013) and Duma and Klein (2013) focused on generating descriptive language for Ontologies and RDF triples. Most recent work utilize neural networks on data-to-text generation (Mahapatra et al., 2016; Wiseman et al., 2017; Laha et al., 2018; Kaffee et al., 2018; Freitag and Roy, 2018; Qader et al., 2018; Dou et al., 2018; Yeh et al., 2018; Jhamtani et al., 2018; Jain et al., 2018; Liu et al., 2017b, 2019; Peng et al., 2019; 5992 Duˇsek et al., 2019). Some closely relevant work also focused on the table-to-text generation. Mei et al. (2016) proposed an encoder-aligner-decoder framework for generating weather broadcast. Hachey et al. (2017) used a table-text and text-table autoencoder framework for table-to-text generation. Nema et al. (2018) proposed gated orthogonalization to avoid repetitions. Wiseman et al. (2018) used neural semi-HMM to generate template-like descriptions for structured data. Our work somewhat shares similar goals as Kiddon et al. (2016); Tu et al. (2016); Liu et al. (2017a); Gong et al. (2018) in the sense that they emphasis easily ignored (usually less frequent) features or bits of information in the train"
P19-1600,N18-1139,0,0.545422,"player who plays as forward Groundless info: A Utah forward in the national team Less Informative: An American forward Table 1: An example for comprehensive generation. Suppose we only have two attribute-value tuples, the underlined content is groundless information not mentioned in source tables. Introduction Generating descriptions for the factual attributevalue tables has attracted widely interests among NLP researchers especially in a neural end-to-end fashion (e.g. Lebret et al. (2016); Liu et al. (2018); Sha et al. (2018); Bao et al. (2018); Puduppully et al. (2018); Li and Wan (2018); Nema et al. (2018)) as shown in Fig 1a. For broader potential applications in this field, we also simulate useroriented generation, whose goal is to provide comprehensive generation for the selected attributes according to particular user interests like Fig 1b. However, we find that previous models might miss key information and generate less informative and groundless content in its generated descriptions towards source tables. For example, in Table 1, the ‘missing key attribute’ case doesn’t mention where the player comes from (birthplace) while the ‘less informative’ one chooses American rather than Utah. Th"
P19-1600,P02-1040,0,0.105184,"Missing"
P19-1600,N18-1137,0,0.347035,"ayer) Comprehensive: A Utah soccer player who plays as forward Missing Key Attri.: A soccer player who plays as forward Groundless info: A Utah forward in the national team Less Informative: An American forward Table 1: An example for comprehensive generation. Suppose we only have two attribute-value tuples, the underlined content is groundless information not mentioned in source tables. Introduction Generating descriptions for the factual attributevalue tables has attracted widely interests among NLP researchers especially in a neural end-to-end fashion (e.g. Lebret et al. (2016); Liu et al. (2018); Sha et al. (2018); Bao et al. (2018); Puduppully et al. (2018); Li and Wan (2018); Nema et al. (2018)) as shown in Fig 1a. For broader potential applications in this field, we also simulate useroriented generation, whose goal is to provide comprehensive generation for the selected attributes according to particular user interests like Fig 1b. However, we find that previous models might miss key information and generate less informative and groundless content in its generated descriptions towards source tables. For example, in Table 1, the ‘missing key attribute’ case doesn’t mention where th"
P19-1600,W18-6532,0,0.0313192,"Missing"
P19-1600,J18-3002,0,0.0261587,"rmation richness (Eq 5) as one of our automatic evaluation. ‘Hit at least 1 word’ for an attribute means that a biography has at least one overlapping word with the words (or their synonyms) in that attribute, which are lemmatized and filtered by a stop-words list like the way we get WB-filter in Sec 4.1. ‘HIT-1 coverage’ for an attribute is the ratio of the instances involving that attribute whose biographies ‘Hit at least 1 word’ in that attribute. Human Evaluation: Since automatic evaluations like BLEU may not be reliable for NLG systems (Callison-Burch et al., 2006; Reiter and Belz, 2009; Reiter, 2018). We use human evaluation which involves the generation fluency, coverage (how much given information in the infobox is mentioned in the related biography) and correctness (how much false or irrelevant information is mentioned in the biography). We firstly sampled 300 generated biographies from the generators for human evaluation. After that, we hired 3 thirdparty crowd-workers who are equipped with sufficient background knowledge to rank the given biographies. We present the generated descriptions to the annotators in a randomized order and ask them to be objective and not to guess which syst"
P19-1600,J09-4008,0,0.0604034,"boxes, we also use information richness (Eq 5) as one of our automatic evaluation. ‘Hit at least 1 word’ for an attribute means that a biography has at least one overlapping word with the words (or their synonyms) in that attribute, which are lemmatized and filtered by a stop-words list like the way we get WB-filter in Sec 4.1. ‘HIT-1 coverage’ for an attribute is the ratio of the instances involving that attribute whose biographies ‘Hit at least 1 word’ in that attribute. Human Evaluation: Since automatic evaluations like BLEU may not be reliable for NLG systems (Callison-Burch et al., 2006; Reiter and Belz, 2009; Reiter, 2018). We use human evaluation which involves the generation fluency, coverage (how much given information in the infobox is mentioned in the related biography) and correctness (how much false or irrelevant information is mentioned in the biography). We firstly sampled 300 generated biographies from the generators for human evaluation. After that, we hired 3 thirdparty crowd-workers who are equipped with sufficient background knowledge to rank the given biographies. We present the generated descriptions to the annotators in a randomized order and ask them to be objective and not to g"
P19-1600,P16-1008,0,0.275522,"nted reinforcement learning to produce accurate, informative and loyal descriptions. 3.1 Force-Attention Module For ‘missing key attributes’ problem (Table 1), we find that the generator usually focuses on particular attributes while the other attributes have relatively low attention values in the entire decoding procedure. So force attention method is proposed to guide the decoder to pay more attention to the previous uncovered attributes with low attention values to avoid potential key attribute missing. Note that FA method focuses on attributelevel coverage rather than word-level coverage (Tu et al., 2016) as our goal is to reduce the ‘missing key attributes’ phenomenons instead of building rigid word-by-word alignment between tables and descriptions. Stepwise Forcing Attention: We define attributeP level attention βtak = avg( xi ∈ak αti ) at the t-th step for attribute ak as the average value of the word-level attention values for the words in that attribute. The word-level coverage is defined as the sum of attention vector before the t-th step i θti = θt−1 + αti (Tu et al., 2016). In the similar way, we define the attribute-level coverage ak γtak = γt−k + βtak as the overall attention for att"
P19-1600,D17-1239,0,0.0943602,"Missing"
P19-1600,D18-1356,0,0.0863405,"Missing"
S17-2045,P02-1034,0,0.0962705,"of representations of the two pieces of text is used as a feature. Longest common subsequence: we measure the lexical similarity of each text pair with the term-level longest common subsequence (LCS) (Allison and Dix, 1986). The length of LCS is normalized by dividing the maximum length of the two pieces of text. Word overlap: we calculate the normalized count of common ngrams (n=1,2,3) and nouns. Tree kernels: tree kernels are similarity functions used to measure the syntactic similarity of a text pair. We compute the subtree kernel (ST) (Schlkopf et al., 2003), the subset tree kernel (SST) (Collins and Duffy, 2002), and the partial tree kernel (PTK) (Moschitti, 2006) on the parse trees of a text pair. Translation probability: we learn word-toword translation probabilities using GIZA++ 1 with the unannotated Qatar Living data. In training, we regard questions as source language and their answers as target language. Following (Jeon et al., 2005), we use translation probability p(qusetion A|question B) and p(comment|question) as features for a questionii = σ(W (i) ex,i + U (i) hx,i−1 + b(i) ) fi = σ(W (f ) ex,i + U (f ) hx,i−1 + b(f ) ) oi = σ(W (o) ex,i + U (o) hx,i−1 + b(o) ) ui = tanh(W (u) ex,i + U (u)"
S17-2045,P03-1054,0,0.0058722,"1 , ..., ex,i , ..., ex,I ] and Sy = [ey,1 , ..., ey,i , ..., ey,J ] respectively, where ex,i , ey,i are the embeddings of the i-th words of Sx and Sy respectively. Then Sx and Sy are encoded in hidden sequences by a bi-LSTM which consists of a forward LSTM and a backward LSTM. The forward LSTM reads Sx in its order (i.e., from wx,1 to wx,I ) and transforms it to a forward hidden se→ − → − quence { h x,i }Ii=1 . ∀i ∈ {1, . . . , I}, h x,i is defined by: Preprocessing We exploit NLTK toolkit (Loper and Bird, 2002) to conduct stemming, tokenization, and POS tagging. We use Stanford PCFG parser (Klein and Manning, 2003) to get the parse tree of each sentence. 2.2 Neural Matching Features Traditional NLP Features The following features are designed based on words and syntactic analysis. Tf-idf cosine: each piece of text is converted to a one hot representation weighted by tf-idf values, where tf is the term frequency in the text, and idf is calculated using the unannotated Qatar corpora (Nakov et al., 2017). The cosine of representations of the two pieces of text is used as a feature. Longest common subsequence: we measure the lexical similarity of each text pair with the term-level longest common subsequence"
S17-2045,W02-0109,0,0.132576,", given a text pair (Sx , Sy ), the model looks up an embedding table to convert Sx and Sy to Sx = [ex,1 , ..., ex,i , ..., ex,I ] and Sy = [ey,1 , ..., ey,i , ..., ey,J ] respectively, where ex,i , ey,i are the embeddings of the i-th words of Sx and Sy respectively. Then Sx and Sy are encoded in hidden sequences by a bi-LSTM which consists of a forward LSTM and a backward LSTM. The forward LSTM reads Sx in its order (i.e., from wx,1 to wx,I ) and transforms it to a forward hidden se→ − → − quence { h x,i }Ii=1 . ∀i ∈ {1, . . . , I}, h x,i is defined by: Preprocessing We exploit NLTK toolkit (Loper and Bird, 2002) to conduct stemming, tokenization, and POS tagging. We use Stanford PCFG parser (Klein and Manning, 2003) to get the parse tree of each sentence. 2.2 Neural Matching Features Traditional NLP Features The following features are designed based on words and syntactic analysis. Tf-idf cosine: each piece of text is converted to a one hot representation weighted by tf-idf values, where tf is the term frequency in the text, and idf is calculated using the unannotated Qatar corpora (Nakov et al., 2017). The cosine of representations of the two pieces of text is used as a feature. Longest common subse"
S17-2045,S17-2003,0,0.0948239,"Missing"
