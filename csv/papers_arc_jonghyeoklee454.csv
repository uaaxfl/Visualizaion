2021.nuse-1.6,Transformer-based Screenplay Summarization Using Augmented Learning Representation with Dialogue Information,2021,-1,-1,6,0,2591,myungji lee,Proceedings of the Third Workshop on Narrative Understanding,0,"Screenplay summarization is the task of extracting informative scenes from a screenplay. The screenplay contains turning point (TP) events that change the story direction and thus define the story structure decisively. Accordingly, this task can be defined as the TP identification task. We suggest using dialogue information, one attribute of screenplays, motivated by previous work that discovered that TPs have a relation with dialogues appearing in screenplays. To teach a model this characteristic, we add a dialogue feature to the input embedding. Moreover, in an attempt to improve the model architecture of previous studies, we replace LSTM with Transformer. We observed that the model can better identify TPs in a screenplay by using dialogue information and that a model adopting Transformer outperforms LSTM-based models."
2021.iwslt-1.30,Tag Assisted Neural Machine Translation of Film Subtitles,2021,-1,-1,4,0,5799,aren siekmeier,Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021),0,"We implemented a neural machine translation system that uses automatic sequence tagging to improve the quality of translation. Instead of operating on unannotated sentence pairs, our system uses pre-trained tagging systems to add linguistic features to source and target sentences. Our proposed neural architecture learns a combined embedding of tokens and tags in the encoder, and simultaneous token and tag prediction in the decoder. Compared to a baseline with unannotated training, this architecture increased the BLEU score of German to English film subtitle translation outputs by 1.61 points using named entity tags; however, the BLEU score decreased by 0.38 points using part-of-speech tags. This demonstrates that certain token-level tag outputs from off-the-shelf tagging systems can improve the output of neural translation systems using our combined embedding and simultaneous decoding extensions."
2021.eacl-main.322,Adaptation of Back-translation to Automatic Post-Editing for Synthetic Data Generation,2021,-1,-1,4,1,2594,wonkee lee,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Automatic Post-Editing (APE) aims to correct errors in the output of a given machine translation (MT) system. Although data-driven approaches have become prevalent also in the APE task as in many other NLP tasks, there has been a lack of qualified training data due to the high cost of manual construction. eSCAPE, a synthetic APE corpus, has been widely used to alleviate the data scarcity, but it might not address genuine APE corpora{'}s characteristic that the post-edited sentence should be a minimally edited revision of the given MT output. Therefore, we propose two new methods of synthesizing additional MT outputs by adapting back-translation to the APE task, obtaining robust enlargements of the existing synthetic APE training dataset. Experimental results on the WMT English-German APE benchmarks demonstrate that our enlarged datasets are effective in improving APE performance."
2020.wmt-1.82,{POSTECH}-{ETRI}{'}s Submission to the {WMT}2020 {APE} Shared Task: Automatic Post-Editing with Cross-lingual Language Model,2020,-1,-1,6,0,13914,jihyung lee,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes POSTECH-ETRI{'}s submission to WMT2020 for the shared task on automatic post-editing (APE) for 2 language pairs: English-German (En-De) and English-Chinese (En-Zh). We propose APE systems based on a cross-lingual language model, which jointly adopts translation language modeling (TLM) and masked language modeling (MLM) training objectives in the pre-training stage; the APE models then utilize jointly learned language representations between the source language and the target language. In addition, we created 19 million new sythetic triplets as additional training data for our final ensemble model. According to experimental results on the WMT2020 APE development data set, our models showed an improvement over the baseline by TER of -3.58 and a BLEU score of +5.3 for the En-De subtask; and TER of -5.29 and a BLEU score of +7.32 for the En-Zh subtask."
2020.wmt-1.83,Noising Scheme for Data Augmentation in Automatic Post-Editing,2020,-1,-1,5,1,2594,wonkee lee,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes POSTECH{'}s submission to WMT20 for the shared task on Automatic Post-Editing (APE). Our focus is on increasing the quantity of available APE data to overcome the shortage of human-crafted training data. In our experiment, we implemented a noising module that simulates four types of post-editing errors, and we introduced this module into a Transformer-based multi-source APE model. Our noising module implants errors into texts on the target side of parallel corpora during the training phase to make synthetic MT outputs, increasing the entire number of training samples. We also generated additional training data using the parallel corpora and NMT model that were released for the Quality Estimation task, and we used these data to train our APE model. Experimental results on the WMT20 English-German APE data set show improvements over the baseline in terms of both the TER and BLEU scores: our primary submission achieved an improvement of -3.15 TER and +4.01 BLEU, and our contrastive submission achieved an improvement of -3.34 TER and +4.30 BLEU."
2020.ngt-1.16,{POSTECH} Submission on {D}uolingo Shared Task,2020,-1,-1,3,0,16473,junsu park,Proceedings of the Fourth Workshop on Neural Generation and Translation,0,"In this paper, we propose a transfer learning based simultaneous translation model by extending BART. We pre-trained BART with Korean Wikipedia and a Korean news dataset, and fine-tuned with an additional web-crawled parallel corpus and the 2020 Duolingo official training dataset. In our experiments on the 2020 Duolingo test dataset, our submission achieves 0.312 in weighted macro F1 score, and ranks second among the submitted En-Ko systems."
W19-5412,Transformer-based Automatic Post-Editing Model with Joint Encoder and Multi-source Attention of Decoder,2019,0,0,3,1,2594,wonkee lee,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"This paper describes POSTECH{'}s submission to the WMT 2019 shared task on Automatic Post-Editing (APE). In this paper, we propose a new multi-source APE model by extending Transformer. The main contributions of our study are that we 1) reconstruct the encoder to generate a joint representation of translation (mt) and its src context, in addition to the conventional src encoding and 2) suggest two types of multi-source attention layers to compute attention between two outputs of the encoder and the decoder state in the decoder. Furthermore, we train our model by applying various teacher-forcing ratios to alleviate exposure bias. Finally, we adopt the ensemble technique across variations of our model. Experiments on the WMT19 English-German APE data set show improvements in terms of both TER and BLEU scores over the baseline. Our primary submission achieves -0.73 in TER and +1.49 in BLEU compare to the baseline."
N19-1372,Decay-Function-Free Time-Aware Attention to Context and Speaker Indicator for Spoken Language Understanding,2019,0,0,2,0,15732,jonggu kim,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"To capture salient contextual information for spoken language understanding (SLU) of a dialogue, we propose time-aware models that automatically learn the latent time-decay function of the history without a manual time-decay function. We also propose a method to identify and label the current speaker to improve the SLU accuracy. In experiments on the benchmark dataset used in Dialog State Tracking Challenge 4, the proposed models achieved significantly higher F1 scores than the state-of-the-art contextual models. Finally, we analyze the effectiveness of the introduced models in detail. The analysis demonstrates that the proposed methods were effective to improve SLU accuracy individually."
W18-6470,Multi-encoder Transformer Network for Automatic Post-Editing,2018,0,0,2,1,2593,jaehun shin,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper describes the POSTECH{'}s submission to the WMT 2018 shared task on Automatic Post-Editing (APE). We propose a new neural end-to-end post-editing model based on the transformer network. We modified the encoder-decoder attention to reflect the relation between the machine translation output, the source and the post-edited translation in APE problem. Experiments on WMT17 English-German APE data set show an improvement in both TER and BLEU score over the best result of WMT17 APE shared task. Our primary submission achieves -4.52 TER and +6.81 BLEU score on PBSMT task and -0.13 TER and +0.40 BLEU score for NMT task compare to the baseline."
W17-4763,Predictor-Estimator using Multilevel Task Learning with Stack Propagation for Neural Quality Estimation,2017,6,20,2,1,23838,hyun kim,Proceedings of the Second Conference on Machine Translation,0,None
W16-2384,Recurrent Neural Network based Translation Quality Estimation,2016,33,9,2,1,23838,hyun kim,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes our submission to the shared task on word/phrase level Quality Estimation (QE) in the First Conference on Statistical Machine Translation (WMT16). The objective of the shared task was to predict if the given word/phrase is a correct/incorrect (OK/BAD) translation in the given sentence. In this paper, we propose a novel approach for word level Quality Estimation using Recurrent Neural Network Language Model (RNN-LM) architecture. RNN-LMs have been found very effective in different Natural Language Processing (NLP) applications. RNN-LM is mainly used for vector space language modeling for different NLP problems. For this task, we modify the architecture of RNNLM. The modified system predicts a label (OK/BAD) in the slot rather than predicting the word. The input to the system is a word sequence, similar to the standard RNN-LM. The approach is language independent and requires only the translated text for QE. To estimate the phrase level quality, we use the output of the word level QE system."
N16-1059,A Recurrent Neural Networks Approach for Estimating the Quality of Machine Translation Output,2016,8,11,2,1,23838,hyun kim,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W14-3327,Postech{'}s System Description for Medical Text Translation Task,2014,6,3,4,0,38570,jianri li,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,This short paper presents a system description for intrinsic evaluation of the WMT 14xe2x80x99s medical text translation task. Our systems consist of phrase-based statistical machine translation system and query translation system between German-English language pairs. Our work focuses on the query translation task and we achieved the highest BLEU score among the all submitted systems for the English-German intrinsic query translation evaluation.
2013.iwslt-evaluation.9,A discriminative reordering parser for {IWSLT} 2013,2013,18,1,2,1,36252,hwidong na,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We participated in the IWSLT 2013 Evaluation Campaign for the MT track for two official directions: GermanâEnglish. Our system consisted of a reordering module and a statistical machine translation (SMT) module under a pre-ordering SMT framework. We trained the reordering module using three scalable methods in order to utilize training instances as many as possible. The translation quality of our primary submissions were comparable to that of a hierarchical phrasebased SMT, which usually requires a longer time to decode."
2012.iwslt-evaluation.18,Forest-to-string translation using binarized dependency forest for {IWSLT} 2012 {OLYMPICS} task,2012,28,1,2,1,36252,hwidong na,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We participated in the OLYMPICS task in IWSLT 2012 and submitted two formal runs using a forest-to-string translation system. Our primary run achieved better translation quality than our contrastive run, but worse than a phrase-based and a hierarchical system using Moses."
W11-2926,Beyond Chart Parsing: An Analytic Comparison of Dependency Chart Parsing Algorithms,2011,15,0,3,1,44140,meixun jin,Proceedings of the 12th International Conference on Parsing Technologies,0,"In this paper, we give a summary of various dependency chart parsing algorithms in terms of the use of parsing histories for a new dependency arc decision. Some parsing histories are closely related to the target dependency arc, and it is necessary for the parsing algorithm to take them into consideration. Each dependency treebank may have some unique characteristics, and it requires for the parser to model them by certain parsing histories. We show in experiments that proper selection of the parsing algorithm which reflect the dependency annotation of the coordinate structures improves the overall performance."
W11-1005,Multi-Word Unit Dependency Forest-based Translation Rule Extraction,2011,15,1,2,1,36252,hwidong na,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Translation requires non-isomorphic transformation from the source to the target. However, non-isomorphism can be reduced by learning multi-word units (MWUs). We present a novel way of representating sentence structure based on MWUs, which are not necessarily continuous word sequences. Our proposed method builds a simpler structure of MWUs than words using words as vertices of a dependency structure. Unlike previous studies, we collect many alternative structures in a packed forest. As an application of our proposed method, we extract translation rules in form of a source MWU-forest to the target string, and verify the rule coverage empirically. As a consequence, we improve the rule coverage compare to a previous work, while retaining the linear asymptotic complexity."
P10-1061,Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems,2010,17,19,3,1,23620,jungi kim,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"Subjectivity analysis is a rapidly growing field of study. Along with its applications to various NLP tasks, much work have put efforts into multilingual subjectivity learning from existing resources. Multilingual subjectivity analysis requires language-independent criteria for comparable outcomes across languages. This paper proposes to measure the multilanguage-comparability of subjectivity analysis tools, and provides meaningful comparisons of multilingual subjectivity analysis from various points of view."
2010.iwslt-evaluation.20,The {POSTECH}{'}s statistical machine translation system for the {IWSLT} 2010,2010,0,0,2,1,36252,hwidong na,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2010.amta-srw.2,A Synchronous Context Free Grammar using Dependency Sequence for Syntax-based Statistical Machine Translation,2010,-1,-1,4,1,36252,hwidong na,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Student Research Workshop,0,"We introduce a novel translation rule that captures discontinuous, partial constituent, and non-projective phrases from source language. Using the traversal order sequences of the dependency tree, our proposed method 1) extracts the synchronous rules in linear time and 2) combines them efficiently using the CYK chart parsing algorithm. We analytically show the effectiveness of this translation rule in translating relatively free order sentences, and empirically investigate the coverage of our proposed method."
2010.amta-papers.26,Transferring Syntactic Relations of Subject-Verb-Object Pattern in {C}hinese-to-{K}orean {SMT},2010,14,1,3,1,45695,jinji li,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Since most Korean postpositions signal grammatical functions such as syntactic relations, generation of incorrect Korean post-positions results in producing ungrammatical outputs in machine translations targeting Korean. Chinese and Korean belong to morphosyntactically divergent language pairs, and usually Korean postpositions do not have their counterparts in Chinese. In this paper, we propose a preprocessing method for a statistical MT system that generates more adequate Korean postpositions. We transfer syntactic relations of subject-verb-object patterns in Chinese sentences and enrich them with transferred syntactic relations in order to reduce the morpho-syntactic differences. The effectiveness of our proposed method is measured with lexical units of various granularities. Human evaluation also suggest improvements over previous methods, which are consistent with the result of the automatic evaluation."
2010.amta-papers.30,{C}hinese Syntactic Reordering through Contrastive Analysis of Predicate-predicate Patterns in {C}hinese-to-{K}orean {SMT},2010,15,0,3,1,45695,jinji li,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We propose a Chinese dependency tree reordering method for Chinese-to-Korean SMT systems through analyzing systematic differences between the Chinese and Korean languages. Translating predicate-predicate patterns in Chinese into Korean raises various issues such as long-distance reordering. This paper concentrates on syntactic reordering of predicate-predicate patterns in Chinese dependency trees through contrastively analyzing construction types in Chinese and their corresponding translations in Korean. We explore useful linguistic knowledge that assists effective syntactic reordering of Chinese dependency trees; we design two experiments with different kinds of linguistic knowledge combined with the phrase and hierarchical phrase-based SMT systems, and assess the effectiveness of our proposed methods. The experiments achieved significant improvements by resolving the long-distance reordering problem."
Y09-1028,Method of Extracting Is-A and Part-Of Relations Using Pattern Pairs in Mass Corpus,2009,9,1,3,0,38571,sejong kim,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"This paper proposes a method that extracts term pairs satisfying is-a relations or part-of relations from a mass corpus using pairs of patterns sharing a term. We extracted reliable single patterns and pattern pairs using some term pairs that satisfy the target relation, and extracted reliable term pairs using these patterns. The extracted term pairs were used to extract new single patterns and pattern pairs, and we repeated these steps several times. The proposed method achieved 71.5% accuracy in detecting is-a relations and 88% accuracy in detecting part-of relations, and extracted 144 new is-a relations and 85 new part-of relations which could not be extracted using single patterns. These results are useful in constructing an ontology and a thesaurus because these language knowledge bases consist mainly of is-a relations and part-of relations."
W09-0433,{C}hinese Syntactic Reordering for Adequate Generation of {K}orean Verbal Phrases in {C}hinese-to-{K}orean {SMT},2009,16,13,4,1,45695,jinji li,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"Chinese and Korean belong to different language families in terms of word-order and morphological typology. Chinese is an SVO and morphologically poor language while Korean is an SOV and morphologically rich one. In Chinese-to-Korean SMT systems, systematic differences between the verbal systems of the two languages make the generation of Korean verbal phrases difficult. To resolve the difficulties, we address two issues in this paper. The first issue is that the verb position is different from the viewpoint of word-order typology. The second is the difficulty of complex morphology generation of Korean verbs from the viewpoint of morphological typology. We propose a Chinese syntactic reordering that is better at generating Korean verbal phrases in Chinese-to-Korean SMT. Specifically, we consider reordering rules targeting Chinese verb phrases (VPs), preposition phrases (PPs), and modality-bearing words that are closely related to Korean verbal phrases. We verify our system with two corpora of different domains. Our proposed approach significantly improves the performance of our system over a baseline phrased-based SMT system. The relative improvements in the two corpora are 9.32% and 5.43%, respectively."
P09-1029,Discovering the Discriminative Views: Measuring Term Weights for Sentiment Analysis,2009,35,35,3,1,23620,jungi kim,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"This paper describes an approach to utilizing term weights for sentiment analysis tasks and shows how various term weighting schemes improve the performance of sentiment analysis systems. Previously, sentiment analysis was mostly studied under data-driven and lexicon-based frameworks. Such work generally exploits textual features for fact-based analysis tasks or lexical indicators from a sentiment lexicon. We propose to model term weighting into a sentiment analysis system utilizing collection statistics, contextual and topic-related characteristics as well as opinion-related properties. Experiments carried out on various datasets show that our approach effectively improves previous methods."
2009.mtsummit-posters.13,Improving Fluency by Reordering Target Constituents using {MST} Parser in {E}nglish-to-{J}apanese Phrase-based {SMT},2009,16,1,4,1,36252,hwidong na,Proceedings of Machine Translation Summit XII: Posters,0,None
li-etal-2008-annotation,Annotation Guidelines for {C}hinese-{K}orean Word Alignment,2008,11,5,3,1,45695,jinji li,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"For a language pair such as Chinese and Korean that belong to entirely different language families in terms of typology and genealogy, finding the correspondences is quite obscure in word alignment. We present annotation guidelines for Chinese-Korean word alignment through contrastive analysis of morpho-syntactic encodings. We discuss the differences in verbal systems that cause most of linking obscurities in annotation process. Systematic comparison of verbal systems is conducted by analyzing morpho-syntactic encodings. The viewpoint of grammatical category allows us to define consistent and systematic instructions for linguistically distant languages such as Chinese and Korean. The scope of our guidelines is limited to the alignment between Chinese and Korean, but the instruction methods exemplified in this paper are also applicable in developing systematic and comprehensible alignment guidelines for other languages having such different linguistic phenomena."
I08-4002,Automatic Extraction of {E}nglish-{C}hinese Transliteration Pairs using Dynamic Window and Tokenizer,2008,0,5,4,0,48563,chengguo jin,Proceedings of the Sixth {SIGHAN} Workshop on {C}hinese Language Processing,0,None
I08-2085,Search Result Clustering Using Label Language Model,2008,12,16,3,0,46646,yeha lee,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"Search results clustering helps users to browse the search results and locate what they are looking for. In the search result clustering, the label selection which annotates a meaningful phrase for each cluster becomes the most fundamental issue. In this paper, we present a new method of using the language modeling approach over Dmoz for label selection, namely label language model. Experimental results show that our method is helpful to obtain meaningful clustering labels of search results."
I05-2044,Two-Phase Shift-Reduce Deterministic Dependency Parser of {C}hinese,2005,18,8,3,1,44140,meixun jin,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"In the Chinese language, a verb may have its dependents on its left, right or on both sides. The ambiguity resolution of right-side dependencies is essential for dependency parsing of sentences with two or more verbs. Previous works on shiftreduce dependency parsers may not guarantee the connectivity of a dependency tree due to their weakness at resolving the right-side dependencies. This paper proposes a two-phase shift-reduce dependency parser based on SVM learning. The leftside dependents and right-side nominal dependents are detected in Phase I, and rightside verbal dependents are decided in Phase II. In experimental evaluation, our proposed method outperforms previous shift-reduce dependency parsers for the Chine language, showing improvement of dependency accuracy by 10.08%."
I05-1014,Chunking Using Conditional Random Fields in {K}orean Texts,2005,18,6,3,1,27509,yonghun lee,Second International Joint Conference on Natural Language Processing: Full Papers,0,"We present a method of chunking in Korean texts using conditional random fields (CRFs), a recently introduced probabilistic model for labeling and segmenting sequence of data. In agglutinative languages such as Korean and Japanese, a rule-based chunking method is predominantly used for its simplicity and efficiency. A hybrid of a rule-based and machine learning method was also proposed to handle exceptional cases of the rules. In this paper, we present how CRFs can be applied to the task of chunking in Korean texts. Experiments using the STEP 2000 dataset show that the proposed method significantly improves the performance as well as outperforms previous systems."
W04-1809,Term Extraction from {K}orean Corpora via {J}apanese,2004,2,4,3,0,37781,atsushi fujii,Proceedings of {C}ompu{T}erm 2004: 3rd International Workshop on Computational Terminology,0,"This paper proposes a method to extract foreign words, such as technical terms and proper nouns, from Korean corpora and produce a JapaneseKorean bilingual dictionary. Specific words have been imported into multiple countries simultaneously, if they are influential across cultures. The pronunciation of a source word is similar in different languages. Our method extracts words in Korean corpora that are phonetically similar to Katakana words, which can easily be identified in Japanese corpora. We also show the effectiveness of our method by means of experiments."
W04-1101,Segmentation of {C}hinese Long Sentences Using Commas,2004,16,21,4,1,44140,meixun jin,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,"The comma is the most common form of punctuation. As such, it may have the greatest effect on the syntactic analysis of a sentence. As an isolate language, Chinese sentences have fewer cues for parsing. The clues for segmentation of a long Chinese sentence are even fewer. However, the average frequency of comma usage in Chinese is higher than other languages. The comma plays an important role in long Chinese sentence segmentation. This paper proposes a method for classifying commas in Chinese sentences by their context, then segments a long sentence according to the classification results. Experimental results show that accuracy for the comma classification reaches 87.1 percent, and with our segmentation model, our parserxe2x80x99s dependency parsing accuracy improves by 9.6 percent."
U03-1004,An empirical study for generating zero pronoun in {K}orean based on Cost-based centering model,2003,-1,-1,2,0,52809,jieun roh,Proceedings of the Australasian Language Technology Workshop 2003,0,None
U03-1005,{S}-clause segmentation for efficient syntactic analysis using decision trees,2003,17,2,2,1,10897,miyoung kim,Proceedings of the Australasian Language Technology Workshop 2003,0,"In dependency parsing of long sentences with fewer subjects than predicates, it is difficult to recognize which predicate governs which subject. To handle such syntactic ambiguity between subjects and predicates, this paper proposes an xe2x80x9cSclausexe2x80x9d segmentation method, where an S(ubject)clause is defined as a group of words containing several predicates and their common subject. We propose an automatic S-clause segmentation method using decision trees. The S-clause information was shown to be very effective in analyzing long sentences, with an improved performance of 5 percent."
U03-1013,Resolving Sense Ambiguity of {K}orean Nouns Based on Concept Co-occurrence Information,2003,6,0,2,0,52812,youjin chung,Proceedings of the Australasian Language Technology Workshop 2003,0,"From the view point of the linguistic typology, Korean and Japanese have many grammatical similarities which enable it to easily construct a sense-tagged Korean corpus through an existing high-quality Japanese-to-Korean machine translation system. The sense-tagged corpus may serve as a knowledge source to extract useful clues for word sense disambiguation (WSD). This paper addresses a disambiguation model for Korean nouns, whose execution is based on the concept codes extracted from the sense-tagged corpus and the semantic similarity values over a thesaurus hierarchy. By the help of the automatically constructed sensetagged corpus, we overcome the knowledge acquisition bottleneck. Also, we show that the performance of word sense disambiguation can be improved by combining several base classifiers. In an experimental evaluation, the proposed model using a majority voting achieved an average precision of 77.75% with an improvement over the baseline by 15.00%, which is very promising for real world MT systems."
U03-1016,Conceptual Schema Approach to Natural Language Database Access,2003,13,0,3,0,52813,insu kang,Proceedings of the Australasian Language Technology Workshop 2003,0,"Natural language database interfaces require translation knowledge to convert user questions into formal database queries. Previously, translation knowledge acquisition heavily depends on human specialties such as NLP, DBMS and domain engineering, consequently undermining domain portability. This paper attempts to semi-automatically construct translation knowledge by introducing a physically-derived conceptual database schema, and by simplifying translation knowledge into two structures xe2x80x93 classreferring documents and classconstraining selection restrictions. Based on these two structures, this paper proposes a noun translation method that employs an information retrieval framework."
W02-1807,A Knowledge Based Approach to Identification of Serial Verb Construction in {C}hinese-to-{K}orean Machine Translation System,2002,4,2,4,1,47113,dongil kim,{COLING}-02: The First {SIGHAN} Workshop on {C}hinese Language Processing,0,"In Chinese language processing, the recognition and analysis for serial verb constructions (SVCs) is a fascinating research topic. Chinese language researchers each may have a different definition and interpretation of SVC since the structure of SVC makes Chinese unique to other languages and contains complex semantic and pragmatic information. This paper proposes a formal definition of SVC and a knowledge based approach for the recognition of SVCs, which is adopted in TOTAL-CK, a transfer-based MT system from Chinese to Korean. The recognition process is carried out in two stages: the analysis stage classifies SVCs into general categories, and the transfer stage performs further classification for Korean transfer. Some evaluation result for each stage was also given with statistics of each category of SVCs"
W02-1606,Word Sense Disambiguation in a {K}orean-to-{J}apanese {MT} System Using Neural Networks,2002,8,2,4,0,52812,youjin chung,{COLING}-02: Machine Translation in Asia,0,"This paper presents a method to resolve word sense ambiguity in a Korean-to-Japanese machine translation system using neural networks. The execution of our neural network model is based on the concept codes of a thesaurus. Most previous word sense disambiguation approaches based on neural networks have limitations due to their huge feature set size. By contrast, we reduce the number of features of the network to a practical size by using concept codes as features rather than the lexical words themselves."
J02-1004,Syllable-Pattern-Based Unknown-Morpheme Segmentation and Estimation for Hybrid Part-of-Speech Tagging of {K}orean,2002,13,31,3,0,30468,gary lee,Computational Linguistics,0,"Most errors in Korean morphological analysis and part-of-speech (POS) tagging are caused by unknown morphemes. This paper presents a syllable-pattern-based generalized unknown-morpheme-estimation method with POSTAG (POStech TAGger), which is a statistical and rule-based hybrid POS tagging system. This method of guessing unknown morphemes is based on a combination of a morpheme pattern dictionary that encodes general lexical patterns of Korean morphemes with a posteriori syllable trigram estimation. The syllable trigrams help to calculate lexical probabilities of the unknown morphemes and are utilized to search for the best tagging result. This method can guess the POS tags of unknown morphemes regardless of their numbers and/or positions in an eojeol (a Korean spacing unit similar to an English word), which is not possible with other systems for tagging Korean. In a series of experiments using three different domain corpora, the system achieved a 97% tagging accuracy even though 10% of the morphemes in the test corpora were unknown. It also achieved very high coverage and accuracy of estimation for all classes of unknown morphemes."
W01-1006,"Semi-Automatic Practical Ontology Construction by Using a Thesaurus, Computational Dictionaries, and Large Corpora",2001,13,17,2,1,52551,sinjae kang,Proceedings of the {ACL} 2001 Workshop on Human Language Technology and Knowledge Management,0,"This paper presents the semi-automatic construction method of a practical ontology by using various resources. In order to acquire a reasonably practical ontology in a limited time and with less manpower, we extend the Kadokawa thesaurus by inserting additional semantic relations into its hierarchy, which are classified as case relations and other semantic relations. The former can be obtained by converting valency information and case frames from previously-built computational dictionaries used in machine translation. The latter can be acquired from concept co-occurrence information, which is extracted automatically from large corpora. The ontology stores rich semantic constraints among 1,110 concepts, and enables a natural language processing system to resolve semantic ambiguities by making inferences with the concept network of the ontology. In our practical machine translation system, our ontology-based word sense disambiguation method achieved an 8.7% improvement over methods which do not use an ontology for Korean translation."
2001.mtsummit-papers.33,Ontology-based word sense disambiguation using semi-automatically constructed ontology,2001,10,1,2,1,52551,sinjae kang,Proceedings of Machine Translation Summit VIII,0,"This paper describes a method for disambiguating word senses by using semi-automatically constructed ontology. The ontology stores rich semantic constraints among 1,110 concepts, and enables a natural language processing system to resolve semantic ambiguities by making inferences with the concept network of the ontology. In order to acquire a reasonably practical ontology in limited time and with less manpower, we extend the existing Kadokawa thesaurus by inserting additional semantic relations into its hierarchy, which are classified as case relations and other semantic relations. The former can be obtained by converting valency information and case frames from previously-built electronic dictionaries used in machine translation. The latter can be acquired from concept co-occurrence information, which is extracted automatically from large corpora. In our practical machine translation system, our word sense disambiguation method achieved a 9.2{\%} improvement over methods which do not use an ontology for Korean translation."
C00-1079,Representation and Recognition Method for Multi-Word Translation Units in {K}orean-to-{J}apanese {MT} System,2000,2,6,2,0,53175,kyonghi moon,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Due to grammatical similarities, even a one-to-one mapping between Korean and Japanese words (or morphemes) can usually result in a high quality Korean-to-Japanese machine translation. However, multi-word translation units (MWTU) such as idioms, compound words, etc., need an n-to-m mapping, and their component words often do not appear adjacently, resulting in a discontinuous MWTU. During translation, the MWTU should be treated as one lexical item rather than a phrase. In this paper, we define the types of MWTUs and propose their representation and recognition method depending on their characteristics in Korean-to-Japanese MT system. In an experimental evaluation, the proposed method turned out to be very effective in handling MWTUs, showing an average recognition accuracy of 98.4% and a fast recognition time."
1999.mtsummit-1.57,The use of abstracted knowledge from an automatically sense-tagged corpus for lexical transfer ambiguity resolution,1999,-1,-1,3,1,50810,huifeng li,Proceedings of Machine Translation Summit VII,0,"This paper proposes a method for lexical transfer ambiguity resolution using corpus and conceptual information. Previous researches have restricted the use of linguistic knowledge to the lexical level. Since the extracted knowledge is stored in words themselves, these methods require a large amount of space with a low recall rate. On the contrary, we resolve word sense ambiguity by using concept co-occurrence information extracted from an automatically sense-tagged corpus. In one experiment, it achieved, on average, a precision of 82.4{\%} for nominal words, and 83{\%} for verbal words. Considering that the test corpus is completely irrelevant to the learning corpus, this is a promising result."
W98-1110,Generalized unknown morpheme guessing for hybrid {POS} tagging of {K}orean,1998,8,19,3,0.882353,26685,jeongwon cha,Sixth Workshop on Very Large Corpora,0,None
P98-2125,Identifying Syntactic Role of Antecedent in {K}orean Relative Clause using Corpus and Thesaurus Informationes,1998,3,7,2,1,50810,huifeng li,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"This paper describes an approach to identifying the syntactic role of an antecedent in a Korean relative clause, which is essential to structural disambiguation and semantic analysis. In a learning phase, linguistic knowledge such as conceptual co-occurrence patterns and syntactic role distribution of antecedents is extracted from a large-scale corpus. Then, in an application phase, the extracted knowledge is applied in determining the correct syntactic role of an antecedent in relative clauses. Unlike previous research based on co-occurrence patterns at the lexical level, we represent co-occurrence patterns with concept types in a thesaurus. In an experiment, the proposed method showed a high accuracy rate of 90.4% in resolving ambiguities of syntactic role determination of antecedents."
P98-1111,Unlimited Vocabulary Grapheme to Phoneme Conversion for {K}orean {TTS},1998,5,6,4,0,3608,byeongchang kim,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules. The method consists of mainly four modules including morpheme normalization, phrase-break detection, morpheme to phoneme conversion and phoneme connectivity check.The morpheme normalization is to replace non-Korean symbols into standard Korean graphemes. The phrase-break detector assigns phrase breaks using part-of-speech (POS) information. In the morpheme-to-phoneme conversion module, each morpheme in the phrase is converted into phonetic patterns by looking up the morpheme phonetic pattern dictionary which contains candidate phonological changes in boundaries of the morphemes. Graphemes within a morpheme are grouped into CCV patterns and converted into phonemes by the CCV conversion rules. The phoneme connectivity table supports grammaticality checking of the adjacent two phonetic morphemes.In the experiments with a corpus of 4,973 sentences, we achieved 99.9% of the grapheme-to-phoneme conversion performance. The full Korean TTS system is now being implemented using this conversion method."
C98-2120,Identifying Syntactic Role of Antecedent in {K}orean Relative Clause Using Corpus and Thesaurus Information,1998,3,7,2,1,50810,huifeng li,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"This paper describes an approach to identifying the syntactic role of an antecedent in a Korean relative clause, which is essential to structural disambiguation and semantic analysis. In a learning phase, linguistic knowledge such as conceptual co-occurrence patterns and syntactic role distribution of antecedents is extracted from a large-scale corpus. Then, in an application phase, the extracted knowledge is applied in determining the correct syntactic role of an antecedent in relative clauses. Unlike previous research based on co-occurrence patterns at the lexical level, we represent co-occurrence patterns with concept types in a thesaurus. In an experiment, the proposed method showed a high accuracy rate of 90.4% in resolving ambiguities of syntactic role determination of antecedents."
C98-1107,Unlimited Vocabulary Grapheme to Phoneme Conversion for {K}orean {TTS},1998,5,6,4,0,3608,byeongchang kim,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules. The method consists of mainly four modules including morpheme normalization, phrase-break detection, morpheme to phoneme conversion and phoneme connectivity check.The morpheme normalization is to replace non-Korean symbols into standard Korean graphemes. The phrase-break detector assigns phrase breaks using part-of-speech (POS) information. In the morpheme-to-phoneme conversion module, each morpheme in the phrase is converted into phonetic patterns by looking up the morpheme phonetic pattern dictionary which contains candidate phonological changes in boundaries of the morphemes. Graphemes within a morpheme are grouped into CCV patterns and converted into phonemes by the CCV conversion rules. The phoneme connectivity table supports grammaticality checking of the adjacent two phonetic morphemes.In the experiments with a corpus of 4,973 sentences, we achieved 99.9% of the grapheme-to-phoneme conversion performance. The full Korean TTS system is now being implemented using this conversion method."
C94-2147,Table-driven Neural Syntactic Analysis of Spoken {K}orean,1994,8,4,3,0,56455,wonll lee,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"A CYK-table-driven interactive relaxation parsing method of spoken Korean, integrated with the CYK-based morphological analysis is introduced. An extension of the Categorial Grammar is introduced to treat the free wordorder in Korean. The table-driven control of interactive relaxation gives efficiency in constituent searching and expectation generation. The lexical nature of the Categorial Grammar and the distributed nature of the interactive relaxation parsing together show a smooth integration of both bottom-up and top-down effects during the spoken language analysis."
