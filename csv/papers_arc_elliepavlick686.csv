2021.findings-emnlp.370,Does Vision-and-Language Pretraining Improve Lexical Grounding?,2021,-1,-1,3,0,7333,tian yun,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Linguistic representations derived from text alone have been criticized for their lack of grounding, i.e., connecting words to their meanings in the physical world. Vision-and- Language (VL) models, trained jointly on text and image or video data, have been offered as a response to such criticisms. However, while VL pretraining has shown success on multimodal tasks such as visual question answering, it is not yet known how the internal linguistic representations themselves compare to their text-only counterparts. This paper compares the semantic representations learned via VL vs. text-only pretraining for two recent VL models using a suite of analyses (clustering, probing, and performance on a commonsense question answering task) in a language-only setting. We find that the multimodal models fail to significantly outperform the text-only variants, suggesting that future work is required if multimodal pretraining is to be pursued as a means of improving NLP in general."
2021.findings-acl.181,Are Rotten Apples Edible? Challenging Commonsense Inference Ability with Exceptions,2021,-1,-1,2,0,7941,nam do,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.72,Frequency Effects on Syntactic Rule Learning in Transformers,2021,-1,-1,4,0,4299,jason wei,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Pre-trained language models perform well on a variety of linguistic tasks that require symbolic reasoning, raising the question of whether such models implicitly represent abstract symbols and rules. We investigate this question using the case study of BERT{'}s performance on English subject{--}verb agreement. Unlike prior work, we train multiple instances of BERT from scratch, allowing us to perform a series of controlled interventions at pre-training time. We show that BERT often generalizes well to subject{--}verb pairs that never occurred in training, suggesting a degree of rule-governed behavior. We also find, however, that performance is heavily influenced by word frequency, with experiments showing that both the absolute frequency of a verb form, as well as the frequency relative to the alternate inflection, are causally implicated in the predictions BERT makes at inference time. Closer analysis of these frequency effects reveals that BERT{'}s behavior is consistent with a system that correctly applies the SVA rule in general but struggles to overcome strong training priors and to estimate agreement features (singular vs. plural) on infrequent lexical items."
2021.emnlp-main.790,{``}Was it {``}stated{''} or was it {``}claimed{''}?: How linguistic bias affects generative language models,2021,-1,-1,2,0.882353,3922,roma patel,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"People use language in subtle and nuanced ways to convey their beliefs. For instance, saying \textit{claimed} instead of \textit{said} casts doubt on the truthfulness of the underlying proposition, thus representing the author{'}s opinion on the matter. Several works have identified such linguistic classes of words that occur frequently in natural language text and are bias-inducing by virtue of their framing effects. In this paper, we test whether generative language models (including GPT-2 (CITATION) are sensitive to these linguistic framing effects. In particular, we test whether prompts that contain linguistic markers of author bias (e.g., hedges, implicatives, subjective intensifiers, assertives) influence the distribution of the generated text. Although these framing effects are subtle and stylistic, we find evidence that they lead to measurable style and topic differences in the generated text, leading to language that is, on average, more polarised and more skewed towards controversial entities and events."
2021.conll-1.9,Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color,2021,-1,-1,5,0,10900,mostafa abdou,Proceedings of the 25th Conference on Computational Natural Language Learning,0,"Pretrained language models have been shown to encode relational information, such as the relations between entities or concepts in knowledge-bases {---} (Paris, Capital, France). However, simple relations of this type can often be recovered heuristically and the extent to which models implicitly reflect topological structure that is grounded in world, such as perceptual structure, is unknown. To explore this question, we conduct a thorough case study on color. Namely, we employ a dataset of monolexemic color terms and color chips represented in CIELAB, a color space with a perceptually meaningful distance metric. Using two methods of evaluating the structural alignment of colors in this space with text-derived color term representations, we find significant correspondence. Analyzing the differences in alignment across the color spectrum, we find that warmer colors are, on average, better aligned to the perceptual color space than cooler ones, suggesting an intriguing connection to findings from recent work on efficient communication in color naming. Further analysis suggests that differences in alignment are, in part, mediated by collocationality and differences in syntactic usage, posing questions as to the relationship between color perception and usage and context."
2021.acl-short.21,{AND} does not mean {OR}: Using Formal Languages to Study Language Models{'} Representations,2021,-1,-1,3,0,12515,aaron traylor,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"A current open question in natural language processing is to what extent language models, which are trained with access only to the form of language, are able to capture the meaning of language. This question is challenging to answer in general, as there is no clear line between meaning and form, but rather meaning constrains form in consistent ways. The goal of this study is to offer insights into a narrower but critical subquestion: Under what conditions should we expect that meaning and form covary sufficiently, such that a language model with access only to form might nonetheless succeed in emulating meaning? Focusing on several formal languages (propositional logic and a set of programming languages), we generate training corpora using a variety of motivated constraints, and measure a distributional language model{'}s ability to differentiate logical symbols (AND, OR, and NOT). Our findings are largely negative: none of our simulated training corpora result in models which definitively differentiate meaningfully different symbols (e.g., AND vs. OR), suggesting a limitation to the types of semantic signals that current models are able to exploit."
2021.acl-long.304,Which Linguist Invented the Lightbulb? Presupposition Verification for Question-Answering,2021,-1,-1,2,0.666667,2284,najoung kim,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Many Question-Answering (QA) datasets contain unanswerable questions, but their treatment in QA systems remains primitive. Our analysis of the Natural Questions (Kwiatkowski et al. 2019) dataset reveals that a substantial portion of unanswerable questions ({\textasciitilde}21{\%}) can be explained based on the presence of unverifiable presuppositions. Through a user preference study, we demonstrate that the oracle behavior of our proposed system{---}which provides responses based on presupposition failure{---}is preferred over the oracle behavior of existing QA systems. Then, we present a novel framework for implementing such a system in three steps: presupposition generation, presupposition verification, and explanation generation, reporting progress on each. Finally, we show that a simple modification of adding presuppositions and their verifiability to the input of a competitive end-to-end QA system yields modest gains in QA performance and unanswerability detection, demonstrating the promise of our approach."
2020.starsem-1.16,A Visuospatial Dataset for Naturalistic Verb Learning,2020,-1,-1,2,0,14535,dylan ebert,Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics,0,"We introduce a new dataset for training and evaluating grounded language models. Our data is collected within a virtual reality environment and is designed to emulate the quality of language data to which a pre-verbal child is likely to have access: That is, naturalistic, spontaneous speech paired with richly grounded visuospatial context. We use the collected data to compare several distributional semantics models for verb learning. We evaluate neural models based on 2D (pixel) features as well as feature-engineered models based on 3D (symbolic, spatial) features, and show that neither modeling approach achieves satisfactory performance. Our results are consistent with evidence from child language acquisition that emphasizes the difficulty of learning verbs from naive distributional data. We discuss avenues for future work on cognitively-inspired grounded language learning, and release our corpus with the intent of facilitating research on the topic."
2020.emnlp-main.335,Are {``}Undocumented Workers{''} the Same as {``}Illegal Aliens{''}? {D}isentangling Denotation and Connotation in Vector Spaces,2020,-1,-1,4,0,20380,albert webson,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"In politics, neologisms are frequently invented for partisan objectives. For example, {``}undocumented workers{''} and {``}illegal aliens{''} refer to the same group of people (i.e., they have the same denotation), but they carry clearly different connotations. Examples like these have traditionally posed a challenge to reference-based semantic theories and led to increasing acceptance of alternative theories (e.g., Two-Factor Semantics) among philosophers and cognitive scientists. In NLP, however, popular pretrained models encode both denotation and connotation as one entangled representation. In this study, we propose an adversarial nerual netowrk that decomposes a pretrained representation as independent denotation and connotation representations. For intrinsic interpretability, we show that words with the same denotation but different connotations (e.g., {``}immigrants{''} vs. {``}aliens{''}, {``}estate tax{''} vs. {``}death tax{''}) move closer to each other in denotation space while moving further apart in connotation space. For extrinsic application, we train an information retrieval system with our disentangled representations and show that the denotation vectors improve the viewpoint diversity of document rankings."
2020.blackboxnlp-1.4,What Happens To {BERT} Embeddings During Fine-tuning?,2020,61,0,3,0,22204,amil merchant,Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,0,"While much recent work has examined how linguistic information is encoded in pre-trained sentence representations, comparatively little is understood about how these models change when adapted to solve downstream tasks. Using a suite of analysis techniques{---}supervised probing, unsupervised similarity analysis, and layer-based ablations{---}we investigate how fine-tuning affects the representations of the BERT model. We find that while fine-tuning necessarily makes some significant changes, there is no catastrophic forgetting of linguistic phenomena. We instead find that fine-tuning is a conservative process that primarily affects the top layers of BERT, albeit with noteworthy variation across tasks. In particular, dependency parsing reconfigures most of the model, whereas SQuAD and MNLI involve much shallower processing. Finally, we also find that fine-tuning has a weaker effect on representations of out-of-domain sentences, suggesting room for improvement in model generalization."
2020.acl-tutorials.1,Interpretability and Analysis in Neural {NLP},2020,-1,-1,3,0,8869,yonatan belinkov,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,"While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network models in NLP. This body of work is so far lacking a common framework and methodology. Moreover, approaching the analysis of modern neural networks can be difficult for newcomers to the field. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, such as structural analyses using probing classifiers, behavioral studies and test suites, and interactive visualizations. We will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches, in order to inform participants where to focus future efforts."
W19-2918,Using Grounded Word Representations to Study Theories of Lexical Concepts,2019,-1,-1,2,0,14535,dylan ebert,Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics,0,"The fields of cognitive science and philosophy have proposed many different theories for how humans represent {``}concepts{''}. Multiple such theories are compatible with state-of-the-art NLP methods, and could in principle be operationalized using neural networks. We focus on two particularly prominent theories{--}Classical Theory and Prototype Theory{--}in the context of visually-grounded lexical representations. We compare when and how the behavior of models based on these theories differs in terms of categorization and entailment tasks. Our preliminary results suggest that Classical-based representations perform better for entailment and Prototype-based representations perform better for categorization. We discuss plans for additional experiments needed to confirm these initial observations."
S19-1026,Probing What Different {NLP} Tasks Teach Machines about Function Word Comprehension,2019,0,16,12,0.666667,2284,najoung kim,Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019),0,"We introduce a set of nine challenge tasks that test for the understanding of function words. These tasks are created by structurally mutating sentences from existing datasets to target the comprehension of specific types of function words (e.g., prepositions, wh-words). Using these probing tasks, we explore the effects of various pretraining objectives for sentence encoders (e.g., language modeling, CCG supertagging and natural language inference (NLI)) on the learned representations. Our results show that pretraining on CCG{---}our most syntactic objective{---}performs the best on average across our probing tasks, suggesting that syntactic knowledge helps function word comprehension. Language modeling also shows strong performance, supporting its widespread use for pretraining state-of-the-art NLP models. Overall, no pretraining objective dominates across the board, and our function word probing tasks highlight several intuitive differences between pretraining objectives, e.g., that NLI helps the comprehension of negation."
Q19-1043,Inherent Disagreements in Human Textual Inferences,2019,24,4,1,1,7335,ellie pavlick,Transactions of the Association for Computational Linguistics,0,"We analyze human{'}s disagreements about the validity of natural language inferences. We show that, very often, disagreements are not dismissible as annotation {``}noise{''}, but rather persist as we collect more ratings and as we vary the amount of context provided to raters. We further show that the type of uncertainty captured by current state-of-the-art models for natural language inference is not reflective of the type of uncertainty present in human disagreements. We discuss implications of our results in relation to the recognizing textual entailment (RTE)/natural language inference (NLI) task. We argue for a refined evaluation objective that requires models to explicitly capture the full distribution of plausible human judgments."
P19-1334,Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference,2019,47,24,2,0,25232,tom mccoy,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area."
P19-1439,Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling,2019,0,13,15,0,9746,alex wang,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Natural language understanding has recently seen a surge of progress with the use of sentence encoders like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) which are pretrained on variants of language modeling. We conduct the first large-scale systematic study of candidate pretraining tasks, comparing 19 different tasks both as alternatives and complements to language modeling. Our primary results support the use language modeling, especially when combined with pretraining on additional labeled-data tasks. However, our results are mixed across pretraining tasks and show some concerning trends: In ELMo{'}s pretrain-then-freeze paradigm, random baselines are worryingly strong and results vary strikingly across target tasks. In addition, fine-tuning BERT on an intermediate task often negatively impacts downstream transfer. In a more positive trend, we see modest gains from multitask training, suggesting the development of more sophisticated multitask and transfer learning techniques as an avenue for further research."
P19-1452,{BERT} Rediscovers the Classical {NLP} Pipeline,2019,0,81,3,0,19975,ian tenney,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations."
D19-1228,How well do {NLI} models capture verb veridicality?,2019,0,1,2,0,8285,alexis ross,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"In natural language inference (NLI), contexts are considered veridical if they allow us to infer that their underlying propositions make true claims about the real world. We investigate whether a state-of-the-art natural language inference model (BERT) learns to make correct inferences about veridicality in verb-complement constructions. We introduce an NLI dataset for veridicality evaluation consisting of 1,500 sentence pairs, covering 137 unique verbs. We find that both human and model inferences generally follow theoretical patterns, but exhibit a systematic bias towards assuming that verbs are veridical{--}a bias which is amplified in BERT. We further show that, encouragingly, BERT{'}s inferences are sensitive not only to the presence of individual verb types, but also to the syntactic role of the verb, the form of the complement clause (to- vs. that-complements), and negation."
W18-5441,Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation,2018,0,29,5,0.729167,799,adam poliak,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},0,"We present a large scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation encoded by a neural network captures distinct types of reasoning. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. Our collection of diverse datasets is available at \url{http://www.decomp.net/}, and will grow over time as additional resources are recast and added from novel sources."
D18-1007,Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation,2018,0,29,5,0.729167,799,adam poliak,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of reasoning. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our collection as the DNC: Diverse Natural Language Inference Collection. The DNC is available online at \url{https://www.decomp.net}, and will grow over time as additional resources are recast and added from novel sources."
D18-1028,{W}iki{A}tomic{E}dits: A Multilingual Corpus of {W}ikipedia Edits for Modeling Language and Discourse,2018,36,4,2,0,8204,manaal faruqui,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We release a corpus of 43 million atomic edits across 8 languages. These edits are mined from Wikipedia edit history and consist of instances in which a human editor has inserted a single contiguous phrase into, or deleted a single contiguous phrase from, an existing sentence. We use the collected data to show that the language generated during editing differs from the language that we observe in standard corpora, and that models trained on edits encode different aspects of semantics and discourse than models trained on raw text. We release the full corpus as a resource to aid ongoing research in semantics, discourse, and representation learning."
D18-1202,Learning Scalar Adjective Intensity from Paraphrases,2018,0,4,3,0.454545,24896,anne cocos,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Adjectives like {``}warm{''}, {``}hot{''}, and {``}scalding{''} all describe temperature but differ in intensity. Understanding these differences between adjectives is a necessary part of reasoning about natural language. We propose a new paraphrase-based method to automatically learn the relative intensity relation that holds between a pair of scalar adjectives. Our approach analyzes over 36k adjectival pairs from the Paraphrase Database under the assumption that, for example, paraphrase pair {``}really hot{''} {\textless}{--}{\textgreater} {``}scalding{''} suggests that {``}hot{''} {\textless} {``}scalding{''}. We show that combining this paraphrase evidence with existing, complementary pattern- and lexicon-based approaches improves the quality of systems for automatically ordering sets of scalar adjectives and inferring the polarity of indirect answers to {``}yes/no{''} questions."
P17-1192,Identifying 1950s {A}merican Jazz Musicians: Fine-Grained {I}s{A} Extraction via Modifier Composition,2017,0,1,1,1,7335,ellie pavlick,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a method for populating fine-grained classes (e.g., {``}1950s American jazz musicians{''}) with instances (e.g., Charles Mingus ). While state-of-the-art methods tend to treat class labels as single lexical units, the proposed method considers each of the individual modifiers in the class label relative to the head. An evaluation on the task of reconstructing Wikipedia category pages demonstrates a {\textgreater}10 point increase in AUC, over a strong baseline relying on widely-used Hearst patterns."
S16-2014,So-Called Non-Subsective Adjectives,2016,11,3,1,1,7335,ellie pavlick,Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics,0,None
Q16-1005,An Empirical Analysis of Formality in Online Communication,2016,35,37,1,1,7335,ellie pavlick,Transactions of the Association for Computational Linguistics,0,"This paper presents an empirical study of linguistic formality. We perform an analysis of humans{'} perceptions of formality in four different genres. These findings are used to develop a statistical model for predicting formality, which is evaluated under different feature settings and genres. We apply our model to an investigation of formality in online discussion forums, and present findings consistent with theories of formality and linguistic coordination."
Q16-1029,Optimizing Statistical Machine Translation for Text Simplification,2016,64,57,3,0,4068,wei xu,Transactions of the Association for Computational Linguistics,0,"Most recent sentence simplification systems use basic machine translation models to learn lexical and syntactic paraphrases from a manually simplified parallel corpus. These methods are limited by the quality and quantity of manually simplified corpora, which are expensive to build. In this paper, we conduct an in-depth adaptation of statistical machine translation to perform text simplification, taking advantage of large-scale paraphrases learned from bilingual texts and a small amount of manual simplifications with multiple references. Our work is the first to design automatic metrics that are effective for tuning and evaluating simplification systems, which will facilitate iterative development for this task."
P16-2024,Simple {PPDB}: A Paraphrase Database for Simplification,2016,21,16,1,1,7335,ellie pavlick,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We release the Simple Paraphrase Database, a subset of of the Paraphrase Database (PPDB) adapted for the task of text simplification. We train a supervised model to associate simplification scores with each phrase pair, producing rankings competitive with state-of-theart lexical simplification models. Our new simplification database contains 4.5 million paraphrase rules, making it the largest available resource for lexical simplification."
P16-1204,Most {``}babies{''} are {``}little{''} and most {``}problems{''} are {``}huge{''}: Compositional Entailment in Adjective-Nouns,2016,29,15,1,1,7335,ellie pavlick,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
D16-1106,The Gun Violence Database: A new task and data set for {NLP},2016,17,9,1,1,7335,ellie pavlick,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
D16-1240,Tense Manages to Predict Implicative Behavior in Verbs,2016,11,5,1,1,7335,ellie pavlick,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
W15-2614,Effectively Crowdsourcing Radiology Report Annotations,2015,18,3,4,0.454545,24896,anne cocos,Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis,0,"Crowdsourcing platforms are a popular choice for researchers to gather text annotations quickly at scale. We investigate whether crowdsourced annotations are useful when the labeling task requires medical domain knowledge. Comparing a sentence classification model trained with expert-annotated sentences to the same model trained on crowd-labeled sentences, we find the crowdsourced training data to be just as effective as the manually produced dataset. We can improve the accuracy of the crowd-fueled model without collecting further labels by filtering out worker labels applied with low confidence."
P15-2010,Domain-Specific Paraphrase Extraction,2015,21,3,1,1,7335,ellie pavlick,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"The validity of applying paraphrase rules depends on the domain of the text that they are being applied to. We develop a novel method for extracting domainspecific paraphrases. We adapt the bilingual pivoting paraphrase method to bias the training data to be more like our target domain of biology. Our best model results in higher precision while retaining complete recall, giving a 10% relative improvement in AUC."
P15-2067,{F}rame{N}et+: Fast Paraphrastic Tripling of {F}rame{N}et,2015,22,16,1,1,7335,ellie pavlick,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We increase the lexical coverage of FrameNet through automatic paraphrasing. We use crowdsourcing to manually filter out bad paraphrases in order to ensure a high-precision resource. Our expanded FrameNet contains an additional 22K lexical units, a 3-fold increase over the current FrameNet, and achieves 40% better coverage when evaluated in a practical setting on New York Times data."
P15-2070,"{PPDB} 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification",2015,26,47,1,1,7335,ellie pavlick,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We present a new release of the Paraphrase Database. PPDB 2.0 includes a discriminatively re-ranked set of paraphrases that achieve a higher correlation with human judgments than PPDB 1.0xe2x80x99s heuristic rankings. Each paraphrase pair in the database now also includes finegrained entailment relations, word embedding similarities, and style annotations."
P15-1146,Adding Semantics to Data-Driven Paraphrasing,2015,39,24,1,1,7335,ellie pavlick,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"We add an interpretable semantics to the paraphrase database (PPDB). To date, the relationship between phrase pairs in the database has been weakly defined as approximately equivalent. We show that these pairs represent a variety of relations, including directed entailment (little girl/girl) and exclusion (nobody/someone). We automatically assign semantic entailment relations to entries in PPDB using features derived from past work on discovering inference rules from text and semantic taxonomy induction. We demonstrate that our model assigns these relations with high accuracy. In a downstream RTE task, our labels rival relations from WordNet and improve the coverage of a proof-based RTE system by 17%."
N15-4002,Crowdsourcing for {NLP},2015,0,5,3,0,3274,chris callisonburch,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Tutorial Abstracts,0,"Crowdsourced applications to scientific problems is a hot research area, with over 10,000 publications in the past five years. Platforms such as Amazons Mechanical Turk and CrowdFlower provide researchers with easy access to large numbers of workers. The crowds vast supply of inexpensive, intelligent labor allows people to attack problems that were previously impractical and gives potential for detailed scientific inquiry of social, psychological, economic, and linguistic phenomena via massive sample sizes of human annotated data. We introduce crowdsourcing and describe how it is being used in both industry and academia. Crowdsourcing is valuable to computational linguists both (a) as a source of labeled training data for use in machine learning and (b) as a means of collecting computational social science data that link language use to underlying beliefs and behavior. We present case studies for both categories: (a) collecting labeled data for use in natural language processing tasks such as word sense disambiguation and machine translation and (b) collecting experimental data in the context of psychology; e.g. finding how word use varies with age, sex, personality, health, and happiness. We will also cover tools and techniques for crowdsourcing. Effectively collecting crowdsourced data requires careful attention to the collection process, through selection of appropriately qualified workers, giving clear instructions that are understandable to non-?experts, and performing quality control on the results to eliminate spammers who complete tasks randomly or carelessly in order to collect the small financial reward. We will introduce different crowdsourcing platforms, review privacy and institutional review board issues, and provide rules of thumb for cost and time estimates. Crowdsourced data also has a particular structure that raises issues in statistical analysis; we describe some of the key methods to address these issues. No prior exposure to the area is required."
N15-1023,Inducing Lexical Style Properties for Paraphrase and Genre Differentiation,2015,25,21,1,1,7335,ellie pavlick,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present an intuitive and effective method for inducing style scores on words and phrases. We exploit signal in a phrasexe2x80x99s rate of occurrence across stylistically contrasting corpora, making our method simple to implement and efficient to scale. We show strong results both intrinsically, by correlation with human judgements, and extrinsically, in applications to genre analysis and paraphrasing."
Q14-1007,The Language Demographics of {A}mazon {M}echanical {T}urk,2014,37,42,1,1,7335,ellie pavlick,Transactions of the Association for Computational Linguistics,0,"We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers{'} self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems."
P14-1107,Are Two Heads Better than One? Crowdsourced Translation via a Two-Step Collaboration of Non-Professional Translators and Editors,2014,46,9,3,0,3650,rui yan,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Crowdsourcing is a viable mechanism for creating training data for machine translation. It provides a low cost, fast turnaround way of processing large volumes of data. However, when compared to professional translation, naive collection of translations from non-professionals yields low-quality results. Careful quality control is necessary for crowdsourcing to work well. In this paper, we examine the challenges of a two-step collaboration process with translation and post-editing by non-professionals. We develop graphbased ranking models that automatically select the best output from multiple redundant versions of translations and edits, and improves translation quality closer to professionals."
