2021.naacl-main.181,What About the Precedent: An Information-Theoretic Analysis of Common Law,2021,-1,-1,5,0,3812,josef valvoda,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In common law, the outcome of a new case is determined mostly by precedent cases, rather than by existing statutes. However, how exactly does the precedent influence the outcome of a new case? Answering this question is crucial for guaranteeing fair and consistent judicial decision-making. We are the first to approach this question computationally by comparing two longstanding jurisprudential views; Halsbury{'}s, who believes that the arguments of the precedent are the main determinant of the outcome, and Goodhart{'}s, who believes that what matters most is the precedent{'}s facts. We base our study on the corpus of legal cases from the European Court of Human Rights (ECtHR), which allows us to access not only the case itself, but also cases cited in the judges{'} arguments (i.e. the precedent cases). Taking an information-theoretic view, and modelling the question as a case out-come classification task, we find that the precedent{'}s arguments share 0.38 nats of information with the case{'}s outcome, whereas precedent{'}s facts only share 0.18 nats of information (i.e.,58{\%} less); suggesting Halsbury{'}s view may be more accurate in this specific court. We found however in a qualitative analysis that there are specific statues where Goodhart{'}s view dominates, and present some evidence these are the ones where the legal concept at hand is less straightforward."
2021.emnlp-main.73,A surprisal{--}duration trade-off across and within the world{'}s languages,2021,-1,-1,4,0.340909,1357,tiago pimentel,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"While there exist scores of natural languages, each with its unique features and idiosyncrasies, they all share a unifying theme: enabling human communication. We may thus reasonably predict that human cognition shapes how these languages evolve and are used. Assuming that the capacity to process information is roughly constant across human populations, we expect a surprisal{--}duration trade-off to arise both across and within languages. We analyse this trade-off using a corpus of 600 languages and, after controlling for several potential confounds, we find strong supporting evidence in both settings. Specifically, we find that, on average, phones are produced faster in languages where they are less surprising, and vice versa. Further, we confirm that more surprising phones are longer, on average, in 319 languages out of the 600. We thus conclude that there is strong evidence of a surprisal{--}duration trade-off in operation, both across and within the world{'}s languages."
2021.emnlp-main.653,On Homophony and R{\\'e}nyi Entropy,2021,-1,-1,3,0.340909,1357,tiago pimentel,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Homophony{'}s widespread presence in natural languages is a controversial topic. Recent theories of language optimality have tried to justify its prevalence, despite its negative effects on cognitive processing time, e.g., Piantadosi et al. (2012) argued homophony enables the reuse of efficient wordforms and is thus beneficial for languages. This hypothesis has recently been challenged by Trott and Bergen (2020), who posit that good wordforms are more often homophonous simply because they are more phonotactically probable. In this paper, we join in on the debate. We first propose a new information-theoretic quantification of a language{'}s homophony: the sample R{\'e}nyi entropy. Then, we use this quantification to revisit Trott and Bergen{'}s claims. While their point is theoretically sound, a specific methodological issue in their experiments raises doubts about their results. After addressing this issue, we find no clear pressure either towards or against homophony{---}a much more nuanced result than either Piantadosi et al.{'}s or Trott and Bergen{'}s findings."
2021.emnlp-main.654,Synthetic Textual Features for the Large-Scale Detection of Basic-level Categories in {E}nglish and {M}andarin,2021,-1,-1,2,0,9960,yiwen chen,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Basic-level categories (BLC) are an important psycholinguistic concept introduced by Rosch et al. (1976); they are defined as the most inclusive categories for which a concrete mental image of the category as a whole can be formed, and also as those categories which are acquired early in life. Rosch{'}s original algorithm for detecting BLC (called cue-validity) is based on the availability of semantic features such as {``}has tail{''} for {``}cat{''}, and has remained untested at large. An at-scale algorithm for the automatic determination of BLC exists, but it operates without Rosch-style semantic features, and is thus unable to verify Rosch{'}s hypothesis. We present the first method for the detection of BLC at scale that makes use of Rosch-style semantic features. For both English and Mandarin, we test three methods of generating such features for any synset within Wordnet (WN): extraction of textual features from Wikipedia pages, Distributional Memory (DM) and BART. The best of our methods outperforms the current SoA in BLC detection, with an accuracy of English BLC detection of 75.0{\%}, and of Mandarin BLC detection 80.7{\%} on a test set. When applied to all of WordNet, our model predicts that 1,118 synsets in English Wordnet (1.4{\%}) are BLC, far fewer than existing methods, and with a precision improvement of over 200{\%} over these. As well as confirming the usefulness of Rosch{'}s cue validity algorithm, we also developed and evaluated our own new indicator for BLC, which models the fact that BLC features tend to be BLC themselves."
2021.eacl-main.55,End-to-End Argument Mining as Biaffine Dependency Parsing,2021,-1,-1,2,0,10590,yuxiao ye,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Non-neural approaches to argument mining (AM) are often pipelined and require heavy feature-engineering. In this paper, we propose a neural end-to-end approach to AM which is based on dependency parsing, in contrast to the current state-of-the-art which relies on relation extraction. Our biaffine AM dependency parser significantly outperforms the state-of-the-art, performing at F1 = 73.5{\%} for component identification and F1 = 46.4{\%} for relation identification. One of the advantages of treating AM as biaffine dependency parsing is the simple neural architecture that results. The idea of treating AM as dependency parsing is not new, but has previously been abandoned as it was lagging far behind the state-of-the-art. In a thorough analysis, we investigate the factors that contribute to the success of our model: the biaffine model itself, our representation for the dependency structure of arguments, different encoders in the biaffine model, and syntactic information additionally fed to the model. Our work demonstrates that dependency parsing for AM, an overlooked idea from the past, deserves more attention in the future."
2021.bea-1.10,Parsing Argumentative Structure in {E}nglish-as-Foreign-Language Essays,2021,-1,-1,2,1,12222,jan putra,Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications,0,"This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. The parsing process consists of two steps, linking related sentences and then labelling their relations. We experiment with several deep learning architectures to address each task independently. In the sentence linking task, a biaffine model performed the best. In the relation labelling task, a fine-tuned BERT model performed the best. Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. We trained our models using two types of parallel texts: original noisy EFL essays and those improved by annotators, then evaluate them on the original essays. The experiment shows that an end-to-end in-domain system achieved an accuracy of .341. On the other hand, the cross-domain system achieved 94{\%} performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts."
2021.argmining-1.2,Multi-task and Multi-corpora Training Strategies to Enhance Argumentative Sentence Linking Performance,2021,-1,-1,2,1,12222,jan putra,Proceedings of the 8th Workshop on Argument Mining,0,"Argumentative structure prediction aims to establish links between textual units and label the relationship between them, forming a structured representation for a given input text. The former task, linking, has been identified by earlier works as particularly challenging, as it requires finding the most appropriate structure out of a very large search space of possible link combinations. In this paper, we improve a state-of-the-art linking model by using multi-task and multi-corpora training strategies. Our auxiliary tasks help the model to learn the role of each sentence in the argumentative structure. Combining multi-corpora training with a selective sampling strategy increases the training data size while ensuring that the model still learns the desired target distribution well. Experiments on essays written by English-as-a-foreign-language learners show that both strategies significantly improve the model{'}s performance; for instance, we observe a 15.8{\%} increase in the F1-macro for individual link predictions."
2020.lrec-1.854,{TIARA}: A Tool for Annotating Discourse Relations and Sentence Reordering,2020,-1,-1,2,1,12222,jan putra,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper introduces TIARA, a new publicly available web-based annotation tool for discourse relations and sentence reordering. Annotation tasks such as these, which are based on relations between large textual objects, are inherently hard to visualise without either cluttering the display and/or confusing the annotators. TIARA deals with the visual complexity during the annotation process by systematically simplifying the layout, and by offering interactive visualisation, including coloured links, indentation, and dual-view. TIARA{'}s text view allows annotators to focus on the analysis of logical sequencing between sentences. A separate tree view allows them to review their analysis in terms of the overall discourse structure. The dual-view gives it an edge over other discourse annotation tools and makes it particularly attractive as an educational tool (e.g., for teaching students how to argue more effectively). As it is based on standard web technologies and can be easily customised to other annotation schemes, it can be easily used by anybody. Apart from the project it was originally designed for, in which hundreds of texts were annotated by three annotators, TIARA has already been adopted by a second discourse annotation study, which uses it in the teaching of argumentation."
2020.figlang-1.30,Metaphor Detection using Context and Concreteness,2020,-1,-1,4,0.869565,3246,rowan maudslay,Proceedings of the Second Workshop on Figurative Language Processing,0,"We report the results of our system on the Metaphor Detection Shared Task at the Second Workshop on Figurative Language Processing 2020. Our model is an ensemble, utilising contextualised and static distributional semantic representations, along with word-type concreteness ratings. Using these features, it predicts word metaphoricity with a deep multi-layer perceptron. We are able to best the state-of-the-art from the 2018 Shared Task by an average of 8.0{\%} F1, and finish fourth in both sub-tasks in which we participate."
2020.conll-1.12,A Corpus of Very Short Scientific Summaries,2020,-1,-1,4,0,20956,yifan chen,Proceedings of the 24th Conference on Computational Natural Language Learning,0,"We present a new summarisation task, taking scientific articles and producing journal table-of-contents entries in the chemistry domain. These are one- or two-sentence author-written summaries that present the key findings of a paper. This is a first look at this summarisation task with an open access publication corpus consisting of titles and abstracts, as input texts, and short author-written advertising blurbs, as the ground truth. We introduce the dataset and evaluate it with state-of-the-art summarisation methods."
D19-1530,It{'}s All in the Name: Mitigating Gender Bias with Name-Based Counterfactual Data Substitution,2019,19,9,4,0.869565,3246,rowan maudslay,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"This paper treats gender bias latent in word embeddings. Previous mitigation attempts rely on the operationalisation of gender bias as a projection over a linear subspace. An alternative approach is Counterfactual Data Augmentation (CDA), in which a corpus is duplicated and augmented to remove bias, e.g. by swapping all inherently-gendered words in the copy. We perform an empirical comparison of these approaches on the English Gigaword and Wikipedia, and find that whilst both successfully reduce direct bias and perform well in tasks which quantify embedding quality, CDA variants outperform projection-based methods at the task of drawing non-biased gender analogies by an average of 19{\%} across both corpora. We propose two improvements to CDA: Counterfactual Data Substitution (CDS), a variant of CDA in which potentially biased text is randomly substituted to avoid duplication, and the Names Intervention, a novel name-pairing technique that vastly increases the number of words being treated. CDA/S with the Names Intervention is the only approach which is able to mitigate indirect gender bias: following debiasing, previously biased words are significantly less clustered according to gender (cluster purity is reduced by 49{\%}), thus improving on the state-of-the-art for bias mitigation."
N18-1028,Variable Typing: Assigning Meaning to Variables in Mathematical Text,2018,0,1,4,1,29410,yiannos stathopoulos,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Information about the meaning of mathematical variables in text is useful in NLP/IR tasks such as symbol disambiguation, topic modeling and mathematical information retrieval (MIR). We introduce \textit{variable typing}, the task of assigning one \textit{mathematical type} (multi-word technical terms referring to mathematical concepts) to each variable in a sentence of mathematical text. As part of this work, we also introduce a new annotated data set composed of 33,524 data points extracted from scientific documents published on arXiv. Our intrinsic evaluation demonstrates that our data set is sufficient to successfully train and evaluate current classifiers from three different model architectures. The best performing model is evaluated on an extrinsic task: MIR, by producing a \textit{typed formula index}. Our results show that the best performing MIR models make use of our typed index, compared to a formula index only containing raw symbols, thereby demonstrating the usefulness of variable typing."
W17-5103,Annotation of argument structure in {J}apanese legal documents,2017,8,2,2,0,24198,hiroaki yamada,Proceedings of the 4th Workshop on Argument Mining,0,"We propose a method for the annotation of Japanese civil judgment documents, with the purpose of creating flexible summaries of these. The first step, described in the current paper, concerns content selection, i.e., the question of which material should be extracted initially for the summary. In particular, we utilize the hierarchical argument structure of the judgment documents. Our main contributions are a) the design of an annotation scheme that stresses the connection between legal points (called issue topics) and argument structure, b) an adaptation of rhetorical status to suit the Japanese legal system and c) the definition of a linked argument structure based on legal sub-arguments. In this paper, we report agreement between two annotators on several aspects of the overall task."
P16-2078,Improving Argument Overlap for Proposition-Based Summarisation,2016,26,2,2,1,6591,yimai fang,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,The CSC Cambridge International Scholarship for the first author is gratefully acknowledged.
L16-1697,Solving the {AL} Chicken-and-Egg Corpus and Model Problem: Model-free Active Learning for Phenomena-driven Corpus Construction,2016,41,0,3,0,20637,dain kaplan,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Active learning (AL) is often used in corpus construction (CC) for selecting {``}informative{''} documents for annotation. This is ideal for focusing annotation efforts when all documents cannot be annotated, but has the limitation that it is carried out in a closed-loop, selecting points that will improve an existing model. For phenomena-driven and exploratory CC, the lack of existing-models and specific task(s) for using it make traditional AL inapplicable. In this paper we propose a novel method for model-free AL utilising characteristics of phenomena for applying AL to select documents for annotation. The method can also supplement traditional closed-loop AL-based CC to extend the utility of the corpus created beyond a single task. We introduce our tool, MOVE, and show its potential with a real world case-study."
D16-1259,Unsupervised Timeline Generation for {W}ikipedia History Articles,2016,16,1,2,1,35622,sandro bauer,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
C16-1055,A Proposition-Based Abstractive Summariser,2016,20,5,5,1,6591,yimai fang,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Abstractive summarisation is not yet common amongst today{'}s deployed and research systems. Most existing systems either extract sentences or compress individual sentences. In this paper, we present a summariser that works by a different paradigm. It is a further development of an existing summariser that has an incremental, proposition-based content selection process but lacks a natural language (NL) generator for the final output. Using an NL generator, we can now produce the summary text to directly reflect the selected propositions. Our evaluation compares textual quality of our system to the earlier preliminary output method, and also uses ROUGE to compare to various summarisers that use the traditional method of sentence extraction, followed by compression. Our results suggest that cutting out the middle-man of sentence extraction can lead to better abstractive summaries."
C16-1221,Mathematical Information Retrieval based on Type Embeddings and Query Expansion,2016,22,0,2,1,29410,yiannos stathopoulos,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We present an approach to mathematical information retrieval (MIR) that exploits a special kind of technical terminology, referred to as a mathematical type. In this paper, we present and evaluate a type detection mechanism and show its positive effect on the retrieval of research-level mathematics. Our best model, which performs query expansion with a type-aware embedding space, strongly outperforms standard IR models with state-of-the-art query expansion (vector space-based and language modelling-based), on a relatively new corpus of research-level queries."
P15-2055,Retrieval of Research-level Mathematical Information Needs: A Test Collection and Technical Terminology Experiment,2015,30,3,2,1,29410,yiannos stathopoulos,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In this paper, we present a test collection for mathematical information retrieval composed of real-life, researchlevel mathematical information needs. Topics and relevance judgements have been procured from the on-line collaboration website MathOverflow by delegating domain-specific decisions to experts on-line. With our test collection, we construct a baseline using Lucenexe2x80x99s vectorspace model implementation and conduct an experiment to investigate how prior extraction of technical terms from mathematical text can affect retrieval efficiency. We show that by boosting the importance of technical terms, statistically significant improvements in retrieval performance can be obtained over the baseline."
P15-2137,A Methodology for Evaluating Timeline Generation Algorithms based on Deep Semantic Units,2015,13,2,2,1,35622,sandro bauer,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Timeline generation is a summarisation task which transforms a narrative, roughly chronological input text into a set of timestamped summary sentences, each expressing an atomic historical event. We present a methodology for evaluating systems which create such timelines, based on a novel corpus consisting of 36 humancreated timelines. Our evaluation relies on deep semantic units which we call historical content units. An advantage of our approach is that it does not require human annotation of new system summaries."
E14-3006,Resolving Coreferent and Associative Noun Phrases in Scientific Text,2014,25,3,2,0,28149,ina roesiger,Proceedings of the Student Research Workshop at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present a study of information status in scientific text as well as ongoing work on the resolution of coreferent and associative anaphora in two different scientific disciplines, namely computational linguistics and genetics. We present an annotated corpus of over 8000 definite descriptions in scientific articles. To adapt a state-of-the-art coreference resolver to the new domain, we develop features aimed at modelling technical terminology and integrate these into the coreference resolver. Our results indicate that this integration, combined with domain-dependent training data, can outperform the performance of an out-of-the-box coreference resolver. For the (much harder) task of resolving associative anaphora, our preliminary results show the need for and the effect of semantic features."
E14-1053,Topical {P}age{R}ank: A Model of Scientific Expertise for Bibliographic Search,2014,58,6,2,0,40085,james jardine,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We model scientific expertise as a mixture of topics and authority. Authority is calculated based on the network properties of each topic network. ThemedPageRank, our combination of LDA-derived topics with PageRank differs from previous models in that topics influence both the bias and transition probabilities of PageRank. It also incorporates the age of documents. Our model is general in that it can be applied to all tasks which require an estimate of documentxe2x80x90document, documentxe2x80x90 query, documentxe2x80x90topic and topicxe2x80x90query similarities. We present two evaluations, one on the task of restoring the reference lists of 10,000 articles, the other on the task of automatically creating reading lists that mimic reading lists created by experts. In both evaluations, our system beats state-of-the-art, as well as Google Scholar and Google Search indexed againt the corpus. Our experiments also allow us to quantify the beneficial effect of our two proposed modifications to PageRank."
E14-1077,A Summariser based on Human Memory Limitations and Lexical Competition,2014,38,7,2,1,6591,yimai fang,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Kintsch and van Dijk proposed a model of human comprehension and summarisation which is based on the idea of processing propositions on a sentence-bysentence basis, detecting argument overlap, and creating a summary on the basis of the best connected propositions. We present an implementation of that model, which gets around the problem of identifying concepts in text by applying coreference resolution, named entity detection, and semantic similarity detection, implemented as a two-step competition. We evaluate the resulting summariser against two commonly used extractive summarisers using ROUGE, with encouraging results."
C14-1002,Unsupervised learning of rhetorical structure with un-topic models,2014,34,18,2,0,20639,diarmuid seaghdha,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In this paper we investigate whether unsupervised models can be used to induce conventional aspects of rhetorical language in scientific writing. We rely on the intuition that the rhetorical language used in a document is general in nature and independent of the documentxe2x80x99s topic. We describe a Bayesian latent-variable model that implements this intuition. In two empirical evaluations based on the task of argumentative zoning (AZ), we demonstrate that our generality hypothesis is crucial for distinguishing between rhetorical and topical language and that features provided by our unsupervised model trained on a large corpus can improve the performance of a supervised AZ classifier."
J13-2003,Statistical Metaphor Processing,2013,117,72,2,0.416667,4353,ekaterina shutova,Computational Linguistics,0,"Metaphor is highly frequent in language, which makes its computational processing indispensable for real-world NLP applications addressing semantic tasks. Previous approaches to metaphor modeling rely on task-specific hand-coded knowledge and operate on a limited domain or a subset of phenomena. We present the first integrated open-domain statistical model of metaphor processing in unrestricted text. Our method first identifies metaphorical expressions in running text and then paraphrases them with their literal paraphrases. Such a text-to-text model of metaphor interpretation is compatible with other NLP applications that can benefit from metaphor resolution. Our approach is minimally supervised, relies on the state-of-the-art parsing and lexical acquisition technologies distributional clustering and selectional preference induction, and operates with a high accuracy."
W12-4303,Detection of Implicit Citations for Sentiment Detection,2012,37,34,2,0,17574,awais athar,Proceedings of the Workshop on Detecting Structure in Scholarly Discourse,0,"Sentiment analysis of citations in scientific papers is a new and interesting problem which can open up many exciting new applications in bibliometrics. Current research assumes that using just the citation sentence is enough for detecting sentiment. In this paper, we show that this approach misses much of the existing sentiment. We present a new corpus in which all mentions of a cited paper have been annotated. We explore methods to automatically identify these mentions and show that the inclusion of implicit citations in citation sentiment analysis improves the quality of the overall sentiment assignment."
N12-1073,Context-Enhanced Citation Sentiment Detection,2012,26,60,2,0,17574,awais athar,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Sentiment analysis of citations in scientific papers and articles is a new and interesting problem which can open up many exciting new applications in bibliographic search and bibliometrics. Current work on citation sentiment detection focuses on only the citation sentence. In this paper, we address the problem of context-enhanced citation sentiment detection. We present a new citation sentiment corpus which has been annotated to take the dominant sentiment in the entire citation context into account. We believe that this gold standard is closer to the truth than annotation that looks only at the citation sentence itself. We then explore the effect of context windows of different lengths on the performance of a state-of-the-art citation sentiment detection system when using this context-enhanced gold standard definition."
shutova-teufel-2010-metaphor,Metaphor Corpus Annotated for Source - Target Domain Mappings,2010,21,55,2,0.416667,4353,ekaterina shutova,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Besides making our thoughts more vivid and filling our communication with richer imagery, metaphor also plays an important structural role in our cognition. Although there is a consensus in the linguistics and NLP research communities that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of isolated words, but rather involves reconceptualization of a whole area of experience (target domain) in terms of another (source domain), there still has been no proposal for a comprehensive procedure for annotation of cross-domain mappings. However, a corpus annotated for conceptual mappings could provide a new starting point for both linguistic and cognitive experiments. The annotation scheme we present in this paper is a step towards filling this gap. We test our procedure in an experimental setting involving multiple annotators and estimate their agreement on the task. The associated corpus annotated for source â target domain mappings will be publicly available."
liakata-etal-2010-corpora,Corpora for the Conceptualisation and Zoning of Scientific Papers,2010,17,76,2,0,3114,maria liakata,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present two complementary annotation schemes for sentence based annotation of full scientific papers, CoreSC and AZ-II, applied to primary research articles in chemistry. AZ-II is the extension of AZ for chemistry papers. AZ has been shown to have been reliably annotated by independent human coders and useful for various information access tasks. Like AZ, AZ-II follows the rhetorical structure of a scientific paper and the knowledge claims made by the authors. The CoreSC scheme takes a different view of scientific papers, treating them as the humanly readable representations of scientific investigations. It seeks to retrieve the structure of the investigation from the paper as generic high-level Core Scientific Concepts (CoreSC). CoreSCs have been annotated by 16 chemistry experts over a total of 265 full papers in physical chemistry and biochemistry. We describe the differences and similarities between the two schemes in detail and present the two corpora produced using each scheme. There are 36 shared papers in the corpora, which allows us to quantitatively compare aspects of the annotation schemes. We show the correlation between the two schemes, their strengths and weeknesses and discuss the benefits of combining a rhetorical based analysis of the papers with a content-based one."
D09-1155,Towards Domain-Independent Argumentative Zoning: Evidence from Chemistry and Computational Linguistics,2009,20,98,1,1,3813,simone teufel,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"Argumentative Zoning (AZ) is an analysis of the argumentative and rhetorical structure of a scientific paper. It has been shown to be reliably used by independent human coders, and has proven useful for various information access tasks. Annotation experiments have however so far been restricted to one discipline, computational linguistics (CL). Here, we present a more informative AZ scheme with 15 categories in place of the original 7, and show that it can be applied to the life sciences as well as to CL. We use a domain expert to encode basic knowledge about the subject (such as terminology and domain specific rules for individual categories) as part of the annotation guidelines. Our results show that non-expert human coders can then use these guidelines to reliably annotate this scheme in two domains, chemistry and computational linguistics."
rupp-etal-2008-language,Language Resources and Chemical Informatics,2008,10,1,6,0,48159,cj rupp,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Chemistry research papers are a primary source of information about chemistry, as in any scientific field. The presentation of the data is, predominantly, unstructured information, and so not immediately susceptible to processes developed within chemical informatics for carrying out chemistry research by information processing techniques. At one level, extracting the relevant information from research papers is a text mining task, requiring both extensive language resources and specialised knowledge of the subject domain. However, the papers also encode information about the way the research is conducted and the structure of the field itself. Applying language technology to research papers in chemistry can facilitate eScience on several different levels. The SciBorg project sets out to provide an extensive, analysed corpus of published chemistry research. This relies on the cooperation of several journal publishers to provide papers in an appropriate form. The work is carried out as a collaboration involving the Computer Laboratory, Chemistry Department and eScience Centre at Cambridge University, and is funded under the UK eScience programme."
W07-1530,Discourse Annotation Working Group Report,2007,0,2,5,0,2824,manfred stede,Proceedings of the Linguistic Annotation Workshop,0,None
W07-1008,Annotation of Chemical Named Entities,2007,14,52,3,0.784314,46344,peter corbett,"Biological, translational, and clinical language processing",0,"We describe the annotation of chemical named entities in scientific text. A set of annotation guidelines defines 5 types of named entities, and provides instructions for the resolution of special cases. A corpus of fulltext chemistry papers was annotated, with an inter-annotator agreement F score of 93%. An investigation of named entity recognition using LingPipe suggests that F scores of 63% are possible without customisation, and scores of 74% are possible with the addition of custom tokenisation and the use of dictionaries."
N07-1040,"Whose Idea Was This, and Why Does it Matter? Attributing Scientific Work to Citations",2007,13,41,2,0,10906,advaith siddharthan,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"Scientific papers revolve around citations, and for many discourse level tasks one needs to know whose work is being talked about at any point in the discourse. In this paper, we introduce the scientific attribution task, which links different linguistic expressions to citations. We discuss the suitability of different evaluation metrics and evaluate our classification approach to deciding attribution both intrinsically and in an extrinsic evaluation where information about scientific attribution is shown to improve performance on Argumentative Zoning, a rhetorical classification task."
W06-1613,Automatic classification of citation function,2006,29,234,1,1,3813,simone teufel,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"Citation function is defined as the author's reason for citing a given paper (e.g. acknowledgement of the use of the cited method). The automatic recognition of the rhetorical function of citations in scientific text has many applications, from improvement of impact factor calculations to text summarisation and more informative citation indexers. We show that our annotation scheme for citation function is reliable, and present a supervised machine learning framework to automatically classify citation function, using both shallow and linguistically-inspired features. We find, amongst other things, a strong relationship between citation function and sentiment classification."
W06-1312,An annotation scheme for citation function,2006,-1,-1,1,1,3813,simone teufel,Proceedings of the 7th {SIG}dial Workshop on Discourse and Dialogue,0,None
W06-0804,How to Find Better Index Terms Through Citations,2006,13,35,2,0,49827,anna ritchie,Proceedings of the Workshop on How Can Computational Linguistics Improve Information Retrieval?,0,"We consider the question of how information from the textual context of citations in scientific papers could improve indexing of the cited papers. We first present examples which show that the context should in principle provide better and new index terms. We then discuss linguistic phenomena around citations and which type of processing would improve the automatic determination of the right context. We present a case study, studying the effect of combining the existing index terms of a paper with additional terms from papers citing that paper in our corpus. Finally, we discuss the need for experimentation for the practical validation of our claim."
P06-1116,A Bootstrapping Approach to Unsupervised Detection of Cue Phrase Variants,2006,22,16,2,0,49991,rashid abdalla,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We investigate the unsupervised detection of semi-fixed cue phrases such as This paper proposes a novel approach...1 from unseen text, on the basis of only a handful of seed cue phrases with the desired semantics. The problem, in contrast to bootstrapping approaches for Question Answering and Information Extraction, is that it is hard to find a constraining context for occurrences of semi-fixed cue phrases. Our method uses components of the cue phrase itself, rather than external context, to bootstrap. It successfully excludes phrases which are different from the target semantics, but which look superficially similar. The method achieves 88% accuracy, outperforming standard bootstrapping approaches."
N06-1050,Creating a Test Collection for Citation-based {IR} Experiments,2006,18,30,2,0,49827,anna ritchie,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"We present an approach to building a test collection of research papers. The approach is based on the Cranfield 2 tests but uses as its vehicle a current conference; research questions and relevance judgements of all cited papers are elicited from conference authors. The resultant test collection is different from TREC's in that it comprises scientific articles rather than newspaper text and, thus, allows for IR experiments that include citation information. The test collection currently consists of 170 queries with relevance judgements; the document collection is the ACL Anthology. We describe properties of our queries and relevance judgements, and demonstrate the use of the test collection in an experimental setup. One potentially problematic property of our collection is that queries have a low number of relevant documents; we discuss ways of alleviating this."
W04-3254,Evaluating Information Content by Factoid Analysis: Human annotation and stability,2004,10,52,1,1,3813,simone teufel,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,None
teufel-van-halteren-2004-agreement,Agreement in Human Factoid Annotation for Summarization Evaluation,2004,8,5,1,1,3813,simone teufel,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Factoid analysis was introduced by (van Halteren and Teufel, 2003) as an objective, yet semantics-oriented way of measuring overlap of information rather than surface strings in summaries. In this paper, we report on annotation experiments with two sets of summaries, and on a factoid-pairing program which finds correlations between factoids semi-automatically."
radev-etal-2004-mead,{MEAD} - A Platform for Multidocument Multilingual Text Summarization,2004,11,273,14,0.259808,2447,dragomir radev,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Abstract This paper describes the functionality of MEAD, a comprehensive, public domain, open source, multidocument multilingual summarization environment that has been thus far downloaded by more than 500 organizations. MEAD has been used in a variety of summarization applications ranging from summarization for mobile devices to Web page summarization within a search engine and to novelty detection."
W03-0508,Examining the consensus between human summaries: initial experiments with factoid analysis,2003,11,79,2,0,17743,hans halteren,Proceedings of the {HLT}-{NAACL} 03 Text Summarization Workshop,0,"We present a new approach to summary evaluation which combines two novel aspects, namely (a) content comparison between gold standard summary and system summary via factoids, a pseudo-semantic representation based on atomic information units which can be robustly marked in text, and (b) use of a gold standard consensus summary, in our case based on 50 individual summaries of one text. Even though future work on more than one source text is imperative, our experiments indicate that (1) ranking with regard to a single gold standard summary is insufficient as rankings based on any two randomly chosen summaries are very dissimilar (correlations average xcfx81 = 0.20), (2) a stable consensus summary can only be expected if a larger number of summaries are collected (in the range of at least 30--40 summaries), and (3) similarity measurement using unigrams shows a similarly low ranking correlation when compared with factoid-based ranking."
P03-1048,Evaluation Challenges in Large-Scale Document Summarization,2003,18,92,2,0.419286,2447,dragomir radev,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"We present a large-scale meta evaluation of eight evaluation measures for both single-document and multi-document summarizers. To this end we built a corpus consisting of (a) 100 Million automatic summaries using six summarizers and baselines at ten summary lengths in both English and Chinese, (b) more than 10,000 manual abstracts and extracts, and (c) 200 Million automatic document and summary retrievals using 20 queries. We present both qualitative and quantitative results showing the strengths and draw-backs of all evaluation methods and how they rank the different summarizers."
teufel-elhadad-2002-collection,Collection and linguistic processing of a large-scale corpus of medical articles,2002,7,9,1,1,3813,simone teufel,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"We have collected a large-scale corpus of electronic articles in the cardiology domain (85 million words) in the framework of a digital library project that tailors the presentation of online medical literature to both patients and healthcare providers. We describe the webbased and XML technologies we used for the collection, encoding and linguistic processing of the corpus. This resulted in a largescale, high-quality, thoroughly marked-up resource which is used by many researchers in our project, in the areas of natural language processing, information retrieval and medical informatics. We show how the final use of the resource has influenced the design of its structural and linguistic encoding. The procedure we describe is general enough to be of use to researchers in a similar position wishing to compile, encode and linguistically annotate their own corpus from the web."
saggion-etal-2002-developing,Developing Infrastructure for the Evaluation of Single and Multi-document Summarization Systems in a Cross-lingual Environment,2002,29,29,3,0,5986,horacio saggion,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"We describe our work on the development of Language and Evaluation Resources for the evaluation of summaries in English and Chinese. The language resources include a parallel corpus of English and Chinese texts which are translations of each other, a set of queries in both languages, clusters of documents relevants to each query, sentence relevance measures for each sentence in the document clusters, and manual multi-document summaries at different compression rates. The evaluation resources consist of metrics for measuring the content of automatic summaries against reference summaries. The framework can be used in the evaluation of extractive, non-extractive, single and multi-document summarization. We focus on the resources developed that are made available for the research community."
J02-4002,Articles Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status,2002,77,441,1,1,3813,simone teufel,Computational Linguistics,0,"In this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: Material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work.We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. We present several experiments measuring our judges' agreement on these annotations.We also present an algorithm that, on the basis of the annotated training material, selects content from unseen articles and classifies it into a fixed set of seven rhetorical categories. The output of this extraction and classification system can be viewed as a single-document summary in its own right; alternatively, it provides starting material for the generation of task-oriented and user-tailored summaries designed to give users an overview of a scientific field."
C02-1073,Meta-evaluation of Summaries in a Cross-lingual Environment using Content-based Metrics,2002,17,41,3,0,5986,horacio saggion,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We describe a framework for the evaluation of summaries in English and Chinese using similarity measures. The framework can be used to evaluate extractive, non-extractive, single and multi-document summarization. We focus on the resources developed that are made available for the research community."
W00-1302,What{'}s Yours and What{'}s Mine: Determining Intellectual Attribution in Scientific Text,2000,28,41,1,1,3813,simone teufel,2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"We believe that identifying the structure of scientific argumentation in articles can help in tasks such as automatic summarization or the automated construction of citation indexes. One particularly important aspect of this structure is the question of who a given scientific statement is attributed to: other researchers, the field in general, or the authors themselves.We present the algorithm and a systematic evaluation of a system which can recognize the most salient textual properties that contribute to the global argumentative structure of a text. In this paper we concentrate on two particular features, namely the occurrences of prototypical agents and their actions in scientific text."
W99-0311,Discourse-level argumentation in scientific articles: human and automatic annotation,1999,16,30,1,1,3813,simone teufel,Towards Standards and Tools for Discourse Tagging,0,None
E99-1015,An annotation scheme for discourse-level argumentation in research articles,1999,21,109,1,1,3813,simone teufel,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In order to build robust automatic abstracting systems, there is a need for better training resources than are currently available. In this paper, we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way. The seven categories of the scheme are based on rhetorical moves of argumentation. Our experimental results show that the scheme is stable, reproducible and intuitive to use."
W98-0307,Meta-discourse markers and problem-structuring in scientific articles,1998,-1,-1,1,1,3813,simone teufel,Discourse Relations and Discourse Markers,0,None
W97-1301,Resolving bridging references in unrestricted text,1997,13,63,3,0,1743,massimo poesio,"Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts",0,"Our goal is to develop a system capable of treating the largest possible subset of definite descriptions in unrestricted written texts. A previous prototype resolved anaphoric uses of definite descriptions and identified some types of first-mention uses, achieving a recall of 56%. In this paper we present the latest version of our system, which handles some types of bridging references, uses WordNet as a source of lexical knowledge, and achieves a recall of 65%."
W97-0710,Sentence extraction as a classification task,1997,-1,-1,1,1,3813,simone teufel,Intelligent Scalable Text Summarization,0,None
P97-1072,Towards resolution of bridging descriptions,1997,8,14,2,0,6070,renata vieira,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,We present preliminary results concerning robust techniques for resolving bridging definite descriptions. We report our analysis of a collection of 20 Wall Street Journal articles from the Penn Treebank Corpus and our experiments with WordNet to identify relations between bridging descriptions and their antecedents.
E95-1014,Corpus-based Method for Automatic Identification of Support Verbs for Nominalizations,1995,5,37,1,1,3813,simone teufel,Seventh Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Nominalization is a highly productive phenomena in most languages. The process of nominalization ejects a verb from its syntactic role into a nominal position. The original verb is often replaced by a semantically emptied support verb (e.g., make a proposal). The choice of a support verb for a given nominalization is unpredictable, causing a problem for language learners as well as for natural language processing systems. We present here a method of discovering support verbs from an untagged corpus via low-level syntactic processing and comparison of arguments attached to verbal forms and potential nominalized forms. The result of the process is a list of potential support verbs for the nominalized form of a given predicate."
