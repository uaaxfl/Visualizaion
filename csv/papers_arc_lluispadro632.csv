D19-1346,Semantic Relatedness Based Re-ranker for Text Spotting,2019,0,1,3,0,26972,ahmed sabir,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Applications such as textual entailment, plagiarism detection or document clustering rely on the notion of semantic similarity, and are usually approached with dimension reduction techniques like LDA or with embedding-based neural approaches. We present a scenario where semantic similarity is not enough, and we devise a neural approach to learn semantic relatedness. The scenario is text spotting in the wild, where a text in an image (e.g. street sign, advertisement or bus destination) must be identified and recognized. Our goal is to improve the performance of vision systems by leveraging semantic information. Our rationale is that the text to be spotted is often related to the image context in which it appears (word pairs such as Delta-airplane, or quarters-parking are not similar, but are clearly related). We show how learning a word-to-word or word-to-sentence relatedness score can improve the performance of text spotting systems up to 2.9 points, outperforming other measures in a benchmark dataset."
L18-1057,Coreference Resolution in {F}ree{L}ing 4.0,2018,0,0,2,0.427838,26502,montserrat marimon,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This paper presents the integration of RelaxCor into FreeLing. RelaxCor is a coreference resolution system based on constraint satisfaction that ranked second in the CoNLL-2011 shared task. FreeLing is an open-source library for NLP with more than fifteen years of existence and a widespread user community. We present the difficulties found in porting RelaxCor from a shared task scenario to a production enviroment, as well as the solutions devised. We present two strategies for this integration and a rough evaluation of the obtained results"
C18-1236,Challenges and Opportunities of Applying Natural Language Processing in Business Process Management,2018,0,6,5,0,30883,han aa,Proceedings of the 27th International Conference on Computational Linguistics,0,"The Business Process Management (BPM) field focuses in the coordination of labor so that organizational processes are smoothly executed in a way that products and services are properly delivered. At the same time, NLP has reached a maturity level that enables its widespread application in many contexts, thanks to publicly available frameworks. In this position paper, we show how NLP has potential in raising the benefits of BPM practices at different levels. Instead of being exhaustive, we show selected key challenges were a successful application of NLP techniques would facilitate the automation of particular tasks that nowadays require a significant effort to accomplish. Finally, we report on applications that consider both the process perspective and its enhancement through NLP."
E17-2035,Morphological Analysis of the {D}ravidian Language Family,2017,0,1,3,1,32982,arun kumar,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"The Dravidian languages are one of the most widely spoken language families in the world, yet there are very few annotated resources available to NLP researchers. To remedy this, we create DravMorph, a corpus annotated for morphological segmentation and part-of-speech. Additionally, we exploit novel features and higher-order models to set state-of-the-art results on these corpora on both tasks, beating techniques proposed in the literature by as much as 4 points in segmentation F1."
W15-5404,Joint {B}ayesian Morphology Learning for {D}ravidian Languages,2015,-1,-1,2,1,32982,arun kumar,"Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects",0,None
W15-2207,Suitability of {P}ar{T}es Test Suite for Parsing Evaluation,2015,18,1,3,1,36948,marina lloberes,Proceedings of the 14th International Conference on Parsing Technologies,0,"Parsers have evolved significantly in the last decades, but currently big and accurate improvements are needed to enhance their performance. ParTes, a test suite in Spanish and Catalan for parsing evaluation, aims to contribute to this situation by pointing to the main factors that can decisively improve the parser performance"
W15-2123,Enhancing {F}ree{L}ing Rule-Based Dependency Grammars with Subcategorization Frames,2015,30,0,3,1,36948,marina lloberes,Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015),0,"Despite the recent advances in parsing, significant efforts are needed to improve the current parsers performance, such as the enhancement of the argument/adjunct recognition. There is evidence that verb subcategorization frames can contribute to parser accuracy, but a number of issues remain open. The main aim of this paper is to show how subcategorization frames acquired from a syntactically annotated corpus and organized into fine-grained classes can improve the performance of two rulebased dependency grammars."
R15-1041,Learning Agglutinative Morphology of {I}ndian Languages with Linguistically Motivated {A}daptor {G}rammars,2015,0,2,2,1,32982,arun kumar,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"In this paper an automatic morphology learning system for complex and agglutinative languages is presented. We process complex agglutinative morphology of Indian languages using Adaptor Grammars and linguistic rules of morphology. Adaptor Grammars are a compositional Bayesian framework for grammatical inference, where we define a morphological boundaries are inferred from a corpora of plain text. Once it produces morphological segmentation, regular expressions for orthography rules are applied to achieve final segmentation. We test our algorithm in the case of three complex languages from the Dravidian family and evaluate the results comparing to other state of the art unsupervised morphology learning systems and show significant improvements in the results."
alegria-etal-2014-tweetnorm,{T}weet{N}orm{\\_}es: an annotated corpus for {S}panish microtext normalization,2014,4,1,6,0.227273,28091,inaki alegria,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper we introduce TweetNorm{\_}es, an annotated corpus of tweets in Spanish language, which we make publicly available under the terms of the CC-BY license. This corpus is intended for development and testing of microtext normalization systems. It was created for Tweet-Norm, a tweet normalization workshop and shared task, and is the result of a joint annotation effort from different research groups. In this paper we describe the methodology defined to build the corpus as well as the guidelines followed in the annotation process. We also present a brief overview of the Tweet-Norm shared task, as the first evaluation environment where the corpus was used."
padro-etal-2014-language,Language Processing Infrastructure in the {XL}ike Project,2014,23,4,1,1,26974,lluis padro,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents the linguistic analysis tools and its infrastructure developed within the XLike project. The main goal of the implemented tools is to provide a set of functionalities for supporting some of the main objectives of XLike, such as enabling cross-lingual services for publishers, media monitoring or developing new business intelligence applications. The services cover seven major and minor languages: English, German, Spanish, Chinese, Catalan, Slovenian, and Croatian. These analyzers are provided as web services following a lightweight SOA architecture approach, and they are publically callable and are catalogued in META-SHARE."
J14-3001,{S}quibs: Automatic Selection of {HPSG}-Parsed Sentences for Treebank Construction,2014,21,7,3,0.427838,26502,montserrat marimon,Computational Linguistics,0,"This article presents an ensemble parse approach to detecting and selecting high-quality linguistic analyses output by a hand-crafted HPSG grammar of Spanish implemented in the LKB system. The approach uses full agreement (i.e., exact syntactic match) along with a MaxEnt parse selection model and a statistical dependency parser trained on the same data. The ultimate goal is to develop a hybrid corpus annotation methodology that combines fully automatic annotation and manual parse selection, in order to make the annotation task more efficient while maintaining high accuracy and the high degree of consistency necessary for any foreseen uses of a treebank."
E14-2003,{XL}ike Project Language Analysis Services,2014,10,5,2,0,7024,xavier carreras,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper presents the linguistic analysis infrastructure developed within the XLike project. The main goal of the implemented tools is to provide a set of functionalities supporting the XLike main objectives: Enabling cross-lingual services for publishers, media monitoring or developing new business intelligence applications. The services cover seven major and minor languages: English, German, Spanish, Chinese, Catalan, Slovenian, and Croatian. These analyzers are provided as web services following a lightweigth SOA architecture approach, and they are publically accessible and shared through META-SHARE. 1"
J13-4003,A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution,2013,67,11,2,1,41632,emili sapena,Computational Linguistics,0,"This work is focused on research in machine learning for coreference resolution. Coreference resolution is a natural language processing task that consists of determining the expressions in a discourse that refer to the same entity.n n The main contributions of this article are i a new approach to coreference resolution based on constraint satisfaction, using a hypergraph to represent the problem and solving it by relaxation labeling; and ii research towards improving coreference resolution performance using world knowledge extracted from Wikipedia.n n The developed approach is able to use an entity-mention classification model with more expressiveness than the pair-based ones, and overcome the weaknesses of previous approaches in the state of the art such as linking contradictions, classifications without context, and lack of information evaluating pairs. Furthermore, the approach allows the incorporation of new information by adding constraints, and research has been done in order to use world knowledge to improve performances.n n RelaxCor, the implementation of the approach, achieved results at the state-of-the-art level, and participated in international competitions: SemEval-2010 and CoNLL-2011. RelaxCor achieved second place in CoNLL-2011."
cuadros-etal-2012-highlighting,Highlighting relevant concepts from Topic Signatures,2012,23,2,2,0.877193,17770,montse cuadros,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents deepKnowNet, a new fully automatic method for building highly dense and accurate knowledge bases from existing semantic resources. Basically, the method applies a knowledge-based Word Sense Disambiguation algorithm to assign the most appropriate WordNet sense to large sets of topically related words acquired from the web, named TSWEB. This Word Sense Disambiguation algorithm is the personalized PageRank algorithm implemented in UKB. This new method improves by automatic means the current content of WordNet by creating large volumes of new and accurate semantic relations between synsets. KnowNet was our first attempt towards the acquisition of large volumes of semantic relations. However, KnowNet had some limitations that have been overcomed with deepKnowNet. deepKnowNet disambiguates the first hundred words of all Topic Signatures from the web (TSWEB). In this case, the method highlights the most relevant word senses of each Topic Signature and filter out the ones that are not so related to the topic. In fact, the knowledge it contains outperforms any other resource when is empirically evaluated in a common framework based on a similarity task annotated with human judgements."
padro-stanilovsky-2012-freeling,{F}ree{L}ing 3.0: Towards Wider Multilinguality,2012,9,259,1,1,26974,lluis padro,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"FreeLing is an open-source multilingual language processing library providing a wide range of analyzers for several languages. It offers text processing and language annotation facilities to NLP application developers, lowering the cost of building those applications. FreeLing is customizable, extensible, and has a strong orientation to real-world applications in terms of speed and robustness. Developers can use the default linguistic resources (dictionaries, lexicons, grammars, etc.), extend/adapt them to specific domains, or --since the library is open source-- develop new ones for specific languages or special application needs. This paper describes the general architecture of the library, presents the major changes and improvements included in FreeLing version 3.0, and summarizes some relevant industrial projects in which it has been used."
W11-1903,{R}elax{C}or Participation in {C}o{NLL} Shared Task on Coreference Resolution,2011,12,11,2,1,41632,emili sapena,Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,0,This paper describes the participation of RelaxCor in the CoNLL-2011 shared task: Modeling Unrestricted Coreference in Ontonotes. RELAXCOR is a constraint-based graph partitioning approach to coreference resolution solved by relaxation labeling. The approach combines the strengths of groupwise classifiers and chain formation methods in one global method.
W11-1501,"Extending the tool, or how to annotate historical language varieties",2011,10,16,3,0,44322,cristina sanchezmarco,"Proceedings of the 5th {ACL}-{HLT} Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",0,"We present a general and simple method to adapt an existing NLP tool in order to enable it to deal with historical varieties of languages. This approach consists basically in expanding the dictionary with the old word variants and in retraining the tagger with a small training corpus. We implement this approach for Old Spanish.n n The results of a thorough evaluation over the extended tool show that using this method an almost state-of-the-art performance is obtained, adequate to carry out quantitative studies in the humanities: 94.5% accuracy for the main part of speech and 92.6% for lemma. To our knowledge, this is the first time that such a strategy is adopted to annotate historical language varieties and we believe that it could be used as well to deal with other non-standard varieties of languages."
2011.freeopmt-1.2,{F}ree{L}ing: open-source natural language processing for research and development,2011,-1,-1,1,1,26974,lluis padro,Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation,0,None
S10-1017,{R}elax{C}or: A Global Relaxation Labeling Approach to Coreference Resolution,2010,6,12,2,1,41632,emili sapena,Proceedings of the 5th International Workshop on Semantic Evaluation,0,This paper describes the participation of RelaxCor in the Semeval-2010 task number 1: Coreference Resolution in Multiple Languages. RelaxCor is a constraint-based graph partitioning approach to coreference resolution solved by relaxation labeling. The approach combines the strengths of groupwise classifiers and chain formation methods in one global method.
padro-etal-2010-freeling,{F}ree{L}ing 2.1: Five Years of Open-source Language Processing Tools,2010,11,103,1,1,26974,lluis padro,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"FreeLing is an open-source multilingual language processing library providing a wide range of language analyzers for several languages. It offers text processing and language annotation facilities to natural language processing application developers, simplifying the task of building those applications. FreeLing is customizable and extensible. Developers can use the default linguistic resources (dictionaries, lexicons, grammars, etc.) directly, or extend them, adapt them to specific domains, or even develop new ones for specific languages. This paper overviews the recent history of this tool, summarizes the improvements and extensions incorporated in the latest version, and depicts the architecture of the library. Special focus is brought to the fact and consequences of the library being open-source: After five years and over 35,000 downloads, a growing user community has extended the initial threelanguages (English, Spanish and Catalan) to eight (adding Galician, Italian, Welsh, Portuguese, and Asturian), proving that the collaborative open model is a productive approach for the development of NLP tools and resources."
reese-etal-2010-wikicorpus,{W}ikicorpus: A Word-Sense Disambiguated Multilingual {W}ikipedia Corpus,2010,16,21,4,0,45828,samuel reese,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This article presents a new freely available trilingual corpus (Catalan, Spanish, English) that contains large portions of the Wikipedia and has been automatically enriched with linguistic information. To our knowledge, this is the largest such corpus that is freely available to the community: In its present version, it contains over 750 million words. The corpora have been annotated with lemma and part of speech information using the open source library FreeLing. Also, they have been sense annotated with the state of the art Word Sense Disambiguation algorithm UKB. As UKB assigns WordNet senses, and WordNet has been aligned across languages via the InterLingual Index, this sort of annotation opens the way to massive explorations in lexical semantics that were not possible before. We present a first attempt at creating a trilingual lexical resource from the sense-tagged Wikipedia corpora, namely, WikiNet. Moreover, we present two by-products of the project that are of use for the NLP community: An open source Java-based parser for Wikipedia pages developed for the construction of the corpus, and the integration of the WSD algorithm UKB in FreeLing."
lloberes-etal-2010-spanish,{S}panish {F}ree{L}ing Dependency Grammar,2010,9,16,3,1,36948,marina lloberes,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents the development of an open-source Spanish Dependency Grammar implemented in FreeLing environment. This grammar was designed as a resource for NLP applications that require a step further in natural language automatic analysis, as is the case of Spanish-to-Basque translation. The development of wide-coverage rule-based grammars using linguistic knowledge contributes to extend the existing Spanish deep parsers collection, which sometimes is limited. Spanish FreeLing Dependency Grammar, named EsTxala, provides deep and robust parse trees, solving attachments for any structure and assigning syntactic functions to dependencies. These steps are dealt with hand-written rules based on linguistic knowledge. As a result, FreeLing Dependency Parser gives a unique analysis as a dependency tree for each sentence analyzed. Since it is a resource open to the scientific community, exhaustive grammar evaluation is being done to determine its accuracy as well as strategies for its manteinance and improvement. In this paper, we show the results of an experimental evaluation carried out over EsTxala in order to test our evaluation methodology."
melero-etal-2010-language,Language Technology Challenges of a {`}Small{'} Language ({C}atalan),2010,3,2,5,0,4983,maite melero,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we present a brief snapshot of the state of affairs in computational processing of Catalan and the initiatives that are starting to take place in an effort to bring the field a step forward, by making a better and more efficient use of the already existing resources and tools, by bridging the gap between research and market, and by establishing periodical meeting points for the community. In particular, we present the results of the First Workshop on the Computational Processing of Catalan, which succeeded in putting together a fair representation of the research in the area, and received attention from both the industry and the administration. Aside from facilitating communication among researchers and between developers and users, the Workshop provided the organizers with valuable information about existing resources, tools, developers and providers. This information has allowed us to go a step further by setting up a ÂharvestingÂ procedure which will hopefully build the seed of a portal-catalogue-observatory of language resources and technologies in Catalan."
C10-2125,A Global Relaxation Labeling Approach to Coreference Resolution,2010,6,12,2,1,41632,emili sapena,Coling 2010: Posters,0,This paper describes the participation of RelaxCor in the Semeval-2010 task number 1: Coreference Resolution in Multiple Languages. RelaxCor is a constraint-based graph partitioning approach to coreference resolution solved by relaxation labeling. The approach combines the strengths of groupwise classifiers and chain formation methods in one global method.
S07-1095,{UPC}: Experiments with Joint Learning within {S}em{E}val Task 9,2007,7,5,2,0.299152,25372,lluis marquez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes UPC's participation in the SemEval-2007 task 9 (Marquez et al., 2007). We addressed all four subtasks using supervised learning. The paper introduces several novel issues: (a) for the SRL task, we propose a novel reranking algorithm based on the re-ranking Perceptron of Collins and Duffy (2002); and (b) for the same task we introduce a new set of global features that extract information not only at proposition level but also from the complete set of frame candidates. We show that in the SemEval setting, i.e., small training corpora, this approach outperforms previous work. Additionally, we added NSD and NER information in the global SRL model but this experiment was unsuccessful."
2005.mtsummit-osmtw.2,An Open Architecture for Transfer-based Machine Translation between {S}panish and {B}asque,2005,7,10,9,0.227273,28091,inaki alegria,Workshop on open-source machine translation,0,"We present the current status of development of an open architecture for the translation from Spanish into Basque. The machine translation architecture uses an open source analyser for Spanish and new modules mainly based on finite-state transducers. The project is integrated in the OpenTrad initiative, a larger government funded project shared among different universities and small companies, which will also include MT engines for translation among the main languages in Spain. The main objective is the construction of an open, reusable and interoperable framework. This paper describes the design of the engine, the formats it uses for the communication among the modules, the modules reused from other project named Matxin and the new modules we are building."
P04-3016,Knowledge intensive e-mail summarization in {CARPANTA},2004,0,0,4,0,51732,laura alonso,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,None
carreras-etal-2004-freeling,{F}ree{L}ing: An Open-Source Suite of Language Analyzers,2004,3,205,3,1,7024,xavier carreras,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Basic language processing such as tokenizing, morphological analyzers, lemmatizing, PoS tagging, chunking, etc. is a need for most NL applications such as Machine Translation, Summarization, Dialogue systems, etc. A large part of the effort required to develop such applications is devoted to the adaptation of existing software resources to the platform, programming language, format or API of the nal system. In LRECxe2x80x9902, we presented the object architecture that we are currently using (Carreras and Padrxc2xb7 o, 2002), which enables the quick and easy integration of basic language analyzers in any NLP application. Now we present a suite of analysis tools based on that architecture, which is distributed under Lesser General Public License (LGPL) (Free Software Foundation, 1999). The rst release of the suite will include morphological analyzer and Part-of-Speech tagger for English, Spanish, and Catalan."
alonso-etal-2004-multiple,Multiple Sequence Alignment for Characterizing the Lineal Structure of Revision,2004,4,4,5,0,51732,laura alonso,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We present a first approach to the application of a data mining technique, Multiple Sequence Alignment, to the systematization of a polemic aspect of discourse, namely, the expression of contrast, concession, counterargument and semantically similar discursive relations. The representation of the phenomena under study is carried out by very simple techniques, mostly pattern-matching, but the results allow to drive insightful conclusions on the organization of this aspect of discourse: equivalence classes of discourse markers are established, and systematic patterns are discovered, which will be applied in enhancing a discursive parser."
W03-1504,Low-cost Named Entity Classification for {C}atalan: Exploiting Multilingual Resources and Unlabeled Data,2003,8,4,4,1,25372,lluis marquez,Proceedings of the {ACL} 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,0,"This work studies Named Entity Classification (NEC) for Catalan without making use of large annotated resources of this language. Two views are explored and compared, namely exploiting solely the Catalan resources, and a direct training of bilingual classification models (Spanish and Catalan), given that a large collection of annotated examples is available for Spanish. The empirical results obtained on real data point out that multilingual models clearly outperform monolingual ones, and that the resulting Catalan NEC models are easier to improve by bootstrapping on unlabelled data."
W03-0421,A Simple Named Entity Extractor using {A}da{B}oost,2003,5,63,3,1,7024,xavier carreras,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"This paper presents a Named Entity Extraction (NEE) system for the CoNLL-2003 shared task competition. As in the past year edition (Carreras et al., 2002a), we have approached the task by treating the two main subxe2x80x93tasks of the problem, recognition (NER) and classification (NEC), sequentially and independently with separate modules. Both modules are machine learning based systems, which make use of binary and multiclass AdaBoost classifiers. Named Entity recognition is performed as a greedy sequence tagging procedure under the wellxe2x80x93known BIO labelling scheme. This tagging process makes use of three binary classifiers trained to be experts on the recognition of B, I, and O labels, respectively. Named Entity classification is viewed as a 4xe2x80x93class classification problem (with LOC, PER, ORG, and MISC class labels), which is straightforwardly addressed by the use of a multiclass learning algorithm. The system presented here consists of a replication, with some minor changes, of the system that obtained the best results in the CoNLL-2002 NEE task. Therefore, it can be considered as a benchmark of the statexe2x80x93ofxe2x80x93thexe2x80x93 art technology for the current edition, and will allow also to make comparisons about the training corpora of both editions."
W03-0422,Learning a Perceptron-Based Named Entity Chunker via Online Recognition Feedback,2003,5,21,3,1,7024,xavier carreras,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"We present a novel approach for the problem of Named Entity Recognition and Classification (NERC), in the context of the CoNLL-2003 Shared Task."
E03-1038,Named Entity Recognition For {C}atalan Using Only {S}panish Resources and Unlabelled Data,2003,0,3,3,1,7024,xavier carreras,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
W02-2004,Named Entity Extraction using {A}da{B}oost,2002,4,146,3,1,7024,xavier carreras,{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002),0,"This paper presents a Named Entity Extraction (NEE) system for the CoNLL 2002 competition. The two main sub-tasks of the problem, recognition (NER) and classification (NEC), are performed sequentially and independently with separate modules. Both modules are machine learning based systems, which make use of binary AdaBoost classifiers."
carreras-padro-2002-flexible,A Flexible Distributed Architecture for Natural Language Analyzers,2002,4,24,2,1,7024,xavier carreras,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"Many modern NLP applications require basic language processors such as POS taggers, parsers, etc. All these tools are usually preexisting, and must be adapted to fit in the requirements of the application to be developed. This adaptation procedure is usually time consuming and increases the application development cost. Our proposal to minimize this effort is to use standard engineering solutions for software reusability. In that sense, we converted all our language processors to classes which may be instantiated and accessed from any application via a CORBA broker. Reusability is not the only advantatge, since the distributed CORBA approach also makes it possible to access the analyzers from any remote application, developed in any language, and running on any operating system."
W01-1013,Multilingual Authoring: the {NAMIC} Approach,2001,11,7,8,0,12620,roberto basili,Proceedings of the {ACL} 2001 Workshop on Human Language Technology and Knowledge Management,0,"With increasing amounts of electronic information available, and the increase in the variety of languages used to produce documents of the same type, the problem of how to manage similar documents in different languages arises. This paper proposes an approach to processing/structuring text so that Multilingual Authoring (creating hypertext links) can be effectively carried out. This work, funded by the European Union, is applied to the Multilingual Authoring of news agency text. We have applied methods from Natural Language Processing, especially Information Extraction technology, to both monolingual and Multilingual Authoring."
P98-2164,On the Evaluation and Comparison of Taggers: the Effect of Noise in Testing Corpora,1998,4,18,1,1,26974,lluis padro,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"This paper addresses the issue of POS tagger evaluation. Such evaluation is usually performed by comparing the tagger output with a reference test corpus, which is assumed to be error-free. Currently used corpora contain noise which causes the obtained performance to be a distortion of the real value. We analyze to what extent this distortion may invalidate the comparison between taggers or the measure of the improvement given by a new system. The main conclusion is that a more rigorous testing experimentation setting/designing is needed to reliably evaluate and compare tagger accuracies."
C98-2159,On the Evaluation and Comparison of Taggers: the Effect of Noise in Testing Corpora.,1998,4,18,1,1,26974,lluis padro,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"This paper addresses the issue of POS tagger evaluation. Such evaluation is usually performed by comparing the tagger output with a reference test corpus, which is assumed to be error-free. Currently used corpora contain noise which causes the obtained performance to be a distortion of the real value. We analyze to what extent this distortion may invalidate the comparison between taggers or the measure of the improvement given by a new system. The main conclusion is that a more rigorous testing experimentation setting/designing is needed to reliably evaluate and compare tagger accuracies."
P97-1031,A Flexible {POS} Tagger Using an Automatically Acquired Language Model,1997,25,21,2,0.670048,25372,lluis marquez,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"We present an algorithm that automatically learns context constraints using statistical decision trees. We then use the acquired constraints in a flexible POS tagger. The tagger is able to use information of any degree: n-grams, automatically learned context constraints, linguistically motivated manually written constraints, etc. The sources and kinds of constraints are unrestricted, and the language model can be easily extended, improving the results. The tagger has been tested and evaluated on the WSJ corpus."
A97-1013,Developing a hybrid {NP} parser,1997,15,13,2,0,28693,atro voutilainen,Fifth Conference on Applied Natural Language Processing,0,"We describe the use of energy function optimisation in very shallow syntactic parsing. The approach can use linguistic rules and corpus-based statistics, so the strengths of both linguistic and statistical approaches to NLP can be combined in a single framework. The rules are contextual constraints for resolving syntactic ambiguities expressed as alternative tags, and the statistical language model consists of corpus-based n-grams of syntactic tags. The success of the hybrid syntactic disambiguator is evaluated against a held-out benchmark corpus. Also the contributions of the linguistic and statistical language models to the hybrid model are estimated."
C96-2148,{POS} Tagging Using Relaxation Labelling,1996,7,18,1,1,26974,lluis padro,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"Relaxation labelling is an optimization technique used in many fields to solve contraint satisfcation problems. The algorithm finds a combination of values for a set of variables such that satisfies -to the maximum possible degree- a set of given constraints. This paper describes some experiments performed applying it to POS tagging, and the results obtained. It also ponders the possibility of applying it to Word Sense Disambiguation."
