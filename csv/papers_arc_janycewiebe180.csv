W16-0411,How can {NLP} Tasks Mutually Benefit Sentiment Analysis? A Holistic Approach to Sentiment Analysis,2016,28,0,2,1,8715,lingjia deng,"Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"Existing opinion analysis techniques rely on the clues within the sentence that focus on the sentiment analysis task itself. However, the sentiment analysis task is not isolated from other NLP tasks (co-reference resolution, entity linking, etc) but they can benefit each other. In this paper, we define dependencies between sentiment analysis and other tasks, and express the dependencies in first order logic rules regardless of the representations of different tasks. The conceptual framework proposed in this paper using such dependency rules as constraints aims at exploiting information outside the sentence and outside the document to improve sentiment analysis. Further, the framework allows exception to the rules."
S16-1081,"{S}em{E}val-2016 Task 1: Semantic Textual Similarity, Monolingual and Cross-Lingual Evaluation",2016,29,110,8,0,8824,eneko agirre,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"Comunicacio presentada al 10th International Workshop on Semantic Evaluation (SemEval-2016), celebrat els dies 16 i 17 de juny de 2016 a San Diego, California."
S15-2045,"{S}em{E}val-2015 Task 2: Semantic Textual Similarity, {E}nglish, {S}panish and Pilot on Interpretability",2015,15,106,13,0,8824,eneko agirre,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"In semantic textual similarity (STS), systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new datasets in English and Spanish. The annotations for both subtasks leveraged crowdsourcing. The English subtask attracted 29 teams with 74 system runs, and the Spanish subtask engaged 7 teams participating with 16 system runs. In addition, this year we ran a pilot task on interpretable STS, where the systems needed to add an explanatory layer, that is, they had to align the chunks in the sentence pair, explicitly annotating the kind of relation and the score of the chunk pair. The train and test data were manually annotated by an expert, and included headline and image sentence pairs from previous years. 7 teams participated with 29 runs."
S15-1009,A New Dataset and Evaluation for Belief/Factuality,2015,15,5,18,0,90,vinodkumar prabhakaran,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"The terms xe2x80x9cbeliefxe2x80x9d and xe2x80x9cfactualityxe2x80x9d both refer to the intention of the writer to present the propositional content of an utterance as firmly believed by the writer, not firmly believed, or having some other status. This paper presents an ongoing annotation effort and an associated evaluation."
P15-5003,"Sentiment and Belief: How to Think about, Represent, and Annotate Private States",2015,22,3,2,0,1354,owen rambow,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing: Tutorial Abstracts,0,"Over the last ten years, there has been an explosion in interest in sentiment analysis, with many interesting and impressive results. For example, the first twenty publications on Google Scholar returned for the Query xe2x80x9csentiment analysisxe2x80x9d all date from 2003 or later, and have a total citation count of 12,140. The total number of publications is in the thousands. Partly, this interest is driven by the immediate commercial applications of sentiment analysis. Sentiment is a xe2x80x9cprivate statexe2x80x9d (Wiebe, 1990). However, it is not the only private state that has received attention in the computational literature; others include belief and intention. In this tutorial, we propose to provide a deeper understanding of what a private state is. We will concentrate on sentiment and belief. We will provide background that will allow the tutorial participants to understand the notion of a private state as a cognitive phenomenon, which can be manifested linguistically in communication in various ways. We will explain the formalization in terms of a triple of state, source, and target. We will discuss how to model the source and the target. We will then explain in some detail the annotations that have been made. The issue of annotation is crucial for private states: while the MPQA corpus (Wiebe et al., 2005; Wilson, 2007) has been around for some time, most research using it does not make use of many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of xe2x80x9cprivate statexe2x80x9d, which is what the annotation is getting at. Furthermore, there are currently several efforts underway of creating new versions of annotations, which we will also present. The larger goal of this tutorial is to allow the tutorial participants to gain a deeper understanding of the role of private states in human communication, and to encourage them to use this deeper understanding in their computational work. The immediate goal of this tutorial is to allow the participants to make more complete use of available annotated resources. We propose to achieve these goals by concentrating on annotated corpora, since this will allow participants to both understand the underlying content (achieving the larger goal) and the technical details of the annotations (achieving the immediate goal)."
N15-1146,{MPQA} 3.0: An Entity/Event-Level Sentiment Corpus,2015,16,45,2,1,8715,lingjia deng,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper presents an annotation scheme for adding entity and event target annotations to the MPQA corpus, a rich span-annotated opinion corpus. The new corpus promises to be a valuable new resource for developing systems for entity/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study."
D15-1018,Joint Prediction for Entity/Event-Level Sentiment Analysis using Probabilistic Soft Logic Models,2015,28,32,2,1,8715,lingjia deng,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"In this work, we build an entity/event-level sentiment analysis system, which is able to recognize and infer both explicit and implicit sentiments toward entities and events in the text. We design Probabilistic Soft Logic models that integrate explicit sentiments, inference rules, and /-effect event information (events that positively or negatively affect entities). The experiments show that the method is able to greatly improve over baseline accuracies in recognizing entity/event-level sentiments."
W14-3408,Generating Patient Problem Lists from the {S}h{AR}e Corpus using {SNOMED} {CT}/{SNOMED} {CT} {CORE} Problem List,2014,8,0,5,0,31798,danielle mowery,Proceedings of {B}io{NLP} 2014,0,Generating Patient Problem Lists from the ShARe Corpus using SNOMED CT/SNOMED CT CORE Problem List
W14-2603,An Investigation for Implicatures in {C}hinese : Implicatures in {C}hinese and in {E}nglish are similar !,2014,29,3,2,1,8715,lingjia deng,"Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"Implicit opinions are commonly seen in opinion-oriented documents, such as political editorials. Previous work have utilized opinion inference rules to detect implicit opinions evoked by events that positively/negatively affect entities (goodFor/badFor) to improve sentiment analysis for English text. Since people in different languages may express implicit opinions in different ways, in this work we investigate implicit opinions expressed via goodFor/badFor events in Chinese. The positive results have provided evidences that such implicit opinions and inference rules are similar in Chinese and in English. Moreover, we have observed cases where the inferences are blocked."
W14-2618,Lexical Acquisition for Opinion Inference: A Sense-Level Lexicon of Benefactive and Malefactive Events,2014,20,15,3,1,13794,yoonjung choi,"Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"Opinion inference arises when opinions are expressed toward states and events which positive or negatively affect entities, i.e., benefactive and malefactive events. This paper addresses creating a lexicon of such events, which would be helpful to infer opinions. Verbs may be ambiguous, in that some meanings may be benefactive and others may be malefactive or neither. Thus, we use WordNet to create a sense-level lexicon. We begin with seed senses culled from FrameNet and expand the lexicon using WordNet relationships. The evaluations show that the accuracy of the approach is well above baseline accuracy."
W14-2625,A Conceptual Framework for Inferring Implicatures,2014,19,3,1,1,34094,janyce wiebe,"Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"While previous sentiment analysis research has concentrated on the interpretation of explicitly stated opinions and attitudes, this work addresses a type of opinion implicature (i.e., opinion-oriented default inference) in real-world text. This work describes a rule-based conceptual framework for representing and analyzing opinion implicatures. In the course of understanding implicatures, the system recognizes implicit sentiments (and beliefs) toward various events and entities in the sentence, often of mixed polarities; thus, it produces a richer interpretation than is typical in opinion analysis."
S14-2010,{S}em{E}val-2014 Task 10: Multilingual Semantic Textual Similarity,2014,25,158,10,0,8824,eneko agirre,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In Semantic Textual Similarity, systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new data sets for English, as well as the introduction of Spanish, as a new language in which to assess semantic similarity. For the English subtask, we exposed the systems to a diversity of testing scenarios, by preparing additional OntoNotesWordNet sense mappings and news headlines, as well as introducing new genres, including image descriptions, DEFT discussion forums, DEFT newswire, and tweet-newswire headline mappings. For Spanish, since, to our knowledge, this is the first time that official evaluations are conducted, we used well-formed text, by featuring sentences extracted from encyclopedic content and newswire. The annotations for both tasks leveraged crowdsourcing. The Spanish subtask engaged 9 teams participating with 22 system runs, and the English subtask attracted 15 teams with 38 system runs."
S14-2098,{S}im{C}ompass: Using Deep Learning Word Embeddings to Assess Cross-level Similarity,2014,30,21,5,0.914606,21353,carmen banea,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This article presents our teamxe2x80x99s participating system at SemEval-2014 Task 3. Using a meta-learning framework, we experiment with traditional knowledgebased metrics, as well as novel corpusbased measures based on deep learning paradigms, paired with varying degrees of context expansion. The framework enabled us to reach the highest overall performance among all competing systems."
E14-1029,Iterative Constrained Clustering for Subjectivity Word Sense Disambiguation,2014,36,3,2,1,25921,cem akkaya,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Subjectivity word sense disambiguation (SWSD) is a supervised and applicationspecific word sense disambiguation task disambiguating between subjective and objective senses of a word. Not surprisingly, SWSD suffers from the knowledge acquisition bottleneck. In this work, we use a xe2x80x9ccluster and labelxe2x80x9d strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset."
E14-1040,Sentiment Propagation via Implicature Constraints,2014,18,46,2,1,8715,lingjia deng,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Opinions may be expressed implicitly via inference over explicit sentiments and events that positively/negatively affect entities (goodFor/badFor events). We investigate how such inferences may be exploited to improve sentiment analysis, given goodFor/badFor event information. We apply Loopy Belief Propagation to propagate sentiments among entities. The graph-based model improves over explicit sentiment classification by 10 points in precision and, in an evaluation of the model itself, we find it has an 89% chance of propagating sentiments correctly."
D14-1125,+/-{E}ffect{W}ord{N}et: Sense-level Lexicon Acquisition for Opinion Inference,2014,26,33,2,1,13794,yoonjung choi,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Recently, work in NLP was initiated on a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities (/-effect events). This paper addresses methods for creating a lexicon of such events, to support such work on opinion inference. Due to significant sense ambiguity, our goal is to develop a sense-level rather than word-level lexicon. To maximize the effectiveness of different types of information, we combine a graph-based method using WordNet 1 relations and a standard classifier using gloss information. A hybrid between the two gives the best results. Further, we provide evidence that the model is an effective way to guide manual annotation to find /-effect senses that are not in the seed set."
C14-1009,Joint Inference and Disambiguation of Implicit Sentiments via Implicature Constraints,2014,30,21,2,1,8715,lingjia deng,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"This paper addresses implicit opinions expressed via inference over explicit sentiments and events that positively/negatively affect entities (goodFor/badFor, gfbf events). We incorporate the inferences developed by implicature rules into an optimization framework, to jointly improve sentiment detection toward entities and disambiguate components of gfbf events. The framework simultaneously beats the baselines by more than 10 points in F-measure on sentiment detection and more than 7 points in accuracy on gfbf polarity disambiguation."
P13-2022,Benefactive/Malefactive Event and Writer Attitude Annotation,2013,10,39,3,1,8715,lingjia deng,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper presents an annotation scheme for events that negatively or positively affect entities (benefactive/malefactive events) and for the attitude of the writer toward their agents and objects. Work on opinion and sentiment tends to focus on explicit expressions of opinions. However, many attitudes are conveyed implicitly, and benefactive/malefactive events are important for inferring implicit attitudes. We describe an annotation scheme and give the results of an inter-annotator agreement study. The annotated corpus is available online."
W12-3810,Recognizing Arguing Subjectivity and Argument Tags,2012,25,30,2,0,42190,alexander conrad,Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics,0,"In this paper we investigate two distinct tasks. The first task involves detecting arguing subjectivity, a type of linguistic subjectivity on which relatively little work has yet to be done. The second task involves labeling instances of arguing subjectivity with argument tags reflecting the conceptual argument being made. We refer to these two tasks collectively as recognizing arguments. We develop a new annotation scheme and assemble a new annotated corpus to support our learning efforts. Through our machine learning experiments, we investigate the utility of a sentiment lexicon, discourse parser, and semantic similarity measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results."
W12-3702,Subjectivity Word Sense Disambiguation,2012,0,8,1,1,34094,janyce wiebe,Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis,0,"Many approaches to opinion and sentiment analysis rely on lexicons of words that may be used to express subjectivity. These are compiled as lists of keywords, rather than word meanings (senses). However, many keywords have both subjective and objective senses. False hits -- subjectivity clues used with objective senses -- are a significant source of error in subjectivity and sentiment analysis. This talk will focus on sense-level opinion and sentiment analysis. First, I will give the results of a study showing that even words judged in previous work to be reliable opinion clues have significant degrees of subjectivity sense ambiguity. Then, we will consider the task of distinguishing between the subjective and objective senses of words in a dictionary, and the related task of creating usage inventories of opinion clues. Given such distinctions, the next step is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses (we call this task SWSD). We will see evidence that SWSD is more feasible than full word sense disambiguation, because it is more coarse grained -- often, the exact sense need not be pinpointed, and that SWSD can be exploited to improve the performance of opinion and sentiment analysis systems via sense-aware classification. Finally, I will discuss experiments in acquiring SWSD data, via token-based context discrimination where the context vector representation is adapted to distinguish between subjective and objective contexts, and the clustering process is enriched by pair-wise constraints, making it semi-supervised."
P12-4004,Multilingual Subjectivity and Sentiment Analysis,2012,3,8,3,0,1124,rada mihalcea,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,"Subjectivity and sentiment analysis focuses on the automatic identification of private states, such as opinions, emotions, sentiments, evaluations, beliefs, and speculations in natural language. While subjectivity classification labels text as either subjective or objective, sentiment classification adds an additional level of granularity, by further classifying subjective text as either positive, negative or neutral.n n While much of the research work in this area has been applied to English, research on other languages is growing, including Japanese, Chinese, German, Spanish, Romanian. While most of the researchers in the field are familiar with the methods applied on English, few of them have closely looked at the original research carried out in other languages. For example, in languages such as Chinese, researchers have been looking at the ability of characters to carry sentiment information (Ku et al., 2005; Xiang, 2011). In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (Banea et al., 2008). These additional sources of information may not be available across all languages, yet, various articles have pointed out that by investigating a synergistic approach for detecting subjectivity and sentiment in multiple languages at the same time, improvements can be achieved not only in other languages, but in English as well. The development and interest in these methods is also highly motivated by the fact that only 27% of Internet users speak English (www.internetworldstats.com/stats.htm, Oct 11, 2011), and that number diminishes further every year, as more people across the globe gain Internet access.n n The aim of this tutorial is to familiarize the attendees with the subjectivity and sentiment research carried out on languages other than English in order to enable and promote cross-fertilization. Specifically, we will review work along three main directions. First, we will present methods where the resources and tools have been specifically developed for a given target language. In this category, we will also briefly overview the main methods that have been proposed for English, but which can be easily ported to other languages. Second, we will describe cross-lingual approaches, including several methods that have been proposed to leverage on the resources and tools available in English by using cross-lingual projections. Finally, third, we will show how the expression of opinions and polarity pervades language boundaries, and thus methods that holistically explore multiple languages at the same time can be effectively considered."
W11-3707,Sense-level Subjectivity in a Multilingual Setting,2011,33,1,3,1,21353,carmen banea,Proceedings of the Workshop on Sentiment Analysis where {AI} meets Psychology ({SAAIP} 2011),0,"This paper explores the ability of senses aligned across languages to carry coherent subjectivity information. We start out with a manual annotation study, and then seek to create an automatic framework to determine subjectivity labeling for unseen senses. We identify two methods that are able to incorporate subjectivity information originating from different languages, namely co-training and multilingual vector spaces, and show that for this task the latter method is better suited and obtains superior results."
W11-0311,Improving the Impact of Subjectivity Word Sense Disambiguation on Contextual Opinion Analysis,2011,32,21,2,1,25921,cem akkaya,Proceedings of the Fifteenth Conference on Computational Natural Language Learning,0,"Subjectivity word sense disambiguation (SWSD) is automatically determining which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. SWSD has been shown to improve the performance of contextual opinion analysis, but only on a small scale and using manually developed integration rules. In this paper, we scale up the integration of SWSD into contextual opinion analysis and still obtain improvements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis."
W10-0731,{A}mazon {M}echanical {T}urk for Subjectivity Word Sense Disambiguation,2010,14,55,3,1,25921,cem akkaya,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"Amazon Mechanical Turk (MTurk) is a marketplace for so-called human intelligence tasks (HITs), or tasks that are easy for humans but currently difficult for automated processes. Providers upload tasks to MTurk which workers then complete. Natural language annotation is one such human intelligence task. In this paper, we investigate using MTurk to collect annotations for Subjectivity Word Sense Disambiguation (SWSD), a coarse-grained word sense disambiguation task. We investigate whether we can use MTurk to acquire good annotations with respect to gold-standard data, whether we can filter out low-quality workers (spammers), and whether there is a learning effect associated with repeatedly completing the same kind of task. While our results with respect to spammers are inconclusive, we are able to obtain high-quality annotations for the SWSD task. These results suggest a greater role for MTurk with respect to constructing a large scale SWSD system in the future, promising substantial improvement in subjectivity and sentiment analysis."
W10-0214,Recognizing Stances in Ideological On-Line Debates,2010,24,183,2,1,12223,swapna somasundaran,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,0,"This work explores the utility of sentiment and arguing opinions for classifying stances in ideological debates. In order to capture arguing opinions in ideological stance taking, we construct an arguing lexicon automatically from a manually annotated corpus. We build supervised systems employing sentiment and arguing opinions and their targets as features. Our systems perform substantially better than a distribution-based baseline. Additionally, by employing both types of opinion features, we are able to perform better than a unigram-based system."
C10-1004,Multilingual Subjectivity: Are More Languages Better?,2010,21,101,3,1,21353,carmen banea,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"While subjectivity related research in other languages has increased, most of the work focuses on single languages. This paper explores the integration of features originating from multiple languages into a machine learning approach to subjectivity analysis, and aims to show that this enriched feature set provides for more effective modeling for the source as well as the target languages. We show not only that we are able to achieve over 75% macro accuracy in all of the six languages we experiment with, but also that by using features drawn from multiple languages we can construct high-precision meta-classifiers with a precision of over 83%."
W09-3210,Opinion Graphs for Polarity and Discourse Classification,2009,30,22,4,1,12223,swapna somasundaran,Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing ({T}ext{G}raphs-4),0,"This work shows how to construct discourse-level opinion graphs to perform a joint interpretation of opinions and discourse relations. Specifically, our opinion graphs enable us to factor in discourse information for polarity classification, and polarity information for discourse-link classification. This inter-dependent framework can be used to augment and improve the performance of local polarity and discourse-link classifiers."
P09-1026,Recognizing Stances in Online Debates,2009,20,198,2,1,12223,swapna somasundaran,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"This paper presents an unsupervised opinion analysis method for debate-side classification, i.e., recognizing which stance a person is taking in an online debate. In order to handle the complexities of this genre, we mine the web to learn associations that are indicative of opinion stances in debates. We combine this knowledge with discourse information, and formulate the debate side classification task as an Integer Linear Programming problem. Our results show that our method is substantially better than challenging baseline methods."
N09-1002,Integrating Knowledge for Subjectivity Sense Labeling,2009,23,20,2,0,47329,yaw gyamfi,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper introduces an integrative approach to automatic word sense subjectivity annotation. We use features that exploit the hierarchical structure and domain information in lexical resources such as WordNet, as well as other types of features that measure the similarity of glosses and the overlap among sets of semantically related words. Integrated in a machine learning framework, the entire set of features is found to give better results than any individual type of feature."
J09-3003,{A}rticles: Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis,2009,60,488,2,1,41211,theresa wilson,Computational Linguistics,0,"Many approaches to automatic sentiment analysis begin with a large lexicon of words marked with their prior polarity (also called semantic orientation). However, the contextual polarity of the phrase in which a particular instance of a word appears may be quite different from the word's prior polarity. Positive words are used in phrases expressing negative sentiments, or vice versa. Also, quite often words that are positive or negative out of context are neutral in context, meaning they are not even being used to express a sentiment. The goal of this work is to automatically distinguish between prior and contextual polarity, with a focus on understanding which features are important for this task. Because an important aspect of the problem is identifying when polar terms are being used in neutral contexts, features for distinguishing between neutral and polar instances are evaluated, as well as features for distinguishing between positive and negative contextual polarity. The evaluation includes assessing the performance of features across multiple machine learning algorithms. For all learning algorithms except one, the combination of all features together gives the best performance. Another facet of the evaluation considers how the presence of neutral instances affects the performance of features for distinguishing between positive and negative polarity. These experiments show that the presence of neutral instances greatly degrades the performance of these features, and that perhaps the best way to improve performance across all polarity classes is to improve the system's ability to identify when an instance is neutral."
J09-2002,Exploiting Semantic Role Resources for Preposition Disambiguation,2009,51,23,2,1,47361,tom ohara,Computational Linguistics,0,"This article describes how semantic role resources can be exploited for preposition disambiguation. The main resources include the semantic role annotations provided by the Penn Treebank and FrameNet tagged corpora. The resources also include the assertions contained in the Factotum knowledge base, as well as information from Cyc and Conceptual Graphs. A common inventory is derived from these in support of definition analysis, which is the motivation for this work.n n The disambiguation concentrates on relations indicated by prepositional phrases, and is framed as word-sense disambiguation for the preposition in question. A new type of feature for word-sense disambiguation is introduced, using WordNet hypernyms as collocations rather than just words. Various experiments over the Penn Treebank and FrameNet data are presented, including prepositions classified separately versus together, and illustrating the effects of filtering. Similar experimentation is done over the Factotum data, including a method for inferring likely preposition usage from corpora, as knowledge bases do not generally indicate how relationships are expressed in English (in contrast to the explicit annotations on this in the Penn Treebank and FrameNet). Other experiments are included with the FrameNet data mapped into the common relation inventory developed for definition analysis, illustrating how preposition disambiguation might be applied in lexical acquisition."
D09-1018,Supervised and Unsupervised Methods in Employing Discourse Relations for Improving Opinion Polarity Classification,2009,31,68,3,1,12223,swapna somasundaran,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This work investigates design choices in modeling a discourse scheme for improving opinion polarity classification. For this, two diverse global inference paradigms are used: a supervised collective classification framework and an unsupervised optimization framework. Both approaches perform substantially better than baseline approaches, establishing the efficacy of the methods and the underlying discourse scheme. We also present quantitative and qualitative analyses showing how the improvements are achieved."
D09-1020,Subjectivity Word Sense Disambiguation,2009,27,119,2,1,25921,cem akkaya,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper investigates a new task, subjectivity word sense disambiguation (SWSD), which is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. We provide empirical evidence that SWSD is more feasible than full word sense disambiguation, and that it can be exploited to improve the performance of contextual subjectivity and sentiment analysis systems."
W08-0122,Discourse Level Opinion Relations: An Annotation Study,2008,16,26,3,1,12223,swapna somasundaran,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"This work proposes opinion frames as a representation of discourse-level associations that arise from related opinion targets and which are common in task-oriented meeting dialogs. We define the opinion frames and explain their interpretation. Additionally we present an annotation scheme that realizes the opinion frames and via human annotation studies, we show that these can be reliably identified."
banea-etal-2008-bootstrapping,A Bootstrapping Method for Building Subjectivity Lexicons for Languages with Scarce Resources,2008,16,113,3,1,21353,carmen banea,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper introduces a method for creating a subjectivity lexicon for languages with scarce resources. The method is able to build a subjectivity lexicon by using a small seed set of subjective words, an online dictionary, and a small raw corpus, coupled with a bootstrapping process that ranks new candidate words based on a similarity measure. Experiments performed with a rule-based sentence level subjectivity classifier show an 18{\%} absolute improvement in F-measure as compared to previously proposed semi-supervised methods."
ruppenhofer-etal-2008-finding,Finding the Sources and Targets of Subjective Expressions,2008,23,59,3,1,3382,josef ruppenhofer,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"As many popular text genres such as blogs or news contain opinions by multiple sources and about multiple targets, finding the sources and targets of subjective expressions becomes an important sub-task for automatic opinion analysis systems. We argue that while automatic semantic role labeling systems (ASRL) have an important contribution to make, they cannot solve the problem for all cases. Based on the experience of manually annotating opinions, sources, and targets in various genres, we present linguistic phenomena that require knowledge beyond that of ASRL systems. In particular, we address issues relating to the attribution of opinions to sources; sources and targets that are realized as zero-forms; and inferred opinions. We also discuss in some depth that for arguing attitudes we need to be able to recover propositions and not only argued-about entities. A recurrent theme of the discussion is that close attention to specific discourse contexts is needed to identify sources and targets correctly."
D08-1014,Multilingual Subjectivity Analysis Using Machine Translation,2008,20,182,3,1,21353,carmen banea,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Although research in other languages is increasing, much of the work in subjectivity analysis has been applied to English data, mainly due to the large body of electronic resources and tools that are available for this language. In this paper, we propose and evaluate methods that can be employed to transfer a repository of subjectivity resources across languages. Specifically, we attempt to leverage on the resources available for English and, by employing machine translation, generate resources for subjectivity analysis in other languages. Through comparative evaluations on two different languages (Romanian and Spanish), we show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language."
C08-1101,Discourse Level Opinion Interpretation,2008,16,63,2,1,12223,swapna somasundaran,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,This work proposes opinion frames as a representation of discourse-level associations which arise from related opinion topics. We illustrate how opinion frames help gather more information and also assist disambiguation. Finally we present the results of our experiments to detect these associations.
W07-1530,Discourse Annotation Working Group Report,2007,0,2,2,0,2824,manfred stede,Proceedings of the Linguistic Annotation Workshop,0,None
P07-1123,Learning Multilingual Subjective Language via Cross-Lingual Projections,2007,22,294,3,0.0254579,1124,rada mihalcea,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,This paper discusses learning multilingual subjective language via cross-lingual projections.
2007.sigdial-1.5,Detecting Arguing and Sentiment in Meetings,2007,22,57,3,1,12223,swapna somasundaran,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,This paper analyzes opinion categories like Sentiment and Arguing in meetings. We first annotate the categories manually. We then develop genre-specific lexicons using interesting function word combinations for detecting the opinions. We analyze relations between dialog structure information and opinion expression in context of multiparty discourse. Finally we show that classifiers using lexical and discourse knowledge have significant improvement over baseline.
W06-2915,Which Side are You on? Identifying Perspectives at the Document and Sentence Levels,2006,22,196,3,0,48044,weihao lin,Proceedings of the Tenth Conference on Computational Natural Language Learning ({C}o{NLL}-X),0,"In this paper we investigate a new problem of identifying the perspective from which a document is written. By perspective we mean a point of view, for example, from the perspective of Democrats or Republicans. Can computers learn to identify the perspective of a document? Not every sentence is written strongly from a perspective. Can computers learn to identify which sentences strongly convey a particular perspective? We develop statistical models to capture how perspectives are expressed at the document and sentence levels, and evaluate the proposed models on articles about the Israeli-Palestinian conflict. The results show that the proposed models successfully learn how perspectives are reflected in word usage and can identify the perspective of a document with high accuracy."
W06-1652,Feature Subsumption for Opinion Analysis,2006,19,185,3,0,10821,ellen riloff,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"Lexical features are key to many approaches to sentiment analysis and opinion detection. A variety of representations have been used, including single words, multi-word Ngrams, phrases, and lexico-syntactic patterns. In this paper, we use a subsumption hierarchy to formally define different types of lexical features and their relationship to one another, both in terms of representational coverage and performance. We use the subsumption hierarchy in two ways: (1) as an analytic tool to automatically identify complex features that outperform simpler features, and (2) to reduce a feature set by removing unnecessary features. We show that reducing the feature set improves performance on three opinion classification tasks, especially when combined with traditional feature selection."
W06-0607,Manual Annotation of Opinion Categories in Meetings,2006,18,12,2,1,12223,swapna somasundaran,Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006,0,"This paper applies the categories from an opinion annotation scheme developed for monologue text to the genre of multiparty meetings. We describe modifications to the coding guidelines that were required to extend the categories to the new type of data, and present the results of an inter-annotator agreement study. As researchers have found with other types of annotations in speech data, inter-annotator agreement is higher when the annotators both read and listen to the data than when they only read the transcripts. Previous work exploited prosodic clues to perform automatic detection of speaker emotion (Liscombe et al. 2003). Our findings suggest that doing so to recognize opinion categories would be a promising line of work."
P06-1134,Word Sense and Subjectivity,2006,27,227,1,1,34094,janyce wiebe,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Subjectivity and meaning are both important properties of language. This paper explores their interaction, and brings empirical evidence in support of the hypotheses that (1) subjectivity is a property that can be associated with word senses, and (2) word sense disambiguation can directly benefit from subjectivity annotations."
W05-0308,Annotating Attributions and Private States,2005,12,62,2,1,41211,theresa wilson,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"This paper describes extensions to a corpus annotation scheme for the manual annotation of attributions, as well as opinions, emotions, sentiments, speculations, evaluations and other private states in language. It discusses the scheme with respect to the Pie in the Sky Check List of Desirable Semantic Information for Annotation. We believe that the scheme is a good foundation for adding private state annotations to other layers of semantic meaning."
H05-2018,{O}pinion{F}inder: A System for Subjectivity Analysis,2005,11,358,5,1,41211,theresa wilson,Proceedings of {HLT}/{EMNLP} 2005 Interactive Demonstrations,0,"OpinionFinder is a system that performs subjectivity analysis, automatically identifying when opinions, sentiments, speculations, and other private states are present in text. Specifically, OpinionFinder aims to identify subjective sentences and to mark various aspects of the subjectivity in these sentences, including the source (holder) of the subjectivity and words that are included in phrases expressing positive or negative sentiments."
H05-1044,Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis,2005,21,2259,2,1,41211,theresa wilson,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a new approach to phrase-level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions. With this approach, the system is able to automatically identify the contextual polarity for a large subset of sentiment expressions, achieving results that are significantly better than baseline."
H05-1116,Multi-Perspective Question Answering Using the {O}p{QA} Corpus,2005,18,111,3,0,4502,veselin stoyanov,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"We investigate techniques to support the answering of opinion-based questions. We first present the OpQA corpus of opinion questions and answers. Using the corpus, we compare and contrast the properties of fact and opinion questions and answers. Based on the disparate characteristics of opinion vs. fact answers, we argue that traditional fact-based QA approaches may have difficulty in an MPQA setting without modification. As an initial step towards the development of MPQA systems, we investigate the use of machine learning and rule-based subjectivity and opinion source filters and show that they can be used to guide MPQA systems."
W04-2116,Empirical Acquisition of Differentiating Relations from Definitions,2004,15,1,2,1,47361,tom ohara,Proceedings of the Workshop on Enhancing and Using Electronic Dictionaries,0,This paper describes a new automatic approach for extracting conceptual distinctions from dictionary definitions. A broad-coverage dependency parser is first used to extract the lexical relations from the definitions. Then the relations are disambiguated using associations learned from tagged corpora. This contrasts with earlier approaches using manually developed rules for disambiguation.
W04-0849,Class-based collocations for Word Sense Disambiguation,2004,10,5,4,1,47361,tom ohara,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,This paper describes the NMSU-Pitt-UNCA word-sense disambiguation system participating in the Senseval-3 English lexical sample task. The focus of the work is on using semantic class-based collocations to augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary definition analysis.
J04-3002,Learning Subjective Language,2004,69,534,1,1,34094,janyce wiebe,Computational Linguistics,0,"Subjectivity in natural language refers to aspects of language used to express opinions, evaluations, and speculations. There are numerous natural language processing applications for which subjectivity analysis is relevant, including information extraction and text categorization. The goal of this work is learning subjective language from corpora. Clues of subjectivity are generated and tested, including low-frequency words, collocations, and adjectives and verbs identified using distributional similarity. The features are also examined working together in concert. The features, generated from different data sets using different procedures, exhibit consistency in performance in that they all do better and worse on the same data sets. In addition, this article shows that the density of subjectivity clues in the surrounding context strongly affects how likely it is that a word is subjective, and it provides the results of an annotation study assessing the subjectivity of sentences with high-density features. Finally, the clues are used to perform opinion piece recognition (a type of text categorization and genre detection) to demonstrate the utility of the knowledge acquired in this article."
W03-2102,Annotating Opinions in the World Press,2003,14,77,2,1,41211,theresa wilson,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,"In this paper we present a detailed scheme for annotating expressions of opinions, beliefs, emotions, sentiment and speculation (private states) in the news and other discourse. We explore inter-annotator agreement for individual private state expressions, and show that these low-level annotations are useful for producing higher-level subjective sentence annotations."
W03-1014,Learning Extraction Patterns for Subjective Expressions,2003,28,743,2,0,10821,ellen riloff,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a bootstrapping process that learns linguistically rich extraction patterns for subjective (opinionated) expressions. High-precision classifiers label unannotated data to automatically create a large training set, which is then given to an extraction pattern learning algorithm. The learned patterns are then used to identify more subjective sentences. The bootstrapping process learns many subjective patterns and increases recall while maintaining high precision."
W03-0404,Learning subjective nouns using extraction pattern bootstrapping,2003,27,417,2,0,10821,ellen riloff,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"We explore the idea of creating a subjectivity classifier that uses lists of subjective nouns learned by bootstrapping algorithms. The goal of our research is to develop a system that can distinguish subjective sentences from objective sentences. First, we use two bootstrapping algorithms that exploit extraction patterns to learn sets of subjective nouns. Then we train a Naive Bayes classifier using the subjective nouns, discourse features, and subjectivity clues identified in prior research. The bootstrapping algorithms learned over 1000 subjective nouns, and the subjectivity classifier performed well, achieving 77% recall with 81% precision."
W03-0411,Preposition Semantic Classification via Treebank and {F}rame{N}et,2003,23,40,2,1,47361,tom ohara,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"This paper reports on experiments in classifying the semantic role annotations assigned to prepositional phrases in both the Penn Treebank and FrameNet. In both cases, experiments are done to see how the prepositions can be classified given the dataset's role inventory, using standard word-sense disambiguation features. In addition to using traditional word collocations, the experiments incorporate class-based collocations in the form of WordNet hypernyms. For Treebank, the word collocations achieve slightly better performance: 78.5% versus 77.4% when separate classifiers are used per preposition. When using a single classifier for all of the prepositions together, the combined approach yields a significant gain at 85.8% accuracy versus 81.3% for word-only collocations. For FrameNet, the combined use of both collocation types achieves better performance for the individual classifiers: 70.3% versus 68.5%. However, classification using a single classifier is not effective due to confusion among the fine-grained roles."
N03-4017,Identifying Opinionated Sentences,2003,7,16,3,1,41211,theresa wilson,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Demonstrations,0,"Natural language processing applications that summarize or answer questions about news and other discourse need to process information about opinions, emotions, and evaluations. For example, a question answering system that could identify opinions in the news could answer questions such as the following:Was the 2002 presidential election in Zimbabwe regarded as fair?What was the world-wide reaction to the 2001 annual U.S. report on human rights?"
W02-2034,Learning to Disambiguate Potentially Subjective Expressions,2002,12,37,1,1,34094,janyce wiebe,{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002),0,"The goal of this work is recognizing opinionated and evaluative (subjective) language in text. The ability to recognize such language would be beneficial for many NLP applications such as question answering, information extraction, summarization, and genre detection. This paper focuses on disambiguating potentially subjective expressions in context, based on the density of other clues in the surrounding text."
W01-1626,A Corpus Study of Evaluative and Speculative Language,2001,22,51,1,1,34094,janyce wiebe,Proceedings of the Second {SIG}dial Workshop on Discourse and Dialogue,0,"This paper presents a corpus study of evaluative and speculative language. Knowledge of such language would be useful in many applications, such as text categorization and summarization. Analyses of annotator agreement and of characteristics of subjective language are performed. This study yields knowledge needed to design effective machine learning systems for identifying subjective language."
C00-1044,Effects of Adjective Orientation and Gradability on Sentence Subjectivity,2000,16,521,2,0,45547,vasileios hatzivassiloglou,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Subjectivity is a pragmatic, sentence-level feature that has important implications for text processing applications such as information extraction and information retrieval. We study the effects of dynamic adjectives, semantically oriented adjectives, and gradable adjectives on a simple subjectivity classifier, and establish that they are strong predictors of subjectivity. A novel trainable method that statistically combines two indicators of gradability is presented and evaluated, complementing existing automatic techniques for assigning orientation labels."
P99-1032,Development and Use of a Gold-Standard Data Set for Subjectivity Classifications,1999,30,334,1,1,34094,janyce wiebe,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,This paper presents a case study of analyzing and improving intercoder reliability in discourse tagging using statistical techniques. Bias-corrected tags are formulated and successfully used to guide a revision of the coding manual and develop an automatic classifier.
J99-2002,Decomposable Modeling in Natural Language Processing,1999,29,40,2,1,51650,rebecca bruce,Computational Linguistics,0,"In this paper, we describe a framework for developing probabilistic classifiers in natural language processing. Our focus is on formulating models that capture the most important interdependencies among features, to avoid overfitting the data while also characterizing the data well. The class of probability models and the associated inference techniques described here were developed in mathematical statistics, and are widely used in artificial intelligence and applied statistics. Our goal is to make this model selection framework accessible to researchers in NLP, and provide pointers to available software and important references. In addition, we describe how the quality of the three determinants of classifier performance (the features, the form of the model, and the parameter estimates) can be separately evaluated. We also demonstrate the classification performance of these models in a large-scale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Hanks 1996). In 10-fold cross-validations, the model search procedure performs significantly better than naive Bayes on 6 of the words without being significantly worse on any of them."
W98-1507,Word-Sense Distinguishability and Inter-Coder Agreement,1998,8,27,2,1,51650,rebecca bruce,Proceedings of the Third Conference on Empirical Methods for Natural Language Processing,0,None
W98-1126,Mapping Collocational Properties into Machine Learning Features,1998,19,16,1,1,34094,janyce wiebe,Sixth Workshop on Very Large Corpora,0,None
W97-0320,An Empirical Approach to Temporal Reference Resolution,1997,0,11,1,1,34094,janyce wiebe,Second Conference on Empirical Methods in Natural Language Processing,0,None
W97-0202,Experience in {W}ord{N}et Sense Tagging in the {W}all {S}treet {J}ournal,1997,11,3,1,1,34094,janyce wiebe,"Tagging Text with Lexical Semantics: Why, What, and How?",0,None
W97-0214,Writing Annotation Instructions,1997,-1,-1,1,1,34094,janyce wiebe,"Tagging Text with Lexical Semantics: Why, What, and How?",0,None
A97-1056,Sequential Model Selection for Word Sense Disambiguation,1997,20,25,3,0,1754,ted pedersen,Fifth Conference on Applied Natural Language Processing,0,"Statistical models of word-sense disambiguation are often based on a small number of contextual features or on a model that is assumed to characterize the interactions among a set of features. Model selection is presented as an alternative to these approaches, where a sequential search of possible models is conducted in order to find the model that best characterizes the interactions among features. This paper expands existing model selection methodology and presents the first comparative study of model selection search strategies and evaluation criteria when applied to the problem of building probabilistic classifiers for word-sense disambiguation."
W96-0210,The Measure of a Model,1996,0,14,2,1,51650,rebecca bruce,Conference on Empirical Methods in Natural Language Processing,0,None
P94-1020,Word-Sense Disambiguation Using Decomposable Models,1994,29,202,2,1,51650,rebecca bruce,32nd Annual Meeting of the Association for Computational Linguistics,1,"Most probabilistic classifiers used for word-sense disambiguation have either been based on only one contextual feature or have used a model that is simply assumed to characterize the interdependencies among multiple contextual features. In this paper, a different approach to formulating a probabilistic model is presented along with a case study of the performance of models produced in this manner for the disambiguation of the noun interest. We describe a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation, without requiring untested assumptions regarding the form of the model. Using this approach, the joint distribution of all variables is described by only the most systematic variable interactions, thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data."
J94-2004,Tracking Point of View in Narrative,1994,41,231,1,1,34094,janyce wiebe,Computational Linguistics,0,"Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Such passages take a character's psychological point of view. A language understander must determine the current psychological point of view in order to distinguish the beliefs of the characters from the facts of the story, to correctly attribute beliefs and other attitudes to their sources, and to understand the discourse relations among sentences. Tracking the psychological point of view is not a trivial problem, because many sentences are not explicitly marked for point of view, and whether the point of view of a sentence is objective or that of a character (and if the latter, which character it is) often depends on the context in which the sentence appears. Tracking the psychological point of view is the problem addressed in this work. The approach is to seek, by extensive examinations of naturally occurring narrative, regularities in the ways that authors manipulate point of view, and to develop an algorithm that tracks point of view on the basis of the regularities found. This paper presents this algorithm, gives demonstrations of an implemented system, and describes the results of some preliminary empirical studies, which lend support to the algorithm."
H94-1047,A New Approach to Word Sense Disambiguation,1994,14,11,2,1,51650,rebecca bruce,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"This paper presents and evaluates models created according to a schema that provides a description of the joint distribution of the values of sense tags and contextual features that is potentially applicable to a wide range of content words. The models are evaluated through a series of experiments, the results of which suggest that the schema is particularly well suited to nouns but that it is also applicable to words in other syntactic categories."
W93-0239,Issues in Linguistic Segmentation,1993,-1,-1,1,1,34094,janyce wiebe,Intentionality and Structure in Discourse Relations,0,None
J92-3012,Book Reviews: Literature and Cognition,1992,-1,-1,1,1,34094,janyce wiebe,Computational Linguistics,0,None
P91-1020,A System for Translating Locative Prepositions From {E}nglish Into {F}rench,1991,6,13,2,0,53830,nathalie japkowicz,29th Annual Meeting of the Association for Computational Linguistics,1,"Machine translation of locative prepositions is not straightforward, even between closely related languages. This paper discusses a system of translation of locative prepositions between English and French. The system is based on the premises that English and French do not always conceptualize objects in the same way, and that this accounts for the major differences in the ways that locative prepositions are used in these languages. This paper introduces knowledge representations of conceptualizations of objects, and a method for translating prepositions based on these conceptual representations."
C90-2069,Identifying Subjective Characters in Narrative,1990,12,51,1,1,34094,janyce wiebe,{COLING} 1990 Volume 2: Papers presented to the 13th International Conference on Computational Linguistics,0,"Part of understanding fictional narrative text is determining for each sentence whether it takes some character's point of view and, if it does, identifying the character whose point of view is taken. This paper presents part of an algorithm for performing the latter. When faced with a sentence that takes a character's point of view, the reader has to decide whether that character is a previously mentioned character or one mentioned in the sentence. We give particular consideration to sentences about private states, such as seeing and wanting, for which both possibilities exist. Our algorithm is based on regularities in the ways that texts initiate, continue, and resume a character's point of view, found during extensive examinations of published novels and short stories."
P88-1016,A Computational Theory of Perspective and Reference in Narrative,1988,22,33,1,1,34094,janyce wiebe,26th Annual Meeting of the Association for Computational Linguistics,1,Narrative passages told from a character's perspective convey the character's thoughts and perceptions. We present a discourse process that recognizes characters' thoughts and perceptions in third-person narrative. An effect of perspective on reference in narrative is addressed: references in passages told from the perspective of a character reflect the character's beliefs. An algorithm that uses the results of our discourse process to understand references with respect to an appropriate set of beliefs is presented.
