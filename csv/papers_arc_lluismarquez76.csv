R19-1141,It Takes Nine to Smell a Rat: Neural Multi-Task Learning for Check-Worthiness Prediction,2019,46,2,3,0,25371,slavena vasileva,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"We propose a multi-task deep-learning approach for estimating the check-worthiness of claims in political debates. Given a political debate, such as the 2016 US Presidential and Vice-Presidential ones, the task is to predict which statements in the debate should be prioritized for fact-checking. While different fact-checking organizations would naturally make different choices when analyzing the same debate, we show that it pays to learn from multiple sources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and Washington Post) in a multi-task learning setup, even when a particular source is chosen as a target to imitate. Our evaluation shows state-of-the-art results on a standard dataset for the task of check-worthiness prediction."
D19-5811,Book {QA}: Stories of Challenges and Opportunities,2019,20,0,5,0,7223,stefanos angelidis,Proceedings of the 2nd Workshop on Machine Reading for Question Answering,0,"We present a system for answering questions based on the full text of books (BookQA), which first selects book passages given a question at hand, and then uses a memory network to reason and predict an answer. To improve generalization, we pretrain our memory network using artificial questions generated from book sentences. We experiment with the recently published NarrativeQA corpus, on the subset of Who questions, which expect book characters as answers. We experimentally show that BERT-based retrieval and pretraining improve over baseline results significantly. At the same time, we confirm that NarrativeQA is a highly challenging data set, and that there is need for novel research in order to achieve high-precision BookQA results. We analyze some of the bottlenecks of the current approach, and we argue that more research is needed on text representation, retrieval of relevant passages, and reasoning, including commonsense knowledge."
N18-5006,{C}laim{R}ank: Detecting Check-Worthy Claims in {A}rabic and {E}nglish,2018,15,8,4,0,11032,israa jaradat,Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"We present ClaimRank, an online system for detecting check-worthy claims. While originally trained on political debates, the system can work for any kind of text, e.g., interviews or just regular news articles. Its aim is to facilitate manual fact-checking efforts by prioritizing the claims that fact-checkers should consider first. ClaimRank supports both Arabic and English, it is trained on actual annotations from nine reputable fact-checking organizations (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and Washington Post), and thus it can mimic the claim selection strategies for each and any of them, as well as for the union of them all."
N18-2004,Integrating Stance Detection and Fact Checking in a Unified Corpus,2018,19,7,4,0,20437,ramy baly,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"A reasonable approach for fact checking a claim involves retrieving potentially relevant documents from different sources (e.g., news websites, social media, etc.), determining the stance of each document with respect to the claim, and finally making a prediction about the claim{'}s factuality by aggregating the strength of the stances, while taking the reliability of the source into account. Moreover, a fact checking system should be able to explain its decision by providing relevant extracts (rationales) from the documents. Yet, this setup is not directly supported by existing datasets, which treat fact checking, document retrieval, source credibility, stance detection and rationale extraction as independent tasks. In this paper, we support the interdependencies between these tasks as annotations in the same corpus. We implement this setup on an Arabic fact checking corpus, the first of its kind."
N18-1070,Automatic Stance Detection Using End-to-End Memory Networks,2018,20,18,5,0,12657,mitra mohtarami,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"We present an effective end-to-end memory network model that jointly (i) predicts whether a given document can be considered as relevant evidence for a given claim, and (ii) extracts snippets of evidence that can be used to reason about the factuality of the target claim. Our model combines the advantages of convolutional and recurrent neural networks as part of a memory network. We further introduce a similarity matrix at the inference level of the memory network in order to extract snippets of evidence for input claims more accurately. Our experiments on a public benchmark dataset, FakeNewsChallenge, demonstrate the effectiveness of our approach."
D18-1452,Joint Multitask Learning for Community Question Answering Using Task-Specific Embeddings,2018,0,3,2,0.432002,3407,shafiq joty,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We address jointly two important tasks for Question Answering in community forums: given a new question, (i) find related existing questions, and (ii) find relevant answers to this new question. We further use an auxiliary task to complement the previous two, i.e., (iii) find good answers with respect to the thread question in a question-comment thread. We use deep neural networks (DNNs) to learn meaningful task-specific embeddings, which we then incorporate into a conditional random field (CRF) model for the multitask setting, performing joint learning over a complex graph structure. While DNNs alone achieve competitive results when trained to produce the embeddings, the CRF, which makes use of the embeddings and the dependencies between the tasks, improves the results significantly and consistently across a variety of evaluation metrics, thus showing the complementarity of DNNs and structured learning."
S17-2003,{S}em{E}val-2017 Task 3: Community Question Answering,2017,0,65,3,0,1636,preslav nakov,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"We describe SemEval{--}2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016: (A) Question{--}Comment Similarity, (B) Question{--}Question Similarity, (C) Question{--}External Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. Additionally, we added a new subtask E in order to enable experimentation with Multi-domain Question Duplicate Detection in a larger-scale scenario, using StackExchange subforums. A total of 23 teams participated in the task, and submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks A{--}D. Unfortunately, no teams participated in subtask E. A variety of approaches and features were used by the participating systems to address the different subtasks. The best systems achieved an official score (MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D, respectively. These scores are better than the baselines, especially for subtasks A{--}C."
gencheva-etal-2017-context,A Context-Aware Approach for Detecting Worth-Checking Claims in Political Debates,2017,20,15,3,1,29273,pepa gencheva,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"In the context of investigative journalism, we address the problem of automatically identifying which claims in a given document are most worthy and should be prioritized for fact-checking. Despite its importance, this is a relatively understudied problem. Thus, we create a new corpus of political debates, containing statements that have been fact-checked by nine reputable sources, and we train machine learning models to predict which claims should be prioritized for fact-checking, i.e., we model the problem as a ranking task. Unlike previous work, which has looked primarily at sentences in isolation, in this paper we focus on a rich input representation modeling the context: relationship between the target statement and the larger context of the debate, interaction between the opponents, and reaction by the moderator and by the public. Our experiments show state-of-the-art results, outperforming a strong rivaling system by a margin, while also confirming the importance of the contextual information."
karadzhov-etal-2017-fully,Fully Automated Fact Checking Using External Sources,2017,25,8,3,0,7697,georgi karadzhov,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Given the constantly growing proliferation of false claims online in recent years, there has been also a growing research interest in automatically distinguishing false rumors from factually true claims. Here, we propose a general-purpose framework for fully-automatic fact checking using external sources, tapping the potential of the entire Web as a knowledge source to confirm or reject a claim. Our framework uses a deep neural network with LSTM text encoding to combine semantic kernels with task-specific embeddings that encode a claim together with pieces of potentially relevant text fragments from the Web, taking the source reliability into account. The evaluation results show good performance on two different tasks and datasets: (i) rumor detection and (ii) fact checking of the answers to a question in community question answering forums."
nakov-etal-2017-trust,Do Not Trust the Trolls: Predicting Credibility in Community Question Answering Forums,2017,0,9,3,0,1636,preslav nakov,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"We address information credibility in community forums, in a setting in which the credibility of an answer posted in a question thread by a particular user has to be predicted. First, we motivate the problem and we create a publicly available annotated English corpus by crowdsourcing. Second, we propose a large set of features to predict the credibility of the answers. The features model the user, the answer, the question, the thread as a whole, and the interaction between them. Our experiments with ranking SVMs show that the credibility labels can be predicted with high performance according to several standard IR ranking metrics, thus supporting the potential usage of this layer of credibility information in practical applications. The features modeling the profile of the user (in particular trollness) turn out to be most important, but embedding features modeling the answer and the similarity between the question and the answer are also very relevant. Overall, half of the gap between the baseline performance and the perfect classifier can be covered using the proposed features."
K17-1024,Cross-language Learning with Adversarial Neural Networks,2017,26,22,3,0.52257,3407,shafiq joty,Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017),0,"We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language. In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages. The evaluation results show sizable improvements for our cross-language adversarial neural network (CLANN) model over a strong non-adversarial system."
J17-4001,Discourse Structure in Machine Translation Evaluation,2017,109,3,3,0.52257,3407,shafiq joty,Computational Linguistics,0,"In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple linear combination with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment level and at the system level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DiscoTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) nuclearity is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality."
I17-1001,Evaluating Layers of Representation in Neural Machine Translation on Part-of-Speech and Semantic Tagging Tasks,2017,0,36,2,0,8869,yonatan belinkov,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"While neural machine translation (NMT) models provide improved translation quality in an elegant framework, it is less clear what they learn about language. Recent work has started evaluating the quality of vector representations learned by NMT models on morphological and syntactic tasks. In this paper, we investigate the representations learned at different layers of NMT encoders. We train NMT systems on parallel data and use the models to extract features for training a classifier on two tasks: part-of-speech and semantic tagging. We then measure the performance of the classifier as a proxy to the quality of the original NMT model for the given task. Our quantitative analysis yields interesting insights regarding representation learning in NMT models. For instance, we find that higher layers are better at learning semantics while lower layers tend to be better for part-of-speech tagging. We also observe little effect of the target language on source-side representations, especially in higher quality models."
S16-1083,{S}em{E}val-2016 Task 3: Community Question Answering,2016,42,81,2,0,1636,preslav nakov,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper describes the SemEvalxe2x80x932016 Task 3 on Community Question Answering, which we offered in English and Arabic. For English, we had three subtasks: Questionxe2x80x93Comment Similarity (subtask A), Questionxe2x80x93Question Similarity (B), and Questionxe2x80x93External Comment Similarity (C). For Arabic, we had another subtask: Rerank the correct answers for a new question (D). Eighteen teams participated in the task, submitting a total of 95 runs (38 primary and 57 contrastive) for the four subtasks. A variety of approaches and features were used by the participating systems to address the different subtasks, which are summarized in this paper. The best systems achieved an official score (MAP) of 79.19, 76.70, 55.41, and 45.83 in subtasks A, B, C, and D, respectively. These scores are significantly better than those for the baselines that we provided. For subtask A, the best system improved over the 2015 winner by 3 points absolute in terms of Accuracy."
S16-1137,{MTE}-{NN} at {S}em{E}val-2016 Task 3: Can Machine Translation Evaluation Help Community Question Answering?,2016,25,13,3,0.753048,7331,francisco guzman,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
P16-2075,Machine Translation Evaluation Meets Community Question Answering,2016,29,21,2,0.753048,7331,francisco guzman,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We explore the applicability of machine translation evaluation (MTE) methods to a very different problem: answer ranking in community Question Answering. In particular, we adopt a pairwise neural network (NN) architecture, which incorporates MTE features, as well as rich syntactic and semantic embeddings, and which efficiently models complex non-linear interactions. The evaluation results show state-of-the-art performance, with sizeable contribution from both the MTE features and from the pairwise NN architecture."
N16-1084,Joint Learning with Global Inference for Comment Classification in Community Question Answering,2016,11,11,2,0.52257,3407,shafiq joty,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
N16-1153,Semi-supervised Question Retrieval with Gated Convolutions,2016,19,32,7,0.666667,4452,tao lei,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
D16-1165,It Takes Three to Tango: Triangulation Approach to Answer Ranking in Community Question Answering,2016,27,9,2,0,1636,preslav nakov,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
C16-2001,An Interactive System for Exploring Community Question Answering Forums,2016,8,2,3,0,18000,enamul hoque,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,We present an interactive system to provide effective and efficient search capabilities in Community Question Answering (cQA) forums. The system integrates state-of-the-art technology for answer search with a Web-based user interface specifically tailored to support the cQA forum readers. The answer search module automatically finds relevant answers for a new question by exploring related questions and the comments within their threads. The graphical user interface presents the search results and supports the exploration of related information. The system is running live at \url{http://www.qatarliving.com/betasearch/}.
W15-4908,Document-Level Machine Translation with Word Vector Models,2015,30,3,3,1,16565,eva garcia,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"In this paper we apply distributional semantic information to document-level machine translation. We train monolingual and bilingual word vector models on large corpora and we evaluate them first in a cross-lingual lexical substitution task and then on the final translation task. For translation, we incorporate the semantic information in a statistical document-level decoder (Docent), by enforcing translation choices that are semantically similar to the context. As expected, the bilingual word vector models are more appropriate for the purpose of translation. The final document-level translator incorporatingn the semantic model outperforms the basic Docent (without semantics) and alson performs slightly over a standard sentence level SMT system in terms of ULC (the average of a set of standard automatic evaluation metrics for MT). Finally, we also present some manual analysis of the translations of some concrete documents"
W15-3402,A Factory of Comparable Corpora from {W}ikipedia,2015,39,10,4,1,15265,alberto barroncedeno,Proceedings of the Eighth Workshop on Building and Using Comparable Corpora,0,"Multiple approaches to grab comparable data from the Web have been developed up to date. Nevertheless, coming out with a high-quality comparable corpus of a specific topic is not straightforward. We present a model for the automatic extraction of comparable texts in multiple languages and on specific topics from Wikipedia. In order to prove the value of the model, we automatically extract parallel sentences from the comparable collections and use them to train statistical machine translation engines for specific domains. Our experiments on the Englishxe2x80x90 Spanish pair in the domains of Computer Science, Science, and Sports show that our in-domain translator performs significantly better than a generic one when translating in-domain Wikipedia articles. Moreover, we show that these corpora can help when translating out-of-domain texts."
S15-2036,{QCRI}: Answer Selection for Community Question Answering - Experiments for {A}rabic and {E}nglish,2015,13,26,11,0,7095,massimo nicosia,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes QCRIxe2x80x99s participation in SemEval-2015 Task 3 xe2x80x9cAnswer Selection in Community Question Answeringxe2x80x9d, which targeted real-life Web forums, and was offered in both Arabic and English. We apply a supervised machine learning approach considering a manifold of features including among others word n-grams, text similarity, sentiment analysis, the presence of specific words, and the context of a comment. Our approach was the best performing one in the Arabic subtask and the third best in the two English subtasks."
S15-2047,{S}em{E}val-2015 Task 3: Answer Selection in Community Question Answering,2015,23,85,2,0,1636,preslav nakov,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"Community Question Answering (cQA) provides new interesting research directions to the traditional Question Answering (QA) field, e.g., the exploitation of the interaction between users and the structure of related posts. In this context, we organized SemEval2015 Task 3 on Answer Selection in cQA, which included two subtasks: (a) classifying answers as good, bad, or potentially relevant with respect to the question, and (b) answering a YES/NO question with yes, no, or unsure, based on the list of all answers. We set subtask A for Arabic and English on two relatively different cQA domains, i.e., the Qatar Living website for English, and a Quran-related website for Arabic. We used crowdsourcing on Amazon Mechanical Turk to label a large English training dataset, which we released to the research community. Thirteen teams participated in the challenge with a total of 61 submissions: 24 primary and 37 contrastive. The best systems achieved an official score (macro-averaged F1) of 57.19 and 63.7 for the English subtasks A and B, and 78.55 for the Arabic subtask A."
P15-2113,Thread-Level Information for Comment Classification in Community Question Answering,2015,26,17,5,1,15265,alberto barroncedeno,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Community Question Answering (cQA) is a new application of QA in social contexts (e.g., fora). It presents new interesting challenges and research directions, e.g., exploiting the dependencies between the different comments of a thread to select the best answer for a given question. In this paper, we explored two ways of modeling such dependencies: (i) by designing specific features looking globally at the thread; and (ii) by applying structure prediction models. We trained and evaluated our models on data from SemEval-2015 Task 3 on Answer Selection in cQA. Our experiments show that: (i) the thread-level features consistently improve the performance for a variety of machine learning models, yielding state-of-the-art results; and (ii) sequential dependencies between the answer labels captured by structured prediction models are not enough to improve the results, indicating that more information is needed in the joint model."
P15-1078,Pairwise Neural Machine Translation Evaluation,2015,31,28,3,0.972222,7331,francisco guzman,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"We present a novel framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is compacted into relatively small distributed vector representations, and fed into a multi-layer neural network that models the interaction between each of the hypotheses and the reference, as well as between the two hypotheses. These compact representations are in turn based on word and sentence embeddings, which are learned using neural networks. The framework is flexible, allows for efficient learning and classification, and yields correlation with humans that rivals the state of the art."
N15-1121,High-Order Low-Rank Tensors for Semantic Role Labeling,2015,27,9,3,0.666667,4452,tao lei,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper introduces a tensor-based approach to semantic role labeling (SRL). The motivation behind the approach is to automatically induce a compact feature representation for words and their relations, tailoring them to the task. In this sense, our dimensionality reduction method provides a clear alternative to the traditional feature engineering approach used in SRL. To capture meaningful interactions between the argument, predicate, their syntactic path and the corresponding role label, we compress each feature representation first to a lower dimensional space prior to assessing their interactions. This corresponds to using an overall cross-product feature representation and maintaining associated parameters as a four-way low-rank tensor. The tensor parameters are optimized for the SRL performance using standard online algorithms. Our tensor-based approach rivals the best performing system on the CoNLL-2009 shared task. In addition, we demonstrate that adding the representation tensor to a competitive tensorfree model yields 2% absolute increase in Fscore. 1"
D15-1068,Global Thread-level Inference for Comment Classification in Community Question Answering,2015,26,17,5,0.550509,3407,shafiq joty,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Community Question Answering (cQA) is a new application of QA in social contexts (e.g., fora). It presents new interesting challenges and research directions, e.g., exploiting the dependencies between the different comments of a thread to select the best answer for a given question. In this paper, we explored two ways of modeling such dependencies: (i) by designing specific features looking globally at the thread; and (ii) by applying structure prediction models. We trained and evaluated our models on data from SemEval-2015 Task 3 on Answer Selection in cQA. Our experiments show that: (i) the thread-level features consistently improve the performance for a variety of machine learning models, yielding state-of-the-art results; and (ii) sequential dependencies between the answer labels captured by structured prediction models are not enough to improve the results, indicating that more information is needed in the joint model."
2015.eamt-1.9,Document-Level Machine Translation with Word Vector Models,2015,30,3,3,1,16565,eva garcia,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"In this paper we apply distributional semantic information to document-level machine translation. We train monolingual and bilingual word vector models on large corpora and we evaluate them first in a cross-lingual lexical substitution task and then on the final translation task. For translation, we incorporate the semantic information in a statistical document-level decoder (Docent), by enforcing translation choices that are semantically similar to the context. As expected, the bilingual word vector models are more appropriate for the purpose of translation. The final document-level translator incorporatingn the semantic model outperforms the basic Docent (without semantics) and alson performs slightly over a standard sentence level SMT system in terms of ULC (the average of a set of standard automatic evaluation metrics for MT). Finally, we also present some manual analysis of the translations of some concrete documents"
W14-4015,Word{'}s Vector Representations meet Machine Translation,2014,10,3,4,1,16565,eva garcia,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,Distributed vector representations of words are useful in various NLP tasks. We briefly review the CBOW approach and propose a bilingual application of this architecture with the aim to improve consistency and coherence of Machine Translation. The primary goal of the bilingual extension is to handle ambiguous words for which the different senses are conflated in the monolingual setup.
W14-3351,{IPA} and {STOUT}: Leveraging Linguistic and Source-based Features for Machine Translation Evaluation,2014,22,3,3,1,18034,meritxell gonzalez,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the UPC submissions to the WMT14 Metrics Shared Task: UPCIPA and UPC-STOUT. These metrics use a collection of evaluation measures integrated in ASIYA, a toolkit for machine translation evaluation. In addition to some standard metrics, the two submissions take advantage of novel metrics that consider linguistic structures, lexical relationships, and semantics to compare both source and reference translation against the candidate translation. The new metrics are available for several target languages other than English. In the the official WMT14 evaluation, UPC-IPA and UPC-STOUT scored above the average in 7 out of 9 language pairs at the system level and 8 out of 9 at the segment level."
W14-3352,{D}isco{TK}: Using Discourse Structure for Machine Translation Evaluation,2014,20,29,3,0.550509,3407,shafiq joty,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We present novel automatic metrics for machine translation evaluation that use discourse structure and convolution kernels to compare the discourse tree of an automatic translation with that of the human reference. We experiment with five transformations and augmentations of a base discourse tree representation based on the rhetorical structure theory, and we combine the kernel scores for each of them into a single score. Finally, we add other metrics from the ASIYA MT evaluation toolkit, and we tune the weights of the combination on actual human judgments. Experiments on the WMT12 and WMT13 metrics shared task datasets show correlation with human judgments that outperforms what the best systems that participated in these years achieved, both at the segment and at the system level."
P14-1065,Using Discourse Structure Improves Machine Translation Evaluation,2014,44,40,3,0.972222,7331,francisco guzman,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present experiments in using discourse structure for improving machine translation evaluation. We first design two discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory. Then, we show that these measures can help improve a number of existing machine translation evaluation metrics both at the segment- and at the system-level. Rather than proposing a single new metric, we show that discourse information is complementary to the state-of-the-art evaluation metrics, and thus should be taken into account in the development of future richer evaluation metrics."
D14-1027,Learning to Differentiate Better from Worse Translations,2014,30,7,3,0.972222,7331,francisco guzman,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference. We integrate several layers of linguistic information encapsulated in tree-based structures, making use of both the reference and the system output simultaneously, thus bringing our ranking closer to how humans evaluate translations. Most importantly, instead of deciding upfront which types of features are important, we use the learning framework of preference re-ranking kernels to learn the features automatically. The evaluation results show that learning in the proposed framework yields better correlation with humans than computing the direct similarity over the same type of structures. Also, we show our structural kernel learning (SKL) can be a general framework for MT evaluation, in which syntactic and semantic information can be naturally incorporated."
D14-1049,A Shortest-path Method for Arc-factored Semantic Role Labeling,2014,18,0,3,1,40104,xavier lluis,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We introduce a Semantic Role Labeling (SRL) parser that finds semantic roles for a predicate together with the syntactic paths linking predicates and arguments. Our main contribution is to formulate SRL in terms of shortest-path inference, on the assumption that the SRL model is restricted to arc-factored features of the syntactic paths behind semantic roles. Overall, our method for SRL is a novel way to exploit larger variability in the syntactic realizations of predicate-argument relations, moving away from pipeline architectures. Experiments show that our approach improves the robustness of the predictions, producing arc-factored models that perform closely to methods using unrestricted features from the syntax."
D14-1050,Semantic Kernels for Semantic Parsing,2014,39,6,4,0,37202,iman saleh,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We present an empirical study on the use of semantic information for Concept Segmentation and Labeling (CSL), which is an important step for semantic parsing. We represent the alternative analyses output by a state-of-the-art CSL parser with tree structures, which we rerank with a classifier trained on two types of semantic tree kernels: one processing structures built with words, concepts and Brown clusters, and another one using semantic similarity among the words composing the structure. The results on a corpus from the restaurant domain show that our semantic kernels exploiting similarity measures outperform state-of-the-art rerankers."
C14-1020,A Study of using Syntactic and Semantic Structures for Concept Segmentation and Labeling,2014,26,5,5,0,37202,iman saleh,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"This paper presents an empirical study on using syntactic and semantic information for Concept Segmentation and Labeling (CSL), a well-known component in spoken language understanding. Our approach is based on reranking N -best outputs from a state-of-the-art CSL parser. We perform extensive experimentation by comparing different tree-based kernels with a variety of representations of the available linguistic information, including semantic concepts, words, POS tags, shallow and full syntax, and discourse trees. The results show that the structured representation with the semantic concepts yields significant improvement over the base CSL parser, much larger compared to learning with an explicit feature vector representation. We also show that shallow syntax helps improve the results and that discourse relations can be partially beneficial."
W13-2215,"The {TALP}-{UPC} Phrase-Based Translation Systems for {WMT}13: System Combination with Morphology Generation, Domain Adaptation and Corpus Filtering",2013,18,5,6,0.853659,40950,lluis formiga,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes the TALP participation in the WMT13 evaluation campaign. Our participation is based on the combination of several statistical machine translation systems: based on standard phrasebased Moses systems. Variations include techniques such as morphology generation, training sentence filtering, and domain adaptation through unit derivation. The results show a coherent improvement on TER, METEOR, NIST, and BLEU scores when compared to our baseline system."
W13-2244,The {TALP}-{UPC} Approach to System Selection: {A}siya Features and Pairwise Classification Using Random Forests,2013,19,3,5,0.853659,40950,lluis formiga,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes the TALP-UPC participation in the WMTxe2x80x9913 Shared Task on Quality Estimation (QE). Our participation is reduced to task 1.2 on System Selection. We used a broad set of features (86 for German-to-English and 97 for English-to-Spanish) ranging from standard QE features to features based on pseudo-references and semantic similarity. We approached system selection by means of pairwise ranking decisions. For that, we learned Random Forest classifiers especially tailored for the problem. Evaluation at development time showed considerably good results in a cross-validation experiment, with Kendallxe2x80x99s values around 0.30. The results on the test set dropped significantly, raising different discussions to be taken into account."
S13-1020,{UPC}-{CORE}: What Can Machine Translation Evaluation Metrics and {W}ikipedia Do for Estimating Semantic Textual Similarity?,2013,11,2,2,1,15265,alberto barroncedeno,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"In this paper we discuss our participation ton the 2013 Semeval Semantic Textual Similarityn task. Our core features include (i) a set of metrics borrowed from automatic machine translation, originally intended to evaluate automatic against reference translations and (ii) an instance of explicit semantic analysis, built upon opening paragraphs of Wikipedia 2010 articles. Our similarity estimator relies on a support vector regressor with RBF kernel. Our best approach required 13 machine translation metrics  explicit semantic analysis and ranked 65 in the competition. Our postcompetitionn analysis shows that the features have a good expression level, but overfitting and xe2x80x94mainlyxe2x80x94 normalization issues caused our correlation values to decrease."
Q13-1018,Joint Arc-factored Parsing of Syntactic and Semantic Dependencies,2013,33,20,3,1,40104,xavier lluis,Transactions of the Association for Computational Linguistics,0,"In this paper we introduce a joint arc-factored model for syntactic and semantic dependency parsing. The semantic role labeler predicts the full syntactic paths that connect predicates with their arguments. This process is framed as a linear assignment task, which allows to control some well-formedness constraints. For the syntactic part, we define a standard arc-factored dependency model that predicts the full syntactic tree. Finally, we employ dual decomposition techniques to produce consistent syntactic and predicate-argument structures while searching over a large space of syntactic configurations. In experiments on the CoNLL-2009 English benchmark we observe very competitive results."
P13-4031,t{SEARCH}: Flexible and Fast Search over Automatic Translations for Improved Quality/Error Analysis,2013,13,1,3,1,18034,meritxell gonzalez,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"This work presents tSEARCH, a web-based application that provides mechanisms for doing complex searches over a collection of translation cases evaluated with a large set of diverse measures. tSEARCH uses the evaluation results obtained with the ASIYA toolkit for MT evaluation and it is connected to its on-line GUI, which makes possible a graphical visualization and interactive access to the evaluation results. The search engine offers a flexible query language allowing to find translation examples matching a combination of numerical and structural features associated to the calculation of the quality metrics. Its database design permits a fast response time for all queries supported on realistic-size test beds. In summary, tSEARCH, used with ASIYA, offers developers of MT systems and evaluation metrics a powerful tool for helping translation and error analysis."
J13-3006,Selectional Preferences for Semantic Role Classification,2013,57,22,3,1,37296,benat zapirain,Computational Linguistics,0,"This paper focuses on a well-known open issue in Semantic Role Classification (SRC) research: the limited influence and sparseness of lexical features. We mitigate this problem using models that integrate automatically learned selectional preferences (SP). We explore a range of models based on WordNet and distributional-similarity SPs. Furthermore, we demonstrate that the SRC task is better modeled by SP models centered on both verbs and prepositions, rather than verbs alone. Our experiments with SP-based models in isolation indicate that they outperform a lexical baseline with 20 F1 points in domain and almost 40 F1 points out of domain. Furthermore, we show that a state-of-the-art SRC system extended with features based on selectional preferences performs significantly better, both in domain (17% error reduction) and out of domain (13% error reduction). Finally, we show that in an end-to-end semantic role labeling system we obtain small but statistically significant improvements, even though our modifie..."
2013.mtsummit-posters.10,{MT} Techniques in a Retrieval System of Semantically Enriched Patents,2013,11,1,5,1,18034,meritxell gonzalez,Proceedings of Machine Translation Summit XIV: Posters,0,This paper focuses on how automaticn translation techniques integrated in an patent retrieval system increase its capabilities and make possible extended features and functionalities. We describe 1)n a novel methodology for natural languagen to SPARQL translation based on a grammarxe2x80x93n ontology interoperability automation and a query grammar for the patents domain; 2) a devised strategy for statisticalbasedn translation of patents that allows to transfer semantic annotations to the targetn language; 3) a built-in knowledge representation infrastructure that uses multilingual semantic annotations; and 4) an online application that offers a multilingualn search interface over structural knowledgen databases (domain ontologies) and multilingual documents (biomedical patents)n that have been automatically translated.
2013.mtsummit-papers.9,Real-life Translation Quality Estimation for {MT} System Selection,2013,4,5,2,0.853659,40950,lluis formiga,Proceedings of Machine Translation Summit XIV: Papers,0,"Research on translation quality annotation and estimation usually makes use of standard language, sometimes related to a specific language genre or domain. However, real-life machine translation (MT), performed for instance by on-line translation services, has to cope with some extra dif- ficulties related to the usage of open, non-standard and noisy language. In this paper we study the learning of quality estimation (QE) models able to rank translations from real-life input according to their goodness without the need of translation references. For that, we work with a corpus collected from the 24/7 Reverso.net MT service, translated by 5 different MT systems, and manually annotated with quality scores. We define several families of features and train QE predictors in the form of regressors or direct rankers. The predictors show a remarkable correlation with gold standard rankings and prove to be useful in a system combination scenario, obtaining better results than any individual translation system."
2013.mtsummit-european.8,{FAUST}: Feedback Analysis for User Adaptive Statistical Translation,2013,-1,-1,2,0,40052,william byrne,Proceedings of Machine Translation Summit XIV: European projects,0,None
W12-3115,The {UPC} Submission to the {WMT} 2012 Shared Task on Quality Estimation,2012,10,16,3,1,20383,daniele pighin,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"In this paper, we describe the UPC system that participated in the WMT 2012 shared task on Quality Estimation for Machine Translation. Based on the empirical evidence that fluencyrelated features have a very high correlation with post-editing effort, we present a set of features for the assessment of quality estimation for machine translation designed around different kinds of n-gram language models, plus another set of features that model the quality of dependency parses automatically projected from source sentences to translations. We document the results obtained on the shared task dataset, obtained by combining the features that we designed with the baseline features provided by the task organizers."
P12-3024,A Graphical Interface for {MT} Evaluation and Error Analysis,2012,12,19,3,1,18034,meritxell gonzalez,Proceedings of the {ACL} 2012 System Demonstrations,0,"Error analysis in machine translation is a necessary step in order to investigate the strengths and weaknesses of the MT systems under development and allow fair comparisons among them. This work presents an application that shows how a set of heterogeneous automatic metrics can be used to evaluate a test bed of automatic translations. To do so, we have set up an online graphical interface for the Asiya toolkit, a rich repository of evaluation measures working at different linguistic levels. The current implementation of the interface shows constituency and dependency trees as well as shallow syntactic and semantic annotations, and word alignments. The intelligent visualization of the linguistic structures used by the metrics, as well as a set of navigational functionalities, may lead towards advanced methods for automatic error analysis."
pighin-etal-2012-analysis,An Analysis (and an Annotated Corpus) of User Responses to Machine Translation Output,2012,3,5,2,1,20383,daniele pighin,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present an annotated resource consisting of open-domain translation requests, automatic translations and user-provided corrections collected from casual users of the translation portal http://reverso.net. The layers of annotation provide: 1) quality assessments for 830 correction suggestions for translations into English, at the segment level, and 2) 814 usefulness assessments for English-Spanish and English-French translation suggestions, a suggestion being useful if it contains at least local clues that can be used to improve translation quality. We also discuss the results of our preliminary experiments concerning 1) the development of an automatic filter to separate useful from non-useful feedback, and 2) the incorporation in the machine translation pipeline of bilingual phrases extracted from the suggestions. The annotated data, available for download from ftp://mi.eng.cam.ac.uk/data/faust/LW-UPC-Oct11-FAUST-feedback-annotation.tgz, is released under a Creative Commons license. To our best knowledge, this is the first resource of this kind that has ever been made publicly available."
pighin-etal-2012-faust,The {FAUST} Corpus of Adequacy Assessments for Real-World Machine Translation Output,2012,6,5,2,1,20383,daniele pighin,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present a corpus consisting of 11,292 real-world English to Spanish automatic translations annotated with relative (ranking) and absolute (adequate/non-adequate) quality assessments. The translation requests, collected through the popular translation portal http://reverso.net, provide a most variated sample of real-world machine translation (MT) usage, from complete sentences to units of one or two words, from well-formed to hardly intelligible texts, from technical documents to colloquial and slang snippets. In this paper, we present 1) a preliminary annotation experiment that we carried out to select the most appropriate quality criterion to be used for these data, 2) a graph-based methodology inspired by Interactive Genetic Algorithms to reduce the annotation effort, and 3) the outcomes of the full-scale annotation experiment, which result in a valuable and original resource for the analysis and characterization of MT-output quality."
2012.freeopmt-1.7,Deep evaluation of hybrid architectures: use of different metrics in {MERT} weight optimization,2012,-1,-1,4,1,5030,cristina espanabonet,Proceedings of the Third International Workshop on Free/Open-Source Rule-Based Machine Translation,0,None
2012.eamt-1.15,Context-Aware Machine Translation for Software Localization,2012,5,4,4,0,43860,victor muntesmulero,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"Software localization requires translating short text strings appearing in user interfaces (UI) into several languages. These strings are usually unrelated to the other strings in the UI. Due to the lack of semantic context, many ambiguity problems cannot be solved during translation. However, UI are composed of several visual components to which text strings are associated. Although this association might be very valuable for word disambiguation, it has not been exploited. In this paper, we present the problem of lack of context awareness for UI localization, providing real examples and identifying the main research challenges."
2012.eamt-1.61,A Hybrid System for Patent Translation,2012,20,13,4,1,36791,ramona enache,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"This work presents a HMT system for patent translation. The system exploits the high coverage of SMT and the high precision of an RBMT system based on GF to deal with specific issues of the language. The translator is specifically developed to translate patents and it is evaluated in the English-French language pair. Although the number of issues tackled by the grammar are not extremely numerous yet, both manual and automatic evaluations consistently show their preference for the hybrid system in front of the two individual translators."
2012.amta-papers.13,A Graph-based Strategy to Streamline Translation Quality Assessments,2012,17,4,3,1,20383,daniele pighin,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We present a detailed analysis of a graph-based annotation strategy that we employed to annotate a corpus of 11,292 real-world English to Spanish automatic translations with relative (ranking) and absolute (adequate/non-adequate) quality assessments. The proposed approach, inspired by previous work in Interactive Evolutionary Computation and Interactive Genetic Algorithms, results in a simpler and faster annotation process. We empirically compare the method against a traditional, explicit ranking approach, and show that the graph-based strategy: 1) is considerably faster, and 2) produces consistently more reliable annotations."
W11-1001,Automatic Projection of Semantic Structures: an Application to Pairwise Translation Ranking,2011,18,7,2,1,20383,daniele pighin,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"We present a model for the inclusion of semantic role annotations in the framework of confidence estimation for machine translation. The model has several interesting properties, most notably: 1) it only requires a linguistic processor on the (generally well-formed) source side of the translation; 2) it does not directly rely on properties of the translation model (hence, it can be applied beyond phrase-based systems). These features make it potentially appealing for system ranking, translation re-ranking and user feedback evaluation. Preliminary experiments in pairwise hypothesis ranking on five confidence estimation benchmarks show that the model has the potential to capture salient aspects of translation quality."
2011.mtsummit-wpt.7,Patent translation within the {MOLTO} project,2011,9,16,5,1,5030,cristina espanabonet,Proceedings of the 4th Workshop on Patent Translation,0,"MOLTO is an FP7 European project whose goal is to translate texts between multiple languages in real time with high quality. Patents translation is a case of study where research is focused on simultaneously obtaining a large coverage without loosing quality in the translation. This is achieved by hybridising between a grammar-based multilingual translation system, GF, and a specialised statistical machine translation system. Moreover, both individual systems by themselves already represent a step forward in the translation of patents in the biomedical domain, for which the systems have been trained."
2011.mtsummit-papers.63,Hybrid Machine Translation Guided by a Rule{--}Based System,2011,11,17,4,1,5030,cristina espanabonet,Proceedings of Machine Translation Summit XIII: Papers,0,"This paper presents a machine translation architecture which hybridizes Matxin, a rulebased system, with regular phrase-based Statistical Machine Translation. In short, the hybrid translation process is guided by the rulebased engine and, before transference, a set of partial candidate translations provided by SMT subsystems is used to enrich the treebased representation. The final hybrid translation is created by choosing the most probable combination among the available fragments with a statistical decoder in a monotonic way.n We have applied the hybrid model to a pairn of distant languages, Spanish and Basque, andn according to our evaluation (both automaticn and manual) the hybrid approach significantlyn outperforms the best SMT system on out-of-domain data."
W10-1750,Document-Level Automatic {MT} Evaluation based on Discourse Representations,2010,11,21,3,0,36865,elisabet comelles,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the joint submission of Universitat Politecnica de Catalunya and Universitat de Barcelona to the Metrics MaTr 2010 evaluation challenge, in collaboration with ELDA/ELRA. Our work is aimed at widening the scope of current automatic evaluation measures from sentence to document level. Preliminary experiments, based on an extension of the metrics by Gimenez and Marquez (2009) operating over discourse representations, are presented."
S10-1001,{S}em{E}val-2010 Task 1: Coreference Resolution in Multiple Languages,2010,24,99,2,0.555556,28963,marta recasens,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This paper presents the SemEval-2010 task on Coreference Resolution in Multiple Languages. The goal was to evaluate and compare automatic coreference resolution systems for six different languages (Catalan, Dutch, English, German, Italian, and Spanish) in four evaluation settings and using four different metrics. Such a rich scenario had the potential to provide insight into key issues concerning coreference resolution: (i) the portability of systems across languages, (ii) the relevance of different levels of linguistic information, and (iii) the behavior of scoring metrics."
N10-1058,Improving Semantic Role Classification with Selectional Preferences,2010,10,14,3,1,37296,benat zapirain,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This work incorporates Selectional Preferences (SP) into a Semantic Role (SR) Classification system. We learn separate selectional preferences for noun phrases and prepositional phrases and we integrate them in a state-of-the-art SR classification system both in the form of features and individual class predictors. We show that the inclusion of the refined SPs yields statistically significant improvements on both in domain and out of domain data (14.07% and 11.67% error reduction, respectively). The key factor for success is the combination of several SP methods with the original classification model using meta-classification."
2010.eamt-1.15,Robust Estimation of Feature Weights in Statistical Machine Translation,2010,18,4,2,1,5030,cristina espanabonet,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"Weights of the various components in a standard Statistical Machine Translation model are usually estimated via Minimum Error Rate Training. With this, one finds their optimum value on a development set with the expectation that these optimal weights generalise well to other test sets. However, this is not always the case when domains differ. This work uses a perceptron algorithm to learn more robust weights to be used on out-of-domain corpora without the need for specialised data. For an Arabic-to-English translation system, the generalisation of weights represents an improvement of more than 2 points of BLEU with respect to the MERT baseline using the same information."
W09-2411,{S}em{E}val-2010 Task 1: Coreference Resolution in Multiple Languages,2009,0,4,4,0.555556,28963,marta recasens,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"This paper presents the task Coreferencen Resolution in Multiple Languages to be runn in SemEval-2010 (5th International Workshopn on Semantic Evaluations). This task aims ton evaluate and compare automatic coreferencen resolution systems for three different languages (Catalan, English, and Spanish) byn means of two alternative evaluation metrics,n thus providing an insight into (i) the portability of coreference resolution systems across languages, and (ii) the effect of different scoring metrics on ranking the output of the participantn systems."
W09-1201,The {C}o{NLL}-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages,2009,26,269,6,0,17503,jan hajivc,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"For the 11th straight year, the Conference on Computational Natural Language Learning has been accompanied by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2009, the shared task was dedicated to the joint parsing of syntactic and semantic dependencies in multiple languages. This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task. In this paper, we define the shared task, describe how the data sets were created and show their quantitative properties, report the results and summarize the approaches of the participating systems."
W09-1212,A Second-Order Joint Eisner Model for Syntactic and Semantic Dependency Parsing,2009,17,16,3,1,40104,xavier lluis,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"We present a system developed for the CoNLL-2009 Shared Task (Hajic et al., 2009). We extend the Carreras (2007) parser to jointly annotate syntactic and semantic dependencies. This state-of-the-art parser factorizes the built tree in second-order factors. We include semantic dependencies in the factors and extend their score function to combine syntactic and semantic scores. The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method. Our averaged results for all seven languages are 71.49 macro F1, 79.11 LAS and 63.06 semantic F1."
W09-0440,On the Robustness of Syntactic and Semantic Features for Automatic {MT} Evaluation,2009,17,12,2,1,29307,jesus gimenez,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"Linguistic metrics based on syntactic and semantic information have proven very effective for Automatic MT Evaluation. However, no results have been presented so far on their performance when applied to heavily ill-formed low quality translations. In order to glean some light into this issue, in this work we present an empirical study on the behavior of a heterogeneous set of metrics based on linguistic analysis in the paradigmatic case of speech translation between non-related languages. Corroborating previous findings, we have verified that metrics based on deep linguistic analysis exhibit a very robust and stable behavior at the system level. However, these metrics suffer a significant decrease at the sentence level. This is in many cases attributable to a loss of recall, due to parsing errors or to a lack of parsing at all, which may be partially ameliorated by backing off to lexical similarity."
P09-5003,"Semantic Role Labeling: Past, Present and Future",2009,104,8,1,1,25372,lluis marquez,Tutorial Abstracts of {ACL}-{IJCNLP} 2009,0,"Semantic Role Labeling (SRL) consists of, given a sentence, detecting basic event structures such as who did what to whom, when and where. From a linguistic point of view, a key component of the task corresponds to identifying the semantic arguments filling the roles of the sentence predicates. Typical predicate semantic arguments include Agent, Patient, and Instrument, but semantic roles may also be found as adjuncts (e.g., Locative, Temporal, Manner, and Cause). The identification of such event frames holds potential for significant impact in many NLP applications, such as Information Extraction, Question Answering, Summarization and Machine Translation."
P09-2019,Generalizing over Lexical Features: Selectional Preferences for Semantic Role Classification,2009,9,21,3,1,37296,benat zapirain,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"This paper explores methods to alleviate the effect of lexical sparseness in the classification of verbal arguments. We show how automatically generated selectional preferences are able to generalize and perform better than lexical features in a large dataset for semantic role classification. The best results are obtained with a novel second-order distributional similarity measure, and the positive effect is specially relevant for out-of-domain data. Our findings suggest that selectional preferences have potential for improving a full system for Semantic Role Labeling."
W08-2121,The {C}o{NLL} 2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies,2008,34,372,4,0.562478,673,mihai surdeanu,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"The Conference on Computational Natural Language Learning is accompanied every year by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2008 the shared task was dedicated to the joint parsing of syntactic and semantic dependencies. This shared task not only unifies the shared tasks of the previous four years under a unique dependency-based formalism, but also extends them significantly: this year's syntactic dependencies include more information such as named-entity boundaries; the semantic dependencies model roles of both verbal and nominal predicates. In this paper, we define the shared task and describe how the data sets were created. Furthermore, we report and analyze the results and describe the approaches of the participating systems."
W08-2124,A Joint Model for Parsing Syntactic and Semantic Dependencies,2008,9,16,2,1,40104,xavier lluis,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"This paper describes a system that jointly parses syntactic and semantic dependencies, presented at the CoNLL-2008 shared task (Surdeanu et al., 2008). It combines online Peceptron learning (Collins, 2002) with a parsing model based on the Eisner algorithm (Eisner, 1996), extended so as to jointly assign syntactic and semantic labels. Overall results are 78.11 global F1, 85.84 LAS, 70.35 semantic F1. Official results for the shared task (63.29 global F1; 71.95 LAS; 54.52 semantic F1) were significantly lower due to bugs present at submission time."
W08-0332,A Smorgasbord of Features for Automatic {MT} Evaluation,2008,8,55,2,1,29307,jesus gimenez,Proceedings of the Third Workshop on Statistical Machine Translation,0,"This document describes the approach by the NLP Group at the Technical University of Catalonia (UPC-LSI), for the shared task on Automatic Evaluation of Machine Translation at the ACL 2008 Third SMT Workshop."
P08-1063,Robustness and Generalization of Role Sets: {P}rop{B}ank vs. {V}erb{N}et,2008,10,17,3,1,37296,benat zapirain,Proceedings of ACL-08: HLT,1,"This paper presents an empirical study on the robustness and generalization of two alternative role sets for semantic role labeling: PropBank numbered roles and VerbNet thematic roles. By testing a statexe2x80x93ofxe2x80x93thexe2x80x93art SRL system with the two alternative role annotations, we show that the PropBank role set is more robust to the lack of verbxe2x80x93specific semantic information and generalizes better to infrequent and unseen predicates. Keeping in mind that thematic roles are better for application needs, we also tested the best way to generate VerbNet annotation. We conclude that tagging first PropBank roles and mapping into VerbNet roles is as effective as training and tagging directly on VerbNet, and more robust for domain shifts."
gimenez-marquez-2008-towards,Towards Heterogeneous Automatic {MT} Error Analysis,2008,21,9,2,1,29307,jesus gimenez,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This work studies the viability of performing heterogeneous automatic MT error analyses. Error analysis is, undoubtly, one of the most crucial stages in the development cycle of an MT system. However, often not enough attention is paid to this process. The reason is that performing an accurate error analysis requires intensive human labor. In order to speed up the error analysis process, we suggest partially automatizing it by having automatic evaluation metrics play a more active role. For that purpose, we have compiled a large and heterogeneous set of features at different linguistic levels and at different levels of granularity. Through a practical case study, we show how these features provide an effective means of ellaborating interpretable and detailed automatic reports of translation quality."
J08-2001,Special Issue Introduction: Semantic Role Labeling: An Introduction to the Special Issue,2008,48,167,1,1,25372,lluis marquez,Computational Linguistics,0,"Semantic role labeling, the computational identification and labeling of arguments in text, has become a leading task in computational linguistics today. Although the issues for this task have been studied for decades, the availability of large resources and the development of statistical machine learning methods have heightened the amount of effort in this field. This special issue presents selected and representative work in the field. This overview describes linguistic background of the problem, the movement from linguistic theories to computational practice, the major resources that are being used, an overview of steps taken in computational systems, and a description of the key issues and results in semantic role labeling (as revealed in several international evaluations). We assess weaknesses in semantic role labeling and identify important challenges facing the field. Overall, the opportunities and the potential for useful further research in semantic role labeling are considerable."
I08-1042,Heterogeneous Automatic {MT} Evaluation Through Non-Parametric Metric Combinations,2008,22,12,2,1,29307,jesus gimenez,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"Combining different metrics into a single measure of quality seems the most direct and natural way to improve over the quality of individual metrics. Recently, several approaches have been suggested (Kulesza and Shieber, 2004; Liu and Gildea, 2007; Albrecht and Hwa, 2007a). Although based on different assumptions, these approaches share the common characteristic of being parametric. Their models involve a number of parameters whose weight must be adjusted. As an alternative, in this work, we study the behaviour of non-parametric schemes, in which metrics are combined without having to adjust their relative importance. Besides, rather than limiting to the lexical dimension, we work on a wide set of metrics operating at different linguistic levels (e.g., lexical, syntactic and semantic). Experimental results show that non-parametric methods are a valid means of putting different quality dimensions together, thus tracing a possible path towards heterogeneous automatic MT evaluation."
W07-0719,Context-aware Discriminative Phrase Selection for Statistical Machine Translation,2007,24,39,2,1,29307,jesus gimenez,Proceedings of the Second Workshop on Statistical Machine Translation,0,"In this work we revise the application of discriminative learning to the problem of phrase selection in Statistical Machine Translation. Inspired by common techniques used in Word Sense Disambiguation, we train classifiers based on local context to predict possible phrase translations. Our work extends that of Vickrey et al. (2005) in two main aspects. First, we move from word translation to phrase translation. Second, we move from the 'blank-filling' task to the 'full translation' task. We report results on a set of highly frequent source phrases, obtaining a significant improvement, specially with respect to adequacy, according to a rigorous process of manual evaluation."
W07-0738,Linguistic Features for Automatic Evaluation of Heterogenous {MT} Systems,2007,22,87,2,1,29307,jesus gimenez,Proceedings of the Second Workshop on Statistical Machine Translation,0,"Evaluation results recently reported by Callison-Burch et al. (2006) and Koehn and Monz (2006), revealed that, in certain cases, the BLEU metric may not be a reliable MT quality indicator. This happens, for instance, when the systems under evaluation are based on different paradigms, and therefore, do not share the same lexicon. The reason is that, while MT quality aspects are diverse, BLEU limits its scope to the lexical dimension. In this work, we suggest using metrics which take into account linguistic features at more abstract levels. We provide experimental results showing that metrics based on deeper linguistic information (syntactic/shallow-semantic) are able to produce more reliable system rankings than metrics based on lexical matching alone, specially when the systems under evaluation are of a different nature."
S07-1008,{S}em{E}val-2007 Task 09: Multilevel Semantic Annotation of {C}atalan and {S}panish,2007,3,29,1,1,25372,lluis marquez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we describe SemEval-2007 task number 9 (Multilevel Semantic Annotation of Catalan and Spanish). In this task, we aim at evaluating and comparing automatic systems for the annotation of several semantic linguistic levels for Catalan and Spanish. Three semantic levels are considered: noun sense disambiguation, named entity recognition, and semantic role labeling."
S07-1077,{UBC}-{UPC}: Sequential {SRL} Using Selectional Preferences. An approach with Maximum Entropy {M}arkov Models,2007,8,7,3,1,37296,benat zapirain,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We present a sequential Semantic Role Labeling system that describes the tagging problem as a Maximum Entropy Markov Model. The system uses full syntactic information to select BIO-tokens from input data, and classifies them sequentially using state-of-the-art features, with the addition of Selectional Preference features. The system presented achieves competitive performance in the CoNLL-2005 shared task dataset and it ranks first in the SRL subtask of the Semeval-2007 task 17."
S07-1095,{UPC}: Experiments with Joint Learning within {S}em{E}val Task 9,2007,7,5,1,1,25372,lluis marquez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes UPC's participation in the SemEval-2007 task 9 (Marquez et al., 2007). We addressed all four subtasks using supervised learning. The paper introduces several novel issues: (a) for the SRL task, we propose a novel reranking algorithm based on the re-ranking Perceptron of Collins and Duffy (2002); and (b) for the same task we introduce a new set of global features that extract information not only at proposition level but also from the complete set of frame candidates. We show that in the SemEval setting, i.e., small training corpora, this approach outperforms previous work. Additionally, we added NSD and NER information in the global SRL model but this experiment was unsuccessful."
W06-3126,The {LDV}-{COMBO} system for {SMT},2006,19,3,2,1,29307,jesus gimenez,Proceedings on the Workshop on Statistical Machine Translation,0,"We describe the LDV-COMBO system presented at the Shared Task. Our approach explores the possibility of working with alignments at different levels of abstraction using different degrees of linguistic analysis from the lexical to the shallow syntactic level. Translation models are built on top of combinations of these alignments. We present results for the Spanish-to-English and English-to-Spanish tasks. We show that liniguistic information may be helpful, specially when the target language has a rich morphology."
W06-2925,Projective Dependency Parsing with Perceptron,2006,17,25,3,1,7024,xavier carreras,Proceedings of the Tenth Conference on Computational Natural Language Learning ({C}o{NLL}-X),0,"We describe an online learning dependency parser for the CoNLL-X Shared Task, based on the bottom-up projective algorithm of Eisner (2000). We experiment with a large feature set that models: the tokens involved in dependencies and their immediate context, the surface-text distance between tokens, and the syntactic context dominated by each dependency. In experiments, the treatment of multilingual information was totally blind."
P06-2003,{MT} Evaluation: Human-Like vs. Human Acceptable,2006,14,22,4,0,22853,enrique amigo,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"We present a comparative study on Machine Translation Evaluation according to two different criteria: Human Likeness and Human Acceptability. We provide empirical evidence that there is a relationship between these two kinds of evaluation: Human Likeness implies Human Acceptability but the reverse is not true. From the point of view of automatic evaluation this implies that metrics based on Human Likeness are more reliable for system tuning.n n Our results also show that current evaluation metrics are not always able to distinguish between automatic and human translations. In order to improve the descriptive power of current metrics we propose the use of additional syntax-based metrics, and metric combinations inside the QARLA Framework."
P06-2037,Low-Cost Enrichment of {S}panish {W}ord{N}et with Automatically Translated Glosses: Combining General and Specialized Models,2006,17,5,2,1,29307,jesus gimenez,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"This paper studies the enrichment of Spanish WordNet with synset glosses automatically obtained from the English Word-Net glosses using a phrase-based Statistical Machine Translation system. We construct the English-Spanish translation system from a parallel corpus of proceedings of the European Parliament, and study how to adapt statistical models to the domain of dictionary definitions. We build specialized language and translation models from a small set of parallel definitions and experiment with robust manners to combine them. A statistically significant increase in performance is obtained. The best system is finally used to generate a definition for all Spanish synsets, which are currently ready for a manual revision. As a complementary issue, we analyze the impact of the amount of in-domain data needed to improve a system trained entirely on out-of-domain data."
moreno-etal-2006-generation,Generation of Language Resources for the Development of Speech Technologies in {C}atalan,2006,1,5,3,0,50506,moreno,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes a joint initiative of the Catalan and Spanish Government to produce Language Resources for the Catalan language. A similar methodology to the Basic Language Resource Kit (BLARK) concept was applied to determine the priorities on the production of the Language Resources. The paper shows the LR and tools currently available for the Catalan Language both for Language and Speech technologies. The production of large databases for Automatic Speech Recognition purposes already started. All the resources generated in the project follow EU standards, will be validated by an external centre and will be free and public available through ELRA."
W05-0826,Combining Linguistic Data Views for Phrase-based {SMT},2005,12,10,2,1,29307,jesus gimenez,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"We describe the Spanish-to-English LDV-COMBO system for the Shared Task 2: Exploiting Parallel Texts for Statistical Machine Translation of the ACL-2005 Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond. Our approach explores the possibility of working with alignments at different levels of abstraction, using different degrees of linguistic annotation. Several phrase-based translation models are built out from these alignments. Their combination significatively outperforms any of them in isolation. Moreover, we have built a word-based translation model based on WordNet which is used for unknown words."
W05-0620,Introduction to the {C}o{NLL}-2005 Shared Task: Semantic Role Labeling,2005,37,498,2,1,7024,xavier carreras,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"In this paper we describe the CoNLL-2005 shared task on Semantic Role Labeling. We introduce the specification and goals of the task, describe the data sets and evaluation methods, and present a general overview of the 19 systems that have contributed to the task, providing a comparative description and results."
W05-0628,Semantic Role Labeling as Sequential Tagging,2005,4,40,1,1,25372,lluis marquez,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"In this paper we present a semantic role labeling system submitted to the CoNLL-2005 shared task. The system makes use of partial and full syntactic information and converts the task into a sequential BIO-tagging. As a result, the labeling architecture is very simple. Building on a state-of-the-art set of features, a binary classifier for each label is trained using AdaBoost with fixed depth decision trees. The final system, which combines the outputs of two base systems performed F1=76.59 on the official test set. Additionally, we provide results comparing the system when using partial vs. full parsing input information."
H05-1081,A Robust Combination Strategy for Semantic Role Labeling,2005,16,17,1,1,25372,lluis marquez,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper focuses on semantic role labeling using automatically-generated syntactic information. A simple and robust strategy for system combination is presented, which allows to partially recover from input parsing errors and to significantly boost results of individual systems. This combination scheme is also very flexible since the individual systems are not required to provide any information other than their solution. Extensive experimental evaluation in the CoNLL-2005 shared task framework supports our previous claims. The proposed architecture outperforms the best results reported in that evaluation exercise."
W04-2412,Introduction to the {C}o{NLL}-2004 Shared Task: Semantic Role Labeling,2004,28,221,2,1,7024,xavier carreras,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,"In this paper we describe the CoNLL-2004 shared task: semantic role labeling. We introduce the specification and goal of the task, describe the data sets and evaluation methods, and present a general overview of the systems that have contributed to the task, providing comparative description."
W04-2415,Hierarchical Recognition of Propositional Arguments with Perceptrons,2004,4,28,2,1,7024,xavier carreras,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,None
W04-0806,Senseval-3: The {S}panish lexical sample task,2004,2,8,1,1,25372,lluis marquez,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
W04-0828,{TALP} system for the {E}nglish lexical sample task,2004,4,11,2,1,51637,gerard escudero,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
W04-0836,Senseval-3: The {C}atalan lexical sample task,2004,0,3,1,1,25372,lluis marquez,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
W04-0861,The {``}Meaning{''} system on the {E}nglish all-words task,2004,0,4,2,0,49095,luis villarejo,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
gimenez-marquez-2004-svmtool,{SVMT}ool: A general {POS} Tagger Generator Based on Support Vector Machines,2004,6,296,2,1,29307,jesus gimenez,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents the SVMTool, a simple, flexible, effective and efficient partxe2x80x93ofxe2x80x93speech tagger based on Support Vector Machines. The SVMTool offers a fairly good balance among these properties which make it really practical for current NLP applications. It is very easy to use and easily configurable so as to perfectly fit the needs of a number of different applications. Results are also very competitive, achieving an accuracy of 97.16% for English on the Wall Street Journal corpus. It has been also successfully applied to Spanish exhibiting a similar performance. A first release of the SVMTool Perl prototype is now freely available for public use. A most efficient C version is coming very soon."
W03-2903,Automatic Lexical Acquisition from Raw Corpora: An Application to {R}ussian,2003,7,1,3,0,17853,antoni oliver,Proceedings of the 2003 {EACL} Workshop on Morphological Processing of {S}lavic Languages,0,"This paper presents a methodology for the automatic acquisition of lexical and morpho-syntactic information from raw corpora. The system uses information about the inflectional morphology declared by rules and is based on the co-occurrence of different forms of the same paradigm in the corpus. A direct application of this methodology gives very poor precision rates due to rule interaction between paradigms. We present a rule analysis algorithm that solves this problem, giving quite better precision rates, although recall decreases dramatically. Finally, we investigate some techniques to raise the recall, achieving recall rates around 67% with a precision of 92%."
W03-1504,Low-cost Named Entity Classification for {C}atalan: Exploiting Multilingual Resources and Unlabeled Data,2003,8,4,1,1,25372,lluis marquez,Proceedings of the {ACL} 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,0,"This work studies Named Entity Classification (NEC) for Catalan without making use of large annotated resources of this language. Two views are explored and compared, namely exploiting solely the Catalan resources, and a direct training of bilingual classification models (Spanish and Catalan), given that a large collection of annotated examples is available for Spanish. The empirical results obtained on real data point out that multilingual models clearly outperform monolingual ones, and that the resulting Catalan NEC models are easier to improve by bootstrapping on unlabelled data."
W03-0421,A Simple Named Entity Extractor using {A}da{B}oost,2003,5,63,2,1,7024,xavier carreras,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"This paper presents a Named Entity Extraction (NEE) system for the CoNLL-2003 shared task competition. As in the past year edition (Carreras et al., 2002a), we have approached the task by treating the two main subxe2x80x93tasks of the problem, recognition (NER) and classification (NEC), sequentially and independently with separate modules. Both modules are machine learning based systems, which make use of binary and multiclass AdaBoost classifiers. Named Entity recognition is performed as a greedy sequence tagging procedure under the wellxe2x80x93known BIO labelling scheme. This tagging process makes use of three binary classifiers trained to be experts on the recognition of B, I, and O labels, respectively. Named Entity classification is viewed as a 4xe2x80x93class classification problem (with LOC, PER, ORG, and MISC class labels), which is straightforwardly addressed by the use of a multiclass learning algorithm. The system presented here consists of a replication, with some minor changes, of the system that obtained the best results in the CoNLL-2002 NEE task. Therefore, it can be considered as a benchmark of the statexe2x80x93ofxe2x80x93thexe2x80x93 art technology for the current edition, and will allow also to make comparisons about the training corpora of both editions."
W03-0422,Learning a Perceptron-Based Named Entity Chunker via Online Recognition Feedback,2003,5,21,2,1,7024,xavier carreras,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"We present a novel approach for the problem of Named Entity Recognition and Classification (NERC), in the context of the CoNLL-2003 Shared Task."
E03-1038,Named Entity Recognition For {C}atalan Using Only {S}panish Resources and Unlabelled Data,2003,0,3,2,1,7024,xavier carreras,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
W02-2004,Named Entity Extraction using {A}da{B}oost,2002,4,146,2,1,7024,xavier carreras,{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002),0,"This paper presents a Named Entity Extraction (NEE) system for the CoNLL 2002 competition. The two main sub-tasks of the problem, recognition (NER) and classification (NEC), are performed sequentially and independently with separate modules. Both modules are machine learning based systems, which make use of binary AdaBoost classifiers."
C02-1112,Syntactic Features for High Precision Word Sense Disambiguation,2002,15,26,3,0,13902,david martinez,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper explores the contribution of a broad range of syntactic features to WSD: grammatical relations coded as the presence of adjuncts/arguments in isolation or as subcategorization frames, and instantiated grammatical relations between words. We have tested the performance of syntactic features using two different ML algorithms (Decision Lists and AdaBoost) on the Senseval-2 data. Adding syntactic features to a basic set of traditional features improves performance, especially for AdaBoost. In addition, several methods to build arbitrarily high accuracy WSD systems are also tried, showing that syntactic features allow for a precision of 86% and a coverage of 26% or 95% precision and 8% coverage."
W01-0726,Boosting trees for clause splitting,2001,1,52,2,1,7024,xavier carreras,Proceedings of the {ACL} 2001 Workshop on Computational Natural Language Learning ({C}on{LL}),0,"We present a system for the CoNLL-2001 shared task: the clause splitting problem. Our approach consists in decomposing the clause splitting problem into a combination of binary simple decisions, which we solve with the AdaBoost learning algorithm. The whole problem is decomposed in two levels, with two chained decisions per level. The first level corresponds to parts 1 and 2 presented in the introductory document for the task. The second level corresponds to the part 3, which we decompose in two decisions and a combination procedure."
S01-1017,Using {L}azy{B}oosting for Word Sense Disambiguation,2001,9,10,2,1,51637,gerard escudero,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"This paper describes the architecture and results of the TALP system presented at the SENSEVAL-2 exercise for the English lexical--sample task. This system is based on the LazyBoosting algorithm for Word Sense Disambiguation (Escudero et al., 2000), and incorporates some improvements and adaptations to this task. The evaluation reported here includes an analysis of the contribution of each component to the overall system performance."
W00-1322,An Empirical Study of the Domain Dependence of Supervised Word Disambiguation Systems,2000,28,52,2,1,51637,gerard escudero,2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"This paper describes a set of experiments carried out to explore the domain dependence of alternative supervised Word Sense Disambiguation algorithms. The aim of the work is threefold: studying the performance of these algorithms when tested on a different corpus from that they were trained on; exploring their ability to tune to new domains, and demonstrating empirically that the Lazy-Boosting algorithm outperforms state-of-the-art supervised WSD algorithms in both previous situations."
W00-0706,A Comparison between Supervised Learning Algorithms for Word Sense Disambiguation,2000,30,26,2,1,51637,gerard escudero,Fourth Conference on Computational Natural Language Learning and the Second Learning Language in Logic Workshop,0,"This paper describes a set of comparative experiments, including cross-corpus evaluation, between five alternative algorithms for supervised Word Sense Disambiguation (WSD), namely Naive Bayes, Exemplar-based learning, SNoW, Decision Lists, and Boosting. Two main conclusions can be drawn: 1) The LazyBoosting algorithm outperforms the other four state-of-the-art algorithms in terms of accuracy and ability to tune to new domains; 2) The domain dependence of WSD systems seems very strong and suggests that some kind of adaptation or tuning is required for cross-corpus application."
W99-0608,Improving {POS} Tagging Using Machine-Learning Techniques,1999,28,15,1,1,25372,lluis marquez,1999 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"In this paper we show how machine learning techniques for constructing and combining several classifiers can be applied to improve the accuracy of an existing English POS tagger (MSxquez and Rodrfguez, 1997). Additionally, the problem of data sparseness is also addressed by applying a technique of generating convez pseudo-data (Breiman, 1998). Experimental results and a comparison to other s ta te-oftheart tuggers are reported. K e y w o r d s : POS Tagging, Corpus-based modeling, Decision Trees, Ensembles of Classifiers."
P98-2164,On the Evaluation and Comparison of Taggers: the Effect of Noise in Testing Corpora,1998,4,18,2,0,26974,lluis padro,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"This paper addresses the issue of POS tagger evaluation. Such evaluation is usually performed by comparing the tagger output with a reference test corpus, which is assumed to be error-free. Currently used corpora contain noise which causes the obtained performance to be a distortion of the real value. We analyze to what extent this distortion may invalidate the comparison between taggers or the measure of the improvement given by a new system. The main conclusion is that a more rigorous testing experimentation setting/designing is needed to reliably evaluate and compare tagger accuracies."
C98-2159,On the Evaluation and Comparison of Taggers: the Effect of Noise in Testing Corpora.,1998,4,18,2,0,26974,lluis padro,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"This paper addresses the issue of POS tagger evaluation. Such evaluation is usually performed by comparing the tagger output with a reference test corpus, which is assumed to be error-free. Currently used corpora contain noise which causes the obtained performance to be a distortion of the real value. We analyze to what extent this distortion may invalidate the comparison between taggers or the measure of the improvement given by a new system. The main conclusion is that a more rigorous testing experimentation setting/designing is needed to reliably evaluate and compare tagger accuracies."
P97-1031,A Flexible {POS} Tagger Using an Automatically Acquired Language Model,1997,25,21,1,1,25372,lluis marquez,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"We present an algorithm that automatically learns context constraints using statistical decision trees. We then use the acquired constraints in a flexible POS tagger. The tagger is able to use information of any degree: n-grams, automatically learned context constraints, linguistically motivated manually written constraints, etc. The sources and kinds of constraints are unrestricted, and the language model can be easily extended, improving the results. The tagger has been tested and evaluated on the WSJ corpus."
