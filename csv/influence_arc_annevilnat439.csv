2002.jeptalnrecital-long.28,P99-1044,0,0.0119111,"re longueur qui le forment. L&apos;analyse de la question se fonde sur l&apos;utilisation d&apos;un analyseur robuste dans le but d&apos;extraire plusieurs informations de la question, informations utiles pour la sélection de phrases ou pour l’extraction de la réponse. Cette partie sera développée dans la section suivante. Le module de traitement des documents utilise les sorties fournies par le NIST1, résultat de l&apos;application d’un moteur de recherche de type vectoriel sur le corpus de documents pour l’ensemble des questions de l’évaluation TREC. Les 200 meilleurs documents sont ré-indexés par le système FASTR (Jacquemin, 1999), analyseur transformationnel de surface qui reconnaît les occurrences et les variantes des termes produits par le module d&apos;extraction de 1 Le NIST est l’organisateur des conférences TREC. 309 Ferret O., Grau B., Hurault-Plantet M., Illouz G., Monceaux L., Robba I., Vilnat A. termes. Chaque occurrence ou variante constitue un index qui est ensuite utilisé dans le processus de classement des documents. En effet, ces index permettent à QALC de réordonner les documents et de sélectionner les plus pertinents (Ferret et al. 2001). Le module de reconnaissance des entités nommées est ensuite appliqué"
2003.jeptalnrecital-long.9,A97-1012,0,0.0518277,"Missing"
2003.jeptalnrecital-long.9,P02-1054,0,0.031363,"pté pour la recherche des réponses dans la collection de référence doublée d&apos; une autre dans une autre source d’informations afin de confronter les résultats des deux recherches. Le principe est de favoriser des réponses trouvées dans les deux sources, par rapport aux réponses, même fortement pondérées, mais trouvées dans une seule collection. Un tel raisonnement s’applique d’autant mieux que les sources de connaissances sont de nature différente, ainsi notre deuxième recherche s’effectue sur le Web, qui, de surcroît, par sa diversité et sa redondance conduit à trouver de nombreuses réponses (Magnini et al., 2002a et 2002b ; Clarke et al., 2001 ; Brill et al., 2001). Après la présentation générale de notre système, QALC, section 2, nous décrivons section 3 la reformulation des questions pour interroger le Web. La section 4 présente ensuite l’extraction des réponses pour une seule source de connaissances, et la section 5 les stratégies pour réaliser le choix final. Les résultats de QALC sont décrits en section 6 avant de rapprocher notre travail de ce qui existe dans le domaine. 2 Le système QALC Le système QALC (figure 1) participe aux évaluations TREC depuis 4 ans et a été conçu pour rechercher des r"
2004.jeptalnrecital-long.32,J93-2004,0,0.0234603,"Missing"
2004.jeptalnrecital-long.32,C96-2120,0,0.0690649,"Missing"
2006.jeptalnrecital-long.20,W02-1033,0,0.0939832,"Missing"
2007.jeptalnrecital-poster.17,C00-1039,0,0.0313156,"Missing"
2007.jeptalnrecital-poster.24,abeille-etal-2000-building,0,0.129185,"Missing"
2007.jeptalnrecital-poster.24,H91-1060,0,0.0349069,"Missing"
2007.jeptalnrecital-poster.24,E03-1085,1,0.899581,"Missing"
2007.jeptalnrecital-poster.24,J93-2004,0,0.0276908,"Missing"
2007.jeptalnrecital-poster.24,C96-2120,0,0.100692,"Missing"
2007.jeptalnrecital-poster.24,paroubek-etal-2006-data,1,0.859225,"Missing"
2007.jeptalnrecital-poster.24,roark-etal-2006-sparseval,0,0.0289417,"Missing"
2007.jeptalnrecital-poster.24,vilnat-etal-2004-ongoing,1,0.89069,"Missing"
2009.jeptalnrecital-court.26,rosset-petel-2006-ritel,1,0.885696,"Missing"
2009.jeptalnrecital-court.26,toney-etal-2008-evaluation,1,0.881957,"Missing"
2009.jeptalnrecital-demonstration.2,J08-4005,0,0.0548956,"Missing"
2009.jeptalnrecital-demonstration.2,2008.jeptalnrecital-long.23,1,0.755463,"Missing"
2009.jeptalnrecital-demonstration.2,N03-1024,0,0.0677999,"Missing"
2010.jeptalnrecital-court.18,P05-1074,0,0.148687,"Missing"
2010.jeptalnrecital-court.18,N03-1003,0,0.0954374,"Missing"
2010.jeptalnrecital-court.18,2010.jeptalnrecital-recital.5,1,0.496316,"Missing"
2010.jeptalnrecital-court.18,D08-1021,0,0.100887,"Missing"
2010.jeptalnrecital-court.18,C08-1013,0,0.149237,"Missing"
2010.jeptalnrecital-court.18,P99-1044,0,0.228551,"Missing"
2010.jeptalnrecital-court.18,N03-1016,0,0.0475047,"Missing"
2010.jeptalnrecital-court.18,2008.jeptalnrecital-long.23,1,0.853768,"Missing"
2010.jeptalnrecital-court.18,J03-1002,0,0.0123418,"Missing"
2010.jeptalnrecital-court.18,N03-1024,0,0.563199,"Missing"
2010.jeptalnrecital-court.25,W09-3007,0,0.0550101,"Missing"
2010.jeptalnrecital-court.25,doddington-etal-2004-automatic,0,0.0630594,"Missing"
2010.jeptalnrecital-court.25,2009.jeptalnrecital-long.17,0,0.0619111,"Missing"
2010.jeptalnrecital-long.27,P06-1034,0,0.0437718,"Missing"
2011.jeptalnrecital-court.7,P06-1114,0,0.0337413,"Missing"
2011.jeptalnrecital-court.7,quintard-etal-2010-question,1,0.881271,"Missing"
2011.jeptalnrecital-court.9,P06-2022,0,0.0701731,"Missing"
2011.jeptalnrecital-court.9,doddington-etal-2004-automatic,0,0.0347708,"Missing"
2011.jeptalnrecital-court.9,2002.jeptalnrecital-long.22,0,0.0936818,"Missing"
2011.jeptalnrecital-long.38,P05-1074,0,0.0841195,"Missing"
2011.jeptalnrecital-long.38,N03-1003,0,0.0657265,"Missing"
2011.jeptalnrecital-long.38,P01-1008,0,0.146473,"Missing"
2011.jeptalnrecital-long.38,2010.jeptalnrecital-recital.5,1,0.812219,"Missing"
2011.jeptalnrecital-long.38,2010.jeptalnrecital-court.18,1,0.783574,"Missing"
2011.jeptalnrecital-long.38,D08-1021,0,0.0432575,"Missing"
2011.jeptalnrecital-long.38,C08-1013,0,0.0271679,"Missing"
2011.jeptalnrecital-long.38,C10-1027,1,0.871956,"Missing"
2011.jeptalnrecital-long.38,W09-3102,0,0.0252497,"Missing"
2011.jeptalnrecital-long.38,I05-5002,0,0.054168,"Missing"
2011.jeptalnrecital-long.38,P08-4006,0,0.0400888,"Missing"
2011.jeptalnrecital-long.38,W03-1608,0,0.0648712,"Missing"
2011.jeptalnrecital-long.38,P99-1044,0,0.11808,"Missing"
2011.jeptalnrecital-long.38,N06-1058,0,0.0538278,"Missing"
2011.jeptalnrecital-long.38,P07-2045,0,0.00674383,"Missing"
2011.jeptalnrecital-long.38,P98-1116,0,0.0309369,"Missing"
2011.jeptalnrecital-long.38,2008.jeptalnrecital-long.23,1,0.87252,"Missing"
2011.jeptalnrecital-long.38,W09-2503,1,0.885153,"Missing"
2011.jeptalnrecital-long.38,J03-1002,0,0.00695544,"Missing"
2011.jeptalnrecital-long.38,N03-1024,0,0.0817453,"Missing"
2011.jeptalnrecital-long.38,W04-3219,0,0.0613814,"Missing"
2011.jeptalnrecital-long.38,W09-0441,0,0.0401231,"Missing"
2011.jeptalnrecital-long.38,2010.amta-papers.18,0,0.0870546,"Missing"
2019.jeptalnrecital-court.6,P05-1074,0,0.274855,"Missing"
2019.jeptalnrecital-court.6,S17-2002,0,0.02368,"Missing"
2019.jeptalnrecital-court.6,C10-2013,0,0.022481,"Missing"
2019.jeptalnrecital-court.6,W17-3209,0,0.0215049,"Missing"
2019.jeptalnrecital-court.6,dorr-etal-2002-duster,0,0.0183981,"Missing"
2019.jeptalnrecital-court.6,N13-1092,0,0.039073,"Missing"
2019.jeptalnrecital-court.6,N03-1017,0,0.0401901,"Missing"
2019.jeptalnrecital-court.6,N06-1014,0,0.156059,"Missing"
2019.jeptalnrecital-court.6,P14-5010,0,0.00551609,"Missing"
2019.jeptalnrecital-court.6,P15-1146,0,0.036796,"Missing"
2019.jeptalnrecital-court.6,P15-2070,0,0.0266084,"Missing"
2019.jeptalnrecital-court.6,petrov-etal-2012-universal,0,0.0894211,"Missing"
2019.jeptalnrecital-court.6,D18-1328,0,0.0303832,"Missing"
2019.jeptalnrecital-court.6,S17-2008,0,0.0199604,"Missing"
2019.jeptalnrecital-court.6,N18-1136,0,0.0216067,"Missing"
2019.jeptalnrecital-court.6,2018.jeptalnrecital-recital.7,1,0.832089,"Missing"
2019.jeptalnrecital-court.6,W18-3814,1,0.811011,"Missing"
2020.coling-main.522,ahrenberg-2017-comparing,0,0.150664,"bon. (Lit. That’s why we decided to spend massively on a communication campaign intended to tell, and blur, the truth about coal.) Table 1: English-French non-literal translations, found in the subtitles of TED Talks 2015). Non-literal translations can also cause noisy sentence pairs in parallel corpora, which affect the training of MT systems (Carpuat et al., 2017; Pham et al., 2018; Vyas et al., 2018). On the other hand, non-literal but appropriate translations are difficult to produce (Carl and Schaeffer, 2017) and machines are still on the way to simulate human translators on this aspect (Ahrenberg, 2017; Toral and Way, 2018). To inspire MT system’s development, efforts have been done to analyze language contrasts through alignment discrepancies (Lapshinova-Koltunski and Hardmeier, 2017), and to detect free and fluent translation examples from English-Chinese parallel corpora (Chen et al., 2018). In order to foster the study on non-literal translations, automatically detecting them in parallel corpora is an important step, which can help constructing materials to teach translation to human learners or serve as the first step to assembling as much representative data as we can to train MT syst"
2020.coling-main.522,D19-1542,0,0.0339379,"Missing"
2020.coling-main.522,P05-1074,0,0.584078,"ically studied by linguists and translation scholars, such as generalization, particularization, modulation, transposition, etc. (Vinay and Darbelnet, 1958; Chuquet and Paillard, 1989; Molina and Hurtado Albir, 2002). Based on these studies, Zhai (2019) investigated the possibility of annotating and automatically recognizing different translation techniques at sub-sentential level. For natural language processing (NLP) tasks, non-literal translations can bring difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017) or for paraphrase extraction via bilingual pivoting (Bannard and Callison-Burch, 2005; Pavlick et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. 1 https://www.ted.com/ License details: http:// 5944 Proceedings of the 28th International Conference on Computational Linguistics, pages 5944–5956 Barcelona, Spain (Online), December 8-13, 2020 It’s nothing if not ambitious. → C’est v´eritablement ambitieux. (Lit. It’s really ambitious.) That’s why we’ve made it our primary goal to spend a large sum of money on an advertising effort to help bring out and complicate the truth about coal. → C’est pourquoi"
2020.coling-main.522,W17-3209,0,0.419383,"rge sum of money on an advertising effort to help bring out and complicate the truth about coal. → C’est pourquoi nous avons d´ecid´e de d´epenser massivement pour une campagne de communication destin´ee a` dire, et a` brouiller, la v´erit´e sur le charbon. (Lit. That’s why we decided to spend massively on a communication campaign intended to tell, and blur, the truth about coal.) Table 1: English-French non-literal translations, found in the subtitles of TED Talks 2015). Non-literal translations can also cause noisy sentence pairs in parallel corpora, which affect the training of MT systems (Carpuat et al., 2017; Pham et al., 2018; Vyas et al., 2018). On the other hand, non-literal but appropriate translations are difficult to produce (Carl and Schaeffer, 2017) and machines are still on the way to simulate human translators on this aspect (Ahrenberg, 2017; Toral and Way, 2018). To inspire MT system’s development, efforts have been done to analyze language contrasts through alignment discrepancies (Lapshinova-Koltunski and Hardmeier, 2017), and to detect free and fluent translation examples from English-Chinese parallel corpora (Chen et al., 2018). In order to foster the study on non-literal translati"
2020.coling-main.522,Y18-1010,0,0.133337,"el corpora, which affect the training of MT systems (Carpuat et al., 2017; Pham et al., 2018; Vyas et al., 2018). On the other hand, non-literal but appropriate translations are difficult to produce (Carl and Schaeffer, 2017) and machines are still on the way to simulate human translators on this aspect (Ahrenberg, 2017; Toral and Way, 2018). To inspire MT system’s development, efforts have been done to analyze language contrasts through alignment discrepancies (Lapshinova-Koltunski and Hardmeier, 2017), and to detect free and fluent translation examples from English-Chinese parallel corpora (Chen et al., 2018). In order to foster the study on non-literal translations, automatically detecting them in parallel corpora is an important step, which can help constructing materials to teach translation to human learners or serve as the first step to assembling as much representative data as we can to train MT systems to start producing more non-literal translations than their literal alternatives. Our research questions are the following: do non-literal translations occur more often in human translations? Could pre-trained language models be fine-tuned to detect the presence of non-literal translations in"
2020.coling-main.522,D17-1070,0,0.0290005,"Missing"
2020.coling-main.522,D18-1269,0,0.0183035,"d as input. When predicting a masked word in an English sentence, the model can either attend to surrounding English words or to the French translation, encouraging the model to align EN an FR representations. In our experiments, we fine-tune XLM’s released model mlm tlm xnli15 1024.pth, which is pretrained with the objectives MLM+TLM. Conneau and Lample (2019) used 80k BPE (Byte Pair Encoding (Sennrich et al., 2016)) splits and a vocabulary of 95k sub-word units, and trained a 12-layer bidirectional Transformer model (1024 hidden states) on the Wikipedias of 15 languages of the XNLI dataset (Conneau et al., 2018). This model can be used to obtain a better initialization of sentence encoders for zero-shot cross-lingual classification, as is demonstrated in their fine-tuning experiment on XNLI benchmark (Cross-lingual Natural Language Inference). Our fine-tuning scheme In our case, the fine-tuning is conducted on a dataset of EN-FR Human 3 Differences between their approach and the MLM of BERT (Devlin et al., 2019) include the use of text streams of an arbitrary number of sentences (truncated at 256 tokens) instead of pairs of sentences. 4 This produces a supervised cross-lingual LM that combines both t"
2020.coling-main.522,J17-3002,0,0.464783,". Different techniques of producing non-literal translations are systematically studied by linguists and translation scholars, such as generalization, particularization, modulation, transposition, etc. (Vinay and Darbelnet, 1958; Chuquet and Paillard, 1989; Molina and Hurtado Albir, 2002). Based on these studies, Zhai (2019) investigated the possibility of annotating and automatically recognizing different translation techniques at sub-sentential level. For natural language processing (NLP) tasks, non-literal translations can bring difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017) or for paraphrase extraction via bilingual pivoting (Bannard and Callison-Burch, 2005; Pavlick et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. 1 https://www.ted.com/ License details: http:// 5944 Proceedings of the 28th International Conference on Computational Linguistics, pages 5944–5956 Barcelona, Spain (Online), December 8-13, 2020 It’s nothing if not ambitious. → C’est v´eritablement ambitieux. (Lit. It’s really ambitious.) That’s why we’ve made it our primary goal to spend a large sum of money on an adve"
2020.coling-main.522,N19-1423,0,0.100639,"al., 2016)) splits and a vocabulary of 95k sub-word units, and trained a 12-layer bidirectional Transformer model (1024 hidden states) on the Wikipedias of 15 languages of the XNLI dataset (Conneau et al., 2018). This model can be used to obtain a better initialization of sentence encoders for zero-shot cross-lingual classification, as is demonstrated in their fine-tuning experiment on XNLI benchmark (Cross-lingual Natural Language Inference). Our fine-tuning scheme In our case, the fine-tuning is conducted on a dataset of EN-FR Human 3 Differences between their approach and the MLM of BERT (Devlin et al., 2019) include the use of text streams of an arbitrary number of sentences (truncated at 256 tokens) instead of pairs of sentences. 4 This produces a supervised cross-lingual LM that combines both the MLM and the TLM loss using additional parallel data. 5946 vs Machine translations. Since the classifier will be later applied on a sub-corpus of TED Talks, we choose TED Talks, OpenSubtitles, Literary Books5 (Tiedemann, 2012) and Europarl (Koehn, 2005) to observe the effects of having similar and different training corpus genre. The statistics of the four corpus are shown in Table 2. The original Frenc"
2020.coling-main.522,dorr-etal-2002-duster,0,0.154766,"even sentence level. Different techniques of producing non-literal translations are systematically studied by linguists and translation scholars, such as generalization, particularization, modulation, transposition, etc. (Vinay and Darbelnet, 1958; Chuquet and Paillard, 1989; Molina and Hurtado Albir, 2002). Based on these studies, Zhai (2019) investigated the possibility of annotating and automatically recognizing different translation techniques at sub-sentential level. For natural language processing (NLP) tasks, non-literal translations can bring difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017) or for paraphrase extraction via bilingual pivoting (Bannard and Callison-Burch, 2005; Pavlick et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. 1 https://www.ted.com/ License details: http:// 5944 Proceedings of the 28th International Conference on Computational Linguistics, pages 5944–5956 Barcelona, Spain (Online), December 8-13, 2020 It’s nothing if not ambitious. → C’est v´eritablement ambitieux. (Lit. It’s really ambitious.) That’s why we’ve made it our primary goal to spend a large su"
2020.coling-main.522,N03-1017,0,0.188491,"Missing"
2020.coling-main.522,P07-2045,0,0.0130126,"Missing"
2020.coling-main.522,2005.mtsummit-papers.11,0,0.0740587,"ne-tuning scheme In our case, the fine-tuning is conducted on a dataset of EN-FR Human 3 Differences between their approach and the MLM of BERT (Devlin et al., 2019) include the use of text streams of an arbitrary number of sentences (truncated at 256 tokens) instead of pairs of sentences. 4 This produces a supervised cross-lingual LM that combines both the MLM and the TLM loss using additional parallel data. 5946 vs Machine translations. Since the classifier will be later applied on a sub-corpus of TED Talks, we choose TED Talks, OpenSubtitles, Literary Books5 (Tiedemann, 2012) and Europarl (Koehn, 2005) to observe the effects of having similar and different training corpus genre. The statistics of the four corpus are shown in Table 2. The original French text is produced by human translators, and the machine-translated sentences are generated by using fairseq (Ott et al., 2019)6 with their pre-trained model transformer.wmt14.en-fr (Ott et al., 2018).7 The de-tokenized BLEU scores calculated by SacreBLEU (Post, 2018) and CHRF3 (Popovi´c, 2015) for each machine-translated corpus are in Table 3. Literary books Europarl OpenSubtitles TED Talks Nb sentence pairs 33 669 30 000 30 000 30 000 Nb Eng"
2020.coling-main.522,W17-4810,0,0.114965,"teral translations, found in the subtitles of TED Talks 2015). Non-literal translations can also cause noisy sentence pairs in parallel corpora, which affect the training of MT systems (Carpuat et al., 2017; Pham et al., 2018; Vyas et al., 2018). On the other hand, non-literal but appropriate translations are difficult to produce (Carl and Schaeffer, 2017) and machines are still on the way to simulate human translators on this aspect (Ahrenberg, 2017; Toral and Way, 2018). To inspire MT system’s development, efforts have been done to analyze language contrasts through alignment discrepancies (Lapshinova-Koltunski and Hardmeier, 2017), and to detect free and fluent translation examples from English-Chinese parallel corpora (Chen et al., 2018). In order to foster the study on non-literal translations, automatically detecting them in parallel corpora is an important step, which can help constructing materials to teach translation to human learners or serve as the first step to assembling as much representative data as we can to train MT systems to start producing more non-literal translations than their literal alternatives. Our research questions are the following: do non-literal translations occur more often in human trans"
2020.coling-main.522,J03-1002,0,0.0144368,"Missing"
2020.coling-main.522,W18-6301,0,0.0136853,"es both the MLM and the TLM loss using additional parallel data. 5946 vs Machine translations. Since the classifier will be later applied on a sub-corpus of TED Talks, we choose TED Talks, OpenSubtitles, Literary Books5 (Tiedemann, 2012) and Europarl (Koehn, 2005) to observe the effects of having similar and different training corpus genre. The statistics of the four corpus are shown in Table 2. The original French text is produced by human translators, and the machine-translated sentences are generated by using fairseq (Ott et al., 2019)6 with their pre-trained model transformer.wmt14.en-fr (Ott et al., 2018).7 The de-tokenized BLEU scores calculated by SacreBLEU (Post, 2018) and CHRF3 (Popovi´c, 2015) for each machine-translated corpus are in Table 3. Literary books Europarl OpenSubtitles TED Talks Nb sentence pairs 33 669 30 000 30 000 30 000 Nb English tokens 876 866 869 869 215 584 498 440 Table 2: Statistics of different corpora used to train human-vs-machine translation classifier. 30k sentence pairs are randomly taken for the last three corpora Conneau and Lample (2019) processed all languages with the same shared vocabulary created through BPE, which greatly improved the alignment of embed"
2020.coling-main.522,N19-4009,0,0.0116891,"s of sentences. 4 This produces a supervised cross-lingual LM that combines both the MLM and the TLM loss using additional parallel data. 5946 vs Machine translations. Since the classifier will be later applied on a sub-corpus of TED Talks, we choose TED Talks, OpenSubtitles, Literary Books5 (Tiedemann, 2012) and Europarl (Koehn, 2005) to observe the effects of having similar and different training corpus genre. The statistics of the four corpus are shown in Table 2. The original French text is produced by human translators, and the machine-translated sentences are generated by using fairseq (Ott et al., 2019)6 with their pre-trained model transformer.wmt14.en-fr (Ott et al., 2018).7 The de-tokenized BLEU scores calculated by SacreBLEU (Post, 2018) and CHRF3 (Popovi´c, 2015) for each machine-translated corpus are in Table 3. Literary books Europarl OpenSubtitles TED Talks Nb sentence pairs 33 669 30 000 30 000 30 000 Nb English tokens 876 866 869 869 215 584 498 440 Table 2: Statistics of different corpora used to train human-vs-machine translation classifier. 30k sentence pairs are randomly taken for the last three corpora Conneau and Lample (2019) processed all languages with the same shared voca"
2020.coling-main.522,P15-1146,0,0.0458458,"Missing"
2020.coling-main.522,D18-1328,0,0.0492382,"advertising effort to help bring out and complicate the truth about coal. → C’est pourquoi nous avons d´ecid´e de d´epenser massivement pour une campagne de communication destin´ee a` dire, et a` brouiller, la v´erit´e sur le charbon. (Lit. That’s why we decided to spend massively on a communication campaign intended to tell, and blur, the truth about coal.) Table 1: English-French non-literal translations, found in the subtitles of TED Talks 2015). Non-literal translations can also cause noisy sentence pairs in parallel corpora, which affect the training of MT systems (Carpuat et al., 2017; Pham et al., 2018; Vyas et al., 2018). On the other hand, non-literal but appropriate translations are difficult to produce (Carl and Schaeffer, 2017) and machines are still on the way to simulate human translators on this aspect (Ahrenberg, 2017; Toral and Way, 2018). To inspire MT system’s development, efforts have been done to analyze language contrasts through alignment discrepancies (Lapshinova-Koltunski and Hardmeier, 2017), and to detect free and fluent translation examples from English-Chinese parallel corpora (Chen et al., 2018). In order to foster the study on non-literal translations, automatically"
2020.coling-main.522,W15-3049,0,0.061983,"Missing"
2020.coling-main.522,W18-6319,0,0.0135279,"achine translations. Since the classifier will be later applied on a sub-corpus of TED Talks, we choose TED Talks, OpenSubtitles, Literary Books5 (Tiedemann, 2012) and Europarl (Koehn, 2005) to observe the effects of having similar and different training corpus genre. The statistics of the four corpus are shown in Table 2. The original French text is produced by human translators, and the machine-translated sentences are generated by using fairseq (Ott et al., 2019)6 with their pre-trained model transformer.wmt14.en-fr (Ott et al., 2018).7 The de-tokenized BLEU scores calculated by SacreBLEU (Post, 2018) and CHRF3 (Popovi´c, 2015) for each machine-translated corpus are in Table 3. Literary books Europarl OpenSubtitles TED Talks Nb sentence pairs 33 669 30 000 30 000 30 000 Nb English tokens 876 866 869 869 215 584 498 440 Table 2: Statistics of different corpora used to train human-vs-machine translation classifier. 30k sentence pairs are randomly taken for the last three corpora Conneau and Lample (2019) processed all languages with the same shared vocabulary created through BPE, which greatly improved the alignment of embedding spaces across languages. Therefore, after tokenizing input sent"
2020.coling-main.522,2011.mtsummit-papers.48,0,0.0232687,"Zhai et al. (2019), we investigate whether pre-trained cross-lingual language models could be finetuned to detect non-literal translations at sentence and phrase level. For the latter, we compare the results with those obtained by Zhai et al. (2019). 3 Detecting non-literal translations at sentence level Our first goal is to detect whether there are non-literal translations in a sentence. By assuming that human translators employ more non-literal translations than machines (Toral and Way, 2018), we first transfer the problem into training a model to distinguish human and machine translations (Rarrick et al., 2011), expecting that the classifier would learn the linguistic differences between them and further help predict the presence of non-literal translations in a sentence. After training this human-vs-machine translation classifier, we investigate whether there is a positive correlation between the prediction probability of human translation and the non-literal translations’ proportion in a sentence. Finally, we test the hypothesis that resuming the fine-tuning task on detecting the presence of non-literal translations in a sentence after loading this human-vs-machine translation classification model"
2020.coling-main.522,P16-1162,0,0.0124916,", and MLM in combination with TLM (Translation Language Modeling, an extension of MLM, i.e. randomly masking words in both the source and target sentences)4 . For TLM, parallel sentences are concatenated as input. When predicting a masked word in an English sentence, the model can either attend to surrounding English words or to the French translation, encouraging the model to align EN an FR representations. In our experiments, we fine-tune XLM’s released model mlm tlm xnli15 1024.pth, which is pretrained with the objectives MLM+TLM. Conneau and Lample (2019) used 80k BPE (Byte Pair Encoding (Sennrich et al., 2016)) splits and a vocabulary of 95k sub-word units, and trained a 12-layer bidirectional Transformer model (1024 hidden states) on the Wikipedias of 15 languages of the XNLI dataset (Conneau et al., 2018). This model can be used to obtain a better initialization of sentence encoders for zero-shot cross-lingual classification, as is demonstrated in their fine-tuning experiment on XNLI benchmark (Cross-lingual Natural Language Inference). Our fine-tuning scheme In our case, the fine-tuning is conducted on a dataset of EN-FR Human 3 Differences between their approach and the MLM of BERT (Devlin et a"
2020.coling-main.522,W18-6305,0,0.0700251,"Missing"
2020.coling-main.522,tiedemann-2012-parallel,0,0.00990251,"ral Language Inference). Our fine-tuning scheme In our case, the fine-tuning is conducted on a dataset of EN-FR Human 3 Differences between their approach and the MLM of BERT (Devlin et al., 2019) include the use of text streams of an arbitrary number of sentences (truncated at 256 tokens) instead of pairs of sentences. 4 This produces a supervised cross-lingual LM that combines both the MLM and the TLM loss using additional parallel data. 5946 vs Machine translations. Since the classifier will be later applied on a sub-corpus of TED Talks, we choose TED Talks, OpenSubtitles, Literary Books5 (Tiedemann, 2012) and Europarl (Koehn, 2005) to observe the effects of having similar and different training corpus genre. The statistics of the four corpus are shown in Table 2. The original French text is produced by human translators, and the machine-translated sentences are generated by using fairseq (Ott et al., 2019)6 with their pre-trained model transformer.wmt14.en-fr (Ott et al., 2018).7 The de-tokenized BLEU scores calculated by SacreBLEU (Post, 2018) and CHRF3 (Popovi´c, 2015) for each machine-translated corpus are in Table 3. Literary books Europarl OpenSubtitles TED Talks Nb sentence pairs 33 669"
2020.coling-main.522,N18-1136,0,0.348571,"to help bring out and complicate the truth about coal. → C’est pourquoi nous avons d´ecid´e de d´epenser massivement pour une campagne de communication destin´ee a` dire, et a` brouiller, la v´erit´e sur le charbon. (Lit. That’s why we decided to spend massively on a communication campaign intended to tell, and blur, the truth about coal.) Table 1: English-French non-literal translations, found in the subtitles of TED Talks 2015). Non-literal translations can also cause noisy sentence pairs in parallel corpora, which affect the training of MT systems (Carpuat et al., 2017; Pham et al., 2018; Vyas et al., 2018). On the other hand, non-literal but appropriate translations are difficult to produce (Carl and Schaeffer, 2017) and machines are still on the way to simulate human translators on this aspect (Ahrenberg, 2017; Toral and Way, 2018). To inspire MT system’s development, efforts have been done to analyze language contrasts through alignment discrepancies (Lapshinova-Koltunski and Hardmeier, 2017), and to detect free and fluent translation examples from English-Chinese parallel corpora (Chen et al., 2018). In order to foster the study on non-literal translations, automatically detecting them in pa"
2020.coling-main.522,2020.lrec-1.229,0,0.0287769,"ltilingual corpora of translated literary texts, which is particularly important for low-resource languages. In order to provide insights for discourse-aware MT system’s development, discourse-related language contrasts are analyzed for English-Croatian and ˇ stari´c et al., 2018). For inspiring MT’s English-German (Lapshinova-Koltunski and Hardmeier, 2017; Soˇ further improvement on fluency and for human translators’ reference, Chen et al. (2018) proposed a method for detecting free translation examples from bilingual parallel corpora, which is based on an innovative use of attention scores. Yuan and Sharoff (2020) proposed a stacked neural network for finegrained human translation quality estimation, and they discussed that this model has limited validity for adequate scoring of free but still valid translations. In this paper, by using the English-French TED Talks corpus annotated with translation techniques by Zhai et al. (2019), we investigate whether pre-trained cross-lingual language models could be finetuned to detect non-literal translations at sentence and phrase level. For the latter, we compare the results with those obtained by Zhai et al. (2019). 3 Detecting non-literal translations at sent"
2020.jeptalnrecital-taln.37,P01-1008,0,0.449335,"Missing"
2020.jeptalnrecital-taln.37,N13-1073,0,0.0606197,"Missing"
2020.jeptalnrecital-taln.37,francois-etal-2014-flelex,0,0.0716563,"Missing"
2020.jeptalnrecital-taln.37,N13-1092,0,0.121368,"Missing"
2020.jeptalnrecital-taln.37,2013.iwslt-papers.7,0,0.115509,"Missing"
2020.jeptalnrecital-taln.37,J10-3003,0,0.0908621,"Missing"
2020.jeptalnrecital-taln.37,P15-1146,0,0.0275612,"Missing"
2020.jeptalnrecital-taln.37,P15-2070,0,0.055227,"Missing"
2020.lrec-1.496,ahrenberg-2017-comparing,0,0.0150348,"ation divergences, which are caused by nonliteral translations and cross-lingual differences. Chen et al. (2018) used attention mechanism scores in an innovative way to detect free translation in English-Chinese parallel corpora. Xu and Yvon (2016) proposed new methodologies for collecting human judgements on bilingual alignment links, which were used to annotate four new data sets. Their observation confirms that a finer categorization than Sure and Possible word alignment is useful. In our work, we conduct word and segment level alignment, and specify the fine-grained translation technique. Ahrenberg (2017) compared machine and human translations of an English article translated into Swedish, by using MT metrics and translation techniques. The author pointed out that automatically classifying translation techniques should be a topic for future research. Recently, we have worked on automatically classifying translation techniques for the language pair English-French (Zhai et al., 2019). This present work extends these studies by working on a more distant language pair: English-Chinese. 3. Corpus Presentation We extend our previous work which focused on annotating an English-French parallel corpus"
2020.lrec-1.496,L18-1160,0,0.0147584,"ed: X is related in some other way to Y. (e.g. country / patriotic). Independent: X is not related to Y. 4024 2. Related Work The first annotation guidelines for manually annotating parallel corpora were established for the project Blinker (Melamed, 1998a; Melamed, 1998b), in order to annotate translational equivalence in English-French Bible verses. More recently, Monti et al. (2015) annotated multiword expressions in an English-Italian parallel corpus of TED Talks2 . Annotators also indicated whether the generated machine translation is correct, and supplied a correct translation if needed. Ahrens et al. (2018) built an online large database containing English and Chinese political speeches. This corpus is particularly useful for researchers focusing on political speeches and conceptual metaphor analyses. Concerning non-literal translation techniques, several works have proposed different typologies to categorize them (Vinay and Darbelnet, 1958; Newmark, 1988; Chuquet and Paillard, 1989; Molina and Hurtado Albir, 2002). Our corpus annotation is based on these translation theories. Deng and Xue (2017) built a hierarchically aligned parallel corpora and semi-automatically detected ChineseEnglish trans"
2020.lrec-1.496,W05-0909,0,0.0517875,"ak negative correlation, which is rather surprising, since the textual style is close to Official document. We obtain weak or even very weak correlation for the other genres, which deserves a more in-depth study. This experiment is conducted based on 500 sentence pairs annotated (50 pairs for each of ten genres). To confirm our hypothesis that BLEU metric does penalize non-literal human translations, we need to continue the annotation while assuring the annotation quality and the characteristics of each corpus genre. Besides BLEU, we could further investigate other MT metrics, such as METEOR (Banerjee and Lavie, 2005) and TER-plus (Snover et al., 2009), which use paraphrases during the evaluation. However, preliminary results support our hypothesis for the corpus of genre Official document and Literature. BLEU scores are lower when human translations are more nonliteral than machine translations; and gradually higher when human and machine translations are both more literal and similar. Since the algorithm of BLEU compares the matching n-grams between translations, it could penalize human translations with non-literal but correct expressions. Figure 5: Strong positive correlation between the proportion of"
2020.lrec-1.496,P05-1074,0,0.184979,"n-literal translations Non-literal translations between different languages can cause difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017), or cause meaning changes in certain cases. However, non-literal translation techniques receive less attention in developing NLP applications. Take the task of paraphrase extraction from bilingual parallel corpora as an example. The assumption is that two monolingual segments are potential paraphrases if they share common translations in another language, and the extraction relies on Machine Translation (MT) related techniques (Bannard and Callison-Burch, 2005; Mallinson et al., 2017). Currently, the largest paraphrase resource, PPDB (ParaPhrase DataBase), has been built based on this method (Ganitkevitch et al., 2013). Nonetheless, Pavlick et al. (2015) revealed that there exist relations other than strict equivalence in PPDB (i.e. Entailment (in two directions), Exclusion, Other related and Independent)1 . Nonliteral pivot translations inside the parallel corpora could break the strict equivalence between the candidate paraphrases extracted, whereas they have not received enough attention during this corpus exploration. In this working context, o"
2020.lrec-1.496,P04-3031,0,0.220777,"Benesty et al., 2009; Hauke and Kossowski, 2011) between the proportion of literally translated English tokens and the cumulative 4-gram BLEU score (comparing one human translation to four machine translations). Figures 5 and 6 show the relationship between these two variables for the sub-corpus of official doc15 https://cloud.google.com/translate/docs/ https://azure.microsoft.com/ fr-fr/services/cognitive-services/ translator-text-api/ 17 https://api.fanyi.baidu.com/api/trans/ product/index 18 https://ai.qq.com/product/nlptrans. shtml#text 19 We compute BLEU scores with the NLP toolkit NLTK (Bird and Loper, 2004). For scoring sentences, we use the sentence_bleu() function with a smoothing function (method 4). 20 The genre Scientific article is ignored for this experiment, since the translation direction is from Chinese to English. 16 4029 Corpus genre official_document literature spoken education_material microblog art subtitles news science law Figure 4: Distributions of proportion of literally translated English tokens per sentence in each genre of corpus Corpus genre official document literature spoken education material microblog art subtitles news science law English 34 26 14 20 21 27 12 31 20 37"
2020.lrec-1.496,Y18-1010,0,0.0128414,"is particularly useful for researchers focusing on political speeches and conceptual metaphor analyses. Concerning non-literal translation techniques, several works have proposed different typologies to categorize them (Vinay and Darbelnet, 1958; Newmark, 1988; Chuquet and Paillard, 1989; Molina and Hurtado Albir, 2002). Our corpus annotation is based on these translation theories. Deng and Xue (2017) built a hierarchically aligned parallel corpora and semi-automatically detected ChineseEnglish translation divergences, which are caused by nonliteral translations and cross-lingual differences. Chen et al. (2018) used attention mechanism scores in an innovative way to detect free translation in English-Chinese parallel corpora. Xu and Yvon (2016) proposed new methodologies for collecting human judgements on bilingual alignment links, which were used to annotate four new data sets. Their observation confirms that a finer categorization than Sure and Possible word alignment is useful. In our work, we conduct word and segment level alignment, and specify the fine-grained translation technique. Ahrenberg (2017) compared machine and human translations of an English article translated into Swedish, by using"
2020.lrec-1.496,J17-3002,0,0.1099,"f the second sentence divides one sentence into two clauses to paraphrase the expression « unfold out of », thus the translation is more natural and compact. EN: Don’t make me go through all of this and not make it. ZH: 别让我的辛苦白费了。 (""Don’t let my hard work be wasted."") EN: In the east the dawn was unfolding out of the darkness. ZH: 东方晨曦初现，黑暗渐去。 (""In the east the dawn was beginning to appear, and the darkness was fading."") Table 1: English-Chinese non-literal translations Non-literal translations between different languages can cause difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017), or cause meaning changes in certain cases. However, non-literal translation techniques receive less attention in developing NLP applications. Take the task of paraphrase extraction from bilingual parallel corpora as an example. The assumption is that two monolingual segments are potential paraphrases if they share common translations in another language, and the extraction relies on Machine Translation (MT) related techniques (Bannard and Callison-Burch, 2005; Mallinson et al., 2017). Currently, the largest paraphrase resource, PPDB (ParaPhrase DataBase), has been built based on this method"
2020.lrec-1.496,dorr-etal-2002-duster,0,0.0880342,"; the translation of the second sentence divides one sentence into two clauses to paraphrase the expression « unfold out of », thus the translation is more natural and compact. EN: Don’t make me go through all of this and not make it. ZH: 别让我的辛苦白费了。 (""Don’t let my hard work be wasted."") EN: In the east the dawn was unfolding out of the darkness. ZH: 东方晨曦初现，黑暗渐去。 (""In the east the dawn was beginning to appear, and the darkness was fading."") Table 1: English-Chinese non-literal translations Non-literal translations between different languages can cause difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017), or cause meaning changes in certain cases. However, non-literal translation techniques receive less attention in developing NLP applications. Take the task of paraphrase extraction from bilingual parallel corpora as an example. The assumption is that two monolingual segments are potential paraphrases if they share common translations in another language, and the extraction relies on Machine Translation (MT) related techniques (Bannard and Callison-Burch, 2005; Mallinson et al., 2017). Currently, the largest paraphrase resource, PPDB (ParaPhrase DataBase), has been built"
2020.lrec-1.496,N13-1092,0,0.116491,"Missing"
2020.lrec-1.496,P08-4006,0,0.0297933,"if needed. The automatically segmented Chinese corpus contains some errors that could mislead the manual word alignments and the attribution of translation technique categories. Therefore, certain Chinese words need a manual re-segmentation before the annotation, in order to better correspond to English segments. For example, only is → 仅仅是 has been corrected to only is → 仅仅 (only) 是(is). The annotators are told to note down these cases of necessary re-segmentation and the misspellings, which are later corrected in the corpus. We use the web application Yawat (Yet Another Word Alignment Tool) (Germann, 2008) for the manual annotation. 11 http://nlp.stanford.edu/software/ tokenizer.shtml 4026 Translation technique Definition and important rules Literal Equivalence Transposition Modulation Mod+Trans Particularization Generalization Figurative translation Aligned segments Word-for-word translation: a bronze ring → 一 个 青 铜 戒指 Borrowing words using transliteration: a cup of coffee → 一 杯 咖 啡 Possible literal translation of idioms: ivory tower → 象牙 塔 Corresponding expression when absolute literal translation does not make sense: I give you my word. → 我 向 你 保证 。 (""I promise you."") Non-literal translation"
2020.lrec-1.496,J09-4006,0,0.0389743,"ments, except the eight categories in table 3, we also included three other categories which proved useful during the annotation, but not related to translation techniques : 1) Lexical shift (change of verbal tense, verbal modality or of determiner, differences between plural and singular form, and other minor changes alike); 2) Obvious translation errors; 3) Uncertain cases. The definitions in these two tables are generic, we have completed them with specific rules in our annotation guidelines. 5. Manual Annotation We have used Stanford Tokenizer11 to tokenize the English corpus, and THULAC (Li and Sun, 2009) is used for the Chinese word segmentation. The automatic bilingual word alignment is conducted with TsinghuaAligner (Liu and Sun, 2015). These alignments are imported to initialize the annotation, in order to reduce the manual word alignment effort on easy literal word translations. Annotators should verify these automatic word alignments and correct them if needed. The automatically segmented Chinese corpus contains some errors that could mislead the manual word alignments and the attribution of translation technique categories. Therefore, certain Chinese words need a manual re-segmentation"
2020.lrec-1.496,E17-1083,0,0.0130452,"translations between different languages can cause difficulties for automatic word alignment (Dorr et al., 2002; Deng and Xue, 2017), or cause meaning changes in certain cases. However, non-literal translation techniques receive less attention in developing NLP applications. Take the task of paraphrase extraction from bilingual parallel corpora as an example. The assumption is that two monolingual segments are potential paraphrases if they share common translations in another language, and the extraction relies on Machine Translation (MT) related techniques (Bannard and Callison-Burch, 2005; Mallinson et al., 2017). Currently, the largest paraphrase resource, PPDB (ParaPhrase DataBase), has been built based on this method (Ganitkevitch et al., 2013). Nonetheless, Pavlick et al. (2015) revealed that there exist relations other than strict equivalence in PPDB (i.e. Entailment (in two directions), Exclusion, Other related and Independent)1 . Nonliteral pivot translations inside the parallel corpora could break the strict equivalence between the candidate paraphrases extracted, whereas they have not received enough attention during this corpus exploration. In this working context, one of our long term objec"
2020.lrec-1.496,P02-1040,0,0.109645,"t when translating long and complicated English sentences. It could also occur even though all English words are literally translated. 7. 7.1. Evaluation Compare human and machine translation During the annotation, we observed that the distance could be large between good human non-literal translations and machine translations provided by online MT services. Humans can recognize these non-literal translations as good Figure 3: Example of less diagonal word alignment of an English-Chinese sentence pair quality (Schaeffer and Carl, 2014), but would automatic MT evaluation metrics, such as BLEU (Papineni et al., 2002), penalize them? In order to study this question, we conducted an experiment to investigate the correlation between the proportion of literally translated English tokens and the BLEU score of the corresponding human translation compared to four machine translations. Four principal MT engines’ API have been used during this experiment: Google15 , Microsoft16 , Baidu17 and Tencent18 . Cumulative 4-gram BLEU scores with uniform weights are calculated for this experiment.19 All Chinese translations are tokenized at character level, since Chinese words are formed by combining characters, which are"
2020.lrec-1.496,P15-1146,0,0.0310318,"Missing"
2020.lrec-1.496,petrov-etal-2012-universal,0,0.0276328,"Missing"
2020.lrec-1.496,W14-0306,0,0.0680718,"Missing"
2020.lrec-1.496,tian-etal-2014-um,0,0.0267069,"s of eleven genres is constructed based on existing work: art, literature, law, material for education, microblog, news, official document, spoken, subtitles, science and scientific article.3 For our first study of this language pair, we didn’t limit ourselves to only one corpus genre, even though the corpus of different genres don’t have the same quality. Below we present 2 https://www.ted.com These genres are the most used ones in different previous work. 3 the origin of each corpus. The translation direction is from English to Chinese, except for the genre of scientific article. UM-corpus (Tian et al., 2014): this corpus has been constructed by the University of Macau, for training machine translation systems. The corpus released contains 2.2M parallel sentences, and is divided into eight genres with a nearly balanced distribution (law, material for education, microblog, news, science, spoken, subtitles, thesis). The sentence-level alignments have been manually corrected. However, errors still exist, for example, there are cases where a long segment is not translated in a sentence. We annotated this corpus while filtering out the incomplete or incorrect pairs. The segmentation of Chinese words an"
2020.lrec-1.496,L16-1099,0,0.0235977,"on techniques, several works have proposed different typologies to categorize them (Vinay and Darbelnet, 1958; Newmark, 1988; Chuquet and Paillard, 1989; Molina and Hurtado Albir, 2002). Our corpus annotation is based on these translation theories. Deng and Xue (2017) built a hierarchically aligned parallel corpora and semi-automatically detected ChineseEnglish translation divergences, which are caused by nonliteral translations and cross-lingual differences. Chen et al. (2018) used attention mechanism scores in an innovative way to detect free translation in English-Chinese parallel corpora. Xu and Yvon (2016) proposed new methodologies for collecting human judgements on bilingual alignment links, which were used to annotate four new data sets. Their observation confirms that a finer categorization than Sure and Possible word alignment is useful. In our work, we conduct word and segment level alignment, and specify the fine-grained translation technique. Ahrenberg (2017) compared machine and human translations of an English article translated into Swedish, by using MT metrics and translation techniques. The author pointed out that automatically classifying translation techniques should be a topic f"
2020.lrec-1.496,W18-3814,1,0.881515,"an English article translated into Swedish, by using MT metrics and translation techniques. The author pointed out that automatically classifying translation techniques should be a topic for future research. Recently, we have worked on automatically classifying translation techniques for the language pair English-French (Zhai et al., 2019). This present work extends these studies by working on a more distant language pair: English-Chinese. 3. Corpus Presentation We extend our previous work which focused on annotating an English-French parallel corpus of TED Talks with translation techniques (Zhai et al., 2018). English and French languages are very similar in vocabulary and grammar, while the English-Chinese pair shares far fewer cultural and linguistic similarities. A corpus of eleven genres is constructed based on existing work: art, literature, law, material for education, microblog, news, official document, spoken, subtitles, science and scientific article.3 For our first study of this language pair, we didn’t limit ourselves to only one corpus genre, even though the corpus of different genres don’t have the same quality. Below we present 2 https://www.ted.com These genres are the most used one"
2020.lrec-1.496,L16-1561,0,0.0172762,"ailable and we can redistribute the annotated corpus. UB-corpus (Chang and Bai, 2003): this corpus has been constructed by the University of Beijing, mainly for training machine translation systems. The sentence-level alignments have been verified before releasing and the corpus contains a large variety of genres. After signing an agreement, we obtained a corpus of 102k pairs of parallel sentences of genres Literature, Art and Science, which has been freely provided for research purpose. However, we do not have the right to redistribute this part of the annotated corpus. UnitedNations-corpus (Ziemski et al., 2016)4 : this freely available corpus contains official reports and parliamentary documents of the United Nations. Our sub-corpus of genre Official document is a sample from this large corpus containing 15M sentence pairs. For the genre of scientific article, after our examination, the quality of the part contained in the UM-corpus is nonsatisfactory for annotation. Therefore, we constructed our own corpus by collecting bilingual abstracts from these online journals: Chinese Linguistics5 , Chinese Journal of Software6 and Chinese Journal of Computers7 . The translation direction is from Chinese to"
2020.semeval-1.172,baccianella-etal-2010-sentiwordnet,0,0.0495204,"in (Online), December 12, 2020. 2 Background Sentiment classification is the task of detecting whether a textual item (e.g., a product review, a blog post, an editorial, etc.) expresses a POSITIVE or a NEGATIVE opinion in general or about a given entity, e.g., a product, a person, a political party, or a policy (Nakov et al., 2016). Classifying tweets according to sentiment has many applications in political science, social sciences, market research, and many others (Mart´ınez-C´amara et al., 2014; Mejova et al., 2015). Although initially sentiment identification was focused on newswire text (Baccianella et al., 2010), later research turned towards social media (Rosenthal et al., 2015). Since 2013, a sentiment classification task on Twitter data have been organized in SemEval campaigns. Most of the earlier approaches to this problem were based on hand crafted features and sentiment lexicons (Pak and Paroubek, 2010; Mohammad et al., 2013). These features were then used as input to classifiers (e.g., Support Vector Machines). However, such approaches required extensive domain knowledge, were laborious to define, and can lead to incomplete or over-specific features. Recently, researchers pay their attention t"
2020.semeval-1.172,Q17-1010,0,0.0565339,"token is replaced with a TOPIC token. For example, the tokens # and LoveIsLove are merged and replaced with a TOPIC token. • Emoji’s with text were divided into two tokens. For example, he, becomes he and ,. • If a token contains more than one emoji, each emoji was considered as a token. For example, ,/ becomes , and /. Embeddings: Following Collobert et al. (2011), a lot of authors argued that word embedding plays a vital role to improve natural language task performance. Hence, we experimented the use of word embeddings to improve the performance of our proposed models. Using the fastText (Bojanowski et al., 2017), we prepared two embedding models: Skip-gram and Cbow. After empirically evaluating the performance on validation set, the embeddings‘ dimensionality was set to 300 for all the embeddings. The embeddings are trained on training data using the parameters: lr=0.05, context window=5, epochs=5, minimal number of word occurences=5, dimensionality=300. Experiment: We carried out two experiments with similar settings except different word embedding approaches: Skip-gram for SkipGRun, and Cbow for CbowRun. Hyper-parameters: After evaluating the model performance on the validation data, the optimal va"
2020.semeval-1.172,J81-4005,0,0.486121,"Missing"
2020.semeval-1.172,N19-1423,0,0.03792,"we pre-processed the CM tweets and proposed a Recurrent Convolutional Neural Network for the sentiment analysis of CM tweets. We submitted two runs and obtaining promising results: our best run obtained 0.691 of F1 averaged across the positives, negatives and the neutral. We observed that the proposed architecture occasionally strives to separate the positive and negative polarities from the neutral and vice versa. For future work, we will explore the performance of our model with larger corpora against the testing set. Also, we would like to investigate other embedding choices such as BERT (Devlin et al., 2019). Moreover, due to the impact that irony and sarcasm have on sentiment analysis (Hern´andez Farıas and Rosso, 2016) it would be interesting to apply deep learning techniques to detect irony (Zhang et al., 2019) but in a code-mixed scenario. Acknowledgements The research work of the first four authors was supported by ERA-Net CHIST-ERA LIHLITH Project funded by ANR (France) project ANR-17-CHR2-0001-03. The research work of the last author was partially funded by the Spanish MICINN under the project MISMIS-FAKEnHATE on Misinformation and Miscommunication in social media: FAKE news and HATE speec"
2020.semeval-1.172,C16-1234,0,0.0267187,"were based on hand crafted features and sentiment lexicons (Pak and Paroubek, 2010; Mohammad et al., 2013). These features were then used as input to classifiers (e.g., Support Vector Machines). However, such approaches required extensive domain knowledge, were laborious to define, and can lead to incomplete or over-specific features. Recently, researchers pay their attention to sentiment polarity detection on CM data. However, a few research work have been carried out in particular Hindi-English CM data with different approaches: lexicon lookup (Sharma et al., 2015), sub-word with CNN-LSTM (Joshi et al., 2016), Siamese networks (Choudhary et al., 2018), dual Encoder Network with features (Lal et al., 2019). Lai et al. (2015) proposed Recurrent Convolutional Network for text classification which is a foundational task in many NLP applications. We followed this model in our task. 3 System overview We are inspired by the model proposed in (Lai et al., 2015) particularly proposed for the text classification task. The proposed model takes sequence of CM words as input and provides sentiment polarity class as output. The recurrent structure of the proposed model captures the contextual information during"
2020.semeval-1.172,P19-2052,0,0.0137829,", 2013). These features were then used as input to classifiers (e.g., Support Vector Machines). However, such approaches required extensive domain knowledge, were laborious to define, and can lead to incomplete or over-specific features. Recently, researchers pay their attention to sentiment polarity detection on CM data. However, a few research work have been carried out in particular Hindi-English CM data with different approaches: lexicon lookup (Sharma et al., 2015), sub-word with CNN-LSTM (Joshi et al., 2016), Siamese networks (Choudhary et al., 2018), dual Encoder Network with features (Lal et al., 2019). Lai et al. (2015) proposed Recurrent Convolutional Network for text classification which is a foundational task in many NLP applications. We followed this model in our task. 3 System overview We are inspired by the model proposed in (Lai et al., 2015) particularly proposed for the text classification task. The proposed model takes sequence of CM words as input and provides sentiment polarity class as output. The recurrent structure of the proposed model captures the contextual information during the learning of the word representation, and the max-pooling layer identifies the key CM words. I"
2020.semeval-1.172,S13-2053,0,0.0654071,"016). Classifying tweets according to sentiment has many applications in political science, social sciences, market research, and many others (Mart´ınez-C´amara et al., 2014; Mejova et al., 2015). Although initially sentiment identification was focused on newswire text (Baccianella et al., 2010), later research turned towards social media (Rosenthal et al., 2015). Since 2013, a sentiment classification task on Twitter data have been organized in SemEval campaigns. Most of the earlier approaches to this problem were based on hand crafted features and sentiment lexicons (Pak and Paroubek, 2010; Mohammad et al., 2013). These features were then used as input to classifiers (e.g., Support Vector Machines). However, such approaches required extensive domain knowledge, were laborious to define, and can lead to incomplete or over-specific features. Recently, researchers pay their attention to sentiment polarity detection on CM data. However, a few research work have been carried out in particular Hindi-English CM data with different approaches: lexicon lookup (Sharma et al., 2015), sub-word with CNN-LSTM (Joshi et al., 2016), Siamese networks (Choudhary et al., 2018), dual Encoder Network with features (Lal et"
2020.semeval-1.172,S16-1001,0,0.0290725,"tivecommons.org/licenses/by/4.0/. The code of this work is available at https://github.com/somnath-banerjee/Code-Mixed_ SentimentAnalysis. 1 https://code-switching.github.io/2020/ 1281 Proceedings of the 14th International Workshop on Semantic Evaluation, pages 1281–1287 Barcelona, Spain (Online), December 12, 2020. 2 Background Sentiment classification is the task of detecting whether a textual item (e.g., a product review, a blog post, an editorial, etc.) expresses a POSITIVE or a NEGATIVE opinion in general or about a given entity, e.g., a product, a person, a political party, or a policy (Nakov et al., 2016). Classifying tweets according to sentiment has many applications in political science, social sciences, market research, and many others (Mart´ınez-C´amara et al., 2014; Mejova et al., 2015). Although initially sentiment identification was focused on newswire text (Baccianella et al., 2010), later research turned towards social media (Rosenthal et al., 2015). Since 2013, a sentiment classification task on Twitter data have been organized in SemEval campaigns. Most of the earlier approaches to this problem were based on hand crafted features and sentiment lexicons (Pak and Paroubek, 2010; Moha"
2020.semeval-1.172,pak-paroubek-2010-twitter,0,0.100366,"policy (Nakov et al., 2016). Classifying tweets according to sentiment has many applications in political science, social sciences, market research, and many others (Mart´ınez-C´amara et al., 2014; Mejova et al., 2015). Although initially sentiment identification was focused on newswire text (Baccianella et al., 2010), later research turned towards social media (Rosenthal et al., 2015). Since 2013, a sentiment classification task on Twitter data have been organized in SemEval campaigns. Most of the earlier approaches to this problem were based on hand crafted features and sentiment lexicons (Pak and Paroubek, 2010; Mohammad et al., 2013). These features were then used as input to classifiers (e.g., Support Vector Machines). However, such approaches required extensive domain knowledge, were laborious to define, and can lead to incomplete or over-specific features. Recently, researchers pay their attention to sentiment polarity detection on CM data. However, a few research work have been carried out in particular Hindi-English CM data with different approaches: lexicon lookup (Sharma et al., 2015), sub-word with CNN-LSTM (Joshi et al., 2016), Siamese networks (Choudhary et al., 2018), dual Encoder Networ"
2020.semeval-1.172,S15-2078,0,0.0267216,"s the task of detecting whether a textual item (e.g., a product review, a blog post, an editorial, etc.) expresses a POSITIVE or a NEGATIVE opinion in general or about a given entity, e.g., a product, a person, a political party, or a policy (Nakov et al., 2016). Classifying tweets according to sentiment has many applications in political science, social sciences, market research, and many others (Mart´ınez-C´amara et al., 2014; Mejova et al., 2015). Although initially sentiment identification was focused on newswire text (Baccianella et al., 2010), later research turned towards social media (Rosenthal et al., 2015). Since 2013, a sentiment classification task on Twitter data have been organized in SemEval campaigns. Most of the earlier approaches to this problem were based on hand crafted features and sentiment lexicons (Pak and Paroubek, 2010; Mohammad et al., 2013). These features were then used as input to classifiers (e.g., Support Vector Machines). However, such approaches required extensive domain knowledge, were laborious to define, and can lead to incomplete or over-specific features. Recently, researchers pay their attention to sentiment polarity detection on CM data. However, a few research wo"
arnulphy-etal-2012-event,P06-2022,0,\N,Missing
arnulphy-etal-2012-event,tannier-etal-2012-evolution,1,\N,Missing
arnulphy-etal-2012-event,2009.jeptalnrecital-long.17,0,\N,Missing
asadullah-etal-2014-bidirectionnal,candito-etal-2010-statistical,0,\N,Missing
asadullah-etal-2014-bidirectionnal,C10-2013,0,\N,Missing
asadullah-etal-2014-bidirectionnal,villemonte-de-la-clergerie-etal-2008-passage,1,\N,Missing
asadullah-etal-2014-bidirectionnal,vilnat-etal-2010-passage,1,\N,Missing
asadullah-etal-2014-bidirectionnal,W06-2920,0,\N,Missing
asadullah-etal-2014-bidirectionnal,W08-1301,0,\N,Missing
asadullah-etal-2014-bidirectionnal,abeille-barrier-2004-enriching,0,\N,Missing
asadullah-etal-2014-bidirectionnal,paroubek-etal-2006-data,1,\N,Missing
bouamor-etal-2012-contrastive,I05-5002,0,\N,Missing
bouamor-etal-2012-contrastive,W04-3219,0,\N,Missing
bouamor-etal-2012-contrastive,J10-3003,0,\N,Missing
bouamor-etal-2012-contrastive,C04-1077,0,\N,Missing
bouamor-etal-2012-contrastive,W03-1004,0,\N,Missing
bouamor-etal-2012-contrastive,P02-1040,0,\N,Missing
bouamor-etal-2012-contrastive,P01-1008,0,\N,Missing
bouamor-etal-2012-contrastive,C10-1149,0,\N,Missing
bouamor-etal-2012-contrastive,P08-4006,0,\N,Missing
bouamor-etal-2012-contrastive,W07-0734,0,\N,Missing
bouamor-etal-2012-contrastive,W09-0621,0,\N,Missing
bouamor-etal-2012-contrastive,P11-1020,0,\N,Missing
bouamor-etal-2012-contrastive,E09-1082,0,\N,Missing
bouamor-etal-2012-contrastive,J08-4005,0,\N,Missing
bouamor-etal-2012-contrastive,shimohata-etal-2004-building,0,\N,Missing
bouamor-etal-2012-contrastive,max-wisniewski-2010-mining,1,\N,Missing
D12-1066,P05-1074,0,0.234533,"f a pair are extracted from the other sentence, and the intersection of the sets for both directions is kept. Edit rate on word sequences (T ERp ) The T ERp tool (Snover et al., 2010) can be used to compute an optimal set of word and phrase edits that can transform one sentence into another one.9 Edit types are parameterized by one or more weights which were optimized towards F-measure by hill climbing with 100 random restarts using the held-out data set consisting of 125 sentence pairs for each corpus type. Translational equivalence (P IVOT) We exploited the paraphrase probability defined by Bannard and Callison-Burch (2005) on bilingual parallel corpora. We used the Europarl corpus10 of parliamentary debates in English and French, consisting of approximately 1.7 million parallel sentences, using each language as source and pivot in turn. G IZA ++ 9 Note that contrarily to what T ERp allows, we did not used the possibility of using word or phrase equivalents as those are only made available for English. This type of knowledge is however captured in part by the FASTR and P IVOT systems. 10 http://statmt.org/europarl Phrase pair features – edit distance between paraphrases, stem identity, bag-of-tokens similarity,"
D12-1066,W03-1004,0,0.0363564,"ally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study i"
D12-1066,P01-1008,0,0.118027,"summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for"
D12-1066,W08-0906,0,0.0143987,"type contains more than half of the total number of examples for the two languages. Finally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-B"
D12-1066,P08-1077,0,0.0228721,"Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition"
D12-1066,E12-1073,1,0.841294,"e pair candidates that include possible reference paraphrases will not penalize precision while not increasing recall. All performance values reported in the following sections will be obtained using 10-fold crossvalidation and averaging the results on each sub-test. All data sets of cross-validation contain 500 sentence pairs per corpus type, and 125 pairs are kept for development. 3.2 A framework for sub-sentential paraphrase identification We now describe the systems that will be tested on the various corpora described in section 2 using the methodology described in section 3.1. Following (Bouamor et al., 2012), a combination system is used to automatically weight paraphrase pair candidates produced by individual systems using a set of features aiming at recognizing paraphrases, as illustrated on Figure 3. Four individual systems have been used and are described below: the reasons for considering those systems include their free avail725 Statistical learning of word alignments (G IZA) The G IZA ++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized a"
D12-1066,C08-1013,0,0.0746642,"using such types of paraphrases into applications would however often be too strongly context-dependent. 724 TEXT SPEECH SCENE 70 EVENT 60 60 50 50 40 40 30 30 20 20 10 10 0 COSINE*100 BLEU 1-TER METEOR 0 COSINE*100 BLEU 1-TER METEOR Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). 3 3.1 Bilingual experiments across corpus types Evaluation of paraphrase acquisition We followed the PARAMETRIC methodology described in (Callison-Burch et al., 2008) for assessing the performance of systems on the task of subsentential paraphrase acquisition. In this methodology, a set of paraphrase candidates extracted from a sentence pair is compared with a set of reference paraphrases, obtained through human annotation, by computing usual measures of precision (P ) and recall (R). The first value corresponds to the proportion of paraphrase candidates, denoted H, produced by a system and that are correct relative to the reference set containing sure and possible paraphrases, denoted Rall . Recall is obtained by measuring the proportion of the reference"
D12-1066,P11-1020,0,0.141813,"escribed in (Tiedemann, 2007), based on time frames and developed for bilingual subtitles, we then filtered out sentence pairs below a minimal edit distance threshold, and manually removed obvious errors made by the algorithm. a boy rides a bike on a dirt road . So he uses the photo booths to remind people what he looks like . e.g. So he uses the photo booths to remind people what he looks like. ↔ He uses those machines to remind the living of his face. a boy is riding on a bicycle fast . Pigeons have numerical abilities just like primates S CENE We used the Multiple Video Description Corpus (Chen and Dolan, 2011) obtained from multiple descriptions of short videos. Similarly to what we did for T EXT, we selected sentence pairs from clusters by minimal edit distance above a threshold. An important fact is that for English we were able to use what is described as “verified” descriptions. There were, however, far fewer descriptions available for French, and none had the “verified” status. We decided to use this corpus nonetheless, but with the knowledge that this source for French is of a substantially lower quality (this corpus type will therefore appear as “(S CENE)” in all tables to reflect this). Pig"
D12-1066,J08-4005,0,0.137572,"d alignment matrices on Figure 1. A corpus for each type has been collected for 2 languages, English and French, and comprises 625 sentence pairs per language. We now briefly describe how each corpus was built. 721 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural c Language Learning, pages 721–731, Jeju Island, Korea, 12–14 July 2012. 2012 Association for Computational Linguistics It is anticipated that the annual total foreign trade volume will exceed US$9 billion . T EXT For English, we used the MTC corpus1 (described in (Cohn et al., 2008)) consisting of sets of news article translations from Chinese, and for French the CESTA corpus2 consisting of sets of news article translations from English. For each sentence cluster, we selected sentence pairs with minimal edit distance above an empirically-selected threshold, covering all clusters first and then selecting from already used clusters to reach the target number of sentence pairs. It is estimated that the total annual volume of import and export will exceed 9 billion US dollars . He uses those machines to remind the living of his face . e.g. It is estimated that the total annu"
D12-1066,C04-1051,0,0.0997121,"act that this corpus type contains more than half of the total number of examples for the two languages. Finally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in ("
D12-1066,W11-0111,0,0.0659731,"Missing"
D12-1066,C04-1151,0,0.0143876,"y more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisitio"
D12-1066,P08-4006,0,0.0272049,"dates differed from more than one day. We repeated the same selection procedure as for T EXT and S CENE to have a maximal cluster coverage and select more similar pairs first. e.g. Pigeons Have an Understanding of Numbers on Par With Primates ↔ Pigeons Have Numerical Abilities Just Like Primates Table 1 provides various statistics for these corpora. The first observation is that T EXT contains significantly larger sentences than the other types, more than twice as long as those of S PEECH. Annotation was performed following the guidelines proposed by Cohn et al. (2008)5 using the YAWAT tool (Germann, 2008), except that alignments where not initially obtained automatically so as not to bias our annotators’ work (there were two annotators per language). The main guidelines that they had to follow were that sure and possible paraphrases must be distinguished, smaller alignments were to be prefered but any-to-any alignments may be used, and sentences should be aligned as much as possible. Henceforth, we will only consider for all reported statistics and experiments those paraphrases that are not identity pairs (e.g. (a nice day ↔ a nice day)), as they are 4 http://news.google.com See http://staffww"
D12-1066,I11-1090,0,0.0115185,"to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify corpora of various degrees of semantic textual simila"
D12-1066,P99-1044,0,0.00825571,"ividual systems have been used and are described below: the reasons for considering those systems include their free avail725 Statistical learning of word alignments (G IZA) The G IZA ++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized alignments were kept and classical phrase extraction heuristics were applied (Koehn et al., 2003), without growing phrases with unaligned tokens. Linguistic knowledge on term variation (FASTR) The FASTR tool (Jacquemin, 1999) spots term variants in large corpora, where variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on morphosyntactic categories. Paradigmatic variation can also be expressed with constraints between words, imposing that they be of the same morphological or semantic family using existing resources available in our two languages. Variants for all phrases from one sentence of a pair are extracted from the other sentence, and the intersection of the sets for both directions is kept."
D12-1066,N03-1017,0,0.00378411,"ates produced by individual systems using a set of features aiming at recognizing paraphrases, as illustrated on Figure 3. Four individual systems have been used and are described below: the reasons for considering those systems include their free avail725 Statistical learning of word alignments (G IZA) The G IZA ++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized alignments were kept and classical phrase extraction heuristics were applied (Koehn et al., 2003), without growing phrases with unaligned tokens. Linguistic knowledge on term variation (FASTR) The FASTR tool (Jacquemin, 1999) spots term variants in large corpora, where variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on morphosyntactic categories. Paradigmatic variation can also be expressed with constraints between words, imposing that they be of the same morphological or semantic family using existing resources available in our two languages. Variants for all phrases f"
D12-1066,P07-2045,0,0.00433743,"milarity of token context vectors for each phrase of a paraphrase (derived from counts in the large English-French parallel corpus from WMT’11 (http://www.statmt.org/ wmt11/translation-task.html) (approx. 30 million parallel sentences) System features – combination of the individual systems that proposed the paraphrase pair Table 3: Features used by our classifiers. Discretized intervals based on median values are used for real values, and binarized values are used for combinations. was used for word alignment and phrase translation probabilities were estimated from them by the M OSES system (Koehn et al., 2007). For each phrase of a sentence pair, we built its set of paraphrases, and extracted its paraphrase from the other sentence with highest probability. We repeated this process in both directions, and finally kept for each phrase its paraphrase pair from any direction with highest probability. Automatic validation of candidate paraphrases Taking the union of all paraphrase pair candidates from all the above systems for each sentence pair, we perform a Maximum Entropy two-class classification11 , which allows us to include features that were not necessarily exploited or straightforward to exploit"
D12-1066,N10-1017,0,0.0142172,"paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains i"
D12-1066,W07-0734,0,0.0712034,"Missing"
D12-1066,D10-1090,0,0.012901,"al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sen"
D12-1066,J10-3003,0,0.11718,"escribes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given. 1 Introduction Sub-sentential paraphrases can be acquired from text pairs expressing the same meaning (Madnani and Dorr, 2010). If the semantic similarity of a text pair has a direct impact on the quality of the acquired paraphrases, it has, to our knowledge, never been shown what impact the type of original signal has on paraphrase acquisition. In this work, we consider four types of corpora, which we think are representative of the main types of original semantic signals: text pairs (roughly, sentences) originating a) from independent translations of a text (T EXT), b) from independent translations of a speech (S PEECH), c) from independent descriptions of a visual scene (S CENE), and d) from independent descriptio"
D12-1066,2008.amta-papers.13,0,0.0116239,"hey report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify cor"
D12-1066,D09-1040,0,0.0290815,"ness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify corpora of various degre"
D12-1066,D10-1064,1,0.833483,"s difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify corpora of various degrees of seman"
D12-1066,P11-2096,0,0.0136934,". To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pair"
D12-1066,E06-1021,0,0.0169469,"ase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several c"
D12-1066,J04-4002,0,0.00874287,"araphrase identification We now describe the systems that will be tested on the various corpora described in section 2 using the methodology described in section 3.1. Following (Bouamor et al., 2012), a combination system is used to automatically weight paraphrase pair candidates produced by individual systems using a set of features aiming at recognizing paraphrases, as illustrated on Figure 3. Four individual systems have been used and are described below: the reasons for considering those systems include their free avail725 Statistical learning of word alignments (G IZA) The G IZA ++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized alignments were kept and classical phrase extraction heuristics were applied (Koehn et al., 2003), without growing phrases with unaligned tokens. Linguistic knowledge on term variation (FASTR) The FASTR tool (Jacquemin, 1999) spots term variants in large corpora, where variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of r"
D12-1066,N03-1024,0,0.0385101,"d Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Altho"
D12-1066,P02-1040,0,0.0840745,"Missing"
D12-1066,I05-1011,0,0.0215987,"Missing"
D12-1066,D10-1013,0,0.0152712,"ge. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora"
D12-1066,E09-1082,0,0.0134125,"r corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for"
D12-1066,2006.amta-papers.25,0,0.0293574,"Missing"
D12-1066,W09-0621,0,0.0487281,"Missing"
D12-1066,P09-1094,0,0.0240288,"Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, mon"
D12-1066,S12-1051,0,\N,Missing
D12-1066,2010.amta-workshop.3,0,\N,Missing
E03-1085,abeille-etal-2000-building,0,0.648194,"ny segmentation chosen by a parser to be converted into our formalism. For the same reason, the information that is not expressed in the constituents is expressed through a large number of functional relations: twelve in all. Such formalism is closer to a dependency-based formalism than to a constituent based formalism (Sleator and Temperley, 1991). It neither prevents the ""deep"" parsers to be evaluated, nor disadvantages them, but the transcription of their parses could be more complex. The six types of chunks and twelve functional relations are given in table 1. They were mainly inspired by Abeille et al. (2000), and have been adapted while annotating corpus excerpts. Chunks Functional relations NV — verbal subject-verb GN — nominal auxiliary-verb GR — adverbial argument-verb GA — adjectival modifier-verb GP — prepositional introducing a nominal phrase modifier-noun PV — prepositional introducing a verbal phrase modifier-adverb modifier-adjective attribute-subject/object Coordination Apposition Complementer 96 No clausal or sentential segmentation is identified, because as in a dependency-based formalism, the complex structure of the sentence is obtained through the whole chain of relations. The foll"
E03-1085,gendner-etal-2002-protocol,1,0.794438,"Missing"
E12-1073,P05-1074,0,0.569991,"ms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological"
E12-1073,N03-1003,0,0.129166,"phrases, occur in similar contexts then they may be interchangeable has been extensively tested. The distributional hypothesis, attributed to Zellig Harris, was for example applied to syntactic dependency paths in the work of Lin and Pantel (2001). Their results take the form of equivalence patterns with two arguments such as {X asks for Y, X requests Y, X’s request for Y, X wants Y, Y is requested by X, . . .}. Using comparable corpora, where the same information probably exists under various linguistic forms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora i"
E12-1073,P01-1008,0,0.780616,"local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition."
E12-1073,P08-1077,0,0.0788221,"ndency paths in the work of Lin and Pantel (2001). Their results take the form of equivalence patterns with two arguments such as {X asks for Y, X requests Y, X’s request for Y, X wants Y, Y is requested by X, . . .}. Using comparable corpora, where the same information probably exists under various linguistic forms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a"
E12-1073,C08-1013,0,0.212209,"Missing"
E12-1073,D08-1021,0,0.0523473,"des local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple transl"
E12-1073,candito-etal-2010-statistical,0,0.022921,"Missing"
E12-1073,P11-1020,0,0.265691,"Missing"
E12-1073,J08-4005,0,0.252742,"nsists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-senten"
E12-1073,C04-1051,0,0.507008,"Missing"
E12-1073,P08-4006,0,0.16624,"indicates the proportion of tokens from the sentence pairs that could be manually aligned by a native-speaker annotator.2 Obviously, the more common tokens two sentences from a pair contain, the fewer subsentential paraphrases may be extracted from that pair. However, high lexical overlap increases the probability that two sentences be indeed paraphrases, and in turn the probability that some of their phrases be paraphrases. Furthermore, the tated corpora using them we considered all alignments as being correct. 2 The same annotator hand-aligned the 5*100=500 paraphrase pairs using the YAWAT (Germann, 2008) manual alignment tool. presence of common token may serve as useful clues to guide paraphrase extraction. For our experiments, we chose to use parallel monolingual corpora obtained by single language translation, the most direct resource type for acquiring sub-sentential paraphrase pairs. This allows us to define acceptable references for the task and resort to the most consensual evaluation technique for paraphrase acquisition to date. Using such corpora, we expect to be able to extract precise paraphrases (see Table 1), which will be natural candidates for further validation, which will be"
E12-1073,P99-1044,0,0.614531,"more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis"
E12-1073,P03-1054,0,0.00429764,"sider all phrases from 5 http://statmt.org/europarl the first sentence and search for variants in the other sentence, then do the reverse process and finally take the intersection of the two sets. 4.4 Syntactic similarity (Synt) The algorithm introduced by Pang et al. (2003) takes two sentences as input and merges them by top-down syntactic fusion guided by compatible syntactic substructure. A lexical blocking mechanism prevents constituents from fusionning when there is evidence of the presence of a word in another constituent of one of the sentence. We use the Berkeley Probabilistic parser (Klein and Manning, 2003) to obtain syntactic trees for English and its adapted version for French (Candito et al., 2010). Because this process is highly sensitive to syntactic parse errors, we use in our implementation k-best parses and retain the most compact fusion from any pair of candidate parses. 4.5 Edit rate on word sequences (TERp ) TERp (Translation Edit Rate Plus) (Snover et al., 2010) is a score designed for the evaluation of Machine Translation output. Its typical use takes a system hypothesis to compute an optimal set of word edits that can transform it into some existing reference translation. Edit type"
E12-1073,P07-2045,0,0.00309514,"ability between two phrases based on their translation probability through all possible pivot phrases as: X Ppara (p1 , p2 ) = Pt (piv|p1 )Pt (p2 |piv) piv where Pt denotes translation probabilies. We used the Europarl corpus5 of parliamentary debates in English and French, consisting of approximately 1.7 million parallel sentences : this allowed us to use the same resource to build paraphrases for English, using French as the pivot language, and for French, using English as the pivot language. The GIZA++ tool was used for word alignment and the M OSES Statistical Machine Translation toolkit (Koehn et al., 2007) was used to compute phrase translation probabilities from these word alignments. For each sentential paraphrase pair, we applied the following algorithm: for each phrase, we build the entire set of paraphrases using the previous definition. We then extract its best paraphrase as the one exactly appearing in the other sentence with maximum paraphrase probability, using a minimal threshold value of 10−4 . 4.3 Linguistic knowledge on term variation (Fastr) The FASTR tool (Jacquemin, 1999) was designed to spot term/phrase variants in large corpora. Variants are described through metarules express"
E12-1073,D10-1090,0,0.20541,"Missing"
E12-1073,J10-3003,0,0.0362016,"quivalent meaning at the phrasal level (including single words). For instance, the phrases six months and half a year form a paraphrase pair applicable in many different contexts, as they would appropriately denote the same concept. Although one can envisage to manually build high-coverage lists of synonyms, enumerating meaning equivalences at the level of phrases is too daunting a task for humans. Because this type of knowledge can however greatly benefit many NLP applications, automatic acquisition of such paraphrases has attracted a lot of attention (Androutsopoulos and Malakasiotis, 2010; Madnani and Dorr, 2010), and significant research efforts have been devoted to this objective (Callison-Burch, 2007; Bhagat, 2009; Madnani, 2010). Central to acquiring paraphrases is the need of assessing the quality of the candidate paraphrases produced by a given technique. Most works to date have resorted to human evaluation of paraphrases on the levels of grammaticality and meaning equivalence. Human evaluation is however often criticized as being both costly and non reproducible, and the situation is even more complicated by the inherent complexity of the task that can produce low inter-judge agreement. Taskbas"
E12-1073,P11-2096,0,0.341476,"Missing"
E12-1073,J04-4002,0,0.0481864,"ork. In this work, we consider the scenario where sentential paraphrases are available and words and phrases from one sentence can be aligned to words and phrases from the other sentence to form atomic paraphrase pairs. We now describe several techniques that perform the task of sub-sentential unit alignment. We have selected and implemented five techniques which we believe are representative of the type of knowledge that these techniques use, and have reused existing tools, initially developed for other tasks, when possible. 4.1 Statistical learning of word alignments (Giza) The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. While originally developed in the bilingual context of Statistical Machine Translation, nothing prevents building such models on monolingual corpora. However, in order to build reliable models, it is necessary to use enough training material including minimal redundancy of words. To this end, we provided GIZA++ with all possible sentence pairs from our mutiply-translated corpus to improve the quality of its word alignments (note that 4 719 http://www.elda.org/article125.html we used symmetrized alignmen"
E12-1073,N03-1024,0,0.142135,"ariants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. Pairs of related sentences are hand-aligned to define a set of reference atomic paraphrase p"
E12-1073,P08-1089,0,0.0629322,"lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level"
F12-2015,P05-1074,0,0.100015,"Missing"
F12-2015,N03-1003,0,0.0998693,"Missing"
F12-2015,P01-1008,0,0.128195,"Missing"
F12-2015,P08-1077,0,0.0466614,"Missing"
F12-2015,P11-2069,1,0.832338,"Missing"
F12-2015,I05-5001,0,0.0442445,"Missing"
F12-2015,candito-etal-2010-statistical,0,0.0313508,"Missing"
F12-2015,J08-4005,0,0.0391223,"Missing"
F12-2015,C08-1018,0,0.0238144,"Missing"
F12-2015,W09-3102,0,0.0252956,"Missing"
F12-2015,D11-1108,0,0.0281563,"Missing"
F12-2015,N10-1017,0,0.024775,"Missing"
F12-2015,J10-3003,0,0.0338433,"Missing"
F12-2015,2008.amta-papers.13,0,0.0544819,"Missing"
F12-2015,C04-1166,1,0.861184,"Missing"
F12-2015,max-wisniewski-2010-mining,1,0.905676,"Missing"
F12-2015,W08-1911,1,0.894545,"Missing"
F12-2015,P10-2001,0,0.0606923,"Missing"
F12-2015,N03-1024,0,0.0273338,"Missing"
F12-2015,I05-1011,0,0.070267,"Missing"
F12-2015,N07-1051,0,0.0193161,"Missing"
F12-2015,W04-3219,0,0.0732191,"Missing"
F12-2015,D10-1013,0,0.0613904,"Missing"
F12-2015,E09-1082,0,0.0252746,"Missing"
F12-2015,N10-2012,0,0.0230885,"Missing"
F12-2015,P09-1094,0,0.0541476,"Missing"
F12-2015,C10-1149,0,0.0375349,"Missing"
F12-2015,C10-1152,0,0.0607389,"Missing"
F12-2020,P05-1074,0,0.104377,"Missing"
F12-2020,W03-1004,0,0.0177066,"Missing"
F12-2020,P01-1008,0,0.134909,"Missing"
F12-2020,W08-0906,0,0.0568488,"Missing"
F12-2020,P08-1077,0,0.04689,"Missing"
F12-2020,C08-1013,0,0.0337731,"Missing"
F12-2020,W11-2504,0,0.0299908,"Missing"
F12-2020,P11-1020,0,0.0337687,"Missing"
F12-2020,J08-4005,0,0.0286401,"Missing"
F12-2020,D10-1113,0,0.0284105,"Missing"
F12-2020,C04-1051,0,0.0305195,"Missing"
F12-2020,P10-2017,0,0.0473081,"Missing"
F12-2020,W11-0111,0,0.0510101,"Missing"
F12-2020,C04-1151,0,0.0202999,"Missing"
F12-2020,P08-4006,0,0.0272382,"Missing"
F12-2020,P99-1044,0,0.0159824,"Missing"
F12-2020,P07-2045,0,0.00680795,"Missing"
F12-2020,N03-1017,0,0.00672789,"Missing"
F12-2020,N10-1017,0,0.0209541,"Missing"
F12-2020,P10-4008,0,0.0247424,"Missing"
F12-2020,W07-0734,0,0.0414566,"Missing"
F12-2020,D10-1090,0,0.0286066,"Missing"
F12-2020,J10-3003,0,0.0436927,"Missing"
F12-2020,2008.amta-papers.13,0,0.0208433,"Missing"
F12-2020,D09-1040,0,0.0235767,"Missing"
F12-2020,D10-1064,1,0.874667,"Missing"
F12-2020,P11-2096,0,0.0210605,"Missing"
F12-2020,E06-1021,0,0.0267946,"Missing"
F12-2020,J04-4002,0,0.0126002,"Missing"
F12-2020,N03-1024,0,0.0196593,"Missing"
F12-2020,P02-1040,0,0.085289,"Missing"
F12-2020,I05-1011,0,0.0668427,"Missing"
F12-2020,D10-1013,0,0.0442446,"Missing"
F12-2020,E09-1082,0,0.0227366,"Missing"
F12-2020,2006.amta-papers.25,0,0.0530812,"Missing"
F12-2020,W09-0621,0,0.0209422,"Missing"
F12-2020,P09-1094,0,0.0370838,"Missing"
F13-2022,abeille-etal-2000-building,0,0.25588,"Missing"
F13-2022,W06-2920,0,0.0567215,"Missing"
F13-2022,C10-2013,0,0.0544182,"Missing"
F13-2022,F12-2024,0,0.0225171,"Missing"
F13-2022,N04-1013,0,0.0893033,"Missing"
F13-2022,villemonte-de-la-clergerie-etal-2008-passage,1,0.754008,"Missing"
F13-2022,W08-1301,0,0.12586,"Missing"
F13-2022,W03-2401,0,0.0846126,"Missing"
F13-2022,paroubek-etal-2006-data,1,0.872343,"Missing"
F13-2022,vilnat-etal-2010-passage,1,0.863273,"Missing"
F14-1001,C08-1031,0,0.0716509,"Missing"
F14-1001,D12-1120,0,0.0410189,"Missing"
F14-1001,C08-1104,0,0.0644723,"Missing"
F14-1001,E06-1026,0,0.0318269,"Missing"
F14-1001,N07-1037,0,0.0387121,"Missing"
F14-1001,P08-1036,0,0.0506968,"Missing"
F14-1001,P06-1134,0,0.110672,"Missing"
F14-1001,H05-1044,0,0.0724191,"Missing"
F14-1001,J09-3003,0,0.099458,"Missing"
F14-1001,S10-1014,0,0.0302818,"Missing"
F14-2011,falco-etal-2012-kitten,1,0.85603,"Missing"
F14-2011,quintard-etal-2010-question,1,0.884846,"Missing"
F14-2011,tannier-2012-webannotator,0,0.040234,"Missing"
falco-etal-2012-kitten,quintard-etal-2010-question,1,\N,Missing
falco-etal-2012-kitten,baroni-etal-2008-cleaneval,0,\N,Missing
garcia-fernandez-etal-2010-macaq,toney-etal-2008-evaluation,1,\N,Missing
garcia-fernandez-etal-2014-construction,E12-1034,0,\N,Missing
garcia-fernandez-etal-2014-construction,W10-0208,0,\N,Missing
garcia-fernandez-etal-2014-construction,W10-0212,0,\N,Missing
garcia-fernandez-etal-2014-construction,Y09-1013,0,\N,Missing
garcia-fernandez-etal-2014-construction,D11-1067,0,\N,Missing
garcia-fernandez-etal-2014-construction,W10-0205,0,\N,Missing
garcia-fernandez-etal-2014-construction,H05-1073,0,\N,Missing
garcia-fernandez-etal-2014-construction,Y11-1029,0,\N,Missing
garcia-fernandez-etal-2014-construction,el-maarouf-villaneau-2012-french,0,\N,Missing
garcia-fernandez-etal-2014-construction,doukhan-etal-2012-designing,0,\N,Missing
garcia-fernandez-etal-2014-construction,P13-1167,0,\N,Missing
garcia-fernandez-etal-2014-construction,N12-1038,0,\N,Missing
gendner-etal-2002-protocol,paroubek-2000-language,1,\N,Missing
gendner-etal-2002-protocol,mengel-lezius-2000-xml,0,\N,Missing
gendner-etal-2002-protocol,J93-2004,0,\N,Missing
gendner-etal-2002-protocol,A97-1012,0,\N,Missing
gendner-etal-2002-protocol,C92-3129,0,\N,Missing
gendner-etal-2002-protocol,C96-2120,0,\N,Missing
gendner-etal-2002-protocol,H94-1020,0,\N,Missing
gendner-etal-2002-protocol,P01-1040,0,\N,Missing
gendner-etal-2002-protocol,lenci-etal-2000-opposites,0,\N,Missing
grappy-etal-2010-corpus,cramer-etal-2006-building,0,\N,Missing
grappy-etal-2010-corpus,rosset-petel-2006-ritel,0,\N,Missing
grappy-etal-2010-corpus,varasai-etal-2008-building,0,\N,Missing
P11-2069,P05-1074,0,0.0676412,"oses. We show that the tunable TER-PLUS metric from Machine Translation evaluation can achieve good performance on this task and that it can effectively exploit information coming from complementary sources. 1 Introduction The acquisition of subsentential paraphrases has attracted a lot of attention recently (Madnani and Dorr, 2010). Techniques are usually developed for extracting paraphrase candidates from specific types of corpora, including monolingual parallel corpora (Barzilay and McKeown, 2001), monolingual comparable corpora (Del´eger and Zweigenbaum, 2009), bilingual parallel corpora (Bannard and Callison-Burch, 2005), and edit histories of multi-authored text (Max and Wisniewski, 2010). These approaches face two main issues, which correspond to the typical measures of precision, or how appropriate the extracted paraphrases are, and of recall, or how many of the paraphrases present in a given corpus can be found effectively. To start with, both measures are often hard to compute in practice, as 1) the definition of what makes an acceptable paraphrase pair is still a research question, and 2) it is often impractical to extract a complete set of acceptable paraphrases 395 from most resources. Second, as rega"
P11-2069,C08-1013,0,0.0203037,"ties. We are finally also in the process of conducting a careful study of the characteristics of the paraphrase pairs that each technique can extract with high confidence, so that we can improve our hybridation experiments by considering confidence values at the paraphrase level using Machine Learning. This way, we may be able to use an edit rate computation algorithm such as TER-PLUS as a more efficient system combiner for paraphrase extraction methods than what was proposed here. A potential application of this would be an alternative proposal to the paraphrase evaluation metric PARAMETRIC (Callison-Burch et al., 2008), where individual techniques, outputing word alignments or not, could be evaluated from the ability of the informated edit rate technique to use correct equivalence units. 4 Indeed, measuring the precision on the union yields a poor performance of 23.96, but with the highest achievable value of 50.56 for recall. Similarly, the maximum value for precision with a good recall can be obtained by taking the intersection of the results of TER Ppara and G IZA ++, which yields a value of 60.39. 399 Acknowledgments This work was partly funded by a grant from LIMSI. The authors wish to thank the anonym"
P11-2069,candito-etal-2010-statistical,0,0.0892695,"Missing"
P11-2069,J08-4005,0,0.747644,"et al., 2004) often contain unrelated segments that should not be aligned to form a subsentential paraphrase pair. Using bilingual corpora to acquire paraphrases indirectly by pivoting through other languages is faced, in particular, with the issue of phrase polysemy, both in the source and in the pivot languages. It has previously been noted that highly parallel monolingual corpora, typically obtained via multiple translation into the same language, constitute the most appropriate type of corpus for extracting high quality paraphrases, in spite of their rareness (Barzilay and McKeown, 2001; Cohn et al., 2008; Bouamor et al., 2010). We build on this claim here to propose an original approach for the task of subsentential alignment based on the computation of a minimum edit rate between two sentential paraphrases. More precisely, we concentrate on the alignment of atomic paraphrase pairs (Cohn et al., 2008), where the words from both paraphrases are aligned as a whole to the words of the other paraphrase, as opposed to composite paraphrase pairs obtained by joining together adjacent paraphrase pairs or possibly adding unaligned words. Figure 1 provides examples of atomic paraphrase pairs derived fr"
P11-2069,W09-3102,0,0.426347,"Missing"
P11-2069,C04-1051,0,0.0546249,"measures are often hard to compute in practice, as 1) the definition of what makes an acceptable paraphrase pair is still a research question, and 2) it is often impractical to extract a complete set of acceptable paraphrases 395 from most resources. Second, as regards the precision of paraphrase acquisition techniques in particular, it is notable that most works on paraphrase acquisition are not based on direct observation of larger paraphrase pairs. Even monolingual corpora obtained by pairing very closely related texts such as news headlines on the same topic and from the same time frame (Dolan et al., 2004) often contain unrelated segments that should not be aligned to form a subsentential paraphrase pair. Using bilingual corpora to acquire paraphrases indirectly by pivoting through other languages is faced, in particular, with the issue of phrase polysemy, both in the source and in the pivot languages. It has previously been noted that highly parallel monolingual corpora, typically obtained via multiple translation into the same language, constitute the most appropriate type of corpus for extracting high quality paraphrases, in spite of their rareness (Barzilay and McKeown, 2001; Cohn et al., 2"
P11-2069,P08-4006,0,0.0199569,"11.92 18.47 17.10 6.94 21.02 20.28 3.41 18.94 16.44 13.57 19.30 16.35 f1 16.25 9.30 4.21 18.77 4.31 19.26 19.52 16.52 19.14 18.95 11.91 20.92 21.33 6.15 18.47 17.59 18.58 17.96 21.02 Figure 2: Results on the test set on French and English for the individual techniques and TER P hybrid systems. Column headers of the form “→ c” indicate that TER P was tuned on criterion c. figures reveal that the French corpus tends to contain more literal translations, possibly due to the original languages of the sentences, which are closer to the target language than Chinese is to English. We used the YAWAT (Germann, 2008) interactive alignment tool and measure inter-annotator agreement over a subset and found it to be similar to the value reported by Cohn et al. (2008) for English. Results for all individual techniques in the two languages are given on Figure 2. We first note that all techniques fared better on the French corpus than on the English corpus. This can certainly be explained by the fact that the former results from more literal translations, which are consequently easier to word-align. TERMT (i.e. TER tuned for Machine Translation evaluation) performs significantly worse on all metrics for both la"
P11-2069,P99-1044,0,0.0302307,"models it is necessary to use enough training material including minimal redundancy of words. To this end, we will be using monolingual corpora made up of multiply-translated sentences, allowing us to provide GIZA++ with all possible sentence pairs to improve the quality of its word alignments (note that following common practice we used symetrized alignments from the alignments in both directions). This constitutes an advantage for this technique that the following techniques working on each sentence pair independently do not have. Symbolic expression of linguistic variation The FASTR tool (Jacquemin, 1999) was designed to spot term variants in large corpora. Variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on word categories. Paradigmatic variation can also be expressed by defining constraints between words to force them to belong to the same morphological or semantic family, both constraints relying on preexisting repertoires available for English and French. To compute candidate paraphrase pairs using FASTR, we first consider all the phrases from the first sentence and searc"
P11-2069,J10-3003,0,0.064709,", we present a novel way of tackling the monolingual alignment problem on pairs of sentential paraphrases by means of edit rate computation. In order to inform the edit rate, information in the form of subsentential paraphrases is provided by a range of techniques built for different purposes. We show that the tunable TER-PLUS metric from Machine Translation evaluation can achieve good performance on this task and that it can effectively exploit information coming from complementary sources. 1 Introduction The acquisition of subsentential paraphrases has attracted a lot of attention recently (Madnani and Dorr, 2010). Techniques are usually developed for extracting paraphrase candidates from specific types of corpora, including monolingual parallel corpora (Barzilay and McKeown, 2001), monolingual comparable corpora (Del´eger and Zweigenbaum, 2009), bilingual parallel corpora (Bannard and Callison-Burch, 2005), and edit histories of multi-authored text (Max and Wisniewski, 2010). These approaches face two main issues, which correspond to the typical measures of precision, or how appropriate the extracted paraphrases are, and of recall, or how many of the paraphrases present in a given corpus can be found"
P11-2069,max-wisniewski-2010-mining,1,0.799494,"tion can achieve good performance on this task and that it can effectively exploit information coming from complementary sources. 1 Introduction The acquisition of subsentential paraphrases has attracted a lot of attention recently (Madnani and Dorr, 2010). Techniques are usually developed for extracting paraphrase candidates from specific types of corpora, including monolingual parallel corpora (Barzilay and McKeown, 2001), monolingual comparable corpora (Del´eger and Zweigenbaum, 2009), bilingual parallel corpora (Bannard and Callison-Burch, 2005), and edit histories of multi-authored text (Max and Wisniewski, 2010). These approaches face two main issues, which correspond to the typical measures of precision, or how appropriate the extracted paraphrases are, and of recall, or how many of the paraphrases present in a given corpus can be found effectively. To start with, both measures are often hard to compute in practice, as 1) the definition of what makes an acceptable paraphrase pair is still a research question, and 2) it is often impractical to extract a complete set of acceptable paraphrases 395 from most resources. Second, as regards the precision of paraphrase acquisition techniques in particular,"
P11-2069,J04-4002,0,0.0177494,"acquisition, which we will only briefly introduce (see (Bouamor et al., 2010) for more details). As explained previously, we want to evaluate whether and how their candidate paraphrase pairs can be used to improve paraphrase acquisition on sentential paraphrases using TER- PLUS. We selected these three techniques for the complementarity of types of information that they use: statistical word alignment without a priori linguistic knowledge, symbolic expression of linguistic variation exploiting a priori linguistic knowledge, and syntactic similarity. Statistical Word Alignment The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. While originally developped in the bilingual context of Machine Translation, nothing prevents building such models on monolingual corpora. However, in order to build reliable models it is necessary to use enough training material including minimal redundancy of words. To this end, we will be using monolingual corpora made up of multiply-translated sentences, allowing us to provide GIZA++ with all possible sentence pairs to improve the quality of its word alignments (note that following common practice w"
P11-2069,N03-1024,0,0.520245,"Missing"
P11-2069,N07-1051,0,0.0463616,"Missing"
P11-2069,P08-1089,0,0.0201834,"t at the subsentential level from sentential paraphrases and the possibility of informing this search with paraphrase candidates coming from other techniques. Our experiments have shown that in some circumstances some techniques have a good complementarity and manage to improve results significantly. We are currently studying hard-to-align subsentential paraphrases from the type of corpora we used in order to get a better understanding of the types of knowledge required to improve automatic acquisition of these units. Our future work also includes the acquisition of paraphrase patterns (e.g. (Zhao et al., 2008)) to generalize the acquired equivalence units to more contexts, which could be both used in applications and to attempt improving further paraphrase acquisition techniques. Integrating the use of patterns within an edit rate computation technique will however raise new difficulties. We are finally also in the process of conducting a careful study of the characteristics of the paraphrase pairs that each technique can extract with high confidence, so that we can improve our hybridation experiments by considering confidence values at the paraphrase level using Machine Learning. This way, we may"
P11-2069,P01-1008,0,\N,Missing
paroubek-etal-2006-data,J93-2004,0,\N,Missing
paroubek-etal-2006-data,W04-2703,0,\N,Missing
paroubek-etal-2006-data,J05-1004,0,\N,Missing
paroubek-etal-2006-data,vilnat-etal-2004-ongoing,1,\N,Missing
paroubek-etal-2006-data,H91-1060,0,\N,Missing
paroubek-etal-2008-easy,paroubek-2000-language,1,\N,Missing
paroubek-etal-2008-easy,J93-2004,0,\N,Missing
paroubek-etal-2008-easy,vilnat-etal-2004-ongoing,1,\N,Missing
paroubek-etal-2008-easy,chaudiron-mariani-2006-techno,0,\N,Missing
paroubek-etal-2008-easy,paroubek-etal-2006-data,1,\N,Missing
quintard-etal-2010-question,ayache-etal-2006-equer,1,\N,Missing
quintard-etal-2010-question,bernard-etal-2010-question,1,\N,Missing
R09-1053,E03-1020,0,0.020851,"c spaces where each word is represented by a vector from which is derived a measure of similarity with other words, similar words can be grouped together Senses of polysemic words can be induced from various term selections. In [10], clusters are built in one step from the full vocabulary, each word may appear in several clusters. These clusters represent synonym classes and senses of words belonging to several clusters are thus discriminated. [17] approach consists in clustering all the occurence contexts in a corpus of each word for which senses are being learned. Finally, some systems like [4], [20] or [6] cluster cooccurrents of the words they want to distinguish the senses and [14] cluster the nearest neighbors in the semantic space. Our work largely follows [14] as we also group nearest neighbors but differs from it as we dispose of a panel of different semantic spaces (built on different syntactic relations) with different specificities that we combine, instead of using a unique semantic space. Section 2 of this paper details the conception of the semantic spaces we use. We present in Section 3 the method of dimensionality reduction we use. Section 4 describes the clustering me"
R09-1053,C04-1194,0,0.104984,"e each word is represented by a vector from which is derived a measure of similarity with other words, similar words can be grouped together Senses of polysemic words can be induced from various term selections. In [10], clusters are built in one step from the full vocabulary, each word may appear in several clusters. These clusters represent synonym classes and senses of words belonging to several clusters are thus discriminated. [17] approach consists in clustering all the occurence contexts in a corpus of each word for which senses are being learned. Finally, some systems like [4], [20] or [6] cluster cooccurrents of the words they want to distinguish the senses and [14] cluster the nearest neighbors in the semantic space. Our work largely follows [14] as we also group nearest neighbors but differs from it as we dispose of a panel of different semantic spaces (built on different syntactic relations) with different specificities that we combine, instead of using a unique semantic space. Section 2 of this paper details the conception of the semantic spaces we use. We present in Section 3 the method of dimensionality reduction we use. Section 4 describes the clustering methods develop"
R09-1053,P98-2127,0,0.0415511,"e number of cooccurrences, in fixed-size windows, between the line term and the column term (or possibly the mutual information). In [13] and [7], each dimension corresponds to a context obtained through a given syntactic 287 International Conference RANLP 2009 - Borovets, Bulgaria, pages 287–291 relation and the value is their cooccurrence frequency. With these semantic spaces where each word is represented by a vector from which is derived a measure of similarity with other words, similar words can be grouped together Senses of polysemic words can be induced from various term selections. In [10], clusters are built in one step from the full vocabulary, each word may appear in several clusters. These clusters represent synonym classes and senses of words belonging to several clusters are thus discriminated. [17] approach consists in clustering all the occurence contexts in a corpus of each word for which senses are being learned. Finally, some systems like [4], [20] or [6] cluster cooccurrents of the words they want to distinguish the senses and [14] cluster the nearest neighbors in the semantic space. Our work largely follows [14] as we also group nearest neighbors but differs from i"
R09-1053,J07-2002,0,0.0296332,"he emergence of new words in a constantly evolving domain . Semantic spaces can be built using various context types such as documents, paragraphs or occuring words, or again lemmas appearing near the source word (cooccurents). In [16], dimensions of Vector Space Model represent the terms occurrence frequencies in each document where each column represent a document. In [11], dimensions correspond to the most frequent terms of the vocabulary and the values are the number of cooccurrences, in fixed-size windows, between the line term and the column term (or possibly the mutual information). In [13] and [7], each dimension corresponds to a context obtained through a given syntactic 287 International Conference RANLP 2009 - Borovets, Bulgaria, pages 287–291 relation and the value is their cooccurrence frequency. With these semantic spaces where each word is represented by a vector from which is derived a measure of similarity with other words, similar words can be grouped together Senses of polysemic words can be induced from various term selections. In [10], clusters are built in one step from the full vocabulary, each word may appear in several clusters. These clusters represent synonym"
R09-1053,P05-1077,0,0.141762,"Latent Semantic Analysis [9] would have been an alternative if not for the original dimensionality of our data and the quadratic (O(n3 )) complexity of the underlying Singular Vector Decomposition. On the other hand, Random Indexing [19] while more scalable, was not a real option because of its reported low quality. We chose to use Locality Sensitive Hashing which is supposed to be more scalable than LSA and whose quality was still to be tested on complex tasks. [3] has defined a family of LSH functions for which the hashed signatures keep their angular similarity for any input vectors pair. [15] has shown that this hashing is particularly well adapted to set up a fast nearest neighbors search method. 3.1 Dimension reduction: sensitive hashing Locality The goal of a hashing is to obtain a footprint smaller than the original signature. Here, we want a function h giving a smaller footprint and respecting the property that if two vectors v1 and v2 from the initial space are similar, then the two hashed vectors h(v1 ) and h(v2 ) are also similar.The hashing functions family proposed by [3] allows to approximate the cosinus measure whose efficiency has already been shown for proximities of"
R09-1053,J98-1004,0,0.125818,"c 287 International Conference RANLP 2009 - Borovets, Bulgaria, pages 287–291 relation and the value is their cooccurrence frequency. With these semantic spaces where each word is represented by a vector from which is derived a measure of similarity with other words, similar words can be grouped together Senses of polysemic words can be induced from various term selections. In [10], clusters are built in one step from the full vocabulary, each word may appear in several clusters. These clusters represent synonym classes and senses of words belonging to several clusters are thus discriminated. [17] approach consists in clustering all the occurence contexts in a corpus of each word for which senses are being learned. Finally, some systems like [4], [20] or [6] cluster cooccurrents of the words they want to distinguish the senses and [14] cluster the nearest neighbors in the semantic space. Our work largely follows [14] as we also group nearest neighbors but differs from it as we dispose of a panel of different semantic spaces (built on different syntactic relations) with different specificities that we combine, instead of using a unique semantic space. Section 2 of this paper details the"
R09-1053,sellberg-jonsson-2008-using,0,0.0196102,"rse square matrices of 68,000 dimensions. We will see later that these matrices contain different and complementary kind of information. 3 Approximative KNN Given the size of these matrices, it is highly desirable to perform a dimensionality reduction before using them for nearest neighbor search and clustering. A linear Principal Component Analysis method such as Latent Semantic Analysis [9] would have been an alternative if not for the original dimensionality of our data and the quadratic (O(n3 )) complexity of the underlying Singular Vector Decomposition. On the other hand, Random Indexing [19] while more scalable, was not a real option because of its reported low quality. We chose to use Locality Sensitive Hashing which is supposed to be more scalable than LSA and whose quality was still to be tested on complex tasks. [3] has defined a family of LSH functions for which the hashed signatures keep their angular similarity for any input vectors pair. [15] has shown that this hashing is particularly well adapted to set up a fast nearest neighbors search method. 3.1 Dimension reduction: sensitive hashing Locality The goal of a hashing is to obtain a footprint smaller than the original s"
R09-1053,C98-2122,0,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,paroubek-2000-language,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,paroubek-etal-2008-easy,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,2006.iwslt-papers.1,0,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,vilnat-etal-2004-ongoing,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,vanrullen-etal-2006-constraint,0,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,paroubek-etal-2006-data,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,galliano-etal-2006-corpus,0,\N,Missing
vilnat-etal-2004-ongoing,kingsbury-palmer-2002-treebank,0,\N,Missing
vilnat-etal-2004-ongoing,J93-2004,0,\N,Missing
vilnat-etal-2010-passage,W03-2401,0,\N,Missing
vilnat-etal-2010-passage,villemonte-de-la-clergerie-etal-2008-passage,1,\N,Missing
vilnat-etal-2010-passage,W08-1301,0,\N,Missing
vilnat-etal-2010-passage,P04-1041,0,\N,Missing
vilnat-etal-2010-passage,J07-3004,0,\N,Missing
vilnat-etal-2010-passage,bosco-lombardo-2006-comparing,0,\N,Missing
vilnat-etal-2010-passage,declerck-2006-synaf,0,\N,Missing
vilnat-etal-2010-passage,paroubek-etal-2006-data,1,\N,Missing
W06-1904,1999.tc-1.8,0,0.0248958,"ies, the only way for us to get their translation is to combine all the different term translations. The main drawback of this approach is the generated noise, for none of the terms constituting the biterm is disambiguated. For example, three different translations are found for the biterm Conseil de d´efense : defense council, defense advice and defense counsel ; but only the first of those should be finally retained by our system. To reduce this noise, an interesting possibility is to validate the obtained biterms by searching them or their variants in the complete collection of documents. (Grefenstette, 1999) reports a quite similar experiment in the context of a machine translation task : he uses the Web in order to order the possible translations of noun phrases, and in particular noun biterms. Fastr (Jacquemin, 1996) is a parser which takes as input a corpus and a list of terms (multi or monoterms) and outputs the indexed corpus in which terms and their variants are recognized. Hence, Fastr is quite adequate for biterms validation : it tags all the biterms present in the collection, whether in their original form or in a variant that can be semantic or syntactic. In order to validate the biterm"
W06-1904,2006.jeptalnrecital-long.20,1,0.820536,"Missing"
W08-1306,P04-1041,0,0.0689989,"Missing"
W08-1306,P02-1022,0,0.0996386,"Missing"
W08-1306,declerck-2006-synaf,0,0.0295328,"s for French, whether such annotations come from human annotators or parsers. The representation format is intended to be used both in the evaluation of different parsers, so the parses’ representations should be easily comparable, and in the construction of a large scale annotation treebank which requires that all French constructions can be represented with enough details. The format is based on three distinct specifications and requirements: 1. MAF (ISO 24611)4 and SynAF (ISO 24615)5 which are the ISO TC37 specifications for morpho-syntactic and syntactic annotation (Ide and Romary, 2002) (Declerck, 2006) (Francopoulo, 2008). Let us note that these specifications cannot be called ”standards” because they are work in progress and these documents do not yet have the status Published Standard. Currently, their official status is only Committee Draft. 1. Parsing creates syntactic annotations; 2. Syntactic annotations create or enrich linguistic resources such as lexicons, grammars or annotated corpora; 2. The format used during the previous TECHNOLANGUE/EASY evaluation campaign in order to minimize porting effort for the existing tools and corpora. 3. Linguistic resources created or enriched on th"
W08-1306,paroubek-2000-language,1,0.855159,"Missing"
W08-1306,E03-1085,1,0.757565,"l ) includes a verb, the clitic pronouns and possible particles attached to it. Verb kernels may have different forms: conjugated tense, present or past participle, or infinitive. When the conjugation produces compound forms, distinct NVs are identified; element gathers tokens, word forms, groups, relations and marks and all sentences are included inside a “Document” element. 3 PASSAGE Syntactic Annotation Specification 3.1 Introduction The annotation formalism used in PASSAGE7 is based on the EASY one(Vilnat et al., 2004) which whose first version was crafted in an experimental project PEAS (Gendner et al., 2003), with inspiration taken from the propositions of (Carroll et al., 2002). The definition has been completed with the input of all the actors involved in the EASY evaluation campaign (both parsers’ developers and corpus providers) and refined with the input of PASSAGE participants. This formalism aims at making possible the comparison of all kinds of syntactic annotation (shallow or deep parsing, complete or partial analysis), without giving any advantage to any particular approach. It has six kinds of syntactic “chunks”, we call constituents and 14 kinds of relations The annotation formalism a"
W08-1306,J07-3004,0,0.0539813,"Missing"
W08-1306,vilnat-etal-2004-ongoing,1,0.694807,"Data Category Registry, inist.fr 38 see http://syntax. • the verb kernel (NV for noyau verbal ) includes a verb, the clitic pronouns and possible particles attached to it. Verb kernels may have different forms: conjugated tense, present or past participle, or infinitive. When the conjugation produces compound forms, distinct NVs are identified; element gathers tokens, word forms, groups, relations and marks and all sentences are included inside a “Document” element. 3 PASSAGE Syntactic Annotation Specification 3.1 Introduction The annotation formalism used in PASSAGE7 is based on the EASY one(Vilnat et al., 2004) which whose first version was crafted in an experimental project PEAS (Gendner et al., 2003), with inspiration taken from the propositions of (Carroll et al., 2002). The definition has been completed with the input of all the actors involved in the EASY evaluation campaign (both parsers’ developers and corpus providers) and refined with the input of PASSAGE participants. This formalism aims at making possible the comparison of all kinds of syntactic annotation (shallow or deep parsing, complete or partial analysis), without giving any advantage to any particular approach. It has six kinds of"
W08-1306,2006.iwslt-papers.1,0,0.0438108,"Missing"
W08-1306,villemonte-de-la-clergerie-etal-2008-passage,1,0.766148,"Missing"
W08-1306,paroubek-etal-2008-easy,1,\N,Missing
W08-1306,paroubek-etal-2006-data,1,\N,Missing
W11-1602,P05-1074,0,0.562204,"ote that using the web may not always be appropriate, or that at least it should be used in a different way than what we propose in this article, in particular in cases where the desired properties of the rewritten text are better described in controlled corpora. 11 The use of automatic targeted paraphrasing as an authoring aid has been illustrated by the work of Max and Zock (2008), in which writers are presented with potential paraphrases of sub-sentential fragments that they wish to reword. The automatic paraphrasing technique used is a contextual variant of bilingual translation pivoting (Bannard and Callison-Burch, 2005). It has also been proposed to externalize various text editing tasks, including proofreading, by having crowdsourcing functions on text directly from word processors (Bernstein et al., 2010). Text improvements may also be more specifically targeted for automatic applications. In the work by Resnik et al. (2010), rephrasings for specific phrases are acquired through crowdsourcing. Difficult-to-translate phrases in the source text are first identified, and monolingual contributors are asked to provide rephrasings in context. Collected rephrasings can then be used as input for a Machine Translat"
W11-1602,P01-1008,0,0.06346,"generation The acquisition of paraphrases, and in particular of sub-sentential paraphrases and paraphrase patterns, has attracted a lot of works with the advent of data-intensive Natural Language Processing (Madnani and Dorr, 2010). The techniques proposed have a strong relationship to the type of text corpus used 3 This verse from Apollinaire’s Nuit Rh´enane [which seems almost without rhythmic structure → whose cesura is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it"
W11-1602,P08-1077,0,0.0155111,"is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it should more generally be assessed in the specific context of some use of the paraphrase pair. This refers to the problem of substituability in context (e.g. (Connor and Roth, 2007; Zhao et al., 2007)), which is a well studied field at the lexical level and the object of evaluation campains (McCarthy and Navigli, 2009). Contextual phrase substitution poses the additional challenge that phrases are rarer than words, so that"
W11-1602,P11-2069,1,0.819058,"b-sentential paraphrases and paraphrase patterns, has attracted a lot of works with the advent of data-intensive Natural Language Processing (Madnani and Dorr, 2010). The techniques proposed have a strong relationship to the type of text corpus used 3 This verse from Apollinaire’s Nuit Rh´enane [which seems almost without rhythmic structure → whose cesura is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it should more generally be assessed in the specific context of"
W11-1602,I05-5001,0,0.656547,"sed corpus would contain enough information for appropriate modeling of the substituability in context decision. It is therefore tempting to consider using the Web as the largest available information source, in spite of several of its known limitations, including that data can be of varying quality. It has however been shown that a large range of NLP applications can be improved by exploiting n-gram counts from the Web (using Web document counts as a proxy) (Lapata and Keller, 2005). Paraphrase identification has been addressed previously, both using features computed from an offline corpus (Brockett and Dolan, 2005) and features computed from Web queries (Zhao et al., 2007). However, to our knowledge previous work exploiting information from the Web was limited to the identification of lexical paraphrases. Although the probability of finding phrase occurrences significantly increases by considering the Web, some phrases are still very rare or not present in search engine indexes. As in (Brockett and Dolan, 2005), we tackle our paraphrase identification task as one of monolingual classification. More precisely, considering an original phrase p within the context of sentence s, we seek to determine whether"
W11-1602,D08-1021,0,0.0262373,"l., 2008), it should more generally be assessed in the specific context of some use of the paraphrase pair. This refers to the problem of substituability in context (e.g. (Connor and Roth, 2007; Zhao et al., 2007)), which is a well studied field at the lexical level and the object of evaluation campains (McCarthy and Navigli, 2009). Contextual phrase substitution poses the additional challenge that phrases are rarer than words, so that building contextual and grammatical models to ensure that the generated rephrasings are both semantically compatible and grammatical is more complicated (e.g. (Callison-Burch, 2008)). The present work does not aim to present any original technique for paraphrase acquisition, but rather focusses on the task of sub-sentential paraphrase validation in context. We thus resort to some existing repertoire of phrasal paraphrase pairs. As explained in section 2, we use the W I C O PAC O corpus as a source of sub-sentential paraphrases: the phrase after rewriting can thus be used as a potential paraphrase in context.4 To obtain other candidates of various quality, we used two knowledge sources. The first uses automatic pivot translation (Bannard and Callison-Burch, 2005), where a"
W11-1602,candito-etal-2010-statistical,0,0.0325447,"Missing"
W11-1602,C96-2183,0,0.014623,"o-text realization problem. However, such needs apply sometimes to cases where a new text should be derived from some existing texts, an instance of text-to-text generation. The general idea is not anymore to produce a text from data, but to transform a text so as to ensure that it has desirable properties appropriate for some intended application (Zhao et al., 2009). For example, one may want a text to be shorter (Cohn and Lapata, 2008), tailored to some reader profile (Zhu et al., 2010), compliant with some specific norms (Max, 2004), or more adapted for subsequent machine processing tasks (Chandrasekar et al., 1996). The generation process must produce a text having a meaning which is compatible with the definition of the task at hand (e.g. strict paraphrasing for document normalization, relaxed paraGabriel Illouz LIMSI-CNRS Univ. Paris Sud gabrieli@limsi.fr Anne Vilnat LIMSI-CNRS Univ. Paris Sud anne@limsi.fr phrasing for text simplification), while ensuring that it remains grammatically correct. Its complexity, compared with concept-to-text generation, mostly stems from the fact that the semantic relationship between the original text and the new one is more difficult to control, as the mapping from on"
W11-1602,C08-1018,0,0.0219686,"history of Wikipedia. 1 Introduction There are many instances where it is reasonable to expect machines to produce text automatically. Traditionally, this was tackled as a concept-to-text realization problem. However, such needs apply sometimes to cases where a new text should be derived from some existing texts, an instance of text-to-text generation. The general idea is not anymore to produce a text from data, but to transform a text so as to ensure that it has desirable properties appropriate for some intended application (Zhao et al., 2009). For example, one may want a text to be shorter (Cohn and Lapata, 2008), tailored to some reader profile (Zhu et al., 2010), compliant with some specific norms (Max, 2004), or more adapted for subsequent machine processing tasks (Chandrasekar et al., 1996). The generation process must produce a text having a meaning which is compatible with the definition of the task at hand (e.g. strict paraphrasing for document normalization, relaxed paraGabriel Illouz LIMSI-CNRS Univ. Paris Sud gabrieli@limsi.fr Anne Vilnat LIMSI-CNRS Univ. Paris Sud anne@limsi.fr phrasing for text simplification), while ensuring that it remains grammatically correct. Its complexity, compared"
W11-1602,J08-4005,0,0.0146725,"in particular of sub-sentential paraphrases and paraphrase patterns, has attracted a lot of works with the advent of data-intensive Natural Language Processing (Madnani and Dorr, 2010). The techniques proposed have a strong relationship to the type of text corpus used 3 This verse from Apollinaire’s Nuit Rh´enane [which seems almost without rhythmic structure → whose cesura is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it should more generally be assessed in"
W11-1602,W09-3102,0,0.0384282,"Missing"
W11-1602,N10-1017,0,0.0119854,"). The techniques proposed have a strong relationship to the type of text corpus used 3 This verse from Apollinaire’s Nuit Rh´enane [which seems almost without rhythmic structure → whose cesura is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it should more generally be assessed in the specific context of some use of the paraphrase pair. This refers to the problem of substituability in context (e.g. (Connor and Roth, 2007; Zhao et al., 2007)), which is a well studied"
W11-1602,I05-5007,0,0.0221954,"re → whose cesura is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it should more generally be assessed in the specific context of some use of the paraphrase pair. This refers to the problem of substituability in context (e.g. (Connor and Roth, 2007; Zhao et al., 2007)), which is a well studied field at the lexical level and the object of evaluation campains (McCarthy and Navigli, 2009). Contextual phrase substitution poses the additional challenge that phrase"
W11-1602,J10-3003,0,0.0705506,"iel Illouz LIMSI-CNRS Univ. Paris Sud gabrieli@limsi.fr Anne Vilnat LIMSI-CNRS Univ. Paris Sud anne@limsi.fr phrasing for text simplification), while ensuring that it remains grammatically correct. Its complexity, compared with concept-to-text generation, mostly stems from the fact that the semantic relationship between the original text and the new one is more difficult to control, as the mapping from one text to another is very dependent on the rewriting context. The wide variety of techniques for acquiring phrasal paraphrases, which can subsequently be used by text paraphrasing techniques (Madnani and Dorr, 2010), the inherent polysemy of such linguistic units and the pragmatic constraints on their uses make it impossible to ensure that potential paraphrase pairs will be substitutable in any context, an observation which was already made at a lexical level (Zhao et al., 2007). Hence, automatic contextual validation of candidate rewritings is a fundamental issue for text paraphrasing with phrasal units. In this article, we tackle the problem of what we call targeted paraphrasing, defined as the rewriting of a subpart of a sentence, as in e.g. (Resnik et al., 2010) where it is applied to making parts of"
W11-1602,2008.amta-papers.13,0,0.0182599,"original wording. The task of rewriting complete sentences has also been addressed in various works (e.g. (Barzilay and Lee, 2003; Quirk et al., 2004; Zhao et al., 2010)). It poses, however, numerous other challenges, in particular regarding how it could be correctly evaluated. Human judgments of whole sentence transformations are complex and intra- and inter-judge coherence is difficult to attain with hypotheses of comparable quality. Using sentential paraphrases to support a given task (e.g. providing alternative reference translations for optimizing Statistical Machine Translation systems (Madnani et al., 2008)) 2 It is to be noted that, in the scenario presented in (Resnik et al., 2010), monolingual contributors cannot predict how useful their rewritings will be to the underlying Machine Translation engine used. can be seen as a proxy for extrinsic evaluation of the quality of paraphrases, but it is not clear from published results that improvements on the task are clearly correlated with the quality of the produced paraphrases. Lastly, automatic metrics have been proposed for evaluating the grammaticality of sentences (e.g. (Mutton et al., 2007)). Automatic evaluation of sentential paraphrases has"
W11-1602,max-wisniewski-2010-mining,1,0.840188,"metrics have been proposed for evaluating the grammaticality of sentences (e.g. (Mutton et al., 2007)). Automatic evaluation of sentential paraphrases has not produced any consensual results so far, as they do not integrate task-specific considerations and can be strongly biased towards some paraphrasing techniques. In this work, we tackle the comparatively more modest task of sub-sentential paraphrasing applied to text revision. In order to use an unbiased task, we use a corpus of naturally-occurring rewritings from an authoring memory of Wikipedia articles. We use the W I C O PAC O corpus (Max and Wisniewski, 2010), a collection of local rephrasings from the edit history of Wikipedia which contains instances of lexical, syntactical and semantic rephrasings (Dutrey et al., 2011), the latter type being illustrated by the following example: Ce vers de Nuit rh´enane d’Apollinaire [qui paraˆıt presque sans structure rythmique → dont la c´esure est comme masqu´ee]. . . 3 The appropriateness of this corpus for our work is twofold: first, the fact that it contains naturallyoccurring rewritings provides us with an interesting source of text spans in context which have been rewritten. Moreover, for those instance"
W11-1602,W08-1911,1,0.937786,"et al., 2011). This study also reports that there is an important variety of rephrasing phenomena, as illustrated by the difficulty of reaching a good identification coverage using a rule-based term variant identification engine. 1 Note that using the web may not always be appropriate, or that at least it should be used in a different way than what we propose in this article, in particular in cases where the desired properties of the rewritten text are better described in controlled corpora. 11 The use of automatic targeted paraphrasing as an authoring aid has been illustrated by the work of Max and Zock (2008), in which writers are presented with potential paraphrases of sub-sentential fragments that they wish to reword. The automatic paraphrasing technique used is a contextual variant of bilingual translation pivoting (Bannard and Callison-Burch, 2005). It has also been proposed to externalize various text editing tasks, including proofreading, by having crowdsourcing functions on text directly from word processors (Bernstein et al., 2010). Text improvements may also be more specifically targeted for automatic applications. In the work by Resnik et al. (2010), rephrasings for specific phrases are"
W11-1602,C04-1166,1,0.795727,"ce text automatically. Traditionally, this was tackled as a concept-to-text realization problem. However, such needs apply sometimes to cases where a new text should be derived from some existing texts, an instance of text-to-text generation. The general idea is not anymore to produce a text from data, but to transform a text so as to ensure that it has desirable properties appropriate for some intended application (Zhao et al., 2009). For example, one may want a text to be shorter (Cohn and Lapata, 2008), tailored to some reader profile (Zhu et al., 2010), compliant with some specific norms (Max, 2004), or more adapted for subsequent machine processing tasks (Chandrasekar et al., 1996). The generation process must produce a text having a meaning which is compatible with the definition of the task at hand (e.g. strict paraphrasing for document normalization, relaxed paraGabriel Illouz LIMSI-CNRS Univ. Paris Sud gabrieli@limsi.fr Anne Vilnat LIMSI-CNRS Univ. Paris Sud anne@limsi.fr phrasing for text simplification), while ensuring that it remains grammatically correct. Its complexity, compared with concept-to-text generation, mostly stems from the fact that the semantic relationship between t"
W11-1602,P07-1044,0,0.0127222,"optimizing Statistical Machine Translation systems (Madnani et al., 2008)) 2 It is to be noted that, in the scenario presented in (Resnik et al., 2010), monolingual contributors cannot predict how useful their rewritings will be to the underlying Machine Translation engine used. can be seen as a proxy for extrinsic evaluation of the quality of paraphrases, but it is not clear from published results that improvements on the task are clearly correlated with the quality of the produced paraphrases. Lastly, automatic metrics have been proposed for evaluating the grammaticality of sentences (e.g. (Mutton et al., 2007)). Automatic evaluation of sentential paraphrases has not produced any consensual results so far, as they do not integrate task-specific considerations and can be strongly biased towards some paraphrasing techniques. In this work, we tackle the comparatively more modest task of sub-sentential paraphrasing applied to text revision. In order to use an unbiased task, we use a corpus of naturally-occurring rewritings from an authoring memory of Wikipedia articles. We use the W I C O PAC O corpus (Max and Wisniewski, 2010), a collection of local rephrasings from the edit history of Wikipedia which"
W11-1602,P10-2001,0,0.0266855,"does not take the original wording into account. We therefore used a ratio of the language model score of the paraphrased sentence with the language model score of the original 6 http://research.microsoft.com/en-us/ collaboration/focus/cs/web-ngram.aspx 7 Note that in order to query on French text, we had to remove all diacritics for the service to behave correctly, independently of encodings: careful examination of ranked hypotheses showed that this trick allowed us to obtain results coherent with expectations. 14 sentence, after normalization by sentence length of the language model scores (Onishi et al., 2010): hLM ratio = LM (para) lm(para)1/length(para) = LM (orig) lm(orig)1/length(orig) (2) Contextless thematic model scores Cooccurring words are used in distributional semantics to account for common meanings of words. We build vector representations of cooccurrences for both the original phrase p and its paraphrase p0 . Our contextless thematic model is built in the following fashion: we query a search engine to retrieve the top N document snippets for phrase p. We then count frequencies for all content words in these snippets, and keep the set W of words appearing more than a fraction of N . We"
W11-1602,N03-1024,0,0.123923,"f paraphrases, and in particular of sub-sentential paraphrases and paraphrase patterns, has attracted a lot of works with the advent of data-intensive Natural Language Processing (Madnani and Dorr, 2010). The techniques proposed have a strong relationship to the type of text corpus used 3 This verse from Apollinaire’s Nuit Rh´enane [which seems almost without rhythmic structure → whose cesura is as if hidden]. . . 12 for acquisition, mainly: • pairs of sentential paraphrases (monolingual parallel corpora) allow for a good precision but evidently a low recall (e.g. (Barzilay and McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011)) • pairs of bilingual sentences (bilingual parallel corpora) allow for a comparatively better recall (e.g. (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010)) • pairs of related sentences (monolingual comparable corpora) allow for even higher recall but possibly lower precision (e.g. (Barzilay and Lee, 2003; Li et al., 2005; Bhagat and Ravichandran, 2008; Del´eger and Zweigenbaum, 2009) Although the precision of such techniques can in some cases be formulated with regards to a predefined reference set (Cohn et al., 2008), it should more genera"
W11-1602,N07-1051,0,0.00991518,"and right boundary of the sub-sentential paraphrase is higher than 10. Syntactic dependency baseline When rewriting a subpart of a sentence, the fact that syntactic dependencies between the rewritten phrase and its context are the same than those of the original phrase and the same context can provide some information about the grammatical and semantic substituability of the two phrases (Zhao et al., 2007; Max and Zock, 2008). We thus build syntactic dependencies for both the original and rewritten sentence, using the French version (Candito et al., 2010) of the Berkeley probabilistic parser (Petrov and Klein, 2007), and consider the subset of dependencies for the two sentences that exist between a word inside the phrase under focus and a word outside it (Deporig and Deppara ). Our C ONT D EP baseline considers a sentence as a paraphrase iff Deppara = Deporig . 5.3 Evaluation results We used the models described in Section 4 to build a SVM classifier using the LIBSVM package (Chang and Lin, 2001). Accuracy results are reported on Figure 5. P OSSIBLE S URE S URER W EB LM 62.79 68.37 56.79 B OUND LM 54.88 36.27 51.41 C ONT D EP 48.53 51.90 42.69 C LASSIFIER 57.67 70.69 62.85 Figure 5: Accuracy results for"
W11-1602,W04-3219,0,0.02426,"expression to produce more confident translations for better estimated source units (Schroeder et al., 2009).2 For instance, the phrase in bold in the sentence The number of people known to have died has now reached 358 can be rewritten as 1) who died, 2) identified to have died and 3) known to have passed away. All such rephrasings are grammatically correct, the first one being significantly shorter, and they all convey a meaning which is reasonably close to the original wording. The task of rewriting complete sentences has also been addressed in various works (e.g. (Barzilay and Lee, 2003; Quirk et al., 2004; Zhao et al., 2010)). It poses, however, numerous other challenges, in particular regarding how it could be correctly evaluated. Human judgments of whole sentence transformations are complex and intra- and inter-judge coherence is difficult to attain with hypotheses of comparable quality. Using sentential paraphrases to support a given task (e.g. providing alternative reference translations for optimizing Statistical Machine Translation systems (Madnani et al., 2008)) 2 It is to be noted that, in the scenario presented in (Resnik et al., 2010), monolingual contributors cannot predict how usef"
W11-1602,D10-1013,0,0.334238,"ed by text paraphrasing techniques (Madnani and Dorr, 2010), the inherent polysemy of such linguistic units and the pragmatic constraints on their uses make it impossible to ensure that potential paraphrase pairs will be substitutable in any context, an observation which was already made at a lexical level (Zhao et al., 2007). Hence, automatic contextual validation of candidate rewritings is a fundamental issue for text paraphrasing with phrasal units. In this article, we tackle the problem of what we call targeted paraphrasing, defined as the rewriting of a subpart of a sentence, as in e.g. (Resnik et al., 2010) where it is applied to making parts of sentences easier to translate automatically. While this problem is simpler than full sentence rewriting, its study is justified as it should be handled correctly for the more complex task to be successful. Moreover, being simpler, it offers evaluation scenarios which make the performance on the task easier to assess. Our particular experiments here aim to assist a Wikipedia contributor in revising a text to improve its quality. For this, we use a collection of phrases that have been rewritten in Wikipedia, and test the substitutability of paraphrases com"
W11-1602,E09-1082,0,0.0196018,"word processors (Bernstein et al., 2010). Text improvements may also be more specifically targeted for automatic applications. In the work by Resnik et al. (2010), rephrasings for specific phrases are acquired through crowdsourcing. Difficult-to-translate phrases in the source text are first identified, and monolingual contributors are asked to provide rephrasings in context. Collected rephrasings can then be used as input for a Machine Translation system, which can positively exploit the increased variety in expression to produce more confident translations for better estimated source units (Schroeder et al., 2009).2 For instance, the phrase in bold in the sentence The number of people known to have died has now reached 358 can be rewritten as 1) who died, 2) identified to have died and 3) known to have passed away. All such rephrasings are grammatically correct, the first one being significantly shorter, and they all convey a meaning which is reasonably close to the original wording. The task of rewriting complete sentences has also been addressed in various works (e.g. (Barzilay and Lee, 2003; Quirk et al., 2004; Zhao et al., 2010)). It poses, however, numerous other challenges, in particular regardin"
W11-1602,N10-2012,0,0.0235665,"ses proposed by sets of players using a compact word-lattice view. Note that in its standard definition, the game attributes higher scores to paraphrase candidates that are highly rated and rarer. hedit = TER(Lemorig , Lempara ) (1) Note that this model is not derived from information from the Web, in contrast to all the models described next. Language model score The likelihood of a sentence can be a good indicator of its grammaticality (Mutton, 2006). Language model probabilities can now be obtained from Web counts. In our experiments, we used the Microsoft Web N-gram Service6 for research (Wang et al., 2010) to obtain log likelihood scores for text units.7 However, this score is certainly not sufficient as it does not take the original wording into account. We therefore used a ratio of the language model score of the paraphrased sentence with the language model score of the original 6 http://research.microsoft.com/en-us/ collaboration/focus/cs/web-ngram.aspx 7 Note that in order to query on French text, we had to remove all diacritics for the service to behave correctly, independently of encodings: careful examination of ranked hypotheses showed that this trick allowed us to obtain results cohere"
W11-1602,P09-1094,0,0.0165748,"taken from a rewriting memory automatically extracted from the edit history of Wikipedia. 1 Introduction There are many instances where it is reasonable to expect machines to produce text automatically. Traditionally, this was tackled as a concept-to-text realization problem. However, such needs apply sometimes to cases where a new text should be derived from some existing texts, an instance of text-to-text generation. The general idea is not anymore to produce a text from data, but to transform a text so as to ensure that it has desirable properties appropriate for some intended application (Zhao et al., 2009). For example, one may want a text to be shorter (Cohn and Lapata, 2008), tailored to some reader profile (Zhu et al., 2010), compliant with some specific norms (Max, 2004), or more adapted for subsequent machine processing tasks (Chandrasekar et al., 1996). The generation process must produce a text having a meaning which is compatible with the definition of the task at hand (e.g. strict paraphrasing for document normalization, relaxed paraGabriel Illouz LIMSI-CNRS Univ. Paris Sud gabrieli@limsi.fr Anne Vilnat LIMSI-CNRS Univ. Paris Sud anne@limsi.fr phrasing for text simplification), while e"
W11-1602,C10-1149,0,0.0124392,"ce more confident translations for better estimated source units (Schroeder et al., 2009).2 For instance, the phrase in bold in the sentence The number of people known to have died has now reached 358 can be rewritten as 1) who died, 2) identified to have died and 3) known to have passed away. All such rephrasings are grammatically correct, the first one being significantly shorter, and they all convey a meaning which is reasonably close to the original wording. The task of rewriting complete sentences has also been addressed in various works (e.g. (Barzilay and Lee, 2003; Quirk et al., 2004; Zhao et al., 2010)). It poses, however, numerous other challenges, in particular regarding how it could be correctly evaluated. Human judgments of whole sentence transformations are complex and intra- and inter-judge coherence is difficult to attain with hypotheses of comparable quality. Using sentential paraphrases to support a given task (e.g. providing alternative reference translations for optimizing Statistical Machine Translation systems (Madnani et al., 2008)) 2 It is to be noted that, in the scenario presented in (Resnik et al., 2010), monolingual contributors cannot predict how useful their rewritings"
W11-1602,C10-1152,0,0.0258946,"nces where it is reasonable to expect machines to produce text automatically. Traditionally, this was tackled as a concept-to-text realization problem. However, such needs apply sometimes to cases where a new text should be derived from some existing texts, an instance of text-to-text generation. The general idea is not anymore to produce a text from data, but to transform a text so as to ensure that it has desirable properties appropriate for some intended application (Zhao et al., 2009). For example, one may want a text to be shorter (Cohn and Lapata, 2008), tailored to some reader profile (Zhu et al., 2010), compliant with some specific norms (Max, 2004), or more adapted for subsequent machine processing tasks (Chandrasekar et al., 1996). The generation process must produce a text having a meaning which is compatible with the definition of the task at hand (e.g. strict paraphrasing for document normalization, relaxed paraGabriel Illouz LIMSI-CNRS Univ. Paris Sud gabrieli@limsi.fr Anne Vilnat LIMSI-CNRS Univ. Paris Sud anne@limsi.fr phrasing for text simplification), while ensuring that it remains grammatically correct. Its complexity, compared with concept-to-text generation, mostly stems from t"
W11-1602,N03-1003,0,\N,Missing
W11-1602,2010.amta-workshop.3,0,\N,Missing
W18-3814,P05-1074,0,0.196505,"rbelnet, 1958; Chuquet and Paillard, 1989), which categorize different translation techniques apart from literal translations. But to the best of our knowledge, no automatic processing techniques explicitly implement these interlingual relations. As an important natural language understanding and generation task, machine translation (MT) has been seriously improved with first phrase-based statistical machine translation (PBMT) then recently with neural machine translation (NMT). MT has also been exploited to generate paraphrases from bilingual parallel corpus, which was originally proposed by Bannard and Callison-Burch (2005). The assumption is that two segments in the same language are potential paraphrases if they share common translations in a foreign language. Currently the largest resource of paraphrases, PPDB (Paraphrase Database) (Ganitkevitch et al., 2013), has been built following this method exploiting translational equivalence. Nonetheless, the work of Pavlick et al. (2015) revealed that there exist other relations than strict equivalence (paraphrase) in PPDB (i.e. Entailment (in two directions), Exclusion, Other related and Independent). The existence of these other relations in PPDB reflects the lack"
W18-3814,2012.eamt-1.60,0,0.0425191,"difficulties for recent NMT systems. The problems include, in particular, incomplete generalizations; translating common and syntactically flexible idioms, or crossing movement verbs e.g. swim across X → traverser X à la nage. The annotated corpus that we present here could also constitute a challenge set, for the purpose of evaluating MT systems when human translators resort to different translation relations. 3 Corpus In order to study translation relations for several pairs of languages, we have worked on a multilingual parallel corpus. This corpus is available from the Web inventory WIT3 (Cettolo et al., 2012), which gives access to a collection of transcribed and translated talks, including the corpus of TED Talks3 . This corpus was released for the evaluation campaign IWSLT 2013 and 2014.4 The source language, i.e. the original language in which the speakers expressed themselves, is English. We have calculated the intersection of a parallel corpus with translations in French5 , Chinese, Arabic, Spanish and Russian. The translation of subtitles for TED Talks is controlled by volunteers and language coordinators per language6 , which generally ensures good quality translations. The corpus to be ann"
W18-3814,N13-1073,0,0.0121859,"ogy, grammar, expression, etc. For English and French languages, the corpus has been tokenized by Stanford Tokenizer7 , and lemmatized by TreeTagger (Schmid, 1995) while keeping the tokenization of Stanford Tokenizer. The capital letters at the beginning of each sentence are kept only if these words always appear with capital initials elsewhere in the corpus, otherwise they are lowercased. We have used the tool THULAC (Li and Sun, 2009) for the segmentation of the Chinese corpus, and proceeded to several corrections before annotation. The words are automatically aligned by training FastAlign (Dyer et al., 2013), with its default parameters on each entire parallel corpus (i.e. 163 092 lines and 3 303 660 English tokens). We import 2 http://www.parseme.eu/ https://wit3.fbk.eu/ 4 We have used training corpus of 2014 (160 656 lines), development corpus (880 lines) and test corpus (1 556 lines) of 2010. 5 The sentence boundaries have been corrected in French test corpus to calculate the intersection. 6 https://www.ted.com/participate/translate/get-started 7 http://nlp.stanford.edu/software/tokenizer.shtml 3 103 these automatic alignments before annotation to accelerate the process, in particular for the"
W18-3814,N13-1092,0,0.23119,"Missing"
W18-3814,P08-4006,0,0.1314,"l suddenly discover what it would be like → et vous découvrirez ce que ce serait 12. Unaligned and no type attributed: function words necessary in one language but not in the other; segments not translated but which don’t impact the meaning; segments giving repeated information in context; translated segments which don’t correspond to any source segment: minus 271 degrees, colder than → moins 271 degrés, ce qui est plus froid the last example I have time to → le dernier exemple que j’ai le temps de 105 5 Annotation 5.1 Annotation tool and configuration We have used the Web application Yawat8 (Germann, 2008), which allows us to align words or segments (continuous or discontinuous), and then to assign labels adapted to our task on monolingual or bilingual units (see figure 2). Figure 2: Annotation interface of Yawat. Here is a trilingual example from our corpus: well, we use that great euphemism, ""trial and error"", which is exposed to be meaningless. eh bien, nous employons cet euphémisme, procéder par tâtonnements, qui est dénué de sens. 我们 ""we"" 普通人 ""ordinary people"" 会 ""particle for future tense"" 做 ""do"" 各种各样 ""diverse"" 的 ""particle for attribute"" 实验 ""experience"" 不断 ""continuously"" 地 ""particle for ad"
W18-3814,D17-1263,0,0.0829718,"ltiword Expressions) 2 is a European scientific network built up to elaborate universal terminologies and annotation guidelines for MWEs in 18 languages (Savary et al., 2015). Its main outcome is a multilingual 5-million word annotated corpus, which underlies a shared task on automatic identification of verbal MWEs (Savary et al., 2017). Our trilingual annotated corpus focuses on bilingual relation between translations, and we annotate all words in the corpus, including continuous and discontinuous MWEs. As a complement of MT evaluation metrics, which reflect imperfectly systems’ performance, Isabelle et al. (2017) have introduced a challenge set based on difficult linguistic materials. The authors could hence determine some remaining difficulties for recent NMT systems. The problems include, in particular, incomplete generalizations; translating common and syntactically flexible idioms, or crossing movement verbs e.g. swim across X → traverser X à la nage. The annotated corpus that we present here could also constitute a challenge set, for the purpose of evaluating MT systems when human translators resort to different translation relations. 3 Corpus In order to study translation relations for several p"
W18-3814,J09-4006,0,0.132799,"rench and English-Chinese corpora to validate our hierarchy of translation relations, since these two target languages are very dissimilar in several linguistic aspects: morphology, grammar, expression, etc. For English and French languages, the corpus has been tokenized by Stanford Tokenizer7 , and lemmatized by TreeTagger (Schmid, 1995) while keeping the tokenization of Stanford Tokenizer. The capital letters at the beginning of each sentence are kept only if these words always appear with capital initials elsewhere in the corpus, otherwise they are lowercased. We have used the tool THULAC (Li and Sun, 2009) for the segmentation of the Chinese corpus, and proceeded to several corrections before annotation. The words are automatically aligned by training FastAlign (Dyer et al., 2013), with its default parameters on each entire parallel corpus (i.e. 163 092 lines and 3 303 660 English tokens). We import 2 http://www.parseme.eu/ https://wit3.fbk.eu/ 4 We have used training corpus of 2014 (160 656 lines), development corpus (880 lines) and test corpus (1 556 lines) of 2010. 5 The sentence boundaries have been corrected in French test corpus to calculate the intersection. 6 https://www.ted.com/partici"
W18-3814,P15-1146,0,0.485166,"tatistical machine translation (PBMT) then recently with neural machine translation (NMT). MT has also been exploited to generate paraphrases from bilingual parallel corpus, which was originally proposed by Bannard and Callison-Burch (2005). The assumption is that two segments in the same language are potential paraphrases if they share common translations in a foreign language. Currently the largest resource of paraphrases, PPDB (Paraphrase Database) (Ganitkevitch et al., 2013), has been built following this method exploiting translational equivalence. Nonetheless, the work of Pavlick et al. (2015) revealed that there exist other relations than strict equivalence (paraphrase) in PPDB (i.e. Entailment (in two directions), Exclusion, Other related and Independent). The existence of these other relations in PPDB reflects the lack of semantic control during the paraphrasing process. We propose a categorization of translation relations which model human translators’ choices, and we annotate a multilingual (English, French, Chinese) parallel corpus of oral presentations, the TED Talks1 , with these relations. The annotation is still ongoing and we are developing a classifier based on these an"
