2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,19,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.wmt-1.50,Neural Machine Translation for Similar Languages: The Case of {I}ndo-{A}ryan Languages,2020,-1,-1,1,1,13776,santanu pal,Proceedings of the Fifth Conference on Machine Translation,0,"In this paper we present the WIPRO-RIT systems submitted to the Similar Language Translation shared task at WMT 2020. The second edition of this shared task featured parallel data from pairs/groups of similar languages from three different language families: Indo-Aryan languages (Hindi and Marathi), Romance languages (Catalan, Portuguese, and Spanish), and South Slavic Languages (Croatian, Serbian, and Slovene). We report the results obtained by our systems in translating from Hindi to Marathi and from Marathi to Hindi. WIPRO-RIT achieved competitive performance ranking 1st in Marathi to Hindi and 2nd in Hindi to Marathi translation among 22 systems."
2020.wat-1.14,{WT}: Wipro {AI} Submissions to the {WAT} 2020,2020,-1,-1,1,1,13776,santanu pal,Proceedings of the 7th Workshop on Asian Translation,0,"In this paper we present an English{--}Hindi and Hindi{--}English neural machine translation (NMT) system, submitted to the Translation shared Task organized at WAT 2020. We trained a multilingual NMT system based on transformer architecture. In this paper we show: (i) how effective pre-processing helps to improve performance, (ii) how synthetic data through back-translation from available monolingual data can help in overall translation performance, (iii) how language similarity can aid more onto it. Our submissions ranked 1st in both English to Hindi and Hindi to English translation achieving BLEU 20.80 and 29.59 respectively."
2020.coling-main.524,The Transference Architecture for Automatic Post-Editing,2020,-1,-1,1,1,13776,santanu pal,Proceedings of the 28th International Conference on Computational Linguistics,0,"In automatic post-editing (APE) it makes sense to condition post-editing (pe) decisions on both the source (src) and the machine translated text (mt) as input. This has led to multi-encoder based neural APE approaches. A research challenge now is the search for architectures that best support the capture, preparation and provision of src and mt information and its integration with pe decisions. In this paper we present an efficient multi-encoder based APE model, called transference. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a decoder block, but without masking for self-attention on mt, which effectively acts as second encoder combining src {--}{\textgreater} mt, and (iii) feeds this representation into a final decoder block generating pe. Our model outperforms the best performing systems by 1 BLEU point on the WMT 2016, 2017, and 2018 English{--}German APE shared tasks (PBSMT and NMT). Furthermore, the results of our model on the WMT 2019 APE task using NMT data shows a comparable performance to the state-of-the-art system. The inference time of our model is similar to the vanilla transformer-based NMT system although our model deals with two separate encoders. We further investigate the importance of our newly introduced second encoder and find that a too small amount of layers does hurt the performance, while reducing the number of layers of the decoder does not matter much."
2020.amta-pemdt.7,Improving the Multi-Modal Post-Editing ({MMPE}) {CAT} Environment based on Professional Translators{'} Feedback,2020,-1,-1,2,0,10224,nico herbig,Proceedings of 1st Workshop on Post-Editing in Modern-Day Translation,0,None
2020.acl-main.155,{MMPE}: {A} {M}ulti-{M}odal {I}nterface for {P}ost-{E}diting {M}achine {T}ranslation,2020,-1,-1,3,0,10224,nico herbig,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Current advances in machine translation (MT) increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and reduces errors. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while they are of limited use for longer insertions. On the other hand, speech and multi-modal combinations of select {\&} speech are considered suitable for replacements and insertions but offer less potential for deletion and reordering. Overall, participants were enthusiastic about the new modalities and saw them as good extensions to mouse {\&} keyboard, but not as a complete substitute."
2020.acl-demos.37,"{MMPE}: {A} {M}ulti-{M}odal {I}nterface using {H}andwriting, {T}ouch {R}eordering, and {S}peech {C}ommands for {P}ost-{E}diting {M}achine {T}ranslation",2020,-1,-1,2,0,10224,nico herbig,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"The shift from traditional translation to post-editing (PE) of machine-translated (MT) text can save time and reduce errors, but it also affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. Users can directly cross out or hand-write new text, drag and drop words for reordering, or use spoken commands to update the text in place. All text manipulations are logged in an easily interpretable format to simplify subsequent translation process research. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while speech and multi-modal combinations of select {\&} speech are considered suitable for replacements and insertions. Overall, experiment participants were enthusiastic about the new modalities and saw them as useful extensions to mouse {\&} keyboard, but not as a complete substitute."
W19-6702,Improving {CAT} Tools in the Translation Workflow: New Approaches and Evaluation,2019,13,0,2,0,19096,mihaela vela,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,"This paper describes strategies to improve an existing web-based computer-aided translation (CAT) tool entitled CATaLog Online. CATaLog Online provides a post-editing environment with simple yet helpful project management tools. It offers translation suggestions from translation memories (TM), machine translation (MT), and automatic post-editing (APE) and records detailed logs of post-editing activities. To test the new approaches proposed in this paper, we carried out a user study on an English--German translation task using CATaLog Online. User feedback revealed that the users preferred using CATaLog Online over existing CAT tools in some respects, especially by selecting the output of the MT system and taking advantage of the color scheme for TM suggestions."
W19-5414,{USAAR}-{DFKI} {--} The Transference Architecture for {E}nglish{--}{G}erman Automatic Post-Editing,2019,0,0,1,1,13776,santanu pal,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"In this paper we present an English{--}German Automatic Post-Editing (APE) system called transference, submitted to the APE Task organized at WMT 2019. Our transference model is based on a multi-encoder transformer architecture. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a transformer decoder block, but without masking, for self-attention on mt, which effectively acts as second encoder combining src {--}{\textgreater} mt, and (iii) feeds this representation into a final decoder block generating pe. Our model improves over the raw black-box neural machine translation system by 0.9 and 1.0 absolute BLEU points on the WMT 2019 APE development and test set. Our submission ranked 3rd, however compared to the two top systems, performance differences are not statistically significant."
W19-5430,{UDS}{--}{DFKI} Submission to the {WMT}2019 {C}zech{--}{P}olish Similar Language Translation Shared Task,2019,8,0,1,1,13776,santanu pal,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"In this paper we present the UDS-DFKI system submitted to the Similar Language Translation shared task at WMT 2019. The first edition of this shared task featured data from three pairs of similar languages: Czech and Polish, Hindi and Nepali, and Portuguese and Spanish. Participants could choose to participate in any of these three tracks and submit system outputs in any translation direction. We report the results obtained by our system in translating from Czech to Polish and comment on the impact of out-of-domain test data in the performance of our system. UDS-DFKI achieved competitive performance ranking second among ten teams in Czech to Polish translation."
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,13,0,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
W19-5332,{JU}-{S}aarland Submission to the {WMT}2019 {E}nglish{--}{G}ujarati Translation Shared Task,2019,-1,-1,4,0,23873,riktim mondal,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"In this paper we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English{--}Gujarati language pair within the translation task sub-track. Our baseline and primary submissions are built using Recurrent neural network (RNN) based neural machine translation (NMT) system which follows attention mechanism. Given the fact that the two languages belong to different language families and there is not enough parallel data for this language pair, building a high quality NMT system for this language pair is a difficult task. We produced synthetic data through back-translation from available monolingual data. We report the translation quality of our English{--}Gujarati and Gujarati{--}English NMT systems trained at word, byte-pair and character encoding levels where RNN at word level is considered as the baseline and used for comparison purpose. Our English{--}Gujarati system ranked in the second position in the shared task."
W18-6457,Keep It or Not: Word Level Quality Estimation for Post-Editing,2018,0,0,2,0,27729,prasenjit basu,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"The paper presents our participation in the WMT 2018 shared task on word level quality estimation (QE) of machine translated (MT) text, i.e., to predict whether a word in MT output for a given source context is correctly translated and hence should be retained in the post-edited translation (PE), or not. To perform the QE task, we measure the similarity of the source context of the target MT word with the context for which the word is retained in PE in the training data. This is achieved in two different ways, using \textit{Bag-of-Words} (\textit{BoW}) model and \textit{Document-to-Vector} (\textit{Doc2Vec}) model. In the \textit{BoW} model, we compute the cosine similarity while in the \textit{Doc2Vec} model we consider the Doc2Vec similarity. By applying the Kneedle algorithm on the F1mult vs. similarity score plot, we derive the threshold based on which OK/BAD decisions are taken for the MT words. Experimental results revealed that the Doc2Vec model performs better than the BoW model on the word level QE task."
W18-6468,A Transformer-Based Multi-Source Automatic Post-Editing System,2018,0,1,1,1,13776,santanu pal,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper presents our English{--}German Automatic Post-Editing (APE) system submitted to the APE Task organized at WMT 2018 (Chatterjee et al., 2018). The proposed model is an extension of the transformer architecture: two separate self-attention-based encoders encode the machine translation output (mt) and the source (src), followed by a joint encoder that attends over a combination of these two encoded sequences (encsrc and encmt) for generating the post-edited sentence. We compare this multi-source architecture (i.e, {src, mt} â pe) to a monolingual transformer (i.e., mt â pe) model and an ensemble combining the multi-source {src, mt} â pe and single-source mt â pe models. For both the PBSMT and the NMT task, the ensemble yields the best results, followed by the multi-source model and last the single-source approach. Our best model, the ensemble, achieves a BLEU score of 66.16 and 74.22 for the PBSMT and NMT task, respectively."
W18-3920,Discriminating between {I}ndo-{A}ryan Languages Using {SVM} Ensembles,2018,0,1,4,0,17450,alina ciobanu,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"In this paper we present a system based on SVM ensembles trained on characters and words to discriminate between five similar languages of the Indo-Aryan family: Hindi, Braj Bhasha, Awadhi, Bhojpuri, and Magahi. The system competed in the Indo-Aryan Language Identification (ILI) shared task organized within the VarDial Evaluation Campaign 2018. Our best entry in the competition, named ILIdentification, scored 88.95{\%} F1 score and it was ranked 3rd out of 8 teams."
W18-3931,A Neural Approach to Language Variety Translation,2018,19,3,3,0,5326,marta costajussa,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,In this paper we present the first neural-based machine translation system trained to translate between standard national varieties of the same language. We take the pair Brazilian - European Portuguese as an example and compare the performance of this method to a phrase-based statistical machine translation system. We report a performance improvement of 0.9 BLEU points in translating from European to Brazilian Portuguese and 0.2 BLEU points when translating in the opposite direction. We also carried out a human evaluation experiment with native speakers of Brazilian Portuguese which indicates that humans prefer the output produced by the neural-based system in comparison to the statistical system.
W18-2411,A Deep Learning Based Approach to Transliteration,2018,0,3,3,0,28443,soumyadeep kundu,Proceedings of the Seventh Named Entities Workshop,0,"In this paper, we propose different architectures for language independent machine transliteration which is extremely important for natural language processing (NLP) applications. Though a number of statistical models for transliteration have already been proposed in the past few decades, we proposed some neural network based deep learning architectures for the transliteration of named entities. Our transliteration systems adapt two different neural machine translation (NMT) frameworks: recurrent neural network and convolutional sequence to sequence based NMT. It is shown that our method provides quite satisfactory results when it comes to multi lingual machine transliteration. Our submitted runs are an ensemble of different transliteration systems for all the language pairs. In the NEWS 2018 Shared Task on Transliteration, our method achieves top performance for the En{--}Pe and Pe{--}En language pairs and comparable results for other cases."
W17-4773,Multi-source Neural Automatic Post-Editing: {FBK}{'}s participation in the {WMT} 2017 {APE} shared task,2017,20,8,6,0,13898,rajen chatterjee,Proceedings of the Second Conference on Machine Translation,0,None
E17-2056,Neural Automatic Post-Editing Using Prior Alignment and Reranking,2017,0,9,1,1,13776,santanu pal,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"We present a second-stage machine translation (MT) system based on a neural machine translation (NMT) approach to automatic post-editing (APE) that improves the translation quality provided by a first-stage MT system. Our APE system (APE{\_}Sym) is an extended version of an attention based NMT model with bilingual symmetry employing bidirectional models, mt{--}pe and pe{--}mt. APE translations produced by our system show statistically significant improvements over the first-stage MT, phrase-based APE and the best reported score on the WMT 2016 APE dataset by a previous neural APE system. Re-ranking (APE{\_}Rerank) of the n-best translations from the phrase-based APE and APE{\_}Sym systems provides further substantial improvements over the symmetric neural APE model. Human evaluation confirms that the APE{\_}Rerank generated PE translations improve on the previous best neural APE system at WMT 2016."
W16-2333,{JU-USAAR}: A Domain Adaptive {MT} System,2016,27,1,3,0,33889,koushik pahari,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the JU-USAAR Englishxe2x80x90German domain adaptive machine translation (MT) system submitted to the IT domain translation task organized in WMT-2016 . Our system brings improvements over the in-domain baseline system by incorporating out-domain knowledge. We applied two methodologies to accelerate the performance of our in-domain MT system: (i) additional training material extraction from out-domain data using data selection method, and (ii) language model and translation model adaptation through interpolation. Our primary submission obtained a BLEU score of 34.5 (14.5 absolute and 72.5% relative improvements over baseline) and a TER score of 54.0 (14.7 absolute and 21.4% relative improvements over baseline)."
W16-2373,{WMT}2016: A Hybrid Approach to Bilingual Document Alignment,2016,14,7,3,0,1239,sainik mahata,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"Large aligned corpora are required for any computer aided translation system to become effective. In this scenario, bilingual document alignment has gained utmost importance in recent days. We attempt a simple yet effective approach to align URLs (Uniform Resource Locator) within two documents in two languages as a part of WMT2016 Bilingual Document Alignment Shared Task. Our approach includes the processing of URLs and their embedded texts, which serves as the main matching criterion. In order to align the text initially, we have used GaleChurch algorithm, dictionary based translation and Cosine Similarity that in turn helps us to achieve better results in the alignment task."
W16-2379,{USAAR}: An Operation Sequential Model for Automatic Statistical Post-Editing,2016,21,9,1,1,13776,santanu pal,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,None
P16-2046,A Neural Network based Approach to Automatic Post-Editing,2016,18,10,1,1,13776,santanu pal,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,None
L16-1095,{CAT}a{L}og Online: Porting a Post-editing Tool to the Web,2016,15,3,1,1,13776,santanu pal,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents CATaLog online, a new web-based MT and TM post-editing tool. CATaLog online is a freeware software that can be used through a web browser and it requires only a simple registration. The tool features a number of editing and log functions similar to the desktop version of CATaLog enhanced with several new features that we describe in detail in this paper. CATaLog online is designed to allow users to post-edit both translation memory segments as well as machine translation output. The tool provides a complete set of log information currently not available in most commercial CAT tools. Log information can be used both for project management purposes as well as for the study of the translation process and translator{'}s productivity."
C16-2021,{CAT}a{L}og Online: A Web-based {CAT} Tool for Distributed Translation with Data Capture for {APE} and Translation Process Research,2016,4,1,1,1,13776,santanu pal,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"We present a free web-based CAT tool called CATaLog Online which provides a novel and user-friendly online CAT environment for post-editors/translators. The goal is to support distributed translation, reduce post-editing time and effort, improve the post-editing experience and capture data for incremental MT/APE (automatic post-editing) and translation process research. The tool supports individual as well as batch mode file translation and provides translations from three engines {--} translation memory (TM), MT and APE. TM suggestions are color coded to accelerate the post-editing task. The users can integrate their personal TM/MT outputs. The tool remotely monitors and records post-editing activities generating an extensive range of post-editing logs."
C16-1241,Multi-Engine and Multi-Alignment Based Automatic Post-Editing and its Impact on Translation Productivity,2016,30,1,1,1,13776,santanu pal,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"In this paper we combine two strands of machine translation (MT) research: automatic post-editing (APE) and multi-engine (system combination) MT. APE systems learn a target-language-side second stage MT system from the data produced by human corrected output of a first stage MT system, to improve the output of the first stage MT in what is essentially a sequential MT system combination architecture. At the same time, there is a rich research literature on parallel MT system combination where the same input is fed to multiple engines and the best output is selected or smaller sections of the outputs are combined to obtain improved translation output. In the paper we show that parallel system combination in the APE stage of a sequential MT-APE combination yields substantial translation improvements both measured in terms of automatic evaluation metrics as well as in terms of productivity improvements measured in a post-editing experiment. We also show that system combination on the level of APE alignments yields further improvements. Overall our APE system yields statistically significant improvement of 5.9{\%} relative BLEU over a strong baseline (English{--}Italian Google MT) and 21.76{\%} productivity increase in a human post-editing experiment with professional translators."
W15-5206,{CAT}a{L}og: New Approaches to {TM} and Post Editing Interfaces,2015,15,6,3,0,36496,tapas nayek,Proceedings of the Workshop Natural Language Processing for Translation Memories,0,None
W15-3017,{U}d{S}-Sant: {E}nglish{--}{G}erman Hybrid Machine Translation System,2015,19,5,1,1,13776,santanu pal,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,This paper describes the UdS-Sant Englishxe2x80x90German Hybrid Machine Translation (MT) system submitted to the Translation Task organized in the Workshop on Statistical Machine Translation (WMT) 2015. Our proposed hybrid system brings improvements over the baseline system by incorporating additional knowledge such as extracted bilingual named entities and bilingual phrase pairs induced from example-based methods. The reported final submission is the result of a hybrid system obtained from confusion network based system combination that combines the best performance of each individual system in a multi-engine pipeline.
W15-3026,{USAAR}-{SAPE}: An {E}nglish{--}{S}panish Statistical Automatic Post-Editing System,2015,32,11,1,1,13776,santanu pal,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"We describe the USAAR-SAPE Englishxe2x80x90 Spanish Automatic Post-Editing (APE) system submitted to the APE Task organized in the Workshop on Statistical Machine Translation (WMT) in 2015. Our system was able to improve upon the baseline MT system output by incorporating Phrase-Based Statistical MT (PBSMT) technique into the monolingual Statistical APE task (SAPE). The reported final submission crucially involves hybrid word alignment. The SAPE system takes raw Spanish Machine Translation (MT) output provided by the shared task organizers and produces post-edited Spanish text. The parallel data consist of English Text, raw machine translated Spanish output, and their corresponding manually post-edited versions. The major goal of the task is to reduce the post-editing effort by improving the quality of the MT output in terms of fluency and adequacy."
W14-5114,How Sentiment Analysis Can Help Machine Translation,2014,0,0,1,1,13776,santanu pal,Proceedings of the 11th International Conference on Natural Language Processing,0,None
W14-3323,{M}anawi: Using Multi-Word Expressions and Named Entities to Improve Machine Translation,2014,20,15,2,0,10447,liling tan,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We describe the Manawi 1 (mAnEv) system submitted to the 2014 WMT translation shared task. We participated in the English-Hindi (EN-HI) and Hindi-English (HI-EN) language pair and achieved 0.792 for the Translation Error Rate (TER) score 2 for EN-HI, the lowest among the competing systems. Our main innovations are (i) the usage of outputs from NLP tools, viz. billingual multi-word expression extractor and named-entity recognizer to improve SMT quality and (ii) the introduction of a novel filter method based on sentence-alignment features. The Manawi system showed the potential of improving translation quality by incorporating multiple NLP tools within the MT pipeline."
W14-1009,Automatic Building and Using Parallel Resources for {SMT} from Comparable Corpora,2014,24,19,1,1,13776,santanu pal,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"Building parallel resources for corpus based machine translation, especially Statistical Machine Translation (SMT), from comparable corpora has recently received wide attention in the field Machine Translation research. In this paper, we propose an automatic approach for extraction of parallel fragments from comparable corpora. The comparable corpora are collected from Wikipedia documents and this approach exploits the multilingualism of Wikipedia. The automatic alignment process of parallel text fragments uses a textual entailment technique and Phrase Based SMT (PBSMT) system. The parallel text fragments extracted thus are used as additional parallel translation examples to complement the training data for a PBSMT system. The additional training data extracted from comparable corpora provided significant improvements in terms of translation quality over the baseline as measured by BLEU."
pal-etal-2014-word,Word Alignment-Based Reordering of Source Chunks in {PB}-{SMT},2014,26,3,1,1,13776,santanu pal,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Reordering poses a big challenge in statistical machine translation between distant language pairs. The paper presents how reordering between distant language pairs can be handled efficiently in phrase-based statistical machine translation. The problem of reordering between distant languages has been approached with prior reordering of the source text at chunk level to simulate the target language ordering. Prior reordering of the source chunks is performed in the present work by following the target word order suggested by word alignment. The testset is reordered using monolingual MT trained on source and reordered source. This approach of prior reordering of the source chunks was compared with pre-ordering of source words based on word alignments and the traditional approach of prior source reordering based on language-pair specific reordering rules. The effects of these reordering approaches were studied on an English--Bengali translation task, a language pair with different word order. From the experimental results it was found that word alignment based reordering of the source chunks is more effective than the other reordering approaches, and it produces statistically significant improvements over the baseline system on BLEU. On manual inspection we found significant improvements in terms of word alignments."
W13-4305,Event and Event Actor Alignment in Phrase Based Statistical Machine Translation,2013,25,0,2,0,40689,anup kolya,Proceedings of the 11th Workshop on {A}sian Language Resources,0,"This paper proposes the impacts of event and event actor alignment in English and Bengali phrase based Statistical Machine Translation (PB-SMT) System. Initially, events and event actors are identified from English and Bengali parallel corpus. For events and event actor identification in English we proposed a hybrid technique and it was carried out within the TimeML framework. Events in Bengali are identified based on the concept of complex predicate structures. There can be one-to-one and one-to-many mappings between English and Bengali events and event actors. We preprocess the parallel corpus by single tokenizing the multiword events and event-actors which reflects some significant gain on the PB-SMT system. We represent a hybrid alignment approach of events and event-actors in both English-Bengali training corpus by defining a rule based aligner and a statistical hybrid aligner. The rule base aligner assumes a heuristic that the sequence of events and event actors on the source (English) side are also maintained in the target (Bengali) side. The performance of PB-SMT system could vary depending on the number of events and event-actors that are identified in the parallel training data. The proposed system achieves significant improvements (5.79 BLEU points absolute, 53.02% relative improvement) over the baseline system on an English-Bengali translation task."
W13-2814,A Hybrid Word Alignment Model for Phrase-Based Statistical Machine Translation,2013,25,9,1,1,13776,santanu pal,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,This paper proposes a hybrid word alignment model for Phrase-Based Statistical Machine translation (PB-SMT). The proposed hybrid alignment model provides most informative alignment links which are offered by both unsupervised and semi-supervised word alignment models. Two unsupervised word alignment models (GIZA and Berkeley aligner) and a rule based aligner are combined together. The rule based aligner only aligns named entities (NEs) and chunks. The NEs are aligned through transliteration using a joint source-channel model. Chunks are aligned employing a bootstrapping approach by translating the source chunks into the target language using a baseline PB-SMT system and subsequently validating the target chunks using a fuzzy matching technique against the target corpus. All the experiments are carried out after single-tokenizing the multi-word NEs. Our best system provided significant improvements over the baseline as measured by BLEU.
W13-2509,Improving {MT} System Using Extracted Parallel Fragments of Text from Comparable Corpora,2013,13,12,2,0,40919,rajdeep gupta,Proceedings of the Sixth Workshop on Building and Using Comparable Corpora,0,"In this article, we present an automated approach of extracting English-Bengali parallel fragments of text from comparable corpora created using Wikipedia documents. Our approach exploits the multilingualism of Wikipedia. The most important fact is that this approach does not need any domain specific corpus. We have been able to improve the BLEU score of an existing domain specific EnglishBengali machine translation system by 11.14%."
2013.mtsummit-papers.8,{MWE} Alignment in Phrase Based Statistical Machine Translation,2013,-1,-1,1,1,13776,santanu pal,Proceedings of Machine Translation Summit XIV: Papers,0,None
W12-2023,Detection and Correction of Preposition and Determiner Errors in {E}nglish: {HOO} 2012,2012,11,0,3,0.952381,41282,pinaki bhaskar,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"This paper reports on our work in the HOO 2012 shared task. The task is to automatically detect, recognize and correct the errors in the use of prepositions and determiners in a set of given test documents in English. For that, we have developed a hybrid system of an n-gram statistical model along with some rule-based techniques. The system has been trained on the HOO shared task's training datasets and run on the test set given. We have submitted one run, which has demonstrated an F-score of 7.1, 6.46 and 2.58 for detection, recognition and correction respectively before revision and F-score of 8.22, 7.59 and 3.16 for detection, recognition and correction respectively after revision."
W12-0113,Bootstrapping Method for Chunk Alignment in Phrase Based {SMT},2012,21,2,1,1,13776,santanu pal,Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation ({ESIRMT}) and Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"The processing of parallel corpus plays very crucial role for improving the overall performance in Phrase Based Statistical Machine Translation systems (PB-SMT). In this paper the automatic alignments of different kind of chunks have been studied that boosts up the word alignment as well as the machine translation quality. Single-tokenization of Noun-noun MWEs, phrasal preposition (source side only) and reduplicated phrases (target side only) and the alignment of named entities and complex predicates provide the best SMT model for bootstrapping. Automatic bootstrapping on the alignment of various chunks makes significant gains over the previous best English-Bengali PB-SMT system. The source chunks are translated into the target language using the PB-SMT system and the translated chunks are compared with the original target chunk. The aligned chunks increase the size of the parallel corpus. The processes are run in a bootstrapping manner until all the source chunks have been aligned with the target chunks or no new chunk alignment is identified by the bootstrapping process. The proposed system achieves significant improvements (2.25 BLEU over the best System and 8.63 BLEU points absolute over the baseline system, 98.74% relative improvement over the baseline system) on an English- Bengali translation task."
W11-2839,May {I} check the {E}nglish of your paper!!!,2011,4,4,3,0.952381,41282,pinaki bhaskar,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"This paper reports about our work in the HOO shared task 2011. The task is to automatically correct the English of a given document. For that, we have developed a hybrid system of a statistical CRF based model along with a rule-based technique has been used. The system has been trained on the HOO shared task training datasets and run on the test set given by the organizer of HOO. We have submitted one run, which has been demonstrated F-score of 0.204, 0.178 and 0.167 for detection, recognition and correction respectively."
W11-1307,Shared Task System Description: Measuring the Compositionality of Bigrams using Statistical Methodologies,2011,7,2,2,0,7353,tanmoy chakraborty,Proceedings of the Workshop on Distributional Semantics and Compositionality,0,"The measurement of relative compositionality of bigrams is crucial to identify Multi-word Expressions (MWEs) in Natural Language Processing (NLP) tasks. The article presents the experiments carried out as part of the participation in the shared task 'Distributional Semantics and Compositionality (DiSCo)' organized as part of the DiSCo workshop in ACL-HLT 2011. The experiments deal with various collocation based statistical approaches to compute the relative compositionality of three types of bigram phrases (Adjective-Noun, Verb-subject and Verb-object combinations). The experimental results in terms of both fine-grained and coarse-grained compositionality scores have been evaluated with the human annotated gold standard data. Reasonable results have been obtained in terms of average point difference and coarse precision."
2011.mtsummit-papers.23,Handling Multiword Expressions in Phrase-Based Statistical Machine Translation,2011,-1,-1,1,1,13776,santanu pal,Proceedings of Machine Translation Summit XIII: Papers,0,None
W10-3706,Automatic Extraction of Complex Predicates in {B}engali,2010,8,11,2,0,1241,dipankar das,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,"This paper presents the automatic extraction of Complex Predicates (CPs) in Bengali with a special focus on compound verbs (Verb  Verb) and conjunct verbs (Noun /Adjective  Verb). The lexical patterns of compound and conjunct verbs are extracted based on the information of shallow morphology and available seed lists of verbs. Lexical scopes of compound and conjunct verbs in consecutive sequence of Complex Predicates (CPs) have been identified. The fine-grained error analysis through confusion matrix highlights some insufficiencies of lexical patterns and the impacts of different constraints that are used to identify the Complex Predicates (CPs). System achieves F-Scores of 75.73%, and 77.92% for compound verbs and 89.90% and 89.66% for conjunct verbs respectively on two types of Bengali corpus."
W10-3707,Handling Named Entities and Compound Verbs in Phrase-Based Statistical Machine Translation,2010,25,23,1,1,13776,santanu pal,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,"Data preprocessing plays a crucial role in phrase-based statistical machine translation (PB-SMT). In this paper, we show how single-tokenization of two types of multi-word expressions (MWE), namely named entities (NE) and compound verbs, as well as their prior alignment can boost the performance of PB-SMT. Single-tokenization of compound verbs and named entities (NE) provides significant gains over the baseline PB-SMT system. Automatic alignment of NEs substantially improves the overall MT performance, and thereby the word alignment quality indirectly. For establishing NE alignments, we transliterate source NEs into the target language and then compare them with the target NEs. Target language NEs are first converted into a canonical form before the comparison takes place. Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an Englishxe2x80x94Bangla translation task."
S10-1045,{JU}: A Supervised Approach to Identify Semantic Relations from Paired Nominals,2010,5,3,1,1,13776,santanu pal,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This article presents the experiments carried out at Jadavpur University as part of the participation in Multi-Way Classification of Semantic Relations between Pairs of Nomi-nals in the SemEval 2010 exercise. Separate rules for each type of the relations are identified in the baseline model based on the verbs and prepositions present in the segment between each pair of nominals. Inclusion of WordNet features associated with the paired nominals play an important role in distinguishing the relations from each other. The Conditional Random Field (CRF) based machine-learning framework is adopted for classifying the pair of nominals. Application of dependency relations, Named Entities (NE) and various types of WordNet features along with several combinations of these features help to improve the performance of the system. Error analysis suggests that the performance can be improved by applying suitable strategies to differentiate each paired nominal in an already identified relation. Evaluation result gives an overall macro-averaged F1 score of 52.16%."
