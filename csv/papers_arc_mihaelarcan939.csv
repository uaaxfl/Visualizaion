2021.gem-1.13,{NUIG}-{DSI}{'}s submission to The {GEM} Benchmark 2021,2021,-1,-1,2,1,6274,nivranshu pasricha,"Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",0,"This paper describes the submission by NUIG-DSI to the GEM benchmark 2021. We participate in the modeling shared task where we submit outputs on four datasets for data-to-text generation, namely, DART, WebNLG (en), E2E and CommonGen. We follow an approach similar to the one described in the GEM benchmark paper where we use the pre-trained T5-base model for our submission. We train this model on additional monolingual data where we experiment with different masking strategies specifically focused on masking entities, predicates and concepts as well as a random masking strategy for pre-training. In our results we find that random masking performs the best in terms of automatic evaluation metrics, though the results are not statistically significantly different compared to other masking strategies."
2021.deelio-1.8,Enhancing Multiple-Choice Question Answering with Causal Knowledge,2021,-1,-1,2,0,11251,dhairya dalal,Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures,0,"The task of causal question answering aims to reason about causes and effects over a provided real or hypothetical premise. Recent approaches have converged on using transformer-based language models to solve question answering tasks. However, pretrained language models often struggle when external knowledge is not present in the premise or when additional context is required to answer the question. To the best of our knowledge, no prior work has explored the efficacy of augmenting pretrained language models with external causal knowledge for multiple-choice causal question answering. In this paper, we present novel strategies for the representation of causal knowledge. Our empirical results demonstrate the efficacy of augmenting pretrained models with external causal knowledge. We show improved performance on the COPA (Choice of Plausible Alternatives) and WIQA (What If Reasoning Over Procedural Text) benchmark tasks. On the WIQA benchmark, our approach is competitive with the state-of-the-art and exceeds it within the evaluation subcategories of In-Paragraph and Out-of-Paragraph perturbations."
2020.wildre-1.2,A Dataset for Troll Classification of {T}amil{M}emes,2020,-1,-1,4,0,11157,shardul suryawanshi,Proceedings of the WILDRE5{--} 5th Workshop on Indian Language Data: Resources and Evaluation,0,"Social media are interactive platforms that facilitate the creation or sharing of information, ideas or other forms of expression among people. This exchange is not free from offensive, trolling or malicious contents targeting users or communities. One way of trolling is by making memes, which in most cases combines an image with a concept or catchphrase. The challenge of dealing with memes is that they are region-specific and their meaning is often obscured in humour or sarcasm. To facilitate the computational modelling of trolling in the memes for Indian languages, we created a meme dataset for Tamil (TamilMemes). We annotated and released the dataset containing suspected trolls and not-troll memes. In this paper, we use the a image classification to address the difficulties involved in the classification of troll memes with the existing methods. We found that the identification of a troll meme with such an image classifier is not feasible which has been corroborated with precision, recall and F1-score."
2020.webnlg-1.6,Utilising Knowledge Graph Embeddings for Data-to-Text Generation,2020,-1,-1,2,1,6274,nivranshu pasricha,Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+),0,"Data-to-text generation has recently seen a move away from modular and pipeline architectures towards end-to-end architectures based on neural networks. In this work, we employ knowledge graph embeddings and explore their utility for end-to-end approaches in a data-to-text generation task. Our experiments show that using knowledge graph embeddings can yield an improvement of up to 2 {--} 3 BLEU points for seen categories on the WebNLG corpus without modifying the underlying neural network architecture."
2020.webnlg-1.15,{NUIG}-{DSI} at the {W}eb{NLG}+ challenge: Leveraging Transfer Learning for {RDF}-to-text generation,2020,-1,-1,2,1,6274,nivranshu pasricha,Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+),0,"This paper describes the system submitted by NUIG-DSI to the WebNLG+ challenge 2020 in the RDF-to-text generation task for the English language. For this challenge, we leverage transfer learning by adopting the T5 model architecture for our submission and fine-tune the model on the WebNLG+ corpus. Our submission ranks among the top five systems for most of the automatic evaluation metrics achieving a BLEU score of 51.74 over all categories with scores of 58.23 and 45.57 across seen and unseen categories respectively."
2020.vardial-1.6,Bilingual Lexicon Induction across Orthographically-distinct Under-Resourced {D}ravidian Languages,2020,-1,-1,3,0.925926,613,bharathi chakravarthi,"Proceedings of the 7th Workshop on NLP for Similar Languages, Varieties and Dialects",0,"Bilingual lexicons are a vital tool for under-resourced languages and recent state-of-the-art approaches to this leverage pretrained monolingual word embeddings using supervised or semi-supervised approaches. However, these approaches require cross-lingual information such as seed dictionaries to train the model and find a linear transformation between the word embedding spaces. Especially in the case of low-resourced languages, seed dictionaries are not readily available, and as such, these methods produce extremely weak results on these languages. In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts. To take advantage of orthographic information and cognates in these languages, we bring the related languages into a single script. Previous approaches have used linguistically sub-optimal measures such as the Levenshtein edit distance to detect cognates, whereby we demonstrate that the longest common sub-sequence is linguistically more sound and improves the performance of bilingual lexicon induction. We show that our approach can increase the accuracy of bilingual lexicon induction methods on these languages many times, making bilingual lexicon induction approaches feasible for such under-resourced languages."
2020.trac-1.6,Multimodal Meme Dataset ({M}ulti{OFF}) for Identifying Offensive Content in Image and Text,2020,-1,-1,3,0,11157,shardul suryawanshi,"Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying",0,"A meme is a form of media that spreads an idea or emotion across the internet. As posting meme has become a new form of communication of the web, due to the multimodal nature of memes, postings of hateful memes or related events like trolling, cyberbullying are increasing day by day. Hate speech, offensive content and aggression content detection have been extensively explored in a single modality such as text or image. However, combining two modalities to detect offensive content is still a developing area. Memes make it even more challenging since they express humour and sarcasm in an implicit way, because of which the meme may not be offensive if we only consider the text or the image. Therefore, it is necessary to combine both modalities to identify whether a given meme is offensive or not. Since there was no publicly available dataset for multimodal offensive meme content detection, we leveraged the memes related to the 2016 U.S. presidential election and created the MultiOFF multimodal meme dataset for offensive content detection dataset. We subsequently developed a classifier for this task using the MultiOFF dataset. We use an early fusion technique to combine the image and text modality and compare it with a text- and an image-only baseline to investigate its effectiveness. Our results show improvements in terms of Precision, Recall, and F-Score. The code and dataset for this paper is published in \textit{ \url{https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text} }"
2020.semeval-1.208,{NUIG} at {S}em{E}val-2020 Task 12: Pseudo Labelling for Offensive Content Classification,2020,-1,-1,2,0,11157,shardul suryawanshi,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"This work addresses the classification problem defined by sub-task A (English only) of the OffensEval 2020 challenge. We used a semi-supervised approach to classify given tweets into an offensive (OFF) or not-offensive (NOT) class. As the OffensEval 2020 dataset is loosely labelled with confidence scores given by unsupervised models, we used last year{'}s offensive language identification dataset (OLID) to label the OffensEval 2020 dataset. Our approach uses a pseudo-labelling method to annotate the current dataset. We trained four text classifiers on the OLID dataset and the classifier with the highest macro-averaged F1-score has been used to pseudo label the OffensEval 2020 dataset. The same model which performed best amongst four text classifiers on OLID dataset has been trained on the combined dataset of OLID and pseudo labelled OffensEval 2020. We evaluated the classifiers with precision, recall and macro-averaged F1-score as the primary evaluation metric on the OLID and OffensEval 2020 datasets. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: \url{http://creativecommons.org/licenses/by/4.0/}."
2020.globalex-1.15,{NUIG} at {TIAD}: Combining Unsupervised {NLP} and Graph Metrics for Translation Inference,2020,-1,-1,2,0,1255,john mccrae,Proceedings of the 2020 Globalex Workshop on Linked Lexicography,0,"In this paper, we present the NUIG system at the TIAD shard task. This system includes graph-based metrics calculated using novel algorithms, with an unsupervised document embedding tool called ONETA and an unsupervised multi-way neural machine translation method. The results are an improvement over our previous system and produce the highest precision among all systems in the task as well as very competitive F-Measure results. Incorporating features from other systems should be easy in the framework we describe in this paper, suggesting this could very easily be extended to an even stronger result."
2020.coling-main.369,Suggest me a movie for tonight: Leveraging Knowledge Graphs for Conversational Recommendation,2020,-1,-1,3,0,3060,rajdeep sarkar,Proceedings of the 28th International Conference on Computational Linguistics,0,"Conversational recommender systems focus on the task of suggesting products to users based on the conversation flow. Recently, the use of external knowledge in the form of knowledge graphs has shown to improve the performance in recommendation and dialogue systems. Information from knowledge graphs aids in enriching those systems by providing additional information such as closely related products and textual descriptions of the items. However, knowledge graphs are incomplete since they do not contain all factual information present on the web. Furthermore, when working on a specific domain, knowledge graphs in its entirety contribute towards extraneous information and noise. In this work, we study several subgraph construction methods and compare their performance across the recommendation task. We incorporate pre-trained embeddings from the subgraphs along with positional embeddings in our models. Extensive experiments show that our method has a relative improvement of at least 5.62{\%} compared to the state-of-the-art on multiple metrics on the recommendation task."
W19-7101,{W}ord{N}et Gloss Translation for Under-resourced Languages using Multilingual Neural Machine Translation,2019,0,2,2,1,613,bharathi chakravarthi,Proceedings of the Second Workshop on Multilingualism at the Intersection of Knowledge Bases and Machine Translation,0,"This work was supported by the Spanish Ministry of Economy andn Competitiveness (MINECO) FPI grant numbern BES-2017-081045, and projects BigKnowledge (BBVA foundation grant 2018), DOMINOn (PGC2018-102041-B-I00, MCIU/AEI/FEDER,n UE) and PROSA-MED (TIN2016-77820-C3-n 1-R, MCIU/AEI/FEDER, UE). We thank Uxoan Inurrieta for helping us with the glosses."
W19-6809,Multilingual Multimodal Machine Translation for {D}ravidian Languages utilizing Phonetic Transcription,2019,-1,-1,6,1,613,bharathi chakravarthi,Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages,0,None
W19-6725,Leveraging Rule-Based Machine Translation Knowledge for Under-Resourced Neural Machine Translation Models,2019,0,1,7,0,23599,daniel torregrosa,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,"This publication has emanated from research supported in part by a research grant from Sciencen Foundation Ireland (SFI) under Grant Numbern SFI/12/RC/2289, co-funded by the European Regional Development Fund, and the Enterprise Ireland (EI) Innovation Partnership Programme undern grant agreement No IP20180729, NURS xe2x80x93 Neuraln Machine Translation for Under-Resourced Scenarios"
W19-3205,Passive Diagnosis Incorporating the {PHQ}-4 for Depression and Anxiety,2019,-1,-1,3,0,24486,fionn delahunty,Proceedings of the Fourth Social Media Mining for Health Applications ({\\#}SMM4H) Workshop {\\&} Shared Task,0,"Depression and anxiety are the two most prevalent mental health disorders worldwide, impacting the lives of millions of people each year. In this work, we develop and evaluate a multilabel, multidimensional deep neural network designed to predict PHQ-4 scores based on individuals written text. Our system outperforms random baseline metrics and provides a novel approach to how we can predict psychometric scores from written text. Additionally, we explore how this architecture can be applied to analyse social media data."
L18-1149,Automatic Enrichment of Terminological Resources: the {IATE} {RDF} Example,2018,0,0,1,1,6275,mihael arcan,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This publication is supported by a research grant from Science Foundation Ireland, SFI/12/RC/2289 (Insight), a research visit grant from Universidad Politecnica de Madrid, xc2xb4n by the Spanish Datos4.0 project (TIN2016-78011-C4-4-R)n and by the EUxe2x80x99s Lynx project (H2020 Research and Innovation Programme under GA num 780602)."
2018.gwc-1.10,Improving Wordnets for Under-Resourced Languages Using Machine Translation,2018,23,2,2,1,613,bharathi chakravarthi,Proceedings of the 9th Global Wordnet Conference,0,"Wordnets are extensively used in natural language processing, but the current approaches for manually building a wordnet from scratch involves large research groups for a long period of time, which are typically not available for under-resourced languages. Even if wordnet-like resources are available for under-resourced languages, they are often not easily accessible, which can alter the results of applications using these resources. Our proposed method presents an expand approach for improving and generating wordnets with the help of machine translation. We apply our methods to improve and extend wordnets for the Dravidian languages, i.e., Tamil, Telugu, Kannada, which are severly under-resourced languages. We report evaluation results of the generated wordnet senses in term of precision for these languages. In addition to that, we carried out a manual evaluation of the translations for the Tamil language, where we demonstrate that our approach can aid in improving wordnet resources for under-resourced Dravidian languages."
L16-1090,{IRIS}: {E}nglish-{I}rish Machine Translation System,2016,19,0,1,1,6275,mihael arcan,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We describe IRIS, a statistical machine translation (SMT) system for translating from English into Irish and vice versa. Since Irish is considered an under-resourced language with a limited amount of machine-readable text, building a machine translation system that produces reasonable translations is rather challenging. As translation is a difficult task, current research in SMT focuses on obtaining statistics either from a large amount of parallel, monolingual or other multilingual resources. Nevertheless, we collected available English-Irish data and developed an SMT system aimed at supporting human translators and enabling cross-lingual language technology tasks."
C16-1010,Expanding wordnets to new languages with multilingual sense disambiguation,2016,33,5,1,1,6275,mihael arcan,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Princeton WordNet is one of the most important resources for natural language processing, but is only available for English. While it has been translated using the expand approach to many other languages, this is an expensive manual process. Therefore it would be beneficial to have a high-quality automatic translation approach that would support NLP techniques, which rely on WordNet in new languages. The translation of wordnets is fundamentally complex because of the need to translate all senses of a word including low frequency senses, which is very challenging for current machine translation approaches. For this reason we leverage existing translations of WordNet in other languages to identify contextual information for wordnet senses from a large set of generic parallel corpora. We evaluate our approach using 10 translated wordnets for European languages. Our experiment shows a significant improvement over translation without any contextual information. Furthermore, we evaluate how the choice of pivot languages affects performance of multilingual word sense disambiguation."
2016.amta-researchers.1,Instance Selection for Online Automatic Post-Editing in a multi-domain scenario,2016,0,1,2,0,13898,rajen chatterjee,Conferences of the Association for Machine Translation in the Americas: MT Researchers' Track,0,"In recent years, several end-to-end online translation systems have been proposed to successfully incorporate human post-editing feedback in the translation workflow. The performance of these systems in a multi-domain translation environment (involving different text genres, post-editing styles, machine translation systems) within the automatic post-editing (APE) task has not been thoroughly investigated yet. In this work, we show that when used in the APE framework the existing online systems are not robust towards domain changes in the incoming data stream. In particular, these systems lack in the capability to learn and use domain-specific post-editing rules from a pool of multi-domain data sets. To cope with this problem, we propose an online learning framework that generates more reliable translations with significantly better quality as compared with the existing online and batch systems. Our framework includes: i) an instance selection technique based on information retrieval that helps to build domain-specific APE systems, and ii) an optimization procedure to tune the feature weights of the log-linear model that allows the decoder to improve the post-editing quality."
W15-4929,{M}ixed{E}motions: Social Semantic Emotion Analysis for Innovative Multilingual Big Data Analytics Markets,2015,-1,-1,1,1,6275,mihael arcan,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
P15-1069,Knowledge Portability with Semantic Expansion of Ontology Labels,2015,44,13,1,1,6275,mihael arcan,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,This publication has emanated from research supported in part by a research grant from Sciencen Foundation Ireland (SFI) under Grant Numbern SFI/12/RC/2289 (Insight) and the European Unionn supported projects LIDER (ICT-2013.4.1-610782)n and MixedEmotions (H2020-644632).
2015.eamt-1.14,Identifying main obstacles for statistical machine translation of morphologically rich {S}outh {S}lavic languages,2015,11,2,2,0,5059,maja popovic,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"The best way to improve a statistical machine translation system is to identify concrete problems causing translation errors and address them. Many of these problems are related to the characteristics of the involved languages and differences between them. This work explores the main obstacles for statistical machine translation systems involving two morphologically rich and under-resourced languages, namely Serbian and Slovenian. Systems are trained for translations from and into English and German using parallel texts from different domains, including both written and spoken language. It is shown that for all translation directions structural properties concerning multi-noun collocations and exact phrase boundaries are the most difficult for the systems, followed by negation, preposition and local word order differences. For translation into English and German, articles and pronouns are the most problematic, as well as disambiguation of certain frequent functional words. For translation into Serbian and Slovenian, cases and verb inflections are most difficult. In addition, local word order involving verbs is often incorrect and verb parts are often missing, especially when translating from German."
2015.eamt-1.15,Poor man{'}s lemmatisation for automatic error classification,2015,9,0,2,0,5059,maja popovic,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,This publication has emanated from research supported by QTLEAP project xe2x80x93 ECs FP7 (FP7/2007-n 2013) under grant agreement number 610516:n xe2x80x9cQTLEAP: Quality Translation by Deep Language Engineering Approachesxe2x80x9d and by a researchn grant from Science Foundation Ireland (SFI) undern Grant Number SFI/12/RC/2289. We are grateful ton the reviewers for their valuable feedbac
2015.eamt-1.30,{M}ixed{E}motions: Social Semantic Emotion Analysis for Innovative Multilingual Big Data Analytics Markets,2015,-1,-1,1,1,6275,mihael arcan,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
W14-4803,Identification of Bilingual Terms from Monolingual Documents for Statistical Machine Translation,2014,29,10,1,1,6275,mihael arcan,Proceedings of the 4th International Workshop on Computational Terminology (Computerm),0,"This publication has emanated from research supported in part by a research grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289 and by the European Union supported projectsn EuroSentiment (Grant No. 296277), LIDER (Grant No. 610782) and MateCat (ICT-2011.4.2-287688)."
2014.amta-researchers.5,Enhancing statistical machine translation with bilingual terminology in a {CAT} environment,2014,40,14,1,1,6275,mihael arcan,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"In this paper, we address the problem of extracting and integrating bilingual terminology into a Statistical Machine Translation (SMT) system for a Computer Aided Translation (CAT) tool scenario. We develop a framework that, taking as input a small amount of parallel in-domain data, gathers domain-specific bilingual terms and injects them in an SMT system to enhance the translation productivity. Therefore, we investigate several strategies to extract and align bilingual terminology, and to embed it into the SMT. We compare two embedding methods that can be easily used at run-time without altering the normal activity of an SMT system: XML markup and the cache-based model. We tested our framework on two different domains showing improvements up to 15{\%} BLEU score points."
W13-5502,Linguistic Linked Data for Sentiment Analysis,2013,11,10,2,0,6276,paul buitelaar,"Proceedings of the 2nd Workshop on Linked Data in Linguistics ({LDL}-2013): Representing and linking lexicons, terminologies and other language data",0,"In this paper we describe the specification of amodel for the semantically interoperable representation of language resources for sentiment analysis. The model integrates lemon, an RDF-based model for the specification of ontology-lexica (Buitelaar et al. 2009), which is used increasinglyfor the representation of language resources asLinked Data, with Marl, an RDF-based model for the representation of sentiment annotations (West-erski et al., 2011; Sanchez-Rada et al., 2013)"
N13-2006,Ontology Label Translation,2013,20,4,1,1,6275,mihael arcan,Proceedings of the 2013 {NAACL} {HLT} Student Research Workshop,0,"Our research investigates the translation of ontology labels, which has applications in multilingual knowledge access. Ontologies are often defined only in one language, mostly English. To enable knowledge access across languages, such monolingual ontologies need to be translated into other languages. The primary challenge in ontology label translation is the lack of context, which makes this task rather different than document translation. The core objective therefore, is to provide statistical machine translation (SMT) systems with additional context information. In our approach, we first extend standard SMT by enhancing a translation model with context information that keeps track of surrounding words for each translation. We compute a semantic similarity between the phrase pair context vector from the parallel corpus and a vector of noun phrases that occur in surrounding ontology labels. We applied our approach to the translation of a financial ontology, translating from English to German, using Europarl as parallel corpus. This experiment showed that our approach can provide a slight improvement over standard SMT for this task, without exploiting any additional domain-specific resources."
2013.mtsummit-posters.1,Translating the {FINREP} Taxonomy using a Domain-specific Corpus,2013,-1,-1,1,1,6275,mihael arcan,Proceedings of Machine Translation Summit XIV: Posters,0,None
2013.mtsummit-european.13,{MONNET}: Multilingual Ontologies for Networked Knowledge,2013,-1,-1,1,1,6275,mihael arcan,Proceedings of Machine Translation Summit XIV: European projects,0,None
W12-4210,Using Domain-specific and Collaborative Resources for Term Translation,2012,23,2,1,1,6275,mihael arcan,"Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"In this article we investigate the translation of terms from English into German and vice versa in the isolation of an ontology vocabulary. For this study we built new domain-specific resources from the translation search engine Linguee and from the online encyclopedia Wikipedia. We learned that a domain-specific resource produces better results than a bigger, but more general one. The first finding of our research is that the vocabulary and the structure of the parallel corpus are important. By integrating the multilingual knowledge base Wikipedia, we further improved the translation wrt. the domain-specific resources, whereby some translation evaluation metrics outperformed the results of Google Translate. This finding leads us to the conclusion that a hybrid translation system, a combination of bilingual terminological resources and statistical machine translation can help to improve translation of domain-specific terms."
C12-1005,Experiments with Term Translation,2012,24,4,1,1,6275,mihael arcan,Proceedings of {COLING} 2012,0,"In this article we investigate the translation of financial terms from English into German in the isolation of an ontology vocabulary. For this study we automatically built new domain-specific resources from the translation search engine Linguee and from the online encyclopaedia Wikipedia. Due to the fact that we performed the translation approach on a monolingual ontology, we ran several sub-experiments to find the most appropriate model to translate the financial vocabulary. The findings from these experiments lead to the conclusion that a hybrid translation system, a combination of bilingual terminological resources and statistical machine translation, can help to improve translation of domain-specific terms. Finally we undertook a manual cross-lingual evaluation on the monolingual ontology to get a better understanding on this specific short text translation task."
