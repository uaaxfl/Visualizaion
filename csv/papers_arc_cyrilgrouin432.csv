2021.jeptalnrecital-deft.1,Classification de cas cliniques et {\\'e}valuation automatique de r{\\'e}ponses d{'}{\\'e}tudiants : pr{\\'e}sentation de la campagne {DEFT} 2021 (Clinical cases classification and automatic evaluation of student answers : Presentation of the {DEFT} 2021 Challenge),2021,-1,-1,1,1,5675,cyril grouin,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Atelier D{\\'E}fi Fouille de Textes (DEFT),0,"Le d{\'e}fi fouille de textes (DEFT) est une campagne d{'}{\'e}valuation annuelle francophone. Nous pr{\'e}sentons les corpus et baselines {\'e}labor{\'e}es pour trois t{\^a}ches : (i) identifier le profil clinique de patients d{\'e}crits dans des cas cliniques, (ii) {\'e}valuer automatiquement les r{\'e}ponses d{'}{\'e}tudiants sur des questionnaires en ligne (Moodle) {\`a} partir de la correction de l{'}enseignant, et (iii) poursuivre une {\'e}valuation de r{\'e}ponses d{'}{\'e}tudiants {\`a} partir de r{\'e}ponses d{\'e}j{\`a} {\'e}valu{\'e}es par l{'}enseignant. Les r{\'e}sultats varient de 0,394 {\`a} 0,814 de F-mesure sur la premi{\`e}re t{\^a}che (7 {\'e}quipes), de 0,448 {\`a} 0,682 de pr{\'e}cision sur la deuxi{\`e}me (3 {\'e}quipes), et de 0,133 {\`a} 0,510 de pr{\'e}cision sur la derni{\`e}re (3 {\'e}quipes)."
2021.eval4nlp-1.1,Differential Evaluation: a Qualitative Analysis of Natural Language Processing System Behavior Based Upon Data Resistance to Processing,2021,-1,-1,3,0,8588,lucie gianola,Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems,0,None
2020.lrec-1.614,Inference Annotation of a {C}hinese Corpus for Opinion Mining,2020,0,0,4,0,17883,liyun yan,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Polarity classification (positive, negative or neutral opinion detection) is well developed in the field of opinion mining. However, existing tools, which perform with high accuracy on short sentences and explicit expressions, have limited success interpreting narrative phrases and inference contexts. In this article, we will discuss an important aspect of opinion mining: inference. We will give our definition of inference, classify different types, provide an annotation framework and analyze the annotation results. While inferences are often studied in the field of Natural-language understanding (NLU), we propose to examine inference as it relates to opinion mining. Firstly, based on linguistic analysis, we clarify what kind of sentence contains an inference. We define five types of inference: logical inference, pragmatic inference, lexical inference, enunciative inference and discursive inference. Second, we explain our annotation framework which includes both inference detection and opinion mining. In short, this manual annotation determines whether or not a target contains an inference. If so, we then define inference type, polarity and topic. Using the results of this annotation, we observed several correlation relations which will be used to determine distinctive features for automatic inference classification in further research. We also demonstrate the results of three preliminary classification experiments."
2020.jeptalnrecital-deft.1,Pr{\\'e}sentation de la campagne d{'}{\\'e}valuation {DEFT} 2020 : similarit{\\'e} textuelle en domaine ouvert et extraction d{'}information pr{\\'e}cise dans des cas cliniques (Presentation of the {DEFT} 2020 Challenge : open domain textual similarity and precise information extraction from clinical cases ),2020,-1,-1,3,0,5648,remi cardon,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Atelier D{\\'E}fi Fouille de Textes",0,"L{'}{\'e}dition 2020 du d{\'e}fi fouille de texte (DEFT) a propos{\'e} deux t{\^a}ches autour de la similarit{\'e} textuelle et une t{\^a}che d{'}extraction d{'}information. La premi{\`e}re t{\^a}che vise {\`a} identifier le degr{\'e} de similarit{\'e} entre paires de phrases sur une {\'e}chelle de 0 (le moins similaire) {\`a} 5 (le plus similaire). Les r{\'e}sultats varient de 0,65 {\`a} 0,82 d{'}EDRM. La deuxi{\`e}me t{\^a}che consiste {\`a} d{\'e}terminer la phrase la plus proche d{'}une phrase source parmi trois phrases cibles fournies, avec des r{\'e}sultats tr{\`e}s {\'e}lev{\'e}s, variant de 0,94 {\`a} 0,99 de pr{\'e}cision. Ces deux t{\^a}ches reposent sur un corpus du domaine g{\'e}n{\'e}ral et de sant{\'e}. La troisi{\`e}me t{\^a}che propose d{'}extraire dix cat{\'e}gories d{'}informations du domaine m{\'e}dical depuis le corpus de cas cliniques de DEFT 2019. Les r{\'e}sultats varient de 0,07 {\`a} 0,66 de F-mesure globale pour la sous-t{\^a}che des pathologies et signes ou sympt{\^o}mes, et de 0,14 {\`a} 0,76 pour la sous-t{\^a}che sur huit cat{\'e}gories m{\'e}dicales. Les m{\'e}thodes utilis{\'e}es reposent sur des CRF et des r{\'e}seaux de neurones."
W19-5029,Clinical Case Reports for {NLP},2019,0,1,1,1,5675,cyril grouin,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"Textual data are useful for accessing expert information. Yet, since the texts are representative of distinct language uses, it is necessary to build specific corpora in order to be able to design suitable NLP tools. In some domains, such as medical domain, it may be complicated to access the representative textual data and their semantic annotations, while there exists a real need for providing efficient tools and methods. Our paper presents a corpus of clinical cases written in French, and their semantic annotations. Thus, we manually annotated a set of 717 files into four general categories (age, gender, outcome, and origin) for a total number of 2,835 annotations. The values of age, gender, and outcome are normalized. A subset with 70 files has been additionally manually annotated into 27 categories for a total number of 5,198 annotations."
R19-1089,Community Perspective on Replicability in Natural Language Processing,2019,0,0,4,0,3132,margot mieskes,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"With recent efforts in drawing attention to the task of replicating and/or reproducing results, for example in the context of COLING 2018 and various LREC workshops, the question arises how the NLP community views the topic of replicability in general. Using a survey, in which we involve members of the NLP community, we investigate how our community perceives this topic, its relevance and options for improvement. Based on over two hundred participants, the survey results confirm earlier observations, that successful reproducibility requires more than having access to code and data. Additionally, the results show that the topic has to be tackled from the authors{'}, reviewers{'} and community{'}s side."
2019.jeptalnrecital-long.5,Corpus annot{\\'e} de cas cliniques en fran{\\c{c}}ais (Annotated corpus with clinical cases in {F}rench),2019,-1,-1,2,0,5649,natalia grabar,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume I : Articles longs,0,"Les corpus textuels sont utiles pour diverses applications de traitement automatique des langues (TAL) en fournissant les donn{\'e}es n{\'e}cessaires pour leur cr{\'e}ation, adaptation ou {\'e}valuation. Cependant, dans certains domaines comme le domaine m{\'e}dical, l{'}acc{\`e}s aux donn{\'e}es est rendu compliqu{\'e}, voire impossible, pour des raisons de confidentialit{\'e} et d{'}{\'e}thique. Il existe n{\'e}anmoins de r{\'e}els besoins en corpus cliniques pour l{'}enseignement et la recherche. Pour r{\'e}pondre {\`a} ce d{\'e}fi, nous pr{\'e}sentons dans cet article le corpus CAS contenant des cas cliniques de patients, r{\'e}els ou fictifs, que nous avons compil{\'e}s. Ces cas cliniques en fran{\c{c}}ais couvrent plusieurs sp{\'e}cialit{\'e}s m{\'e}dicales et focalisent donc sur diff{\'e}rentes situations cliniques. Actuellement, le corpus contient 4 300 cas (environ 1,5M d{'}occurrences de mots). Il est accompagn{\'e} d{'}informations (discussions des cas cliniques, mots-cl{\'e}s, etc.) et d{'}annotations que nous avons effectu{\'e}es au regard des besoins de la recherche en TAL dans ce domaine. Nous pr{\'e}sentons {\'e}galement les r{\'e}sultats de premi{\`e}res exp{\'e}riences de recherche et d{'}extraction d{'}information qui ont {\'e}t{\'e} effectu{\'e}es avec ce corpus annot{\'e}. Ces exp{\'e}riences peuvent fournir une baseline {\`a} d{'}autres chercheurs souhaitant travailler avec les donn{\'e}es."
2019.jeptalnrecital-deft.1,Recherche et extraction d{'}information dans des cas cliniques. Pr{\\'e}sentation de la campagne d{'}{\\'e}valuation {DEFT} 2019 (Information Retrieval and Information Extraction from Clinical Cases),2019,-1,-1,2,0,5649,natalia grabar,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. D{\\'e}fi Fouille de Textes (atelier TALN-RECITAL),0,"Cet article pr{\'e}sente la campagne d{'}{\'e}valuation DEFT 2019 sur l{'}analyse de textes cliniques r{\'e}dig{\'e}s en fran{\c{c}}ais. Le corpus se compose de cas cliniques publi{\'e}s et discut{\'e}s dans des articles scientifiques, et index{\'e}s par des mots-cl{\'e}s. Nous proposons trois t{\^a}ches ind{\'e}pendantes : l{'}indexation des cas cliniques et discussions, {\'e}valu{\'e}e prioritairement par la MAP (mean average precision), l{'}appariement entre cas cliniques et discussions, {\'e}valu{\'e} au moyen d{'}une pr{\'e}cision, et l{'}extraction d{'}information parmi quatre cat{\'e}gories ({\^a}ge, genre, origine de la consultation, issue), {\'e}valu{\'e}e en termes de rappel, pr{\'e}cision et F-mesure. Nous pr{\'e}sentons les r{\'e}sultats obtenus par les participants sur chaque t{\^a}che."
L18-1025,Three Dimensions of Reproducibility in Natural Language Processing,2018,0,3,9,0,29526,bretonnel cohen,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Despite considerable recent attention to problems with reproducibility of scientific research, there is a striking lack of agreement about even the definition of the term. That is a problem, because the lack of a consensus definition makes it difficult to compare studies of reproducibility, and thus to have even a broad overview of the state of the issue in natural language processing. This paper proposes an ontology of reproducibility in that field. We show that three dimensions of reproducibility, corresponding to three kinds of claims in natural language processing papers, can account for a variety of types of research reports. These dimensions are reproducibility of a conclusion, of a finding, and of a value. Three biomedical natural language processing papers by the authors of this paper are analyzed with respect to these dimensions."
2018.jeptalnrecital-deft.1,{DEFT}2018 : recherche d{'}information et analyse de sentiments dans des tweets concernant les transports en {{\\^I}}le de {F}rance ({DEFT}2018 : Information Retrieval and Sentiment Analysis in Tweets about Public Transportation in {{\\^I}}le de {F}rance Region ),2018,-1,-1,2,0,5615,patrick paroubek,"Actes de la Conf{\\'e}rence TALN. Volume 2 - D{\\'e}monstrations, articles des Rencontres Jeunes Chercheurs, ateliers DeFT",0,"Cet article pr{\'e}sente l{'}{\'e}dition 2018 de la campagne d{'}{\'e}valuation DEFT (D{\'e}fi Fouille de Textes). A partir d{'}un corpus de tweets, quatre t{\^a}ches ont {\'e}t{\'e} propos{\'e}es : identifier les tweets sur la th{\'e}matique des transports, puis parmi ces derniers, identifier la polarit{\'e} (n{\'e}gatif, neutre, positif, mixte), identifier les marqueurs de sentiment et la cible, et enfin, annoter compl{\`e}tement chaque tweet en source et cible des sentiments exprim{\'e}s. Douze {\'e}quipes ont particip{\'e}, majoritairement sur les deux premi{\`e}res t{\^a}ches. Sur l{'}identification de la th{\'e}matique des transports, la micro F-mesure varie de 0,827 {\`a} 0,908. Sur l{'}identification de la polarit{\'e} globale, la micro F-mesure varie de 0,381 {\`a} 0,823."
2018.jeptalnrecital-court.32,Simplification de sch{\\'e}mas d{'}annotation : un aller sans retour ? (Annotation scheme simplification : a one way trip with no return ?),2018,-1,-1,1,1,5675,cyril grouin,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Dans cet article, nous comparons l{'}impact de la simplification d{'}un sch{\'e}ma d{'}annotation sur un syst{\`e}me de rep{\'e}rage d{'}entit{\'e}s nomm{\'e}es (REN). Une simplification consiste {\`a} rassembler les types d{'}entit{\'e}s nomm{\'e}es (EN) sous deux types g{\'e}n{\'e}riques (personne et lieu), l{'}autre revient {\`a} mieux d{\'e}finir chaque type d{'}EN. Nous observons une am{\'e}lioration des r{\'e}sultats sur les deux versions simplifi{\'e}es. Nous {\'e}tudions {\'e}galement la possibilit{\'e} de retrouver le niveau de d{\'e}tail des types d{'}EN du sch{\'e}ma d{'}origine {\`a} partir des versions simplifi{\'e}es. L{'}utilisation de r{\`e}gles de conversion permet de recouvrer les types d{'}EN d{'}origine, mais il reste une forme d{'}ambigu{\""\i}t{\'e} contextuelle qu{'}il est impossible de lever au moyen de r{\`e}gles."
I17-1101,Generating a Training Corpus for {OCR} Post-Correction Using Encoder-Decoder Model,2017,17,2,2,1,32928,eva dhondt,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"In this paper we present a novel approach to the automatic correction of OCR-induced orthographic errors in a given text. While current systems depend heavily on large training corpora or external information, such as domain-specific lexicons or confidence scores from the OCR process, our system only requires a small amount of (relatively) clean training data from a representative corpus to learn a character-based statistical language model using Bidirectional Long Short-Term Memory Networks (biLSTMs). We demonstrate the versatility and adaptability of our system on different text corpora with varying degrees of textual noise, including a real-life OCR corpus in the medical domain."
2017.jeptalnrecital-demo.11,Traitement automatique de la langue biom{\\'e}dicale au {LIMSI} (Biomedical language processing at {LIMSI}),2017,-1,-1,2,0,23937,christopher norman,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 3 - D{\\'e}monstrations,0,"Nous proposons des d{\'e}monstrations de trois outils d{\'e}velopp{\'e}s par le LIMSI en traitement automatique des langues appliqu{\'e} au domaine biom{\'e}dical : la d{\'e}tection de concepts m{\'e}dicaux dans des textes courts, la cat{\'e}gorisation d{'}articles scientifiques pour l{'}assistance {\`a} l{'}{\'e}criture de revues syst{\'e}matiques, et l{'}anonymisation de textes cliniques."
W16-6108,Low-resource {OCR} error detection and correction in {F}rench Clinical Texts,2016,11,2,2,1,32928,eva dhondt,Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis,0,None
W16-6110,Replicability of Research in Biomedical Natural Language Processing: a pilot evaluation for a coding task,2016,0,2,3,0,863,aurelie neveol,Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis,0,None
W16-5107,A Dataset for {ICD}-10 Coding of Death Certificates: Creation and Usage,2016,0,4,4,0,8590,thomas lavergne,Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining ({B}io{T}xt{M}2016),0,"Very few datasets have been released for the evaluation of diagnosis coding with the International Classification of Diseases, and only one so far in a language other than English. This paper describes a large-scale dataset prepared from French death certificates, and the problems which needed to be solved to turn it into a dataset suitable for the application of machine learning and natural language processing methods of ICD-10 coding. The dataset includes the free-text statements written by medical doctors, the associated meta-data, the human coder-assigned codes for each statement, as well as the statement segments which supported the coder{'}s decision for each code. The dataset comprises 93,694 death certificates totalling 276,103 statements and 377,677 ICD-10 code assignments (3,457 unique codes). It was made available for an international automated coding shared task, which attracted five participating teams. An extended version of the dataset will be used in a new edition of the shared task."
W16-5109,Supervised classification of end-of-lines in clinical text with no manual annotation,2016,0,0,2,0,8591,pierre zweigenbaum,Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining ({B}io{T}xt{M}2016),0,"In some plain text documents, end-of-line marks may or may not mark the boundary of a text unit (e.g., of a paragraph). This vexing problem is likely to impact subsequent natural language processing components, but is seldom addressed in the literature. We propose a method which uses no manual annotation to classify whether end-of-lines must actually be seen as simple spaces (soft line breaks) or as true text unit boundaries. This method, which includes self-training and co-training steps based on token and line length features, achieves 0.943 F-measure on a corpus of short e-books with controlled format, F=0.904 on a random sample of 24 clinical texts with soft line breaks, and F=0.898 on a larger set of mixed clinical texts which may or may not contain soft line breaks, a fairly high value for a method with no manual annotation."
W16-5112,Detection of Text Reuse in {F}rench Medical Corpora,2016,12,0,2,1,32928,eva dhondt,Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining ({B}io{T}xt{M}2016),0,"Electronic Health Records (EHRs) are increasingly available in modern health care institutions either through the direct creation of electronic documents in hospitals{'} health information systems, or through the digitization of historical paper records. Each EHR creation method yields the need for sophisticated text reuse detection tools in order to prepare the EHR collections for efficient secondary use relying on Natural Language Processing methods. Herein, we address the detection of two types of text reuse in French EHRs: 1) the detection of updated versions of the same document and 2) the detection of document duplicates that still bear surface differences due to OCR or de-identification processing. We present a robust text reuse detection method to automatically identify redundant document pairs in two French EHR corpora that achieves an overall macro F-measure of 0.68 and 0.60, respectively and correctly identifies all redundant document pairs of interest."
W16-3008,Identification of Mentions and Relations between Bacteria and Biotope from {P}ub{M}ed Abstracts,2016,-1,-1,1,1,5675,cyril grouin,Proceedings of the 4th {B}io{NLP} Shared Task Workshop,0,None
S16-1190,{LIMSI} at {S}em{E}val-2016 Task 12: machine-learning and temporal information to identify clinical events and time expressions,2016,9,3,1,1,5675,cyril grouin,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"Our experiments rely on a combination of machine-learning (CRF) and rule-based (HeidelTime) systems. First, a CRF system identifies both EVENTS and TIMEX3, along with polarity values for EVENT and types of TIMEX. Second, the HeidelTime tool identifies DOCTIME and TIMEX3 elements, and computes DocTimeRel for each EVENT identified by the CRF. Third, another CRF system computes DocTimeRel for each previously identified EVENT, based on DocTimeRel computed by HeidelTime. In the first submission, all EVENTS and TIMEX3 are identified through one general CRF model while in the second submission, we combined two CRF models (one for both EVENT and TIMEX3, and one only for TIMEX3) and we applied post-processing rules on the outputs."
L16-1320,Identification of Drug-Related Medical Conditions in Social Media,2016,0,4,2,1,35053,franccois morlanehondere,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Monitoring social media has been shown to be an interesting approach for the early detection of drug adverse effects. In this paper, we describe a system which extracts medical entities in French drug reviews written by users. We focus on the identification of medical conditions, which is based on the concept of post-coordination: we first extract minimal medical-related entities (pain, stomach) then we combine them to identify complex ones (It was the worst [pain I ever felt in my stomach]). These two steps are respectively performed by two classifiers, the first being based on Conditional Random Fields and the second one on Support Vector Machines. The overall results of the minimal entity classifier are the following: P=0.926; R=0.849; F1=0.886. A thourough analysis of the feature set shows that, when combined with word lemmas, clusters generated by word2vec are the most valuable features. When trained on the output of the first classifier, the second classifier{'}s performances are the following: p=0.683;r=0.956;f1=0.797. The addition of post-processing rules did not add any significant global improvement but was found to modify the precision/recall ratio."
L16-1570,Text Segmentation of Digitized Clinical Texts,2016,13,1,1,1,5675,cyril grouin,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we present the experiments we made to recover the original page layout structure into two columns from layout damaged digitized files. We designed several CRF-based approaches, either to identify column separator or to classify each token from each line into left or right columns. We achieved our best results with a model trained on homogeneous corpora (only files composed of 2 columns) when classifying each token into left or right columns (overall F-measure of 0.968). Our experiments show it is possible to recover the original layout in columns of digitized documents with results of quality."
L16-1643,Controlled Propagation of Concept Annotations in Textual Corpora,2016,9,0,1,1,5675,cyril grouin,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we presented the annotation propagation tool we designed to be used in conjunction with the BRAT rapid annotation tool. We designed two experiments to annotate a corpus of 60 files, first not using our tool, second using our propagation tool. We evaluated the annotation time and the quality of annotations. We shown that using the annotation propagation tool reduces by 31.7{\%} the time spent to annotate the corpus with a better quality of results."
2016.jeptalnrecital-poster.7,Une cat{\\'e}gorisation de fins de lignes non-supervis{\\'e}e (End-of-line classification with no supervision),2016,-1,-1,2,0,8591,pierre zweigenbaum,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,"Dans certains textes bruts, les marques de fin de ligne peuvent marquer ou pas la fronti{\`e}re d{'}une unit{\'e} textuelle (typiquement un paragraphe). Ce probl{\`e}me risque d{'}influencer les traitements subs{\'e}quents, mais est rarement trait{\'e} dans la litt{\'e}rature. Nous proposons une m{\'e}thode enti{\`e}rement non-supervis{\'e}e pour d{\'e}terminer si une fin de ligne doit {\^e}tre vue comme un simple espace ou comme une v{\'e}ritable fronti{\`e}re d{'}unit{\'e} textuelle, et la testons sur un corpus de comptes rendus m{\'e}dicaux. Cette m{\'e}thode obtient une F-mesure de 0,926 sur un {\'e}chantillon de 24 textes contenant des lignes repli{\'e}es. Appliqu{\'e}e sur un {\'e}chantillon plus grand de textes contenant ou pas des lignes repli{\'e}es, notre m{\'e}thode la plus prudente obtient une F-mesure de 0,898, valeur {\'e}lev{\'e}e pour une m{\'e}thode enti{\`e}rement non-supervis{\'e}e."
W15-2604,Is it possible to recover personal health information from an automatically de-identified corpus of {F}rench {EHR}s?,2015,11,1,1,1,5675,cyril grouin,Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis,0,"De-identification aims at preserving patient confidentiality while enabling the use of clinical documents for furthering medical research. Herein, we aim to evaluate whether patient re-identification is possible on a corpus of de-identified clinical documents in French. Personal Health Identifiers are automatically marked by a de-identification system applied to the corpus, followed by reintroduction of plausible surrogates. The resulting documents are shown to individuals with varying knowledge of the documents and de-identification method. The individuals are asked to re-identify the patients. The amount of information recovered increases with familiarity with the documents and/or de-identification method. Surrogate re-introduction with localization from the same (vs. different) geographical area as the original documents is found more effective. The amount of information recovered was not sufficient to re-identify any of the patients, except when privileged access to the hospital health information system and several documents about the same patient were available."
2015.jeptalnrecital-long.3,Identification de facteurs de risque pour des patients diab{\\'e}tiques {\\`a} partir de comptes-rendus cliniques par des approches hybrides,2015,-1,-1,1,1,5675,cyril grouin,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous pr{\'e}sentons les m{\'e}thodes que nous avons d{\'e}velopp{\'e}es pour analyser des comptes- rendus hospitaliers r{\'e}dig{\'e}s en anglais. L{'}objectif de cette {\'e}tude consiste {\`a} identifier les facteurs de risque de d{\'e}c{\`e}s pour des patients diab{\'e}tiques et {\`a} positionner les {\'e}v{\'e}nements m{\'e}dicaux d{\'e}crits par rapport {\`a} la date de cr{\'e}ation de chaque document. Notre approche repose sur (i) HeidelTime pour identifier les expressions temporelles, (ii) des CRF compl{\'e}t{\'e}s par des r{\`e}gles de post-traitement pour identifier les traitements, les maladies et facteurs de risque, et (iii) des r{\`e}gles pour positionner temporellement chaque {\'e}v{\'e}nement m{\'e}dical. Sur un corpus de 514 documents, nous obtenons une F-mesure globale de 0,8451. Nous observons que l{'}identification des informations directement mentionn{\'e}es dans les documents se r{\'e}v{\`e}le plus performante que l{'}inf{\'e}rence d{'}informations {\`a} partir de r{\'e}sultats de laboratoire."
2015.jeptalnrecital-court.4,{\\'E}tude des verbes introducteurs de noms de m{\\'e}dicaments dans les forums de sant{\\'e},2015,-1,-1,2,1,35053,franccois morlanehondere,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous combinons annotations manuelle et automatique pour identifier les verbes utilis{\'e}s pour introduire un m{\'e}dicament dans les messages sur les forums de sant{\'e}. Cette information est notamment utile pour identifier la relation entre un m{\'e}dicament et un effet secondaire. La mention d{'}un m{\'e}dicament dans un message ne garantit pas que l{'}utilisateur a pris ce traitement mais qu{'}il effectue un retour. Nous montrons ensuite que ces verbes peuvent servir pour extraire automatiquement des variantes de noms de m{\'e}dicaments. Nous estimons que l{'}analyse de ces variantes pourrait permettre de mod{\'e}liser les erreurs faites par les usagers des forums lorsqu{'}ils {\'e}crivent les noms de m{\'e}dicaments, et am{\'e}liorer en cons{\'e}quence les syst{\`e}mes de recherche d{'}information."
2015.jeptalnrecital-court.40,"M{\\'e}dicaments qui soignent, m{\\'e}dicaments qui rendent malades : {\\'e}tude des relations causales pour identifier les effets secondaires",2015,-1,-1,2,1,35053,franccois morlanehondere,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous nous int{\'e}ressons {\`a} la mani{\`e}re dont sont exprim{\'e}s les liens qui existent entre un traitement m{\'e}dical et un effet secondaire. Parce que les patients se tournent en priorit{\'e} vers internet, nous fondons cette {\'e}tude sur un corpus annot{\'e} de messages issus de forums de sant{\'e} en fran{\c{c}}ais. L{'}objectif de ce travail consiste {\`a} mettre en {\'e}vidence des {\'e}l{\'e}ments linguistiques (connecteurs logiques et expressions temporelles) qui pourraient {\^e}tre utiles pour des syst{\`e}mes automatiques de rep{\'e}rage des effets secondaires. Nous observons que les modalit{\'e}s d{'}{\'e}criture sur les forums ne permettent pas de se fonder sur les expressions temporelles. En revanche, les connecteurs logiques semblent utiles pour identifier les effets secondaires."
W14-6301,Automatic Analysis of Scientific and Literary Texts. Presentation and Results of the {DEFT}2014 Text Mining Challenge (Analyse automatique de textes litt{\\'e}raires et scientifiques : pr{\\'e}sentation et r{\\'e}sultats du d{\\'e}fi fouille de texte {DEFT}2014) [in {F}rench],2014,-1,-1,5,0,18582,thierry hamon,TALN-RECITAL 2014 Workshop DEFT 2014 : D{\\'E}fi Fouille de Textes (DEFT 2014 Workshop: Text Mining Challenge),0,None
W14-4907,Optimizing annotation efforts to build reliable annotated corpora for training statistical models,2014,17,5,1,1,5675,cyril grouin,Proceedings of {LAW} {VIII} - The 8th Linguistic Annotation Workshop,0,"Creating high-quality manual annotations on text corpus is time-consuming and often requires the work of experts. In order to explore methods for optimizing annotation efforts, we study three key time burdens of the annotation process: (i) multiple annotations, (ii) consensus annotations, and (iii) careful annotations. Through a series of experiments using a corpus of clinical documents annotated for personally identifiable information written in French, we address each of these aspects and draw conclusions on how to make the most of an annotation effort."
grouin-2014-biomedical,Biomedical entity extraction using machine-learning based approaches,2014,25,1,1,1,5675,cyril grouin,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present the experiments we made to process entities from the biomedical domain. Depending on the task to process, we used two distinct supervised machine-learning techniques: Conditional Random Fields to perform both named entity identification and classification, and Maximum Entropy to classify given entities. Machine-learning approaches outperformed knowledge-based techniques on categories where sufficient annotated data was available. We showed that the use of external features (unsupervised clusters, information from ontology and taxonomy) improved the results significantly."
goryainova-etal-2014-morpho,Morpho-Syntactic Study of Errors from Speech Recognition System,2014,8,2,2,0,39602,maria goryainova,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The study provides an original standpoint of the speech transcription errors by focusing on the morpho-syntactic features of the erroneous chunks and of the surrounding left and right context. The typology concerns the forms, the lemmas and the POS involved in erroneous chunks, and in the surrounding contexts. Comparison with error free contexts are also provided. The study is conducted on French. Morpho-syntactic analysis underlines that three main classes are particularly represented in the erroneous chunks: (i) grammatical words (to, of, the), (ii) auxiliary verbs (has, is), and (iii) modal verbs (should, must). Such items are widely encountered in the ASR outputs as frequent candidates to transcription errors. The analysis of the context points out that some left 3-grams contexts (e.g., repetitions, that is disfluencies, bracketing formulas such as {``}cÂest{''}, etc.) may be better predictors than others. Finally, the surface analysis conducted through a Levensthein distance analysis, highlighted that the most common distance is of 2 characters and mainly involves differences between inflected forms of a unique item."
chatzimina-etal-2014-use,Use of unsupervised word classes for entity recognition: Application to the detection of disorders in clinical reports,2014,25,0,2,0,39606,maria chatzimina,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Unsupervised word classes induced from unannotated text corpora are increasingly used to help tasks addressed by supervised classification, such as standard named entity detection. This paper studies the contribution of unsupervised word classes to a medical entity detection task with two specific objectives: How do unsupervised word classes compare to available knowledge-based semantic classes? Does syntactic information help produce unsupervised word classes with better properties? We design and test two syntax-based methods to produce word classes: one applies the Brown clustering algorithm to syntactic dependencies, the other collects latent categories created by a PCFG-LA parser. When added to non-semantic features, knowledge-based semantic classes gain 7.28 points of F-measure. In the same context, basic unsupervised word classes gain 4.16pt, reaching 60{\%} of the contribution of knowledge-based semantic classes and outperforming Wikipedia, and adding PCFG-LA unsupervised word classes gain one more point at 5.11pt, reaching 70{\%}. Unsupervised word classes could therefore provide a useful semantic back-off in domains where no knowledge-based semantic classes are available. The combination of both knowledge-based and basic unsupervised classes gains 8.33pt. Therefore, unsupervised classes are still useful even when rich knowledge-based classes exist."
deleger-etal-2014-annotation,Annotation of specialized corpora using a comprehensive entity and relation scheme,2014,15,8,3,0,17098,louise deleger,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Annotated corpora are essential resources for many applications in Natural Language Processing. They provide insight on the linguistic and semantic characteristics of the genre and domain covered, and can be used for the training and evaluation of automatic tools. In the biomedical domain, annotated corpora of English texts have become available for several genres and subfields. However, very few similar resources are available for languages other than English. In this paper we present an effort to produce a high-quality corpus of clinical documents in French, annotated with a comprehensive scheme of entities and relations. We present the annotation scheme as well as the results of a pilot annotation study covering 35 clinical documents in a variety of subfields and genres. We show that high inter-annotator agreement can be achieved using a complex annotation scheme."
luzzati-etal-2014-human,Human annotation of {ASR} error regions: Is {``}gravity{''} a sharable concept for human annotators?,2014,12,1,2,0,39857,daniel luzzati,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper is concerned with human assessments of the severity of errors in ASR outputs. We did not design any guidelines so that each annotator involved in the study could consider the {``}seriousness{''} of an ASR error using their own scientific background. Eight human annotators were involved in an annotation task on three distinct corpora, one of the corpora being annotated twice, hiding this annotation in duplicate to the annotators. None of the computed results (inter-annotator agreement, edit distance, majority annotation) allow any strong correlation between the considered criteria and the level of seriousness to be shown, which underlines the difficulty for a human to determine whether a ASR error is serious or not."
W13-2321,Automatic Named Entity Pre-annotation for Out-of-domain Human Annotation,2013,23,3,2,0,5280,sophie rosset,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"Automatic pre-annotation is often used to improve human annotation speed and accuracy. We address here out-of-domain named entity annotation, and examine whether automatic pre-annotation is still beneficial in this setting. Our study design includes two different corpora, three pre-annotation schemes linked to two annotation levels, both expert and novice annotators, a questionnaire-based subjective assessment and a corpus-based quantitative assessment. We observe that preannotation helps in all cases, both for speed and for accuracy, and that the subjective assessment of the annotators does not always match the actual benefits measured in the annotation outcome."
W13-2022,Building A Contrasting Taxa Extractor for Relation Identification from Assertions: {BIO}logical Taxonomy {\\&} Ontology Phrase Extraction System,2013,16,11,1,1,5675,cyril grouin,Proceedings of the {B}io{NLP} Shared Task 2013 Workshop,0,"In this paper, we present the methods we used to extract bacteria and biotopes names and then to identify the relation between those entities while participating to the BioNLPxe2x80x9913 Bacteria and Biotopes Shared Task. We used machine-learning based approaches for this task, namely a CRF to extract bacteria and biotopes names and a simple matching algorithm to predict the relations. We achieved poor results: an SER of 0.66 in sub-task 1, and a 0.06 F-measure in both sub-tasks 2 and 3."
F13-1036,Studying frequency-based approaches to process lexical simplification (Approches {\\`a} base de fr{\\'e}quences pour la simplification lexicale) [in {F}rench],2013,0,0,2,0.618983,864,annelaure ligozat,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
W12-3606,Structured Named Entities in two distinct press corpora: Contemporary Broadcast News and Old Newspapers,2012,18,16,2,0.167724,5280,sophie rosset,Proceedings of the Sixth Linguistic Annotation Workshop,0,"This paper compares the reference annotation of structured named entities in two corpora with different origins and properties. It addresses two questions linked to such a comparison. On the one hand, what specific issues were raised by reusing the same annotation scheme on a corpus that differs from the first in terms of media and that predates it by more than a century? On the other hand, what contrasts were observed in the resulting annotations across the two corpora?"
W12-1101,Indexation libre et contr{\\^o}l{\\'e}e d{'}articles scientifiques. Pr{\\'e}sentation et r{\\'e}sultats du d{\\'e}fi fouille de textes {DEFT}2012 (Controlled and free indexing of scientific papers. Presentation and results of the {DEFT}2012 text-mining challenge) [in {F}rench],2012,-1,-1,4,0,5615,patrick paroubek,"JEP-TALN-RECITAL 2012, Workshop DEFT 2012: D{\\'E}fi Fouille de Textes (DEFT 2012 Workshop: Text Mining Challenge)",0,None
S12-1068,"{ANNLOR}: A Na{\\\\\i}ve Notation-system for Lexical Outputs Ranking""",2012,3,7,2,0.618983,864,annelaure ligozat,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper presents the systems we developed while participating in the first task (English Lexical Simplification) of SemEval 2012. Our first system relies on n-grams frequencies computed from the Simple English Wikipedia version, ranking each substitution term by decreasing frequency of use. We experimented with several other systems, based on term frequencies, or taking into account the context in which each substitution term occurs. On the evaluation corpus, we achieved a 0.465 score with the first system."
galibert-etal-2012-extended,Extended Named Entities Annotation on {OCR}ed Documents: From Corpus Constitution to Evaluation Campaign,2012,16,6,3,1,13778,olivier galibert,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Within the framework of the Quaero project, we proposed a new definition of named entities, based upon an extension of the coverage of named entities as well as the structure of those named entities. In this new definition, the extended named entities we proposed are both hierarchical and compositional. In this paper, we focused on the annotation of a corpus composed of press archives, OCRed from French newspapers of December 1890. We present the methodology we used to produce the corpus and the characteristics of the corpus in terms of named entities annotation. This annotated corpus has been used in an evaluation campaign. We present this evaluation, the metrics we used and the results obtained by the participants."
C12-2079,Manual Corpus Annotation: Giving Meaning to the Evaluation Metrics,2012,15,13,6,0,32781,yann mathet,Proceedings of {COLING} 2012: Posters,0,"Computing inter-annotator agreement measures on a manually annotated corpus is necessary to evaluate the reliability of its annotation. However, the interpretation of the obtained results is recognized as highly arbitrary. We describe in this article a method and a tool that we developed which shuffles a reference annotation according to different error paradigms, thereby creating artificial annotations with controlled errors. Agreement measures are computed on these corpora, and the obtained results are used to model the behavior of these measures and understand their actual meaning."
W11-2840,Handling Outlandish Occurrences: Using Rules and Lexicons for Correcting {NLP} Articles,2011,8,2,3,0,44160,elitza ivanova,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"This article describes the experiments we performed during our participation in the HOO Challenge. We present the adaption we made on two systems, mainly designing new grammatical rules and completing a lexicon. We focused our work on some of the most common errors in the corpus: missing punctuation and inaccurate prepositions. Our best experiment achieved a 0.1097 detection score, a 0.0820 recognition score, and a 0.0557 correction score on the test corpus."
W11-0411,"Proposal for an Extension of Traditional Named Entities: From Guidelines to Evaluation, an Overview",2011,27,36,1,1,5675,cyril grouin,Proceedings of the 5th Linguistic Annotation Workshop,0,"Within the framework of the construction of a fact database, we defined guidelines to extract named entities, using a taxonomy based on an extension of the usual named entities definition. We thus defined new types of entities with broader coverage including substantive-based expressions. These extended named entities are hierarchical (with types and components) and compositional (with recursive type inclusion and metonymy annotation). Human annotators used these guidelines to annotate a 1.3M word broadcast news corpus in French. This article presents the definition and novelty of extended named entity annotation guidelines, the human annotation of a global corpus and of a mini reference corpus, and the evaluation of annotations through the computation of inter-annotator agreements. Finally, we discuss our approach and the computed results, and outline further work."
I11-1058,Structured and Extended Named Entity Evaluation in Automatic Speech Transcriptions,2011,25,23,3,1,13778,olivier galibert,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"The evaluation of named entity recognition (NER) methods is an active field of research. This includes the recognition of named entities in speech transcripts. Evaluating NER systems on automatic speech recognition (ASR) output whereas human reference annotation was prepared on clean manual transcripts raises difficult alignment issues. These issues are emphasized when named entities are structured, as is the case in the Quaero NER challenge organized in 2010. This paper describes the structured named entity definition used in this challenge and presents a method to transfer reference annotations to ASR output. This method was used in the Quaero 2010 evaluation of extended named entity annotation on speech transcripts, whose results are given in the paper."
2011.jeptalnrecital-long.6,Acc{\\`e}s au contenu s{\\'e}mantique en langue de sp{\\'e}cialit{\\'e} : extraction des prescriptions et concepts m{\\'e}dicaux (Accessing the semantic content in a specialized language: extracting prescriptions and medical concepts),2011,-1,-1,1,1,5675,cyril grouin,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Pourtant essentiel pour appr{\'e}hender rapidement et globalement l{'}{\'e}tat de sant{\'e} des patients, l{'}acc{\`e}s aux informations m{\'e}dicales li{\'e}es aux prescriptions m{\'e}dicamenteuses et aux concepts m{\'e}dicaux par les outils informatiques se r{\'e}v{\`e}le particuli{\`e}rement difficile. Ces informations sont en effet g{\'e}n{\'e}ralement r{\'e}dig{\'e}es en texte libre dans les comptes rendus hospitaliers et n{\'e}cessitent le d{\'e}veloppement de techniques d{\'e}di{\'e}es. Cet article pr{\'e}sente les strat{\'e}gies mises en oeuvre pour extraire les prescriptions m{\'e}dicales et les concepts m{\'e}dicaux dans des comptes rendus hospitaliers r{\'e}dig{\'e}s en anglais. Nos syst{\`e}mes, fond{\'e}s sur des approches {\`a} base de r{\`e}gles et d{'}apprentissage automatique, obtiennent une F1-mesure globale de 0,773 dans l{'}extraction des prescriptions m{\'e}dicales et dans le rep{\'e}rage et le typage des concepts m{\'e}dicaux."
2011.jeptalnrecital-demonstration.12,Extraction d{'}informations m{\\'e}dicales au {LIMSI} (Medical information extraction at {LIMSI}),2011,-1,-1,1,1,5675,cyril grouin,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,
paroubek-etal-2010-second,The Second Evaluation Campaign of {PASSAGE} on Parsing of {F}rench,2010,-1,-1,4,0,5615,patrick paroubek,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,None
grappy-etal-2010-corpus,A Corpus for Studying Full Answer Justification,2010,7,6,4,0,42529,arnaud grappy,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Question answering (QA) systems aim at retrieving precise information from a large collection of documents. To be considered as reliable by users, a QA system must provide elements to evaluate the answer. This notion of answer justification can also be useful when developping a QA system in order to give criteria for selecting correct answers. An answer justification can be found in a sentence, a passage made of several consecutive sentences or several passages of a document or several documents. Thus, we are interesting in pinpointing the set of information that allows to verify the correctness of the answer in a candidate passage and the question elements that are missing in this passage. Moreover, the relevant information is often given in texts in a different form from the question form: anaphora, paraphrases, synonyms. In order to have a better idea of the importance of all the phenomena we underlined, and to provide enough examples at the QA developer's disposal to study them, we decided to build an annotated corpus."
W08-1204,Human Judgement as a Parameter in Evaluation Campaigns,2008,7,1,2,0,47756,jeanbaptiste berthelin,Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics,0,"The relevance of human judgment in an evaluation campaign is illustrated here through the DEFT text mining campaigns.n n In a first step, testing a topic for a campaign among a limited number of human evaluators informs us about the feasibility of a task. This information comes from the results obtained by the judges, as well as from their personal impressions after passing the test.n n In a second step, results from individual judges, as well as their pairwise matching, are used in order to adjust the task (choice of a marking scale for DEFT'07 and selection of topical categories for DEFT'08).n n Finally, the mutual comparison of competitors' results, at the end of the evaluation campaign, confirms the choices we made at its starting point, and provides means to redefine the task when we shall launch a future campaign based on the same topic."
grouin-2008-certification,Certification and Cleaning up of a Text Corpus: Towards an Evaluation of the {``}Grammatical{''} Quality of a Corpus,2008,6,2,1,1,5675,cyril grouin,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present in this article the methods we used for obtaining measures to ensure the quality and well-formedness of a text corpus. These measures allow us to determine the compatibility of a corpus with the treatments we want to apply on it. We called this method Âcertification of corpusÂ. These measures are based upon the characteristics required by the linguistic treatments we have to apply on the corpus we want to certify. Since the certification of corpus allows us to highlight the errors present in a text, we developed modules to carry out an automatic correction. By applying these modules, we reduced the number of errors. In consequence, it increases the quality of the corpus making it possible to use a corpus that a first certification would not have admitted."
