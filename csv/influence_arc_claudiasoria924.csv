bartolini-etal-2004-semantic,bartolini-etal-2002-lexicon,1,\N,Missing
bartolini-etal-2004-semantic,C02-2011,0,\N,Missing
bunt-etal-2010-towards,bunt-2006-dimensions,1,\N,Missing
bunt-etal-2010-towards,N09-2050,1,\N,Missing
bunt-etal-2010-towards,W03-0804,1,\N,Missing
calzolari-etal-2006-next,picchi-etal-2004-linguistic,1,\N,Missing
calzolari-etal-2012-lre,calzolari-etal-2010-lrec,1,\N,Missing
calzolari-etal-2012-lre,W11-3312,1,\N,Missing
cattoni-etal-2002-adam,W00-1003,0,\N,Missing
cattoni-etal-2002-adam,W00-1002,1,\N,Missing
cattoni-etal-2002-adam,J96-2004,0,\N,Missing
del-gratta-etal-2008-ufra,W07-1501,0,\N,Missing
del-gratta-etal-2008-ufra,wright-2004-global,0,\N,Missing
gavrilidou-etal-2006-language,J03-3002,0,\N,Missing
gavrilidou-etal-2006-language,calzolari-etal-2004-enabler,1,\N,Missing
gavrilidou-etal-2006-language,erjavec-2004-multext,0,\N,Missing
gavrilidou-etal-2006-language,J03-3001,0,\N,Missing
L16-1401,broeder-etal-2010-data,0,0.0217635,"Missing"
L16-1401,buitelaar-etal-2014-hot,0,0.0231595,"C under analysis are reported in Table 1: even if there has been a decrease since 2010 in the input about resources provided by authors, numbers are still interesting, especially when enriched with information about co-authorship for the visualisation of social networks graphs (see Table 3.). The analysis of coauthorship networks in the field of computational linguistics is not new: thanks to the ACL ANTHOLOGY NETWORK initiative (Radev et al., 2009) bibliographic data about papers’ citations and authors’ collaboration from the ACL Anthology are easy to explore 3 . In a similar vein Saffron 4 (Buitelaar et al., 2014; Bordea et al., 2013; Buitelaar et al., 2013) as a research framework based on text mining and linked data principles is able to perform community detection suggesting domain specific experts. Visualisations are organised around topics automatically extracted. The kind of networks we analyse in this paper are focused on the building blocks of scientific work in the field of computational linguistics, language resources. People can be connected because they jointly worked to write a paper but more significantly they can be connected because they used the same resource or resources with similar"
L16-1401,del-gratta-etal-2014-lre,1,0.445182,"a top-down approach to documenting resources and typically list resources that have reached a high level of maturity - in terms of validation, documentation and clearing of Intellectual Property Rights (IPR) issues. As an alternative to this approach, recent projects have been carried out within the LR community to create open, bottom-up repositories where LRs - even those under development can be duly documented and searched. Such initiatives are for instance the META-SHARE platform (Gavrilidou et al., 2012), the CLARIN VLO (Broeder et al., 2010) and the LRE Map (Calzolari et al., 2012; Del Gratta et al., 2014b; Del Gratta et al., 2014a), with their sets of metadata. In particular, the LREMap was launched as an initiative at LREC 2010 in order to crowdsource reliable and accurate documentation for the largest possible set of resources. Authors submitting to that conference were asked to document the resources they used in their paper, both the resources they created and the ones created by others. This initiative has continued and been extended to other conferences1 , and is now a unique source of information on existing language resources and their use in current research. The work in this paper c"
L16-1401,gavrilidou-etal-2012-meta,1,0.850325,"ELRA, LDC, NICT Universal Catalogue, ACL Data and Code Repository, OLAC, and LT World. These catalogues adopt a top-down approach to documenting resources and typically list resources that have reached a high level of maturity - in terms of validation, documentation and clearing of Intellectual Property Rights (IPR) issues. As an alternative to this approach, recent projects have been carried out within the LR community to create open, bottom-up repositories where LRs - even those under development can be duly documented and searched. Such initiatives are for instance the META-SHARE platform (Gavrilidou et al., 2012), the CLARIN VLO (Broeder et al., 2010) and the LRE Map (Calzolari et al., 2012; Del Gratta et al., 2014b; Del Gratta et al., 2014a), with their sets of metadata. In particular, the LREMap was launched as an initiative at LREC 2010 in order to crowdsource reliable and accurate documentation for the largest possible set of resources. Authors submitting to that conference were asked to document the resources they used in their paper, both the resources they created and the ones created by others. This initiative has continued and been extended to other conferences1 , and is now a unique source o"
L16-1401,soria-etal-2012-flarenet,1,0.845963,"h, where resources, papers and authors are nodes. The analysis of the visual representation of the underlying graph is used to study how the community gathers around LRs and how LRs are used in research. Keywords: language resources, resources documentation, data visualisation 1. Introduction The availability of Language Resources (LRs) - such as corpora, computational lexicons and parsers - is crucial to most NLP technologies. Recent initiatives have monitored the availability of Language Resources for different languages, and highlighted a digital divide between English and other languages (Soria et al., 2012), (Rehm and Uszkoreit, 2012). While the economic potential of English ensures that English LRs are developed and maintained not only in the academic sector but also by commercial players, the involvement of research communities for other languages is much more crucial to ensure that the necessary instruments (both data and tools) are made available for natural language processing purposes. At the same time, production of quality LRs is only the first step; in order to be usable, LRs must also be documented and made available to the community in such a way that they are easy to find and to use."
L18-1656,L16-1518,1,0.783333,"of digital development, which offers a starting point to develop strategies for assessing digital vitality of these languages and overcoming specific difficulties such as, for instance, the lack of official data. Keywords: minority languages, digital survival, electronic communication 1. Background and Motivation In this paper we present the results of the first survey about the actual usage of four European minority languages and the related needs of their speakers in terms of digital opportunities. The survey is part of the work carried out by the Digital Language Diversity Project (DLDP) (Soria et al., 2016)1 , a three-year Erasmus+ project started in September 2015. The goal of the DLDP is to help minority language speakers’ communities in the acquisition of intellectual and practical skills to create, share, and reuse online digital content in their languages. At the same time we want to define general guidelines and best practices for the promotion of minority languages with poor digital representation, a fact that further prevents their usability on digital media and devices. One of the underlying assumptions of the Digital Language Diversity Project is that the sustainability and preservatio"
lenci-etal-2000-opposites,1995.iwpt-1.8,0,\N,Missing
lenci-etal-2000-opposites,W96-0209,0,\N,Missing
lenci-etal-2000-opposites,H91-1005,0,\N,Missing
lenci-etal-2000-opposites,W99-0407,1,\N,Missing
lenci-etal-2000-opposites,H94-1020,0,\N,Missing
P06-2106,francopoulo-etal-2006-lexical,1,0.861995,"Missing"
P06-2106,W03-1905,1,0.81081,"ess ordinal, pronoun, for instance. The classifier phrase is syntactically generated according to a specific pattern. Here are some usages of classifiers and their syntactic patterns. gual conditions and perform operations on lexical entries. Originally, in order to meet expectations placed upon lexicons as critical resources for content processing in the Semantic Web, the MILE syntactic and semantic lexical objects have been formalized in RDF(S), thus providing a web-based means to implement the MILE architecture and allowing for encoding individual lexical entries as instances of the model (Ide et al., 2003; Bertagna et al., 2004b). In the framework of our project, by situating our work in the context of W3C standards and relying on standardized technologies underlying this community, the original RDF schema for ISLE lexical entries has been made compliant to OWL. The whole data model has been formalized in OWL by using Prot´eg´e 3.2 beta and has been extended to cover the morphological component as well (see Figure 2). Prot´eg´e 3.2 beta has been also used as a tool to instantiate the lexical entries of our sample monolingual lexicons, thus ensuring adherence to the model, encoding coherence an"
P06-2106,bel-etal-2000-simple,1,0.877753,"s: to increase the competitive edge of Asian countries, to bring Asian countries to closer to their western counterparts, and to bring more cohesion among Asian countries. To achieve this goal, we have launched a two year project to create a common standard for Asian language resources. The project is comprised of the following four research items. There is a long history of creating a standard for western language resources. The human language technology (HLT) society in Europe has been particularly zealous for the standardization, making a series of attempts such as EAGLES1 , PAROLE/SIMPLE (Lenci et al., 2000), ISLE/MILE (Calzolari et al., 2003) and LIRICS2 . These continuous efforts has been crystallized as activities in ISO-TC37/SC4 which aims to make an international standard for language resources. 2 (4) Evaluation through application classification Figure 1: Relations among research items 1 Introduction 1 (2) Sample lexicons (1) building a description framework of lexical entries (2) building sample lexicons (3) building an upper-layer ontology (4) evaluating the proposed framework through an application Figure 1 illustrates the relations among these research items. Our main aim is the researc"
P06-2106,C94-1091,1,0.485541,"ical operations, which are special lexical entities allowing the user to define multilin3 MILE is based on the experience derived from existing computational lexicons (e.g. LE-PAROLE, SIMPLE, EuroWordNet, etc.). 828 “CL” stands for a classifier. They always follow cardinal numbers in Japanese. Note that different classifiers are used for different nouns. In the above examples, classifier “hiki” is used to count noun “inu (dog)”, while “satsu” for “hon (book)”. The classifier is determined based on the semantic type of the noun. In the Thai language, classifiers are used in various situations (Sornlertlamvanich et al., 1994). The classifier plays an important role in construction with noun to express ordinal, pronoun, for instance. The classifier phrase is syntactically generated according to a specific pattern. Here are some usages of classifiers and their syntactic patterns. gual conditions and perform operations on lexical entries. Originally, in order to meet expectations placed upon lexicons as critical resources for content processing in the Semantic Web, the MILE syntactic and semantic lexical objects have been formalized in RDF(S), thus providing a web-based means to implement the MILE architecture and al"
P06-2106,zhang-etal-2004-distributional,1,0.766907,"the set of postpositions as values of FunctionType instead of conventional function types such as “subj” and “obj”. It might be an user defined data category or language dependent data category. Furthermore, it is preferable to prepare the mapping between Japanese postpositions and conventional function types. This is interesting because it seems more a terminological difference, but the model can be applied also to Japanese. 4 Building sample lexicons 4.1 Swadesh list and basic lexicon The issue involved in defining a basic lexicon for a given language is more complicated than one may think (Zhang et al., 2004). The naive approach of simply taking the most frequent words in a language is flawed in many ways. First, all frequency counts are corpus-based and hence inherit the bias of corpus sampling. For instance, since it is easier to sample written formal texts, words used predominantly in informal contexts are usually underrepresented. Second, frequency of content words is topic-dependent and may vary from corpus to corpus. Last, and most crucially, frequency of a word does not correlate to its conceptual necessity, 4.2 Aligning multilingual lexical entries Since our goal is to build a multilingual"
P06-2106,bertagna-etal-2004-content,1,0.887142,"e morphological, syntactic and semantic layers. Moreover, an intermediate module allows to define mechanisms of linkage and mapping between the syntactic and semantic layers. Within each layer, a basic linguistic information unit is identified; basic units are separated but still interlinked each other across the different layers. Within each of the MLM layers, different types of lexical object are distinguished : fits with as many Asian languages as possible, and contributing to the ISO-TC37/SC4 activities. As a starting point, we employ an existing description framework, the MILE framework (Bertagna et al., 2004a), to describe several lexical entries of several Asian languages. Through building sample lexicons (research item (2)), we will find problems of the existing framework, and extend it so as to fit with Asian languages. In this extension, we need to be careful in keeping consistency with the existing framework. We start with Chinese, Japanese and Thai as target Asian languages and plan to expand the coverage of languages. The research items (2) and (3) also comprise the similar feedback loop. Through building sample lexicons, we refine an upper-layer ontology. An application built in the resea"
P06-2106,Y06-1043,1,\N,Missing
S01-1007,roventini-etal-2000-italwordnet,1,0.832624,"format conversions. A common 1 SI-TAL (&apos;Integrated System for the Automatic Treatment of Language&apos;) is a National Project, coordinated by Antonio Zampolli at the &apos;Consorzio Pis a Ricerche&apos; and involving several research centers in Italy, aiming at developing large linguistic resources and software tools for the Italian written and spoken language processing. See Monternagni et al. (2000a) and Monternagni et al. (2000b). 2 29 conceivable that a system could make use of the syntactic information as well. In the lSST, this was performed manually using the ItalWordNet lexicon (henceforth IWN, see Roventini et al. 2000) as a reference resource (see below for a description). Semantic annotation consisted in assigning to each full word or sequence of words corresponding to a single unit of sense (such as compounds, idioms, etc.) a given sense number (referring to a specific synset) taken from IWN, plus specific features created for the annotation task to account for idioms, compounds and multi-words, figurative uses, evaluative suffixation, foreign words, proper nouns and titles, among the others. From this point of view, the semantic annotation of the corpus enriches the information available in the lexical r"
S01-1007,W00-1903,0,\N,Missing
S01-1007,A00-2006,1,\N,Missing
S01-1007,bel-etal-2000-simple,1,\N,Missing
savas-etal-2010-lmf,vossen-etal-2008-kyoto,1,\N,Missing
savas-etal-2010-lmf,bond-etal-2008-boot,0,\N,Missing
savas-etal-2010-lmf,francopoulo-etal-2006-lexical,1,\N,Missing
savas-etal-2010-lmf,hayashi-ishida-2006-dictionary,1,\N,Missing
savas-etal-2010-lmf,murakami-etal-2010-language,0,\N,Missing
savas-etal-2010-lmf,van-assem-etal-2006-conversion,0,\N,Missing
savas-etal-2010-lmf,W06-1003,1,\N,Missing
savas-etal-2010-lmf,1995.mtsummit-1.17,0,\N,Missing
soria-etal-2002-advanced,bernsen-etal-2002-nite,1,\N,Missing
soria-etal-2006-moving,W01-1507,1,\N,Missing
soria-etal-2006-moving,W03-1905,1,\N,Missing
soria-etal-2006-moving,francopoulo-etal-2006-lexical,1,\N,Missing
soria-etal-2006-moving,bertagna-etal-2004-content,1,\N,Missing
tokunaga-etal-2008-adapting,bel-etal-2000-simple,1,\N,Missing
tokunaga-etal-2008-adapting,P06-2106,1,\N,Missing
tokunaga-etal-2008-adapting,I08-1052,1,\N,Missing
tokunaga-etal-2008-adapting,francopoulo-etal-2006-lexical,1,\N,Missing
W00-1002,bird-etal-2000-atlas,0,\N,Missing
W06-1001,francopoulo-etal-2006-lexical,1,\N,Missing
W06-1001,bertagna-etal-2004-content,1,\N,Missing
W06-1003,huang-etal-2004-sinica,1,0.835312,"“curvatura, svolta, curva” (C). Therefore the procedure will propose a new candidate meronymy relation between the two Italian WordNet synsets (D). Figure 6. Schema of Wordnet Synsets Returned by WN Web Services. The scores returned by the method “GetWeightedSynsetsByIli” are used by our module to calculate the reliability rating for each new proposed relation. 3.3 A Case Study: Cross-fertilization between Italian and Chinese Wordnets. We explore this idea with a case-study involving the ItalianWordNet (Roventini et al., 2003) and the Academia Sinica Bilingual Ontological Wordnet (Sinica BOW, Huang et al., 2004). The BOW integrates three resources: WordNet, English-Chinese Translation Equivalents Database (ECTED), and SUMO (Suggested Upper Merged Ontology). With the integration of these three key resources, Sinica BOW functions both as an English-Chinese bilingual wordnet and a bilingual lexical access to SUMO. Sinica Bow currently has two bilingual versions, corresponding to WordNet 1.6. and 1.7. Based on these bootstrapped versions, a Chinese Wordnet (CWN, Huang et al. 2005) is under construction with handcrafted senses and lexical semantic relations. For the current experiment, we have used the ve"
W06-1003,kemps-snijders-etal-2006-lexus,0,0.0289533,"n guage away from where the language is spoken. Lastly, the vast range of diversity of languages also makes it impossible to have one single universal centralized resource, or even a centralized repository of resources. Although the paradigm of distributed and interoperable lexical resources has largely been discussed and invoked, very little has been made in comparison for the development of new methods and techniques for its practical realization. Some initial steps are made to design frameworks enabling inter-lexica access, search, integration and operability. An example is the Lexus tool (Kemps-Snijders et al., 2006), based on the Lexical Markup Framework (Romary et al., 2006), that goes in the direction of managing the exchange of data among large-scale lexical resources. A similar tool, but more tailored to the collaborative creation of lexicons for endangered language, is SHAWEL (Gulrajani and Harrison, 2002). However, the general impression is that little has been made towards the development of new methods and techniques for attaining a concrete interoperability among lexical resources. Admittedly, this is a long-term scenario requiring the contribution of many different actors and initiatives (among"
W06-1003,O05-5001,1,\N,Missing
W09-3421,francopoulo-etal-2006-lexical,1,0.857972,"Missing"
W09-3421,bel-etal-2000-simple,1,0.763962,"the advantages of corpusbased approaches is that the techniques used are less language specific than classical rulebased approaches where a human analyses the behaviour of target languages and constructs rules manually. This naturally led the way for international resource standardisation, and indeed there is a long standing precedent in the West for it. The Human Language Technology (HLT) society in Europe has been particularly zealous in this regard, propelling the creation of resource interoperability through a series of initiatives, namely EAGLES (Sanfilippo et al., 1999), PAROLE/SIMPLE (Lenci et al., 2000), ISLE/MILE (Ide et al., 2003), and LIRICS1 . These 1 • Based on existing description frameworks, each research member tries to describe several lexical entries and find problems with them. • Through periodical meetings, we exchange information about problems found and generalise them to propose solutions. • Through an implementation of an application system, we verify the effectiveness of the proposed framework. Below we summarise our significant contribution to an International Standard (ISO24613; Lexical Markup Framework: LMF). 1st year After considering many characteristics of Asian langua"
W09-3421,W03-1905,1,0.826021,"pproaches is that the techniques used are less language specific than classical rulebased approaches where a human analyses the behaviour of target languages and constructs rules manually. This naturally led the way for international resource standardisation, and indeed there is a long standing precedent in the West for it. The Human Language Technology (HLT) society in Europe has been particularly zealous in this regard, propelling the creation of resource interoperability through a series of initiatives, namely EAGLES (Sanfilippo et al., 1999), PAROLE/SIMPLE (Lenci et al., 2000), ISLE/MILE (Ide et al., 2003), and LIRICS1 . These 1 • Based on existing description frameworks, each research member tries to describe several lexical entries and find problems with them. • Through periodical meetings, we exchange information about problems found and generalise them to propose solutions. • Through an implementation of an application system, we verify the effectiveness of the proposed framework. Below we summarise our significant contribution to an International Standard (ISO24613; Lexical Markup Framework: LMF). 1st year After considering many characteristics of Asian languages, we elucidated the shortco"
W09-3421,P06-2106,1,0.822025,"Missing"
W09-3421,tokunaga-etal-2008-adapting,1,0.730656,"Missing"
W09-3421,W06-1001,1,\N,Missing
W99-0407,1995.iwpt-1.8,0,0.0809344,"representations. It is then crucial to make it sure that constituencybased representations, or any other variants thereof, be mappable onto the functional reference annotation recta-scheme. The same point is convincingly argued for by Lin (1998), who also provides an algorithm for mapping a constituency-based representation onto a dependency-based format. To show that the requirement of intertranslatability is satisfied by FAME, we consider here four different analyses for the sentence John tried to open the window together with their translation equivalent in the FAME format: 1. ANLT Parser (Briscoe & Carroll, 1995) - traditional PSG representation: (Tp (V2 (N2 (Ni (NO John_NPl))) (VI (VO tried_VVD) (VI (YO to_T0) (Vl (VO open_VV0) (N2 (DT the_AT)(NI (NO window_NNl)) )))))). F A M E equivalent: subj ( t r y , John) arg (try, open. &lt;introducer=""to"">) dobj (open, window) 2. Fast Partial Parser (Grefenstette, 1994): SUBJ ( t r y , John) DOBJ (open, window) SUBJ (open, John) MODIF (open, try). FAME equivalent: subj (try, John) dobj (open, window) subj (open, John) mod(open, try) 3. Finite State Constraint G r a m m a r Parser (Karlsson et al., 1995): John N SUBJ tried V MVMAINC"" to INFMARK open V_INF MV OBJ"""
W99-0407,W96-0209,0,0.0629999,"6). By assuming that all levels are, in a sense, primitive, rather than some of them being derivative of others, one provides considerable leeway for radically different definitions of functional relations to be cast into a common, albeit redundant, core of required infor•mation. We will return to this point in section 3 of the paper. To be more concrete, a binary functional relationship can be represented formally as consisting of the following types of information: • it is comparatively easy and ""fair"" to evaluate since it overcomes some of the shortcomings of constituency-based evaluation (Carroll and Briscoe, 1996; Carroll et al., 1998; Sampson, 1998; Lin, 1998); • it represents a very informative ""lowest common ground"" of a variety of different syntactic annotation schemes (Lin, 1998); • it is naturally multi-lingual, as functional relations probably represent the most significant level of syntactic analysis at which crosslanguage comparability makes sense; • it permits joint evaluation of systems dealing with both spoken and written language. Spoken data are typically fraught with cases of disfluency, anacoluthon, syntactic incompleteness and any sort of non-canonical syntactic structure (Antoine, 19"
W99-0407,H94-1020,0,0.21444,"Missing"
W99-0407,H91-1005,0,0.382317,"on and recall are to be gauged jointly relative to all such levels. To be concrete, let us first show a full version of the FAME standard representation for the sentence John tried to open the window (cf. Section 2.2): i. ( t r y , John) 44 i i . &lt;try,John> i i i . subj adaptation to different domains and different languages. Nonetheless, the formalisms used for syntax and semantics must have a certain degree of similarity and some additional knowledge about the relationships between syntax and semantics is necessary. An example is provided by what has been done in the ESPRIT SUNDIAL project (Peckam, 1991), where Syntax is defined using a dependency grammar augmented with morphological agreement rules; Semantics is declared through case frames (Fillmore, 1968; Fillmore, 1985) using a conceptual graph formalism. An additional bulk of knowledge, called mapping knowledge, specifies possible links between the symbols of the dependency grammar and the concepts of case frames. In this way syntactic and semantic controls are performed at the same time, avoiding the generation of parse trees that must afterwards be validated semantically. The FAME meta-scheme fits in comparatively well with this approa"
