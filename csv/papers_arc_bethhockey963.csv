W09-2607,Using Artificially Generated Data to Evaluate Statistical Machine Translation,2009,16,2,4,0,11421,manny rayner,Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks ({GEAF} 2009),0,"Although Statistical Machine Translation (SMT) is now the dominant paradigm within Machine Translation, we argue that it is far from clear that it can outperform Rule-Based Machine Translation (RBMT) on small- to medium-vocabulary applications where high precision is more important than recall. A particularly important practical example is medical speech translation. We report the results of experiments where we configured the various grammars and rule-sets in an Open Source medium-vocabulary multi-lingual medical speech translation system to generate large aligned bilingual corpora for English xe2x86x92 French and English xe2x86x92 Japanese, which were then used to train SMT models based on the common combination of Giza, Moses and SRILM. The resulting SMTs were unable fully to reproduce the performance of the RBMT, with performance topping out, even for English xe2x86x92 French, with less than 70% of the SMT translations of previously unseen sentences agreeing with RBMT translations. When the outputs of the two systems differed, human judges reported the SMT result as frequently being worse than the RBMT result, and hardly ever better; moreover, the added robustness of the SMT only yielded a small improvement in recall, with a large penalty in precision."
W09-1503,Using Paraphrases of Deep Semantic Representions to Support Regression Testing in Spoken Dialogue Systems,2009,15,2,1,1,46954,beth hockey,"Proceedings of the Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing ({SETQA}-{NLP} 2009)",0,"Rule-based spoken dialogue systems require a good regression testing framework if they are to be maintainable. We argue that there is a tension between two extreme positions when constructing the database of test examples. On the one hand, if the examples consist of input/output tuples representing many levels of internal processing, they are fine-grained enough to catch most processing errors, but unstable under most system modifications. If the examples are pairs of user input and final system output, they are much more stable, but too coarse-grained to catch many errors. In either case, there are fairly severe difficulties in judging examples correctly. We claim that a good compromise can be reached by implementing a paraphrasing mechanism which maps internal semantic representations into surface forms, and carrying out regression testing using paraphrases of semantic forms rather than the semantic forms themselves. We describe an implementation of the idea using the Open Source Regulus toolkit, where paraphrases are produced using Regulus grammars compiled in generation mode. Paraphrases can also be used at run-time to produce confirmations. By compiling the paraphrase grammar a second time, as a recogniser, it is possible in a simple and natural way to guarantee that confirmations are always within system coverage."
W08-1506,The 2008 {M}ed{SLT} System,2008,7,0,6,0,11421,manny rayner,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,"MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo three different versions of the system: an anyto-any multilingual version involving the languages Japanese, English, French and Arabic, a bidirectional English $ Spanish version, and a mobile version running on a hand-held PDA. We will also demo the Regulus development environment, focussing on features which support rapid prototyping of grammar-based speech translation systems."
W08-1511,A Small-Vocabulary Shared Task for Medical Speech Translation,2008,0,5,6,0,11421,manny rayner,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,We outline a possible small-vocabulary shared task for the emerging medical speech translation community. Data would consist of about 2000 recorded and transcribed utterances collected during an evaluation of an English
W08-0210,Zero to Spoken Dialogue System in One Quarter: Teaching Computational Linguistics to Linguists Using Regulus,2008,8,2,1,1,46954,beth hockey,Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics,0,"This paper describes a Computational Linguistics course designed for Linguistics students. The course is structured around the architecture of a Spoken Dialogue System and makes extensive use of the dialogue system tools and examples available in the Regulus Open Source Project. Although only a quarter long course, students learn Computational Linguistics and programming sufficient to build their own Spoken Dialogue System as a course project."
bouillon-etal-2008-developing,Developing Non-{E}uropean Translation Pairs in a Medium-Vocabulary Medical Speech Translation System,2008,10,9,8,0,2866,pierrette bouillon,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We describe recent work on MedSLT, a medium-vocabulary interlingua-based medical speech translation system, focussing on issues that arise when handling languages of which the grammar engineer has little or no knowledge. We show how we can systematically create and maintain multiple forms of grammars, lexica and interlingual representations, with some versions being used by language informants, and some by grammar engineers. In particular, we describe the advantages of structuring the interlingua definition as a simple semantic grammar, which includes a human-readable surface form. We show how this allows us to rationalise the process of evaluating translations between languages lacking common speakers, and also makes it possible to create a simple generic tool for debugging to-interlingua translation rules. Examples presented focus on the concrete case of translation between Japanese and Arabic in both directions."
C08-1090,Almost Flat Functional Semantics for Speech Translation,2008,10,6,3,0,11421,manny rayner,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"We introduce a novel semantic representation formalism, Almost Flat Functional semantics (AFF), which is designed as an intelligent compromise between linguistically motivated predicate/argument semantics and ad hoc engineering solutions based on flat feature/value lists; the central idea is to tag each semantic element with the functional marking which most closely surrounds it. We argue that AFF is well-suited for medium-vocabulary speech translation applications, and describe simple and general algorithms for parsing, generating and performing transfer using AFF representations. The formalism has been fully implemented within a medium-vocabulary interlingua-based Open Source speech translation system which translates between English, French, Japanese and Arabic."
W07-1806,A Bidirectional Grammar-Based Medical Speech Translator,2007,19,13,8,0,2866,pierrette bouillon,Proceedings of the Workshop on Grammar-Based Approaches to Spoken Language Processing,0,"We describe a bidirectional version of the grammar-based MedSLT medical speech system. The system supports simple medical examination dialogues about throat pain between an English-speaking physician and a Spanish-speaking patient. The physician's side of the dialogue is assumed to consist mostly of WH-questions, and the patient's of elliptical answers. The paper focusses on the grammar-based speech processing architecture, the ellipsis resolution mechanism, and the online help system."
W07-0806,Adapting a Medical speech to speech translation system ({M}ed{SLT}) to {A}rabic,2007,8,3,4,0,2866,pierrette bouillon,Proceedings of the 2007 Workshop on Computational Approaches to {S}emitic Languages: Common Issues and Resources,0,"We describe the adaptation for Arabic of the grammar-based MedSLT medical speech system. The system supports simple medical diagnosis questions about headaches using vocabulary of 322 words. We show that the MedSLT architecture based on motivated general grammars produces very good results, with a limited effort. Based on the grammars for other languages covered by the system, it is in fact very easy to develop an Arabic grammar and to specialize it efficiently for the different system tasks. In this paper, we focus on generation."
W06-3702,Evaluating Task Performance for a Unidirectional Controlled Language Medical Speech Translation System,2006,10,17,6,1,48239,nikos chatzichrisafis,Proceedings of the First International Workshop on Medical Speech Translation,0,"We present a task-level evaluation of the French to English version of MedSLT, a medium-vocabulary unidirectional controlled language medical speech translation system designed for doctor-patient diagnosis interviews. Our main goal was to establish task performance levels of novice users and compare them to expert users. Tests were carried out on eight medical students with no previous exposure to the system, with each student using the system for a total of three sessions. By the end of the third session, all the students were able to use the system confidently, with an average task completion time of about 4 minutes."
W06-3707,{M}ed{SLT}: A Limited-Domain Unidirectional Grammar-Based Medical Speech Translator,2006,7,3,6,0,11421,manny rayner,Proceedings of the First International Workshop on Medical Speech Translation,0,"MedSLT is a unidirectional medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different language pairs and subdomains. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora."
rayner-etal-2006-regulus,{REGULUS}: A Generic Multilingual Open Source Platform for Grammar-Based Speech Applications,2006,13,3,3,0,11421,manny rayner,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We present an overview of Regulus, an Open Source platform that supports corpus-based derivation of efficient domain-specific speech recognisers from general linguistically motivated unification grammars. We list available Open Source resources, which include compilers, resource grammars for various languages, documentation and a development environment. The greater part of the paper presents a series of experiments carried out using a medium-vocabulary medical speech translation application and a corpus of 801 recorded domain utterances, designed to investigate the impact on speech understanding performance of vocabulary size, grammatical coverage, presence or absence of various linguistic features, degree of generality of thegrammar and use or otherwise of probabilistic weighting in the CFGlanguage model. In terms of task accuracy, the most significant factors were the use of probabilistic weighting, the degree of generality of the grammar and the inclusion of features which model sortal restrictions."
P05-3008,A Voice Enabled Procedure Browser for the International Space Station,2005,6,17,2,0,11421,manny rayner,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"Clarissa, an experimental voice enabled procedure browser that has recently been deployed on the International Space Station (ISS), is to the best of our knowledge the first spoken dialog system in space. This paper gives background on the system and the ISS procedures, then discusses the research developed to address three key problems: grammar-based speech recognition using the Regulus toolkit; SVM based methods for open microphone speech recognition; and robust side-effect free dialogue management for handling undos, corrections and confirmations."
H05-2014,{J}apanese Speech Understanding using Grammar Specialization,2005,6,5,7,0,11421,manny rayner,Proceedings of {HLT}/{EMNLP} 2005 Interactive Demonstrations,0,"The most common speech understanding architecture for spoken dialogue systems is a combination of speech recognition based on a class N-gram language model, and robust parsing. For many types of applications, however, grammar-based recognition can offer concrete advantages. Training a good class N-gram language model requires substantial quantities of corpus data, which is generally not available at the start of a new project. Head-to-head comparisons of class N-gram/robust and grammar-based systems also suggest that users who are familiar with system coverage get better results from grammar-based architectures (Knight et al., 2001). As a consequence, deployed spoken dialogue systems for real-world applications frequently use grammar-based methods. This is particularly the case for speech translation systems. Although leading research systems like Verbmobil and NE-SPOLE! (Wahlster, 2000; Lavie et al., 2001) usually employ complex architectures combining statistical and rule-based methods, successful practical examples like Phraselator and S-MINDS (Phraselator, 2005; Sehda, 2005) are typically phrasal translators with grammar-based recognizers."
2005.mtsummit-papers.25,Practicing Controlled Language through a Help System integrated into the Medical Speech Translation System ({M}ed{SLT}),2005,9,13,6,0.833333,37884,marianne starlander,Proceedings of Machine Translation Summit X: Papers,0,"In this paper, we present evidence that providing users of a speech to speech translation system for emergency diagnosis (MedSLT) with a tool that helps them to learn the coverage greatly improves their success in using the system. In MedSLT, the system uses a grammar-based recogniser that provides more predictable results to the translation component. The help module aims at addressing the lack of robustness inherent in this type of approach. It takes as input the result of a robust statistical recogniser that performs better for out-of-coverage data and produces a list of in-coverage example sentences. These examples are selected from a defined list using a heuristic that prioritises sentences maximising the number of N-grams shared with those extracted from the recognition result."
2005.eamt-1.8,A generic multi-lingual open source platform for limited-domain medical speech translation,2005,9,42,4,0.445703,2866,pierrette bouillon,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"We present an overview of MedSLT, an Open Source platform for developing limited-domain medical speech translation systems. We focus in particular on the speech understanding architecture, which uses grammar-based language models derived using cor- pus-based specialisation methods from a single linguistically motivated grammar, and summarise the results of two evaluations which investigate the appropriateness of these de- sign choices. Other sections describe the interlingua and its relationship with the recogni- tion architecture, and the current demo system."
2004.tmi-1.3,Comparing rule-based and statistical approaches to speech understanding in a limited domain speech translation system,2004,14,15,3,0,11421,manny rayner,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"The paper directly compares two versions of a medical speech translation system, one with a grammar based language model (GLM) recognizer and the other with a statistical language model (SLM) recognizer. We construct the GLM using a corpus-based method, so that both the GLM and the SLM can be derived from the same corpus; evaluation is carried out with respect to performance on the speech translation task. Despite using a very small training set for both the GLM and the SLM, the SLM delivers much better word error rates on unseen test material. Nonetheless, evaluating both systems on translation performance rather than word error rates, the GLM-based version of the system outperforms the SLM on the actual translation task."
W03-2125,"A procedure assistant for astronauts in a functional programming architecture, with step previewing and spoken correction of dialogue moves",2003,3,0,4,0,43381,gregory aist,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,"We present a demonstration of a prototype system aimed at providing support with procedural tasks for astronauts on board the International Space Station. Current functionality includes navigation within the procedure, previewing steps, requesting a list of images or a particular image, recording voice notes and spoken alarms, setting parameters such as audio volume. Dialogue capabilities include handling spoken corrections for an entire dialogue move, reestablishing context in response to a user request, responding to user barge-in, and help on demand. The current system has been partially reimplemented for better efficiency and in response to feedback from astronauts and astronaut training personnel. Added features include visual and spoken step previewing, and spoken correction of dialogue moves. The intention is to introduce the system into astronaut training as a prelude to flight on board the International Space Station."
P03-2024,A Limited-Domain {E}nglish to {J}apanese Medical Speech Translator Built Using {REGULUS} 2,2003,5,12,6,0,11421,manny rayner,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"We argue that verbal patient diagnosis is a promising application for limited-domain speech translation, and describe an architecture designed for this type of task which represents a compromise between principled linguistics-based processing on the one hand and efficient phrasal translation on the other. We propose to demonstrate a prototype system instantiating this architecture, which has been built on top of the Open Source REGULUS 2 platform. The prototype translates spoken yes-no questions about headache symptoms from English to Japanese, using a vocabulary of about 200 words."
P03-2038,An Intelligent Procedure Assistant Built Using {REGULUS} 2 and {ALTERF},2003,7,8,2,0,11421,manny rayner,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"We will demonstrate the latest version of an ongoing project to create an intelligent procedure assistant for use by astronauts on the International Space Station (ISS). The system functionality includes spoken dialogue control of navigation, coordinated display of the procedure text, display of related pictures, alarms, and recording and playback of voice notes. The demo also exemplifies several interesting component technologies. Speech recognition and language understanding have been developed using the Open Source REGULUS 2 toolkit. This implements an approach to portable grammar-based language modelling in which all models are derived from a single linguistically motivated unification grammar. Domain-specific CFG language models are produced by first specialising the grammar using an automatic corpus-based method, and then compiling the resulting specialised grammars into CFG form. Translation between language centered and domain centered semantic representations is carried out by ALTERF, another Open Source toolkit, which combines rule-based and corpus-based processing in a transparent way."
E03-2010,An Open-Source Environment for Compiling Typed Unification Grammars into Speech Recognisers,2003,10,21,2,0,11421,manny rayner,Demonstrations,0,"We present REGULUS, an Open Source environment which compiles typed unification grammars into context free grammar language models compatible with the Nuance Toolkit. The environment includes a large general unification grammar of English and corpus-based tools for creating efficient domain-specific recognisers from it. We will demo applications built using the system, including a speech translator and a command and control system for a simulated robotic domain, and show how the development environment can be used to edit and extend them."
E03-1075,Targeted Help for Spoken Dialogue Systems,2003,3,4,1,1,46954,beth hockey,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
E03-1078,Transparent combination of rule-based and data-driven approaches in speech understanding,2003,0,5,2,0,11421,manny rayner,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
P01-1022,Practical Issues in Compiling Typed Unification Grammars for Speech Recognition,2001,20,21,2,0.318418,46824,john dowding,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"Current alternatives for language modeling are statistical techniques based on large amounts of training data, and hand-crafted context-free or finite-state grammars that are difficult to build and maintain. One way to address the problems of the grammar-based approach is to compile recognition grammars from grammars written in a more expressive formalism. While theoretically straight-forward, the compilation process can exceed memory and time bounds, and might not always result in accurate and efficient speech recognition. We will describe and evaluate two approaches to this compilation problem. We will also describe and evaluate additional techniques to reduce the structural ambiguity of the language model."
N01-1030,Do {CFG}-Based Language Models Need Agreement Constraints?,2001,10,7,3,0.26422,11421,manny rayner,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Many people are now routinely building grammar-based language models for interactive spoken language applications; these language models are typically ad hoc semantic grammars which ignore many standard linguistic constraints, in particular grammatical agreement. We describe a series of experiments in which we took three CFG-based language models from non-trivial implemented systems, and in each case contrasted the performance of a version which included agreement constraints against a version which ignored them. Our findings suggest that inclusion of agreement constraints significantly improves performance in terms of both word error rate and semantic error rate."
W00-2026,A comparison of the {XTAG} and {CLE} Grammars for {E}nglish,2000,6,0,2,0.528439,11421,manny rayner,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,"When people develop something intended as a large broad-coverage grammar, they usually have a more specific goal in mind. Sometimes this goal is covering a corpus; sometimes the developers have theoretical ideas they wish to investigate; most often, work is driven by a combination of these two main types of goal. What tends to happen after a while is that the community of people working with the grammar starts thinking of some phenomena as xe2x80x9ccentralxe2x80x9d, and makes serious efforts to deal with them; other phenomena are labelled xe2x80x9cmarginalxe2x80x9d, and ignored. Before long, the distinction between xe2x80x9ccentralxe2x80x9d and xe2x80x9cmarginalxe2x80x9d becomes so ingrained that it is automatic, and people virtually stop thinking about the xe2x80x9cmarginalxe2x80x9d phenomena. In practice, the only way to bring the marginal things back into focus is to look at what other people are doing and compare it with onexe2x80x99s own work. In this paper, we will take two large grammars, XTAG and CLE, and examine each of them from the otherxe2x80x99s point of view. We will find in both cases not only that important things are missing, but that the perspective offered by the other grammar suggests simple and practical ways of filling in the holes. It turns out that there is a pleasing symmetry to the picture. XTAG has a very good treatment of complement structure, which the CLE to some extent lacks; conversely, the CLE offers a powerful and general account of adjuncts, which the XTAG grammar does not fully duplicate. If we examine the way in which each grammar does the thing it is good at, we find that the relevant methods are quite easy to port to the other framework, and in fact only involve generalization and systematization of existing mechanisms. The paper is structured as follows. Section 2 presents a very brief overview of the CLE and XTAG grammars. In Section 3, we describe the CLE grammar from the XTAG grammarxe2x80x99s point of view, following which Section 4 describes the XTAG grammar from a CLE perspective. Section 5 concludes."
W00-0311,A Compact Architecture for Dialogue Management Based on Scripts and Meta-Outputs,2000,12,0,2,0.528439,11421,manny rayner,ANLP-NAACL 2000 Workshop: Conversational Systems,0,"We describe an architecture for spoken dialogue interfaces to semi-autonomous systems that transforms speech signals through successive representations of linguistic, dialogue, and domain knowledge. Each step produces an output, and a meta-output describing the transformation, with an executable program in a simple scripting language as the final result. The output/meta-output distinction permits perspicuous treatment of diverse tasks such as resolving pronouns, correcting user misconceptions, and optimizing scripts."
C00-2097,Compiling Language Models from a Linguistically Motivated Unification Grammar,2000,8,11,2,0.528439,11421,manny rayner,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"Systems now exist which are able to compile unification grammars into language models that can be included in a speech recognizer, but it is so far unclear whether non-trivial linguistically principled grammars can be used for this purpose. We describe a series of experiments which investigate the question empirically, by incrementally constructing a grammar and discovering what problems emerge when successively larger versions are compiled into finite state graph representations and used as language models for a medium-vocabulary recognition task."
A00-1016,A Compact Architecture for Dialogue Management Based on Scripts and Meta-Outputs,2000,12,0,2,0.528439,11421,manny rayner,Sixth Applied Natural Language Processing Conference,0,"We describe an architecture for spoken dialogue interfaces to semi-autonomous systems that transforms speech signals through successive representations of linguistic, dialogue, and domain knowledge. Each step produces an output, and a meta-output describing the transformation, with an executable program in a simple scripting language as the final result. The output/meta-output distinction permits perspicuous treatment of diverse tasks such as resolving pronouns, correcting user misconceptions, and optimizing scripts."
W97-1505,Maintaining the Forest and Burning out the Underbrush in {XTAG},1997,10,7,2,0,42791,christine doran,Computational Environments for Grammar Development and Linguistic Engineering,0,None
C94-2149,{XTAG} System - A Wide Coverage Grammar for {E}nglish,1994,11,73,3,0,45863,christy doran,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper present the XTAG system, a grammar development tool based on the Tree Adjoining Grammar (TAG) formalism that includes a wide-coverage syntactic grammar for English. The various components of the system are discussed and preliminary evaluation results from the parsing of various corpora are given. Results from the comparison of XTAG against the IBM statistical parser and the Alvey Natural Language Tool parser are also given."
