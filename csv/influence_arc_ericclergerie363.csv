2000.iwpt-1.6,E99-1020,1,0.881251,"Missing"
2000.iwpt-1.6,W98-0111,1,0.834384,", 'Y, i, j I B , p , q] and represent one of the following types of [derivation: ⇒ • A['Y] ai+ I . . . ap B[ ] aq+ l . .. aj if and only if (B , p, q) -:/ ( -, -, -), B[ ] is a dependent descendent of A['Y] and (p, q) ::; ( i, j). • A[ ] ⇒ ai+ l . . . aj if and only if 'Y = - and (B , p, q) = ( - , - , - ) . where - means that the value of a component is not bound and (p, q) ::; (i, j) is used to represent that i ::; p ::; q ::; j when p and q are bound. These items are like those proposed for the tabulation of linear indexed automata [10] and for the tabulation of bottom-up 2-stack automata [6] . They are1 slightly different from the items of the form [A, 'Y, i, j I B, 'TJ, P, q] proposed by Vijay-Shanker and Weir in [16] for their CYK-like algorithm, where the element 'T/ E Vi is redundant : due to the context-freeness property of LIG we have that if A[,y] ai+I . . . ap B[ ] aq+ l . . . aj then for any /3 we have that A[,8,y] ai+ l . . . ap B[,8] aq+ l . . . aj. ⇒ ⇒ Schema 1 The parsing system lP CYK corresponding to the bYK-like parsing algorithm for a linear indexed grammar g and a input string a 1 • • • an is defined as follows: LCYK = { [A , ,y, i, j I B , p , q] I A , B E VN,"
2000.iwpt-1.6,C92-2066,0,0.022677,"ndexed grammars associate a stack of indices with each non-terminal symbol, with the restriction that the indices stack of the head non-terminal of each pro duction (the father) can be inherited by at most one body non-terminal (the dependent child) while the other stacks must have a bounded stack size . Several parsing algorithms have been proposed for TAG, ranging from simple bottom-up algorithms, like CYK (17], to sophisticated extensions of the Earley 's algorithm [9]. In order to improve efficiency, it is usual to translate the source tree adjoining grammar into a linear indexed grammar [16, 12, 13, 17] . However, in some cases is not possible to translate the parsing strategy from TAG to LIG, as there are parsing strategies for TAG which are not incorporated in any parsing algorithm for LIG. To eliminate this drawback, we present in this paper several parsing algorithms for LIG which mimic the most popular parsing strategies for TAG [1 ] . 1 .1 Linear Indexed Grammars A linear indexed grammar is a tuple (Vr, VN, Vi, P, S) , where Vr is a finite set of terminals, VN a finite set of non-terminals, Vi is a finite set of indices, S E VN is the start symbol and P is a finite set of productions ."
2000.iwpt-1.6,J94-1004,0,0.0220035,"ndexed grammars associate a stack of indices with each non-terminal symbol, with the restriction that the indices stack of the head non-terminal of each pro duction (the father) can be inherited by at most one body non-terminal (the dependent child) while the other stacks must have a bounded stack size . Several parsing algorithms have been proposed for TAG, ranging from simple bottom-up algorithms, like CYK (17], to sophisticated extensions of the Earley 's algorithm [9]. In order to improve efficiency, it is usual to translate the source tree adjoining grammar into a linear indexed grammar [16, 12, 13, 17] . However, in some cases is not possible to translate the parsing strategy from TAG to LIG, as there are parsing strategies for TAG which are not incorporated in any parsing algorithm for LIG. To eliminate this drawback, we present in this paper several parsing algorithms for LIG which mimic the most popular parsing strategies for TAG [1 ] . 1 .1 Linear Indexed Grammars A linear indexed grammar is a tuple (Vr, VN, Vi, P, S) , where Vr is a finite set of terminals, VN a finite set of non-terminals, Vi is a finite set of indices, S E VN is the start symbol and P is a finite set of productions ."
2001.jeptalnrecital-long.4,W00-2003,1,0.894322,"Missing"
2001.jeptalnrecital-long.4,P01-1007,1,0.874644,"Missing"
2001.jeptalnrecital-long.4,bonhomme-lopez-2000-resources,0,0.0285816,"de lisibilité et de spécifications explicites. Nous avons de plus rencontré différentes variantes de XTAG. Enfin, certaines des grammaires étudiées présentent des problèmes de cohérence, dûs peut-être à un manque d’outils pour la gestion et le développement des TAG. Nous avons donc été amenés à examiner le langage de définition des TAG et à réfléchir à des outils permettant d’exploiter une représentation standardisée. Suivant d’autres, dont le groupe 1 http://www.cis.upenn.edu/~xtag/ F. Barthélemy, P. Boullier, P. Deschamp, L. Kaouane et É. V. de la Clergerie LT XML2 et plus particulièrement [Bonhomme and Lopez, 2000], nous avons conclu que le langage de balisage XML3 est un choix judicieux pour représenter les TAG. En premier lieu, l’utilisation de DTD permet d’exprimer clairement la structure logique des grammaires. Ensuite, le format XML est purement textuel, ce qui permet un échange facile de ressources linguistiques entre environnements hétérogènes ainsi qu’une lecture immédiate par un humain. Enfin, l’ensemble des outils pour le traitement de documents XML croît très rapidement. Partant de l’emploi de XML pour les grammaires, nous nous sommes aussi rendu compte de son intérêt pour stocker des résult"
2001.jeptalnrecital-long.4,W98-0105,1,0.678343,"2001]. En particulier, nous avons testé deux schémas de tabulation, ainsi que deux stratégies d’analyse, à savoir une stratégie strictement descendante vérifiant la propriété de validité des préfixes et une stratégie hybride descendante avec vérification ascendante des traits. La seconde approche utilise les grammaires à concaténation d’intervalles (Range Concatenation Grammars – RCG) pour lesquelles nous construisons des analyseurs très efficaces [Boullier, 2000]. Cela nécessite la suppression des informations de traits et de co-ancrage des F-TAG, puis la conversion des TAG obtenues en RCG [Boullier, 1998, 1999, Barthélemy et al., 2001]. La troisième approche [Barthélemy et al., 2000] combine les deux premières. En effet, la forêt  partagée de dérivation produite par un analyseur RCG ( ) est utilisée pour guider un analyseur   DyALog modifié. L’analyseur vérifie les contraintes de traits et de co-ancrage tandis que  les informations fournies par rendent le traitement extrêmement efficace. 6.2 Le serveur d’analyseurs Étant donné le nombre croissant d’analyseurs que nous gérons, nous avons cherché à faciliter leur utilisation au moyen d’un serveur d’analyseurs, écrit en Perl. Une fois la"
2001.jeptalnrecital-long.4,P81-1022,0,0.402159,"Missing"
2001.jeptalnrecital-long.4,2000.iwpt-1.8,1,0.763087,"pour pouvoir traiter les TAG [Éric Villemonte de la Clergerie and Alonso Pardo, 1998, Alonso Pardo et al., 2000, Éric Villemonte de la Clergerie, 2001]. En particulier, nous avons testé deux schémas de tabulation, ainsi que deux stratégies d’analyse, à savoir une stratégie strictement descendante vérifiant la propriété de validité des préfixes et une stratégie hybride descendante avec vérification ascendante des traits. La seconde approche utilise les grammaires à concaténation d’intervalles (Range Concatenation Grammars – RCG) pour lesquelles nous construisons des analyseurs très efficaces [Boullier, 2000]. Cela nécessite la suppression des informations de traits et de co-ancrage des F-TAG, puis la conversion des TAG obtenues en RCG [Boullier, 1998, 1999, Barthélemy et al., 2001]. La troisième approche [Barthélemy et al., 2000] combine les deux premières. En effet, la forêt  partagée de dérivation produite par un analyseur RCG ( ) est utilisée pour guider un analyseur   DyALog modifié. L’analyseur vérifie les contraintes de traits et de co-ancrage tandis que  les informations fournies par rendent le traitement extrêmement efficace. 6.2 Le serveur d’analyseurs Étant donné le nombre croi"
2001.jeptalnrecital-long.4,W00-2022,0,0.0872284,"et de spécifications explicites. Nous avons de plus rencontré différentes variantes de XTAG. Enfin, certaines des grammaires étudiées présentent des problèmes de cohérence, dûs peut-être à un manque d’outils pour la gestion et le développement des TAG. Nous avons donc été amenés à examiner le langage de définition des TAG et à réfléchir à des outils permettant d’exploiter une représentation standardisée. Suivant d’autres, dont le groupe 1 http://www.cis.upenn.edu/~xtag/ F. Barthélemy, P. Boullier, P. Deschamp, L. Kaouane et É. V. de la Clergerie LT XML2 et plus particulièrement [Bonhomme and Lopez, 2000], nous avons conclu que le langage de balisage XML3 est un choix judicieux pour représenter les TAG. En premier lieu, l’utilisation de DTD permet d’exprimer clairement la structure logique des grammaires. Ensuite, le format XML est purement textuel, ce qui permet un échange facile de ressources linguistiques entre environnements hétérogènes ainsi qu’une lecture immédiate par un humain. Enfin, l’ensemble des outils pour le traitement de documents XML croît très rapidement. Partant de l’emploi de XML pour les grammaires, nous nous sommes aussi rendu compte de son intérêt pour stocker des résult"
2001.jeptalnrecital-long.4,N01-1022,1,0.468237,"Missing"
2001.jeptalnrecital-long.4,P98-2217,1,0.89412,"Missing"
2002.jeptalnrecital-long.6,2001.jeptalnrecital-long.4,1,0.9028,"p ancrant les verbes de modalité comme pouvoir ainsi que les entrées associées à la forme peut et au lemme pouvoir. vvp tag_tree{ name =&gt; vvp, family =&gt; vvp, VP tree=&gt; auxtree bot=VP: :vp{} at vp( &lt;&gt; v , id=vp_ and bot=VP at ∗vp) } . &lt;&gt;V VP  tag_lemma(’∗POUVOIR∗’ ,v, tag_anchor{ name=&gt;vvp, equations=&gt;[bot = vp{ mode=&gt;inf } at vp_]}). tag_lexicon (peut , ’∗POUVOIR∗’ , v , v{ mode =&gt; ind , num =&gt; sing }). Les TAG peuvent être écrites directement en DyALog, mais il existe également un format de représentation XML pour ces grammaires et des outils de conversion vers le format d’entrée de DyALog [Barthélemy et al., 2001]. Comme pour les DCG et les BMG, les stratégies d’analyse pour les TAG sont modulables. En interne, l’analyse tabulaire des TAG s’appuie sur l’utilisation d’automates à 2 piles [Villemonte de la Clergerie, 2001]. Notons qu’en sus de l’extension du compilateur, nous nous sommes aussi amusés à réaliser un méta-interprète pour les TAGs. 3.5 RCG Les grammaires à concaténation d’intervalles [RCG] [Boullier, 2000] forment une classe très puissante de grammaires pouvant néanmoins s’analyser en temps polynomial. De nombreux formalismes, comme les TAG, peuvent être encodés à l’aide des RCG. Les clause"
2002.jeptalnrecital-long.6,2000.iwpt-1.8,0,0.0393073,"ent être écrites directement en DyALog, mais il existe également un format de représentation XML pour ces grammaires et des outils de conversion vers le format d’entrée de DyALog [Barthélemy et al., 2001]. Comme pour les DCG et les BMG, les stratégies d’analyse pour les TAG sont modulables. En interne, l’analyse tabulaire des TAG s’appuie sur l’utilisation d’automates à 2 piles [Villemonte de la Clergerie, 2001]. Notons qu’en sus de l’extension du compilateur, nous nous sommes aussi amusés à réaliser un méta-interprète pour les TAGs. 3.5 RCG Les grammaires à concaténation d’intervalles [RCG] [Boullier, 2000] forment une classe très puissante de grammaires pouvant néanmoins s’analyser en temps polynomial. De nombreux formalismes, comme les TAG, peuvent être encodés à l’aide des RCG. Les clauses RCG ressemblent à des clauses DCG, à la différence que les arguments spécifient les intervalles de la chaîne d’entrée couverts par les non-terminaux. Ces arguments sont des terminaux ou des variables (X, Y , . . . ) séparés par l’opérateur de concaténation @. En plus de ces arguments, l’implantation DyALog des RCG permet d’associer un second jeu d’arguments logiques aux non-terminaux (XRCG). Ainsi, la gram"
2002.jeptalnrecital-long.6,C94-2149,0,0.565191,"tion en logique. En conséquence, DyALog offre actuellement la puissance d’un environnement de programmation en logique, permettant, en particulier, d’auto-amorcer (bootstrap) son compilateur qui est écrit en DyALog. Le fait de pouvoir utiliser la puissance de la programmation en logique présente au moins deux avantages. Premièrement, il est immédiat de réaliser des échappements vers des prédicats logiques dans les grammaires linguistiques. Cela permet de gérer plus facilement certains détails d’un formalisme, comme par exemple la gestion des contraintes de co-ancrage dans les grammaires XTAG [Doran et al., 1994]. Deuxièmement, que le compilateur DyALog soit écrit en DyALog illustre une caractéristique bien connue de la programmation en logique, à savoir la facilité d’écriture de méta-interprètes. En pratique, cela signifie qu’il est facile d’étendre le compilateur de DyALog pour intégrer de nouveaux formalismes ou alternativement de construire rapidement un méta-analyseur. Par défaut, les prédicats logiques sont tabulés. Ce comportement peut être modifié par des directives de compilation, permettant de ne pas tabuler certains prédicats et d’optimiser leur traitement. Nous avons ainsi des optimisatio"
2002.jeptalnrecital-long.6,N01-1022,1,0.869925,"Missing"
2002.jeptalnrecital-long.6,W02-2228,1,0.818443,"Missing"
2005.jeptalnrecital-long.1,P03-1024,0,0.0631623,"Missing"
2005.jeptalnrecital-long.1,C94-2149,0,0.102132,"Missing"
2005.jeptalnrecital-long.1,C00-1065,0,0.386648,"Missing"
2005.jeptalnrecital-long.1,W03-3020,0,0.0441781,"Missing"
2005.jeptalnrecital-long.1,J95-4002,0,0.0396681,"Missing"
2005.jeptalnrecital-long.1,2002.jeptalnrecital-long.6,1,0.891506,"Missing"
2005.jeptalnrecital-long.11,clement-etal-2004-morphology,1,0.881976,"Missing"
2005.jeptalnrecital-long.11,2005.jeptalnrecital-long.1,1,0.702588,"Missing"
2006.jeptalnrecital-long.26,2005.jeptalnrecital-long.1,1,0.744321,"Missing"
2006.jeptalnrecital-long.26,P04-1057,0,0.132069,"Missing"
2007.jeptalnrecital-long.29,J93-2002,0,0.0489844,"Missing"
2007.jeptalnrecital-long.29,P01-1034,0,0.0428912,"Missing"
2007.jeptalnrecital-long.29,sagot-etal-2006-lefff,1,0.879629,"Missing"
2007.jeptalnrecital-long.29,2006.jeptalnrecital-long.26,1,0.806755,"Missing"
2007.jeptalnrecital-long.29,2005.jeptalnrecital-long.1,1,0.802328,"Missing"
2007.jeptalnrecital-long.29,P04-1057,0,0.0670234,"Missing"
2009.jeptalnrecital-long.23,P98-1014,0,0.0256784,"Missing"
2009.jeptalnrecital-long.23,C08-1080,1,0.68042,"Missing"
2009.jeptalnrecital-long.23,P06-1042,1,0.904283,"Missing"
2009.jeptalnrecital-long.23,2005.jeptalnrecital-long.1,1,0.828483,"Missing"
2009.jeptalnrecital-long.23,P04-1057,0,0.0785878,"Missing"
2009.jeptalnrecital-long.23,zhang-kordoni-2006-automated,0,0.0270662,"Missing"
2010.jeptalnrecital-court.33,H05-1091,0,0.385755,"Missing"
2010.jeptalnrecital-court.33,I05-1035,0,0.0438108,"Missing"
2010.jeptalnrecital-court.33,P04-1053,0,0.0830097,"Missing"
2010.jeptalnrecital-court.33,Y06-1006,0,0.027842,"Missing"
2010.jeptalnrecital-court.33,C92-2082,0,0.45188,"Missing"
2010.jeptalnrecital-court.33,I05-1034,0,0.0410671,"Missing"
2010.jeptalnrecital-long.10,W98-0106,0,0.105808,"Missing"
2010.jeptalnrecital-long.10,declerck-2008-framework,0,0.061871,"Missing"
2010.jeptalnrecital-long.10,C00-1065,0,0.077154,"Missing"
2010.jeptalnrecital-long.10,paroubek-etal-2008-easy,0,0.0382906,"Missing"
2017.jeptalnrecital-court.25,W11-1906,0,0.0726368,"Missing"
2017.jeptalnrecital-court.25,D09-1015,0,0.0352993,"détection de chaînes de coréférences que pour une classe restreinte d’entités. Elle permet de ramener le problème de la détection de mentions à une tâche d’étiquetage de séquences, pour laquelle des méthodes efficaces sont connues et ont été étudiées en profondeur : MEMM pour (Florian et al., 2010), CRF pour (Qian et al., 2007) et plus récemment réseaux de neurones récurrents pour (Nguyen et al., 2016). Elle a en revanche le défaut classique de la modélisation de frontières par des étiquettes : la prise en compte d’entités imbriquées complique significativement les modèles (voir par exemple (Finkel & Manning, 2009)). 2.2 Mesures Contrairement aux mesures de qualité de la détection des chaînes de coréférences, la mesure de la qualité de la détection des mentions tend à faire consensus et est en général donnée par le triplet précision/rappel/F1 - mesure. La priorité est souvent donnée (par exemple dans (Lassalle, 2015)) au rappel au détriment de la précision, considérant que les faux positifs seront de toute façon détectés pendant la phase de détection des chaînes de coréférences. Il reste toutefois à déterminer ce que signifie « être correctement identifié » pour une mention trouvée par un système. (Reca"
2017.jeptalnrecital-court.25,D10-1033,0,0.0219351,"upérer directement tous les types de mentions, et nécessite un traitement a posteriori — par exemple des règles de regroupement de chunks. 2.1.3 Apprentissage automatique de la détection des frontières de mentions Les méthodes évoquées précédemment peuvent donner de bons résultats, mais sont entièrement dépendantes de l’existence de ressources linguistiques adaptées. Il existe cependant une autre possibilité : détecter directement dans le texte brut les frontières de mentions, comme le ferait un chunker ou un système de NER. Cette technique a été étudiée entre autres par (Jing et al., 2003), (Florian et al., 2010), et (Qian et al., 2007) (Nguyen et al., 2016) pour la tâche de reconnaissance et de suivi d’entités (EDT) issue des campagnes ACE, qui ne traite de la détection de chaînes de coréférences que pour une classe restreinte d’entités. Elle permet de ramener le problème de la détection de mentions à une tâche d’étiquetage de séquences, pour laquelle des méthodes efficaces sont connues et ont été étudiées en profondeur : MEMM pour (Florian et al., 2010), CRF pour (Qian et al., 2007) et plus récemment réseaux de neurones récurrents pour (Nguyen et al., 2016). Elle a en revanche le défaut classique de"
2017.jeptalnrecital-court.25,W03-1026,0,0.0818752,"ne permet pas de récupérer directement tous les types de mentions, et nécessite un traitement a posteriori — par exemple des règles de regroupement de chunks. 2.1.3 Apprentissage automatique de la détection des frontières de mentions Les méthodes évoquées précédemment peuvent donner de bons résultats, mais sont entièrement dépendantes de l’existence de ressources linguistiques adaptées. Il existe cependant une autre possibilité : détecter directement dans le texte brut les frontières de mentions, comme le ferait un chunker ou un système de NER. Cette technique a été étudiée entre autres par (Jing et al., 2003), (Florian et al., 2010), et (Qian et al., 2007) (Nguyen et al., 2016) pour la tâche de reconnaissance et de suivi d’entités (EDT) issue des campagnes ACE, qui ne traite de la détection de chaînes de coréférences que pour une classe restreinte d’entités. Elle permet de ramener le problème de la détection de mentions à une tâche d’étiquetage de séquences, pour laquelle des méthodes efficaces sont connues et ont été étudiées en profondeur : MEMM pour (Florian et al., 2010), CRF pour (Qian et al., 2007) et plus récemment réseaux de neurones récurrents pour (Nguyen et al., 2016). Elle a en revanch"
2017.jeptalnrecital-court.25,W11-1916,0,0.017262,"ec un système de détection d’entités nommées. Nous ne prétendons pas ici à l’exhaustivité : on pourra se reporter à (Poesio et al., 2016) pour plus de détails. 2.1.1 Extraction à partir d’une analyse syntaxique Cette méthode est utilisée par la majorité des systèmes end-to-end existants, généralement complétée par des systèmes de détection d’entités nommées et d’expressions non-référentielles. Elle consiste à extraire d’une analyse syntaxique les constituants pouvant être des mentions. Cette classification peut être réalisée à l’aide de règles écrites à la main (dos Santos & Carvalho, 2011), (Kummerfeld et al., 2011) ou apprise automatiquement (Uryupina & Moschitti, 2013). Cette procédure est raisonnablement fiable (voir tableau 1) et particulièrement adaptée au traitement de corpus arborés, comme ceux issus d’OntoNotes. Elle est cependant plus difficile à mettre en œuvre dans le cadre d’un système end-to-end, qui devient de ce fait dépendant de l’existence d’analyseurs syntaxiques pour la langue traitée et doit composer avec leurs éventuelles erreurs d’analyse. 2.1.2 Extraction à partir d’une analyse de surface Les inconvénients de l’utilisation d’analyses syntaxiques évoqués dans la section 2.1.1 peuven"
2017.jeptalnrecital-court.25,P10-1052,0,0.0155195,"Missing"
2017.jeptalnrecital-court.25,J13-4004,0,0.0354008,"’est-ce que [vous] en pensez ? — [la langue française] se dégrade dans [le langage parlé et courant [des gens]] [elle] se dégrade ? Fig. 1: Mentions et chaînes de coréférences (corpus ANCOR). On appelle système complet d’identification de chaînes de coréférences ou système end-to-end tout système capable de repérer les mentions dans un texte brut et de les regrouper en chaînes de coréférences. De tels systèmes ont déjà été conçus pour le français par (Trouilleux, 2001) et (Longo, 2013) mais leur portée reste modeste par rapport à celles de systèmes comme BART (Versley et al., 2008) ou dcoref (Lee et al., 2013), faute notamment de corpus en français annoté en chaînes de coréférences. Un système — CROC — réalisant le regroupement des mentions en chaînes a déjà été réalisé pour le français par (Désoyer et al., 2015) avec des performances comparables à l’état de l’art en anglais. Cependant, CROC s’appuyait sur des mentions de référence déjà repérées et portant des annotations morphosyntaxiques et sémantiques. Pour compléter ce travail, il reste donc à détecter les mentions dans le texte brut — c’est l’objet des travaux que nous présentons — et à y ajouter les annotations utilisées par CROC. La détectio"
2017.jeptalnrecital-court.25,I13-1012,0,0.015722,"prétendons pas ici à l’exhaustivité : on pourra se reporter à (Poesio et al., 2016) pour plus de détails. 2.1.1 Extraction à partir d’une analyse syntaxique Cette méthode est utilisée par la majorité des systèmes end-to-end existants, généralement complétée par des systèmes de détection d’entités nommées et d’expressions non-référentielles. Elle consiste à extraire d’une analyse syntaxique les constituants pouvant être des mentions. Cette classification peut être réalisée à l’aide de règles écrites à la main (dos Santos & Carvalho, 2011), (Kummerfeld et al., 2011) ou apprise automatiquement (Uryupina & Moschitti, 2013). Cette procédure est raisonnablement fiable (voir tableau 1) et particulièrement adaptée au traitement de corpus arborés, comme ceux issus d’OntoNotes. Elle est cependant plus difficile à mettre en œuvre dans le cadre d’un système end-to-end, qui devient de ce fait dépendant de l’existence d’analyseurs syntaxiques pour la langue traitée et doit composer avec leurs éventuelles erreurs d’analyse. 2.1.2 Extraction à partir d’une analyse de surface Les inconvénients de l’utilisation d’analyses syntaxiques évoqués dans la section 2.1.1 peuvent être — dans une certaine mesure — évités en utilisant"
2017.jeptalnrecital-court.25,P08-4003,0,0.0349384,"a langue française] se dégrade qu’est-ce que [vous] en pensez ? — [la langue française] se dégrade dans [le langage parlé et courant [des gens]] [elle] se dégrade ? Fig. 1: Mentions et chaînes de coréférences (corpus ANCOR). On appelle système complet d’identification de chaînes de coréférences ou système end-to-end tout système capable de repérer les mentions dans un texte brut et de les regrouper en chaînes de coréférences. De tels systèmes ont déjà été conçus pour le français par (Trouilleux, 2001) et (Longo, 2013) mais leur portée reste modeste par rapport à celles de systèmes comme BART (Versley et al., 2008) ou dcoref (Lee et al., 2013), faute notamment de corpus en français annoté en chaînes de coréférences. Un système — CROC — réalisant le regroupement des mentions en chaînes a déjà été réalisé pour le français par (Désoyer et al., 2015) avec des performances comparables à l’état de l’art en anglais. Cependant, CROC s’appuyait sur des mentions de référence déjà repérées et portant des annotations morphosyntaxiques et sémantiques. Pour compléter ce travail, il reste donc à détecter les mentions dans le texte brut — c’est l’objet des travaux que nous présentons — et à y ajouter les annotations ut"
2020.acl-main.645,C18-1139,0,0.188832,"e of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks. 1 Introduction Pretrained word representations have a long history in Natural Language Processing (NLP), from noncontextual (Brown et al., 1992; Ando and Zhang, 2005; Mikolov et al., 2013; Pennington et al., 2014) to contextual word embeddings (Peters et al., 2018; Akbik et al., 2018). Word representations are usually obtained by training language model architectures on large amounts of textual data and then fed as an input to more complex task-specific architectures. More recently, these specialized architectures have been replaced altogether by large-scale pretrained language models which are fine-tuned for each application considered. This shift has resulted in large improvements in performance over a wide ∗ Equal contribution. Order determined alphabetically. range of tasks (Devlin et al., 2019; Radford et al., 2019; Liu et al., 2019; Raffel et al., 2019). These transf"
2020.acl-main.645,bawden-etal-2014-correcting,0,0.0112223,"ncy parsing consists in predicting the labeled syntactic tree in order to capture the syntactic relations between words. For both of these tasks we run our experiments using the Universal Dependencies (UD)3 framework and its corresponding UD POS tag set (Petrov et al., 2012) and UD treebank collection (Nivre et al., 2018), which was used for the CoNLL 2018 shared task (Seker et al., 2018). We perform our evaluations on the four freely available French UD treebanks in UD v2.2: GSD (McDonald et al., 2013), Sequoia4 (Candito and Seddah, 2012; Candito et al., 2014), Spoken (Lacheret et al., 2014; Bawden et al., 2014)5 , and ParTUT (Sanguinetti and Bosco, 2015). A brief overview of the size and content of each treebank can be found in Table 1. Treebank #Tokens #Sentences GSD 389,363 16,342 68,615 3,099 Spoken 34,972 ParTUT 27,658 ···················· FTB 350,930 2,786 1,020 27,658 ···················· Sequoia ···················· ···················· sion of the Multi-Genre NLI (MultiNLI) corpus (Williams et al., 2018) to 15 languages by translating the validation and test sets manually into each of those languages. The English training set is machine translated for all languages other than English. The da"
2020.acl-main.645,J92-4003,0,0.338164,"Missing"
2020.acl-main.645,W09-3821,0,0.0439594,"l model based on mBERT, UDify is trained simultaneously on 124 different UD treebanks, creating a single POS tagging and dependency parsing model that works across 75 different languages. We report the scores from Kondratyuk (2019) paper. Table 1: Statistics on the treebanks used in POS tagging, dependency parsing, and NER (FTB). We also evaluate our model in NER, which is a sequence labeling task predicting which words refer to real-world objects, such as people, locations, artifacts and organisations. We use the French Treebank6 (FTB) (Abeillé et al., 2003) in its 2008 version introduced by Candito and Crabbé (2009) and with NER annotations by Sagot et al. (2012). The FTB contains more than 11 thousand entity mentions distributed among 7 different entity types. A brief overview of the FTB can also be found in Table 1. Finally, we evaluate our model on NLI, using the French part of the XNLI dataset (Conneau et al., 2018). NLI consists in predicting whether a hypothesis sentence is entailed, neutral or contradicts a premise sentence. The XNLI dataset is the exten3 https://universaldependencies.org https://deep-sequoia.inria.fr 5 Speech transcript uncased that includes annotated disfluencies without punctua"
2020.acl-main.645,2020.acl-main.747,0,0.0712291,"Missing"
2020.acl-main.645,D18-1269,0,0.021825,"g, and NER (FTB). We also evaluate our model in NER, which is a sequence labeling task predicting which words refer to real-world objects, such as people, locations, artifacts and organisations. We use the French Treebank6 (FTB) (Abeillé et al., 2003) in its 2008 version introduced by Candito and Crabbé (2009) and with NER annotations by Sagot et al. (2012). The FTB contains more than 11 thousand entity mentions distributed among 7 different entity types. A brief overview of the FTB can also be found in Table 1. Finally, we evaluate our model on NLI, using the French part of the XNLI dataset (Conneau et al., 2018). NLI consists in predicting whether a hypothesis sentence is entailed, neutral or contradicts a premise sentence. The XNLI dataset is the exten3 https://universaldependencies.org https://deep-sequoia.inria.fr 5 Speech transcript uncased that includes annotated disfluencies without punctuation 6 This dataset has only been stored and used on Inria’s servers after signing the research-only agreement. 4 • UDPipe Future (Straka, 2018): An LSTMbased model ranked 3rd in dependency parsing and 6th in POS tagging at the CoNLL 2018 shared task (Seker et al., 2018). We report the scores from Kondratyuk"
2020.acl-main.645,2020.findings-emnlp.292,0,0.0196656,"B model (81.88 vs. 81.55). This might be due to the random seed used for pretraining, as each model is pretrained only once. 7210 language understanding tasks. However, even with a BASE architecture and 4GB of training data, the validation loss is still decreasing beyond 100k steps (and 400 epochs). This suggests that we are still under-fitting the 4GB pretraining dataset, training longer might increase downstream performance. 7 Discussion Since the pre-publication of this work (Martin et al., 2019), many monolingual language models have appeared, e.g. (Le et al., 2019; Virtanen et al., 2019; Delobelle et al., 2020), for as much as 30 languages (Nozza et al., 2020). In almost all tested configurations they displayed better results than multilingual language models such as mBERT (Pires et al., 2019). Interestingly, Le et al. (2019) showed that using their FlauBert, a RoBERTa-based language model for French, which was trained on less but more edited data, in conjunction to CamemBERT in an ensemble system could improve the performance of a parsing model and establish a new state-of-the-art in constituency parsing of French, highlighting thus the complementarity of both models.18 As it was the case for Engli"
2020.acl-main.645,N19-1423,0,0.496677,"ennington et al., 2014) to contextual word embeddings (Peters et al., 2018; Akbik et al., 2018). Word representations are usually obtained by training language model architectures on large amounts of textual data and then fed as an input to more complex task-specific architectures. More recently, these specialized architectures have been replaced altogether by large-scale pretrained language models which are fine-tuned for each application considered. This shift has resulted in large improvements in performance over a wide ∗ Equal contribution. Order determined alphabetically. range of tasks (Devlin et al., 2019; Radford et al., 2019; Liu et al., 2019; Raffel et al., 2019). These transfer learning methods exhibit clear advantages over more traditional task-specific approaches. In particular, they can be trained in an unsupervized manner, thereby taking advantage of the information contained in large amounts of raw text. Yet they come with implementation challenges, namely the amount of data and computational resources needed for pretraining, which can reach hundreds of gigabytes of text and require hundreds of GPUs (Yang et al., 2019; Liu et al., 2019). This has limited the availability of these stat"
2020.acl-main.645,E17-2068,0,0.0593732,"training data, architecture, training objective and optimisation setup we use for CamemBERT. 4.1 Training data Pretrained language models benefits from being trained on large datasets (Devlin et al., 2018; Liu et al., 2019; Raffel et al., 2019). We therefore use the French part of the OSCAR corpus (Ortiz Suárez et al., 2019), a pre-filtered and pre-classified version of Common Crawl.7 OSCAR is a set of monolingual corpora extracted from Common Crawl snapshots. It follows the same approach as (Grave et al., 2018) by using a language classification model based on the fastText linear classifier (Grave et al., 2017; Joulin et al., 2016) pretrained on Wikipedia, Tatoeba and SETimes, which supports 176 languages. No other filtering is done. We use a non-shuffled version of the French data, which amounts to 138GB of raw text and 32.7B tokens after subword tokenization. 4.2 Pre-processing We segment the input text data into subword units using SentencePiece (Kudo and Richardson, 2018). SentencePiece is an extension of Byte-Pair encoding (BPE) (Sennrich et al., 2016) and WordPiece (Kudo, 2018) that does not require pre-tokenization (at the word or token level), thus removing the need for language-specific to"
2020.acl-main.645,P19-1356,1,0.885465,"Missing"
2020.acl-main.645,D14-1162,0,0.0850598,"entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks. 1 Introduction Pretrained word representations have a long history in Natural Language Processing (NLP), from noncontextual (Brown et al., 1992; Ando and Zhang, 2005; Mikolov et al., 2013; Pennington et al., 2014) to contextual word embeddings (Peters et al., 2018; Akbik et al., 2018). Word representations are usually obtained by training language model architectures on large amounts of textual data and then fed as an input to more complex task-specific architectures. More recently, these specialized architectures have been replaced altogether by large-scale pretrained language models which are fine-tuned for each application considered. This shift has resulted in large improvements in performance over a wide ∗ Equal contribution. Order determined alphabetically. range of tasks (Devlin et al., 2019; Ra"
2020.acl-main.645,N18-1202,0,0.351202,". We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks. 1 Introduction Pretrained word representations have a long history in Natural Language Processing (NLP), from noncontextual (Brown et al., 1992; Ando and Zhang, 2005; Mikolov et al., 2013; Pennington et al., 2014) to contextual word embeddings (Peters et al., 2018; Akbik et al., 2018). Word representations are usually obtained by training language model architectures on large amounts of textual data and then fed as an input to more complex task-specific architectures. More recently, these specialized architectures have been replaced altogether by large-scale pretrained language models which are fine-tuned for each application considered. This shift has resulted in large improvements in performance over a wide ∗ Equal contribution. Order determined alphabetically. range of tasks (Devlin et al., 2019; Radford et al., 2019; Liu et al., 2019; Raffel et al."
2020.acl-main.645,petrov-etal-2012-universal,0,0.0660713,"Natural Language Inference (NLI). We also present the baselines that we will use for comparison. 1 Released at: https://camembert-model.fr under the MIT open-source license. 7204 2 https://allennlp.org/elmo Tasks POS tagging is a low-level syntactic task, which consists in assigning to each word its corresponding grammatical category. Dependency parsing consists in predicting the labeled syntactic tree in order to capture the syntactic relations between words. For both of these tasks we run our experiments using the Universal Dependencies (UD)3 framework and its corresponding UD POS tag set (Petrov et al., 2012) and UD treebank collection (Nivre et al., 2018), which was used for the CoNLL 2018 shared task (Seker et al., 2018). We perform our evaluations on the four freely available French UD treebanks in UD v2.2: GSD (McDonald et al., 2013), Sequoia4 (Candito and Seddah, 2012; Candito et al., 2014), Spoken (Lacheret et al., 2014; Bawden et al., 2014)5 , and ParTUT (Sanguinetti and Bosco, 2015). A brief overview of the size and content of each treebank can be found in Table 1. Treebank #Tokens #Sentences GSD 389,363 16,342 68,615 3,099 Spoken 34,972 ParTUT 27,658 ···················· FTB 350,930 2,786"
2020.acl-main.645,P19-1493,0,0.0210785,"itecture and 4GB of training data, the validation loss is still decreasing beyond 100k steps (and 400 epochs). This suggests that we are still under-fitting the 4GB pretraining dataset, training longer might increase downstream performance. 7 Discussion Since the pre-publication of this work (Martin et al., 2019), many monolingual language models have appeared, e.g. (Le et al., 2019; Virtanen et al., 2019; Delobelle et al., 2020), for as much as 30 languages (Nozza et al., 2020). In almost all tested configurations they displayed better results than multilingual language models such as mBERT (Pires et al., 2019). Interestingly, Le et al. (2019) showed that using their FlauBert, a RoBERTa-based language model for French, which was trained on less but more edited data, in conjunction to CamemBERT in an ensemble system could improve the performance of a parsing model and establish a new state-of-the-art in constituency parsing of French, highlighting thus the complementarity of both models.18 As it was the case for English when BERT was first released, the availability of similar scale language models for French enabled interesting applications, such as large scale anonymization of legal texts, where Ca"
2020.acl-main.645,P16-1162,0,0.0173054,"l snapshots. It follows the same approach as (Grave et al., 2018) by using a language classification model based on the fastText linear classifier (Grave et al., 2017; Joulin et al., 2016) pretrained on Wikipedia, Tatoeba and SETimes, which supports 176 languages. No other filtering is done. We use a non-shuffled version of the French data, which amounts to 138GB of raw text and 32.7B tokens after subword tokenization. 4.2 Pre-processing We segment the input text data into subword units using SentencePiece (Kudo and Richardson, 2018). SentencePiece is an extension of Byte-Pair encoding (BPE) (Sennrich et al., 2016) and WordPiece (Kudo, 2018) that does not require pre-tokenization (at the word or token level), thus removing the need for language-specific tokenisers. We use a vocabulary size of 32k subword tokens. These subwords are learned on 107 sentences sampled randomly from the pretraining dataset. We do not use subword regularisation (i.e. sampling from multiple possible segmentations) for the sake of simplicity. 7 https://commoncrawl.org/about/ 4.3 Language Modeling Transformer Similar to RoBERTa and BERT, CamemBERT is a multi-layer bidirectional Transformer (Vaswani et al., 2017). Given the widesp"
2020.acl-main.645,K18-2020,0,0.0902039,"ent entity types. A brief overview of the FTB can also be found in Table 1. Finally, we evaluate our model on NLI, using the French part of the XNLI dataset (Conneau et al., 2018). NLI consists in predicting whether a hypothesis sentence is entailed, neutral or contradicts a premise sentence. The XNLI dataset is the exten3 https://universaldependencies.org https://deep-sequoia.inria.fr 5 Speech transcript uncased that includes annotated disfluencies without punctuation 6 This dataset has only been stored and used on Inria’s servers after signing the research-only agreement. 4 • UDPipe Future (Straka, 2018): An LSTMbased model ranked 3rd in dependency parsing and 6th in POS tagging at the CoNLL 2018 shared task (Seker et al., 2018). We report the scores from Kondratyuk (2019) paper. • UDPipe Future + mBERT + Flair (Straka et al., 2019): The original UDPipe Future implementation using mBERT and Flair as feature-based contextualized word embeddings. We report the scores from Straka et al. (2019) paper. In French, no extensive work has been done on NER due to the limited availability of annotated corpora. Thus we compare our model with the only recent available baselines set by Dupont (2017), who t"
2020.acl-main.645,P81-1022,0,0.325042,"Missing"
2020.acl-main.645,P19-1527,0,0.185418,"ining set is machine translated for all languages other than English. The dataset is composed of 122k train, 2490 development and 5010 test examples for each language. As usual, NLI performance is evaluated using accuracy. Baselines In dependency parsing and POStagging we compare our model with: • mBERT: The multilingual cased version of BERT (see Section 2.1). We fine-tune mBERT on each of the treebanks with an additional layer for POS-tagging and dependency parsing, in the same conditions as our CamemBERT model. • XLMMLM-TLM : A multilingual pretrained language model from Lample and Conneau (2019), which showed better performance than mBERT on NLI. We use the version available in the Hugging’s Face transformer library (Wolf et al., 2019); like mBERT, we fine-tune it in the same conditions as our model. Genres Blogs, News Reviews, Wiki Medical, News Non-fiction, Wiki Spoken Legal, News, Wikis News • UDify (Kondratyuk, 2019): A multitask and multilingual model based on mBERT, UDify is trained simultaneously on 124 different UD treebanks, creating a single POS tagging and dependency parsing model that works across 75 different languages. We report the scores from Kondratyuk (2019) paper."
2020.acl-main.645,P19-1452,0,0.028162,"Missing"
2020.acl-main.645,N18-1101,0,0.0873351,"Missing"
2020.acl-main.645,D19-1077,0,0.0177636,"Straka et al. (2019) paper. In French, no extensive work has been done on NER due to the limited availability of annotated corpora. Thus we compare our model with the only recent available baselines set by Dupont (2017), who trained both CRF (Lafferty et al., 2001) and 7205 BiLSTM-CRF (Lample et al., 2016) architectures on the FTB and enhanced them using heuristics and pretrained word embeddings. Additionally, as for POS and dependency parsing, we compare our model to a fine-tuned version of mBERT for the NER task. For XNLI, we provide the scores of mBERT which has been reported for French by Wu and Dredze (2019). We report scores from XLMMLM-TLM (described above), the best model from Lample and Conneau (2019). We also report the results of XLM-R (Conneau et al., 2019). 4 CamemBERT: a French Language Model In this section, we describe the pretraining data, architecture, training objective and optimisation setup we use for CamemBERT. 4.1 Training data Pretrained language models benefits from being trained on large datasets (Devlin et al., 2018; Liu et al., 2019; Raffel et al., 2019). We therefore use the French part of the OSCAR corpus (Ortiz Suárez et al., 2019), a pre-filtered and pre-classified vers"
2020.cmlc-1.3,W09-3821,0,0.0209598,"dependency parsing. Finally, it is also relevant to compare our results with CamemBERT on the selected tasks, because compared to UDify it is the work that pushed the furthest the performance in fine-tuning end-to-end a BERT-based model. Genre News Wiki. Blogs Pop. Wiki. Med. EuroParl Oral transcip. Oral Wiki. Legal Table 5: Sizes of the 4 treebanks used in the evaluations of POS-tagging and dependency parsing. 4.3.2. Named Entity Recognition Treebanks test data-set The benchmark data set from the French Treebank (FTB) (Abeillé et al., 2003) was selected in its 2008 version, as introduced by Candito and Crabbé (2009) and complemented with NER annotations by Sagot et al. (2012)10 . The tree-bank, shows a large proportion of the entity mentions that are multi-word entities. We therefore report the three metrics that are commonly used to evaluate models: precision, recall, and F1 score. consists in predicting which words refer to real-world objects, such as people, locations, artifacts and organizations, it directly probes the quality and specificity of semantic representations issued by the more or less balanced corpora under comparison. 4.3.1. POS-tagging and dependency parsing Experiments were run using t"
2020.cmlc-1.3,candito-etal-2014-deep,1,0.785322,"te-of-the-art language model for French, CamemBERT (Martin et al., 2019), based on the RoBERTa architecture pre-trained on the French sub-corpus of the newly available multilingual corpus OSCAR (Ortiz Suárez et al., 2019). Treebanks test data-set We perform our work on the four freely available French UD treebanks in UD v2.2: GSD, Sequoia, Spoken, and ParTUT, presented in Table 5. GSD treebank (McDonald et al., 2013) is the second-largest tree-bank available for French after the FTB (described in subsection 4.3.2.), it contains data from blogs, news, reviews, and Wikipedia. Sequoia tree-bank (Candito et al., 2014) comprises more than 3000 sentences, from the French Europarl, the regional newspaper L’Est Républicain, the French Wikipedia and documents from the European Medicines Agency. Spoken was automatically converted from the Rhapsodie tree-bank (Lacheret et al., 2014) with manual corrections. It consists of 57 sound samples of spoken French with phonetic transcription aligned with sound (word boundaries, syllables, and phonemes), syntactic and prosodic annotations. Finally, ParTUT is a conversion of a multilingual parallel treebank developed at the University of Turin, and consisting of a variety o"
2020.cmlc-1.3,N16-1030,0,0.0868252,"Missing"
2020.cmlc-1.3,P13-2017,0,0.021082,"o trained both CRF and BiLSTM-CRF architectures on the FTB and enhanced them using heuristics and pre-trained word-embeddings. And additional term of comparison was identified in a recently released state-of-the-art language model for French, CamemBERT (Martin et al., 2019), based on the RoBERTa architecture pre-trained on the French sub-corpus of the newly available multilingual corpus OSCAR (Ortiz Suárez et al., 2019). Treebanks test data-set We perform our work on the four freely available French UD treebanks in UD v2.2: GSD, Sequoia, Spoken, and ParTUT, presented in Table 5. GSD treebank (McDonald et al., 2013) is the second-largest tree-bank available for French after the FTB (described in subsection 4.3.2.), it contains data from blogs, news, reviews, and Wikipedia. Sequoia tree-bank (Candito et al., 2014) comprises more than 3000 sentences, from the French Europarl, the regional newspaper L’Est Républicain, the French Wikipedia and documents from the European Medicines Agency. Spoken was automatically converted from the Rhapsodie tree-bank (Lacheret et al., 2014) with manual corrections. It consists of 57 sound samples of spoken French with phonetic transcription aligned with sound (word boundari"
2020.cmlc-1.3,W18-4904,0,0.0227094,"e a significant predictor of ELMo’s accuracy on Spoken test data-set and for NER tasks. Other perspective uses of CaBeRnet involve it use as a corpus offering a reference point for lexical frequency measures, like association measures. Its comparability with English COCA further grants the cross-linguistic validity of measures like Point-wise Mutual Information or DICE’s Coefficient. The representativeness probed through our experimental approach are key aspects that allow such measures to be tested against psycho-linguistic and neurolinguistic data as shown in previous neuro-imaging studies (Fabre et al., 2018). The results obtained for the parsing tasks on ParTUT open a new perspective for the development of the French Balanced Reference Corpus, involving the enhancement of the terminological coverage of CaBeRnet. A sixth sub-part could be included to cover technical domains like legal and medical ones, and thereby enlarge the specialized lexical coverage of CaBeRnet. Further developments of this resource would involve an extension to cover user-generated content, ranging from well written blogs, tweets to more variable written productions like newspaper’s comment or We acknowledge Benoit Crabbé fo"
2020.cmlc-1.3,E17-2068,0,0.0312967,"set of comparable corpora with a similar balance and representativeness. C HILDREN B OOK T EST - FR number of different lemmas total number of forms mean number of forms per lemma Number of lemmas having more than one form : Percentage of lemmas with multiple forms OSCAR gathers a set of monolingual text extracted from Common Crawl - in plain text WET format - where all HTML tags are removed and all text encodings are converted to UTF-8. It follows a similar approach to (Grave et al., 2018) by using a language classification model based on the fastText linear classifier (Joulin et al., 2016; Grave et al., 2017) pre-trained on Wikipedia, Tatoeba and SETimes, supporting 176 different languages. After language classification, a deduplication step is performed without introducing a specialized filtering scheme: paragraphs containing 100 or more UTF-8 encoded characters are kept. This makes OSCAR an example of unfiltered data that is nearly as noisy as to the original Crawled data. WORDS 25 139 95 058 3.78 14 128 56.20 Table 2: Lexical statistics of French CBT, performed as described in §3. 3. 3.1.2. FrWIKI This corpus collects a selection of pages from Wikipediafr from a dump executed in April 2019, whe"
2020.cmlc-1.3,L18-1550,0,0.0194647,"plain narrative text. The effort of keeping proportion, genre, domain, and time as equal as possible yields a multilingual set of comparable corpora with a similar balance and representativeness. C HILDREN B OOK T EST - FR number of different lemmas total number of forms mean number of forms per lemma Number of lemmas having more than one form : Percentage of lemmas with multiple forms OSCAR gathers a set of monolingual text extracted from Common Crawl - in plain text WET format - where all HTML tags are removed and all text encodings are converted to UTF-8. It follows a similar approach to (Grave et al., 2018) by using a language classification model based on the fastText linear classifier (Joulin et al., 2016; Grave et al., 2017) pre-trained on Wikipedia, Tatoeba and SETimes, supporting 176 different languages. After language classification, a deduplication step is performed without introducing a specialized filtering scheme: paragraphs containing 100 or more UTF-8 encoded characters are kept. This makes OSCAR an example of unfiltered data that is nearly as noisy as to the original Crawled data. WORDS 25 139 95 058 3.78 14 128 56.20 Table 2: Lexical statistics of French CBT, performed as described"
2020.cmlc-1.3,2005.mtsummit-papers.11,0,0.0651172,"Missing"
2020.cmlc-1.3,D19-1279,0,0.0884182,"ce, CaBeRnet’s balanced oral language use shows to pay off in POS-tagging. These results are extremely surprising especially given the fact that State-of-the-art For POS-tagging and Parsing we select as a baseline UDPipe Future (2.0), without any additional contextualized embeddings (Straka, 2018). This model was ranked 3rd in dependency parsing and 6th in POS-tagging during the CoNLL 2018 shared task (Seker et al., 2018). Notably, UDPipe Future provides us a strong baseline that does not make use of any pre-trained contextual embedding. We report on Table 6 the published results on UDify by (Kondratyuk, 2019), a multitask and multilingual model based on mBERT that is near state-of-the-art on all UD lan10 The NER-annotated FTB contains approximately than 12k sentences, and more than 350k tokens were extracted from articles of Le Monde newspaper (1989 - 1995). As a whole, it encompasses 11,636 entity mentions distributed among 7 different types : 2025 mentions of “Person”, 3761 of “Location”, 2382 of “Organisation”, 3357 of “Company”, 67 of “Product”, 15 of “POI” (Point of Interest) and 29 of “Fictional Character”. 19 GSD M ODEL S EQUOIA S POKEN PARTUT UPOS UAS LAS UPOS UAS LAS UPOS UAS LAS UPOS UAS"
2020.cmlc-1.3,N18-1202,0,0.187501,"valuation scores on different evaluation sets and tasks. Keywords: Balanced French Corpus, Language Models, French, BERT, ELMo, Tagging, Parsing, NER 1. Introduction uation of the quality of the word-embeddings obtained by pre-training and fine-tuning on different corpora, that are made here publicly available. Based on the underlying assumption that a linguistically representative corpus would possibly generate better word-embeddings. We provide an evaluation-based investigation of how a balanced crossgenre corpus can yield improvements in the performance of neural language models like ELMo (Peters et al., 2018) on various downstream tasks. The two corpora, CaBeRnet and CBT-fr, and the ELMos will be distributed freely under Creative Commons License. The question of quality versus size of training corpora is increasingly gaining attention and interest in the context of the latest developments in neural language models’ performance. The longstanding issue of corpora &quot;representativeness&quot; is here addressed, in order to grasp to what extent a linguistically balanced cross-genre language sample is sufficient for a language model to gain in accuracy for contextualized word-embeddings on different NLP tasks."
2020.cmlc-1.3,F12-2050,1,0.747324,"sults with CamemBERT on the selected tasks, because compared to UDify it is the work that pushed the furthest the performance in fine-tuning end-to-end a BERT-based model. Genre News Wiki. Blogs Pop. Wiki. Med. EuroParl Oral transcip. Oral Wiki. Legal Table 5: Sizes of the 4 treebanks used in the evaluations of POS-tagging and dependency parsing. 4.3.2. Named Entity Recognition Treebanks test data-set The benchmark data set from the French Treebank (FTB) (Abeillé et al., 2003) was selected in its 2008 version, as introduced by Candito and Crabbé (2009) and complemented with NER annotations by Sagot et al. (2012)10 . The tree-bank, shows a large proportion of the entity mentions that are multi-word entities. We therefore report the three metrics that are commonly used to evaluate models: precision, recall, and F1 score. consists in predicting which words refer to real-world objects, such as people, locations, artifacts and organizations, it directly probes the quality and specificity of semantic representations issued by the more or less balanced corpora under comparison. 4.3.1. POS-tagging and dependency parsing Experiments were run using the Universal Dependencies (UD) paradigm and its corresponding"
2020.cmlc-1.3,K18-2021,0,0.0185014,", only an even smaller amount of data comes from purely oral transcripts comparable the ones in the Spoken tree-bank, namely 67,444 words from Rhapsodie corpus, and 575,894 words form ORFEO. Hence, CaBeRnet’s balanced oral language use shows to pay off in POS-tagging. These results are extremely surprising especially given the fact that State-of-the-art For POS-tagging and Parsing we select as a baseline UDPipe Future (2.0), without any additional contextualized embeddings (Straka, 2018). This model was ranked 3rd in dependency parsing and 6th in POS-tagging during the CoNLL 2018 shared task (Seker et al., 2018). Notably, UDPipe Future provides us a strong baseline that does not make use of any pre-trained contextual embedding. We report on Table 6 the published results on UDify by (Kondratyuk, 2019), a multitask and multilingual model based on mBERT that is near state-of-the-art on all UD lan10 The NER-annotated FTB contains approximately than 12k sentences, and more than 350k tokens were extracted from articles of Le Monde newspaper (1989 - 1995). As a whole, it encompasses 11,636 entity mentions distributed among 7 different types : 2025 mentions of “Person”, 3761 of “Location”, 2382 of “Organisat"
2020.cmlc-1.3,P19-1527,0,0.0151385,"more or less balanced corpora under comparison. 4.3.1. POS-tagging and dependency parsing Experiments were run using the Universal Dependencies (UD) paradigm and its corresponding UD POS-tag set (Petrov et al., 2011) and UD treebank collection version 2.2 (Nivre et al., 2018), which was used for the CoNLL 2018 shared task. Different terms of comparisons were considered on the two downstream tasks of part-of-speech (POS) tagging and dependency parsing. NER State-of-the-art English has received the most attention in NER in the past, with some recent developments in German, Dutch and Spanish by Straková et al. (2019). In French, no extensive work has been done due to the limited availability of NER corpora. We compare our model with the stable baselines settled by (Dupont, 2018), who trained both CRF and BiLSTM-CRF architectures on the FTB and enhanced them using heuristics and pre-trained word-embeddings. And additional term of comparison was identified in a recently released state-of-the-art language model for French, CamemBERT (Martin et al., 2019), based on the RoBERTa architecture pre-trained on the French sub-corpus of the newly available multilingual corpus OSCAR (Ortiz Suárez et al., 2019). Treeba"
2020.jeptalnrecital-taln.5,2020.findings-emnlp.292,0,0.0264053,"Missing"
2020.jeptalnrecital-taln.5,N19-1423,0,0.0614451,"Missing"
2020.jeptalnrecital-taln.5,L18-1550,0,0.0310337,"Missing"
2020.jeptalnrecital-taln.5,E17-2068,0,0.0612565,"Missing"
2020.jeptalnrecital-taln.5,P18-1031,0,0.0436608,"Missing"
2020.jeptalnrecital-taln.5,P19-1356,1,0.883155,"Missing"
2020.jeptalnrecital-taln.5,D14-1162,0,0.0850524,"Missing"
2020.jeptalnrecital-taln.5,N18-1202,0,0.122933,"Missing"
2020.jeptalnrecital-taln.5,P19-1493,0,0.0268051,"Missing"
2020.jeptalnrecital-taln.5,F12-2050,1,0.854707,"Missing"
2020.jeptalnrecital-taln.5,P19-1527,0,0.0505485,"Missing"
2020.jeptalnrecital-taln.5,P19-1452,0,0.0305722,"Missing"
2020.jeptalnrecital-taln.5,N18-1101,0,0.0357062,"Missing"
2020.lrec-1.577,D19-3009,1,0.911461,"Missing"
2020.lrec-1.577,W11-1601,0,0.0801056,"ication Text simplification has gained increasing interest through the years and has benefited from advances in Natural Language Processing and notably Machine Translation. In recent years, SS was largely treated as a monolingual variant of machine translation (MT), where simplification operations are learned from complex-simple sentence pairs automatically extracted from English Wikipedia and Simple English Wikipedia (Zhu et al., 2010; Wubben et al., 2012). Phrase-based and Syntax-based MT was successfully used for SS (Zhu et al., 2010) and further tailored to the task using deletion models (Coster and Kauchak, 2011) and candidate reranking (Wubben et al., 2012). The candidate reranking method by Wubben et al. (2012) favors simplifications that are most dissimilar to the source using Levenshtein distance. The authors argue that dissimilarity is a key factor of simplification. Lately, SS has mostly been tackled using Seq2Seq MT models (Sutskever et al., 2014). Seq2Seq models were either used as-is (Nisioi et al., 2017) or combined with reinforcement learning thanks to a specific simplification reward (Zhang and Lapata, 2017), augmented with an external simplification database as a dynamic memory (Zhao et a"
2020.lrec-1.577,W14-1215,0,0.06777,"ion benchmarks. Our model, which we call ACCESS (as shorthand for AudienCe-CEntric Sentence Simplification), establishes the state of the art at 41.87 SARI on the WikiLarge test set, a +1.42 improvement over the best previously reported score. Keywords: Text Simplification, Sequence-to-Sequence models, ACCESS 1. Introduction In Natural Language Processing, the Text Simplification task aims at making a text easier to read and understand. Text simplification can be beneficial for people with cognitive disabilities such as aphasia (Carroll et al., 1998), dyslexia (Rello et al., 2013) and autism (Evans et al., 2014) but also for second language learners (Xia et al., 2016) and people with low literacy (Watanabe et al., 2009). The type of simplification needed for each of these audiences is different. Some aphasic patients struggle to read sentences with a high cognitive load such as long sentences with intricate syntactic structures, whereas second language learners might not understand texts with rare or specific vocabulary. Yet, research in text simplification has been mostly focused on developing models that generate a single generic simplification for a given source text with no possibility to adapt o"
2020.lrec-1.577,K18-1040,0,0.138127,"ic memory (Zhao et al., 2018) or trained with multi-tasking on entailment and paraphrase generation (Guo et al., 2018). 4689 This work builds upon Seq2Seq as well. We prepend additional inputs to the source sentences at train time, in the form of plain text special tokens. Our approach does not require any external data or modified training objective. 2.2. Controllable Text Generation Conditional training with Seq2Seq models was applied to multiple natural language processing tasks such as summarization (Kikuchi et al., 2016; Fan et al., 2017), dialog (See et al., 2019), sentence compression (Fevry and Phang, 2018; Mallinson et al., 2018) or poetry generation (Ghazvininejad et al., 2017). Most approaches for controllable text generation are either decoding-based or learning-based. Decoding-based methods Decoding-based methods use a standard Seq2Seq training setup but modify the system during decoding to control a given attribute. For instance, the length of summaries was controlled by preventing the decoder from generating the End-Of-Sentence token before reaching the desired length or by only selecting hypotheses of a given length during the beam search (Kikuchi et al., 2016). Weighted decoding (i.e."
2020.lrec-1.577,W17-4912,0,0.0414037,"Seq model on the considered attribute at train time, and can then be used to control the output at inference time. Kikuchi et al. (2016) explored learning-based methods to control the length of summaries, e.g. by feeding a target length vector to the neural network. They concluded that learning-based methods worked better than decoding-based methods and allowed finer control on the length without degrading performances. Length control was likewise used in sentence compression by feeding the network a length countdown scalar (Fevry and Phang, 2018) or a length vector (Mallinson et al., 2018). (Ficler and Goldberg, 2017) concatenate a context vector to the hidden state of each time step of their recurrent neural network decoder. This context vector represents the controlled stylistic attributes of the text, where an embedding is learnt for each attribute value. (Hu et al., 2017) achieved controlled text generation by disentangling the latent space representations of a variational auto-encoder between the text representation and its controlled attributes such as sentiment and tense. They impose the latent space structure during training by using additional discriminators. Our work uses a simpler approach: we c"
2020.lrec-1.577,P17-4008,0,0.0154976,"ment and paraphrase generation (Guo et al., 2018). 4689 This work builds upon Seq2Seq as well. We prepend additional inputs to the source sentences at train time, in the form of plain text special tokens. Our approach does not require any external data or modified training objective. 2.2. Controllable Text Generation Conditional training with Seq2Seq models was applied to multiple natural language processing tasks such as summarization (Kikuchi et al., 2016; Fan et al., 2017), dialog (See et al., 2019), sentence compression (Fevry and Phang, 2018; Mallinson et al., 2018) or poetry generation (Ghazvininejad et al., 2017). Most approaches for controllable text generation are either decoding-based or learning-based. Decoding-based methods Decoding-based methods use a standard Seq2Seq training setup but modify the system during decoding to control a given attribute. For instance, the length of summaries was controlled by preventing the decoder from generating the End-Of-Sentence token before reaching the desired length or by only selecting hypotheses of a given length during the beam search (Kikuchi et al., 2016). Weighted decoding (i.e. assigning weights to specific words during decoding) was also used with dia"
2020.lrec-1.577,C18-1039,0,0.203724,"Wubben et al. (2012) favors simplifications that are most dissimilar to the source using Levenshtein distance. The authors argue that dissimilarity is a key factor of simplification. Lately, SS has mostly been tackled using Seq2Seq MT models (Sutskever et al., 2014). Seq2Seq models were either used as-is (Nisioi et al., 2017) or combined with reinforcement learning thanks to a specific simplification reward (Zhang and Lapata, 2017), augmented with an external simplification database as a dynamic memory (Zhao et al., 2018) or trained with multi-tasking on entailment and paraphrase generation (Guo et al., 2018). 4689 This work builds upon Seq2Seq as well. We prepend additional inputs to the source sentences at train time, in the form of plain text special tokens. Our approach does not require any external data or modified training objective. 2.2. Controllable Text Generation Conditional training with Seq2Seq models was applied to multiple natural language processing tasks such as summarization (Kikuchi et al., 2016; Fan et al., 2017), dialog (See et al., 2019), sentence compression (Fevry and Phang, 2018; Mallinson et al., 2018) or poetry generation (Ghazvininejad et al., 2017). Most approaches for"
2020.lrec-1.577,P13-1151,0,0.0596419,"d preprocess using SentencePiece (Kudo and Richardson, 2018) with 10k vocabulary size to handle rare and unknown words. For generation we use beam search with a beam size of 8. 3 Training and evaluation datasets Our models are trained and evaluated on the WikiLarge dataset (Zhang and Lapata, 2017) which contains 296,402/2,000/359 samples (train/validation/test). WikiLarge is a set of automatically aligned complex-simple sentence pairs from English Wikipedia (EW) and Simple English Wikipedia (SEW). It is compiled from previous extractions of EW-SEW (Zhu et al., 2010; Woodsend and Lapata, 2011; Kauchak, 2013). Its validation and test sets are taken from Turkcorpus (Xu 2 We did not investigate predicting ratios on a per sentence basis as done by Scarton and Specia (2018), and leave this for future work. End-users can nonetheless choose the target ratios as they see fit, for each source sentence. 3 Code and pretrained models are released with an open-source license at https://github.com/facebookresearch/access. 4691 et al., 2016), where each complex sentence has 8 human simplifications created by Amazon Mechanical Turk workers. Human annotators were instructed to only paraphrase the source sentences"
2020.lrec-1.577,D16-1140,0,0.543181,"sed on developing models that generate a single generic simplification for a given source text with no possibility to adapt outputs for the needs of various target populations. In this paper, we propose a controllable simplification model that provides explicit ways for users to manipulate and update simplified outputs as they see fit. This work only considers the task of Sentence Simplification (SS) where the input of the model is a single source sentence and the output can be composed of one sentence or split into multiple. Our work builds upon previous work on controllable text generation (Kikuchi et al., 2016; Fan et al., 2017; Scarton and Specia, 2018; Nishihara et al., 2019) where a Sequence-toSequence (Seq2Seq) model is modified to control attributes of the output text. We tailor this mechanism to the task of SS by considering relevant attributes of the output sentence such as the output length, the amount of paraphrasing, lexical complexity, and syntactic complexity. To this end, we condition the model at train time, by feeding parameter tokens representing these attributes along with the source sentence as additional inputs. Our contributions are the following: (1) We adapt a parametrization"
2020.lrec-1.577,D18-1267,0,0.115508,"2018) or trained with multi-tasking on entailment and paraphrase generation (Guo et al., 2018). 4689 This work builds upon Seq2Seq as well. We prepend additional inputs to the source sentences at train time, in the form of plain text special tokens. Our approach does not require any external data or modified training objective. 2.2. Controllable Text Generation Conditional training with Seq2Seq models was applied to multiple natural language processing tasks such as summarization (Kikuchi et al., 2016; Fan et al., 2017), dialog (See et al., 2019), sentence compression (Fevry and Phang, 2018; Mallinson et al., 2018) or poetry generation (Ghazvininejad et al., 2017). Most approaches for controllable text generation are either decoding-based or learning-based. Decoding-based methods Decoding-based methods use a standard Seq2Seq training setup but modify the system during decoding to control a given attribute. For instance, the length of summaries was controlled by preventing the decoder from generating the End-Of-Sentence token before reaching the desired length or by only selecting hypotheses of a given length during the beam search (Kikuchi et al., 2016). Weighted decoding (i.e. assigning weights to spec"
2020.lrec-1.577,P14-1041,0,0.0947046,"Missing"
2020.lrec-1.577,P19-2036,0,0.424028,"tion for a given source text with no possibility to adapt outputs for the needs of various target populations. In this paper, we propose a controllable simplification model that provides explicit ways for users to manipulate and update simplified outputs as they see fit. This work only considers the task of Sentence Simplification (SS) where the input of the model is a single source sentence and the output can be composed of one sentence or split into multiple. Our work builds upon previous work on controllable text generation (Kikuchi et al., 2016; Fan et al., 2017; Scarton and Specia, 2018; Nishihara et al., 2019) where a Sequence-toSequence (Seq2Seq) model is modified to control attributes of the output text. We tailor this mechanism to the task of SS by considering relevant attributes of the output sentence such as the output length, the amount of paraphrasing, lexical complexity, and syntactic complexity. To this end, we condition the model at train time, by feeding parameter tokens representing these attributes along with the source sentence as additional inputs. Our contributions are the following: (1) We adapt a parametrization mechanism to the specific task of Sentence Simplification by conditio"
2020.lrec-1.577,P17-2014,0,0.232541,"Missing"
2020.lrec-1.577,N19-4009,0,0.0706498,"Missing"
2020.lrec-1.577,P02-1040,0,0.107131,"SS. Plain text special tokens were used to encode attributes such as the target school grade-level • Paraphrasing: Paraphrasing is an important aspect for good text simplification systems (Wubben et al., 2012), especially because it allows the user from choosing if he prefers very safe simplifications (i.e. close to the source) or to try and simplify the input more at the cost of more mistakes when using imperfect systems. The amount of paraphrasing was also shown to correlate with human jugdment of meaning preservation and simplicity sometimes even more than traditional metrics such as BLEU (Papineni et al., 2002) and SARI (Xu et al., 2016). • Lexical and Syntactic complexity: (Shardlow, 2014) identified lexical simplification and syntactic simplification as core components of SS systems, which often decomposes there approach into these two subcomponents. Audiences also have different simplification needs along these two attributes. In order to understand a text correctly, second language learner will require a text with less complicated words. On the other hand, some specific types of aphasia will make people struggle more with complex syntactic structures, intricated clauses, and long sentence, thus"
2020.lrec-1.577,P16-2024,0,0.0509818,"ng, combined with a lexical simplification model. Pointer+Ent+Par (Guo et al., 2018) Seq2Seq model based on the pointer-copy mechanism and trained via multi-task learning on the Entailment and Paraphrase Generation tasks. NTS+SARI (Nisioi et al., 2017) Standard Seq2Seq model. The second beam search hypothesis is selected during decoding; the hypothesis number is an hyper-parameter fine-tuned with SARI. NSELSTM-S (Vu et al., 2018) Seq2Seq with a memory-augmented Neural Semantic Encoder, tuned with SARI. DMASS+DCSS (Zhao et al., 2018) Seq2Seq integrating the simple PPDB simplification database (Pavlick and Callison-Burch, 2016) as a dynamic memory. The database is also used to modify the loss and re-weight word probabilities to favor simpler words. We select the model with the best SARI on the validation set and report its score on the test set. This model uses three 4692 Figure 1: Density distribution of the compression ratios between the source sentence and the target sentence. The automatically aligned pairs from WikiLarge train set are spread (red) while human simplifications from the validation and test set (green) are gathered together with a mean ratio of 0.93 (i.e. nearly no compression). parameter tokens ou"
2020.lrec-1.577,P15-2070,0,0.0568582,"Missing"
2020.lrec-1.577,P18-2113,0,0.787515,"single generic simplification for a given source text with no possibility to adapt outputs for the needs of various target populations. In this paper, we propose a controllable simplification model that provides explicit ways for users to manipulate and update simplified outputs as they see fit. This work only considers the task of Sentence Simplification (SS) where the input of the model is a single source sentence and the output can be composed of one sentence or split into multiple. Our work builds upon previous work on controllable text generation (Kikuchi et al., 2016; Fan et al., 2017; Scarton and Specia, 2018; Nishihara et al., 2019) where a Sequence-toSequence (Seq2Seq) model is modified to control attributes of the output text. We tailor this mechanism to the task of SS by considering relevant attributes of the output sentence such as the output length, the amount of paraphrasing, lexical complexity, and syntactic complexity. To this end, we condition the model at train time, by feeding parameter tokens representing these attributes along with the source sentence as additional inputs. Our contributions are the following: (1) We adapt a parametrization mechanism to the specific task of Sentence S"
2020.lrec-1.577,N19-1170,0,0.0475922,"Missing"
2020.lrec-1.577,N16-1005,0,0.0785006,"r each attribute value. (Hu et al., 2017) achieved controlled text generation by disentangling the latent space representations of a variational auto-encoder between the text representation and its controlled attributes such as sentiment and tense. They impose the latent space structure during training by using additional discriminators. Our work uses a simpler approach: we condition the generation process by concatenating plain text special tokens to the source text. This method only modifies the source data and not the training procedure. Such mechanism was used to control politeness in MT (Sennrich et al., 2016), to control summaries in terms of length, of news source style, or to make the summary more focused on a given named entity (Fan et al., 2017). Scarton and Specia (2018) and Nishihara et al. (2019) similarly showed that adding special tokens at the beginning of sentences can improve the performance of Seq2Seq models for SS. Plain text special tokens were used to encode attributes such as the target school grade-level • Paraphrasing: Paraphrasing is an important aspect for good text simplification systems (Wubben et al., 2012), especially because it allows the user from choosing if he prefers"
2020.lrec-1.577,D18-1081,0,0.198008,"Missing"
2020.lrec-1.577,N18-2013,0,0.341706,"Missing"
2020.lrec-1.577,D11-1038,0,0.147036,"the NLTK NIST tokenizer and preprocess using SentencePiece (Kudo and Richardson, 2018) with 10k vocabulary size to handle rare and unknown words. For generation we use beam search with a beam size of 8. 3 Training and evaluation datasets Our models are trained and evaluated on the WikiLarge dataset (Zhang and Lapata, 2017) which contains 296,402/2,000/359 samples (train/validation/test). WikiLarge is a set of automatically aligned complex-simple sentence pairs from English Wikipedia (EW) and Simple English Wikipedia (SEW). It is compiled from previous extractions of EW-SEW (Zhu et al., 2010; Woodsend and Lapata, 2011; Kauchak, 2013). Its validation and test sets are taken from Turkcorpus (Xu 2 We did not investigate predicting ratios on a per sentence basis as done by Scarton and Specia (2018), and leave this for future work. End-users can nonetheless choose the target ratios as they see fit, for each source sentence. 3 Code and pretrained models are released with an open-source license at https://github.com/facebookresearch/access. 4691 et al., 2016), where each complex sentence has 8 human simplifications created by Amazon Mechanical Turk workers. Human annotators were instructed to only paraphrase the"
2020.lrec-1.577,P12-1107,0,0.656872,"Missing"
2020.lrec-1.577,W16-0502,0,0.0231397,"nd for AudienCe-CEntric Sentence Simplification), establishes the state of the art at 41.87 SARI on the WikiLarge test set, a +1.42 improvement over the best previously reported score. Keywords: Text Simplification, Sequence-to-Sequence models, ACCESS 1. Introduction In Natural Language Processing, the Text Simplification task aims at making a text easier to read and understand. Text simplification can be beneficial for people with cognitive disabilities such as aphasia (Carroll et al., 1998), dyslexia (Rello et al., 2013) and autism (Evans et al., 2014) but also for second language learners (Xia et al., 2016) and people with low literacy (Watanabe et al., 2009). The type of simplification needed for each of these audiences is different. Some aphasic patients struggle to read sentences with a high cognitive load such as long sentences with intricate syntactic structures, whereas second language learners might not understand texts with rare or specific vocabulary. Yet, research in text simplification has been mostly focused on developing models that generate a single generic simplification for a given source text with no possibility to adapt outputs for the needs of various target populations. In th"
2020.lrec-1.577,Q16-1029,0,0.106759,"these attributes along with the source sentence as additional inputs. Our contributions are the following: (1) We adapt a parametrization mechanism to the specific task of Sentence Simplification by conditioning on relevant attributes; (2) We show through a detailed analysis that our model can indeed control the considered attributes, making the simplifications potentially able to fit the needs of various end audiences; (3) With careful calibration, our controllable parametrization improves the performance of out-of-thebox Seq2Seq models leading to a new state-of-the-art score of 41.87 SARI (Xu et al., 2016) on the WikiLarge benchmark (Zhang and Lapata, 2017), a +1.42 gain over previous scores, without requiring any external resource or modified training objective. 2. 2.1. Related Work Sentence Simplification Text simplification has gained increasing interest through the years and has benefited from advances in Natural Language Processing and notably Machine Translation. In recent years, SS was largely treated as a monolingual variant of machine translation (MT), where simplification operations are learned from complex-simple sentence pairs automatically extracted from English Wikipedia and Simpl"
2020.lrec-1.577,D17-1062,0,0.48392,"nce as additional inputs. Our contributions are the following: (1) We adapt a parametrization mechanism to the specific task of Sentence Simplification by conditioning on relevant attributes; (2) We show through a detailed analysis that our model can indeed control the considered attributes, making the simplifications potentially able to fit the needs of various end audiences; (3) With careful calibration, our controllable parametrization improves the performance of out-of-thebox Seq2Seq models leading to a new state-of-the-art score of 41.87 SARI (Xu et al., 2016) on the WikiLarge benchmark (Zhang and Lapata, 2017), a +1.42 gain over previous scores, without requiring any external resource or modified training objective. 2. 2.1. Related Work Sentence Simplification Text simplification has gained increasing interest through the years and has benefited from advances in Natural Language Processing and notably Machine Translation. In recent years, SS was largely treated as a monolingual variant of machine translation (MT), where simplification operations are learned from complex-simple sentence pairs automatically extracted from English Wikipedia and Simple English Wikipedia (Zhu et al., 2010; Wubben et al."
2020.lrec-1.577,D18-1355,0,0.646117,"ak, 2011) and candidate reranking (Wubben et al., 2012). The candidate reranking method by Wubben et al. (2012) favors simplifications that are most dissimilar to the source using Levenshtein distance. The authors argue that dissimilarity is a key factor of simplification. Lately, SS has mostly been tackled using Seq2Seq MT models (Sutskever et al., 2014). Seq2Seq models were either used as-is (Nisioi et al., 2017) or combined with reinforcement learning thanks to a specific simplification reward (Zhang and Lapata, 2017), augmented with an external simplification database as a dynamic memory (Zhao et al., 2018) or trained with multi-tasking on entailment and paraphrase generation (Guo et al., 2018). 4689 This work builds upon Seq2Seq as well. We prepend additional inputs to the source sentences at train time, in the form of plain text special tokens. Our approach does not require any external data or modified training objective. 2.2. Controllable Text Generation Conditional training with Seq2Seq models was applied to multiple natural language processing tasks such as summarization (Kikuchi et al., 2016; Fan et al., 2017), dialog (See et al., 2019), sentence compression (Fevry and Phang, 2018; Mallin"
2020.lrec-1.577,C10-1152,0,0.572576,"chmark (Zhang and Lapata, 2017), a +1.42 gain over previous scores, without requiring any external resource or modified training objective. 2. 2.1. Related Work Sentence Simplification Text simplification has gained increasing interest through the years and has benefited from advances in Natural Language Processing and notably Machine Translation. In recent years, SS was largely treated as a monolingual variant of machine translation (MT), where simplification operations are learned from complex-simple sentence pairs automatically extracted from English Wikipedia and Simple English Wikipedia (Zhu et al., 2010; Wubben et al., 2012). Phrase-based and Syntax-based MT was successfully used for SS (Zhu et al., 2010) and further tailored to the task using deletion models (Coster and Kauchak, 2011) and candidate reranking (Wubben et al., 2012). The candidate reranking method by Wubben et al. (2012) favors simplifications that are most dissimilar to the source using Levenshtein distance. The authors argue that dissimilarity is a key factor of simplification. Lately, SS has mostly been tackled using Seq2Seq MT models (Sutskever et al., 2014). Seq2Seq models were either used as-is (Nisioi et al., 2017) or c"
2020.lrec-1.577,Q15-1021,0,0.245796,"Missing"
C02-1028,N01-1022,1,\N,Missing
C02-1028,P92-1018,0,\N,Missing
C02-1028,W02-2228,1,\N,Missing
C08-1080,2005.jeptalnrecital-long.1,1,0.856072,"Missing"
C08-1080,P04-1057,0,0.346299,"Missing"
C08-1080,zhang-kordoni-2006-automated,0,0.0761505,"ole system has been explained with details, we will expose the similarities and differences of our methods with previously publicated ones. 8 Related works Since efﬁcient and linguistically relevant lexical and grammatical formalisms have been developed, the acquisition/extension/correction of linguistic ressources has been an active research ﬁeld, especially during the last decade. The idea to infer lexical data from the grammatical context ﬁrst appeared in 1990 (Erbach, 1990). The combination with error mining/detection technique, such as van Noord (2004), begun in 2006 (van de Cruys, 2006; Yi and Kordoni, 2006). Except in our previous work (2007), nobody has combined it with the technique described in Sagot and Villemonte de La Clergerie (2006). The idea of preﬁltering the sentences (Sec. 3.2) to improve the error mining performance has never been applied so far. The wildcards generation started to be reﬁned with Barg and Walther (1998). Since then, the wildcards are partially underspeciﬁed and restrained to open class POS. In Yi and Kordoni (2006), the authors use an elegant technique based on an entropy classiﬁer to select the most adequate wildcards. The way to rank the corrections is usually bas"
C08-1080,P98-1014,0,0.170741,"ctive research ﬁeld, especially during the last decade. The idea to infer lexical data from the grammatical context ﬁrst appeared in 1990 (Erbach, 1990). The combination with error mining/detection technique, such as van Noord (2004), begun in 2006 (van de Cruys, 2006; Yi and Kordoni, 2006). Except in our previous work (2007), nobody has combined it with the technique described in Sagot and Villemonte de La Clergerie (2006). The idea of preﬁltering the sentences (Sec. 3.2) to improve the error mining performance has never been applied so far. The wildcards generation started to be reﬁned with Barg and Walther (1998). Since then, the wildcards are partially underspeciﬁed and restrained to open class POS. In Yi and Kordoni (2006), the authors use an elegant technique based on an entropy classiﬁer to select the most adequate wildcards. The way to rank the corrections is usually based on a trained tool (van de Cruys, 2006; Yi and Kordoni, 2006), such as an entropy classiﬁer. Surprisingly, the evaluation of hypotheses on various sentences for a same suspicious form in order to discriminate the irrelevant ones has never been considered so far. Finally, all the previous works were achieved with HPSG parsers and"
C08-1080,E03-1041,0,0.23142,"arsing originally non-parsable sentences with wildcards As explained in Sect. 2, in order to generate lexical corrections, we ﬁrst need to get as close as possible to the set of parses that the grammar would have allowed with an error-free lexicon. We achieve this goal by replacing in the associated sentences every suspicious forms with special underspeciﬁed forms called wildcards. The simplest way would be to use totally underspeciﬁed wildcards. Indeed, this would have the beneﬁt to cover all kinds of conﬂicts and thus, it would notably increase the parsing coverage. However, as observed by (Fouvry, 2003), it introduces an unnecessary ambiguity which usually leads to a severe overgeneration of parses or to no parses at all because of time or memory shortage. In a metaphorical way, we said that we wanted the grammar to tell us what lexical information it would have accepted for the suspicious form. Well, by introducing a totally underspeciﬁed wildcard, either the grammar has so many things to say that it is hard to know what to listen to, or it has so many things to think about that it stutters and does not say anything at all. Therefore, we reﬁned the wildcard by introduc635 ing some data. For"
C08-1080,C98-1014,0,\N,Missing
C08-1080,P06-1042,1,\N,Missing
C08-1080,sagot-etal-2006-lefff,1,\N,Missing
candito-etal-2014-deep,candito-etal-2010-statistical,1,\N,Missing
candito-etal-2014-deep,de-marneffe-etal-2006-generating,0,\N,Missing
candito-etal-2014-deep,J93-2004,0,\N,Missing
candito-etal-2014-deep,W09-4624,0,\N,Missing
candito-etal-2014-deep,H94-1020,0,\N,Missing
candito-etal-2014-deep,P05-1011,0,\N,Missing
candito-etal-2014-deep,P04-1041,0,\N,Missing
candito-etal-2014-deep,W00-1436,0,\N,Missing
candito-etal-2014-deep,J05-1004,0,\N,Missing
candito-etal-2014-deep,W13-3724,0,\N,Missing
candito-etal-2014-deep,abeille-barrier-2004-enriching,0,\N,Missing
E99-1020,P98-2217,1,0.833006,"Missing"
E99-1020,W98-0111,1,0.840228,"Missing"
E99-1020,P88-1032,0,0.0393998,"inuum from simple pure bottom-up algorithms to complex predictive algorithms and showing what transformations must be applied to each one in order to obtain the next one in the continuum. 1 Introduction Tree Adjoining Grammars are a extension of CFG introduced by Joshi in (Joshi, 1987) that use trees instead of productions as the primary representing structure. Several parsing algorithms have been proposed for this formalism, most of them based on tabular techniques, ranging from simple bottom-up algorithms (Vijay-Shanker and Joshi, 1985) to sophisticated extensions of the Earley&apos;s algorithm (Schabes and Joshi, 1988; Schabes, 1994; Nederhof, 1997). However, it is difficult to inter-relate different parsing algorithms. In this paper we study several tabular algorithms for TAG parsing, showing their common characteristics and how one algorithm can be derived from another in turn, creating a continuum from simple pure bottom-up to complex predictive algorithms. Formally, a TAG is a 5-tuple ~ = (VN,VT, S , I , A ) , where VN is a finite set of non-terminal symbols, VT a finite set of terminal 150 symbols, S the axiom of the grammar, I a finite set of initial trees and A a finite set of auxiliary trees. I U A"
E99-1020,J94-1004,0,0.0654891,"d Joshi, 1985) in order to avoid several adjunctions on a node. A value of true indicates that an adjunction has taken place in the node N r and therefore further adjunctions on the same node are forbidden. A value of false indicates that no adjunction was performed on that node. In this case, during future processing this item can play the role of the item recognizing the excised part of an elemetitary tree to be attached to the foot node of an auxiliary tree. As a consequence, only one adjunction can take place on an elementary node, as is prescribed by the tree adjoining grammar formalism (Schabes and Shieber, 1994). As an additional advantage, the algorithm does not need to require the restriction that every auxiliary tree must have at least one terminal symbol in its frontier (Vijay-Shanker and Joshi, 1985). S c h e m a 1 The parsing systems ]PCYK corresponding to the CYK-line algorithm for a tree adjoining grammar G and an input string a l . . . an is defined as follows: } I C Y K = { [N 7 , i , j l p , q l a d j ] such that N ~ • 79(7), label(Nr) • VN, 7 E I U A , 0 &lt; i &lt; j, (p,q) &lt;_ (i,j), adj e {true, false} 7&quot;~Cy K = { [a, i -- 1, i] I a = ai, 1 &lt; i &lt; n } [a, i - 1, if ~Scan CYK = [ N r , i - 1, i"
E99-1020,1991.iwpt-1.4,0,0.056192,"for any substring al .. • ak read from the input string al . • • akak+ l • . . an guarantees t h a t there is a string of tokens bl . . . b i n , where bi need not be part of the input string, such that al . . . akbl . .. bm is a valid string of the language. To maintain the valid prefix property, the parser must recognize all possible derived trees in prefix form. In order to do that, two different phases must work coordinately: a top-down phase t h a t expands the children of each node visited and a bottom-up phase grouping the children nodes to indicate the recognition of the parent node (Schabes, 1991). During the recognition of a derived tree in prefix form, node expansion can depend on adjunction operations performed in the previously visited part of the tree. Due to this kind of dependencies the set path is a context-free language (VijayShanker et al., 1987). A b o t t o m - u p algorithm (e.g. CYK-like or b o t t o m - u p Eaxley-like) can stack the dependencies shown by the context-free language defining the path-set. This is sufficient to get a correct parsing algorithm, but without the valid prefix property. To preserve this property the algorithm must have a top-down phase which als"
E99-1020,P85-1011,0,0.373786,"algorithms for Tree Adjoining G r a m m a r parsing, creating a continuum from simple pure bottom-up algorithms to complex predictive algorithms and showing what transformations must be applied to each one in order to obtain the next one in the continuum. 1 Introduction Tree Adjoining Grammars are a extension of CFG introduced by Joshi in (Joshi, 1987) that use trees instead of productions as the primary representing structure. Several parsing algorithms have been proposed for this formalism, most of them based on tabular techniques, ranging from simple bottom-up algorithms (Vijay-Shanker and Joshi, 1985) to sophisticated extensions of the Earley&apos;s algorithm (Schabes and Joshi, 1988; Schabes, 1994; Nederhof, 1997). However, it is difficult to inter-relate different parsing algorithms. In this paper we study several tabular algorithms for TAG parsing, showing their common characteristics and how one algorithm can be derived from another in turn, creating a continuum from simple pure bottom-up to complex predictive algorithms. Formally, a TAG is a 5-tuple ~ = (VN,VT, S , I , A ) , where VN is a finite set of non-terminal symbols, VT a finite set of terminal 150 symbols, S the axiom of the gramma"
E99-1020,J93-4002,0,0.050513,", j I P&apos;,q&apos;] [h, N&apos;r -+ 5M&apos;r • v, i, m I P U p&apos;, q U q&apos;] 155 ~DInit I.J ~DScan LJ &quot;FIPred II Earley Earley ~Earley ~ ~)Comp ,/-)Adj Pred q-)FootPredl i Earley [&apos;j ~ E a r l e y I.J ~ E a r l e y &quot;-&quot; ~)FootComp &quot;/3AdjC°mpl It q&apos;~AdjC°rnp2 Earley IJ ~ E a r l e y &quot;-&quot; ~ E a r l e y Proceedings of EACL &apos;99 &quot;DAdjC°mpl into Now, we must refine steps in &apos;~&apos;Earley ~)AdjC°mp° a n d ~) AdjC°mpff steps in Earley Earley , and req-)AdjComp ° into steps in ~Earley fine steps in q&apos;)AdjC°rnp2 ,iEarley and q&apos;)AdjC°mp2&apos; Correctness of these splittings ~Earley is guaranteed by the context-free property of TA G (Vijay-Shanker and Weir, 1993) establishing the independence of each adjunction with respect to any other adjunction. After step refinement, we get the Earley-like parsing algorithm for TAG described in (Nederhof, 1997), which preserves the valid prefix property having a time complexity O(n 6) with respect to the input string. In this schema we also need to define a new kind of intermediate pseudo-items [[g r --+ 5 • u, i, j I P, q]] such that 5 ~ a i . . . a p F &quot;y a q + l . . . a j ~ a i . . . a j if and only if (p, q) ¢ ( - , - ) and 6 :~ a i . . . aj if and only if (p, q) = ( - , - ) . S c h e m a 5 The parsing system"
E99-1020,P87-1015,0,0.264289,"Missing"
E99-1020,H86-1020,0,\N,Missing
E99-1020,C98-2212,1,\N,Missing
F14-1007,E12-2012,0,0.0550648,"Missing"
F14-1007,C10-1011,0,0.0481027,"Missing"
F14-1007,candito-etal-2010-statistical,0,0.0491991,"Missing"
F14-1007,C10-2013,0,0.0391657,"Missing"
F14-1007,P13-1104,0,0.0433667,"Missing"
F14-1007,Y09-1013,0,0.0248895,"Missing"
F14-1007,P13-2111,0,0.050978,"Missing"
F14-1007,N12-1015,0,0.0569188,"Missing"
F14-1007,P10-1110,0,0.0830931,"Missing"
F14-1007,W12-3412,0,0.0218036,"Missing"
F14-1007,W03-3017,0,0.122126,"Missing"
F14-1007,P09-2010,0,0.0663915,"Missing"
F14-1007,N06-2033,0,0.087076,"Missing"
F14-1007,sagot-etal-2006-lefff,1,0.854937,"Missing"
F14-1007,W13-4917,1,0.875064,"Missing"
F14-1007,W13-4906,1,0.843034,"Missing"
F14-1007,W13-5706,1,0.836663,"Missing"
gabor-etal-2012-boosting,vilnat-etal-2010-passage,1,\N,Missing
gabor-etal-2012-boosting,S07-1002,0,\N,Missing
gabor-etal-2012-boosting,C92-2082,0,\N,Missing
gabor-etal-2012-boosting,C08-1084,0,\N,Missing
gabor-etal-2012-boosting,J02-3004,0,\N,Missing
gabor-etal-2012-boosting,2010.jeptalnrecital-court.19,0,\N,Missing
K17-3026,L16-1262,0,\N,Missing
K17-3026,W14-6111,1,\N,Missing
K18-2023,N15-1184,0,0.0693335,"Missing"
K18-2023,L16-1262,0,0.0200927,"Missing"
K18-2023,N18-1202,0,0.227629,"eate a high performing graph parser, we implement a large BiLSTM-LM network (independent of the ELMoLex parser) which is highly regularized to prevent data overfitting and able to learn useful features. Our BiLSTM-LM consumes both the word and tag embedding as input, which can be formally written as: LM (word) = vi xLM i LM (word) vi = LM (U P oS) ⊕ vi LM (f air) vi ⊕ , (3) LM (char) vi . LM (f air) LM (char) In equation 3, the notations vi , vi LM (U P oS) GP (f air) and vi are the counterparts of vi , GP (char) GP (U P oS) vi and vi respectively. Note that ELMo, as proposed in Peters et al. (2018), builds only on character embeddings, automatically inferring the PoS information in the lower layers of the LSTM network. Since we have less training data to work with, we feed the PoS information explicitly which helps in easening the optimization process of our BiLSTM-LM network. Given a sequence of n LM words, xLM 1 , . . . , xn , BiLSTM-LM learns by maximizing the log likelihood of forward LSTM and backward LSTM directions, which can be defined as: n ∑ − → − → (log Pr(xLM |xLM , . . . , xLM i 1 i−1 ; Θx ; Θ LST M , Θ s )) i=1 ← − ← − LM |xLM (4) + (log Pr(xLM i i+1 , . . . , xn ; Θx ; Θ"
K18-2023,C16-1030,0,0.0323741,"is problem, ELMoLex relies on four signals from the proposed embedding layer: fi_pud sv_pud cs_pud Table 1: Treebanks to source the training data for Delexicalized Parsing of a given target treebank. GP (lex) (vi ) can be computed as follows:9 GP (lex) vi = m ∑ GP (mf ) slex mfj vmfj . (7) j=1 In equation 7, slex mfj corresponds to the softmaxnormalized weight which is a learnable parameter for each available morphological feature (in this case, it is mfj ). The general idea to perform a weighted sum to extract relevant features has been previously studied in the context of sequence labeling (Rei et al., 2016) for integrating word and character level features. Combining the distributional knowledge of words along with the semantic lexicons has been extensively studied for estimating high quality word vectors, also referred to as ‘retrofitting’ in literature (Faruqui et al., 2015). 2.4 Delexicalized Parsing We perform delexicalized “language family” parsing for treebanks with less than 50 or no train sentences (as shown in Table 1). The delexicalized version of ELMoLex throws away word-level information such as vGP (word) and vGP (char) and works with the rest. The source treebanks are concatenated"
K18-2023,L18-1292,1,0.815553,"They exploit the relevant sub-parts of a word such as suffixes or prefixes to generate word representations. They can generalize to unknown words if these unknown words follow such generalizations. Otherwise, they fail to add any improvement (Sagot and Martínez Alonso, 2017) and we may need to look for other sources to complement the information provided by characterlevel embeddings. We term this problem as linguistic naivety. ELMoLex taps into the large inventory of morphological features (gender, number, case, tense, mood, person, etc.) provided by external resources, namely the UDLexicons (Sagot, 2018) lexicon collection, which cover words with an irregular morphology as well as words not present in the training data. Essentially, these lexicons consist of ⟨word, UPoS, morphological features⟩ triplets, which we query using ⟨word, UPoS⟩ pair resulting in one or more hits. When we attempt to integrate the information from these hits, we face the challenge of disambiguation as not all the morphological features returned by the query are relevant to the focal ⟨word, UPoS⟩ pair. ELMoLex relies on attention mechanism (Bahdanau et al., 2014) to select the relevant morphological features, thereby h"
K18-2023,W17-6304,1,0.857446,"Missing"
L16-1566,abeille-barrier-2004-enriching,0,0.019001,"Missing"
L16-1566,D15-1198,0,0.0286923,"Missing"
L16-1566,C14-1133,0,0.0608899,"Missing"
L16-1566,W13-2322,0,0.0242684,"Missing"
L16-1566,P14-1133,0,0.0557857,"Missing"
L16-1566,D13-1160,0,0.0454701,"Missing"
L16-1566,W14-2403,0,0.0220893,"Missing"
L16-1566,candito-etal-2010-statistical,0,0.0652301,"Missing"
L16-1566,candito-etal-2014-deep,1,0.774948,"Missing"
L16-1566,W05-0620,0,0.0187297,"Missing"
L16-1566,W03-1006,0,0.15127,"Missing"
L16-1566,W11-2924,0,0.0721923,"Missing"
L16-1566,P14-1134,0,0.158908,"ally-oriented tasks such as question-answering systems (Berant et al., 2013). This is because many predicate-argument dependencies, such as those arising for instance in control-verb constructions, it-cleft constructions, participle clauses and so on, are lacking from the annotation schemes underlying most data set used by surface syntactic parsers. Representing such constructs in a dependency scheme often leads to graph representations, which are a real challenge to predict, as shown, for example, by the performance obtained in Abstract Meaning Representation parsing (Banarescu et al., 2013; Flanigan et al., 2014; Artzi et al., 2015) or in graph-based semantic dependency parsing (Oepen et al., 2014). Even though some recent works have made good progresses in parsing full-fledged semantic structures (Beschke et al., 2014; Berant and Liang, 2014), they mostly focus on English.1 We propose to dig into that direction by relying on the recent release of a deep syntactic graphbank for French, the D EEP FTB, (Ribeyre et al., 2014a), whose deep syntactic graphs were automatically annotated on top of the dependency version of the French Treebank (Abeillé and Barrier, 2004; Candito et al., 2010). In order to dr"
L16-1566,S14-2082,0,0.01396,"governing a token. These give a wider pobj = 1 = 1 =1 context to the parser whereas the spines are viewed as de=2 3. Graph Parsing terministic supertags bringing a vertical context. Table 2 Schémaan desoverview traits syntaxiques. Le cercle accuracy autour de of PPour marque An increasing number of works have been proposed Figure over 8.9: presents of the expected fea- son appartenance à deux types de traits: BKY (fragment d’arbres) et Head Path. the last few years to cope with graphs (Sagae and Tsujii, tures via the scores of their respective source parsers. The 2008; Flanigan et al., 2014; Martins and Almeida, 2014), feature set is shown in Figure 2. whether acyclic or not. Because it has been shown to be one of the top performers on the SemEval 2014 shared task Head S Path Spine (Oepen et al., 2014), we reuse the higher-order arc-factored (w = 4) parser of (Martins and Almeida, 2014) (TSPARSER), which NP VP takes advantage of dual decomposition methods based on AD3 (Martins et al., 2011). Another motivation for using BKY D N V PP this parser is that we want to assess whether using predicted syntactic features, which do provide additional context, is beneficial even when using a globally optimized parser"
L16-1566,D11-1022,0,0.0378718,"Missing"
L16-1566,J08-2003,0,0.0912556,"Missing"
L16-1566,S14-2008,0,0.18444,"use many predicate-argument dependencies, such as those arising for instance in control-verb constructions, it-cleft constructions, participle clauses and so on, are lacking from the annotation schemes underlying most data set used by surface syntactic parsers. Representing such constructs in a dependency scheme often leads to graph representations, which are a real challenge to predict, as shown, for example, by the performance obtained in Abstract Meaning Representation parsing (Banarescu et al., 2013; Flanigan et al., 2014; Artzi et al., 2015) or in graph-based semantic dependency parsing (Oepen et al., 2014). Even though some recent works have made good progresses in parsing full-fledged semantic structures (Beschke et al., 2014; Berant and Liang, 2014), they mostly focus on English.1 We propose to dig into that direction by relying on the recent release of a deep syntactic graphbank for French, the D EEP FTB, (Ribeyre et al., 2014a), whose deep syntactic graphs were automatically annotated on top of the dependency version of the French Treebank (Abeillé and Barrier, 2004; Candito et al., 2010). In order to draw meaningful comparisons with recent results for English, we use the same types of feat"
L16-1566,P09-2010,0,0.0281423,"coordinated heads and (iv) inverted dependencies in the case of modifying verbs or adjectives (for instance, in (the French counterpart) of ’Children born after 2010 get free tickets’, the participle born both modifies the noun Children, and has this noun as (deep) subject). Moreover, semantically empty functional words are marked as such, and “shunted off” (for instance in ’Anna a parlé à Paul’ (Anna has talked to Paul), both the auxiliary and the prepo3563 sition à are marked as empty, and Paul is directly linked to TAG-based Dependencies (FRMG) As opposed to most the verb). previous works (Øvrelid et al., 2009), we use dependencies features extracted from a hand-written wide-coverage TAGAs with the DM corpus (Oepen et al., 2014), D EEP FTB 4 de la syntaxe de traits : based3 metagrammar (Fprofonde R MG, (de au La moyen Clergerie, 2010)).syntaxiques is comparable in the sense that the semantic arguments8.3. of Prédiction approche à l’état de l’art verbs and adjectives are made explicit, but it leans a litTree Fragments (BKY) These consist of fragments of tle less towards a semantic representation (hence the “deep syntactic constituency trees. They have been extracted ussyntactic” name). In particular"
L16-1566,P06-1055,0,0.0746912,"the impact of topologically different syntactic features 5. Experiments & Discussion extracted from the surfacic syntax and their respective combinations. Both our surfacic parsers use the French Experiments Table 3 displays the baseline scores, the Treebank (Abeillé et al., 2003) in its (Seddah et al., 2013) scores for each type of features separately and our best instance, with predicted POS and morphological features. models. As we can see, our baseline is weak especially The constituency features come from the Berkeley Parser in term of recall, leading us to believe that it is indeed dif(Petrov et al., 2006) trained in a 10-fold jackkniffing ficult to recover the deep structure. Whereas the parser exsetting. Respective parsers’ performance scores are shown plores a large part of the search space, it seems to need more in Table 2. 3 2 The authors wanted to differentiate graphs for X is impossible and an impossible X: if the copula is ignored, it only remains the same impossible −→ X dependency. Tree Adjoining Grammars (Joshi and Schabes, 1997). This parser generates dependency trees after disambiguation and conversion from a shared derivation forest (Villemonte De La Clergerie, 2013b). 3564 4 ARG2"
L16-1566,W12-4625,1,0.779531,"t Test set D EEP FTB DM B EST (TSPARSER ) B EST (DYAL OG -SR) 85.18 82.92 89.70 85.66 BASELINE (TSPARSER ) BASELINE (DYAL OG -SR) 80.79 75.42 88.08 83.91 TSPARSER ( SURF.)+ RULES 80.45 - Table 4: Comparison of baselines and best LF results for D EEP FTB and DM. (D EEP FTB’s best: FRMG + PATHS + SPINES & DM’s best: BN + SPINES + PATHS). Table 4 reports a comparison between the best results for D EEP FTB and DM and the baseline for both parsers. The last row includes results from the TSPARSER, trained on the F TB surface dependencies,6 whose outputs were fed to a tree-to-graph rewriting system (Ribeyre et al., 2012), following Ribeyre (2016).7 This setup provides slightly inferior performance than the TSPARSER baseline parser and is vastly over-performed by our best setup (by almost 5pt). Despite validating our approach, this leads us to wonder if a graph-to-graph rewriting system could not be developed to push the envelope even further. This is left for future work. Interestingly enough, except for the fact that our feature set generalizes well with another parser, we see that the best model for both corpora are of the same kind: mixing dependencies information with spinal trees and head paths. Even tou"
L16-1566,S14-2012,1,0.838229,"graph representations, which are a real challenge to predict, as shown, for example, by the performance obtained in Abstract Meaning Representation parsing (Banarescu et al., 2013; Flanigan et al., 2014; Artzi et al., 2015) or in graph-based semantic dependency parsing (Oepen et al., 2014). Even though some recent works have made good progresses in parsing full-fledged semantic structures (Beschke et al., 2014; Berant and Liang, 2014), they mostly focus on English.1 We propose to dig into that direction by relying on the recent release of a deep syntactic graphbank for French, the D EEP FTB, (Ribeyre et al., 2014a), whose deep syntactic graphs were automatically annotated on top of the dependency version of the French Treebank (Abeillé and Barrier, 2004; Candito et al., 2010). In order to draw meaningful comparisons with recent results for English, we use the same types of features as Ribeyre et al. (2015), which were extracted from the DM corpus (Oepen et al., 2014), an English predicate-argument structure corpus sharing similarities with the D EEP FTB. Despite the differences of language and annotation scheme, we observe that the same combination of different topolog1 An exception is the work of Bal"
L16-1566,N15-1007,1,0.89364,"hough some recent works have made good progresses in parsing full-fledged semantic structures (Beschke et al., 2014; Berant and Liang, 2014), they mostly focus on English.1 We propose to dig into that direction by relying on the recent release of a deep syntactic graphbank for French, the D EEP FTB, (Ribeyre et al., 2014a), whose deep syntactic graphs were automatically annotated on top of the dependency version of the French Treebank (Abeillé and Barrier, 2004; Candito et al., 2010). In order to draw meaningful comparisons with recent results for English, we use the same types of features as Ribeyre et al. (2015), which were extracted from the DM corpus (Oepen et al., 2014), an English predicate-argument structure corpus sharing similarities with the D EEP FTB. Despite the differences of language and annotation scheme, we observe that the same combination of different topolog1 An exception is the work of Ballesteros et al. (2014) on deep syntacting parsing for Spanish, but their work is restricted to tree structure parsing. ical syntactic information leads to the best models for both French and English. 2. Deep Syntactic French Annotation Scheme and Corpus DM C ORPUS D EEP FTB C ORPUS T RAIN D EV T RA"
L16-1566,C08-1095,0,0.0471372,"Missing"
L16-1566,W13-4917,1,0.902976,"Missing"
L16-1566,seddah-2010-exploring,1,0.81561,"ctic constituency trees. They have been extracted ussyntactic” name). In particular it sticks to (canonical) syning the same method as in (Carreras andHead Màrquez, 2005). tactic labels subj, obj, . . . instead of using numbered seS Path Spine Spinal Elementary Trees (SPINES) They consist of the mantic labels arg1, arg2, . . . . Also, in the case of a pred(w = 4) path of the maximal projection VP of a head in a constituency NP icate modifying one of its semantic argument (e.g. an attree. They have been extracted using a spine grammar tributive adjective), both the modifier dependency and the (Seddah, 2010) and percolation table ofBKY DybroD N the head predicative dependency are kept in the deep graph: for inV PP Johansen (2004). The spines are assigned in a deterministic stance for an attributive adjective like in a perfect day, day way. is taken as the subject of perfect, and perfect as a modiP NP Constituent Head Paths (PATHS) We use F R MG depenfier of day. This choice was made in order to keep both dencies to extract the shortest path between a token and its the predicate-argument structures and the general informaD N lexical head and include the path length w (i.e. the number tion structur"
L16-1566,W13-4906,1,0.907525,"Missing"
L16-1566,W13-5706,1,0.908969,"Missing"
L18-1064,K17-3026,1,0.833606,"Missing"
L18-1064,L16-1324,0,0.029957,"Missing"
L18-1064,W17-7411,1,0.889072,"Missing"
L18-1064,lacheret-etal-2014-rhapsodie,0,0.0335607,"Missing"
L18-1064,muzerelle-etal-2014-ancor,0,0.355684,"Missing"
L18-1064,L16-1026,0,0.0609366,"Missing"
L18-1064,L16-1262,0,0.0800186,"Missing"
L18-1064,W12-4501,0,0.234768,"Missing"
L18-1064,W11-1901,0,0.279736,"Missing"
L18-1064,taule-etal-2008-ancora,0,0.11951,"Missing"
L18-1064,K17-3001,0,0.0340453,"Missing"
L18-1718,P13-2107,0,0.0454926,"Missing"
L18-1718,W13-4916,0,0.0300012,"Missing"
L18-1718,W09-3821,1,0.740978,"Missing"
L18-1718,F12-2024,1,0.899058,"Missing"
L18-1718,candito-etal-2010-statistical,1,0.865662,"Missing"
L18-1718,C12-1052,0,0.052222,"Missing"
L18-1718,C12-1059,0,0.0416459,"Missing"
L18-1718,J93-2004,0,0.0629965,"Missing"
L18-1718,P09-2010,0,0.0726827,"Missing"
L18-1718,L16-1375,1,0.89553,"Missing"
L18-1718,W13-4917,1,0.856651,"Missing"
L18-1718,W14-6111,1,0.908556,"Missing"
L18-1718,W13-4906,1,0.857223,"Missing"
L18-1718,E17-1034,0,0.0185843,"an iterative fashion, or as new relevant conversion needs are identified. A full manual evaluation of a converted treebank could represent an effort comparable to full re-annotation of a large part of the data. Indeed, few of the UD-conversion papers provide accuracy scores of the conversion on a manually annotated testbench. For instance, The Danish conversion of Johannsen et al. (2015), uses a small set of hand-annotated sentences that reflect specific phenomena and hard cases that is used as held-out section during the iterative development of conversion rules. The Hungarian conversion of Vincze et al. (2017) uses a hand-corrected gold standard of 1,800 sentences. When comparing the quality of the conversion with the gold standard, they consider the accuracy (87.81 UAS and 75.99 LAS) not sufficient to release the resulting treebank. We draw inspiration on their method to develop a handcorrected sample to evaluate the quality of our conversion.One of the authors of the article, an expert in dependency annotation very familiar with the UD formalism, reviewed 100 sentences from the test section and 100 sentences from the dev section manually, correcting edges and labels that were either not properly"
L18-1718,K17-3001,1,0.897083,"Missing"
lee-etal-2004-towards,callmeier-etal-2004-deepthought,0,\N,Missing
lee-etal-2004-towards,E95-1025,0,\N,Missing
lee-etal-2004-towards,W03-0802,0,\N,Missing
lee-etal-2004-towards,P03-1014,0,\N,Missing
lee-etal-2004-towards,C94-2144,0,\N,Missing
lee-etal-2004-towards,P03-2019,0,\N,Missing
lee-etal-2004-towards,kasper-etal-2004-integrated,0,\N,Missing
lee-etal-2004-towards,2002.jeptalnrecital-long.6,1,\N,Missing
morardo-villemonte-de-la-clergerie-2014-towards,vilnat-etal-2010-passage,1,\N,Missing
morardo-villemonte-de-la-clergerie-2014-towards,W13-5706,1,\N,Missing
N01-1022,P98-1061,0,\N,Missing
N01-1022,C98-1059,0,\N,Missing
N15-1007,C14-1133,0,0.186579,"kinds of syntactic features to improve predicateargument parsing. To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks. Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless of the annotation scheme and the parser used. The question is now to establish whether will this be verified in other semantic data sets? From the parsing of deep syntax treebanks a la Meaning Text Theory (Ballesteros et al., 2014), to Framenet semantic parsing (Das et al., 2014) or data-driven approaches closer to ours (Flanigan et al., 2014), it is difficult to know which models will predominate from this bubbling field and what kind of semantic data sets will benefit the most from syntax. Acknowledgements We would like to thank Kenji Sagae and André F. T. Martins for making their parsers available and for kindly answering our questions. We also thank our anonymous reviewers for their comments. This work was partly funded by the Program &quot;Investissements d’avenir&quot; managed by Agence Nationale de la Recherche ANR-10-LABX"
N15-1007,D12-1091,0,0.0319756,"Missing"
N15-1007,W13-4916,0,0.0653264,"Missing"
N15-1007,P04-1041,0,0.0918059,"Missing"
N15-1007,W05-0620,0,0.0683461,"87.66 88.08 89.13 89.43 89.7 +2.14 +1.77 +1.62 PAS, baseline +grandparent +co-parents 89.73 90.15 90.93 91.68 91.92 92.11 +1.95 +1.77 +1.18 Table 11: LF Results for T.PARSER (test set). Baseline = arc-factored + siblings Related Work A growing interest for semantic parsing has emerged over the past few years, with the availability of resources such as PropBank and NomBank (Palmer et al., 2005; Meyers et al., 2004) built on top of the Penn Treebank. The shallow semantic annotations they provide were among the targets of successful shared tasks on semantic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005). Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here. However, they diverge in that Propbank/Nombank annotations 72 do not form connected graphs by themselves, as they only cover argument identification and nominal predicates. The range of phenomena they describe is also limited, compared to a full predicate-argument analysis as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generali"
N15-1007,A00-2018,0,0.337842,"the parse, the better the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (P TB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae and Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures. For most of the previous decade, the term deep syntax was used"
N15-1007,W03-1006,0,0.252425,"n and nominal predicates. The range of phenomena they describe is also limited, compared to a full predicate-argument analysis as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the A RG 0 argument (i.e. the subject/agent role) leading to inconsistencies. However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009). 8 Conclusion We described the use and combination of several kinds of syntactic features to improve predicateargument parsing. To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks. Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless o"
N15-1007,W02-1001,0,0.0477273,"Xσi , . . . , Xσj . multiple edges between the same pair of nodes. It is to be noted that the pop0 action may also be used to remove words with no heads. We base our work on the the DAG parser of Sagae and Tsujii (2008) (henceforth S&T) which we extended with the set of actions displayed above (Figure 1) to cope with partially connected planar graphs, and we gave it the ability to take advantage of an extended set of features. Finally, for efficiency reasons (memory consumption and speed), we replaced the original Maxent model with an averaged structured perceptron (Freund and Schapire, 1999; Collins, 2002). Transition-based Graphs Parsing (σ, wi |β, A) ` (σ|wi , β, A) (σ|wj |wi , β, A) ` (σ|wi , β, A ∪ (wi , r, wj )) (σ|wj |wi , β, A) ` (σ|wj , β, A ∪ (wj , r, wi )) (σ|wj |wi , β, A) ` (σ|wj |wi , β, A ∪ (wi , r, wj )) (σ|wj |wi , β, A) ` (σ|wj , wi |β, A ∪ (wj , r, wi ) (σ|wi , β, A) ` (σ, β, A) POSσ1 ,σ2 ,σ3 POSβ1 ,β2 ,β3 leftLabelσ1 ,σ2 d12 d011 Table 3: Baseline features for the parser. Table 2: Breakdown of Label Statistics. Cell values in italics not counted in the DM total. 3 Lemmaσ1 ,σ2 ,σ3 Lemmaβ1 ,β2 rightPOSσ1 ,σ2 a 4 4.1 (shift) (lR) (rR) (lA) (rA) (pop0) Figure 1: Set of transition"
N15-1007,1995.tmi-1.2,0,0.173567,"proves the recognition of long distance dependencies and elliptical constructions. We finally discuss the usefulness of our approach, when applied on a second-order model based on dual decomposition (Martins and Almeida, 2014), showing that our use of syntactic features enhances this model accuracy and provides state-of-the-art performance. 2 Deep Syntax and Underspecified Semantic Corpora DeepBank Corpus Semantic dependency graphs in the DM Corpus are the result of a two-step simplification of the underspecified logical-form meaning representations, based on Minimal Recursion Semantic (MRS, (Copestake et al., 1995; Copestake et al., 2005)), derived from the manually annotated DeepBank treebank (Flickinger et al., 2012). First, Oepen and Lønning (2006) define a conversion from original MRS formulae to variable-free Elementary Dependency Structures (EDS), which (a) maps each predication in the MRS logical-form meaning representation to a node in a dependency graph and (b) transforms argument relations represented by shared logical variables into directed dependency links between graph nodes. Then, in a second conversion step, the EDS graphs are further reduced into strict bi-lexical form, i.e. a set of d"
N15-1007,J14-1002,0,0.0348455,"Missing"
N15-1007,S14-2080,0,0.287359,"(Miyao and Tsujii, 2005; Cahill et al., 2004; Hockenmaier, 2003). Its use now spreads by misnomer to models that provide more abstract structures, capable of generalizing classical functional labels to more semantic (in a logical view) arguments, potentially capable of neutralizing diathesis distinctions and of providing accurate predicate-argument structures. Although the building of syntax-to-semantic interface seems inextricably linked to an efficient parsing stage, inspirational works on semantic role labelling (Toutanova et al., 2005) and more recently on broad coverage semantic parsing (Du et al., 2014) that provide stateof-the-art results without relying on surface syntax, lead us to question the usefulness of syntactic parses for predicate-argument structure parsing. In this study, we investigate the impact of syntactic features on a transition-based graph parser by testing on two treebanks. We take advantage of the recent release for the SemEval 2014 shared task on semantic dependency parsing, by Oepen et 64 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 64–74, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computat"
N15-1007,P14-1134,0,0.0909834,"Missing"
N15-1007,P13-2111,0,0.0274346,"orpus (dev. set). Table 9: Shared subjects coordinations eval. (dev sets). Table 8: Long-distance dependencies eval. (dev sets). based parsers to predict predicate-argument structures, especially for LDDs. Yet, compared to stateof-the-art systems, our results built on the S&T parser score lower than the top performers (Table 10). However, we are currently extending a more advanced lattice-aware transition-based parser (DSR) with beams (Villemonte De La Clergerie, 2013) that takes advantage of cutting-edge techniques (dynamic programming, averaged perceptron with early updates, etc. following (Goldberg et al., 2013; Huang et al., 2012)) 4 , which proves effective by reaching the state-of-the-art on PAS, outperforming Thomson et al. (2014) and second to the model of Martins and Almeida (2014). 5 The point here is that using the same syntactic features as our base system exhibits the same improvement over a now much stronger baseline. We can conjecture that the ambiguities added by the relative scarcity of the deep annotations is efficiently handled by a more complete exploration of the search space, made possible by beam optimization. We can also wonder whether the lower improvement brought to DM parsing"
N15-1007,W08-2122,0,0.0213079,"as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the A RG 0 argument (i.e. the subject/agent role) leading to inconsistencies. However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009). 8 Conclusion We described the use and combination of several kinds of syntactic features to improve predicateargument parsing. To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks. Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless of the annotation scheme and the parser used. The question is now to establish whether will this be verified in other semantic da"
N15-1007,N12-1015,0,0.026082,"9: Shared subjects coordinations eval. (dev sets). Table 8: Long-distance dependencies eval. (dev sets). based parsers to predict predicate-argument structures, especially for LDDs. Yet, compared to stateof-the-art systems, our results built on the S&T parser score lower than the top performers (Table 10). However, we are currently extending a more advanced lattice-aware transition-based parser (DSR) with beams (Villemonte De La Clergerie, 2013) that takes advantage of cutting-edge techniques (dynamic programming, averaged perceptron with early updates, etc. following (Goldberg et al., 2013; Huang et al., 2012)) 4 , which proves effective by reaching the state-of-the-art on PAS, outperforming Thomson et al. (2014) and second to the model of Martins and Almeida (2014). 5 The point here is that using the same syntactic features as our base system exhibits the same improvement over a now much stronger baseline. We can conjecture that the ambiguities added by the relative scarcity of the deep annotations is efficiently handled by a more complete exploration of the search space, made possible by beam optimization. We can also wonder whether the lower improvement brought to DM parsing by the PTB-based syn"
N15-1007,W12-3602,0,0.0134445,"k (Flickinger et al., 2012). First, Oepen and Lønning (2006) define a conversion from original MRS formulae to variable-free Elementary Dependency Structures (EDS), which (a) maps each predication in the MRS logical-form meaning representation to a node in a dependency graph and (b) transforms argument relations represented by shared logical variables into directed dependency links between graph nodes. Then, in a second conversion step, the EDS graphs are further reduced into strict bi-lexical form, i.e. a set of directed, binary dependency relations holding exclusively between lexical units (Ivanova et al., 2012). Even though both conversion steps are, by design, lossy, DM semantic dependency graphs present a true subset of the information encoded in the full, original MRS data set. Predicate-Argument Structure Corpus Enju Predicate-Argument Structures (PAS Corpus) are derived from the automatic HPSG-style annotation of the Penn Treebank (Miyao and Tsujii, 2004) that was primarily used for the development of the Enju parsing system (Miyao and Tsujii, 2005). The 65 PAS data set is an extraction of predicate-argument structures from the Enju HPSG treebank and contains word-to-word semantic dependencies."
N15-1007,J93-2004,0,0.0503779,"roduction For the majority of the state-of-the-art parsers that routinely reach ninety percent performance plateau in capturing tree structures, the question of what next crucially arises. Indeed, it has long been thought that the bottleneck preventing the advent of accurate syntax-to-semantic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (P TB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae and Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordinati"
N15-1007,S14-2082,0,0.303828,"framework requires graphs to be predicted. Using the DeepBank (Flickinger et al., 2012) and the PredicateArgument Structure treebank (Miyao and Tsujii, 2005) as a test field, we show how transition-based parsers, extended to handle connected graphs, benefit from the use of topologically different syntactic features such as dependencies, tree fragments, spines or syntactic paths, bringing a much needed context to the parsing models, improving notably over long distance dependencies and elided coordinate structures. By confirming this positive impact on an accurate 2nd-order graphbased parser (Martins and Almeida, 2014), we establish a new state-of-the-art on these data sets. 1 Introduction For the majority of the state-of-the-art parsers that routinely reach ninety percent performance plateau in capturing tree structures, the question of what next crucially arises. Indeed, it has long been thought that the bottleneck preventing the advent of accurate syntax-to-semantic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set"
N15-1007,D07-1013,0,0.0383176,"6 86.74 86.76 87.01 +1.10 +1.29 +1.57 +1.59 +1.84 88.84 89.04 89.18 89.17 89.32 89.44 89.30 89.48 89.49 85.20 85.45 85.49 85.62 85.74 85.72 85.87 85.81 85.80 86.98 87.21 87.30 87.36 87.49 87.54 87.55 87.60 87.61 +1.81 +2.04 +2.13 +2.19 +2.32 +2.37 +2.38 +2.43 +2.44 89.35 89.56 89.76 89.88 89.82 89.93 85.54 86.02 86.15 86.13 86.20 86.32 87.40 87.75 87.92 87.96 87.97 88.09 +2.23 +2.58 +2.75 +2.79 +2.80 +2.92 89.70 89.91 86.11 86.14 87.87 87.99 +2.70 +2.82 BN BN ( HPOS ) BKY PATHS BKY + SPINES SPINES + PATHS BN ( HPOS )+ SPINES BN ( HPOS )+ PATHS Results Analysis BN + PATHS BKY + PATHS Following Mcdonald and Nivre (2007), we conducted an error analysis based on the two best models and the baseline for each corpus. As shown in section 5, syntactic features greatly improve semantic parsing. However, it is interesting to explore more precisely what kind of syntactic information boosts or penalizes our predictions. We consider, among other factors, the impact in terms of distance between the head and the dependent (edge length) and the labels. We also explore several linguistic phenomena well known to be difficult to recover. 3 We tested the statistical significance between our best models and the baseline with t"
N15-1007,meyers-etal-2004-annotating,0,0.0309841,"a strong baseline, as they provide a global view to graph-based models, establishing a new state-of-the-art on these corpora. -S YNT. F EAT. +S YNT. F EAT. δ DM, baseline +grandparent +co-parents 86.99 87.66 88.08 89.13 89.43 89.7 +2.14 +1.77 +1.62 PAS, baseline +grandparent +co-parents 89.73 90.15 90.93 91.68 91.92 92.11 +1.95 +1.77 +1.18 Table 11: LF Results for T.PARSER (test set). Baseline = arc-factored + siblings Related Work A growing interest for semantic parsing has emerged over the past few years, with the availability of resources such as PropBank and NomBank (Palmer et al., 2005; Meyers et al., 2004) built on top of the Penn Treebank. The shallow semantic annotations they provide were among the targets of successful shared tasks on semantic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005). Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here. However, they diverge in that Propbank/Nombank annotations 72 do not form connected graphs by themselves, as they only cover argument identification and nominal predicates. The range of phenomena they describe is also li"
N15-1007,C04-1204,0,0.0284792,"into directed dependency links between graph nodes. Then, in a second conversion step, the EDS graphs are further reduced into strict bi-lexical form, i.e. a set of directed, binary dependency relations holding exclusively between lexical units (Ivanova et al., 2012). Even though both conversion steps are, by design, lossy, DM semantic dependency graphs present a true subset of the information encoded in the full, original MRS data set. Predicate-Argument Structure Corpus Enju Predicate-Argument Structures (PAS Corpus) are derived from the automatic HPSG-style annotation of the Penn Treebank (Miyao and Tsujii, 2004) that was primarily used for the development of the Enju parsing system (Miyao and Tsujii, 2005). The 65 PAS data set is an extraction of predicate-argument structures from the Enju HPSG treebank and contains word-to-word semantic dependencies. Each dependency type is made of two elements: a coarse part-of-speech of the head predicate dependent (e.g. verb and adjective), and the argument (e.g. ARG1 and ARG2). Although both are derived from HSPG resources (a hand-crafted grammar for DM, a treebank-based one for PAS), they differ in their core linguistic choices (functional heads vs lexical head"
N15-1007,P05-1011,0,0.286881,"erb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures. For most of the previous decade, the term deep syntax was used for rich parsing models built upon enriched versions of a constituency treebank, either with added HPSG or LFG annotation or CCG (almost) full rewrites (Miyao and Tsujii, 2005; Cahill et al., 2004; Hockenmaier, 2003). Its use now spreads by misnomer to models that provide more abstract structures, capable of generalizing classical functional labels to more semantic (in a logical view) arguments, potentially capable of neutralizing diathesis distinctions and of providing accurate predicate-argument structures. Although the building of syntax-to-semantic interface seems inextricably linked to an efficient parsing stage, inspirational works on semantic role labelling (Toutanova et al., 2005) and more recently on broad coverage semantic parsing (Du et al., 2014) that p"
N15-1007,J08-2003,0,0.151701,"edicate-argument analysis as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the A RG 0 argument (i.e. the subject/agent role) leading to inconsistencies. However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009). 8 Conclusion We described the use and combination of several kinds of syntactic features to improve predicateargument parsing. To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks. Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless of the annotation scheme and the parser used. The question is now to establish whether will this be veri"
N15-1007,P05-1013,0,0.0429748,"of accurate syntax-to-semantic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (P TB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae and Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between"
N15-1007,W03-3017,0,0.0682555,"etter the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (P TB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae and Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures. For most of the previous decade, the term deep syntax was used for rich par"
N15-1007,oepen-lonning-2006-discriminant,0,0.0784891,"nd-order model based on dual decomposition (Martins and Almeida, 2014), showing that our use of syntactic features enhances this model accuracy and provides state-of-the-art performance. 2 Deep Syntax and Underspecified Semantic Corpora DeepBank Corpus Semantic dependency graphs in the DM Corpus are the result of a two-step simplification of the underspecified logical-form meaning representations, based on Minimal Recursion Semantic (MRS, (Copestake et al., 1995; Copestake et al., 2005)), derived from the manually annotated DeepBank treebank (Flickinger et al., 2012). First, Oepen and Lønning (2006) define a conversion from original MRS formulae to variable-free Elementary Dependency Structures (EDS), which (a) maps each predication in the MRS logical-form meaning representation to a node in a dependency graph and (b) transforms argument relations represented by shared logical variables into directed dependency links between graph nodes. Then, in a second conversion step, the EDS graphs are further reduced into strict bi-lexical form, i.e. a set of directed, binary dependency relations holding exclusively between lexical units (Ivanova et al., 2012). Even though both conversion steps are"
N15-1007,S14-2008,0,0.154697,"and δ in Figure 2). In addition, we expanded these features with the part-of-speech of the head of a given token (HPOS). The idea is to evaluate the informativeness of more abstract syntactic features since a &lt;L ABEL , HPOS&gt; pair can be seen as generalizing many constituent subtrees. 67 5 Experiments Experimental Setup Both DM and PAS treebanks consist of texts from the P TB and which were either automatically derived from the original annotations or annotated with a hand-crafted grammar (see above). We use them in their bi-lexical dependency format, aligned at the token level as provided by Oepen et al. (2014)1 . The following split is used: sections 00-19 for training, 20 for the dev. set and 21 for test2 . All predicted parses are evaluated against the gold standard with labeled precision, recall and f-measure metrics. Results Our experiments are based on the evaluation of the combinations of the 4 main types of syntactic features described in section 4: tree fragments (BKY), predicted mate dependencies (BN) and their extension with POS heads (BN ( HPOS )), spinal elementary trees (SPINES) and head paths (PATHS). The results are shown in Tables 5 and 6. All improvements from the baseline are sign"
N15-1007,J05-1004,0,0.0874258,"is also relevant with a strong baseline, as they provide a global view to graph-based models, establishing a new state-of-the-art on these corpora. -S YNT. F EAT. +S YNT. F EAT. δ DM, baseline +grandparent +co-parents 86.99 87.66 88.08 89.13 89.43 89.7 +2.14 +1.77 +1.62 PAS, baseline +grandparent +co-parents 89.73 90.15 90.93 91.68 91.92 92.11 +1.95 +1.77 +1.18 Table 11: LF Results for T.PARSER (test set). Baseline = arc-factored + siblings Related Work A growing interest for semantic parsing has emerged over the past few years, with the availability of resources such as PropBank and NomBank (Palmer et al., 2005; Meyers et al., 2004) built on top of the Penn Treebank. The shallow semantic annotations they provide were among the targets of successful shared tasks on semantic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005). Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here. However, they diverge in that Propbank/Nombank annotations 72 do not form connected graphs by themselves, as they only cover argument identification and nominal predicates. The range of phenomena th"
N15-1007,P06-1055,0,0.439254,"put. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (P TB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae and Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures. For most of the previous decade, the term deep syntax was used for rich parsing models built upon"
N15-1007,C08-1095,0,0.556292,"antic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (P TB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae and Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer"
N15-1007,W09-3813,0,0.0228927,"S (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the A RG 0 argument (i.e. the subject/agent role) leading to inconsistencies. However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009). 8 Conclusion We described the use and combination of several kinds of syntactic features to improve predicateargument parsing. To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks. Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless of the annotation scheme and the parser used. The question is now to establish whether will this be verified in other semantic data sets? From"
N15-1007,seddah-2010-exploring,1,0.817941,"S +δ S PINES TREES H EAD PATHS 648 272 273 1305 742 731 637 265 268 27,670 3,320 2,389 Table 4: Syntactic features statistics (Counts). Figure 2: Schema of Syntactic Features Constituent Tree Fragments These consist of fragments of syntactic trees predicted by the Petrov et al. (2006) parser in a 10-way jackknife setting. They can be used as enhanced POS or as features. Spinal Elementary Trees A full set of parses was reconstructed from the tree fragments using a slightly tweaked version of the C O NLL 2009 shared task processing tools (Hajiˇc et al., 2009). We then extracted a spine grammar (Seddah, 2010) using the head percolation table of the Bikel (2002) parser, slightly modified to avoid certain determiners being marked as heads in certain configurations. The resulting spines were assigned in a deterministic way (red part in Figure 2). Predicted MATE Dependency Labels These consist of the dependency labels predicted by the MATE parser (Bohnet, 2010), trained on a Stanford surface dependency version of the Penn Treebank. We combined the labels with a distance δ = t − h where t is the token position and h the head position (brown labels and δ in Figure 2). In addition, we expanded these feat"
N15-1007,W08-2121,0,0.0728947,"arent +co-parents 86.99 87.66 88.08 89.13 89.43 89.7 +2.14 +1.77 +1.62 PAS, baseline +grandparent +co-parents 89.73 90.15 90.93 91.68 91.92 92.11 +1.95 +1.77 +1.18 Table 11: LF Results for T.PARSER (test set). Baseline = arc-factored + siblings Related Work A growing interest for semantic parsing has emerged over the past few years, with the availability of resources such as PropBank and NomBank (Palmer et al., 2005; Meyers et al., 2004) built on top of the Penn Treebank. The shallow semantic annotations they provide were among the targets of successful shared tasks on semantic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005). Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here. However, they diverge in that Propbank/Nombank annotations 72 do not form connected graphs by themselves, as they only cover argument identification and nominal predicates. The range of phenomena they describe is also limited, compared to a full predicate-argument analysis as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Pro"
N15-1007,S14-2027,0,0.025904,"Missing"
N15-1007,P05-1073,0,0.0433563,"ebank, either with added HPSG or LFG annotation or CCG (almost) full rewrites (Miyao and Tsujii, 2005; Cahill et al., 2004; Hockenmaier, 2003). Its use now spreads by misnomer to models that provide more abstract structures, capable of generalizing classical functional labels to more semantic (in a logical view) arguments, potentially capable of neutralizing diathesis distinctions and of providing accurate predicate-argument structures. Although the building of syntax-to-semantic interface seems inextricably linked to an efficient parsing stage, inspirational works on semantic role labelling (Toutanova et al., 2005) and more recently on broad coverage semantic parsing (Du et al., 2014) that provide stateof-the-art results without relying on surface syntax, lead us to question the usefulness of syntactic parses for predicate-argument structure parsing. In this study, we investigate the impact of syntactic features on a transition-based graph parser by testing on two treebanks. We take advantage of the recent release for the SemEval 2014 shared task on semantic dependency parsing, by Oepen et 64 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 64–74, c"
N15-1007,W13-4906,1,0.82846,"75.41 ALL ( HPOS ) 97.86 98.57 64.78 65.09 77.96 78.41 BKY + BN ( HPOS )+ PATHS +2.55 +3.00 (b) on PAS (dev. set, 636 dependencies). (b) PAS Corpus (dev. set). Table 9: Shared subjects coordinations eval. (dev sets). Table 8: Long-distance dependencies eval. (dev sets). based parsers to predict predicate-argument structures, especially for LDDs. Yet, compared to stateof-the-art systems, our results built on the S&T parser score lower than the top performers (Table 10). However, we are currently extending a more advanced lattice-aware transition-based parser (DSR) with beams (Villemonte De La Clergerie, 2013) that takes advantage of cutting-edge techniques (dynamic programming, averaged perceptron with early updates, etc. following (Goldberg et al., 2013; Huang et al., 2012)) 4 , which proves effective by reaching the state-of-the-art on PAS, outperforming Thomson et al. (2014) and second to the model of Martins and Almeida (2014). 5 The point here is that using the same syntactic features as our base system exhibits the same improvement over a now much stronger baseline. We can conjecture that the ambiguities added by the relative scarcity of the deep annotations is efficiently handled by a more"
N15-1007,N07-1069,0,0.024958,"antic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005). Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here. However, they diverge in that Propbank/Nombank annotations 72 do not form connected graphs by themselves, as they only cover argument identification and nominal predicates. The range of phenomena they describe is also limited, compared to a full predicate-argument analysis as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the A RG 0 argument (i.e. the subject/agent role) leading to inconsistencies. However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009). 8 Conclusion We described the use and combination of several k"
N15-1007,W09-1201,0,\N,Missing
P01-1007,W98-0105,1,0.57524,"a practical point of view. The next section depicts the practical experiments we have performed to validate our approach. 5 Experiments with an English Grammar In order to compare a (normal) RCL parser and its guided versions, we looked for an existing widecoverage grammar. We chose the grammar for English designed for the XTAG system (XTAG, 1995), because it both is freely available and seems rather mature. Of course, that grammar uses the TAG formalism.1 Thus, we first had to transform that English TAG into an equivalent RCG. To perform this task, we implemented the algorithm described in (Boullier, 1998) (see also (Boullier, 1999)), which allows to transform any TAG into an equivalent simple PRCG.2 However, Boullier’s algorithm was designed for pure TAGs, while the structures used in the XTAG system are not trees, but rather tree schemata, grouped into linguistically pertinent tree families, which have to be instantiated by inflected forms for each given input sentence. That important difference stems from the radical difference in approaches between “classical” TAG parsing and “usual” RCL parsing. In the former, through lexicalization, the input sentence allows the selection of tree schemata"
P01-1007,2000.iwpt-1.8,1,0.871095,"st one variable occurring in its RHS (resp. LHS) which does not appear in its LHS (resp. RHS);  erasing if there exists a variable appearing only in its LHS or only in its RHS;  linear if none of its variables occurs twice in its LHS or twice in its RHS; simple if it is non-combinatorial, nonerasing and linear. These definitions extend naturally from clause to set of clauses (i.e., grammar). In this paper we will not consider negative RCGs, since the guide construction algorithm presented is Section 3 is not valid for this class. Thus, in the sequel, we shall assume that RCGs are PRCGs. In (Boullier, 2000b) is presented a parsing algorithm which, for any RCG and any input string of length , produces a parse forest in time. The exponent , called degree of , is the maximum number of free (independent) bounds in a clause. For a non-bottom-uperasing RCG, is less than or equal to the maximum value, for all clauses, of the sum where, for a clause , is its arity and is the number of (different) variables in its LHS predicate.    RXYR     Q A[ A [xZ[ [ 3 PRCG to 1-PRCG Transformation Algorithm The purpose of this section is to present a transformation algorithm which takes as input a"
P01-1007,P94-1040,0,0.0319713,"abases) but, if we consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted. One reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs a direct access into the guiding structure. Moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (Nederhof, 1998) how a FSA can guide a CF parser). As already noted by many authors (see for example (Carroll, 1994)), the choice of a (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments. Complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have a preponderant effect on the typical size ranges of the application. We have also noted that guiding parsers can be used in classical TAG parsers, as efficient and (very) accurate tree selectors. More generally, we are currently investigating the possibility to use guiding parsers as shallow par"
P01-1007,2000.iwpt-1.3,0,0.043196,"Introduction Usually, during a nondeterministic process, when a nondeterministic choice occurs, one explores all possible ways, either in parallel or one after the other, using a backtracking mechanism. In both cases, the nondeterministic process may be assisted by another process to which it asks its way. This assistant may be either a guide or an oracle. An oracle always indicates all the good ways that will eventually lead to success, and those good ways only, while a guide will indicate all the good ways but may also indicate some wrong ways. In other words, an oracle is a perfect guide (Kay, 2000), and the worst guide indicates all possiand and ble ways. Given two problems and , if they are their respective solutions , any algorithm which solves such that is a candidate guide for nondeterministic algorithms solving . Obviously, supplementary conditions have to be fulfilled for to be a guide. The first one deals with relative efficiency: it ascan be solved more effisumes that problem ciently than problem . Of course, parsers are privileged candidates to be guided. In this paper we apply this technique to the parsing of a subset of RCLs that are the languages defined by RCGs. The syntact"
P01-1007,W98-1302,0,0.0276868,"iple related in this paper is not novel (see for example (Lakshmanan and Yim, 1991) for deductive databases) but, if we consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted. One reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs a direct access into the guiding structure. Moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (Nederhof, 1998) how a FSA can guide a CF parser). As already noted by many authors (see for example (Carroll, 1994)), the choice of a (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments. Complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have a preponderant effect on the typical size ranges of the application. We have also noted that guiding parsers can be used in classical TAG parsers, as efficient and (very) accurate tree selectors."
P01-1007,J00-1003,0,0.0526656,"Missing"
P01-1007,W00-2027,0,0.029976,"ven crossing point seems to occur for sentences of around 16– 20 words. load module initial guided -guided 3.063 8.374 14.530 Table 3: RCL parser sizes (MB) » parser sample set 35-word sent. initial guided -guided XTAG 5.810 1.580 2.440 4 282.870 3 679.570 63.570 49.150 5 days Ò Table 4: Parse times (sec) The sizes of these RCL parsers (load modules) are in Table 3 while their parse times are in Table 4.7 We have also noted in the last line, for reference, the times of the latest XTAG parser (February 2001),8 on our sample set and on the 35-word sentence.9 6 Guiding Parser as Tree Filter In (Sarkar, 2000), there is some evidence to indicate that in LTAG parsing the number of trees selected by the words in a sentence (a measure of the syntactic lexical ambiguity of the sentence) is a better predictor of complexity than the number of words in the sentence. Thus, the accuracy of the tree selection process may be crucial for parsing speeds. In this section, we wish to briefly compare the tree selections performed, on the one hand by the words in a sentence and, on the other hand, by a guiding parser. Such filters can be used, for example, as pre-processors in classical [L]TAG parsing. With a guidi"
P06-1042,P04-1057,0,0.220969,"Missing"
P06-1042,J96-1002,0,0.00747552,"Missing"
P06-1042,W05-1501,1,\N,Missing
R09-1058,francopoulo-etal-2006-lexical,0,0.0611908,"ility, we mean the capacity of the resource to be integrated in NLP tools or applied to a particular language • Foreseeing the exhaustive list of those uses is simply impossible. Therefore, it is essential for the formalisms to be compared to various kind of languages and practical tools in order to adapt and extend them. • The formalisms need to be regularly maintained so as to guarantee their extension to uncovered phenomena. In order to develop our morphological and lexical resources, we chose to use the Alexina framework [7, 8, 2]. This framework, which is compatible with the LMF standard [3] represents morphological and syntactic information in a complete, efficient and readable fashion. The Alexina model is based on a two-level representation distinguishing the description of a lexicon from its use. The intensional level, used for an efficient description, factorizes the lexical information by associating each lemma with a morphological class and deep syntactic information (a deep subcategorization frame, a list of possible restructurations, and other syntactic features such as information on control, attributes, mood of sentencial complements, etc.). The extensional level, used"
R09-1058,W09-4619,1,0.826122,"ological and syntactic lexicons Two wide coverage lexicons for Spanish and Galician have already been produced following the Alexina format. Both 15 At this point, the process discards all entries that do not have their lemma as one of their inflected forms. lexicons are currently being upgraded using the techniques described in section 5.2 and will be available under LGPLLR licenses soon. The Spanish lexicon Leffe 16 has overtaken other well known Spanish lexicons in terms of coverage despite being in beta version. It has been obtained by merging several existing Spanish linguistic resources [4]. Nowadays, the Leffe beta contains more than 165,000 unique (lemma,PoS) pairs, corresponding to approx. 1,590,000 inflected entries that associate a form with morpho-syntactic information (approx. 680,000 unique (form,PoS) pairs). The Leffga17 has been created after the Galician lexicon developed in the CORGA18 project. The Leffga is still in alpha version (April 2009), and less developed than the Leffe. It contains more than 52,000 unique (lemma,PoS) pairs (approx. 515,000 unique (form,PoS) pairs). The complete lexicon includes more than 742,000 inflected entries with little syntactic inform"
R09-1058,C08-1080,1,0.841415,"ious practical experiments (see sect. 5.3.2 and [2]), have shown that existing resource usually share common points. Adapting a large part of the available existing resources is often a reasonable objective. Using existing resources Existing resources are generally valuable sources of data when building new resources or extending others. Ignoring the great efforts invested in order to build existing resources does not seem reasonable or productive. Such an approach 320 We now describe a generic approach which has been abstracted from practical research results described essentially in [9] and [5]. In order to efficiently produce new formalized knowledge, a source of data is needed to detect and acquire the missing knowledge. Since this source should be available in sufficient quantity for any language, we have discarded annotated data13 which is only available in limited quantities for a small number of languages, and opted for plain digital text which is daily produced for most languages. In order to extend and correct a resource from plain text, we apply the following two-step generic approach: • identify as accurately as possible which part of the text is not covered by a resource,"
R09-1058,sagot-etal-2006-lefff,1,0.860569,"inguistic Resources LGPL-compatible, http://www.cecill.info/. By usability, we mean the capacity of the resource to be integrated in NLP tools or applied to a particular language • Foreseeing the exhaustive list of those uses is simply impossible. Therefore, it is essential for the formalisms to be compared to various kind of languages and practical tools in order to adapt and extend them. • The formalisms need to be regularly maintained so as to guarantee their extension to uncovered phenomena. In order to develop our morphological and lexical resources, we chose to use the Alexina framework [7, 8, 2]. This framework, which is compatible with the LMF standard [3] represents morphological and syntactic information in a complete, efficient and readable fashion. The Alexina model is based on a two-level representation distinguishing the description of a lexicon from its use. The intensional level, used for an efficient description, factorizes the lexical information by associating each lemma with a morphological class and deep syntactic information (a deep subcategorization frame, a list of possible restructurations, and other syntactic features such as information on control, attributes, moo"
R09-1058,P04-1057,0,0.0730998,"under such a set of classes. 5.2.2 Syntactic lexical information improvement To achieve this task, we apply the technique described in [5] where the tool observed is a syntactic parser, the unexpected behaviors are parsing failures, and the resources A and B are a morpho-syntactic lexicon and a grammar. In order to correct and extend a lexicon, the authors firstly detect lexical forms suspected to be responsible for some parse failures thanks to two techniques. A statistical computation which emphasizes “suspicious” lexical forms present more frequently than the rest in non-parsable sentence [10]. Lexical forms are even more “suspicious” if present in non-parsable along with forms “cleared” by their presence in parsable ones [9]. A tagger-based approach which highlights absent entries by relying on the tagger’s ability to guess a tag for unknown words and forcing the tagger to use it on forms that are in fact known. If the tag answered represents data absent in the lexicon, the form is suspected. Once the suspicious forms have been identified, the authors rely on the grammar to generate lexical corrections for the identified forms. To achieve this task, they study the expectations of"
R09-1058,W05-1522,1,0.884862,"Missing"
R09-1058,P06-1042,1,\N,Missing
S14-2012,W13-4916,0,0.0464075,"Missing"
S14-2012,C04-1204,0,0.0390746,"Missing"
S14-2012,P13-1091,0,0.0327856,"Missing"
S14-2012,S14-2008,0,0.153665,"Missing"
S14-2012,P13-2111,0,0.0604694,"c Graph Parsing with Syntactic Features Corentin Ribeyre? ◦ Eric Villemonte de la Clergerie? Djamé Seddah?  ? Alpage, INRIA ◦ Univ Paris Diderot, Sorbonne Paris Cité  Université Paris Sorbonne firstname.lastname@inria.fr Abstract wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global performance by more than two points. Although not state-of-the-art, our systems perform very honorably compared with other single systems in this shared task and pave quite an interesting way for further work. In the remainder of this paper, we present the parsers and their extensions for building graphs; we then present our syntactic features an"
S14-2012,C08-1095,0,0.524033,"een used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. plied, etc. For various reasons, we started our experiments with two rather different transition-based parsers, which have finally converged on several aspects. In particular, the main convergence concerns the set of transitions needed to parse the three proposed annotation schemes. To be able to attach zero, one, or more heads to a word, it is necessary to clearly dissociate the addition of a dependency from the reduction of a word (i.e. its removal from the stack). Following Sagae and Tsujii (2008), as shown in Figure 1, beside the usual shift and reduce transitions of the arc-standard strategy, we introduced the new left and right attach actions for adding new dependencies (while keeping the dependent on the stack) and two reduce pop0 and pop1 actions to remove a word from the stack after attachement of its dependents. All transitions adding an edge should also satisfy the condition that the new edge does not create a cycle or multiple edges between the same pair of nodes. It is worth noting that the pop actions may also be used to remove words with no heads. 2.1 2.2 DYAL OG -SR Our se"
S14-2012,P10-1110,0,0.181802,"ransition-based Semantic Graph Parsing with Syntactic Features Corentin Ribeyre? ◦ Eric Villemonte de la Clergerie? Djamé Seddah?  ? Alpage, INRIA ◦ Univ Paris Diderot, Sorbonne Paris Cité  Université Paris Sorbonne firstname.lastname@inria.fr Abstract wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global performance by more than two points. Although not state-of-the-art, our systems perform very honorably compared with other single systems in this shared task and pave quite an interesting way for further work. In the remainder of this paper, we present the parsers and their extensions for building graphs; we then present o"
S14-2012,seddah-2010-exploring,1,0.838798,"Missing"
S14-2012,W13-4906,1,0.843025,"duce transitions of the arc-standard strategy, we introduced the new left and right attach actions for adding new dependencies (while keeping the dependent on the stack) and two reduce pop0 and pop1 actions to remove a word from the stack after attachement of its dependents. All transitions adding an edge should also satisfy the condition that the new edge does not create a cycle or multiple edges between the same pair of nodes. It is worth noting that the pop actions may also be used to remove words with no heads. 2.1 2.2 DYAL OG -SR Our second parsing system is DYAL OG -SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYAL OG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sagae, 2010; Goldberg et al., 2013). It was initially designed to follow an arcstandard parsing strategy, relying on shift and left/right reduce transitions. To deal with dependency graphs and non governed words, we first added the two attach transitions and the pop0 transition. But because there exist some o"
S14-2012,W12-3602,0,\N,Missing
S14-2012,candito-etal-2014-deep,1,\N,Missing
S14-2012,W13-4917,1,\N,Missing
S14-2012,D07-1096,0,\N,Missing
S19-2211,W14-0908,0,0.0387892,"der some verbs in their infinitive form, e.g., suggest, recommend, as well as other lexical cues such as comparative adjectives, e.g., better, worse. For Subtask A, we used a set of 57 handcrafted keywords and 77 keywords were used for Subtask B. Some of the keywords used for Subtask B did not contribute to the results obtained on the subtask A development data, and therefore were discarded. The number of such heuristic keywords in each sentence was used as a feature for the machinelearning algorithm. Function words Function words are considered one of the most important stylometric features (Kestemont, 2014). We hypothesize that the distribution of function words is different for suggestion and non-suggestion sentences. The function word feature set consists of 318 English function words from the scikit-learn package (Pedregosa et al., 2011). Each function word was considered as a separate feature for Subtask A. Sentiment features As mentioned in (Brun and Hag`ege, 2013; Negi et al., 2018), suggestions are usually expressed when a person is not entirely satisfied with the product. To capture this, we used the sentiment information from the NRC WordEmotion Association Lexicon (Mohammad and Turney,"
S19-2211,S16-2022,0,0.518478,"g the TreeTagger software package (Schmid, 1995). When used for Subtask B, function words, sentiment features, digits, and verbs did not improve the performance of our system. 3.2 Experimental setup Classifier We used the scikit-learn (Pedregosa et al., 2011) implementation of the Support Vector Machines (SVM) algorithm, which is considered among the best-performing algorithms for text classification tasks in general, including when cross-domain conditions and binary classification are concerned (Markov et al., 2017), and for the suggestion mining task in particular (Negi and Buitelaar, 2015; Negi et al., 2016). We set the class weight parameter to ‘balanced’ and the penalty parameter (C) to 0.01 for Subtask A and to 0.0001 for Subtask B, tuning the parameters according to the results on the development data. Weighting scheme We used term frequency (tf ) weighting scheme, i.e., the number of times a term occurs in a sentence. Evaluation For the evaluation of our system, we conducted experiments on the development sets for Subtasks A and B measuring the results in terms of precision, recall, and F1-score for the positive class (the official metric). For training our system, we used only the data prov"
S19-2211,D15-1258,0,0.0173247,"the sentiment information from the NRC WordEmotion Association Lexicon (Mohammad and Turney, 2013) focusing on words with negative polarity. The number of negative sentiment words in each sentence was used as a feature for Subtask A. Digits We used the number of digits in a sentence as a feature for Subtask A. This feature is used to evaluate wether the language used in suggestion expressions is more “concrete” (as opposed to abstract) and digits usage can be one of such indicators. Other types of named and numeric entities we examined did not improve our results. Verbs Following the work by Negi and Buitelaar (2015), we used the number of verbs in a sentence as a feature for Subtask A. The parts-of-speech (POS) tags were obtained using the TreeTagger software package (Schmid, 1995). When used for Subtask B, function words, sentiment features, digits, and verbs did not improve the performance of our system. 3.2 Experimental setup Classifier We used the scikit-learn (Pedregosa et al., 2011) implementation of the Support Vector Machines (SVM) algorithm, which is considered among the best-performing algorithms for text classification tasks in general, including when cross-domain conditions and binary classif"
S19-2211,S19-2151,0,0.0404025,"Missing"
S19-2211,W10-0207,0,0.522705,"USA, June 6–7, 2019. ©2019 Association for Computational Linguistics As one can see from Table 1, the distribution of the suggestion and non-suggestion classes is balanced in the development sets, but imbalanced in the training and test data, which is closer to the usual distribution of the suggestion sentences in online reviews and forums (Asher et al., 2009; Negi and Buitelaar, 2015; Negi et al., 2018). 3 Methodology In this section, we describe the features we used and the experimental setup of our best run. 3.1 Features Handcrafted features Following previous studies on suggestion mining (Ramanand et al., 2010; Brun and Hag`ege, 2013; Negi and Buitelaar, 2015), we manually selected a list of representative keywords and patterns of a suggestion from the training and development data. It has been shown that suggestion expressions often contain modal verbs (Ramanand et al., 2010), e.g., should, would, which are included in our list. We also consider some verbs in their infinitive form, e.g., suggest, recommend, as well as other lexical cues such as comparative adjectives, e.g., better, worse. For Subtask A, we used a set of 57 handcrafted keywords and 77 keywords were used for Subtask B. Some of the k"
sagot-etal-2006-lefff,clement-etal-2004-morphology,1,\N,Missing
sagot-etal-2006-lefff,W05-1522,1,\N,Missing
sagot-etal-2006-lefff,W05-1501,1,\N,Missing
sagot-etal-2006-lefff,P04-1057,0,\N,Missing
tolone-etal-2012-evaluating,candito-etal-2010-statistical,0,\N,Missing
tolone-etal-2012-evaluating,sagot-2010-lefff,1,\N,Missing
tolone-etal-2012-evaluating,W05-1522,1,\N,Missing
tolone-etal-2012-evaluating,P06-1042,1,\N,Missing
tolone-etal-2012-evaluating,D07-1096,0,\N,Missing
tolone-etal-2012-evaluating,paroubek-etal-2006-data,0,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,paroubek-2000-language,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,paroubek-etal-2008-easy,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,2006.iwslt-papers.1,0,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,vilnat-etal-2004-ongoing,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,vanrullen-etal-2006-constraint,0,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,paroubek-etal-2006-data,1,\N,Missing
villemonte-de-la-clergerie-etal-2008-passage,galliano-etal-2006-corpus,0,\N,Missing
vilnat-etal-2010-passage,W03-2401,0,\N,Missing
vilnat-etal-2010-passage,villemonte-de-la-clergerie-etal-2008-passage,1,\N,Missing
vilnat-etal-2010-passage,W08-1301,0,\N,Missing
vilnat-etal-2010-passage,P04-1041,0,\N,Missing
vilnat-etal-2010-passage,J07-3004,0,\N,Missing
vilnat-etal-2010-passage,bosco-lombardo-2006-comparing,0,\N,Missing
vilnat-etal-2010-passage,declerck-2006-synaf,0,\N,Missing
vilnat-etal-2010-passage,paroubek-etal-2006-data,1,\N,Missing
W00-2003,E93-1045,0,0.0815284,"Missing"
W00-2003,P98-2217,1,0.521658,"Missing"
W00-2003,C98-2212,1,\N,Missing
W01-1509,bonhomme-lopez-2000-resources,0,0.0240712,"these formalisms, important from a linguistic point of view but also because it is possible to design efficient parsers. However, during our work on TAG, we were confronted with a lack of standardization of grammars, especially when dealing with wide coverage grammars. The XTAG System1 (The XTAG Research Group, 1995) provides an implicit standard, but it is not very readable and lacks explicit specifications. The various grammars we studied presented many variations. Moreover, we also noted many problems of consistencies in most of them. Following others, amongst whom LT XML2 and especially (Bonhomme and Lopez, 2000), we considered that the markup language XML3 1 http://www.cis.upenn.edu/~xtag/ http://www.ltg.ed.ac.uk/ 3 http://www.w3c.org/XML/ 2 Pierre Boullier, Philippe Deschamp Linda Kaouane, Abdelaziz Khajour Éric Villemonte de la Clergerie ATOLL - INRIA, Domaine de Voluceau - BP 105 FR-78153 Le Chesnay Cedex Eric.De_La_Clergerie@inria.fr would be a good choice to represent TAG, especially with the possibility of providing an explicit and logical specification via a DTD. Being textual, resources in XML can be read by humans and easily exchanged and maintained. Finally, there exists more and more suppo"
W01-1509,2000.iwpt-1.8,0,0.223527,"riv tree=""np"" anchor=""Sabine"" /> </op> <op cat=""d"" span=""2 3"" id=""8"" type=""subst""> <deriv tree=""d"" anchor=""un"" /> </op> <op cat=""n"" span=""3 5 4 5"" id=""10"" type=""adj""> <deriv tree=""an"" anchor=""joli"" /> </op> </forest> 4 Maintenance tools 4.1 For the grammars The XML encoding of grammars is convenient for maintenance and exchange. However, it does not correspond to the input formats expected by the two parser compilers we develop. One of them (DyALog) expects a prolog-like representation of the grammars (Alonso Pardo et al., 2000) while the second one expects Range Concatenation Grammars [RCG] (Boullier, 2000). Dep LP FOREST HTML XML RCG XTAG Tree Analyzer Strip XTAG XML Checker TAG LaTeX SQL RCG Figure 8: Maintenance Tools for the forests LP Figure 7: Maintenance Tools for the grammars Therefore, we have developed in Perl a set of maintenance modules, for these conversions and for other tasks (Figure 7). The central module TAG implements an object-oriented view of the logical structure specified by the Grammar DTD. The other modules add new methods to the classes introduced by TAG. Besides the conversion modules LP and RCG, we also have a read/write XML module. Module Checker is used to check (par"
W01-1509,W00-2022,0,0.073024,"isms, important from a linguistic point of view but also because it is possible to design efficient parsers. However, during our work on TAG, we were confronted with a lack of standardization of grammars, especially when dealing with wide coverage grammars. The XTAG System1 (The XTAG Research Group, 1995) provides an implicit standard, but it is not very readable and lacks explicit specifications. The various grammars we studied presented many variations. Moreover, we also noted many problems of consistencies in most of them. Following others, amongst whom LT XML2 and especially (Bonhomme and Lopez, 2000), we considered that the markup language XML3 1 http://www.cis.upenn.edu/~xtag/ http://www.ltg.ed.ac.uk/ 3 http://www.w3c.org/XML/ 2 Pierre Boullier, Philippe Deschamp Linda Kaouane, Abdelaziz Khajour Éric Villemonte de la Clergerie ATOLL - INRIA, Domaine de Voluceau - BP 105 FR-78153 Le Chesnay Cedex Eric.De_La_Clergerie@inria.fr would be a good choice to represent TAG, especially with the possibility of providing an explicit and logical specification via a DTD. Being textual, resources in XML can be read by humans and easily exchanged and maintained. Finally, there exists more and more suppo"
W01-1509,N01-1022,1,\N,Missing
W01-1509,P01-1007,1,\N,Missing
W01-1509,P98-2217,1,\N,Missing
W01-1509,C98-2212,1,\N,Missing
W01-1509,W00-2003,1,\N,Missing
W02-2228,2000.iwpt-1.8,0,0.278438,"ads, may terminate, and may be suspended to give control to their parent or one of their direct descendants. Intuitively, a thread may be used to recognize a constituent while new sub-threads are started to recognize its sub-constituents. Because a thread may be suspended and resumed several times, we can recognize discontinuous constituents with holes such as auxiliary trees in TAG. More generally, TA may handle complex interleaving of discontinuous constituents as shown by Fig. 4(a) for the constituents B and C. TA may also be used to parse a sub-class of Range Concatenation Grammars [RCG] (Boullier, 2000b), which covers LCFRS. Though TA exhibit strong expressive power, they still ensure good operational and complexity properties. Indeed, we propose a simple Dynamic Programming [DP] interpretation for TA that ensures tabular parsing in polynomial worst-case complexity for space and time w.r.t. the length of the input string. If we focus in this paper on top-down pv parsing strategies, it is not because we believe them to be the most important ones, but rather because we think it is important to cover the full spectrum of parsing strategies. Moreover, a tabular parser which handles pv parsing s"
W02-2228,N01-1022,1,0.503036,"Missing"
W02-2228,P98-2217,1,0.898602,"Missing"
W02-2228,P92-1018,0,0.0976117,"alysis of Section 2 holds, we get a time complexity O(n3+2(m+v) ), to be compared with the time complexity O(n2(m+v) ) mentionned in (Boullier, 1999) for set-local MC-TAG. 1 2 5. Parsing Range Concatenation Grammars Range Concatenation Grammars (Boullier, 2000b) are defined in terms of terminals, non-terminals, and range variables that may be instantiated by ranges of the input string. Many sub-classes of RCG may be identified and we characterize here a new one called ordered simple RCG [osRCG], equivalent to simple RCG which are themselves equivalent to Linear Context-Free Rewriting Systems (Weir, 1992). OsRCG are simple RCG where all ranges appearing in a literal are implicitly ordered: for instance p(X1 X2 , X3 ) means that range X1 immediately precedes range X2 which precedes X3 (with some hole between X2 and X3 ). Fig. 4(a) shows an osRCG clause γ with two interleaved discontinuous sub-constituents B and C of clause head A, and a hole H inherited by A. Fig. 5 shows two simple osRCGs for the COPY language {ww|w ∈ {a, b}∗ } and for the COUNT-3 language an bn cn . A B C (1) (2) (3) (4) (5) (6) A7−→γ1.0 B 7−→ [B] B [γ1.0 ] void 7−→ γ1.1 [void] C 7−→ [C] C [γ1.1 ] void 7−→ γ1.2 [void] [γ1.2 ]"
W03-0804,P01-1040,1,0.753817,"e semantics of data categories included in annotations (whether they exist in the Registry or not) are well-defined and understood. The data model that will define the pivot format must be capable of representing all of the information contained in diverse annotation types. The model we assume is a feature structure graph for annotation information, capable of referencing n-dimensional regions of primary data as well as other annotations. The choice of this model is indicated by its almost universal use in defining general-purpose annotation formats, including the Generic Modeling Tool (GMT) (Ide & Romary, 2001, 2002) and Annotation Graphs (Bird & Liberman, 2001). The XML-based GMT could serve as a starting point for defining the pivot format; its applicability to diverse annotation types, including terminology, dictionaries and other lexical data (Ide, et al., 2000), morphological annotation (Ide & Romary, 2001a; 2003) and syntactic annotation (Ide & Romary, 2001b) demonstrates its generality. As specified by the LAF architecture, the GMT implements a feature structure graph, and exploits the hierarchical structure of XML elements and XML’s powerful interand intra-document pointing and linkage mech"
W03-0804,ide-romary-2002-standards,1,\N,Missing
W05-1522,C00-1065,0,0.0301951,"Missing"
W05-1522,2005.jeptalnrecital-long.1,1,0.876711,"Missing"
W08-1306,P04-1041,0,0.0689989,"Missing"
W08-1306,P02-1022,0,0.0996386,"Missing"
W08-1306,declerck-2006-synaf,0,0.0295328,"s for French, whether such annotations come from human annotators or parsers. The representation format is intended to be used both in the evaluation of different parsers, so the parses’ representations should be easily comparable, and in the construction of a large scale annotation treebank which requires that all French constructions can be represented with enough details. The format is based on three distinct specifications and requirements: 1. MAF (ISO 24611)4 and SynAF (ISO 24615)5 which are the ISO TC37 specifications for morpho-syntactic and syntactic annotation (Ide and Romary, 2002) (Declerck, 2006) (Francopoulo, 2008). Let us note that these specifications cannot be called ”standards” because they are work in progress and these documents do not yet have the status Published Standard. Currently, their official status is only Committee Draft. 1. Parsing creates syntactic annotations; 2. Syntactic annotations create or enrich linguistic resources such as lexicons, grammars or annotated corpora; 2. The format used during the previous TECHNOLANGUE/EASY evaluation campaign in order to minimize porting effort for the existing tools and corpora. 3. Linguistic resources created or enriched on th"
W08-1306,paroubek-2000-language,1,0.855159,"Missing"
W08-1306,E03-1085,1,0.757565,"l ) includes a verb, the clitic pronouns and possible particles attached to it. Verb kernels may have different forms: conjugated tense, present or past participle, or infinitive. When the conjugation produces compound forms, distinct NVs are identified; element gathers tokens, word forms, groups, relations and marks and all sentences are included inside a “Document” element. 3 PASSAGE Syntactic Annotation Specification 3.1 Introduction The annotation formalism used in PASSAGE7 is based on the EASY one(Vilnat et al., 2004) which whose first version was crafted in an experimental project PEAS (Gendner et al., 2003), with inspiration taken from the propositions of (Carroll et al., 2002). The definition has been completed with the input of all the actors involved in the EASY evaluation campaign (both parsers’ developers and corpus providers) and refined with the input of PASSAGE participants. This formalism aims at making possible the comparison of all kinds of syntactic annotation (shallow or deep parsing, complete or partial analysis), without giving any advantage to any particular approach. It has six kinds of syntactic “chunks”, we call constituents and 14 kinds of relations The annotation formalism a"
W08-1306,J07-3004,0,0.0539813,"Missing"
W08-1306,vilnat-etal-2004-ongoing,1,0.694807,"Data Category Registry, inist.fr 38 see http://syntax. • the verb kernel (NV for noyau verbal ) includes a verb, the clitic pronouns and possible particles attached to it. Verb kernels may have different forms: conjugated tense, present or past participle, or infinitive. When the conjugation produces compound forms, distinct NVs are identified; element gathers tokens, word forms, groups, relations and marks and all sentences are included inside a “Document” element. 3 PASSAGE Syntactic Annotation Specification 3.1 Introduction The annotation formalism used in PASSAGE7 is based on the EASY one(Vilnat et al., 2004) which whose first version was crafted in an experimental project PEAS (Gendner et al., 2003), with inspiration taken from the propositions of (Carroll et al., 2002). The definition has been completed with the input of all the actors involved in the EASY evaluation campaign (both parsers’ developers and corpus providers) and refined with the input of PASSAGE participants. This formalism aims at making possible the comparison of all kinds of syntactic annotation (shallow or deep parsing, complete or partial analysis), without giving any advantage to any particular approach. It has six kinds of"
W08-1306,2006.iwslt-papers.1,0,0.0438108,"Missing"
W08-1306,villemonte-de-la-clergerie-etal-2008-passage,1,0.766148,"Missing"
W08-1306,paroubek-etal-2008-easy,1,\N,Missing
W08-1306,paroubek-etal-2006-data,1,\N,Missing
W10-4414,C94-2149,0,0.233635,"lization, and extended domain of locality of trees. However, it is well-known that the two last properties easily lead to a combinatorial explosion in term of trees, with large coverage grammars of several thousand trees (or even more) (Crabbé, 2005; Abeillé, 2002). This explosion induces problems of development and maintenance of the grammars, but also of efficiency during parsing. Several approaches have been proposed to remedy to the situation, either on the maintenance side or on the efficiency side. On the maintenance side, besides the notion of families present in the XTAG architecture (Doran et al., 1994), one may cite the use of metarules (Prolo, 2002) to derive trees from the “canonical” versions, and meta-grammars (Candito, 1999; Duchier et al., 2004) where the grammars are derived from a constraint-based modular level of syntactic descriptions organized as an inheritance hierarchy of elementary classes. On the efficiency side, besides more or less clever lexicalization-based filtering techniques (such as suppertagging), one may cite the factorization of common sub-trees using automata (Carroll et al., 1998) or the possibility to attach, modulo regular expressions, several possible tree tra"
W10-4414,W08-1701,0,0.119593,"s on distinct nodes with − det :: agr and −root :: agr ). The constraints from the R-provider class C + are renamed with namespace N to avoid names clashes for nodes, variables, and resources, as shown by the following equation: C − [−N ::R ∪ K− ] ⊕ C + [+R ∪ K+ ] = (C − ⊕ N ::C + )[=N ::R ∪ K− ∪ N ::K+ ] The surviving neutral classes (i.e. those requiring or providing no resources) are used to generate a minimal set of minimal trees, given their constraints. Again, the notion of tree minimality depends on the flavor of MGs and also on the target syntactic formalism (for instance MC-TAGs for (Kallmeyer et al., 2008)). In general, a minimal tree does not introduce nodes not mentioned in the constraints and replaces non immediate dominance constraints by parent relations. In our case, we also try also to preserve tree factoring as much as possible. 3 From MGs to factorized trees Tree factoring relies on regexp-like operators working on nodes, or more precisely on the subtrees rooted by these nodes. The (informal) notation T [(t1 op t2 )] denotes the application of the operator op on subtrees t1 and t2 in the context of tree T . 3.1 Disjunction The first operator concerns disjunction over nodes, with T [(t1"
W10-4414,C00-1065,0,0.437783,"y of the grammar and its overhead at parsing time. Practically, overgeneration seems to be adequately controlled through the guards, with no obvious overhead. Another reason explaining this behaviour may come from the constraints provided by the forms of the input string. Indeed, tree #198 covers many subcategorization frames, much more than the number of frames usually attached to a given verb. The notion of family attached to a frame as defined in the XTAG model (Doran et al., 1994) is therefore no longer pertinent. Instead, we use a more flexible mechanism based on the notion of hypertags (Kinyon, 2000). A hypertag is a feature structure, issued from the class decorations, providing information on the linguistic phenomena covered by a tree or allowed by a word. The anchoring of a tree by a word is only possible if their hypertags do unify, as illustrated by Fig. 2. The verb “promettre/ to promise” may anchor tree #198, only selecting (after unification) the presence of an optional object (arg1.kind) and of an optional prepositional object (arg2.kind) introduced by “à/to” (arg2.pcas). The link between an hypertag H and the allowed syntactic constructions is done through the variables occurrin"
W10-4414,W03-3020,0,0.0254605,"uards by removing the parts that are trivially true or false3 . Obviously, if a guard is of the form G = G1 ∧ G2 and G1 is shown to be trivially true (resp. false) then G may be reduced to G2 (resp. to false). Guards are heavily used in FRMG. Actually, positive guards are also used on non optional nodes to attach disjunctive constraints to a node, or constraints to a node under a disjunctive node, for instance to state that a sentential subject should be in subjunctive mood: 3.4 Shuffling S_Sent + node (V) . t o p . mood= v a l u e ( ~ s u b j u n c t i v e ) Less known but well motivated in (Nederhof et al., 2003) to handle free word ordering, the shuffling (or interleaving) of two sequences (ai )i=1···n ##(bj )j=1···m returns all sequences containing all ai and bj in any order that preserves the original orderings (i.e. ai &lt; ai+1 and bj &lt; bj+1 ). For instance, the shuffling of a, b with c, d returns the sequences “a, b, c, d”, “a, c, b, d”, “a, c, d, b”, “c, a, b, d”, “c, a, d, b”, and “c, d, a, b”. In our case, the shuffle operator ## is used on sequences of subtrees, with in particular T [(t1 ##t2 )] ≡ {T [(t1 , t2 )], T [(t2 , t1 )]}. At MG level, shuffling naturally arises from underspecification"
W10-4414,paroubek-etal-2008-easy,0,0.0225254,"Missing"
W10-4414,C02-1153,0,0.152461,"ver, it is well-known that the two last properties easily lead to a combinatorial explosion in term of trees, with large coverage grammars of several thousand trees (or even more) (Crabbé, 2005; Abeillé, 2002). This explosion induces problems of development and maintenance of the grammars, but also of efficiency during parsing. Several approaches have been proposed to remedy to the situation, either on the maintenance side or on the efficiency side. On the maintenance side, besides the notion of families present in the XTAG architecture (Doran et al., 1994), one may cite the use of metarules (Prolo, 2002) to derive trees from the “canonical” versions, and meta-grammars (Candito, 1999; Duchier et al., 2004) where the grammars are derived from a constraint-based modular level of syntactic descriptions organized as an inheritance hierarchy of elementary classes. On the efficiency side, besides more or less clever lexicalization-based filtering techniques (such as suppertagging), one may cite the factorization of common sub-trees using automata (Carroll et al., 1998) or the possibility to attach, modulo regular expressions, several possible tree traversals to a tree (Harbusch and Woch, 2004). Howe"
W10-4414,J95-4002,0,0.116204,"be noted that while it is easy to naively unfold the operators, it is much more difficult and costly to get a minimal set of unfolded trees. 5 Building efficient parsers The French TAG grammar is compiled offline into a chart parser, able to take profit of the factoring operators. Actually, several optimizations, developed for TAGs (and not related to MGs), are also applied to improve the efficiency of the parser. The first optimisation is a static analysis of the grammar to identify the auxiliary trees that behave as left or right auxiliary trees as defined in Tree Insertion Grammars (TIG – (Schabes and Waters, 1995)), a variant of TAGs that may be parsed in cubic time rather than O(n6 ) for TAGs. Roughly speaking, TIG auxiliary trees adjoin material either on the left side or the right side of the adjoined node, which actually corresponds to the behavior of most auxiliary trees. TIG and TAG auxiliary trees may be used simultaneously leading to a hybrid TAG/TIG parser (Alonso and Díaz, 2003). Another static analysis of the grammar is used to identify the node features that are left unmodified through adjoining, greatly reducing the amount of information to be stored in items, and potentially increasing co"
W12-4625,W11-0108,0,0.241602,"Missing"
W12-4625,candito-etal-2010-statistical,0,0.107162,"nces grouped in sets illustrating the various syntactic phenomena and their configuration. Given the annotations and the parse trees, the algorithm basically tries to generalize over the selected nodes and edges, through the following steps: 2. The tree view (right hand panel) where one can select nodes and edges (the red dotted lines); 3. The triggering part (bottom panel) of the induced transformation rule, to be then edited and completed by the transformation part. The examples described below are annotated with the CoNLL scheme used for the dependency version of the French Treebank (FTB) (Candito et al., 2010a; Abeillé et al., 2003). Our goal is to construct a new version of the FTB with deeper syntactic annotations, as a first step towards a shallow semantic representation for FTB. Hence, in the figures 6, 7 and 9, we illustrate some complex syntactic constructions and try to exhibit simple transformations, using the constraints. In the examples, we use the following color code: • Red edges for the final edges after all constraint applications, • Green edges for the initial constrained edges, 1. Extract a graph from the annotations of the first annotated parse tree • Blue edges for non constraine"
W12-4625,C10-2013,0,0.13744,"nces grouped in sets illustrating the various syntactic phenomena and their configuration. Given the annotations and the parse trees, the algorithm basically tries to generalize over the selected nodes and edges, through the following steps: 2. The tree view (right hand panel) where one can select nodes and edges (the red dotted lines); 3. The triggering part (bottom panel) of the induced transformation rule, to be then edited and completed by the transformation part. The examples described below are annotated with the CoNLL scheme used for the dependency version of the French Treebank (FTB) (Candito et al., 2010a; Abeillé et al., 2003). Our goal is to construct a new version of the FTB with deeper syntactic annotations, as a first step towards a shallow semantic representation for FTB. Hence, in the figures 6, 7 and 9, we illustrate some complex syntactic constructions and try to exhibit simple transformations, using the constraints. In the examples, we use the following color code: • Red edges for the final edges after all constraint applications, • Green edges for the initial constrained edges, 1. Extract a graph from the annotations of the first annotated parse tree • Blue edges for non constraine"
W12-4625,C08-1069,0,0.0209318,"n explosion of the number of transformation rules, difficult to create and maintain. And, when not bounding these non local phenomena, it becomes necessary to introduce recursive transformation rules that raise delicate problems of ordering when applying them, as presented in the Grew system (Bonfante et al., 2011b) based on graph rewriting rules. Many approaches have been proposed for tree or graph transformations, such as Top-Down or Bottom-Up Tree Transducers (Courcelle and Engelfriet, 2012), Tree-Walking Transducers (Boja´nczyk, 2008), Synchronous Grammars (Shieber and Schabes, 1990) and (Matsuzaki and Tsujii, 2008) for an application on annotation scheme conversion, or Graph Rewriting Systems based, for instance, on the Single PushOut model (SPO) (Löwe et al., 1993; Geiss et al., 2006). But either they are complex to implement or they suffer from the above mentioned problems (coverage, maintenance, ordering). Moreover, they are not always suited for natural language processing, especially in case of complex phenomena. Based on a preliminary experiment of scheme to scheme transformation, but motivated by more generic linguistic considerations, we propose a simple new two stage model. The first stage esse"
W12-4625,C90-3045,0,0.0812113,"re canonical cases may lead to an explosion of the number of transformation rules, difficult to create and maintain. And, when not bounding these non local phenomena, it becomes necessary to introduce recursive transformation rules that raise delicate problems of ordering when applying them, as presented in the Grew system (Bonfante et al., 2011b) based on graph rewriting rules. Many approaches have been proposed for tree or graph transformations, such as Top-Down or Bottom-Up Tree Transducers (Courcelle and Engelfriet, 2012), Tree-Walking Transducers (Boja´nczyk, 2008), Synchronous Grammars (Shieber and Schabes, 1990) and (Matsuzaki and Tsujii, 2008) for an application on annotation scheme conversion, or Graph Rewriting Systems based, for instance, on the Single PushOut model (SPO) (Löwe et al., 1993; Geiss et al., 2006). But either they are complex to implement or they suffer from the above mentioned problems (coverage, maintenance, ordering). Moreover, they are not always suited for natural language processing, especially in case of complex phenomena. Based on a preliminary experiment of scheme to scheme transformation, but motivated by more generic linguistic considerations, we propose a simple new two"
W13-4906,E12-2012,0,0.139252,"YALOG - SR. The first one is the (relatively straightforward) evolution of the parsing strategy for handling directly non-projective dependency trees, through the addition of some kind of SWAP transition (Nivre, 2009). Our preliminary experiments have shown the importance of larger beam sizes to cover the increased level of ambiguity due to lattices. However, it seems 60 possible to adjust locally the beam size in function of the topology of the lattice, for improved accuracy and faster parsing. It also seems necessary to explore feature filtering, possibly using a tool like M ALT O PTIMIZER (Ballesteros and Nivre, 2012), to determine the most discriminating ones. The current implementation scales correctly w.r.t. sentence length and, to a lesser extent, beam size. Nevertheless, for efficiency reasons, we plan to implement a simple C module for beam management to avoid the manipulation in DYAL OG of sorted lists. Interestingly, such a module, plus the already implemented model manager, should also be usable to speed up the disambiguation process of DYAL OGbased TAG parser FRMG (de La Clergerie, 2005a). Actually, these components could be integrated in a slow but on-going effort to add first-class probabilitie"
W13-4906,W05-1522,1,0.75189,"results, a simple beam-based shift-reduce dependency parser on top of the tabular logic programming system DYAL OG. The parser was also extended to handle ambiguous word lattices, with almost no loss w.r.t. disambiguated input, thanks to specific training, use of oracle segmentation, and large beams. We believe that this result is an interesting new one for shift-reduce parsing. 1 Introduction DYAL OG is a tabular-based logic programming environment, including a language (variant of Prolog), a bootstrapped compiler, and C-based abstract machine. It is mostly used for chart-like parsing (de La Clergerie, 2005b), in particular for a wide coverage French Tree Adjoining Grammar (de La Clergerie, 2005a). However, DYAL OG offers all the power of a programming language a la Prolog, with some specific advantages, and it was tempting to try it on statistical parsing paradigms. The SPMRL 2013 shared task (Seddah et al., 2013) was an interesting opportunity to develop a simple (non-deterministic) beam-based shift-reduce dependency parser, called DYALOG - SR, inspired by (Huang and Sagae, 2010). The main advantage of logic programming is the (almost) transparent handling of non-determinism, useful for instan"
W13-4906,P13-2111,0,0.147635,"Missing"
W13-4906,P09-2056,0,0.0401832,"modes, we added a subcategorization feature for verbs (with a list value), again extracted from L EFFF. For Arabic, Hebrew, and Swedish, the lemma feature is removed because of the absence of lemma in the treebanks. Similarly, for Polish and German, with identical CPOS and POS tagsets, we remove the cat feature. For Hungarian, the SubPOS morphosyntactic feature is appended to the fullcat feature, to get a 3 We used the shared task Arabic data set, originally provided by the LDC (Maamouri et al., 2004), specifically its SPMRL 2013 dependency instance, derived from the Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) richer set of POS. The set of dependency labels being large (450 labels), we split the labels into lists of more elementary ones for the label features. Similarly, the Korean POS tags are also split into lists, because of their large number (2743 tags) and of their compound structure. For French, Hebrew, and Korean, in order to compensate initially large differences in performance between the gold and pred modes, we added, for the pred mode, dict features filled by predicted information about the possible tags for a given form, thanks to the dict lexicons provided by the"
W13-4906,P10-1110,0,0.308848,"variant of Prolog), a bootstrapped compiler, and C-based abstract machine. It is mostly used for chart-like parsing (de La Clergerie, 2005b), in particular for a wide coverage French Tree Adjoining Grammar (de La Clergerie, 2005a). However, DYAL OG offers all the power of a programming language a la Prolog, with some specific advantages, and it was tempting to try it on statistical parsing paradigms. The SPMRL 2013 shared task (Seddah et al., 2013) was an interesting opportunity to develop a simple (non-deterministic) beam-based shift-reduce dependency parser, called DYALOG - SR, inspired by (Huang and Sagae, 2010). The main advantage of logic programming is the (almost) transparent handling of non-determinism, useful for instance to handle ambiguous word lattices. DYAL OG allows an easy tabulation of items, and their fast retrieval (thanks to full term indexing), needed for the dynamic programming part of the algorithm. Thanks to structure sharing and term hashing, it also reduces the costs related to the tabulation of multiple items (sharing subparts) and to term unification. Logic programs tend to be very concise, with, in our case, around 1500 lines of DYAL OG code. However, one of the disadvantages"
W13-4906,N12-1015,0,0.144054,"Missing"
W13-4906,P05-1013,0,0.0666426,"into lists, because of their large number (2743 tags) and of their compound structure. For French, Hebrew, and Korean, in order to compensate initially large differences in performance between the gold and pred modes, we added, for the pred mode, dict features filled by predicted information about the possible tags for a given form, thanks to the dict lexicons provided by the IMS_SZEGED team. Finally, we discovered very late that the dependency trees were not necessarily projective for a few languages. A last-second solution was to use the MALT projectivization / deprojectivization wrappers (Nivre and Nilsson, 2005) to be able to train on projectivized versions of the treebanks for German, Hungarian, and Swedish, while returning non projective trees. 4 First results Under the team label ALPAGE-DYALOG, we have returned parsed data for the 9 languages of the shared task, for the full and 5k training size modes, and for the gold and pred data modes. For each configuration, we provided 3 runs, for beam sizes 8, 6, and 4. The results are synthesized in Tables 2, with LAS4 on the test and dev files, contrasted with the LAS for the best system, the baseline, and the mean LAS of all systems. The tables show that"
W13-4906,nivre-etal-2006-talbanken05,0,0.0191483,"e is a list, the traversal is run for all its components (with summation of all found costs). 3 Preparing the shared task We trained the parser on the training and dev dependency treebanks kindly provided by the organizers for the 9 languages of the task, namely Arabic3 , Basque (Aduriz et al., 2003), French (Abeillé et al., 2003), German (Brants et al., 2002; Seeker and Kuhn, 2012), Hebrew (Sima’an et al., 2001; Tsarfaty, 2013; Goldberg, 2011), Hungarian (Vincze et al., 2010; Csendes et al., 2005), Korean (Choi ´ et al., 1994; Choi, 2013) , Polish (Swidzi´ nski and Woli´nski, 2010), Swedish (Nivre et al., 2006). Being very short in time, we essentially used the same set of around 110 templates for all languages. Nevertheless, minimal tuning was performed for some languages and for the pred data mode (when using predicted data), as summarized below. For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode. Predicted features mwehead and pred were added, thanks to a list of MWEs collected in the gold treebank and in the French lexicon L EFFF (Sagot et al., 2006). We also added the predicted feature is_number to help detecting numerical MWEs such as 120 000, and also"
W13-4906,P09-1040,0,0.0139914,"3 shared task has shown its potential, even if far from the results of the best participants. As far as we know, DYALOG - SR is also the first system to show that shift-parsing techniques can be applied on ambiguous lattices, with almost no accuracy loss and with only minimal modifications (but large beams). Several options are currently under consideration for improving the performances of DYALOG - SR. The first one is the (relatively straightforward) evolution of the parsing strategy for handling directly non-projective dependency trees, through the addition of some kind of SWAP transition (Nivre, 2009). Our preliminary experiments have shown the importance of larger beam sizes to cover the increased level of ambiguity due to lattices. However, it seems 60 possible to adjust locally the beam size in function of the topology of the lattice, for improved accuracy and faster parsing. It also seems necessary to explore feature filtering, possibly using a tool like M ALT O PTIMIZER (Ballesteros and Nivre, 2012), to determine the most discriminating ones. The current implementation scales correctly w.r.t. sentence length and, to a lesser extent, beam size. Nevertheless, for efficiency reasons, we"
W13-4906,sagot-etal-2006-lefff,1,0.795257,"al., 2005), Korean (Choi ´ et al., 1994; Choi, 2013) , Polish (Swidzi´ nski and Woli´nski, 2010), Swedish (Nivre et al., 2006). Being very short in time, we essentially used the same set of around 110 templates for all languages. Nevertheless, minimal tuning was performed for some languages and for the pred data mode (when using predicted data), as summarized below. For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode. Predicted features mwehead and pred were added, thanks to a list of MWEs collected in the gold treebank and in the French lexicon L EFFF (Sagot et al., 2006). We also added the predicted feature is_number to help detecting numerical MWEs such as 120 000, and also a is_capitalized feature. For all data modes, we added a subcategorization feature for verbs (with a list value), again extracted from L EFFF. For Arabic, Hebrew, and Swedish, the lemma feature is removed because of the absence of lemma in the treebanks. Similarly, for Polish and German, with identical CPOS and POS tagsets, we remove the cat feature. For Hungarian, the SubPOS morphosyntactic feature is appended to the fullcat feature, to get a 3 We used the shared task Arabic data set, or"
W13-4906,seeker-kuhn-2012-making,0,0.0344061,"label. By traversing in a synchronous way the model trie and the argument tree, and accumulating costs for all possible actions and labels, a single query returns in order the cost for the b best actions. Furthermore, when a feature value is a list, the traversal is run for all its components (with summation of all found costs). 3 Preparing the shared task We trained the parser on the training and dev dependency treebanks kindly provided by the organizers for the 9 languages of the task, namely Arabic3 , Basque (Aduriz et al., 2003), French (Abeillé et al., 2003), German (Brants et al., 2002; Seeker and Kuhn, 2012), Hebrew (Sima’an et al., 2001; Tsarfaty, 2013; Goldberg, 2011), Hungarian (Vincze et al., 2010; Csendes et al., 2005), Korean (Choi ´ et al., 1994; Choi, 2013) , Polish (Swidzi´ nski and Woli´nski, 2010), Swedish (Nivre et al., 2006). Being very short in time, we essentially used the same set of around 110 templates for all languages. Nevertheless, minimal tuning was performed for some languages and for the pred data mode (when using predicted data), as summarized below. For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode. Predicted features mwehead and"
W13-4906,P13-2103,0,0.0257384,"ie and the argument tree, and accumulating costs for all possible actions and labels, a single query returns in order the cost for the b best actions. Furthermore, when a feature value is a list, the traversal is run for all its components (with summation of all found costs). 3 Preparing the shared task We trained the parser on the training and dev dependency treebanks kindly provided by the organizers for the 9 languages of the task, namely Arabic3 , Basque (Aduriz et al., 2003), French (Abeillé et al., 2003), German (Brants et al., 2002; Seeker and Kuhn, 2012), Hebrew (Sima’an et al., 2001; Tsarfaty, 2013; Goldberg, 2011), Hungarian (Vincze et al., 2010; Csendes et al., 2005), Korean (Choi ´ et al., 1994; Choi, 2013) , Polish (Swidzi´ nski and Woli´nski, 2010), Swedish (Nivre et al., 2006). Being very short in time, we essentially used the same set of around 110 templates for all languages. Nevertheless, minimal tuning was performed for some languages and for the pred data mode (when using predicted data), as summarized below. For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode. Predicted features mwehead and pred were added, thanks to a list of MWEs col"
W13-4906,W13-4917,1,\N,Missing
W13-4906,vincze-etal-2010-hungarian,0,\N,Missing
W13-4917,P06-1084,0,0.0139791,"s of incomplete lexicon coverage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leadi"
W13-4917,P08-1083,1,0.743016,"in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respectable accuracy.25 4.7 The Hungarian Treebank Hungarian is an agglutinative language, thus a lemma can have hundreds of word forms due to derivational or inflectional affixation (nomina"
W13-4917,W13-4903,0,0.0228459,"such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Re"
W13-4917,W10-1411,1,0.835873,"challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and w"
W13-4917,W10-1408,1,0.383126,"Missing"
W13-4917,E12-2012,1,0.0774441,"parsing evaluation campaign SANCL 2012 (Petrov and McDonald, 2012). The present shared task was extremely demanding on our participants. From 30 individuals or teams who registered and obtained the data sets, we present results for the seven teams that accomplished successful executions on these data in the relevant scenarios in the given the time frame. 5.1 Dependency Track Seven teams participated in the dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To"
W13-4917,W13-4907,0,0.0733412,"Missing"
W13-4917,W10-1404,0,0.0222482,"merged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and"
W13-4917,W13-4916,1,0.230959,"Missing"
W13-4917,H91-1060,0,0.199934,"n the expected performance of parsers in real-world scenarios. Results reported for MRLs using gold morphological information are then, at best, optimistic. One reason for adopting this less-than-realistic evaluation scenario in previous tasks has been the lack of sound metrics for the more realistic scenario. Standard evaluation metrics assume that the number of terminals in the parse hypothesis equals the number of terminals in the gold tree. When the predicted morphological segmentation leads to a different number of terminals in the gold and parse trees, standard metrics such as ParsEval (Black et al., 1991) or Attachment Scores (Buchholz and Marsi, 2006) fail to produce a score. In this task, we use TedEval (Tsarfaty et al., 2012b), a metric recently suggested for joint morpho-syntactic evaluation, in which normalized tree-edit distance (Bille, 2005) on morphosyntactic trees allows us to quantify the success on the joint task in realistic parsing scenarios. Finally, the previous tasks focused on dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performa"
W13-4917,D12-1133,1,0.807979,"cy-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed"
W13-4917,C10-1011,0,0.0102695,"r system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-"
W13-4917,W07-1506,0,0.220289,"s of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version is available from http://www.ims. uni-stuttgart.de/forschung/ressourcen/ korpora/tiger.html 159 to the &quot;raising&quot; algorithm described by Boyd (2007). In a third steps, all those newly introduced nodes that did not cover the head daughter of the original discontinuous node were deleted. For the second and the third step, we used the same script as for the Swedish constituency data. Predicted Morphology For the predicted scenario, a single sequence of POS tags and morphological features has been assigned using the MATE toolchain via a model trained on the train set via crossvalidation on the training set. The MATE toolchain was used to provide predicted annotation for lemmas, POS tags, morphology, and syntax. In order to achieve the best re"
W13-4917,W06-2920,0,0.827477,"ouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency relations are marked between input tokens directly, and allow the annotation of non-projective dependencies that are parseable efficiently. Dependency syntax was applied to the description of different types of languages (Tesnière, 1959; Mel’ˇcuk, 2001), which raised the hope that in these settings, parsing MRLs will further improve. However, the 2007 shared task organizers (Nivre et al., 2007a) concluded that: &quot;[Performance] classes are more ea"
W13-4917,W10-1409,1,0.0435485,"for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing"
W13-4917,candito-etal-2010-statistical,1,0.0386487,"g of 18,535 sentences,18 split into 14,759 sentences for training, 1,235 sentences for development, and 2,541 sentences for the final evaluation.19 Adapting the Data to the Shared Task The constituency trees are provided in an extended PTB bracketed format, with morphological features at the pre-terminal level only. They contain slight, automatically performed, modifications with respect to the original trees of the French treebank. The syntagmatic projection of prepositions and complementizers was normalized, in order to have prepositions and complementizers as heads in the dependency trees (Candito et al., 2010). The dependency representations are projective dependency trees, obtained through automatic conversion from the constituency trees. The conversion procedure is an enhanced version of the one described by Candito et al. (2010). Both the constituency and the dependency representations make use of coarse- and fine-grained POS tags (CPOS and FPOS respectively). The CPOS are the categories from the original treebank. The FPOS 18 The process of functional annotation is still ongoing, the objective of the FTB providers being to have all the 20000 sentences annotated with functional tags. 19 The firs"
W13-4917,W08-2102,0,0.0353476,"troduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality par"
W13-4917,A00-2018,0,0.0705659,"n analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing E"
W13-4917,W11-3801,1,0.926035,"ers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard Engli"
W13-4917,chrupala-etal-2008-learning,0,0.045003,"Missing"
W13-4917,W10-1406,0,0.0618994,"Missing"
W13-4917,W13-4909,0,0.199525,"derived from the Hebrew Treebank V2 (Sima’an et al., 2001; Guthmann et al., 2009). The treebank is based on just over 6000 sentences from the daily newspaper ‘Ha’aretz’, manually annotated with morphological information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same"
W13-4917,J03-4003,0,0.48866,"omparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the ma"
W13-4917,W13-4905,1,0.719588,"method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZE"
W13-4917,W13-4906,1,0.680312,"dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 200"
W13-4917,W08-1301,0,0.0393335,"Missing"
W13-4917,P98-1062,0,0.0491049,"Missing"
W13-4917,P08-1109,0,0.0220424,"ences. In order to avoid comparing apples and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Str"
W13-4917,J13-1005,1,0.838989,"html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? How to parse effectively in the face of resource scarcity? The first step to answering all of these"
W13-4917,W13-4908,1,0.872762,"Missing"
W13-4917,W10-1412,1,0.789087,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,N10-1115,1,0.576439,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,P08-1085,1,0.364225,"overage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respe"
W13-4917,E09-1038,1,0.867766,"ices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming to the lexical resource used to build the lattices, and is shared by the two treebanks. The higher level is syntactic, and follows the tag set and annotation decisions of the original constituency treebank.23 In addition, we unified the representation of morphological features, and fixed inconsistencies and mistakes in the treebanks. Data Split The Hebrew treebank is one of the smallest in our language set, and hence it is provided in only the small (5k) setting. For the sake of comparabilit"
W13-4917,C10-1045,1,0.826872,"nflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Haba"
W13-4917,W12-3410,0,0.0157938,"umulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realis"
W13-4917,J13-1009,1,0.747017,"Missing"
W13-4917,P09-2056,1,0.833708,".2 The Arabic Treebanks Arabic is a morphologically complex language which has rich inflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional A"
W13-4917,D07-1116,1,0.604822,"010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Habash et al., 2007). The CATiB treebank uses the word tokenization of the PATB 11 The LDC kindly provided their latest version of the Arabic Treebanks. In particular, we used PATB 1 v4.1 (Maamouri et al., 2005), PATB 2 v3.1 (Maamouri et al., 2004a) and PATB 3 v3.3. (Maamouri et al., 2009) train: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS tags #total NTs Dep. Label Set Size train5k: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS Tags #total NTs Dep. Label Set Size dev: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Toke"
W13-4917,P07-2053,0,0.0323622,"Missing"
W13-4917,D07-1097,1,0.346865,"Missing"
W13-4917,D10-1002,0,0.0151688,"oaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predica"
W13-4917,P08-1067,0,0.0226773,"a-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information co"
W13-4917,J98-4004,0,0.0891486,"ir strengths and weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying t"
W13-4917,J13-1006,1,0.798597,"hbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? Ho"
W13-4917,P03-1054,0,0.00438043,"d weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank"
W13-4917,W06-1614,1,0.812546,"nd machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) hi"
W13-4917,kubler-etal-2008-compare,1,0.91565,"node to the root node in the output tree and the corresponding path in the gold tree. The path consists of a sequence of node labels between the terminal node and the root node, and the similarity of two paths is calculated by using the Levenshtein distance. This distance is normalized by path length, and the score of the tree is an aggregated score of the values for all terminals in the tree (xt is the leaf-ancestor path of t in tree x). P LA(h, g) = t∈yield(g) Lv(ht ,gt )/(len(ht )+len(gt )) |yield(g)| This metric was shown to be less sensitive to differences between annotation schemes in (Kübler et al., 2008), and was shown by Rehbein and van Genabith (2007a) to evaluate trees more faithfully than ParsEval in the face of certain annotation decisions. We used the implementation of Wagner (2012).6 3.4.2 Evaluation Metrics for Dependency Structures Attachment Scores Labeled and Unlabeled Attachment scores have been proposed as evaluation metrics for dependency parsing in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007a) and have since assumed the role of standard metrics in multiple shared tasks and independent studies. Assume that g, h are gold and hypothesized dependency trees"
W13-4917,W12-3408,1,0.878953,"Missing"
W13-4917,P03-1056,0,0.0207769,"disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on depend"
W13-4917,W12-4615,1,0.809959,"ly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This was done in three steps. In the first step, the head daughters of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version"
W13-4917,J93-2004,0,0.0437888,"participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend."
W13-4917,D10-1004,0,0.0390834,"nd MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for"
W13-4917,J13-1008,1,0.913933,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,W13-4910,1,0.915357,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,N06-1020,0,0.225446,"for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on"
W13-4917,P05-1012,0,0.042194,"Missing"
W13-4917,moreno-etal-2000-treebank,0,0.0581254,"e generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency"
W13-4917,nivre-etal-2006-talbanken05,1,0.442193,"subject agreement with respect to person and number has been dropped in modern Swedish. The Data Set The Swedish data sets are taken from the Talbanken section of the Swedish Treebank (Nivre and Megyesi, 2007). Talbanken is a syntactically annotated corpus developed in the 1970s, originally annotated according to the MAMBA scheme (Teleman, 1974) with a syntactic layer consisting of flat phrase structure and grammatical functions. The syntactic annotation was later automatically converted to full phrase structure with grammatical functions and from that to dependency structure, as described by Nivre et al. (2006). Both the phrase structure and the dependency version use the functional labels from the original MAMBA scheme, which provides a fine-grained classification of syntactic functions with 65 different labels, while the phrase structure annotation (which had to be inferred automatically) uses a coarse set of only 8 labels. For the release of the Swedish treebank, the POS level was re-annotated to conform to the current de facto standard for Swedish, which is the Stockholm-Umeå tagset (Ejerhed et al., 1992) with 25 base tags and 25 morpho-syntactic features, which together produce over 150 complex"
W13-4917,P06-1055,0,0.480329,"as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it"
W13-4917,N10-1003,0,0.0195824,"2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for morphological analysis and POS tagging. Finally, as already mentioned, AI:KU clusters words and POS tags in an unsupervised fashion exploiting additional, un-annotated data. 5.2 Constituency Track A single team participated in the constituency parsing task, the IMS:S ZEGED :CIS team (Björkelund et al., 2013). Their phrase-structure parsing system uses a combination of 8 PCFG-LA parsers, trained using a product-of-grammars procedure (Petrov, 2010). The 50-best parses of this combination are then reranked by a model based on the reranker by Charniak and Johnson (2005).33 5.3 6.1 Baselines We additionally provide the results of two baseline systems for the nine languages, one for constituency parsing and one for dependency parsing. For the dependency track, our baseline system is MaltParser in its default configuration (the arc-eager algorithm and liblinear for training). Results marked as BASE :M ALT in the next two sections report the results of this baseline system in different scenarios. The constituency parsing baseline is based on"
W13-4917,W07-2460,0,0.109747,"Missing"
W13-4917,D07-1066,0,0.0884872,"Missing"
W13-4917,W11-3808,0,0.027114,"rameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer an"
W13-4917,N06-2033,0,0.0563478,"rst dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2"
W13-4917,schmid-etal-2004-smor,0,0.00857226,"information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming t"
W13-4917,W10-1410,1,0.889145,"Missing"
W13-4917,seeker-kuhn-2012-making,1,0.106665,"n constituency data set is based on the TiGer treebank release 2.2.21 The original annotation scheme represents discontinuous constituents such that all arguments of a predicate are always grouped under a single node regardless of whether there is intervening material between them or not (Brants et al., 2002). Furthermore, punctuation and several other elements, such as parentheses, are not attached to the tree. In order to make the constituency treebank usable for PCFG parsing, we adapted this treebank as described shortly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This w"
W13-4917,P12-1046,0,0.00731402,"based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formatio"
W13-4917,W11-3803,0,0.0414253,"to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCF"
W13-4917,W10-1405,1,0.891538,"Missing"
W13-4917,W10-1401,1,0.779419,"sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 146–182, c Seattle, Washington, USA, 18 October 2013. 2013 Association for Computational Linguistics recently, advances in PCFG-LA parsing (Petrov et al., 2006) and language-agnostic data-driven dependency parsing (McD"
W13-4917,D11-1036,1,0.926772,"dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performance between parsers of different types. We are now faced with an additional question: how can we compare parsing results across different frameworks? Adopting standard metrics will not suffice as we would be comparing apples and oranges. In contrast, TedEval is defined for both phrase structures and dependency structures through the use of an intermediate representation called function trees (Tsarfaty et al., 2011; Tsarfaty et al., 2012a). Using TedEval thus allows us to explore both dependency and constituency parsing frameworks and meaningfully compare the performance of parsers of different types. 149 3 3.1 Defining the Shared-Task Input and Output We define a parser as a structure prediction function that maps sequences of space-delimited input tokens (henceforth, tokens) in a language to a set of parse trees that capture valid morpho-syntactic structures in that language. In the case of constituency parsing, the output structures are phrase-structure trees. In dependency parsing, the output consis"
W13-4917,E12-1006,1,0.148172,"er languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologicall"
W13-4917,P13-2103,1,0.111695,"les and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Structures ParsEval The ParsEval metrics (B"
W13-4917,P11-2033,1,0.563308,"em, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure o"
W13-4917,R13-1099,1,0.0375053,"orphology In order to provide the same POS tag set for the constituent and dependency treebanks, we used the dependency POS tagset for both treebank instances. Both versions of the treebank are available with gold standard and automatic morphological annotation. The automatic POS tagging was carried out by a 10-fold cross-validation on the shared task data set by magyarlanc, a natural language toolkit for processing Hungarian texts (segmentation, morphological analysis, POS tagging, and dependency parsing). The annotation provides POS tags and deep morphological features for each input token (Zsibrita et al., 2013).28 28 The full data sets of both the constituency and dependency versions of the Szeged Treebank are available at 161 4.8 The Korean Treebank The Treebank The Korean corpus is generated by collecting constituent trees from the K AIST Treebank (Choi et al., 1994), then converting the constituent trees to dependency trees using head-finding rules and heuristics. The K AIST Treebank consists of about 31K manually annotated constituent trees from 97 different sources (e.g., newspapers, novels, textbooks). After filtering out trees containing annotation errors, a total of 27,363 trees with 350,090"
W13-4917,E93-1064,0,\N,Missing
W13-4917,C00-1001,0,\N,Missing
W13-4917,C10-1061,1,\N,Missing
W13-4917,J13-1003,1,\N,Missing
W13-4917,C08-1112,1,\N,Missing
W13-4917,W08-1008,1,\N,Missing
W13-4917,P05-1022,0,\N,Missing
W13-4917,P98-1063,0,\N,Missing
W13-4917,C98-1060,0,\N,Missing
W13-4917,vincze-etal-2010-hungarian,1,\N,Missing
W13-4917,D07-1096,1,\N,Missing
W13-5706,adolphs-etal-2008-fine,0,0.0336366,"Missing"
W13-5706,H91-1060,0,0.642208,"Missing"
W13-5706,D12-1133,0,0.068398,"Missing"
W13-5706,P06-2006,0,0.0775848,"Missing"
W13-5706,W97-1502,0,0.106021,"Missing"
W13-5706,cer-etal-2010-parsing,0,0.060772,"Missing"
W13-5706,P07-1032,0,0.0642383,"Missing"
W13-5706,W08-1301,0,0.0382472,"Missing"
W13-5706,D13-1120,0,0.0326728,"Missing"
W13-5706,I11-1100,0,0.0443292,"Missing"
W13-5706,P10-1035,0,0.056575,"Missing"
W13-5706,W01-0521,0,0.0325518,"Missing"
W13-5706,J07-3004,0,0.0185705,"sed learning techniques to improve the performances of FRMG to the levels reached by the statistical parsers. 1 Introduction Most stochastic parsers are trained and evaluated on the same source treebank (for instance the Penn TreeBank), which, by definition, avoid all problems related to differences between the structures returned by the parsers and those present in the treebank. Some symbolic or hybrid parsers are evaluated on a treebank specifically designed for their underlying formalism, possibly by converting and hand-correcting the treebank from some other annotation scheme (as done in (Hockenmaier and Steedman, 2007)). Besides the cost of the operation, an issue concerns the comparison with other parsers. By contrast, the most problematic case remains the evaluation of a parser on an unrelated treebank and scheme (Sagae et al., 2008). This situation arose for French with the recent emergence of several statistical parsers trained and evaluated on the French TreeBank (FTB) (Abeillé et al., 2003), in particular under its dependency version (Candito et al., 2010b) represented in CONLL format (Nivre et al., 2007). On the other hand, older parsing systems still exist for French, most of them not based on stati"
W13-5706,P13-3005,0,0.0258857,"Missing"
W13-5706,W12-3602,0,0.0369018,"Missing"
W13-5706,W03-2401,0,0.110538,"Missing"
W13-5706,J93-2004,0,0.0477714,"Missing"
W13-5706,D07-1013,0,0.101903,"Missing"
W13-5706,A00-2022,0,0.0900062,"Missing"
W13-5706,P06-1055,0,0.158462,"Missing"
W13-5706,W10-2105,0,0.0525222,"Missing"
W13-5706,C12-1147,0,0.0343892,"Missing"
W13-5706,W11-2923,0,0.0332727,"Missing"
W13-5706,W07-2207,0,0.0358833,"Missing"
W13-5706,P09-1043,0,0.049787,"Missing"
W13-5706,candito-etal-2010-statistical,0,\N,Missing
W13-5706,W05-1522,1,\N,Missing
W13-5706,paroubek-etal-2006-data,0,\N,Missing
W18-7005,S15-2017,0,0.0685004,"Missing"
W18-7005,L18-1008,0,0.0395658,"s... • Metrics based on the baseline Q U E ST features (17 features) (Specia et al., 2013), such as statistics on the number of words, word lengths, language model probability and ngram frequency. Features In our experiments, we compared about 60 elementary metrics, which can be organised as follows: • Metrics based on other features: frequency table position, concreteness as extracted from Brysbaert et al.’s 2014 list, language model probability of words using a convolutional sequence to sequence model from (Gehring et al., 2017), comparison methods using pretrained fastText word embeddings (Mikolov et al., 2018) or Skip-thought sentence embeddings (Kiros et al., 2015). • MT metrics – BLEU, ROUGE, METEOR, TERp – Variants of BLEU: BLEU 1gram, BLEU 3gram, BLEU 2gram, BLEU 4gram and seven smoothing methods5 from NLTK (Bird and Loper, 2004). – Intermediate components of TERp inˇ spired by (Stajner et al., 2016a): e.g. number of insertions, deletions, shifts... TABLE 2 lists 30 of the elementary metrics that we compared, which are those that we found to correlate the most with human judgments on one or more of the three dimensions (grammaticality, meaning preservation, simplicity). 3.3 4 http://qats2016.gi"
W18-7005,P04-3031,0,0.120063,"compared about 60 elementary metrics, which can be organised as follows: • Metrics based on other features: frequency table position, concreteness as extracted from Brysbaert et al.’s 2014 list, language model probability of words using a convolutional sequence to sequence model from (Gehring et al., 2017), comparison methods using pretrained fastText word embeddings (Mikolov et al., 2018) or Skip-thought sentence embeddings (Kiros et al., 2015). • MT metrics – BLEU, ROUGE, METEOR, TERp – Variants of BLEU: BLEU 1gram, BLEU 3gram, BLEU 2gram, BLEU 4gram and seven smoothing methods5 from NLTK (Bird and Loper, 2004). – Intermediate components of TERp inˇ spired by (Stajner et al., 2016a): e.g. number of insertions, deletions, shifts... TABLE 2 lists 30 of the elementary metrics that we compared, which are those that we found to correlate the most with human judgments on one or more of the three dimensions (grammaticality, meaning preservation, simplicity). 3.3 4 http://qats2016.github.io/shared.html https://www.nltk.org/api/nltk. translate.html#nltk.translate.bleu_ score.SmoothingFunction 5 Experimental setup Evaluation of elementary metrics We rank all features by comparing their behaviour with human 32"
W18-7005,P14-1041,0,0.472366,"Missing"
W18-7005,W14-1206,0,0.0550454,"Missing"
W18-7005,D17-1064,0,0.0138618,"aluate the structural simplicity of a TS system output given the corresponding source sentence. SAMSA is maximized when the simplified text is a sequence of short and simple sentences, each accounting for one semantic event in the original sentence. It relies on an in-depth analysis of the source sentence and the corresponding output, based on a semantic parser and a word aligner. A drawback of this approach is that good quality semantic parsers are only available for a handful of languages. The intuition that sentence splitting is an important sub-task for producing simplified text motivated Narayan et al. (2017) to organize the Split and Rephrase shared task, which was dedicated to this problem. 2.3 Figure 1: Label repartition on the QATS Shared task this end, we use the dataset provided in the QATS shared task. We first compare the behaviour of elementary metrics, which range from commonly used metrics such as BLEU to basic metrics based on a single low-level feature such as sentence length. We then compare the effect of aggregating these elementary metrics into more complex ones and compare our results with the state of the art, based on the QATS shared task data and results. Other metrics One can"
W18-7005,W15-1604,0,0.170014,"Missing"
W18-7005,P02-1040,0,0.106586,"city in this context. Previous works often rely on the intuition of human annotators to evaluate the level of simplicity of a TS system output. 29 Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA), pages 29–38, c Tilburg, The Netherlands, November 8 2018. 2018 Association for Computational Linguistics evaluation methods and traditional quality estimation features. We then present the QATS shared task and the associated dataset, which we use for our experiments. Finally we compare all methods in a reference-less setting and analyze the results. evaluation metrics such as BLEU (Papineni et al., 2002). However, MT evaluation metrics rely on the existence of parallel corpora of source sentences and manually produced reference translations, which are available on a large scale for many language pairs (Tiedemann, 2012). TS datasets are less numerous and smaller. Moreover, they are often automatically extracted from comparable corpora rather than strictly parallel corpora, which results in noisier reference data. For example, the PWKP dataset (Zhu et al., 2010) consists of 100,000 sentences from the English Wikipedia automatically aligned with sentences from the Simple English Wikipedia based"
W18-7005,C96-2183,0,0.67445,"er version of a source text that is both easier to read and to understand, thus improving the accessibility of text for people suffering from a range of disabilities such as aphasia (Carroll et al., 1998) or dyslexia (Rello et al., 2013), as well as for second language learners (Xia et al., 2016) and people with low literacy (Watanabe et al., 2009). This topic has been researched for a variety of languages such as English (Zhu et al., 2010; Wubben 1 Note that text simplification has also been used as a preprocessing step for other natural language processing tasks such as machine translation (Chandrasekar et al., 1996) and semantic role labelling (Vickrey and Koller, 2008). 2 There is no unique way to define the notion of simplicity in this context. Previous works often rely on the intuition of human annotators to evaluate the level of simplicity of a TS system output. 29 Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA), pages 29–38, c Tilburg, The Netherlands, November 8 2018. 2018 Association for Computational Linguistics evaluation methods and traditional quality estimation features. We then present the QATS shared task and the associated dataset, which we use for our experiments. Final"
W18-7005,W15-5710,0,0.0361497,"cs One can also estimate the quality of a TS system output based on simple features extracted from it. For instance, the Q U E ST framework for quality estimation in MT gives a number of useful baseline features for evaluating an output sentence (Specia et al., 2013). These features range from simple statistics, such as the number of words in the sentence, to more sophisticated features, such as the probability of the sentence according to a language model. Several teams who participated in the QATS shared task used metrics ˇ based on this framework, namely SMH (Stajner et al., 2016a), UoLGP (Rios and Sharoff, 2015) and UoW (B´echara et al., 2015). Readability metrics such as Flesch-Kincaid Grade Level (FKGL) and Flesch Reading Ease (FRE) (Kincaid et al., 1975) have been extensively used for evaluating simplicity. These two metrics, which were shown experimentally to give good results, are linear combinations of the number of words per sentence and the number of syllables per word, using carefully adjusted weights. 3 3.1 The QATS shared task ˇ The data from the QATS shared task (Stajner et al., 2016b) consists of a collection of 631 pairs of english sentences composed of a source sentence extracted from"
W18-7005,P08-1040,0,0.100971,"and to understand, thus improving the accessibility of text for people suffering from a range of disabilities such as aphasia (Carroll et al., 1998) or dyslexia (Rello et al., 2013), as well as for second language learners (Xia et al., 2016) and people with low literacy (Watanabe et al., 2009). This topic has been researched for a variety of languages such as English (Zhu et al., 2010; Wubben 1 Note that text simplification has also been used as a preprocessing step for other natural language processing tasks such as machine translation (Chandrasekar et al., 1996) and semantic role labelling (Vickrey and Koller, 2008). 2 There is no unique way to define the notion of simplicity in this context. Previous works often rely on the intuition of human annotators to evaluate the level of simplicity of a TS system output. 29 Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA), pages 29–38, c Tilburg, The Netherlands, November 8 2018. 2018 Association for Computational Linguistics evaluation methods and traditional quality estimation features. We then present the QATS shared task and the associated dataset, which we use for our experiments. Finally we compare all methods in a reference-less setting a"
W18-7005,P12-1107,0,0.140763,"Missing"
W18-7005,P13-4014,0,0.0857038,"of elementary metrics, which range from commonly used metrics such as BLEU to basic metrics based on a single low-level feature such as sentence length. We then compare the effect of aggregating these elementary metrics into more complex ones and compare our results with the state of the art, based on the QATS shared task data and results. Other metrics One can also estimate the quality of a TS system output based on simple features extracted from it. For instance, the Q U E ST framework for quality estimation in MT gives a number of useful baseline features for evaluating an output sentence (Specia et al., 2013). These features range from simple statistics, such as the number of words in the sentence, to more sophisticated features, such as the probability of the sentence according to a language model. Several teams who participated in the QATS shared task used metrics ˇ based on this framework, namely SMH (Stajner et al., 2016a), UoLGP (Rios and Sharoff, 2015) and UoW (B´echara et al., 2015). Readability metrics such as Flesch-Kincaid Grade Level (FKGL) and Flesch Reading Ease (FRE) (Kincaid et al., 1975) have been extensively used for evaluating simplicity. These two metrics, which were shown exper"
W18-7005,W16-0502,0,0.0198883,"nt of (sentencelevel) MT. The standard approach to automatic TS evaluation is therefore to view the task as a translation problem and to use machine translation (MT) Introduction Text simplification (hereafter TS) has received increasing interest by the scientific community in recent years. It aims at producing a simpler version of a source text that is both easier to read and to understand, thus improving the accessibility of text for people suffering from a range of disabilities such as aphasia (Carroll et al., 1998) or dyslexia (Rello et al., 2013), as well as for second language learners (Xia et al., 2016) and people with low literacy (Watanabe et al., 2009). This topic has been researched for a variety of languages such as English (Zhu et al., 2010; Wubben 1 Note that text simplification has also been used as a preprocessing step for other natural language processing tasks such as machine translation (Chandrasekar et al., 1996) and semantic role labelling (Vickrey and Koller, 2008). 2 There is no unique way to define the notion of simplicity in this context. Previous works often rely on the intuition of human annotators to evaluate the level of simplicity of a TS system output. 29 Proceedings"
W18-7005,P15-2135,0,0.0481227,"Missing"
W18-7005,Q15-1021,0,0.0797566,"of parallel corpora of source sentences and manually produced reference translations, which are available on a large scale for many language pairs (Tiedemann, 2012). TS datasets are less numerous and smaller. Moreover, they are often automatically extracted from comparable corpora rather than strictly parallel corpora, which results in noisier reference data. For example, the PWKP dataset (Zhu et al., 2010) consists of 100,000 sentences from the English Wikipedia automatically aligned with sentences from the Simple English Wikipedia based on term-based similarity metrics. It has been shown by Xu et al. (2015) that many of PWKP’s “simplified” sentences are in fact not simpler or even not related to their corresponding source sentence. Even if better quality corpora such as Newsela do exist (Xu et al., 2015), they are costly to create, often of limited size, and not necessarily open-access. 2 2.1 Existing evaluation methods Using MT metrics to compare the output and a reference TS can be considered as a monolingual translation task. As a result, MT metrics such as BLEU (Papineni et al., 2002), which compare the output of an MT system to a reference translation, have been extensively used for TS (Nar"
W18-7005,W14-1201,0,0.222835,"Missing"
W18-7005,Q16-1029,0,0.303592,"in fact not simpler or even not related to their corresponding source sentence. Even if better quality corpora such as Newsela do exist (Xu et al., 2015), they are costly to create, often of limited size, and not necessarily open-access. 2 2.1 Existing evaluation methods Using MT metrics to compare the output and a reference TS can be considered as a monolingual translation task. As a result, MT metrics such as BLEU (Papineni et al., 2002), which compare the output of an MT system to a reference translation, have been extensively used for TS (Narayan and Garˇ dent, 2014; Stajner et al., 2015; Xu et al., 2016). Other successful MT metrics include TER (Snover et al., 2009), ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005), but they have not gained much traction in the TS literature. These metrics rely on good quality references, something which is often not available in TS, as ˇ discussed by Xu et al. (2015). Moreover, Stajner et al. (2015) and Sulem et al. (2018a) showed that using BLEU to compare the system output with a reference is not a good way to perform TS evaluation, even when good quality references are available. This is especially true when the TS system produces more than one sen"
W18-7005,C10-1152,0,0.468655,"e translation (MT) Introduction Text simplification (hereafter TS) has received increasing interest by the scientific community in recent years. It aims at producing a simpler version of a source text that is both easier to read and to understand, thus improving the accessibility of text for people suffering from a range of disabilities such as aphasia (Carroll et al., 1998) or dyslexia (Rello et al., 2013), as well as for second language learners (Xia et al., 2016) and people with low literacy (Watanabe et al., 2009). This topic has been researched for a variety of languages such as English (Zhu et al., 2010; Wubben 1 Note that text simplification has also been used as a preprocessing step for other natural language processing tasks such as machine translation (Chandrasekar et al., 1996) and semantic role labelling (Vickrey and Koller, 2008). 2 There is no unique way to define the notion of simplicity in this context. Previous works often rely on the intuition of human annotators to evaluate the level of simplicity of a TS system output. 29 Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA), pages 29–38, c Tilburg, The Netherlands, November 8 2018. 2018 Association for Computation"
W18-7005,D18-1081,0,0.362221,"translation task. As a result, MT metrics such as BLEU (Papineni et al., 2002), which compare the output of an MT system to a reference translation, have been extensively used for TS (Narayan and Garˇ dent, 2014; Stajner et al., 2015; Xu et al., 2016). Other successful MT metrics include TER (Snover et al., 2009), ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005), but they have not gained much traction in the TS literature. These metrics rely on good quality references, something which is often not available in TS, as ˇ discussed by Xu et al. (2015). Moreover, Stajner et al. (2015) and Sulem et al. (2018a) showed that using BLEU to compare the system output with a reference is not a good way to perform TS evaluation, even when good quality references are available. This is especially true when the TS system produces more than one sentence for a single source sentence. This creates a challenge for the use of referencebased MT metrics for TS evaluation. However, TS has the advantage of being a monolingual translation-like task, the source being in the same language as the output. This allows for new, nonconventional ways to use MT evaluation metrics, namely by using them to compare the output o"
W18-7005,N18-1063,0,0.115581,"Missing"
W18-7005,tiedemann-2012-parallel,0,0.0105104,"8, c Tilburg, The Netherlands, November 8 2018. 2018 Association for Computational Linguistics evaluation methods and traditional quality estimation features. We then present the QATS shared task and the associated dataset, which we use for our experiments. Finally we compare all methods in a reference-less setting and analyze the results. evaluation metrics such as BLEU (Papineni et al., 2002). However, MT evaluation metrics rely on the existence of parallel corpora of source sentences and manually produced reference translations, which are available on a large scale for many language pairs (Tiedemann, 2012). TS datasets are less numerous and smaller. Moreover, they are often automatically extracted from comparable corpora rather than strictly parallel corpora, which results in noisier reference data. For example, the PWKP dataset (Zhu et al., 2010) consists of 100,000 sentences from the English Wikipedia automatically aligned with sentences from the Simple English Wikipedia based on term-based similarity metrics. It has been shown by Xu et al. (2015) that many of PWKP’s “simplified” sentences are in fact not simpler or even not related to their corresponding source sentence. Even if better quali"
W19-7816,C16-1013,0,0.0222213,"ner and Kübler (2012) did for Old Occitan, a language from the South of France and close to Old French. They chose modern Catalan as their source language for syntax because the word-order is &quot;relatively free&quot;, as in Old Occitan. We can use a treebank of Contemporary French, but it is likely to introduce a bias in favour of an analysis close to the modern language. We would not be able to constrain the syntactic models according to linguistic knowledge. We can also consider using automatic normalisation as an additional layer of annotation, because it has shown efficient for historical texts (Bollmann and Søgaard, 2016). This too is to be explored in a machine learning approach. This work focuses on a symbolic approach, which will be compared to statistical parsing later on. Brants et al. (2002) pointed out an advantage of parsing with a grammar: the annotation is consistent and has high accuracy. Some projects were successful in adapting existing systems to former stages of a language, as discussed earlier. The extension of the LinGO Redwoods treebank should also be mentioned (Oepen et al., 2004; Toutanova et al., 2005). The authors use a HPSG grammar for analysis and statistical models for disambiguation,"
W19-7816,C96-1034,0,0.0815116,"g systems to former stages of a language, as discussed earlier. The extension of the LinGO Redwoods treebank should also be mentioned (Oepen et al., 2004; Toutanova et al., 2005). The authors use a HPSG grammar for analysis and statistical models for disambiguation, ensuring the coherence of annotation. Our grammar should also enable us to annotate new texts following the existing treebank’s scheme. 5 Solutions for syntactic analysis In order to parse Medieval French, we chose to adapt FRMG because of the modularity and flexibility a metagrammar provides. 5.1 French Metagrammar A metagrammar (Candito, 1996) consists of a hierarchy of small classes describing the rules underlying a grammar. It is a mean to factorise linguistic description, therefore making maintenance and corrections easier. A first general description of a phenomenon is written in a &quot;mother class&quot;, from which more specific classes inherit. The metagrammar is compiled into a grammar, which is then used by a parser. FRMG is a metagrammar based on the Tree Adjoining Grammar (TAG) formalism (Joshi et al., 1975), extended with feature structures. These grammars use elementary trees as units, which have a finite depth and are associat"
W19-7816,hinrichs-krauwer-2014-clarin,0,0.0137476,"and has an impact on syntactic analysis because their distributions are different at each period. Variation is a salient property of Medieval French. It appears at many levels and needs to be handled by parsers. 3 Some characteristics, like dialect, are more discriminative than others. 4 Related work Several treebanks for ancient languages are available, for example Latin (Bamman and Crane, 2006), Old English (Taylor, 2007), Medieval Portuguese (Rocio et al., 2003) and Middle High German (Hinrichs and Zastrow, 2012). Other annotated corpora can be found in the CLARIN Research Infrastructure (Hinrichs and Krauwer, 2014). They can be diachronic, which makes the annotation challenging because of morphological and syntactic changes. The MCVF treebank is the biggest treebank for Medieval French, with 361.283 words for Old French alone, against 251.000 in the SRCMF treebank. Although adjustments must be done in order to adapt the annotation scheme to ours, its size and the presence of texts of Middle French make it a promising resource for machine learning techniques, some of which seem more appropriate for this kind of data. For example, transfer learning is nowadays used for low-resource languages (Agi´c et al."
W19-7816,sagot-2010-lefff,0,0.0427692,"st probable solution. It is trained on the French Treebank (FTB) (Abeillé et al., 2003) for contemporary French (Villemonte de la Clergerie, 2013). We will use the SRCMF for our system. Following Guibon et al. (2015), training data should be split according to the metadata of texts, so that the weights in the model fit the new texts to parse. We also consider automatically classifying texts, which would help making use of texts with uncertain metadata or no assigned dialect. 5.2 Adapting FRMG We use the pipeline described above to parse Medieval French. OFrLex, a lexicon similar to the Lefff (Sagot, 2010), is under development (Sagot, 2019). It includes a new kind of information to add to entries: spelling variants. All variants of a word are linked to it, which is useful for a language with no strict notion of &quot;orthography&quot;. The adaptation of FRMG to Medieval French is a work in progress divided into four main steps. We chose to develop only one metagrammar for the whole period because it is not possible for us to accurately describe each state of language separately. There is no clear boundary between them, they tend to overlap. We consider at first that their main difference is the distribu"
W98-0111,P98-2217,1,0.465381,"Missing"
W98-0111,P90-1035,0,0.0437846,"Missing"
W98-0111,H86-1020,0,\N,Missing
W98-0111,J93-4002,0,\N,Missing
W98-0111,C98-2212,1,\N,Missing
W98-0111,P85-1011,0,\N,Missing
