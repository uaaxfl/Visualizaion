2021.inlg-1.25,Text-in-Context: Token-Level Error Detection for Table-to-Text Generation,2021,-1,-1,2,0,5965,zdenvek kasner,Proceedings of the 14th International Conference on Natural Language Generation,0,"We present our Charles-UPF submission for the Shared Task on Evaluating Accuracy in Generated Texts at INLG 2021. Our system can detect the errors automatically using a combination of a rule-based natural language generation (NLG) system and pretrained language models (LMs). We first utilize a rule-based NLG system to generate sentences with facts that can be derived from the input. For each sentence we evaluate, we select a subset of facts which are relevant by measuring semantic similarity to the sentence in question. Finally, we finetune a pretrained language model on annotated data along with the relevant facts for fine-grained error detection. On the test set, we achieve 69{\%} recall and 75{\%} precision with a model trained on a mixture of human-annotated and synthetic data."
2021.inlg-1.30,Another {PASS}: A Reproduction Study of the Human Evaluation of a Football Report Generation System,2021,-1,-1,1,1,5966,simon mille,Proceedings of the 14th International Conference on Natural Language Generation,0,"This paper reports results from a reproduction study in which we repeated the human evaluation of the PASS Dutch-language football report generation system (van der Lee et al., 2017). The work was carried out as part of the ReproGen Shared Task on Reproducibility of Human Evaluations in NLG, in Track A (Paper 1). We aimed to repeat the original study exactly, with the main difference that a different set of evaluators was used. We describe the study design, present the results from the original and the reproduction study, and then compare and analyse the differences between the two sets of results. For the two {`}headline{'} results of average Fluency and Clarity, we find that in both studies, the system was rated more highly for Clarity than for Fluency, and Clarity had higher standard deviation. Clarity and Fluency ratings were higher, and their standard deviations lower, in the reproduction study than in the original study by substantial margins. Clarity had a higher degree of reproducibility than Fluency, as measured by the coefficient of variation. Data and code are publicly available."
2021.gem-1.10,"The {GEM} Benchmark: Natural Language Generation, its Evaluation and Metrics",2021,-1,-1,33,0,6246,sebastian gehrmann,"Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",0,"We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics. This disconnect makes it challenging to identify the limitations of current models and opportunities for progress. Addressing this limitation, GEM provides an environment in which models can easily be applied to a wide set of tasks and in which evaluation strategies can be tested. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop."
2021.findings-acl.333,Assessing the Syntactic Capabilities of Transformer-based Multilingual Language Models,2021,-1,-1,3,0,36,laura perezmayos,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2020.webnlg-1.1,A Case Study of {NLG} from Multimedia Data Sources: Generating Architectural Landmark Descriptions,2020,-1,-1,1,1,5966,simon mille,Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+),0,"In this paper, we present a pipeline system that generates architectural landmark descriptions using textual, visual and structured data. The pipeline comprises five main components:(i) a textual analysis component, which extracts information from Wikipedia pages; (ii)a visual analysis component, which extracts information from copyright-free images; (iii) a retrieval component, which gathers relevant (property, subject, object) triples from DBpedia; (iv) a fusion component, which stores the contents from the different modalities in a Knowledge Base (KB) and resolves the conflicts that stem from using different sources of information; (v) an NLG component, which verbalises the resulting contents of the KB. We show that thanks to the addition of other modalities, we can make the verbalisation of DBpedia triples more relevant and/or inspirational."
2020.webnlg-1.3,A General Benchmarking Framework for Text Generation,2020,-1,-1,10,0,14063,diego moussallem,Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+),0,"The RDF-to-text task has recently gained substantial attention due to the continuous growth of RDF knowledge graphs in number and size. Recent studies have focused on systematically comparing RDF-to-text approaches on benchmarking datasets such as WebNLG. Although some evaluation tools have already been proposed for text generation, none of the existing solutions abides by the Findability, Accessibility, Interoperability, and Reusability (FAIR) principles and involves RDF data for the knowledge extraction task. In this paper, we present BENG, a FAIR benchmarking platform for Natural Language Generation (NLG) and Knowledge Extraction systems with focus on RDF data. BENG builds upon the successful benchmarking platform GERBIL, is opensource and is publicly available along with the data it contains."
2020.webnlg-1.7,"The 2020 Bilingual, Bi-Directional {W}eb{NLG}+ Shared Task: Overview and Evaluation Results ({W}eb{NLG}+ 2020)",2020,-1,-1,5,0,5949,thiago ferreira,Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+),0,"WebNLG+ offers two challenges: (i) mapping sets of RDF triples to English or Russian text (generation) and (ii) converting English or Russian text to sets of RDF triples (semantic parsing). Compared to the eponymous WebNLG challenge, WebNLG+ provides an extended dataset that enable the training, evaluation, and comparison of microplanners and semantic parsers. In this paper, we present the results of the generation and semantic parsing task for both English and Russian and provide a brief description of the participating systems."
2020.msr-1.1,The Third Multilingual Surface Realisation Shared Task ({SR}{'}20): Overview and Evaluation Results,2020,-1,-1,1,1,5966,simon mille,Proceedings of the Third Workshop on Multilingual Surface Realisation,0,"This paper presents results from the Third Shared Task on Multilingual Surface Realisation (SR{'}20) which was organised as part of the COLING{'}20 Workshop on Multilingual Surface Realisation. As in SR{'}18 and SR{'}19, the shared task comprised two tracks: (1) a Shallow Track where the inputs were full UD structures with word order information removed and tokens lemmatised; and (2) a Deep Track where additionally, functional words and morphological information were removed. Moreover, each track had two subtracks: (a) restricted-resource, where only the data provided or approved as part of a track could be used for training models, and (b) open-resource, where any data could be used. The Shallow Track was offered in 11 languages, whereas the Deep Track in 3 ones. Systems were evaluated using both automatic metrics and direct assessment by human evaluators in terms of Readability and Meaning Similarity to reference outputs. We present the evaluation results, along with descriptions of the SR{'}19 tracks, data and evaluation methods, as well as brief summaries of the participating systems. For full descriptions of the participating systems, please see the separate system reports elsewhere in this volume."
2020.inlg-1.23,Twenty Years of Confusion in Human Evaluation: {NLG} Needs Evaluation Sheets and Standardised Definitions,2020,-1,-1,7,0,10049,david howcroft,Proceedings of the 13th International Conference on Natural Language Generation,0,"Human assessment remains the most trusted form of evaluation in NLG, but highly diverse approaches and a proliferation of different quality criteria used by researchers make it difficult to compare results and draw conclusions across papers, with adverse implications for meta-evaluation and reproducibility. In this paper, we present (i) our dataset of 165 NLG papers with human evaluations, (ii) the annotation scheme we developed to label the papers for different aspects of evaluations, (iii) quantitative analyses of the annotations, and (iv) a set of recommendations for improving standards in evaluation reporting. We use the annotations as a basis for examining information included in evaluation reports, and levels of consistency in approaches, experimental design and terminology, focusing in particular on the 200+ different terms that have been used for evaluated aspects of quality. We conclude that due to a pervasive lack of clarity in reports and extreme diversity in approaches, human evaluation in NLG presents as extremely confused in 2020, and that the field is in urgent need of standard methods and terminology."
2020.inlg-1.24,"Disentangling the Properties of Human Evaluation Methods: A Classification System to Support Comparability, Meta-Evaluation and Reproducibility Testing",2020,-1,-1,2,0,5962,anya belz,Proceedings of the 13th International Conference on Natural Language Generation,0,"Current standards for designing and reporting human evaluations in NLP mean it is generally unclear which evaluations are comparable and can be expected to yield similar results when applied to the same system outputs. This has serious implications for reproducibility testing and meta-evaluation, in particular given that human evaluation is considered the gold standard against which the trustworthiness of automatic metrics is gauged. {\%}and merging others, as well as deciding which evaluations should be able to reproduce each other{'}s results. Using examples from NLG, we propose a classification system for evaluations based on disentangling (i) what is being evaluated (which aspect of quality), and (ii) how it is evaluated in specific (a) evaluation modes and (b) experimental designs. We show that this approach provides a basis for determining comparability, hence for comparison of evaluations across papers, meta-evaluation experiments, reproducibility testing."
W19-8659,Teaching {FORG}e to Verbalize {DB}pedia Properties in {S}panish,2019,0,0,1,1,5966,simon mille,Proceedings of the 12th International Conference on Natural Language Generation,0,"Statistical generators increasingly dominate the research in NLG. However, grammar-based generators that are grounded in a solid linguistic framework remain very competitive, especially for generation from deep knowledge structures. Furthermore, if built modularly, they can be ported to other genres and languages with a limited amount of work, without the need of the annotation of a considerable amount of training data. One of these generators is FORGe, which is based on the Meaning-Text Model. In the recent WebNLG challenge (the first comprehensive task addressing the mapping of RDF triples to text) FORGe ranked first with respect to the overall quality in human evaluation. We extend the coverage of FORGE{'}s open source grammatical and lexical resources for English, so as to further improve the English texts, and port them to Spanish, to achieve a comparable quality. This confirms that, as already observed in the case of SimpleNLG, a robust universal grammar-driven framework and a systematic organization of the linguistic resources can be an adequate choice for NLG applications."
D19-6301,The Second Multilingual Surface Realisation Shared Task ({SR}{'}19): Overview and Evaluation Results,2019,0,2,1,1,5966,simon mille,Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019),0,"We report results from the SR{'}19 Shared Task, the second edition of a multilingual surface realisation task organised as part of the EMNLP{'}19 Workshop on Multilingual Surface Realisation. As in SR{'}18, the shared task comprised two tracks with different levels of complexity: (a) a shallow track where the inputs were full UD structures with word order information removed and tokens lemmatised; and (b) a deep track where additionally, functional words and morphological information were removed. The shallow track was offered in eleven, and the deep track in three languages. Systems were evaluated (a) automatically, using a range of intrinsic metrics, and (b) by human judges in terms of readability and meaning similarity. This report presents the evaluation results, along with descriptions of the SR{'}19 tracks, data and evaluation methods. For full descriptions of the participating systems, please see the separate system reports elsewhere in this volume."
D19-6313,Back-Translation as Strategy to Tackle the Lack of Corpus in Natural Language Generation from Semantic Representations,2019,0,0,2,0,6269,marco cabezudo,Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019),0,"This paper presents an exploratory study that aims to evaluate the usefulness of back-translation in Natural Language Generation (NLG) from semantic representations for non-English languages. Specifically, Abstract Meaning Representation and Brazilian Portuguese (BP) are chosen as semantic representation and language, respectively. Two methods (focused on Statistical and Neural Machine Translation) are evaluated on two datasets (one automatically generated and another one human-generated) to compare the performance in a real context. Also, several cuts according to quality measures are performed to evaluate the importance (or not) of the data quality in NLG. Results show that there are still many improvements to be made but this is a promising approach."
W18-6527,Underspecified {U}niversal {D}ependency Structures as Inputs for Multilingual Surface Realisation,2018,0,1,1,1,5966,simon mille,Proceedings of the 11th International Conference on Natural Language Generation,0,"In this paper, we present the datasets used in the Shallow and Deep Tracks of the First Multilingual Surface Realisation Shared Task (SR{'}18). For the Shallow Track, data in ten languages has been released: Arabic, Czech, Dutch, English, Finnish, French, Italian, Portuguese, Russian and Spanish. For the Deep Track, data in three languages is made available: English, French and Spanish. We describe in detail how the datasets were derived from the Universal Dependencies V2.0, and report on an evaluation of the Deep Track input quality. In addition, we examine the motivation for, and likely usefulness of, deriving NLG inputs from annotations in resources originally developed for Natural Language Understanding (NLU), and assess whether the resulting inputs supply enough information of the right kind for the final stage in the NLG process."
W18-6542,Sentence Packaging in Text Generation from Semantic Graphs as a Community Detection Problem,2018,0,1,2,0,80,alexander shvets,Proceedings of the 11th International Conference on Natural Language Generation,0,"An increasing amount of research tackles the challenge of text generation from abstract ontological or semantic structures, which are in their very nature potentially large connected graphs. These graphs must be {``}packaged{''} into sentence-wise subgraphs. We interpret the problem of sentence packaging as a community detection problem with post optimization. Experiments on the texts of the VerbNet/FrameNet structure annotated-Penn Treebank, which have been converted into graphs by a coreference merge using Stanford CoreNLP, show a high F1-score of 0.738."
W18-3601,The First Multilingual Surface Realisation Shared Task ({SR}{'}18): Overview and Evaluation Results,2018,0,11,1,1,5966,simon mille,Proceedings of the First Workshop on Multilingual Surface Realisation,0,"We report results from the SR{'}18 Shared Task, a new multilingual surface realisation task organised as part of the ACL{'}18 Workshop on Multilingual Surface Realisation. As in its English-only predecessor task SR{'}11, the shared task comprised two tracks with different levels of complexity: (a) a shallow track where the inputs were full UD structures with word order information removed and tokens lemmatised; and (b) a deep track where additionally, functional words and morphological information were removed. The shallow track was offered in ten, and the deep track in three languages. Systems were evaluated (a) automatically, using a range of intrinsic metrics, and (b) by human judges in terms of readability and meaning similarity. This report presents the evaluation results, along with descriptions of the SR{'}18 tracks, data and evaluation methods. For full descriptions of the participating systems, please see the separate system reports elsewhere in this volume."
W17-3517,Shared Task Proposal: Multilingual Surface Realization Using {U}niversal {D}ependency Trees,2017,0,1,1,1,5966,simon mille,Proceedings of the 10th International Conference on Natural Language Generation,0,"We propose a shared task on multilingual Surface Realization, i.e., on mapping unordered and uninflected universal dependency trees to correctly ordered and inflected sentences in a number of languages. A second deeper input will be available in which, in addition, functional words, fine-grained PoS and morphological information will be removed from the input trees. The first shared task on Surface Realization was carried out in 2011 with a similar setup, with a focus on English. We think that it is time for relaunching such a shared task effort in view of the arrival of Universal Dependencies annotated treebanks for a large number of languages on the one hand, and the increasing dominance of Deep Learning, which proved to be a game changer for NLP, on the other hand."
W17-3539,A demo of {FORG}e: the {P}ompeu {F}abra Open Rule-based Generator,2017,0,0,1,1,5966,simon mille,Proceedings of the 10th International Conference on Natural Language Generation,0,"This demo paper presents the multilingual deep sentence generator developed by the TALN group at Universitat Pompeu Fabra, implemented as a series of rule-based graph-transducers for the syntacticization of the input graphs, the resolution of morphological agreements, and the linearization of the trees."
S17-2158,{FORG}e at {S}em{E}val-2017 Task 9: Deep sentence generation based on a sequence of graph transducers,2017,0,7,1,1,5966,simon mille,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"We present the contribution of Universitat Pompeu Fabra{'}s NLP group to the SemEval Task 9.2 (AMR-to-English Generation). The proposed generation pipeline comprises: (i) a series of rule-based graph-transducers for the syntacticization of the input graphs and the resolution of morphological agreements, and (ii) an off-the-shelf statistical linearization component."
W15-2107,Towards a multi-layered dependency annotation of {F}innish,2015,14,1,2,0,30209,alicia burga,Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015),0,"We present a dependency annotation scheme for Finnish which aims at respecting the multilayered nature of language. We first tackle the annotation of surfacesyntactic structures (SSyntS) as inspired by the Meaning-Text framework. Exclusively syntactic criteria are used when defining the surface-syntactic relations tagset. Our annotation scheme allows for a direct mapping between surface-syntax and a more semantics-oriented representation, in particular predicate-argument structures. It has been applied to a corpus of Finnish, composed of 2,025 sentences related to weather conditions."
N15-3012,Visualizing Deep-Syntactic Parser Output,2015,19,1,4,0,2827,juan solercompany,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"xe2x80x9cDeep-syntacticxe2x80x9d dependency structures bridge the gap between the surface-syntactic structures as produced by state-of-the-art dependency parsers and semantic logical forms in that they abstract away from surfacesyntactic idiosyncrasies, but still keep the linguistic structure of a sentence. They have thus a great potential for such downstream applications as machine translation and summarization. In this demo paper, we propose an online version of a deep-syntactic parser that outputs deep-syntactic structures from plain sentences and visualizes them using the Brat tool. Along with the deep-syntactic structures, the user can also inspect the visual presentation of the surface-syntactic structures that serve as input to the deep-syntactic parser and that are produced by the joint tagger and syntactic transition-based parser ran in the pipeline before deep-syntactic parsing takes place."
N15-1042,Data-driven sentence generation with non-isomorphic trees,2015,36,15,3,0.746854,3435,miguel ballesteros,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Abstract structures from which the generation naturally starts often do not contain any func- tional nodes, while surface-syntactic struc- tures or a chain of tokens in a linearized tree contain all of them. Therefore, data-driven linguistic generation needs to be able to cope with the projection between non-isomorphic structures that differ in their topology and number of nodes. So far, such a projection has been a challenge in data-driven genera- tion and was largely avoided. We present a fully stochastic generator that is able to cope with projection between non-isomorphic structures. The generator, which starts from PropBank-like structures, consists of a cas- cade of SVM-classifier based submodules that map in a series of transitions the input struc- tures onto sentences. The generator has been evaluated for English on the Penn-Treebank and for Spanish on the multi-layered Ancora- UPF corpus."
W14-4416,Classifiers for data-driven deep sentence generation,2014,17,6,2,0.746854,3435,miguel ballesteros,Proceedings of the 8th International Natural Language Generation Conference ({INLG}),0,"State-of-the-art statistical sentence generators deal with isomorphic structures only. Therefore, given that semantic and syntactic structures tend to differ in their topology and number of nodes, i.e., are not isomorphic, statistical generation saw so far itself confined to shallow, syntactic generation. In this paper, we present a series of fine-grained classifiers that are essential for data-driven deep sentence generation in that they handle the problem of the projection of non-isomorphic structures."
C14-1133,Deep-Syntactic Parsing,2014,39,11,3,0.746854,3435,miguel ballesteros,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"xe2x80x9cDeep-syntacticxe2x80x9d dependency structures that capture the argumentative, attributive and coordinative relations between full words of a sentence have a great potential for a number of NLPapplications. The abstraction degree of these structures is in-between the output of a syntactic dependency parser (connected trees defined over all words of a sentence and language-specific grammatical functions) and the output of a semantic parser (forests of trees defined over individual lexemes or phrasal chunks and abstract semantic role labels which capture the argument structure of predicative elements, dropping all attributive and coordinative dependencies). We propose a parser that delivers deep syntactic structures as output."
W13-3703,Exploring Morphosyntactic Annotation over a {S}panish Corpus for Dependency Parsing,2013,27,3,2,0.666667,3435,miguel ballesteros,Proceedings of the Second International Conference on Dependency Linguistics ({D}ep{L}ing 2013),0,"It has been observed that the inclusion of morphosyntactic information in dependency treebanks is crucial to obtain high results in dependency parsing for some languages. In this paper we explore in depth to what extent it is useful to include morphological features, and the impact of diverse morphosyntactic annotations on statistical dependency parsing of Spanish. For this, we give a detailed analysis of the results of over 80 experiments performed with MaltParser through the application of MaltOptimizer. Our goal is to isolate configurations of morphosyntactic features which would allow for optimizing the parsing of Spanish texts, and to evaluate the impact that each feature has, independently and in combination with others."
W13-3724,{A}n{C}ora-{UPF}: A Multi-Level Annotation of {S}panish,2013,20,11,1,1,5966,simon mille,Proceedings of the Second International Conference on Dependency Linguistics ({D}ep{L}ing 2013),0,"There is an increasing need for the annotation of multiple types of linguistic information that are rather different in their nature, e.g., word order, morphological features, syntactic and semantic relations, etc. Quite frequently, their annotation is combined in a single structure, which not only results in inadequate annotations of treebanks and consequent low-quality applications trained on them, but also is deficient from a theoretical (linguistic) perspective. We present a new corpus of Spanish annotated on four independent levels, morphology, surface-syntax, deep-syntax and semantics, as well as the methodology that allows for obtaining it with fewer cost while maintaining a high inter-annotator agreement."
W12-1506,Towards a Surface Realization-Oriented Corpus Annotation,2012,25,6,2,0,82,leo wanner,{INLG} 2012 Proceedings of the Seventh International Natural Language Generation Conference,0,"Until recently, deep stochastic surface realization has been hindered by the lack of semantically annotated corpora. This is about to change. Such corpora are increasingly available, e.g., in the context of CoNLL shared tasks. However, recent experiments with CoNLL 2009 corpora show that these popular resources, which serve well for other applications, may not do so for generation. The attempts to adapt them for generation resulted so far in a better performance of the realizers, but not yet in a genuinely semantic generation-oriented annotation schema. Our goal is to initiate a debate on how a generation suitable annotation schema should be defined. We define some general principles of a semantic generation-oriented annotation and propose an annotation schema that is based on these principles. Experiments shows that making the semantic corpora comply with the suggested principles does not need to have a negative impact on the quality of the stochastic generators trained on them."
W12-1525,The Surface Realisation Task: Recent Developments and Future Plans,2012,13,8,3,0,26421,anja belz,{INLG} 2012 Proceedings of the Seventh International Natural Language Generation Conference,0,"The Surface Realisation Shared Task was first run in 2011. Two common-ground input representations were developed and for the first time several independently developed surface realisers produced realisations from the same shared inputs. However, the input representations had several shortcomings which we have been aiming to address in the time since. This paper reports on our work to date on improving the input representations and on our plans for the next edition of the SR Task. We also briefly summarise other related developments in NLG shared tasks and outline how the different ideas may be usefully brought together in the future."
bott-etal-2012-text,Text Simplification Tools for {S}panish,2012,19,20,3,0,32029,stefan bott,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we describe the development of a text simplification system for Spanish. Text simplification is the adaptation of a text to the special needs of certain groups of readers, such as language learners, people with cognitive difficulties and elderly people, among others. There is a clear need for simplified texts, but manual production and adaptation of existing texts is labour intensive and costly. Automatic simplification is a field which attracts growing attention in Natural Language Processing, but, to the best of our knowledge, there are no simplification tools for Spanish. We present a prototype for automatic simplification, which shows that the most important structural simplification operations can be successfully treated with an approach based on rules which can potentially be improved by statistical methods. For the development of this prototype we carried out a corpus study which aims at identifying the operations a text simplification system needs to carry out in order to produce an output similar to what human editors produce when they simplify texts."
C12-2082,How Does the Granularity of an Annotation Scheme Influence Dependency Parsing Performance?,2012,19,10,1,1,5966,simon mille,Proceedings of {COLING} 2012: Posters,0,"The common use of a single de facto standard annotation scheme for dependency treebank creation leaves the question open to what extent the performance of an application trained on a treebank depends on this annotation scheme and whether a linguistically richer scheme would imply a decrease of the performance of the application. We investigate the effect of the variation of the number of grammatical relations in a tagset on the performance of dependency parsers. In order to obtain several levels of granularity of the annotation, we design a hierarchical annotation scheme exclusively based on syntactic criteria. The richest annotation contains 60 relations. The more coarse-grained annotations are derived from the richest. As a result, all annotations and thus also the performance of a parser trained on different annotations remain comparable. We carried out experiments with four state-of-the-art dependency parsers. The results support the claim that annotating with more fine-grained syntactic relations does not necessarily imply a significant loss of accuracy. We also show the limits of this approach by giving details on the fine-grained relations that do have a negative impact on the performance of the parsers."
W11-2835,{\\textless}{S}tu{M}a{B}a{\\textgreater}: From Deep Representation to Surface,2011,7,11,2,0.295899,16528,bernd bohnet,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"We realize the full generation pipeline, from the deep (= semantic) representation (SemR), over the shallow (= surface-syntactic) representation (SSyntR) to the surface. To account systematically for the non-isomorphic projection between SemR and SSyntR, we introduce an intermediate representation: the so-called deep-syntactic representation (DSyntR), which does not contain yet (all) function words (as SemR), but which already contains grammatical function relation labels (as SSyntR)."
mille-wanner-2010-syntactic,Syntactic Dependencies for Multilingual and Multilevel Corpus Annotation,2010,21,4,1,1,5966,simon mille,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The relevance of syntactic dependency annotated corpora is nowadays unquestioned. However, a broad debate on the optimal set of dependency relation tags did not take place yet. As a result, largely varying tag sets of a largely varying size are used in different annotation initiatives. We propose a hierarchical dependency structure annotation schema that is more detailed and more flexible than the known annotation schemata. The schema allows us to choose the level of the desired detail of annotation, which facilitates the use of the schema for corpus annotation for different languages and for different NLP applications. Thanks to the inclusion of semantico-syntactic tags into the schema, we can annotate a corpus not only with syntactic dependency structures, but also with valency patterns as they are usually found in separate treebanks such as PropBank and NomBank. Semantico-syntactic tags and the level of detail of the schema furthermore facilitate the derivation of deep-syntactic and semantic annotations, leading to truly multilevel annotated dependency corpora. Such multilevel annotations can be readily used for the task of ML-based acquisition of grammar resources that map between the different levels of linguistic representation â something which forms part of, for instance, any natural language text generator."
C10-1012,Broad Coverage Multilingual Deep Sentence Generation with a Stochastic Multi-Level Realizer,2010,25,42,3,0.295899,16528,bernd bohnet,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Most of the known stochastic sentence generators use syntactically annotated corpora, performing the projection to the surface in one stage. However, in full-fledged text generation, sentence realization usually starts from semantic (predicate-argument) structures. To be able to deal with semantic structures, stochastic generators require semantically annotated, or, even better, multilevel annotated corpora. Only then can they deal with such crucial generation issues as sentence planning, linearization and morphologization. Multilevel annotated corpora are increasingly available for multiple languages. We take advantage of them and propose a multilingual deep stochastic sentence realizer that mirrors the state-of-the-art research in semantic parsing. The realizer uses an SVM learning algorithm. For each pair of adjacent levels of annotation, a separate decoder is defined. So far, we evaluated the realizer for Chinese, English, German, and Spanish."
mille-wanner-2008-making,Making Text Resources Accessible to the Reader: the Case of Patent Claims,2008,15,13,1,1,5966,simon mille,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Hardly any other kind of text structures is as notoriously difficult to read as patents. This is first of all due to their abstract vocabulary and their very complex syntactic constructions. Especially the claims in a patent are a challenge: in accordance with international patent writing regulations, each claim must be rendered in a single sentence. As a result, sentences with more than 200 words are not uncommon. Therefore, paraphrasing of the claims in terms the user can understand is of high demand. We present a rule-based paraphrasing module that realizes paraphrasing of patent claims in English as a rewriting task. Prior to the rewriting proper, the module implies the stages of simplification and discourse and syntactic analyses. The rewriting makes use of a full-fledged text generator and consists in a number of genuine generation tasks such as aggregation, selection of referring expressions, choice of discourse markers and syntactic generation. As generator, we use the MATE-work bench, which is based on the Meaning-Text Theory of linguistics."
2008.eamt-1.18,Multilingual summarization in practice: the case of patent claims,2008,15,7,1,1,5966,simon mille,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,"Hardly any other type of textual material is as difficult to read and comprehend as patents. Especially the claims in a patent reveal very complex syntactic constructions which are difficult to process even for native speakers, let alone for foreigners who do not master well the language in which the patent is written. Therefore, multilingual summarization is very attractive to practitioners in the field. We propose a multilingual summarizer that operates at the Deep-Syntactic Structures (DSyntSs) as introduced in the Meaning-Text Theory. Firstly, the original claims are linguistically simplified and analyzed down to DSyntSs. Then, syntactic and discursive summarization criteria are applied to the DSyntSs to remove summary irrelevant DSyntS-branches. The pruned DSyntS are transferred into DSyntSs of the language in which the summary is to be generated. For the generation of the summary from the transferred DSyntSs, we use the full fledged text generator MATE."
