2008.iwslt-evaluation.14,P03-1021,0,0.0350389,"e are combined in a log-linear model. We used the following features those are presented by the default setting of Moses system.  Source to target and target to source phrase translation probabilities  Source to target and target to source word translation probabilities (lexical weightings)  Phrase penalty (a constant by default)  Word penalty  Distance based distortion model A target language model was used in addition to the features. We have used the SRILM toolkit [2] in order to build the target language model. The weights for the features are optimized by minimum error rate training [3] which maximizes BLEU score. We have used only IWSLT 2008 train and development data for training translation and language model. The corpus statistics are summarized in table 1. Table 1. Corpus statistics of supplied data for ArabicEnglish, Chinese-English, and Chinese-Spanish tasks: Word counts and vocabulary sizes are measured after preprocessing steps Arabic Train Dev1 Dev2 Dev3 Dev4 Dev5 Dev6 Test Sent. Word Vcb. Sent. Word Vcb. Sent. Word Vcb. Sent. Word Vcb. Sent. Word Vcb. Sent. Word Vcb. Sent. Word Vcb. Sent. Word Vcb. 150303 14854 506 2865 1102 500 3040 1180 506 2918 1174 489 4825 14"
2008.iwslt-evaluation.14,J03-1002,0,0.00536698,"d target language could make some useless tokens in statistical machine translation. We define the term useless token as follows:  In parallel texts, if a token does not have - 98 - Proceedings of IWSLT 2008, Hawaii - U.S.A. Figure 1. Deletion test results corresponding tokens of same meaning or function in the opposite side text, the token is useless. The useless words should be aligned with NULL position because they have no proper words to be matched with, by the definition. However, we observed that the useless words are usually aligned incorrectly in other experiments when we use GIZA++ [4] to get the alignment. These erroneous alignments should be refined or removed in order to improve machine translation quality. Our approach to the problem is to delete the useless words before word alignment stage to prevent the incorrect word alignment caused by the useless words. In order to precisely identify the useless words, careful comparison between source and target languages based on linguistic insight is necessary. However, the comparison is not available because the authors do not have any knowledge in the source languages of BTEC tasks: Chinese and Arabic. As an alternative, a se"
2008.iwslt-evaluation.14,N04-4038,0,\N,Missing
2008.iwslt-evaluation.14,P02-1040,0,\N,Missing
2008.iwslt-evaluation.14,J04-4002,0,\N,Missing
2008.iwslt-evaluation.14,P07-2045,0,\N,Missing
2008.iwslt-evaluation.14,P03-1056,0,\N,Missing
2008.iwslt-evaluation.14,N03-1017,0,\N,Missing
C10-1064,P06-1017,0,0.0783227,"y of labeled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been incre"
C10-1064,P04-1054,0,0.0371203,", Chinese and Arabic. Although these datasets encourage the development and evaluation of statistical relation extractors for such languages, there would be a scarcity of labeled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech"
C10-1064,doddington-etal-2004-automatic,0,0.0551996,"projection method that leverages parallel corpora to bootstrap a relation detector without significant annotation efforts for a resource-poor language. In order to make our method more reliable, we introduce three simple projection noise reduction methods. The merit of our method is demonstrated through a novel Korean relation detection task. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Many relation extraction studies have followed the Relation Detection and Characterization (RDC) task organized by the Automatic Content Extraction project (Doddington et al., 2004) to make multilingual corpora of English, Chinese and Arabic. Although these datasets encourage the development and evaluation of statistical relation extractors for such languages, there would be a scarcity of labeled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Z"
C10-1064,P05-1045,0,0.0172764,"an 2 . The English sentences in the parallel corpus were prepro2 The parallel corpus collected and other resources are all available in our website http://isoft.postech.ac.kr/∼megaup/research/resources/ 567 cessed by the Stanford Parser 3 (Klein and Manning, 2003) which provides a set of analyzed results including part-of-speech tag sequences, a dependency tree, and a constituent parse tree for a sentence. The annotation for English sentences is divided into two subtasks: entity mention recognition and relation detection. We utilized an offthe-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model learned with the training set of the ACE 2003 corpus which consists of 674 documents and 9,683 relation instances was built for relation detection in English. In our implementation, we built a tree kernelbased SVM model using SVM-Light 5 (Joachims, 1998) and Tree Kernel Tools 6 (Moschitti, 2006). The subtree kernel method (Moschitti, 2006) for shortest p"
C10-1064,P03-1054,0,0.00375831,"ion in Korean text with propagated annotations from English resources. 4.1 Annotation The first step to evaluate our method was annotating the English sentences in a given parallel corpus. We use an English-Korean parallel corpus crawled from an English-Korean dictionary on the web. The parallel corpus consists of 454,315 bisentence pairs in English and Korean 2 . The English sentences in the parallel corpus were prepro2 The parallel corpus collected and other resources are all available in our website http://isoft.postech.ac.kr/∼megaup/research/resources/ 567 cessed by the Stanford Parser 3 (Klein and Manning, 2003) which provides a set of analyzed results including part-of-speech tag sequences, a dependency tree, and a constituent parse tree for a sentence. The annotation for English sentences is divided into two subtasks: entity mention recognition and relation detection. We utilized an offthe-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model"
C10-1064,N03-1017,0,0.00454035,"Missing"
C10-1064,J02-1004,1,0.853211,"all/F-measure on the test set of the ACE 2003 corpus, which consists of 97 documents and 1,386 relation instances. The annotation of relations was performed by determining the existence of semantic relations for all 115,452 instances with the trained model for relation detection. The annotation detected 22,162 instances as positive which have semantic relations. 4.2 Projection The labels about entities and relations in the English sentences of the parallel corpora were propagated into the corresponding sentences in Korean. The Korean sentences were preprocessed by our part-of-speech tagger 7 (Lee et al., 2002) and a dependency parser implemented by MSTParser with 3 http://nlp.stanford.edu/software/lex-parser.shtml http://nlp.stanford.edu/software/CRF-NER.shtml 5 http://svmlight.joachims.org/ 6 http://disi.unitn.it/∼moschitt/Tree-Kernel.htm 7 http://isoft.postech.ac.kr/∼megaup/research/postag/ 4 Filter none + heuristics + dictionary Without assessing 97,239 31,652 39,891 With assessing 39,203 12,775 17,381 Table 1: Numbers of projected instances a model trained on the Sejong corpus (Kim, 2006). The annotation projections were performed on the bi-sentences of the parallel corpus followed by descripti"
C10-1064,P02-1027,0,0.0607408,"For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 564 Proceedings of the 23rd International Confe"
C10-1064,P06-1104,0,0.235575,"e the development and evaluation of statistical relation extractors for such languages, there would be a scarcity of labeled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entit"
C10-1064,P05-1053,0,0.0542912,") to make multilingual corpora of English, Chinese and Arabic. Although these datasets encourage the development and evaluation of statistical relation extractors for such languages, there would be a scarcity of labeled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for"
C10-1064,D08-1063,0,0.0611228,"context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 564 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 564–571, Beijing, August 2010 word-aligned target sentences, and a target relation detector can bootstrap from projected ann"
C10-1064,E06-1015,0,0.252552,"ffthe-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model learned with the training set of the ACE 2003 corpus which consists of 674 documents and 9,683 relation instances was built for relation detection in English. In our implementation, we built a tree kernelbased SVM model using SVM-Light 5 (Joachims, 1998) and Tree Kernel Tools 6 (Moschitti, 2006). The subtree kernel method (Moschitti, 2006) for shortest path enclosed subtrees (Zhang et al., 2006) was adopted in our model. Our relation detection model achieved 81.2/69.8/75.1 in Precision/Recall/F-measure on the test set of the ACE 2003 corpus, which consists of 97 documents and 1,386 relation instances. The annotation of relations was performed by determining the existence of semantic relations for all 115,452 instances with the trained model for relation detection. The annotation detected 22,162 instances as positive which have semantic relations. 4.2 Projection The labels about entit"
C10-1064,J03-1002,0,0.00699598,"Missing"
C10-1064,N01-1026,0,0.0930469,"and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates t"
C10-1064,H01-1035,0,\N,Missing
C10-1064,H05-1091,0,\N,Missing
C12-2102,W06-1302,0,0.0324871,"log system; Multi-domain selection; Hierarchical domain model; Candidate domain detection; Final domain determination KEYWORDS IN KOREAN : 다중 도메인 대화 시스템; 다중 도메인 선택; 계층적 도메인 모델; 후보 도메인 검출; 최종 도메인 결정 Proceedings of COLING 2012: Posters, pages 1049–1058, COLING 2012, Mumbai, December 2012. 1049 1 Introduction A dialog system is a natural and effective interface between humans and machines because dialog is a natural method of human communication. Recently, multi-domain dialog systems that provide service to multiple domains have become widely employed in real-life situations (Allen et al., 2000; Komatani et al., 2006; Larsson and Ericsson, 2002; Pakucs, 2003). Multi-domain dialog systems that employ the distributed architecture first select a domain based on a user utterance, and then execute the domain-specific processes of the selected domain (Lin et al., 1999). Therefore, previous research has focused on the correct selection of a single domain based on a user utterance (Çelikyilmaz et al., 2011; Ikeda et al., 2008; Nakano et al., 2011). However, to our knowledge, no previous research has focused on the selection of one or more domains at the same time for multi-domain dialog systems that provide servi"
C12-2102,W11-2004,0,0.0548859,"Missing"
D09-1130,W04-3240,0,0.740207,"1 http://tripadvisor.com/ in this paper) and large unlabeled data sets can be collected from the Web. Thus, we focus on the problem of how to accurately recognize speech acts in emails and forums by making maximum use of data from existing resources. Recently, there are increasing interests in speech act recognition of online text-based conversations. Analysis of speech acts for online chat and instant messages and have been studied in computer-mediated communication (CMC) and distance learning (Twitchell et al., 2004; Nastri et al., 2006; Ros´e et al., 2008). In natural language processing, Cohen et al. (2004) and Feng et al. (2006) used speech acts to capture the intentional focus of emails and discussion boards. However, they assume that enough labeled data are available for developing speech act recognition models. A main contribution of this paper is that we address the problem of learning speech act recognition in a semi-supervised way. To our knowledge, this is the first use of semi-supervised speech act recognition in emails and online forums. To do this, we make use of labeled data from spoken conversations (Jurafsky et al., 1997; Dhillon et al., 2004). A second contribution is that our mod"
D09-1130,P04-1085,0,0.142462,"der Dialog Act (MRDA). SWBD is an annotation scheme and collection of labeled dialog act2 data for telephone conversations (Jurafsky et al., 1997). The main purpose of SWBD is to acquire stochastic discourse grammars for training better language models for automatic speech recognition. More recently, an MRDA corpus has been adapted from SWBD but its tag set for labeling meetings has been modified to better reflect the types of interaction in multi-party face-to-face meetings (Dhillon et al., 2004). These two corpora have been extensively studied, e.g., (Stolcke et al., 2000; Ang et al., 2005; Galley et al., 2004). We also use these for our experiments. 2 A dialog act is the meaning of an utterance at the level of illocutionary force (Austin, 1962), and broadly covers the speech act and adjacency pair (Stolcke et al., 2000). In this paper, we use only the term ‘speech act’ for clarity. This paper focuses on the problem of semisupervised speech act recognition. The goal of semi-supervised learning techniques is to use auxiliary data to improve a model’s capability to recognize speech acts. The approach in Tur et al. (2005) presented semi-supervised learning to employ auxiliary unlabeled data in call cla"
D09-1130,W04-3239,0,0.390245,"n “What site should we use to book a Beijing-Chonqing flight?” can be predicted by two discriminative features, “(<s>, WRB) → QW” and “(?, </s>) → QW” where <s> and </s> are sentence start and end symbols, and WRB is a part-of-speech tag that denotes a Wh-adverb. In addition, useful features could be of various lengths, i.e. not fixed length n-grams, and nonadjacent. One key idea of this paper is a novel use of subtree features to model these for speech act recognition. 4.1 Exploiting Subtree Features To exploit subtree features in our model, we use a subtree pattern mining method proposed by Kudo and Matsumoto (2004). We briefly introduce this algorithm here. In Section 3.1, we defined x = {xj } as the forest that is a set of trees. More precisely, xj is a labeled ordered tree where each node has its own label and is ordered leftto-right. Several types of labeled ordered trees Figure 3: Representations of tree: (a) bag-ofwords, (b) n-gram, (c) word pair, and (d) dependency tree. A node denotes a word and a directed edge indicates a parent-and-child relationship. are possible (Figure 3). Note that S-expression can be used instead for computation, for example (a(b(c(d)))) for the n-gram (Figure 3(b)). Moreo"
D09-1130,N06-1027,0,0.714336,"m/ in this paper) and large unlabeled data sets can be collected from the Web. Thus, we focus on the problem of how to accurately recognize speech acts in emails and forums by making maximum use of data from existing resources. Recently, there are increasing interests in speech act recognition of online text-based conversations. Analysis of speech acts for online chat and instant messages and have been studied in computer-mediated communication (CMC) and distance learning (Twitchell et al., 2004; Nastri et al., 2006; Ros´e et al., 2008). In natural language processing, Cohen et al. (2004) and Feng et al. (2006) used speech acts to capture the intentional focus of emails and discussion boards. However, they assume that enough labeled data are available for developing speech act recognition models. A main contribution of this paper is that we address the problem of learning speech act recognition in a semi-supervised way. To our knowledge, this is the first use of semi-supervised speech act recognition in emails and online forums. To do this, we make use of labeled data from spoken conversations (Jurafsky et al., 1997; Dhillon et al., 2004). A second contribution is that our model learns subtree featu"
D09-1130,N03-1030,0,0.073973,"Missing"
D09-1130,J00-3003,0,0.446913,"Missing"
I05-1058,H92-1045,0,0.0257589,"s in the candidates using several Expand/Accept Annotation Accepted Entities Learn Boundary Patterns Correct Entities Corpus (raw  tagged (partial  complete)) Boundary Patterns Control Annotation Errors Entity Candidates Extract Entity Candidates Seeds Initial Annotation Fig. 1. The bootstrapping overview Heuristic Methods for Reducing Errors of Geographic Named Entities 661 linguistic heuristics, which is described in detail in Section 4. Finally, the remaining entity candidates propagate their annotations into other occurrences within the same document by one sense per discourse principle [2]. This loop continues until there are no new patterns learned. The algorithm is summarized as follows: Step 0: Seed Preparation and Initial Annotation We prepare seeds from the gazetteer and obtain initial entity candidate set, C1 , by marking occurrences of the seeds in the training raw corpus. C1 = {ei |ei is an entity candidate obtained from seeds but not accepted yet}; And we initialize the number of iteration (k), the set of accepted boundary patterns (P0 ) and the set of accepted entities (E0 ) as follows: k = 1; P0 = φ; E0 = φ; Step 1: Controlling the Annotation Errors We ﬁlter out anno"
I05-1058,P91-1019,0,0.0235848,"us entities whose inconsistencies cannot be detected since their true entities are not identiﬁed yet. We call it potential inconsistency. We examine potential inclusion and potential type conﬂict for each entity candidate using the gazetteer and Web resources. To overcome this limitation of statistical measures obtained from the training corpus, we design several methods that incorporate linguistic knowledge and external resources, which are described in the following subsections. 4.1 Co-occurrence Information Co-occurrence information (CI) has been widely used to resolve word sense ambiguity [3,8,10] and also can be employed to resolve crossing and type conﬂict inconsistencies, which can be regarded as word sense ambiguity problem. We assume that two instances of an ambiguous entity that occur in diﬀerent texts can be classiﬁed into the same class if they share their CI. CI can be collected from deﬁnition statements of an entity of an encyclopedia. For example, the underlined phrases are collected as CI of an entity ‘Clinton’ with class CITY from a statement “Clinton is a city in Big Stone County, Minnesota, USA”. In this way, we could construct initial CI for 18000 entities from the Prob"
I05-1058,W03-0106,0,0.0228462,"re of their patterns to select better patterns. However, those statistical measures are calculated only using data obtained from their training corpus which cannot often 660 S. Lee and G.G. Lee give enough information. Instead, other resources like World Wide Web as well as a gazetteer can be incorporated to compensate the lack of information from the training corpus. Research on analysis of geographic references recently started to appear and has two directions. One is to focus on building gazetteer databases [6,11] and the other is to focus on classifying geographic entity instances in text [5]. Manov et al. [6] presented KIM (Knowledge and Information Management) that consists of an ontology and a knowledge base. They used it for information extraction but did not show notable results. Uryupina [11] presented a bootstrapping method to obtain gazetteers from the internet. By searching for seed names on the internet, she obtained lexical patterns and learned each classiﬁer for six location sub-types, such as COUNTRY, CITY, ISLAND, RIVER, MOUNTAIN and REGION. Then she obtained and classiﬁed candidate names by searching the patterns in the internet. Li et al. [5] suggested a hybrid app"
I05-1058,W03-0101,0,0.0226864,"out ambiguous terms and Yangarber et al. [12] calculated accuracy, conﬁdence and score of their patterns to select better patterns. However, those statistical measures are calculated only using data obtained from their training corpus which cannot often 660 S. Lee and G.G. Lee give enough information. Instead, other resources like World Wide Web as well as a gazetteer can be incorporated to compensate the lack of information from the training corpus. Research on analysis of geographic references recently started to appear and has two directions. One is to focus on building gazetteer databases [6,11] and the other is to focus on classifying geographic entity instances in text [5]. Manov et al. [6] presented KIM (Knowledge and Information Management) that consists of an ontology and a knowledge base. They used it for information extraction but did not show notable results. Uryupina [11] presented a bootstrapping method to obtain gazetteers from the internet. By searching for seed names on the internet, she obtained lexical patterns and learned each classiﬁer for six location sub-types, such as COUNTRY, CITY, ISLAND, RIVER, MOUNTAIN and REGION. Then she obtained and classiﬁed candidate name"
I05-1058,C94-1049,0,0.0285275,"us entities whose inconsistencies cannot be detected since their true entities are not identiﬁed yet. We call it potential inconsistency. We examine potential inclusion and potential type conﬂict for each entity candidate using the gazetteer and Web resources. To overcome this limitation of statistical measures obtained from the training corpus, we design several methods that incorporate linguistic knowledge and external resources, which are described in the following subsections. 4.1 Co-occurrence Information Co-occurrence information (CI) has been widely used to resolve word sense ambiguity [3,8,10] and also can be employed to resolve crossing and type conﬂict inconsistencies, which can be regarded as word sense ambiguity problem. We assume that two instances of an ambiguous entity that occur in diﬀerent texts can be classiﬁed into the same class if they share their CI. CI can be collected from deﬁnition statements of an entity of an encyclopedia. For example, the underlined phrases are collected as CI of an entity ‘Clinton’ with class CITY from a statement “Clinton is a city in Big Stone County, Minnesota, USA”. In this way, we could construct initial CI for 18000 entities from the Prob"
I05-1058,W02-1017,0,0.0203508,"s for controlling the annotation errors are explained in Section 4. Section 5 gives some experimental results verifying our approach, which is followed by conclusions and future works in Section 6. 2 Related Works Most bootstrapping approaches start with incomplete annotations and patterns obtained from selected seeds and learn to obtain more complete annotations and patterns. However, the incompleteness is apt to cause annotation errors to be introduced in each bootstrapping iteration. Most previous works have designed their own statistical measures to control such errors. Phillips and Riloﬀ [9] developed evidence and exclusivity measures to ﬁlter out ambiguous terms and Yangarber et al. [12] calculated accuracy, conﬁdence and score of their patterns to select better patterns. However, those statistical measures are calculated only using data obtained from their training corpus which cannot often 660 S. Lee and G.G. Lee give enough information. Instead, other resources like World Wide Web as well as a gazetteer can be incorporated to compensate the lack of information from the training corpus. Research on analysis of geographic references recently started to appear and has two direct"
I05-1058,S01-1027,0,0.0132844,"us entities whose inconsistencies cannot be detected since their true entities are not identiﬁed yet. We call it potential inconsistency. We examine potential inclusion and potential type conﬂict for each entity candidate using the gazetteer and Web resources. To overcome this limitation of statistical measures obtained from the training corpus, we design several methods that incorporate linguistic knowledge and external resources, which are described in the following subsections. 4.1 Co-occurrence Information Co-occurrence information (CI) has been widely used to resolve word sense ambiguity [3,8,10] and also can be employed to resolve crossing and type conﬂict inconsistencies, which can be regarded as word sense ambiguity problem. We assume that two instances of an ambiguous entity that occur in diﬀerent texts can be classiﬁed into the same class if they share their CI. CI can be collected from deﬁnition statements of an entity of an encyclopedia. For example, the underlined phrases are collected as CI of an entity ‘Clinton’ with class CITY from a statement “Clinton is a city in Big Stone County, Minnesota, USA”. In this way, we could construct initial CI for 18000 entities from the Prob"
I05-1058,W03-0103,0,0.0275183,"out ambiguous terms and Yangarber et al. [12] calculated accuracy, conﬁdence and score of their patterns to select better patterns. However, those statistical measures are calculated only using data obtained from their training corpus which cannot often 660 S. Lee and G.G. Lee give enough information. Instead, other resources like World Wide Web as well as a gazetteer can be incorporated to compensate the lack of information from the training corpus. Research on analysis of geographic references recently started to appear and has two directions. One is to focus on building gazetteer databases [6,11] and the other is to focus on classifying geographic entity instances in text [5]. Manov et al. [6] presented KIM (Knowledge and Information Management) that consists of an ontology and a knowledge base. They used it for information extraction but did not show notable results. Uryupina [11] presented a bootstrapping method to obtain gazetteers from the internet. By searching for seed names on the internet, she obtained lexical patterns and learned each classiﬁer for six location sub-types, such as COUNTRY, CITY, ISLAND, RIVER, MOUNTAIN and REGION. Then she obtained and classiﬁed candidate name"
I05-1058,C02-1154,0,0.0189135,"tal results verifying our approach, which is followed by conclusions and future works in Section 6. 2 Related Works Most bootstrapping approaches start with incomplete annotations and patterns obtained from selected seeds and learn to obtain more complete annotations and patterns. However, the incompleteness is apt to cause annotation errors to be introduced in each bootstrapping iteration. Most previous works have designed their own statistical measures to control such errors. Phillips and Riloﬀ [9] developed evidence and exclusivity measures to ﬁlter out ambiguous terms and Yangarber et al. [12] calculated accuracy, conﬁdence and score of their patterns to select better patterns. However, those statistical measures are calculated only using data obtained from their training corpus which cannot often 660 S. Lee and G.G. Lee give enough information. Instead, other resources like World Wide Web as well as a gazetteer can be incorporated to compensate the lack of information from the training corpus. Research on analysis of geographic references recently started to appear and has two directions. One is to focus on building gazetteer databases [6,11] and the other is to focus on classifyi"
I08-8001,1993.iwpt-1.3,0,0.14764,"lied to the translation tasks with Korean as a source language. 2 Methods Our task is splitting a long compound sentence into short sub-sentences to improve the performance of phrase-based statistical machine translation system. We use a transformation based approach to accomplish our goal. 2.1 A Concept of Transformation The transformation based learning (TBL) is a kind of rule learning methods. The formalism of TBL is introduced by Brill (1995). In past years, the TBL approach was used to solve various problems in natural language processing such as part of speech (POS) tagging and parsing (Brill, 1993). A transformation consists of two parts: a triggering environment and a rewriting rule. And the rewriting rule consists of a source pattern and a target pattern. Our consideration is how to get the right transformations and apply them to split the long sentences. A transformation works in the following manner; some portion of the input is changed by the rewriting rule if the input meets a condition specified in the triggering environment. The rewriting rule finds the source pattern in the input and replaces it with the target pattern. For example, suppose that a transformation which have a tr"
I08-8001,J95-4004,0,0.0465027,"volves parsing which requires heavy cost. In this paper we propose a transformation based splitting method to improve machine translation quality which can be applied to the translation tasks with Korean as a source language. 2 Methods Our task is splitting a long compound sentence into short sub-sentences to improve the performance of phrase-based statistical machine translation system. We use a transformation based approach to accomplish our goal. 2.1 A Concept of Transformation The transformation based learning (TBL) is a kind of rule learning methods. The formalism of TBL is introduced by Brill (1995). In past years, the TBL approach was used to solve various problems in natural language processing such as part of speech (POS) tagging and parsing (Brill, 1993). A transformation consists of two parts: a triggering environment and a rewriting rule. And the rewriting rule consists of a source pattern and a target pattern. Our consideration is how to get the right transformations and apply them to split the long sentences. A transformation works in the following manner; some portion of the input is changed by the rewriting rule if the input meets a condition specified in the triggering environ"
I08-8001,J93-2003,0,0.0075669,"chnology (POSTECH) {jh21983, semko, gblee}@postech.ac.kr Abstract We propose a transformation based sentence splitting method for statistical machine translation. Transformations are expanded to improve machine translation quality after automatically obtained from manually split corpus. Through a series of experiments we show that the transformation based sentence splitting is effective pre-processing to long sentence translation. 1 Introduction Statistical approaches to machine translation have been studied actively, after the formalism of statistical machine translation (SMT) is proposed by Brown et al. (1993). Although many approaches of them were effective, there are still lots of problems to solve. Among others, we have an interest in the problems occurring with long sentence decoding. Various problems occur when we try to translate long input sentences because a longer sentence contains more possibilities of selecting translation options and reordering phrases. However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003). Some methods which can offer powerful reordering policies have been propo"
I08-8001,C04-1017,0,0.0188841,"ation of the sentence structures which can be obtained by syntactic or semantic analysis. Unfortunately, the high level syntactic and semantic analysis can be erroneous and costs as expensive as SMT itself. So, we don’t want to fully analyze the sentences to get a series of sub-sentences, and our approach to this problem considers splitting only compound sentences. In the past years, many research works were concerned with sentence splitting methods to improve machine translation quality. This idea had been used in speech translation (Furuse et al, 1998) and example based machine translation (Doi and Sumita, 2004). These research works achieved meaningful results in terms of machine translation quality. Unfortunately, however, the method of Doi and Sumita using n-gram is not available if the source language is Korean. In Korean language, most of sentences have special form of ending morphemes at the end. For that reason, we should determine not only the splitting position but also the ending morphemes that we should replace instead of connecting morphemes. And the Furuse et al’s method involves parsing which requires heavy cost. In this paper we propose a transformation based splitting method to improv"
I08-8001,P98-1070,0,0.0182737,"osing a complex sentence into sub-sentences requires information of the sentence structures which can be obtained by syntactic or semantic analysis. Unfortunately, the high level syntactic and semantic analysis can be erroneous and costs as expensive as SMT itself. So, we don’t want to fully analyze the sentences to get a series of sub-sentences, and our approach to this problem considers splitting only compound sentences. In the past years, many research works were concerned with sentence splitting methods to improve machine translation quality. This idea had been used in speech translation (Furuse et al, 1998) and example based machine translation (Doi and Sumita, 2004). These research works achieved meaningful results in terms of machine translation quality. Unfortunately, however, the method of Doi and Sumita using n-gram is not available if the source language is Korean. In Korean language, most of sentences have special form of ending morphemes at the end. For that reason, we should determine not only the splitting position but also the ending morphemes that we should replace instead of connecting morphemes. And the Furuse et al’s method involves parsing which requires heavy cost. In this paper"
I08-8001,koen-2004-pharaoh,0,0.0404555,"tag. We choose one of them in a fixed order: forward POS tag, forward morpheme, backward POS tag and backward morpheme. These choices can be limited by 9 heuristics. For example, suppose that we use a heuristic with forward policy on morpheme context window and no expansion policy for POS tag context window. In this case we have only one choice: forward morpheme. 3 Experiments We performed a series of experiments on Korean to English translation task to see how the sentence splitting affects machine translation quality and which heuristics are the best. Our baseline system built with Pharaoh (Koehn, 2004) which is most popular phrase-based decoder. And trigram language model with KN-discounting (Kneser and Ney, 1995) built by SRILM toolkit (Stolcke, 2002) is used. Table 1 shows the corpus statistics used in the experiments. The training corpus for MT system has been built by manually translating Korean sentences which are collected from various sources. We built 123,425 sentence pairs for training SMT, 1,577 pairs for splitting and another 1,577 pairs for testing. The domain of the text is daily conversations and travel expressions. The sentence splitting corpus has been built by extracting lo"
I08-8001,N03-1017,0,0.0452818,"ter the formalism of statistical machine translation (SMT) is proposed by Brown et al. (1993). Although many approaches of them were effective, there are still lots of problems to solve. Among others, we have an interest in the problems occurring with long sentence decoding. Various problems occur when we try to translate long input sentences because a longer sentence contains more possibilities of selecting translation options and reordering phrases. However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003). Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation (Yamada and Knight, 2001) and Inversion Transduction Grammar (Wu, 1997). Although these approaches are effective, decoding long sentences is still difficult due to their computational complexity. As the length of an input sentence becomes longer, the analysis and decoding become more complex. The complexity causes approximations and errors inevitable during the decoding search. In order to reduce this kind of difficulty caused by the complexity, a long sentence can be paraphrase"
I08-8001,2001.mtsummit-papers.68,0,0.0252078,"four types: ‘and’, ‘or’, ‘but’ and ‘NULL’. (4) A splitting position is a non-negative integer that means the position of starting word of second sub-sentence. 2.3 Learning the Transformation for Sentence Splitting At the training phase, TBL process determines the order of application (or rank) of the transformations to minimize the error-rate defined by a specific measure. The order is determined by choosing the best rule for a given situation and applying the best rule for each situation iteratively. In the sentence splitting task, we maximize the machine translation quality with BLEU score (Papineni et al., 2001) instead of minimizing the error of sentence splitting. During the training phase, we determine the order of applying transformation after we build a set of transformations. To build the set of transformations, we need manually split examples to learn the transformations. Building a transformation starts from extracting a rewriting rule by calculating edit-distance matrix between an original sentence and its split form from the corpus. We can easily extract the different parts from the matrix. BaseBLEU := BLEU score of the baseline system S := Split example sentence T := Extracted initial tran"
I08-8001,J97-3002,0,0.0474784,"rs, we have an interest in the problems occurring with long sentence decoding. Various problems occur when we try to translate long input sentences because a longer sentence contains more possibilities of selecting translation options and reordering phrases. However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003). Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation (Yamada and Knight, 2001) and Inversion Transduction Grammar (Wu, 1997). Although these approaches are effective, decoding long sentences is still difficult due to their computational complexity. As the length of an input sentence becomes longer, the analysis and decoding become more complex. The complexity causes approximations and errors inevitable during the decoding search. In order to reduce this kind of difficulty caused by the complexity, a long sentence can be paraphrased by several shorter sentences with the same meaning. Generally, however, decomposing a complex sentence into sub-sentences requires information of the sentence structures which can be obt"
I08-8001,P01-1067,0,0.0590603,"ective, there are still lots of problems to solve. Among others, we have an interest in the problems occurring with long sentence decoding. Various problems occur when we try to translate long input sentences because a longer sentence contains more possibilities of selecting translation options and reordering phrases. However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003). Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation (Yamada and Knight, 2001) and Inversion Transduction Grammar (Wu, 1997). Although these approaches are effective, decoding long sentences is still difficult due to their computational complexity. As the length of an input sentence becomes longer, the analysis and decoding become more complex. The complexity causes approximations and errors inevitable during the decoding search. In order to reduce this kind of difficulty caused by the complexity, a long sentence can be paraphrased by several shorter sentences with the same meaning. Generally, however, decomposing a complex sentence into sub-sentences requires informati"
I08-8001,P02-1040,0,\N,Missing
I08-8001,C98-1067,0,\N,Missing
I11-1083,P08-1004,0,0.414424,"d this determination based on syntactic structural heuristics or structured information from Wikipedia, our proposed self-supervision approach utilizes the projected annotations from the results of Open IE system developed for another language. Details about our self-supervision approach are provided in Section 3. In the learning step, a set of training examples obtained from self-supervision is utilized to learn an extractor f . The extractor has been successfully implemented using statistical models such as the Naive Bayes classifier (Banko et al., 2007) and conditional random fields (CRF) (Banko et al., 2008). 2 Open Information Extraction 3 Cross-Lingual Annotation Projection-Based Self-Supervision The problem of Open IE is to learn a function f : D → {hei , ri,j , ej i|1 ≤ i, j ≤ N }, where D is a given natural language document, ei and ej are entities which have a semantic relationship that is explicitly expressed in a contextual subtext ri,j , and N is the total number of entities in D. For example, the output of an Open IE system for an input sentence “Obama was born in Hawaii.” will be a tuple h Obama, was born in, Hawaii i. Whereas traditional relation extraction problems such as ACE RDC ha"
I11-1083,H05-1091,0,0.0636944,"of our future work is to investigate a hybrid approach to self-supervision considering not only cross-lingual projected annotations, but also various external knowledge source such as Wikipedia and WordNet. We expect that this fusion approach can help to improve the quality of extracted results, because the effectiveness of each approach has been demonstrated for IE tasks. 6 Related Work Many supervised machine learning approaches have been successfully applied to solve traditional relation extraction tasks (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), but these approaches require a large number of training examples to achieve high performance. To reduce the annotation cost, weakly-supervised techniques have been designed (Zhang, 2004; Chen et al., 2006). Open IE pioneered by TextRunner (Banko et al., 2007) is an alternative weakly-supervised IE paradigm. TextRunner aims to perform relationindependent extraction by introducing the selfsupervision approach based on a small set of heuristics about syntactic structural constraints. The performance of TextRunner was further improved using O-CRF and casting the Open IE task"
I11-1083,H01-1035,0,0.117268,"Hawaii.” will be a tuple h Obama, was born in, Hawaii i. Whereas traditional relation extraction problems such as ACE RDC have attempted to process both explicit and implicit relationships, Open IE aims to only extract explicit relationships ri,j Cross-lingual annotation projection is an approach to obtain training examples for LT by projecting the annotations for LS using parallel corpora between LT and LS . This approach has been applied for several natural language processing tasks which have differences in the amounts of available resources among target languages (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002; Hwa et al., 2002; Zitouni and Florian, 2008; Pado and Lapata, 2009). A premise of our method is that parallel corpora between LT and LS are 742 much easier to obtain than is a task-specific training dataset for LT : this premise is generally reasonable because large numbers of parallel corpora for various language pairs are available. We consider the Open IE as a task with an imbalance problem in resource according to the target language, because most reported systems for Open IE were developed only for English and because they depend on language-specific knowledge. We pr"
I11-1083,P06-1017,0,0.0167803,"approach can help to improve the quality of extracted results, because the effectiveness of each approach has been demonstrated for IE tasks. 6 Related Work Many supervised machine learning approaches have been successfully applied to solve traditional relation extraction tasks (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), but these approaches require a large number of training examples to achieve high performance. To reduce the annotation cost, weakly-supervised techniques have been designed (Zhang, 2004; Chen et al., 2006). Open IE pioneered by TextRunner (Banko et al., 2007) is an alternative weakly-supervised IE paradigm. TextRunner aims to perform relationindependent extraction by introducing the selfsupervision approach based on a small set of heuristics about syntactic structural constraints. The performance of TextRunner was further improved using O-CRF and casting the Open IE task as a kind of sequential labeling problem (Banko et al., 2008). Wu and Weld (2010) presented another Open IE system WOE which utilizes an alternative self-supervision approach based on Wikipedia infoboxes. The main difference be"
I11-1083,P04-1054,0,0.0266358,"his work. Another direction of our future work is to investigate a hybrid approach to self-supervision considering not only cross-lingual projected annotations, but also various external knowledge source such as Wikipedia and WordNet. We expect that this fusion approach can help to improve the quality of extracted results, because the effectiveness of each approach has been demonstrated for IE tasks. 6 Related Work Many supervised machine learning approaches have been successfully applied to solve traditional relation extraction tasks (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), but these approaches require a large number of training examples to achieve high performance. To reduce the annotation cost, weakly-supervised techniques have been designed (Zhang, 2004; Chen et al., 2006). Open IE pioneered by TextRunner (Banko et al., 2007) is an alternative weakly-supervised IE paradigm. TextRunner aims to perform relationindependent extraction by introducing the selfsupervision approach based on a small set of heuristics about syntactic structural constraints. The performance of TextRunner was further improved using O-CRF an"
I11-1083,P06-1104,0,0.0170515,"nvestigate a hybrid approach to self-supervision considering not only cross-lingual projected annotations, but also various external knowledge source such as Wikipedia and WordNet. We expect that this fusion approach can help to improve the quality of extracted results, because the effectiveness of each approach has been demonstrated for IE tasks. 6 Related Work Many supervised machine learning approaches have been successfully applied to solve traditional relation extraction tasks (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), but these approaches require a large number of training examples to achieve high performance. To reduce the annotation cost, weakly-supervised techniques have been designed (Zhang, 2004; Chen et al., 2006). Open IE pioneered by TextRunner (Banko et al., 2007) is an alternative weakly-supervised IE paradigm. TextRunner aims to perform relationindependent extraction by introducing the selfsupervision approach based on a small set of heuristics about syntactic structural constraints. The performance of TextRunner was further improved using O-CRF and casting the Open IE task as a kind of sequent"
I11-1083,P02-1050,0,0.0377934,"in, Hawaii i. Whereas traditional relation extraction problems such as ACE RDC have attempted to process both explicit and implicit relationships, Open IE aims to only extract explicit relationships ri,j Cross-lingual annotation projection is an approach to obtain training examples for LT by projecting the annotations for LS using parallel corpora between LT and LS . This approach has been applied for several natural language processing tasks which have differences in the amounts of available resources among target languages (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002; Hwa et al., 2002; Zitouni and Florian, 2008; Pado and Lapata, 2009). A premise of our method is that parallel corpora between LT and LS are 742 much easier to obtain than is a task-specific training dataset for LT : this premise is generally reasonable because large numbers of parallel corpora for various language pairs are available. We consider the Open IE as a task with an imbalance problem in resource according to the target language, because most reported systems for Open IE were developed only for English and because they depend on language-specific knowledge. We propose a cross-lingual annotation proje"
I11-1083,P04-3022,0,0.0216116,"ntroduce assessment techniques which are not included in this work. Another direction of our future work is to investigate a hybrid approach to self-supervision considering not only cross-lingual projected annotations, but also various external knowledge source such as Wikipedia and WordNet. We expect that this fusion approach can help to improve the quality of extracted results, because the effectiveness of each approach has been demonstrated for IE tasks. 6 Related Work Many supervised machine learning approaches have been successfully applied to solve traditional relation extraction tasks (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), but these approaches require a large number of training examples to achieve high performance. To reduce the annotation cost, weakly-supervised techniques have been designed (Zhang, 2004; Chen et al., 2006). Open IE pioneered by TextRunner (Banko et al., 2007) is an alternative weakly-supervised IE paradigm. TextRunner aims to perform relationindependent extraction by introducing the selfsupervision approach based on a small set of heuristics about syntactic structural constrain"
I11-1083,N03-1017,0,0.00474884,"Missing"
I11-1083,H05-1066,0,0.0259078,"Missing"
I11-1083,P02-1027,0,0.0277066,"e h Obama, was born in, Hawaii i. Whereas traditional relation extraction problems such as ACE RDC have attempted to process both explicit and implicit relationships, Open IE aims to only extract explicit relationships ri,j Cross-lingual annotation projection is an approach to obtain training examples for LT by projecting the annotations for LS using parallel corpora between LT and LS . This approach has been applied for several natural language processing tasks which have differences in the amounts of available resources among target languages (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002; Hwa et al., 2002; Zitouni and Florian, 2008; Pado and Lapata, 2009). A premise of our method is that parallel corpora between LT and LS are 742 much easier to obtain than is a task-specific training dataset for LT : this premise is generally reasonable because large numbers of parallel corpora for various language pairs are available. We consider the Open IE as a task with an imbalance problem in resource according to the target language, because most reported systems for Open IE were developed only for English and because they depend on language-specific knowledge. We propose a cross-lingua"
I11-1083,J03-1002,0,0.00548798,"Missing"
I11-1083,P10-1013,0,0.176704,"hout significant annotation efforts have been sought (Zhang, 2004; Chen et al., 2006). Open IE is an alternative weakly-supervised IE paradigm (Banko et al., 2007). The goal of Open IE is to yield both domain-independent and relation-independent extractions from a large amount of natural language text without requiring hand-crafted rules or hand-annotated training examples. A key challenge to implementing Open IE is to learn extractors without manually annotated training examples. Self-supervised learning approaches have allowed Open IE systems such as TextRunner (Banko et al., 2007) and WOE (Wu and Weld, 2010) to extract relations from largescale English text with automatically annotated training examples obtained using external knowledge. However, applying the self-supervision approaches adopted by previously reported Open IE systems to build a new system is problematic in languages other than English, because these approaches mainly depend on language-specific knowledge for English. For example, TextRunner obtains training examples from the English Penn Treebank by triggering a set of hand-written heuristics denoting syntactic structural constraints to decide whether or not a given instance has a"
I11-1083,N01-1026,0,0.291871,"tence “Obama was born in Hawaii.” will be a tuple h Obama, was born in, Hawaii i. Whereas traditional relation extraction problems such as ACE RDC have attempted to process both explicit and implicit relationships, Open IE aims to only extract explicit relationships ri,j Cross-lingual annotation projection is an approach to obtain training examples for LT by projecting the annotations for LS using parallel corpora between LT and LS . This approach has been applied for several natural language processing tasks which have differences in the amounts of available resources among target languages (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002; Hwa et al., 2002; Zitouni and Florian, 2008; Pado and Lapata, 2009). A premise of our method is that parallel corpora between LT and LS are 742 much easier to obtain than is a task-specific training dataset for LT : this premise is generally reasonable because large numbers of parallel corpora for various language pairs are available. We consider the Open IE as a task with an imbalance problem in resource according to the target language, because most reported systems for Open IE were developed only for English and because they depend on language-sp"
I11-1083,P05-1053,0,0.043983,"nt techniques which are not included in this work. Another direction of our future work is to investigate a hybrid approach to self-supervision considering not only cross-lingual projected annotations, but also various external knowledge source such as Wikipedia and WordNet. We expect that this fusion approach can help to improve the quality of extracted results, because the effectiveness of each approach has been demonstrated for IE tasks. 6 Related Work Many supervised machine learning approaches have been successfully applied to solve traditional relation extraction tasks (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), but these approaches require a large number of training examples to achieve high performance. To reduce the annotation cost, weakly-supervised techniques have been designed (Zhang, 2004; Chen et al., 2006). Open IE pioneered by TextRunner (Banko et al., 2007) is an alternative weakly-supervised IE paradigm. TextRunner aims to perform relationindependent extraction by introducing the selfsupervision approach based on a small set of heuristics about syntactic structural constraints. The performance"
I11-1083,D08-1063,0,0.0232737,"eas traditional relation extraction problems such as ACE RDC have attempted to process both explicit and implicit relationships, Open IE aims to only extract explicit relationships ri,j Cross-lingual annotation projection is an approach to obtain training examples for LT by projecting the annotations for LS using parallel corpora between LT and LS . This approach has been applied for several natural language processing tasks which have differences in the amounts of available resources among target languages (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002; Hwa et al., 2002; Zitouni and Florian, 2008; Pado and Lapata, 2009). A premise of our method is that parallel corpora between LT and LS are 742 much easier to obtain than is a task-specific training dataset for LT : this premise is generally reasonable because large numbers of parallel corpora for various language pairs are available. We consider the Open IE as a task with an imbalance problem in resource according to the target language, because most reported systems for Open IE were developed only for English and because they depend on language-specific knowledge. We propose a cross-lingual annotation projection-based self-supervisio"
J02-1004,J95-4004,0,0.767037,"ion purposes at http://nlp.postech.ac.kr/. Follow the link OpenResources→DownLoad. c 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 Previous techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and Tur ¨ 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown morphemes is to guess all the possible POS tags for an unknown morpheme by checking connectable functional morphemes in the sa"
J02-1004,A92-1018,0,0.291606,"pattern-based generalized unknown-morpheme estimation method using a morpheme pattern dictionary that enables us to treat unknown morphemes in the same way as registered known morphemes, and thereby to guess them regardless of their numbers or positions in an eojeol. The method for estimating unknown morphemes using the morpheme pattern dictionary in Korean needs to be tightly integrated into morphological analysis and POS disambiguation systems. POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993). These approaches are also dominant for Korean, with slight improvements to accommodate the agglutinative nature of Korean. For Korean, early HMM tagging was based on eojeols. The eojeol-based tagging model calculates lexical and transition probabilities with eojeols as a unit; it suffers from severe data sparseness problems since a single eojeol consists of many different morphemes (Lee, Choi, and Kim 1993). Later, morpheme-based HMM tagging was tried; such models assign a single tag to a morpheme regardless of the space in a sentence. Morpheme-based tag"
J02-1004,J94-2001,0,0.043092,"Missing"
J02-1004,P96-1043,0,0.0203309,"s techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and Tur ¨ 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown morphemes is to guess all the possible POS tags for an unknown morpheme by checking connectable functional morphemes in the same eojeol (Kang 1993).2 However, in this way, it is only possible to guess probable POS tags for a single unknown morpheme when it occurs at the beginning of an eojeol. Unlike in English,"
J02-1004,C94-1032,0,0.0269678,"Lexical Probability Estimation for Unknown-Morpheme Guessing The lexical probabilities for unknown morphemes cannot be precalculated using Equation (8) since we assume the unknown morphemes do not appear in the training corpus, so a special on-the-fly estimation method must be applied. We suggest using syllable trigrams since Korean syllables can play an important role in restricting units for guessing the POS of a morpheme. The lexical probability PrPr(t(ti |mi )i ) for unknown morphemes can be estimated using the frequency of syllable trigram products according to the formula in (11)–(13) (Nagata 1994), m Pr (t |m) Pr (t) = e1 e2 . . . en ≈ Pr t (e1 |#, # )Pr t (e2 |#, e1 ) × n Y i=3 62 Pr t (ei |ei−2 , ei−1 ) (11) Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation × Pr (# |en−1 , en ) (12) Pr t (ei |ei−2 , ei−1 ) ≈ ft (ei |ei−2 , ei−1 ) + ft (ei |ei−1 ) (13) + ft (ei ) where m is a morpheme, e is a syllable, t is a POS tag, “#” is a morpheme boundary symbol, and ft (ei |ei−2 , ei−1 ) is a frequency datum for tag t with co-occurrence syllables ei−2 , ei−1 , and ei . Trigram probabilities are smoothed by Equation (13) to cope with the data sparseness problem. For example, P"
J02-1004,W96-0207,0,0.0193826,"single unknown morpheme when it occurs at the beginning of an eojeol. Unlike in English, in Korean, more than one unknown morpheme can appear in a single eojeol because an eojeol can include complex components such as Chinese characters, Japanese words, and other foreign words. If an eojeol contains more than one unknown morpheme or if the unknown morphemes appear in other than first position in the eojeol, all previous methods fail to efficiently estimate them. This is the reason why we try to avoid conventional guessing rules using word morphology features such as those proposed in Mikheev (1996) and Oflazer and Tur ¨ (1996).3 In this paper, we propose a syllable-pattern-based generalized unknown-morpheme estimation method using a morpheme pattern dictionary that enables us to treat unknown morphemes in the same way as registered known morphemes, and thereby to guess them regardless of their numbers or positions in an eojeol. The method for estimating unknown morphemes using the morpheme pattern dictionary in Korean needs to be tightly integrated into morphological analysis and POS disambiguation systems. POS disambiguation has usually been performed by statistical approaches, mainly"
J02-1004,J93-2006,0,0.14406,"POSTECH), Pohang, 790-784, Korea. E-mail: jhlee@postech.ac.kr. 1 The binary code of POSTAG is open to the public for research and evaluation purposes at http://nlp.postech.ac.kr/. Follow the link OpenResources→DownLoad. c 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 Previous techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and Tur ¨ 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown mo"
J02-1004,E95-1022,0,\N,Missing
J02-1004,A94-1008,0,\N,Missing
N06-2018,W04-1213,0,0.0681734,"Missing"
N07-4004,P00-1056,0,0.0431288,"inal analyzed form of an eojeol (in the form of a sequence of morphemes plus POS tags) is defined as a word in the ASR lexicon, the transformed sentences are directly generated by the ASR only, so POS tagger errors can be removed from the system. Preprocessor also removes useless words in SMT in the transformed sentences produced by the ASR. 2.2 2.6 SMT We implemented a Korean-English phrase-based SMT decoder based on Pharaoh (Koehn, 2004). The decoder needs a phrase translation model for the Korean-English pair and a language model for English. We used the Pharaoh training module and GIZA++ (Och and Ney, 2000) to construct the phrase translation table. For language modeling, SRILM toolkit (Stolcke, 2002) was used to build a trigram language model. 2.3 TTS We used Microsoft SAPI 5.1 TTS engine for English TTS. The final best translation is pronounced using the engine. 2.4 LM Loader We implemented a re-ranking module to make a robust SLT system against the speech recognition errors. The re-ranking module uses several features: ASR acoustic model scores, ASR language model scores, and SMT translation scores. Finally, the re-ranking module sorts the N-best lists by comparing the total scores. Acknowled"
N07-4004,koen-2004-pharaoh,0,0.0453099,"st hypotheses determined through the decoding process, which are used as the input of SMT. However, for these techniques, Part-Of-Speech (POS) tagger is needed. If the final analyzed form of an eojeol (in the form of a sequence of morphemes plus POS tags) is defined as a word in the ASR lexicon, the transformed sentences are directly generated by the ASR only, so POS tagger errors can be removed from the system. Preprocessor also removes useless words in SMT in the transformed sentences produced by the ASR. 2.2 2.6 SMT We implemented a Korean-English phrase-based SMT decoder based on Pharaoh (Koehn, 2004). The decoder needs a phrase translation model for the Korean-English pair and a language model for English. We used the Pharaoh training module and GIZA++ (Och and Ney, 2000) to construct the phrase translation table. For language modeling, SRILM toolkit (Stolcke, 2002) was used to build a trigram language model. 2.3 TTS We used Microsoft SAPI 5.1 TTS engine for English TTS. The final best translation is pronounced using the engine. 2.4 LM Loader We implemented a re-ranking module to make a robust SLT system against the speech recognition errors. The re-ranking module uses several features: A"
N07-4004,C04-1168,0,0.0719629,"Missing"
N09-2023,P06-1026,0,0.0305472,"s automatic construction of domain model (or topic structure) which is one of the important resources to handle user’s queries in call centers. Traditional approach to building domain models is that the analysts manually generate a domain model through inspection of the call records. However, it has recently been proposed to use an unsupervised technique to generate domain models automatically from call transcriptions (Roy and Subramaniam, 2006). In addition, there has been research on how to automatically learn models of taskoriented discourse structure using dialog act and task information (Bangalore et al., 2006). Discourse structure is necessary for dialog state-specific speech recognition and language understanding to improve the performance by predicting the next possible dialog states. In addition, the discourse structure is essential to determine whether the current utterance in the dialog is part of the current subtask or starts a new task. 89 Proceedings of NAACL HLT 2009: Short Papers, pages 89–92, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics Feature Types Features unigram Word-level bigram features trigram dialog act (DA) Utterance-level main goal (MG) featur"
N09-2023,W08-1503,1,0.890159,"Missing"
N09-2023,P06-1093,0,0.0341486,"9). In general, the datadriven approaches are more robust and portable than traditional knowledge-based approaches. However, various knowledge sources are still used in many spoken dialog systems that have been developed recently. These knowledge sources contain task model, domain model, and agenda which are powerful representation to reflect the hierarchy of natural dialog control. In the spoken dialog systems, these are manually designed for various purposes including dialog modeling (Bohus and Rudnicky, 2003, Lee et al., 2008), search space reduction (Young et al., 2007), domain knowledge (Roy and Subramaniam, 2006), and user simulation (Schatzmann et al., 2007). We have proposed an example-based dialog modeling (EBDM) framework using an agenda graph as prior Clustering techniques have been widely used to build prior knowledge for spoken dialog systems. One of them is automatic construction of domain model (or topic structure) which is one of the important resources to handle user’s queries in call centers. Traditional approach to building domain models is that the analysts manually generate a domain model through inspection of the call records. However, it has recently been proposed to use an unsupervis"
N09-2023,N07-2038,0,0.0355249,"e robust and portable than traditional knowledge-based approaches. However, various knowledge sources are still used in many spoken dialog systems that have been developed recently. These knowledge sources contain task model, domain model, and agenda which are powerful representation to reflect the hierarchy of natural dialog control. In the spoken dialog systems, these are manually designed for various purposes including dialog modeling (Bohus and Rudnicky, 2003, Lee et al., 2008), search space reduction (Young et al., 2007), domain knowledge (Roy and Subramaniam, 2006), and user simulation (Schatzmann et al., 2007). We have proposed an example-based dialog modeling (EBDM) framework using an agenda graph as prior Clustering techniques have been widely used to build prior knowledge for spoken dialog systems. One of them is automatic construction of domain model (or topic structure) which is one of the important resources to handle user’s queries in call centers. Traditional approach to building domain models is that the analysts manually generate a domain model through inspection of the call records. However, it has recently been proposed to use an unsupervised technique to generate domain models automati"
N09-2023,P08-1072,1,\N,Missing
N09-2043,W06-0204,0,0.0290196,"controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been proposed. The predicate-argument (SVO) model allows subtr"
N09-2043,H01-1009,0,0.0358896,"fective strategy for controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been proposed. The predicate-a"
N09-2043,P03-1029,0,0.0194241,"pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been proposed. The predicate-argument (SVO) model allows subtrees containing only"
N09-2043,C04-1078,0,0.0177704,"do et al., 2003). Regardless of the applied pattern representation model, the methods have concentrated on extracting only exactly equivalent subtrees of test instances to the extraction patterns, which we call hard pattern matching. While the hard pattern matching policy is helpful to improve the precision of the extracted results, it can cause the low recall problem. In order to tackle this problem, a number of soft pattern matching approaches which aim to improve recall with minimized precision loss have been applied to the linear vector pattern models by introducing a probabilistic model (Xiao et al., 2004) or a sequence alignment algorithm (Kim et al., 2008). In this paper, we propose an alternative soft pattern matching method for IE based on a local tree alignment algorithm. While other soft pattern matching approaches have been able to handle the matching among linear vector instances with features from tree structures only, our method aims to directly solve the low recall problem of tree-to-tree pattern matching by introducing the local tree alignment algorithm which is widely used in bioinformatics to analyze RNA secondary structures. Moreover, 169 Proceedings of NAACL HLT 2009: Short Pape"
N09-2043,P03-1044,0,0.0335263,"gorithm, and an effective strategy for controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been propo"
N15-3023,D13-1160,0,0.152649,"d respond to keywords. We use multiple information sources including curated knowledge base, raw text, auto-generated triples, and NL processing results. We develop open semantic answer type detector for answer merging and improve previous developed single QA modules such as knowledge base based QA, information retrieval based QA. 1 Introduction Several massive knowledge bases such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) have been released. To utilize these resources, various approaches to question answering (QA) on linked data have been proposed (He et al., 2014; Berant et al., 2013). QA on linked data or on a knowledge base (KB) can give very high precision, but because KBs consist of fragmentary knowledge with no contextual information and is powered by community effort, they cannot cover all information needs of users. Furthermore, QA systems achieve low precision when disambiguating question sentences in to KB concepts; this flaw reduces QAs’ performance (Yih et al., 2014). A QA system can understand a natural language (NL) question and return the answer. In some ways, perfection of QA systems is the final goal of information retrieval (IR). Early QA systems were IR-b"
N15-3023,D14-1116,0,0.0220864,"(NL) questions and respond to keywords. We use multiple information sources including curated knowledge base, raw text, auto-generated triples, and NL processing results. We develop open semantic answer type detector for answer merging and improve previous developed single QA modules such as knowledge base based QA, information retrieval based QA. 1 Introduction Several massive knowledge bases such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) have been released. To utilize these resources, various approaches to question answering (QA) on linked data have been proposed (He et al., 2014; Berant et al., 2013). QA on linked data or on a knowledge base (KB) can give very high precision, but because KBs consist of fragmentary knowledge with no contextual information and is powered by community effort, they cannot cover all information needs of users. Furthermore, QA systems achieve low precision when disambiguating question sentences in to KB concepts; this flaw reduces QAs’ performance (Yih et al., 2014). A QA system can understand a natural language (NL) question and return the answer. In some ways, perfection of QA systems is the final goal of information retrieval (IR). Earl"
N15-3023,P14-1112,0,0.0339439,"Missing"
N15-3023,C02-1150,0,0.287718,"Missing"
N15-3023,P14-2105,0,0.0242493,"al., 2007) and Freebase (Bollacker et al., 2008) have been released. To utilize these resources, various approaches to question answering (QA) on linked data have been proposed (He et al., 2014; Berant et al., 2013). QA on linked data or on a knowledge base (KB) can give very high precision, but because KBs consist of fragmentary knowledge with no contextual information and is powered by community effort, they cannot cover all information needs of users. Furthermore, QA systems achieve low precision when disambiguating question sentences in to KB concepts; this flaw reduces QAs’ performance (Yih et al., 2014). A QA system can understand a natural language (NL) question and return the answer. In some ways, perfection of QA systems is the final goal of information retrieval (IR). Early QA systems were IR-based QAs (IRQAs). However, as large KBs such as DBpedia and Freebase have been constructed, KB-based QA (KBQA) has become increasingly important (Lehmann et al., 2015; Unger et al., 2012). These two kinds of QA systems use heterogeneous data; IRQA systems search raw text, whereas KBQA systems search KB. KBQA systems give accurate answers because they search from KBs curated by humans. However, they"
P03-2031,W98-1118,0,0.015888,"s demonstrates that the suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention. 1 Introduction Current trend in Named Entity Recognition (NER) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of a machine learning system to another domain is much easier than that of a rule-based one. Various supervised learning methods for Named Entity (NE) tasks were successfully applied and have shown reasonably satisfiable performance.((Zhou and Su, 2002)(Borthwick et al., 1998)(Sassano and Utsuro, 2000)) However, most of these systems heavily rely on a tagged corpus for training. For a machine learning approach, a large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate a large training corpus are non-trivial. In this paper, we suggest a method that automatically constructs an NE tagged corpus from the web to be used for learning of NER systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through the sentence separation"
P03-2031,J02-1004,1,0.863126,"cially, bi-gram matching. This leads us to refine the sentences to exclude these erroneous matches. Sentence refinement is accomplished by three different processes: separation of functional words, segmentation of compound nouns, and verification of the usefulness of the extracted sentences. An NE is often concatenated with more than one josa, a Korean functional word, to compose a Korean word. Therefore we need to separate the functional words from an NE instance to detect the boundary of the NE instance and this is achieved by a part-of-speech tagger, POSTAG, which can detect unknown words (Lee et al., 2002). The separation of functional words gives us another benefit that we can resolve the ambiguities between an NE and a common noun plus functional words 1 We used Empas (http://www.empas.com) Training Test Automatic Manual Manual Person 29,042 1,014 102 Location 37,480 724 72 Organization 2,271 1,338 193 Training corpus Seeds only Manual Automatic Manual + Automatic Precision 84.13 80.21 81.45 82.03 Recall 42.91 86.11 85.41 85.94 F-measure 63.52 83.16 83.43 83.99 Table 1: Corpus description (number of NE’s) (Automatic: Automatically annotated corpus, Manual: Manually annotated corpus Table 2: P"
P03-2031,C00-2102,0,0.0260531,"suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention. 1 Introduction Current trend in Named Entity Recognition (NER) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of a machine learning system to another domain is much easier than that of a rule-based one. Various supervised learning methods for Named Entity (NE) tasks were successfully applied and have shown reasonably satisfiable performance.((Zhou and Su, 2002)(Borthwick et al., 1998)(Sassano and Utsuro, 2000)) However, most of these systems heavily rely on a tagged corpus for training. For a machine learning approach, a large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate a large training corpus are non-trivial. In this paper, we suggest a method that automatically constructs an NE tagged corpus from the web to be used for learning of NER systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through the sentence separation and text refinement proced"
P03-2031,P02-1060,0,0.0258931,"ies. Our experiments demonstrates that the suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention. 1 Introduction Current trend in Named Entity Recognition (NER) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of a machine learning system to another domain is much easier than that of a rule-based one. Various supervised learning methods for Named Entity (NE) tasks were successfully applied and have shown reasonably satisfiable performance.((Zhou and Su, 2002)(Borthwick et al., 1998)(Sassano and Utsuro, 2000)) However, most of these systems heavily rely on a tagged corpus for training. For a machine learning approach, a large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate a large training corpus are non-trivial. In this paper, we suggest a method that automatically constructs an NE tagged corpus from the web to be used for learning of NER systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through"
P06-2054,J02-3001,0,0.236502,"xity in inference/learning time and it is only suitable for representing constraints by enforcing label consistency. We wish to identify ambiguous labels with more general dependency without additional time cost in inference/learning time. Another approach to modeling non-locality is to use observational features which can capture non-local information. Traditionally, many systems prefer to use a syntactic parser. In a language understanding task, the head word dependencies or parse tree path are successfully applied to learn and predict semantic roles, especially those with ambiguous labels (Gildea and Jurafsky, 2002). Although the power of syntactic structure is impressive, using the parser-based feature fails to encode correct global information because of the low accuracy of a modern parser. Furthermore the inaccurate result of parsing is more serious in a spoken language understanding (SLU) task. In contrast to written language, spoken language loses much information including grammar, structure or morphology and contains some errors in automatically recognized speech. To solve the above problems, we present one method to exploit non-local information – the trigger feature. In this paper, we incorporat"
P06-2054,W95-0107,0,0.0149434,"Missing"
P06-2054,N03-1028,0,\N,Missing
P06-2054,P05-1045,0,\N,Missing
P07-2016,P03-1035,0,0.0371138,"Missing"
P07-2016,C96-2136,0,0.0484536,"yap and Oommen, 1984; Mays et al., 1991). But these previous algorithms have a critical limitation: They all corrected word spacing errors and spelling errors separately. Word spacing algorithms define the problem as a task for determining whether to insert the delimiter between characters or not. Since the determination is made according to the characters, the algorithms cannot work if the characters have spelling errors. Likewise, algorithms for solving spelling error problem cannot work well with word spacing errors. To cope with the limitation, there is an algorithm proposed for Japanese (Nagata, 1996). Japanese sentence cannot be divided into words, but into chunks (bunsetsu in Japanese), like Eojeol in Korean. The proposed system is for sentences recognized by OCR, and it uses character transition probabilities and POS (part of speech) tag n-gram. However it needs a word dictionary and takes long time for searching many character combinations. 61 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 61–64, c Prague, June 2007. 2007 Association for Computational Linguistics We propose a new algorithm which can correct both word spacing error and spelling error simultaneously for Kore"
P07-2016,P06-1129,0,\N,Missing
P08-1072,J98-4001,0,0.0327915,"hen, the attributes of each dialog example are examined via the preconditions of each user goal node by breadth-first traversal. If the precondition is true, the node holds relevant that may appear in the user’s goal state. The method of selecting the best of these examples will be described in 5. 4.2 Discourse Interpretation Inspired by Collagen (Rich and Sidner, 1998; Lesh et al., 2001), we investigated a discourse interpretation algorithm to consider how the current user’s goal can contribute to the current agenda in a focus stack according to Lochbaum’s discourse interpretation algorithm (Lochbaum, 1998). The focus stack takes into account the discourse structure by keeping track of discourse states. In our system, the focus stack is a set of user goal nodes which lead to completion of the subtask. The top on the focus stack is the previous node in this set. The focus stack is updated after every utterance. To interpret the type of the discourse state, this breaks down into five main cases of possible current node for an observed user’s goal: 4.1 Mapping Examples to Nodes • NEW TASK: Starting a new task to complete a new agenda (Child of the root). In the agenda graph G, each node v should ho"
P09-2005,N07-1034,0,0.02097,"also personalized in the designed direction. 1 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the framework, diverse type of user knowledge can be easily designed and selectively integrated into data-driven user intention simulation. Introduction User simulation technique"
P09-2005,J08-4002,0,0.019573,"ized in the designed direction. 1 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the framework, diverse type of user knowledge can be easily designed and selectively integrated into data-driven user intention simulation. Introduction User simulation techniques are widely used for lea"
P09-2005,2007.sigdial-1.48,0,0.0314272,"ated users, and it turned out that our approach was successful to generate user intention patterns which are not only unseen in the training corpus and but also personalized in the designed direction. 1 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the framework, diverse type of user"
P09-2021,N04-1028,0,0.026381,"and evaluation of spoken dialog systems (Schatzmann et al., 2006), they have not yet simulated grammar errors because those systems were assumed to be used by native speakers, who normally produce few grammar errors in utterances. However, as telephone-based information access systems become more commonly available to the general public, the inability to deal with non-native speakers is becoming a serious limitation since, at least for some applications, (e.g. tourist information, legal/social advice) non-native speakers represent a significant portion of the everyday user population. Thus, (Raux and Eskenazi, 2004) conducted a study on adaptation of spoken dialog systems to non-native users. In particular, DB-CALL systems should obviously deal with grammar errors because language learners naturally commit numerous grammar errors. Thus grammar error simulation should be embedded in the user simulation for the development and evaluation of such systems. In Foster’s (2007) pioneering work, she described a procedure which automatically introduces frequently occurring grammatical errors into sentences to make ungrammatical training data for a robust parser. However the algorithm cannot be directly applied to"
P09-2021,I05-6009,0,\N,Missing
P09-2071,N03-1028,0,0.132249,"the previous state-of-the-art features we expect the achievement of better accuracy. All our models were trained until parameter estimation converged with a Gaussian prior variance of 4. During training, a pseudo-likelihood parameter estimation (Sutton and McCallum, 2006) was used as an initial weight (estimated in 30 iterations). We used complete and dense input/output joint features for dense model (Dense), and only supported features that are used at least once in the training examples for sparse form better, the sparse model performs well in practice without significant loss of accuracy (Sha and Pereira, 2003). 3 Penn Treebank3: Catalog No. LDC99T42 4 http://www.cnts.ua.ac.be/conll2000/chunking/ 5 http://www.cnts.ua.ac.be/conll2003/ner/ 6 http://archive.ics.uci.edu/ml/ 7 8 283 Ver. 2.0 RC3, http://mallet.cs.umass.edu/ Ver. 0.51, http://crfpp.sourceforge.net/ 10000 20000 30000 40000 0 500 1500 −2000 −6000 Log−likelihood 0 500 1000 1500 (d) NetTalk (e) Communicator (f) Encyclopedia 5000 0 1000 Training time (sec) 3000 5000 Training time (sec) −20000 Log−likelihood Sparse Method 1 Method 2 Method 3 Method 4 −30000 −5500 Log−likelihood −7500 3000 −6500 −39000 1000 Dense Sparse Method 1 Method 2 Method"
P09-2071,P06-2054,1,\N,Missing
P12-2010,H05-1091,0,0.336922,"annotation effort, we can exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training sa"
P12-2010,P07-1073,0,0.0366463,"med by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the direct projection (Kim et al., 2010) and graph-based projection approach. Table 1 shows the performances of the relation extraction of the two systems. The graph-based system achieved better performances in precision and recall than the 3 http://code.google.com/p/giza-pp/ http://code.google.com/p/junto/ 5 http://svmlight.joachims.org/ 6 http://disi."
P12-2010,P06-1017,0,0.0152805,", 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010)"
P12-2010,P11-1061,0,0.0370481,"pproach is still vulnerable to erroneous inputs generated by submodules. We note two main causes for this limitation: (1) the direct projection approach considers only alignments between entity candidates, and it does not consider any contextual information; and, (2) it is performed by a single pass process. To solve both of these problems at once, we propose a graph-based projection approach for relation extraction. 3 Graph Construction The most crucial factor in the success of graphbased learning approaches is how to construct a graph that is appropriate for the target task. Das and Petrov (Das and Petrov, 2011) proposed a graphbased bilingual projection of part-of-speech tagging by considering the tagged words in the source language as labeled examples and connecting them to the unlabeled words in the target language, while referring to the word alignments. Graph construction for projecting semantic relationships is more complicated than part-of-speech tagging because the unit instance of projection is a pair of entities and not a word or morpheme that is equivalent to the alignment unit. 3.1 Graph Vertices To construct a graph for a relation projection, we define two types of vertices: instance ver"
P12-2010,doddington-etal-2004-automatic,0,0.0555715,"parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation"
P12-2010,D11-1142,0,0.0299455,"of iterations exceeds a specific number. The Y matrix, after finishing its iterations, is considered to be the result of the algorithm. 5 Implementation To demonstrate the effectiveness of the graph-based projection approach for relation extraction, we developed a Korean relation extraction system that was trained with projected annotations from English resources. We used an English-Korean parallel corpus 1 that contains 266,892 bi-sentence pairs in English and Korean. We obtained 155,409 positive instances from the English sentences using an off-theshelf relation extraction system, ReVerb 2 (Fader et al., 2011). 1 The parallel corpus collected is available in our website: http://isoft.postech.ac.kr/˜megaup/acl/datasets 2 http://reverb.cs.washington.edu/ Table 1: Comparison between direct and graph-based projection approaches to extract semantic relationships for four relation types Type Acquisition Birthplace Inventor Of Won Prize Total P 51.6 69.8 62.4 73.3 63.9 Direct R 87.7 84.5 85.3 80.5 84.2 F 64.9 76.4 72.1 76.7 72.7 Graph-based P R F 55.3 91.2 68.9 73.8 87.3 80.0 66.3 89.7 76.3 76.4 82.9 79.5 67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the"
P12-2010,C96-1079,0,0.226739,"jected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et"
P12-2010,C10-1064,1,0.92265,"hen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010). To obtain training examples in the resource-poor target language, this approach exploited a cross-lingual annotation projection by propagating annotations that were generated by a relation extraction system in a resourcerich source language. In this approach, projected annotations were determined in a single pass process by considering only alignments between entity candidates; we call this action direct projection. In this paper, we propose a graph-based projection approach for weakly supervised relation extraction. This approach utilizes a graph that is constucted with both instance and co"
P12-2010,E06-1015,0,0.0209852,"67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the corresponding Korean sentences. We used the GIZA++ software 3 (Och and Ney, 2003) to obtain the word alignments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the direct projection (Kim et al., 2010) and graph"
P12-2010,J03-1002,0,0.00330498,"http://isoft.postech.ac.kr/˜megaup/acl/datasets 2 http://reverb.cs.washington.edu/ Table 1: Comparison between direct and graph-based projection approaches to extract semantic relationships for four relation types Type Acquisition Birthplace Inventor Of Won Prize Total P 51.6 69.8 62.4 73.3 63.9 Direct R 87.7 84.5 85.3 80.5 84.2 F 64.9 76.4 72.1 76.7 72.7 Graph-based P R F 55.3 91.2 68.9 73.8 87.3 80.0 66.3 89.7 76.3 76.4 82.9 79.5 67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the corresponding Korean sentences. We used the GIZA++ software 3 (Och and Ney, 2003) to obtain the word alignments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on"
P12-2010,P10-1013,0,0.158092,"nguages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010). To obtain training examples in the resource-poor target language, this approach exploited a cross-lingual annotation projection by propagating annotations that were generated by a relation extraction system in a resourcerich source language. In this approach, projected annotations were determined in a single pass process by considering only alignm"
P12-2010,N01-1026,0,0.283306,"annotated text for ft , utilizing a well-made extractor fs for a resource-rich source language Ls and a parallel corpus of Ls and Lt . Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance hBarack Obama, Honolului is extracted as positive. Then, its translational counterpart hbeo-rak-o-ba-ma, ho-nol-rul-rui in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strat  j i egy can be formularized as follows: ft et , et =   fs A(eit ), A(ejt ) , where A(et ) is the aligned entity 49 of et . However, these automatic annotations can be unreliable because of source text mis-classification and"
P12-2010,H01-1035,0,0.161222,"tilizing a well-made extractor fs for a resource-rich source language Ls and a parallel corpus of Ls and Lt . Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance hBarack Obama, Honolului is extracted as positive. Then, its translational counterpart hbeo-rak-o-ba-ma, ho-nol-rul-rui in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strat  j i egy can be formularized as follows: ft et , et =   fs A(eit ), A(ejt ) , where A(et ) is the aligned entity 49 of et . However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors;"
P12-2010,P06-1104,0,0.0594645,"exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning ne"
P12-2010,D08-1063,0,0.0266088,"esource-rich source language Ls and a parallel corpus of Ls and Lt . Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance hBarack Obama, Honolului is extracted as positive. Then, its translational counterpart hbeo-rak-o-ba-ma, ho-nol-rul-rui in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strat  j i egy can be formularized as follows: ft et , et =   fs A(eit ), A(ejt ) , where A(et ) is the aligned entity 49 of et . However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors; thus, it can cause a critical falling-off in"
P12-2064,P11-1092,0,0.242977,"article given the surrounding context. Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods (Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008). Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (Han et al., 2010; Rozovskaya and Roth, 2010). Since the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng (2011) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone. However, methods which train a GEC model from various GE tagged corpora have received less focus. In this paper, we present a novel approach to the GEC task using meta-learning. We focus mainly on article errors for two reasons. First, articles are one of the most significant sources of GE for the learners with various L1 backgrounds. Second, the effective features for article error correction are already well engineered allo"
P12-2064,han-etal-2010-using,0,0.0241929,"e corpora rather than GE tagged learner corpora for the GEC task. The native corpus approach consists of learning a model that predicts the correct form of an article given the surrounding context. Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods (Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008). Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (Han et al., 2010; Rozovskaya and Roth, 2010). Since the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng (2011) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone. However, methods which train a GEC model from various GE tagged corpora have received less focus. In this paper, we present a novel approach to the GEC task using meta-learning. We focus mainly on article errors for two reasons. First, articles are one of the most"
P12-2064,P03-1054,0,0.00493811,"ems which are closely related to the main problems. A word selection problem is a task to predict the appropriate word given the surrounding context in a native corpus and is a closely related auxiliary problem of the GEC task. We can obtain the common structure from the article selection problem and use it for the correction problem. In this work, all the base classifiers used the same least squares loss function for structural learning. We adopted the feature set investigated in De Felice (2008) for article error correction. We use the Stanford coreNLP toolkit1 (Toutanova and Manning, 2000; Klein and Manning, 2003a; Klein and Manning, 2003b; Finkel et al, 2005) to extract the features. 2.3. Evaluation Metric The effectiveness of the proposed method is evaluated in terms of accuracy, precision, recall, and F1-score (Dahlmeire and Ng, 2011). Accuracy is the number of correct predictions divided by the total number of instances. Precision is the ratio of the suggested corrections that agree with the tagged answer to the total number of the suggested corrections whereas recall is the ratio of the suggested corrections that agree with the tagged answer to the total number of corrections in the corpus. 3. Ex"
P12-2064,N04-2006,0,0.0268014,"ora are mostly small datasets having different characteristics depending on the development methods, e.g. spoken corpus vs. written corpus. This situation forced researchers to utilize native corpora rather than GE tagged learner corpora for the GEC task. The native corpus approach consists of learning a model that predicts the correct form of an article given the surrounding context. Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods (Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008). Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (Han et al., 2010; Rozovskaya and Roth, 2010). Since the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng (2011) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone. However, methods which train a GEC model from various GE tagged cor"
P12-2064,P06-1031,0,0.0568244,"tly small datasets having different characteristics depending on the development methods, e.g. spoken corpus vs. written corpus. This situation forced researchers to utilize native corpora rather than GE tagged learner corpora for the GEC task. The native corpus approach consists of learning a model that predicts the correct form of an article given the surrounding context. Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods (Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008). Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (Han et al., 2010; Rozovskaya and Roth, 2010). Since the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng (2011) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone. However, methods which train a GEC model from various GE tagged corpora have received le"
P12-2064,W00-0708,0,0.0590316,"ilable GE tagged corpora are mostly small datasets having different characteristics depending on the development methods, e.g. spoken corpus vs. written corpus. This situation forced researchers to utilize native corpora rather than GE tagged learner corpora for the GEC task. The native corpus approach consists of learning a model that predicts the correct form of an article given the surrounding context. Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods (Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008). Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (Han et al., 2010; Rozovskaya and Roth, 2010). Since the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng (2011) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone. However, methods which train a GEC model from various GE"
P12-2064,I05-6009,0,0.156184,"Missing"
P12-2064,N10-1018,0,0.0629381,"han GE tagged learner corpora for the GEC task. The native corpus approach consists of learning a model that predicts the correct form of an article given the surrounding context. Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods (Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008). Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (Han et al., 2010; Rozovskaya and Roth, 2010). Since the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng (2011) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone. However, methods which train a GEC model from various GE tagged corpora have received less focus. In this paper, we present a novel approach to the GEC task using meta-learning. We focus mainly on article errors for two reasons. First, articles are one of the most significant sources of GE f"
P12-2064,W00-1308,0,0.0768933,"obtained from auxiliary problems which are closely related to the main problems. A word selection problem is a task to predict the appropriate word given the surrounding context in a native corpus and is a closely related auxiliary problem of the GEC task. We can obtain the common structure from the article selection problem and use it for the correction problem. In this work, all the base classifiers used the same least squares loss function for structural learning. We adopted the feature set investigated in De Felice (2008) for article error correction. We use the Stanford coreNLP toolkit1 (Toutanova and Manning, 2000; Klein and Manning, 2003a; Klein and Manning, 2003b; Finkel et al, 2005) to extract the features. 2.3. Evaluation Metric The effectiveness of the proposed method is evaluated in terms of accuracy, precision, recall, and F1-score (Dahlmeire and Ng, 2011). Accuracy is the number of correct predictions divided by the total number of instances. Precision is the ratio of the suggested corrections that agree with the tagged answer to the total number of the suggested corrections whereas recall is the ratio of the suggested corrections that agree with the tagged answer to the total number of correct"
P12-2064,P11-1019,0,0.140915,"Missing"
P12-2064,P05-1045,0,\N,Missing
seo-etal-2012-grammatical,P98-2196,0,\N,Missing
seo-etal-2012-grammatical,C98-2191,0,\N,Missing
seo-etal-2012-grammatical,izumi-etal-2004-overview,0,\N,Missing
W01-1202,P00-1070,0,0.114811,"On retrieval time, it just calculates the similarities between a user’s query and the candidates. As a result, it can minimize the retrieval time. This paper is organized as follows. In Section 2, we review the previous works of the QA systems. In Section 3, we describe the applied NLP techniques, and present our system. In Section 4, we analyze the result of our experiments. Finally, we draw conclusions in Section 5.  2 Previous Works The current QA approaches can be classified into two groups; text-snippet extraction systems and noun-phrase extraction systems (also called closed-class QA) (Vicedo and Ferrándex, 2000). The text-snippet extraction approaches are based on locating and extracting the most relevant sentences or paragraphs to the query by assuming that this text will probably contain the correct answer to the query. These approaches have been the most commonly used by participants in last TREC QA Track (Ferret et al., 1999; Hull, 1999; Moldovan et al., 1999; Prager et al., 1999; Srihari and Li, 1999). ExtrAns (Berri et al., 1998) is a representative QA system in the text-snippet extraction approaches. The system locates the phrases in a document from which a user can infer an answer. However, i"
W02-1902,J82-2002,0,0.452217,"nguage Interface to DataBases). Gary Geunbae Lee Department of Computer Science and Engineering Pohang University of Science and Technology San 31, Hyoja-dong, Nam-gu, Pohang, Kyungbuk, Korea (790-784) Telephone: +82-54-279-5581 gblee@postech.ac.kr formal query language interface directly using SQL, a form-based interface with fields to input query patterns, and a graphical interface using a keyboard and a mouse to access tables. The NL interface does not require the learning of formal query languages, and it easily represents negation and quantification [4], and provides discourse processing [8]. The use of natural language has both advantages and disadvantages. Including general NLP problems such as quantifier scoping, PP attachment, anaphora resolution, and elliptical questions, current NLIDB has many shortcomings [1]: First, as a frequent complaint, it is difficult for users to understand which kinds of questions are actually allowed or not. Second, the user assumes that the system is intelligent; he or she thinks NLIDB has common sense, and can deduce facts. Finally, users do not know whether a failure is caused by linguistic coverage or by conceptual mismatch. Nevertheless, natu"
W02-1902,W01-1202,1,0.87097,"tedious to devise, which drops the portability of languages and domains. front-end (LFE), and the other processes as the database back-end (DBE). This architecture has the merits that LFE is DBMS-independent and an inference module can be placed between LFE and DBE. However, the limitation of parsing and semantic analysis requires semantic post-processing. Nevertheless, it is difficult to achieve high quality analysis for database applications. On the contrary, we apply linguistic processing based on lexico-semantic patterns (LSP), a prominent method verified in text-based question answering [10] [12], into NLIDB, and propose multi-level grammars to represent query structures and to translate into SQL queries. Our system is a hybridization of the pattern matching system and the intermediate representation language system. However, our LSP-based pattern covers lexical to semantic matching, and the multi-level grammars for intermediate representation evidently separate the database back-end from the linguistic front-end. Thus, our method has the ability to divide LFE and DBE, but promises greater adaptability due to the hybrid linguistic analysis and the pattern-matching characteristics"
W02-1902,E95-1027,0,0.0180273,"]. They are useful to rapidly develop parsers in limited domains, but are not ported well to new domains due to hard-wired and domain-dependent semantic information [18]. 1 LSP-based Linguistic Multi-level Grammars Intermediate representation language systems: Most current systems place an intermediate logical query between NL question and SQL [5]. The processes before the intermediate query are defined as the linguistic A lexico-semantic pattern (LSP) is the structure where linguistic entries and semantic types can be used in combinations to abstract certain sequences of words in a text [12] [15]. Linguistic entries consist of words, phrases and Processing and part-of-speech tags, such as “television,” “3D Surround,” and “NP2.” Semantic types consist of attribute names, semantic tags (categories) 3 and user-defined semantic classes 4 , such as “@model,” “@person,” and “%each.” LSP-based language processing simplifies the natural language interface due to the following characteristics: First, linguistic elements from lexicons to semantic categories offer flexibility in representing natural language. Second, simple LSP matching without fragile high-level analyses assures a robust lingui"
W02-1902,A83-1002,0,0.235861,"into two tight corners, i.e., the language-dependent part into front linguistic analysis, and the domain-dependent and database-dependent parts into backend SQL query generation. In our LSP description, attribute vocabularies are also represented as semantic classes that represent semantic meaning of words. Thus, the domain-dependent attributes and values are automatically extracted from databases, and get registered in a semantic category dictionary. Semantic grammar systems: The systems adopt techniques interleaving syntactic and semantic processing, and generate SQL queries from the result [19] [21]. They are useful to rapidly develop parsers in limited domains, but are not ported well to new domains due to hard-wired and domain-dependent semantic information [18]. 1 LSP-based Linguistic Multi-level Grammars Intermediate representation language systems: Most current systems place an intermediate logical query between NL question and SQL [5]. The processes before the intermediate query are defined as the linguistic A lexico-semantic pattern (LSP) is the structure where linguistic entries and semantic types can be used in combinations to abstract certain sequences of words in a text ["
W02-1902,P01-1037,0,\N,Missing
W02-1902,J82-3002,0,\N,Missing
W04-1220,W03-1309,0,0.0227132,"Missing"
W04-1220,W03-1305,0,\N,Missing
W04-1220,W03-1027,0,\N,Missing
W04-3009,P96-1009,0,0.199961,"on of the errors in speech recognition. They simplified a statistical machine translation (MT) model called an IBM model (Brown et al., 1990), and tried to construct a general post-processor that can correct errors generated by any speech recognizer. The model consists of two parts: a channel model, which accounts for errors made by the ASR, and the language model, which accounts for the likelihood of a sequence of words being uttered. They trained the channel model and the language model both using some transcriptions from TRAINS-95 dialogue system which is a train traveling planning system (Allen et al., 1996). Here, the channel model has the distribution that an original word may be recognized as an erroneous word. They use the probability of mistakenly recognized words, the co-occurrence information extracted from the words and their neighboring words, and the tagged word bi-grams, which are all lexical clues in error strings. Such approaches based on lexical information of words have shown some successful results, but they still have major drawbacks; The performance of such systems depends on the size and the quality of speech recognition result, or on the database of collected error strings sin"
W04-3009,P00-1037,0,0.0218901,"for ASR error correction and discuss some problems with them. We then introduce our improved channel model especially for Korean language in section 3. We also propose a new high-level error correction model using syntactic and semantic knowledge in section 4. We prove the feasibility of our approach through some experiments in section 5, and draw some conclusions in section 6. 2 Noisy Channel Error Correction Model The noisy channel error correction framework has been applied to a wide range of problems, such as spelling correction, statistical machine translation, and ASR error correction (Brill and Moore, 2000; Brown et al., 1990; Ringger and Allen, 1996). The key idea of noisy channel model is that we can model some channel properties through estimating the posterior probabilities. The problem of ASR error correction can be stated in this model as follows: For an input sentence, O = o1 , o2 , . . . , on produced as the output sequence of ASR, ˆ = w1 , w2 , . . . , wn , that find the best word sequence, W maximizes the posterior probability P (W |O). Then, applying Bayes’ rule and dropping the constant denominator, we can rewrite as: ˆ = arg max P (W |O) = arg max P (W )P (O|W ) (1) W W W Now, we h"
W04-3009,W02-1025,0,0.0659856,"Missing"
W04-3009,P98-1107,0,0.34094,"tion techniques to improve the recognition accuracy, and the primary advanFigure 1: Adaptation via Post Error Correction tage of the error correction approach is its independence of the specific speech recognizer. If the speech recognizer can be regarded as a black-box, we can perform robust and flexible domain adaptation through the post error correction process. Figure 1 shows the paradigm of this post error correction approach. One approach in post error correction, which is a straightforward and intuitive method to robustly handle many kinds of recognition errors, was rule-based approach (Kaki et al., 1998). (Kaki et al., 1998) collected many lexical error patterns that occurred in a speech translation system in Japanese. They could correct any type of errors by matching the strings in the transcription with lexical error patterns in the database. However, their approach has a disadvantage in that the correction is only feasible to the trained (or collected) lexical error patterns. Another approach has been based on a statistical method utilizing the probabilistic information of words in a spoken dialogue situation and the language models adapted to the application domain (Ringger and Allen, 199"
W04-3009,W01-1202,1,0.82396,"i search algorithm to find the best tion to abstract certain sequences of the words in a text. sequence. For implementation of candidate generation, It has been used in the area of natural language interface we store the syllable channel probabilities P (si |xi ) as a for database (NLIDB) (Jung et al., 2003) and a TREC hash-table to pop them easily and fast. The system can QA system for the purpose of matching the user query generate a candidate word sequence network using sylla- with the appropriate answer types at syntax/semantic ble channel model and a lexicon. And then, we can find level (Kim et al., 2001; Lee et al., 2001). In an LSP, optimal sequence which has the best probability through linguistic entries consist of words, phrases and part-ofspeech (POS) tags, such as ‘YMCA,’ ‘Young Men’s Viterbi decoding by including a language model. Christian Association,’ and ‘NNP.’3 Semantic types con2 We omitted detail character-level match lines to simplify. The whole word match is depicted in bold lines, while no-line means character-level match errors. 3 Part-of-speech tag denoting a proper noun which is used in Penn TreeBank (Marcus et al., 1994). Phrases Reading trainer Fairy tale trainer Recrea"
W04-3009,J93-2004,0,\N,Missing
W04-3009,C02-1169,0,\N,Missing
W04-3009,J90-2002,0,\N,Missing
W04-3009,J02-1004,1,\N,Missing
W04-3009,P97-1064,0,\N,Missing
W04-3009,P03-2031,1,\N,Missing
W04-3009,C98-1103,0,\N,Missing
W08-0120,N04-1006,0,\N,Missing
W08-1503,P04-1009,0,0.162281,"chine dialog is heavily influenced by speech recognition errors. Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2"
W08-1503,2007.sigdial-1.48,0,0.0745802,"ndent techniques for simulating both intentions and utterances are needed, and ASR channel simulation is desirable for evaluating the spoken dialog systems accurately because human-machine dialog is heavily influenced by speech recognition errors. Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: us"
W08-1503,W08-0120,1,0.880417,"Missing"
W08-1503,2005.sigdial-1.6,0,0.0293186,"omain and language independent techniques for simulating both intentions and utterances are needed, and ASR channel simulation is desirable for evaluating the spoken dialog systems accurately because human-machine dialog is heavily influenced by speech recognition errors. Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divi"
W11-2043,P09-2021,1,0.813067,"Missing"
W14-1709,P06-1032,0,0.0379128,"is used mainly as the correction resource. Correction candidates are extracted from NUCLE training data and each candidate is evaluated with development data to extract high precision rules and n-gram frames. Out of 13 participating teams, our system is ranked 4th on both the original and revised annotation. 1 Introduction Automatic grammar error correction (GEC) is widely used by learners of English as a second language (ESL) in written tasks. Many methods have been proposed to correct grammatical errors; these include methods based on rules (Naber, 2003), on statistical machine translation (Brockett et al., 2006), on machine learning, and on n-grams (Alam et al., 2006). Early research (Han et al., 2006; De Felice, 2008; Knight & Chander, 1994; Nagata et al., 2006) on error correction for nonnative text was based on well-formed corpora. Most recent work (Cahill et al., 2013; Rozovskaya & Roth, 2011; Wu & Ng, 2013) has used machine learning methods that rely on a GEtagged corpus such as NUCLE, Japanese English Learner corpus, and Cambridge Learner Corpus (Dahlmeier et al., 2013; Izumi et al., 2005; Nicholls, 2003), because well-formed and GEtagged approaches are closely related to each other, can be syn"
W14-1709,N13-1055,0,0.0216157,"both the original and revised annotation. 1 Introduction Automatic grammar error correction (GEC) is widely used by learners of English as a second language (ESL) in written tasks. Many methods have been proposed to correct grammatical errors; these include methods based on rules (Naber, 2003), on statistical machine translation (Brockett et al., 2006), on machine learning, and on n-grams (Alam et al., 2006). Early research (Han et al., 2006; De Felice, 2008; Knight & Chander, 1994; Nagata et al., 2006) on error correction for nonnative text was based on well-formed corpora. Most recent work (Cahill et al., 2013; Rozovskaya & Roth, 2011; Wu & Ng, 2013) has used machine learning methods that rely on a GEtagged corpus such as NUCLE, Japanese English Learner corpus, and Cambridge Learner Corpus (Dahlmeier et al., 2013; Izumi et al., 2005; Nicholls, 2003), because well-formed and GEtagged approaches are closely related to each other, can be synergistically combined. Therefore, 65 Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 65–73, c Baltimore, Maryland, 26-27 July 2014. 2014 Association for Computational Linguistics Figure 1. Overall Process of R"
W14-1709,W13-1703,0,0.0234963,"proposed to correct grammatical errors; these include methods based on rules (Naber, 2003), on statistical machine translation (Brockett et al., 2006), on machine learning, and on n-grams (Alam et al., 2006). Early research (Han et al., 2006; De Felice, 2008; Knight & Chander, 1994; Nagata et al., 2006) on error correction for nonnative text was based on well-formed corpora. Most recent work (Cahill et al., 2013; Rozovskaya & Roth, 2011; Wu & Ng, 2013) has used machine learning methods that rely on a GEtagged corpus such as NUCLE, Japanese English Learner corpus, and Cambridge Learner Corpus (Dahlmeier et al., 2013; Izumi et al., 2005; Nicholls, 2003), because well-formed and GEtagged approaches are closely related to each other, can be synergistically combined. Therefore, 65 Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 65–73, c Baltimore, Maryland, 26-27 July 2014. 2014 Association for Computational Linguistics Figure 1. Overall Process of Router-based Correction Correction (Deletion Correction → Insertion Correction → Replacement) for various error types → Rule-based method for verb errors. Between each pair of step, we parse, tag, and tokeniz"
W14-1709,hermet-etal-2008-using,0,0.285692,"Missing"
W14-1709,I05-6009,0,0.0329404,"matical errors; these include methods based on rules (Naber, 2003), on statistical machine translation (Brockett et al., 2006), on machine learning, and on n-grams (Alam et al., 2006). Early research (Han et al., 2006; De Felice, 2008; Knight & Chander, 1994; Nagata et al., 2006) on error correction for nonnative text was based on well-formed corpora. Most recent work (Cahill et al., 2013; Rozovskaya & Roth, 2011; Wu & Ng, 2013) has used machine learning methods that rely on a GEtagged corpus such as NUCLE, Japanese English Learner corpus, and Cambridge Learner Corpus (Dahlmeier et al., 2013; Izumi et al., 2005; Nicholls, 2003), because well-formed and GEtagged approaches are closely related to each other, can be synergistically combined. Therefore, 65 Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 65–73, c Baltimore, Maryland, 26-27 July 2014. 2014 Association for Computational Linguistics Figure 1. Overall Process of Router-based Correction Correction (Deletion Correction → Insertion Correction → Replacement) for various error types → Rule-based method for verb errors. Between each pair of step, we parse, tag, and tokenize again using the St"
W14-1709,P11-1093,0,0.0192109,"revised annotation. 1 Introduction Automatic grammar error correction (GEC) is widely used by learners of English as a second language (ESL) in written tasks. Many methods have been proposed to correct grammatical errors; these include methods based on rules (Naber, 2003), on statistical machine translation (Brockett et al., 2006), on machine learning, and on n-grams (Alam et al., 2006). Early research (Han et al., 2006; De Felice, 2008; Knight & Chander, 1994; Nagata et al., 2006) on error correction for nonnative text was based on well-formed corpora. Most recent work (Cahill et al., 2013; Rozovskaya & Roth, 2011; Wu & Ng, 2013) has used machine learning methods that rely on a GEtagged corpus such as NUCLE, Japanese English Learner corpus, and Cambridge Learner Corpus (Dahlmeier et al., 2013; Izumi et al., 2005; Nicholls, 2003), because well-formed and GEtagged approaches are closely related to each other, can be synergistically combined. Therefore, 65 Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 65–73, c Baltimore, Maryland, 26-27 July 2014. 2014 Association for Computational Linguistics Figure 1. Overall Process of Router-based Correction Co"
W14-1709,P12-2064,1,0.886734,"Missing"
W14-1709,P13-1143,0,0.0197755,"troduction Automatic grammar error correction (GEC) is widely used by learners of English as a second language (ESL) in written tasks. Many methods have been proposed to correct grammatical errors; these include methods based on rules (Naber, 2003), on statistical machine translation (Brockett et al., 2006), on machine learning, and on n-grams (Alam et al., 2006). Early research (Han et al., 2006; De Felice, 2008; Knight & Chander, 1994; Nagata et al., 2006) on error correction for nonnative text was based on well-formed corpora. Most recent work (Cahill et al., 2013; Rozovskaya & Roth, 2011; Wu & Ng, 2013) has used machine learning methods that rely on a GEtagged corpus such as NUCLE, Japanese English Learner corpus, and Cambridge Learner Corpus (Dahlmeier et al., 2013; Izumi et al., 2005; Nicholls, 2003), because well-formed and GEtagged approaches are closely related to each other, can be synergistically combined. Therefore, 65 Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 65–73, c Baltimore, Maryland, 26-27 July 2014. 2014 Association for Computational Linguistics Figure 1. Overall Process of Router-based Correction Correction (Deleti"
W14-1709,P11-1019,0,0.162024,"Missing"
W14-1709,W08-1301,0,\N,Missing
W14-1709,W14-1701,0,\N,Missing
W14-1709,P11-1092,0,\N,Missing
W14-1709,P06-1031,0,\N,Missing
W14-1709,N12-1067,0,\N,Missing
W14-1709,W13-3602,0,\N,Missing
W14-1709,W13-3603,0,\N,Missing
W15-4616,W13-4054,1,0.465839,"cally to the utterances. Listening agents should generate various responses to encourage the user to continue the dialog. If responses are monotonous, a dialog can be boring, and a user may lose interest in talking to the system. In previous work, listening agents 2 Related Work 2.1 Listening Agent Two main types of listening agents have been developed: non-verbal agents and verbal agents. Non-verbal listening agents generate multimodal responses from multimodal user input (Schroder et al., 2012). Verbal listening agents get text input from user and generate a text response (Weizenbaum, 1966; Han et al., 2013; Han et al., 2015). Our study focused on a verbal listening agent. 2.2 ELIZA & Counseling Dialog System ELIZA (Weizenbaum, 1966) is a natural language conversation program that interacts with 129 Proceedings of the SIGDIAL 2015 Conference, pages 129–133, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics a speaker as a psychoterapist would. The system models person-centered therapy, a counseling technique based on the reflective listening strategy (Rautalinko and Lisper, 2004), which aims to encourage a user to continue talking. It includes encouragem"
W15-4616,W09-3917,0,0.0482938,"Missing"
W15-4618,N04-3002,0,0.0599174,"al contents. The proposed system not only converses with a user but also answer questions that the user asked or asks some educational questions by integrating a dialog system with a knowledge base. We used the Wikipedia corpus to learn the weights between two entities and embedding of properties to calculate similarities for the selection of system questions and answers. 1 Introduction Dialog is the most natural interaction between a mentor and mentee in the real world. Therefore, dialog-based intelligent tutoring systems (ITSs) have been widely studied to teach science (Jordan et al., 2013; Litman and Silliman, 2004; Graesser et al., 2004; VanLehn et al., 2002; Vanlehn et al., 2005), foreign language (Kyusong et al., 2014;Lee et al., 2010; Lee et al., 2011;Johnson et al., 2007), and programming language (Fossati et al., 2008; Lane and VanLehn, 2015) usually without intervention from a human teacher. However, previous dialog-based language learning systems mostly only play the role of a conversational partner using chatting like spoken dialog technology, and providing feedback such as grammatical error correction and suggesting better expressions. However, in real situations, students usually ask many que"
W15-4618,P14-1133,0,0.116121,"POSTECH Immersive English Study (POMY). The program allows users to exercise their visual, aural and tactile senses to receive a full immersion experience to develop into independent EFL learners and to increase their memory and concentration abilities to the greatest extent (Kyusong Lee et al., 2014). During field tests, we found that many advanced students asked questions that cannot be answered using only a dialog system1. Recently, knowledge base (KB) data such as freebase and DBpedia have become publicly available. Using the KB, knowledge base question answering (KB-QA) has been studied (Berant and Liang, 2014); it has advantages of very high precision because it exploits huge databases. Hence, we proposed a dialogbased intelligent tutoring system that uses a KB, as an extension of POMY, POMY Intelligent Tutoring System (POMY-ITS). The main advantage is that the human cost to manually construct educational contents is eliminated. Moreover, the system chooses its response after considering information importance, current discourse, relative weights between two entities, and property similarity. The additional functions of the POMY-ITS are that it: 1) Answers user’s question such as factoid questions,"
