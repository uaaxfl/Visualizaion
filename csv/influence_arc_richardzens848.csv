2004.iwslt-evaluation.13,J90-2002,0,0.494047,"Missing"
2004.iwslt-evaluation.13,W99-0604,1,0.657673,"Missing"
2004.iwslt-evaluation.13,E99-1010,0,0.0439985,"Missing"
2004.iwslt-evaluation.13,W02-1021,1,0.117557,"Missing"
2004.iwslt-evaluation.13,N04-1021,0,0.0547991,"Missing"
2004.iwslt-evaluation.13,C04-1030,1,0.594268,"Missing"
2004.iwslt-evaluation.13,J97-3002,0,0.0526216,"Missing"
2004.iwslt-evaluation.13,takezawa-etal-2002-toward,0,0.0402389,"Missing"
2004.iwslt-evaluation.13,2003.mtsummit-papers.51,0,0.0619504,"Missing"
2004.iwslt-evaluation.13,P02-1040,0,\N,Missing
2004.iwslt-evaluation.13,P02-1038,1,\N,Missing
2004.iwslt-evaluation.13,P03-1021,0,\N,Missing
2004.iwslt-papers.7,J90-2002,0,0.250978,"some of the presented techniques. 2. Statistical Machine Translation 2.1. Word Alignment In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we choose the sentence with the highest probability:  eˆI1 = argmax P r(eI1 |f1J ) (1) eI1 = argmax eI1  P r(eI1 ) · P r(f1J |eI1 ) (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [3]. It allows an independent modeling of the target language model P r(eI1 ) and translation model P r(f1J |eI1 ). The target language model describes the wellformedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The word alignment A is introduced into the translation model as a hidden variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to"
2004.iwslt-papers.7,J93-2003,0,0.0389305,"ment A is introduced into the translation model as a hidden variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted"
2004.iwslt-papers.7,C96-2141,1,0.642373,"den variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The a"
2004.iwslt-papers.7,J03-1002,1,0.143593,"f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The alignment templates a"
2004.iwslt-papers.7,P02-1038,1,0.627781,"word penalty and alignment template penalty feature functions. To model the alignment template reorderings, we use a feature function that penalizes reorderings linear in the jump width. We use a dynamic programming beam search algorithm to generate the translation hypothesis with maximum probability. This search algorithm allows for arbitrary reorderings at the level of alignment templates. Within the alignment templates, the word order is learned in training and kept fix during the search process. This is only a brief description of the alignment template approach. For further details, see [9, 7]. 3. Acquiring Additional Training Data 2.2. Translation: Alignment Template Approach The argmax operation in Eq. 2 denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. For the search, we choose an alternative to the classical source-channel approach and model the posterior probability P r(eI1 |f1J ) directly. Using a log-linear model [7], we obtain: ! M X I J J I J P r(e1 |f1 ) = Z(f1 ) · exp λm hm (e1 , f1 ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant, hm are the fe"
2004.iwslt-papers.7,P03-1021,0,0.0274503,"h and model the posterior probability P r(eI1 |f1J ) directly. Using a log-linear model [7], we obtain: ! M X I J J I J P r(e1 |f1 ) = Z(f1 ) · exp λm hm (e1 , f1 ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant, hm are the feature functions and λm are the corresponding scaling factors. We thus arrive at the decision rule: ( M ) X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 to the maximum entropy principle, e.g. using the Generalized Iterative Scaling (GIS) algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion [8]. m=1 This approach has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according 140 When only a small corpus of sentence pairs is available for training of the statistical translation models, it may be reasonable to include additional bilingual training data from other sources. Since this additional data may come from another domain and substantially differ from the original training corpus, a method for selecting relevant sentences is desirable. In our experiments, we use a relevance measu"
2004.iwslt-papers.7,W99-0604,1,0.944144,"...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The alignment templates are build at the level of word classes, which improves their generalization capability. Besides the alignment template translation model probabilities, we use additional feature functions. These are the word translation model and two language models: a"
2004.iwslt-papers.7,2001.mtsummit-papers.68,0,0.0231131,"and substantially differ from the original training corpus, a method for selecting relevant sentences is desirable. In our experiments, we use a relevance measure of ngram coverage. To this end, we compute the set C of ngrams occurring in the source part of the initial training corpus (n = 1, 2, 3, 4). Then, for each candidate source sentence in the additional corpus, we compute a score based on the occurrence of the n-grams from C in that sentence. The score is defined as the geometric mean of n-gram precisions and is therefore similar to the BLEU score used in machine translation evaluation [10]. Such score provides a quantitative measure of how “out-of-domain” or “in-domain” the additional training data may be. We add only those sentence pairs to the initial training corpus, for which this score is sufficiently high. 4. Morphological Information for Word Alignments 4.1. Lexicon Smoothing Existing statistical translation systems usually treat different derivations of the same base form as they were independent of each other. In our approach, the dependencies between such derivations are taken into account during the EM training of the statistical alignment models. Typically, the stat"
2004.iwslt-papers.7,P00-1056,1,0.650352,"word alignment quality on the Verbmobil task. The German– English Verbmobil task [13] is a speech translation task in the domain of appointment scheduling, travel planning and hotel reservation. The corpus statistics are shown in Table 1. The number of running words and the vocabularies are based on full-form words including punctuation marks. As in [6], the first 100 sentences of the alignment test corpus are used as a development corpus to optimize model parameters that are not trained via the EM algorithm, e.g. the smoothing parameters. We use the same evaluation criterion as described in [14]. The generated word alignment is compared to a reference alignment which is produced by human experts. The obtained reference alignment may contain many-to-one and one-to-many relationships and includes sure (S) and possible (P) alignment points. The quality of an alignment A is computed as appropriately redefined precision and recall measures. We also use the alignment error rate (AER), which is derived from the well-known F-measure. |A ∩ S| |A ∩ P | , precision = |S| |A| |A ∩ S |+ |A ∩ P | AER(S, P ; A) = 1 − |A |+ |S| recall = With these definitions a recall error can only occur if a S(ure"
2004.iwslt-papers.7,W01-1407,1,\N,Missing
2004.iwslt-papers.7,P02-1040,0,\N,Missing
2005.eamt-1.37,P91-1022,0,0.147266,"arameters. In practice, many sentences in the training corpora are long. Some translation applications cannot handle a sentence whose length is larger than a predetermined value. The reasons are memory limits and the computational complexity of the algorithms. Therefore, long sentences are usually removed during the preprocessing. But even if long sentences are included, the resulting quality is usually not as good as it is for short sentences. 1.2 Comparison with Sentence Alignment The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on"
2005.eamt-1.37,J93-2003,0,0.0217239,"In statistical machine translation, we are given a source language (‘French’) sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language (‘English’) sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: eˆI1 = argmax eI1 = argmax eI1  P r(eI1 |f1J )    P r(eI1 ) · P r(f1J |eI1 ) (1) The decomposition into two knowledge sources in Equation 1 allows an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 , known as source-channel model (Brown et al., 1993). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e. the generation of the output sentence into the target language. We have to maximize over all possible target language sentences. The translation model P r(f1J |eI1 ) can be further extended to a statistical alignment model with the following equation: P r(f1J |eI1 ) =  P r(f1J , aJ1 |eI1 ) 2.2 Alignment Models There are different decompositions of the alignment"
2005.eamt-1.37,P93-1002,0,0.0633879,"ce, many sentences in the training corpora are long. Some translation applications cannot handle a sentence whose length is larger than a predetermined value. The reasons are memory limits and the computational complexity of the algorithms. Therefore, long sentences are usually removed during the preprocessing. But even if long sentences are included, the resulting quality is usually not as good as it is for short sentences. 1.2 Comparison with Sentence Alignment The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on the lexicon"
2005.eamt-1.37,moore-2002-fast,0,0.0152406,"tences in the training corpora are long. Some translation applications cannot handle a sentence whose length is larger than a predetermined value. The reasons are memory limits and the computational complexity of the algorithms. Therefore, long sentences are usually removed during the preprocessing. But even if long sentences are included, the resulting quality is usually not as good as it is for short sentences. 1.2 Comparison with Sentence Alignment The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on the lexicon information. H"
2005.eamt-1.37,W03-2205,0,0.018661,"nt The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on the lexicon information. However, it only allows a monotone alignment of the bilingual segmented sentences and it requires a list of manually defined anchor words. 1.4 Idea of the Method Inspired by the phrase extraction approach (Vogel et al., 2004), we introduce a new sentence segmentation method which does not need anchor words and allows for nonmonotone alignments of the subsentences. Here we separate a sentence pair into two subpairs with the so-called “IBM Word Alignment Model"
2005.eamt-1.37,J03-1002,1,0.0133802,"f the alignment probability P r(f1J , aJ1 |eI1 ). The IBM-1 model (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution:   I J   1 p(fj |ei ) p(f1J |eI1 ) = I j=1 Hence, the word order does not affect the alignment probability. We use the IBM-1 model and the higher-order models IBM-4 (Brown et al., 1993) and HiddenMarkov model (HMM) (Vogel et al., 1996) to train the lexicon parameters p(fj |ei ). The resulting probability distribution is more concentrated than the one trained unsing the IBM-1 model only. The training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the alignment template translation approach (Och and Ney, 2004) is applied. A dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability. 3 Segmentation Methods In this section, we describe the sentence segmentation algorithm in detail. The main idea is that we use the word alignment information to find the optimal split point in a sentence pair and separate it into two pairs. To calculate the alignment probability of a segment pair, we indicate (j1 , i1 ) and (j2 , i2 ) as the start"
2005.eamt-1.37,J04-4002,1,0.654087,"the same probability by using a uniform distribution:   I J   1 p(fj |ei ) p(f1J |eI1 ) = I j=1 Hence, the word order does not affect the alignment probability. We use the IBM-1 model and the higher-order models IBM-4 (Brown et al., 1993) and HiddenMarkov model (HMM) (Vogel et al., 1996) to train the lexicon parameters p(fj |ei ). The resulting probability distribution is more concentrated than the one trained unsing the IBM-1 model only. The training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the alignment template translation approach (Och and Ney, 2004) is applied. A dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability. 3 Segmentation Methods In this section, we describe the sentence segmentation algorithm in detail. The main idea is that we use the word alignment information to find the optimal split point in a sentence pair and separate it into two pairs. To calculate the alignment probability of a segment pair, we indicate (j1 , i1 ) and (j2 , i2 ) as the start and end point of a segment, respectively. aJ 1 The alignment model P r(f1J , aJ1 |eI1 ) introduces a ‘hidden’ word alig"
2005.eamt-1.37,P02-1040,0,0.0750529,"substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with a penalty for too short sentences. (Papineni et al., 2002). • NIST score: This score is similar to BLEU, but it uses an arithmetic average of N-gram counts rather than a geometric average, and it weights more heavily those N-grams that are more informative. (Doddington, 2002). The BLEU and NIST scores measure accuracy, i.e. larger scores are better. In our evaluation the scores are measured as case insensitive and with respect to multiple references. 4.5 Translation Results The evaluation is done on two tasks described in Section 4.1. In the NIST Chinese-English evaluations, the BLEU score is used as evaluation criterion. Therefore, we optimize the p"
2005.eamt-1.37,C96-2141,1,0.716387,"on model P r(f1J |eI1 ) can be further extended to a statistical alignment model with the following equation: P r(f1J |eI1 ) =  P r(f1J , aJ1 |eI1 ) 2.2 Alignment Models There are different decompositions of the alignment probability P r(f1J , aJ1 |eI1 ). The IBM-1 model (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution:   I J   1 p(fj |ei ) p(f1J |eI1 ) = I j=1 Hence, the word order does not affect the alignment probability. We use the IBM-1 model and the higher-order models IBM-4 (Brown et al., 1993) and HiddenMarkov model (HMM) (Vogel et al., 1996) to train the lexicon parameters p(fj |ei ). The resulting probability distribution is more concentrated than the one trained unsing the IBM-1 model only. The training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the alignment template translation approach (Och and Ney, 2004) is applied. A dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability. 3 Segmentation Methods In this section, we describe the sentence segmentation algorithm in detail. The main idea is that we use the word alignme"
2005.eamt-1.37,2004.iwslt-evaluation.11,0,0.0288695,"Missing"
2005.eamt-1.37,J97-3002,0,0.0918773,"ed as the split point. 3.4 Recursive Segmentation We introduce the maximum sentence lengths for the source language Jmax and for the target language Imax . If a sentence is longer than the maximum length, the sentence pair is split into two subsentence pairs. In most cases, these sub-sentences are still too long. Therefore, the splitting is applied recursively until the length of each new sentence is less than the predefined value. The recursive algorithm is shown in Figure 4 for a bilingual sentence segmentation S(f1J , eI1 ). The algorithm is similar to the bracketing transduction grammars (Wu, 1997). Here, we take the local decision after each recursion. The full parsing with BTG is not feasible for long sentences because of its cubic complexity. 3.5 Segmentation Example We take the sentence pair in Figure 1 as an example. The maximum lengths in both languages is defined as three. In practice, the segmented sentences contain from 25 to hundreds of words. Using the algorithm in Figure 4, this sentence pair is segmented as follows: First, the lengths of the two sentences are larger than the maximum lengths, the sentences will be segmented. After the calculation with Equation 5, we find the"
2005.eamt-1.6,2004.iwslt-evaluation.13,1,0.857242,"till has to be determined is if the response time of the system, increased by the overhead of regenerating the word graphs, remains acceptable for interactive use under real-life conditions. Off-line experiments seem to indicate that this is the case (see next section). 6 6.1 Experimental Results Experimental Setup The experiments were performed on the SpanishEnglish and English-German Xerox corpora, which consist of the translation of technical manuals. The corpora allocations are summarized in Table 1 and Table 2. After training and optimization of the model scaling factors, the SMT engine (Bender et al., 2004) was used to translate the test corpus. The results using the standard evaluation measures for machine translation (word error rate, positionindependent word error rate, BLEU score and NIST score) are shown in Table 3. Using the same parameter settings, a simulation of the interactive mode was carried out. This simulation mode is described in (Och et al., 2003). The system with the same parameter settings was also successfully used by human translators to evaluate it under real-life conditions. Due to the high effort that human evaluations require, only the wordgraph based generation strategy"
2005.eamt-1.6,C96-1067,0,0.580617,"ife applications. The produced sentences often contain grammatical errors and the preservation of the meaning is not even always achieved. Therefore a manual post-processing of the texts has to be done. The concept of interactive machine translation already has a long history, and the first systems appeared in the end of the 1960’s. However in most of these systems the user doesn’t have a direct control over the translation process, and most of the user interaction is reduced to performing source language disambiguation on demand. The approach we center on in this work was first suggested by (Foster et al., 1996) and an implementation was carried out in the TransType project (Langlais et al., 2000). In such an environment, human translators interact with a translation system that acts as an assistance tool and dynamically provides a list of translations that best complete the part of the source senEAMT 2005 Conference Proceedings tence already translated. Further refinements were presented in the TransType2 project (SchlumbergerSema S.A. et al., 2001). The work presented in this paper deals with generation strategies for interactive (statistical) machine translation systems. Clearly, the best approach"
2005.eamt-1.6,W00-0507,0,0.366059,"servation of the meaning is not even always achieved. Therefore a manual post-processing of the texts has to be done. The concept of interactive machine translation already has a long history, and the first systems appeared in the end of the 1960’s. However in most of these systems the user doesn’t have a direct control over the translation process, and most of the user interaction is reduced to performing source language disambiguation on demand. The approach we center on in this work was first suggested by (Foster et al., 1996) and an implementation was carried out in the TransType project (Langlais et al., 2000). In such an environment, human translators interact with a translation system that acts as an assistance tool and dynamically provides a list of translations that best complete the part of the source senEAMT 2005 Conference Proceedings tence already translated. Further refinements were presented in the TransType2 project (SchlumbergerSema S.A. et al., 2001). The work presented in this paper deals with generation strategies for interactive (statistical) machine translation systems. Clearly, the best approach would be to start a new search for every given prefix. However, in these kind of syste"
2005.eamt-1.6,E03-1032,1,0.906128,"rent way, as it itself can be a prefix of the next word. To ensure the extensions start with this word prefix, the comparison must be done at the character level. One might think about different costs for the mismatch of words within the prefix and for extensions which do not start with the given word prefix. If a word within the prefix can not be produced by the search algorithm, then it will obviously not be produced by any further search call. This kind of substitution error is less harmful for producing good hypotheses than unfitting extensions, and should therefore be penalized less. In (Och et al., 2003), an efficient algorithm for interactive generation using word graphs was presented. A word graph is a weighted directed acyclic graph, in which each node represents a partial translation hypothesis and each edge is labeled with a word of the target sentence and is weighted according to the language and translation model scores. (Ueffing et al., 2002) give a more detailed description of word graphs and show how they can be easily produced as a sub-product of the search process. An example of a word graph is shown in Figure 2. It is clear that each node in the word graph defines a prefix of a p"
2005.eamt-1.6,W02-1021,1,0.904238,"that have the same word prefix. In the actual implementation, the method is applied on the character level, and the search for an extension is performed after each keystroke of the human translator. The crucial factor is an efficient maximization of Eq. 3, because human translators will only accept response times of fractions of a second. Using state-of-the-art search algorithms this is not 34 achievable without putting up with an unacceptable amount of search errors. To overcome this problem, we can compute a word graph which represents a subset of possible extensions (Ney and Aubert, 1994; Ueffing et al., 2002). The generation is then constrained to this set of extensions. 3 Phrase-based Approach The base method we use in our translation system is the alignment template approach as described in (Och et al., 1999; Och and Ney, 2004). This approach uses the so-called alignment templates, which are pairs of source and target language phrases1 together with the word alignment within the phrases. The alignment templates are introduced as hidden variables z1K when modelling the conditional translation probability Pr(f1J |eI1 ): Pr(f1J |eI1 ) =  I K K I Pr(aK 1 |e1 ) · Pr(z1 |a1 , e1 )· z1K ,aK 1 I Pr(f1J"
2005.eamt-1.6,J04-4002,1,0.629855,"icient maximization of Eq. 3, because human translators will only accept response times of fractions of a second. Using state-of-the-art search algorithms this is not 34 achievable without putting up with an unacceptable amount of search errors. To overcome this problem, we can compute a word graph which represents a subset of possible extensions (Ney and Aubert, 1994; Ueffing et al., 2002). The generation is then constrained to this set of extensions. 3 Phrase-based Approach The base method we use in our translation system is the alignment template approach as described in (Och et al., 1999; Och and Ney, 2004). This approach uses the so-called alignment templates, which are pairs of source and target language phrases1 together with the word alignment within the phrases. The alignment templates are introduced as hidden variables z1K when modelling the conditional translation probability Pr(f1J |eI1 ): Pr(f1J |eI1 ) =  I K K I Pr(aK 1 |e1 ) · Pr(z1 |a1 , e1 )· z1K ,aK 1 I Pr(f1J |z1K , aK 1 , e1 ) . (4) In Equation (4), we introduce the additional hidden variables aK 1 that model the alignment of the alignment templates themselves. As smoothing, automatically trained word classes can be used, and ad"
2005.eamt-1.6,W99-0604,1,0.787605,"l factor is an efficient maximization of Eq. 3, because human translators will only accept response times of fractions of a second. Using state-of-the-art search algorithms this is not 34 achievable without putting up with an unacceptable amount of search errors. To overcome this problem, we can compute a word graph which represents a subset of possible extensions (Ney and Aubert, 1994; Ueffing et al., 2002). The generation is then constrained to this set of extensions. 3 Phrase-based Approach The base method we use in our translation system is the alignment template approach as described in (Och et al., 1999; Och and Ney, 2004). This approach uses the so-called alignment templates, which are pairs of source and target language phrases1 together with the word alignment within the phrases. The alignment templates are introduced as hidden variables z1K when modelling the conditional translation probability Pr(f1J |eI1 ): Pr(f1J |eI1 ) =  I K K I Pr(aK 1 |e1 ) · Pr(z1 |a1 , e1 )· z1K ,aK 1 I Pr(f1J |z1K , aK 1 , e1 ) . (4) In Equation (4), we introduce the additional hidden variables aK 1 that model the alignment of the alignment templates themselves. As smoothing, automatically trained word classes"
2005.iwslt-1.18,P03-1021,0,0.0418797,"0]. A phrase is a contiguous sequence of words. The pairs of source and target phrases are extracted from the training corpus and used in the translation. The phrase translation probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a word-based lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The model scaling factors are optimized with respect to some evaluation criterion [11]. 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 3. Segmentation methods 3.1. Conventional segmentation methods In this section, we give a short overview of the current Chinese word segmentation methods in statistical machine translation, most of these methods can be classified into three categories: • The training and test texts are segmented with an automatic segmentation tool. Many segmentation to"
2005.iwslt-1.18,W04-1118,1,0.652012,"may contain some errors, and we also found that a much more accurate word segmentation does not always lead to a large improvement in the translation performance. • The training and test texts are segmented manually. Manual segmentation avoids segmentation errors but requires a human effort. Moreover, the correct segmentation will not result in the best translation result, if the segmentations in the test and training sets are inconsistent. • Each Chinese character is treated as a word Training and translation at the Chinese character level do not require additional tool or human effort. But [1] showed that the translation results are not so good as the results obtained when translation is at the word level. To minimize the number of lexicon entries and to ensure the consistency of the segmentations in the training and in the translation, we developed a new segmentation method, which uses the training text at the word level and translate the test text at the character level. 3.2. Idea Figure 1 shows the translation procedures. With the conventional method, only a single-best word segmentation is transferred to the search for the best translation. This approach is not ideal because th"
2005.iwslt-1.18,P02-1040,0,0.101372,"ed word segmentation in the translation, we only need to read segmentation lattice in Figure 3 instead of the manual segmented sentence. 4.2. Evaluation criteria ?:? xu:xu shou:shou ji:ji deng:deng li:li na:nali ban:ban li:eps li:li na:na ban:banli zai:zai li:eps 0 deng:dengji ji:eps shou:shouxu xu:eps 1 2 3 4 Figure 5: Segmentation transducer. So far, in machine translation research, a single generally accepted criterion for the evaluation of the experimental results does not exist. Therefore, we used different criteria: WER (word error rate), PER (position-independent word error rate), BLEU [12] and NIST [13]. For the evaluation corpus, we have sixteen references available. The four criteria are computed with respect to multiple references. The evaluation was case-insensitive. The BLEU and NIST scores measure accuracy, i.e. larger scores are better. 4.3. Evaluation results We present the translation results on the IWSLT 2005 task [4] described in Section 4.1. The experiments are based on two translation systems: • Finite-state transducer-based translation 3.5. Weighting with language model costs A problem of translation with the lattice in Figure 3 is that shorter paths are usually p"
2005.iwslt-1.18,P96-1019,0,0.0862748,"Missing"
2005.iwslt-1.18,J90-2002,0,0.555513,"on 4. 2. Statistical machine translation system 2.1. Bayes decision rule In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) eI1 ,I = argmax eI1 ,I © P r(eI1 ) · P r(f1J |eI1 ) ª (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state tran"
2005.iwslt-1.18,J03-1002,1,0.011191,") eI1 ,I = argmax eI1 ,I © P r(eI1 ) · P r(f1J |eI1 ) ª (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state transducer (Q, Σ ∪ {}, Ω ∪ {}, K, E, i, F, λ, ρ) is a structure with a set of states Q, an alphabet of input symbols Σ, an alphabet of output symbols Ω, a weight semiring K, a set of arcs E, a single initial state i with weight λ and a set of final states F weighted by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition"
2005.iwslt-1.18,P04-1065,1,0.420284,"atistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state transducer (Q, Σ ∪ {}, Ω ∪ {}, K, E, i, F, λ, ρ) is a structure with a set of states Q, an alphabet of input symbols Σ, an alphabet of output symbols Ω, a weight semiring K, a set of arcs E, a single initial state i with weight λ and a set of final states F weighted by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition algorithm is defined as: Let T1 : Σ∗ × Ω → K and T2 : Ω∗ × Γ∗ → K be two transducers defined over the same semiring K. Their composition T1 ◦T2 realizes the functio"
2005.iwslt-1.18,N04-1033,1,0.737334,"by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition algorithm is defined as: Let T1 : Σ∗ × Ω → K and T2 : Ω∗ × Γ∗ → K be two transducers defined over the same semiring K. Their composition T1 ◦T2 realizes the function T : Σ∗ × Γ∗ → K. ∗ By using the structure of the weighted finite-state transducers, the translation model is simply estimated as the language model on a bilanguage of source phrase/target phrase tuples, see [9]. 2.3. Phrase-based translation The phrase-based translation model is described in [10]. A phrase is a contiguous sequence of words. The pairs of source and target phrases are extracted from the training corpus and used in the translation. The phrase translation probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a word-based lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The model scaling factors are optimized with respect to some evaluation criterion [1"
2005.iwslt-1.20,1998.amta-tutorials.6,0,0.566661,"Missing"
2005.iwslt-1.20,J90-2002,0,0.695619,". Additionally, we translated Chinese ASR lattices. 1.1. Source-channel approach to SMT In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) I,eI1 = argmax I,eI1 © P r(eI1 ) · P r(f1J |eI1 ) ª (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation [1]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. 1.2. Log-linear model 1. Introduction We give an overview of the RWTH phrase-based statistical machine translation system that was used in the evaluation campaign of the International W"
2005.iwslt-1.20,P02-1038,1,0.79314,"ll review the statistical approach to machine translation and introduce the notation that we will use in the later sections. Then, we will describe the models and algorithms that are used for generating the N -best lists, i.e., the first pass. In Section 4, we will describe the models that are used to rescore and rerank this N -best list, i.e., the second pass. Afterward, we will give an overview of the tasks and discuss the experimental results. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [2], we obtain: ´ P M J I ) , f exp λ h (e m m 1 1 m=1 P ´ P r(eI1 |f1J ) = P (3) M J 0I0 exp m=1 λm hm (e 1 , f1 ) e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 1 The m=1 notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p"
2005.iwslt-1.20,P03-1021,0,0.0758006,"follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). This approach is a generalization of the source-channel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [3]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to a linear interpolation of WER, PER, BLEU and NIST using the Downhill Simplex algorithm from [4]. 1.3. Phrase-based approach The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. This idea is illustrated in Figure 1. Formally, we define a segmentation of a given sentence pair (f1J , eI1 ) into K blocks: k → sk := (ik ; bk , jk ), for k = 1 . . . K. (5) Here, ik denotes t"
2005.iwslt-1.20,2002.tmi-tutorials.2,0,0.161904,"get sentence are covered by exactly one phrase. Thus, there are no gaps and there is no overlap. For a given sentence pair (f1J , eI1 ) and a given segmentation sK 1 , we define the bilingual phrases as: e˜k f˜k := eik−1 +1 . . . eik (6) := fbk . . . fjk (7) target positions I = i4 i3 2. Search algorithms The RWTH phrase-based system supports two alternative search strategies that will be described in this section. Translating a source language word graph. The first search strategy that our system supports takes a source language word graph as input and translates this graph in a monotone way [5]. The input graph can represent different reorderings of the input sentence so that the overall search can generate nonmonotone translations. Using this approach, it is very simple to experiment with various reordering constraints, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target"
2005.iwslt-1.20,W05-0831,1,0.219539,"itions I = i4 i3 2. Search algorithms The RWTH phrase-based system supports two alternative search strategies that will be described in this section. Translating a source language word graph. The first search strategy that our system supports takes a source language word graph as input and translates this graph in a monotone way [5]. The input graph can represent different reorderings of the input sentence so that the overall search can generate nonmonotone translations. Using this approach, it is very simple to experiment with various reordering constraints, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceed"
2005.iwslt-1.20,J03-1005,1,0.786355,"s, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J"
2005.iwslt-1.20,C04-1030,1,0.855321,"To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phra"
2005.iwslt-1.20,W05-0834,1,0.835929,"rdinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, t"
2005.iwslt-1.20,W02-1021,1,0.799925,"rdinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, t"
2005.iwslt-1.20,N04-1033,1,0.843447,"tion. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not We use a log-linear combination of several models (also called feature functions). In this section, we will describe the models that are used in the first pass, i.e., during search. This is an improved version of the system described in [12]. More specifically the models are: a phrase translation model, a word-based translation model, a deletion model, word and phrase penalty, a target language model and a reordering model. 3.1. Phrase-based model The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus. The phrase extraction algorithm is described in detail in [5]. The main idea is to extract phrase pairs that are consis"
2005.iwslt-1.20,W99-0604,1,0.92093,"del The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus. The phrase extraction algorithm is described in detail in [5]. The main idea is to extract phrase pairs that are consistent with the word alignment. Thus, the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [13]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N &gt; 1 possible translations, each of them contributes to N (f˜, e˜) with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (9) The word translation probabilities p(f"
2005.iwslt-1.20,2004.iwslt-evaluation.13,1,0.873901,", eI1 , sK 1 ) = log jk K Y Y ik X p(fj |ei ) (10) k=1 j=bk i=ik−1 +1 The word translation probabilities p(f |e) are estimated as relative frequencies from the word-aligned training corpus. The word-based lexicon model is also used in both directions p(f |e) and p(e|f ). 3.3. Deletion model The deletion model [14] is designed to penalize hypotheses that miss the translation of a word. For each source word, we check if a target word with a probability higher than a given threshold τ exists. If not, this word is considered a deletion. The feature simply counts the number of deletions. Last year [15], we used this model during rescoring only, whereas this year, we integrated a within-phrase variant of the deletion model into the search: hDel (f1J , eI1 , sK 1 )= jk K X X ik Y k=1 j=bk i=ik−1 +1 [ p(fj |ei ) &lt; τ ] (11) 3.5. Target language model We use the SRI language modeling toolkit [17] to train a standard n-gram language model. The smoothing technique we apply is the modified Kneser-Ney discounting with interpolation. The order of the language model depends on the translation direction. For most tasks, we use a trigram model, except for Chinese-English, where we use a fivegram languag"
2005.iwslt-1.20,2005.eamt-1.17,1,0.801958,"techniques need specialized tools which traverse the graph appropriately. Additionally, because a node within a word graph allows for many histories, one can only apply local rescoring techniques, whereas for N -best lists, techniques can be used that consider properties of the whole target sentence. In the next sections, we will present several rescoring techniques. 4.1. Clustered language models One of the first ideas in rescoring is to use additional language models that were not used in the generation procedure. In our system, we use clustered language models based on regular expressions [18]. Each hypothesis is classified by matching it to regular expressions that identify the type of the sentence. Then, a cluster-specific (or sentence-type-specific) language model is interpolated into a global language model to compute the score of the sentence: hCLM (f1J , eI1 ) = (17) X£ ¤¡ ¢ I I I log Rc (e1 ) αc pc (e1 ) + (1 − αc )pg (e1 ) , c pg (eI1 ) I where is the global language ¤ pc (e1 ) the £ model, I cluster-specific language model, and Rc (e1 ) denotes the true-or-false statement (cf. Equation 12) which is 1 if the cth regular expression Rc (·) matches the target sentence eI1 and"
2005.iwslt-1.20,J03-1002,1,0.116578,"τ . In the experiments, τ was chosen between 10−1 and 10−4 . 4.4. Hidden Markov alignment model The next step after IBM model 1 rescoring is HMM rescoring. We use the HMM to compute the log-likelihood of a 2 The clusters are disjunct, thus only one regular expression matches. sentence pair (f1J , eI1 ): hHMM (f1J , eI1 ) = log J XY ¡ p(aj |aj−1 , I) · p(fj |eaj ) ¢ j=1 aJ 1 (20) In our experiments, we use a refined alignment probability p(aj − aj−1 |G(eaj ), I) that conditions the jump widths of the alignment positions aj − aj−1 on the word class G(eaj ). This is the so-called homogeneous HMM [19]. 4.5. Word penalties Several word penalties are used in the rescoring step:  (a)  I I/J (b) hWP (f1J , eI1 ) =  2|I − J|/(I + J) (c) (21) The word penalties are heuristics that affect the generated hypothesis length. In general, sentences that are too short should be avoided. 5. Integrating ASR and MT In the experiments on coupling speech recognition and machine translation, we used the phrase-based MT system described in Section 2 to translate ASR lattices. In addition to the models described in Section 3, we use the acoustic model and the source language model of the ASR system in the lo"
2005.iwslt-1.20,takezawa-etal-2002-toward,0,0.0815201,"g speech recognition and translation is the mismatch between the vocabularies of the ASR and MT system. For the Chinese-English task, the number of out-of-vocabulary (OOV) words was rather high. Ideally, the vocabulary of the recognition system should be a subset of the translation system source vocabulary. In the IWSLT evaluation, we had no control over the recognition experiments. For this reason, the reported improvements might have been larger with a proper handling of the vocabularies. 6. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [20]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the supplied data track, 20 000 sentences training corpus and two test sets (C-Star’03 and IWSLT’04) were made available for each language pair. As additional training resources for the C-Star track, we used the full BTEC for Japanese-English and the Spoken Language DataBase (SLDB) [21], which consists of transcriptions of spoken dialogs in the domain of hotel reservations3 . 3 The Japanese-English training corpora (BTE"
2005.iwslt-1.20,P02-1040,0,0.119193,"Missing"
2005.iwslt-1.20,W05-0909,0,0.0806623,"Missing"
2005.iwslt-1.20,2003.mtsummit-papers.51,0,0.106807,"Missing"
2005.mtsummit-papers.34,J93-2003,0,0.0128844,"uation results. 1 The structure of the paper is as follows: In Section 2 we will describe the statistical approach to machine translation and in Section 3 further methods used in our translation system. The EPPS databases and experimental results will be presented in Section 4. We will draw conclusions in the last Section. 2 Statistical Machine Translation In a machine translation framework we are given a sentence f1J = f1 . . . fJ in a source language that is to be translated as sentence eI1 = e1 . . . eI into a target language (f and e stand for ‘French’ and ‘English’ in the original paper (Brown et al., 1993)). For the statistical approach, we use Bayes decision rule which states that we should choose the sentence that maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) (1) eI1 = argmax p(eI1 )p(f1J |eI1 ) , (2) eI1 Introduction Speech-to-speech translation is an outstanding reasearch goal in the machine translation community. Up to now, most of the projects dealing with this issue have dealt only with artiﬁcial or very limited tasks (Wahlster, 2000; EuTransProject, 2000; Lavie et al., 2001; Ueﬃng and Ney, 2005). The goal of the TC-Star project is to build a speech-to-speech translation"
2005.mtsummit-papers.34,2005.eamt-1.17,1,0.776963,"IBM1 Rescoring Although the IBM1 model is the easiest one of the single-word based translation models and the phrase based models clearly outperform this approach, the inclusion of the scores of this 261 model, i.e. hIBM1 (f1J |eI1 ) = I J   1 p(fj |ei ) (I + 1)J (6) j=1 i=0 has been shown experimentally to improve the performance of a machine translation system (Och et al., 2003). 3.5 LM Rescoring During the generation process, a single language model is used. However, additional language models speciﬁc to each sentence to be translated can help to improve the machine translation quality (Hasan and Ney, 2005). The motivation behind this lies in the following observation: the syntactic structure of a sentence is inﬂuenced by its type. It is obvious that an interrogative sentence has a diﬀerent structure from a declarative one due to non-local dependencies arising e.g. from wh-extraction. As an example, let us consider the syntax of the following sentences: “Is the commissioner ready to give an undertaking?” and “The commissioner is ready to give an undertaking.” If we look closer at the ﬁrst four words of each sentence (is, the, commissioner and ready), the trigrams observed are quite diﬀerent, lea"
2005.mtsummit-papers.34,H01-1007,0,0.0254038,". . . eI into a target language (f and e stand for ‘French’ and ‘English’ in the original paper (Brown et al., 1993)). For the statistical approach, we use Bayes decision rule which states that we should choose the sentence that maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) (1) eI1 = argmax p(eI1 )p(f1J |eI1 ) , (2) eI1 Introduction Speech-to-speech translation is an outstanding reasearch goal in the machine translation community. Up to now, most of the projects dealing with this issue have dealt only with artiﬁcial or very limited tasks (Wahlster, 2000; EuTransProject, 2000; Lavie et al., 2001; Ueﬃng and Ney, 2005). The goal of the TC-Star project is to build a speech-to-speech translation system that can deal with real life data. For this purpose we have collected data from parliamentary speeches held in the European Parliament Plenary Sessions (EPPS) to build an open domain corpus. There are three different versions of the data, the oﬃcial version of the speeches as available on the web page of the European Parliament, the actual exact transcription of the speeches produced by human transcribers and the output of an automatic speech recognition system. We evaluate our system unde"
2005.mtsummit-papers.34,P02-1038,1,0.542956,"ord based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the used models are IBM-1, HMM and IBM-4. with hm diﬀerent models, λm scaling factors and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing a performance measure over a development corpus using the downhill simplex algorithm as presented in (Press et al., 2002). The source-channel model (2) is a special case of (5) with appropriate feature functions. The log-linear model, however, has the advantage that addition"
2005.mtsummit-papers.34,J03-1002,1,0.010911,"context into the translation model is to learn translations for whole phrases instead of single words. Here, a phrase is simply a sequence of words, no other linguistic meaning is required. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and ﬁnally compose the target sentence from these phrase translations. First an alignment between source and target sentence is found by using a chain of single-word based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the"
2005.mtsummit-papers.34,P02-1040,0,0.0715923,"ion. Sentence pairs Running Words Running Words without Punct. Marks Vocabulary Singletons Spanish English 1 207 740 34 851 423 33 335 048 31 360 260 30 049 355 139 587 93 995 48 631 33 891 Table 2: Statistics of the EPPS training corpus. order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU and NIST scores: These scores are a weighted n-gram precision in combination with a penalty for sentences which are too short, and were deﬁned in (Papineni et al., 2002) and (Doddington, 2002). Both measure accuracy, i.e. large scores are better. All of these metrics can be extended to the case where we have multiple references by calculating the value for each of the reference translations and choosing the best one among them. In our case we had two references per sentence. 4.4 Results The results for the FTE corpus are given in Table 4. The baseline results refer to the output of the translation system, as described in Section 3.1, without any of the further improvements discussed in Section 3. It can be seen that the log-linear combination of models signiﬁ"
2005.mtsummit-papers.34,W02-1021,1,0.821509,"rom being perfect. For eﬃciency reasons in most tasks, the whole search space can not be treated directly. So some pruning has to be carried out in the search process, which can lead to the rejection of valid translations (socalled search errors). The state-of-the-art algorithms used in current systems, however, allow to minimize these kinds of errors, so the main source of errors still lies in the probability models, i.e. sentences which are better translations do not get a better score (a higher probability). In order to alleviate this eﬀect, we can make use of word graphs and n-best lists (Ueﬃng et al., 2002). These are representations of diﬀerent possible translations for a given sentence. Once we have this representation we can use further models in order to compute an additional score for each of the possible candidates and then choose the one with the best score. Ideally these additional models would be integrated into the generation algorithm, but most of them are too costly to include in the search procedure or do not have a structure which allows this kind of coupling. How to eﬃciently compute n-best lists and word graphs for the phrase-based approach is presented in (Zens and Ney, 2005). 3"
2005.mtsummit-papers.34,C96-2141,1,0.629724,"the output of an automatic speech recognition system. We evaluate our system under these three conditions. 259 where the argmax operator denotes the search process. The transformation from (1) to (2) using Bayes rule allows us to use two sources of information, the translation model p(f1J |eI1 ) and the target language model p(eI1 ). The translation model can be further decomposed into a lexicon model, which gives the probability for word translations, and an alignment model, which connects the words in the source and target sentences. Let us consider the HMM Alignment model as presented in (Vogel et al., 1996) in order to illustrate this decomposition. This model decomposes the translation probability as follows: J  pϑ (f1J |eI1 ) = [pϑ (aj |aj−1 , I, J)pϑ (fj |eaj )] , j=1 aJ 1 (3) where the term pϑ (aj |aj−1 , I, J) is a ﬁrstorder model for the alignment, and the term Source Language Text Transformation f1J Pr(f1J |eI1 ) Global Search: maximize Pr(eI1 ) · Pr(f1J |eI1 ) over eI1 Lexicon model Alignment model Pr(eI1 ) Language model Transformation Target Language Text Figure 1: Architecture of the translation approach based on Bayes decision rule. pϑ (fj |eaj ) is the lexicon model1 , both depend"
2005.mtsummit-papers.34,N04-1033,1,0.844315,"guistic meaning is required. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and ﬁnally compose the target sentence from these phrase translations. First an alignment between source and target sentence is found by using a chain of single-word based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the used models are IBM-1, HMM and IBM-4. with hm diﬀerent models, λm scaling factors and the denominator a normalization factor that can be ignored in the maximizati"
2005.mtsummit-papers.34,W05-0834,1,0.828788,"s (Ueﬃng et al., 2002). These are representations of diﬀerent possible translations for a given sentence. Once we have this representation we can use further models in order to compute an additional score for each of the possible candidates and then choose the one with the best score. Ideally these additional models would be integrated into the generation algorithm, but most of them are too costly to include in the search procedure or do not have a structure which allows this kind of coupling. How to eﬃciently compute n-best lists and word graphs for the phrase-based approach is presented in (Zens and Ney, 2005). 3.4 IBM1 Rescoring Although the IBM1 model is the easiest one of the single-word based translation models and the phrase based models clearly outperform this approach, the inclusion of the scores of this 261 model, i.e. hIBM1 (f1J |eI1 ) = I J   1 p(fj |ei ) (I + 1)J (6) j=1 i=0 has been shown experimentally to improve the performance of a machine translation system (Och et al., 2003). 3.5 LM Rescoring During the generation process, a single language model is used. However, additional language models speciﬁc to each sentence to be translated can help to improve the machine translation qual"
2006.eamt-1.11,2005.eamt-1.6,1,0.88575,"Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was already presented in (Isabelle et al., 1993). In this paper, we enhance a phrase-based SMT system with interactive search capabilities. Another phrase-based approach using alignment templates was presented in (Och et al., 2003). It uses a word-graph as a compact representation of the search space and locates nodes that correspond to word sequences with minimum edit distance to a given prefix. An investigation on different search strategies based on this approach is reported in (Bender, Hasan, Vilar, Zens, & Ney, 2005). Other approaches use stochastic finitestate transducers that represent weighted graphs and, thus, efficiently code possible source-target sentence pairs in a compact manner (Civera et al., 2004). 3 Machine translation engine In this section, we shortly summarize the theoretical background of an interactive statistical machine translation system. First, we review the underlying non-interactive SMT part. Then, we describe the translation model for interactive machine translation from a statistical viewpoint. We also present an extension that allows for arbitrary text as input, without limitat"
2006.eamt-1.11,J90-2002,0,0.21354,"bability: ˆ eˆI1 = argmax  I,eI1 P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och & Ney, 2002): P r(eI1 |f1J ) = (2)  M I J exp m=1 λm hm (e1 , f1 )  P P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 P I 0 ,e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (3) I,eI1 m=1 This approach is a generalization of the source-channel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distance-base"
2006.eamt-1.11,W04-3245,0,0.0356611,"Missing"
2006.eamt-1.11,P04-3001,0,0.0231145,"Missing"
2006.eamt-1.11,A83-1029,0,0.159087,"system based on alignment templates. Related work in the CAT domain is referred to in the next section. In Section 3, we review the theoretical framework for interactive machine translation being derived from a statistical MT viewpoint. In Section 4, we present a detailed overview on the technical architecture, whereas Section 5 addresses some preliminary experiments using a stateof-the-art phrase-based machine translation system within the presented framework. We conclude the paper in Section 6. 2 Related work A multi-level design of interactive machine translation was already suggested by (Melby, 1983) based on work presented in (Kay, 1980). The main idea is to provide an environment with interactive capabilities to a human translator that suggests extensions of a partly translated sentence. The user can either accept or reject these completions. A recent implementation of such a tool was performed within the TransType project (Foster, Isabelle, & Plamondon, 1996, 1997; Langlais, Foster, & Lapalme, 2000). The assistance tool was then refined for the TransType2 project (Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was alread"
2006.eamt-1.11,P03-1021,0,0.00740553,"P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 P I 0 ,e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (3) I,eI1 m=1 This approach is a generalization of the source-channel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distance-based, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. 3.2 Interactive machine translation In interactive machine translation, we have to find an extension eIi+1 fo"
2006.eamt-1.11,P02-1038,1,0.54339,"st corpus. Thus, the system is capable of being employed in a real-world translation environment. 3.1 Baseline statistical translation system machine In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax  I,eI1 P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och & Ney, 2002): P r(eI1 |f1J ) = (2)  M I J exp m=1 λm hm (e1 , f1 )  P P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 P I 0 ,e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (3) I,eI1 m=1 This approach is a generalization of the source-channel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to t"
2006.eamt-1.11,C96-1067,0,0.0208176,"e preliminary experiments using a stateof-the-art phrase-based machine translation system within the presented framework. We conclude the paper in Section 6. 2 Related work A multi-level design of interactive machine translation was already suggested by (Melby, 1983) based on work presented in (Kay, 1980). The main idea is to provide an environment with interactive capabilities to a human translator that suggests extensions of a partly translated sentence. The user can either accept or reject these completions. A recent implementation of such a tool was performed within the TransType project (Foster, Isabelle, & Plamondon, 1996, 1997; Langlais, Foster, & Lapalme, 2000). The assistance tool was then refined for the TransType2 project (Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was already presented in (Isabelle et al., 1993). In this paper, we enhance a phrase-based SMT system with interactive search capabilities. Another phrase-based approach using alignment templates was presented in (Och et al., 2003). It uses a word-graph as a compact representation of the search space and locates nodes that correspond to word sequences with minimum edit distan"
2006.eamt-1.11,E03-1032,1,0.872017,"totype on different language pairs. 1 Introduction Computer Assisted Translation (CAT) aims at helping professional translators to faster translate texts from one language into another. The broad term covers many aspects, reaching from electronic dictionaries, terminology databases, automatic translation systems and other modules, such as translation memories. A crucial component is the machine translation system, as it imposes most of the computation and memory requirement constraints. Obviously, a separation of the translator’s environment and a dedicated translation server is intelligible (Och, Zens, & Ney, 2003). Generally, there might be additional components involved in the overall translation process, such as preprocessing, on-the-fly reranking and eventual postprocessing (e.g. truecasing). We present a straightforward framework that allows for several modules to be connected in series, employing a common interface and defined data structures as input and output. Thus, the overall maintenance effort is facilitated. The idea is to use translation objects that hold all necessary information and pass them from one application to another. For flexibility reasons and ease of use, we choose TCP/IP sock"
2006.eamt-1.11,1997.mtsummit-papers.1,0,0.152906,"Missing"
2006.eamt-1.11,P02-1040,0,0.0729848,"on and deletion operations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU and NIST scores: These scores are a weighted n-gram precision in combination with a penalty for sentences which are too short, and were defined in (Papineni, Roukos, Ward, & Zhu, 2002) and (Doddington, 2002), respectively. Both measure accuracy, i.e. higher scores are better. In order to determine the effort a human translator would need to produce a reference translation, we use the following measure: • KSMR (keystroke and mouse action ratio): This is the overall number of interactions of the user with the CAT system divided by the number of running characters for each sentence. As an interaction, we count keystrokes when typing in characters for parts where the system does not offer appropriate extensions as well as mouse actions (i.e. mouse clicks) that are needed to ac"
2006.eamt-1.11,1993.tmi-1.17,0,0.030612,"resented in (Kay, 1980). The main idea is to provide an environment with interactive capabilities to a human translator that suggests extensions of a partly translated sentence. The user can either accept or reject these completions. A recent implementation of such a tool was performed within the TransType project (Foster, Isabelle, & Plamondon, 1996, 1997; Langlais, Foster, & Lapalme, 2000). The assistance tool was then refined for the TransType2 project (Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was already presented in (Isabelle et al., 1993). In this paper, we enhance a phrase-based SMT system with interactive search capabilities. Another phrase-based approach using alignment templates was presented in (Och et al., 2003). It uses a word-graph as a compact representation of the search space and locates nodes that correspond to word sequences with minimum edit distance to a given prefix. An investigation on different search strategies based on this approach is reported in (Bender, Hasan, Vilar, Zens, & Ney, 2005). Other approaches use stochastic finitestate transducers that represent weighted graphs and, thus, efficiently code poss"
2006.eamt-1.11,W00-0507,0,0.0796508,"Missing"
2006.eamt-1.11,2005.iwslt-1.20,1,0.821969,"am therefore has to incorporate only a small set of basic capabilities, i.e. receiving, parsing and sending the object, in order to be usable in the application chain. One major advantage is that many such modules can be provided by different research groups and easily set up for experimentation. By using TCP/IP, the servers even do not need to be in one intranet but can be located anywhere on the internet instead. Furthermore, to test our basic framework, we incorporated server-like capabilities and an interactive search mode in a state-of-theart phrase-based machine translation (MT) system (Zens et al., 2005). The current performance is similar to an interactive machine translation (IMT) system based on alignment templates. Related work in the CAT domain is referred to in the next section. In Section 3, we review the theoretical framework for interactive machine translation being derived from a statistical MT viewpoint. In Section 4, we present a detailed overview on the technical architecture, whereas Section 5 addresses some preliminary experiments using a stateof-the-art phrase-based machine translation system within the presented framework. We conclude the paper in Section 6. 2 Related work A"
2006.iwslt-evaluation.15,P02-1038,1,0.675938,"tion [2]. It allows for an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. 1.2. Log-linear model A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [3], we obtain: P ´ M exp λm hm (eI1 , f1J ) m=1 P ´ P r(eI1 |f1J ) = P (3) M J 0I0 exp m=1 λm hm (e 1 , f1 ) e0 I1 0 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 103 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (4) targe"
2006.iwslt-evaluation.15,P03-1021,0,0.0724362,"that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (4) target positions I,eI1 I = i4 m=1 This is a generalization of the source-channel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [4]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to the BLEU measure, using the Downhill Simplex algorithm from [5]. i3 i2 i1 0 = i0 0 = j0 j2 b2 b1 j4 = J j3 j1 b4 b3 source positions Figure 1: Illustration of the phrase segmentation. 1.3. Phrase-based approach The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. This idea is illustrated in Figure 1. Formally, we define a segmentation of a given sentence pair (f1J , eI"
2006.iwslt-evaluation.15,2005.iwslt-1.20,1,0.136382,"ation and introduce the notation that we will use in the later sections. Then, we will describe the models and algorithms that are used for generating the N -best list, i.e., the first pass. In Section 3, we will describe the models that are used to rescore and rerank this N -best list, i.e., the second pass. Afterwards, we will give an overview of the tasks and discuss the experimental results. This paper will also include a section describing the method used for the system combination of the TC-Star project partners. The overall system is similar to the one used in the 2005 IWSLT evaluation [1]. However, it contains novel features for the first pass, as well as for the second pass. In the first pass, we use phrase count features (cf. 2.2) to smooth the phrase probabiliies. In the second pass, we used sentence mixture language models 3.2 as a new model for rescoring. 1.1. Source-channel approach to SMT In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest pro"
2006.iwslt-evaluation.15,J03-1005,1,0.669481,". . fjk (7) Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). 1.4. Source cardinality synchronous search For single-word based models, this search strategy is described in [6]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [7]. 2. Models used during search When searching for the best translation for a given input sentence, we use a log-linear combination of several models (also called feature functions) as decision criterion. In this section, we will describe the models that are used in the first pass, i.e., during N best list generation. More specifically the models are: a"
2006.iwslt-evaluation.15,C04-1030,1,0.839059,"ossible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). 1.4. Source cardinality synchronous search For single-word based models, this search strategy is described in [6]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [7]. 2. Models used during search When searching for the best translation for a given input sentence, we use a log-linear combination of several models (also called feature functions) as decision criterion. In this section, we will describe the models that are used in the first pass, i.e., during N best list generation. More specifically the models are: a phrase translation model, a word-based translation model, word and phrase penalty, a target language model and a reordering model. We will now describe the models in detail. 2.1. Phrase-based model The phrase-based translation model is the main"
2006.iwslt-evaluation.15,2002.tmi-tutorials.2,0,0.0348216,", i.e., during N best list generation. More specifically the models are: a phrase translation model, a word-based translation model, word and phrase penalty, a target language model and a reordering model. We will now describe the models in detail. 2.1. Phrase-based model The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus by the phrase extraction algorithm described in detail in [8]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [9]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each o"
2006.iwslt-evaluation.15,W99-0604,1,0.875186,"e phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus by the phrase extraction algorithm described in detail in [8]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [9]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each of them contributes to N (f˜, e˜) 104 with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) 2.4. Word and phrase penalty model In a"
2006.iwslt-evaluation.15,2004.iwslt-evaluation.13,1,0.815761,"sentence and phrase lengths. The model scaling factors can be adjusted to prefer longer sentences and longer phrases. 2.5. Target language model We use the SRI language modeling toolkit [11] to train a standard n-gram language model. The resulting feature function is: I Y hLM (f1J , eI1 , sK p(ei |ei−1 (14) 1 ) = log i−n+1 ) i=1 The smoothing technique we apply is the modified KneserNey discounting with interpolation. We used a 6-gram language model for all tasks. [N (f˜k , e˜k ) ≤ τ ] jk K Y Y I K 2.6. Reordering model We use a very simple reordering model that is also used in, for instance, [9, 12]. It assigns costs based on the jump width: hRM (f1J , eI1 , sK 1 )= K X |bk − jk−1 − 1 |+ J − jK (15) k=1 3. Rescoring models In this section, we describe the second pass of our system, the rescoring of N -best lists. N -best lists are suitable for easily applying several rescoring techniques because the hypotheses are already fully generated. In comparison, word graph rescoring techniques need specialized tools which traverse the graph appropriately. Additionally, because a node within a word graph allows for many histories, one can only apply local rescoring techniques, whereas for N -best"
2006.iwslt-evaluation.15,2005.eamt-1.17,1,0.888573,"Missing"
2006.iwslt-evaluation.15,W06-3110,1,0.184162,"se of another rescoring technique that benefits from the IBM model 1 lexical probabilities: hDel (f1J , eI1 ) = J Y I X [ p(fj |ei ) < τ ] (19) j=1 i=0 We call this the IBM1 deletion model. It counts all source words whose lexical probability given each target word is below a threshold τ . In the experiments, τ was chosen between 10−1 and 10−4 . 3.5. Sentence length model Sentence length is crucial for the evaluation of machine translation output, especially when using automatic evalua106 tion measures. Therefore we explicitly modeled the target sentence length I using the method described in [16]: X hSL (f1J , eI1 ) = log p(eI1 |f1J ) Table 2: Progress over time: comparison of the RWTH systems of the years 2004 to 2006 for the supplied data track on the IWSLT 2005 test set. eI1 Translation Direction Chin.-Engl. The sum is carried out only over those target hypotheses that have length I. 4. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [17]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the open data trac"
2006.iwslt-evaluation.15,takezawa-etal-2002-toward,0,0.0460057,"the evaluation of machine translation output, especially when using automatic evalua106 tion measures. Therefore we explicitly modeled the target sentence length I using the method described in [16]: X hSL (f1J , eI1 ) = log p(eI1 |f1J ) Table 2: Progress over time: comparison of the RWTH systems of the years 2004 to 2006 for the supplied data track on the IWSLT 2005 test set. eI1 Translation Direction Chin.-Engl. The sum is carried out only over those target hypotheses that have length I. 4. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [17]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the open data track a 40 000 sentences training corpus and four test sets were made available for each language pair. Other resources, despite proprietary data were permitted, but were not used in this system. As the BTEC is a rather clean corpus, the preprocessing consisted mainly of tokenization, i.e., separating punctuation marks from words. Additionally, we expanded contractions such as it’s or I’m in the English co"
2006.iwslt-evaluation.15,J03-1002,1,0.094442,"Missing"
2006.iwslt-evaluation.15,P02-1040,0,0.123176,"Missing"
2006.iwslt-evaluation.15,W05-0909,0,0.0606975,"Missing"
2006.iwslt-evaluation.15,E06-1005,1,0.51274,"Missing"
2006.iwslt-evaluation.15,W02-1021,1,\N,Missing
2006.iwslt-evaluation.15,J90-2002,0,\N,Missing
2006.iwslt-evaluation.15,W05-0834,1,\N,Missing
2006.iwslt-evaluation.15,W05-0831,1,\N,Missing
2006.iwslt-evaluation.8,takezawa-etal-2002-toward,0,0.0497024,"Missing"
2006.iwslt-evaluation.8,P03-1020,0,0.10591,"Missing"
2006.iwslt-evaluation.8,koen-2004-pharaoh,0,\N,Missing
2006.iwslt-evaluation.8,J00-2004,0,\N,Missing
2006.iwslt-evaluation.8,2005.iwslt-1.11,1,\N,Missing
2006.iwslt-evaluation.8,2006.iwslt-evaluation.15,1,\N,Missing
2007.iwslt-1.3,J96-1002,0,0.0137253,"Missing"
2007.iwslt-1.3,W05-0831,1,0.886998,"Missing"
2007.iwslt-1.3,N03-1017,0,0.0103966,"Missing"
2007.iwslt-1.3,2001.mtsummit-papers.45,1,0.810172,"since different languages have different word order requirements. In current phrasebased Statistical Machine Translation (SMT) systems, distance-based reordering constraints are widely used, such as IBM constraints [1], local constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more"
2007.iwslt-1.3,popovic-ney-2006-pos,1,0.238747,"nt languages have different word order requirements. In current phrasebased Statistical Machine Translation (SMT) systems, distance-based reordering constraints are widely used, such as IBM constraints [1], local constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than PO"
2007.iwslt-1.3,W06-1609,0,0.0922268,"ferent word order requirements. In current phrasebased Statistical Machine Translation (SMT) systems, distance-based reordering constraints are widely used, such as IBM constraints [1], local constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they"
2007.iwslt-1.3,P05-1066,0,0.396938,"l constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two"
2007.iwslt-1.3,D07-1077,0,0.154608,"straints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two level"
2007.iwslt-1.3,P07-1091,0,0.399,"nts [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syn"
2007.iwslt-1.3,D07-1056,0,0.0538963,"2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syntactic"
2007.iwslt-1.3,W03-1002,0,0.0524565,"parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syntactic transduction which uses chunks on both language sides. It is a whole translation system. Here, we only apply chunks on source language and are more interested in using chunk knowledge in the phrasebased translation framework. In this paper, we will improve the approach described in [12] by adding a weight model using the rules probability and repeating training on the reordered sentence pairs. In Section 3, the baseline systems are introduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presen"
2007.iwslt-1.3,W07-0401,1,0.649895,"the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syntactic transduction which uses chunks on both language sides. It is a whole translation system. Here, we only apply chunks on source language and are more interested in using chunk knowledge in the phrasebased translation framework. In this paper, we will improve the approach described in [12] by adding a weight model using the rules probability and repeating training on the reordered sentence pairs. In Section 3, the baseline systems are introduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presented. Section 5 describes the experiments and the analysis. Finally, Section 6 is the conclusion. 2. Related work In the previous chunk level reordering work, [12] has represented the reorderings generated with some rules in a weighted lattice. The lattice is weighted with language model trained on reordered source data. The informatio"
2007.iwslt-1.3,W03-1709,0,0.0619507,"is POS tagged and chunked. Five chunks are generated from seven words. The English gloss is also shown at the last row for each chunks. The three rules for reordering the chunks are listed in the second table. Then the corresponding lattice with the three rules is generated. Note that when building the lattice, the monotone word sequence without any reordering is guaranteed to be included. The chunk parser is the maximum entropy tool YASMET 1 . The F-measure is 63.3 for chunk tagging. Since the chunking requires POS tags, “Inst. of Computing Tech., Chinese Lexical Analysis System. (ICTCLAS)” [19] is used. It does word segmentation and Part-Of-Speech tagging in one pass. The lattice is weighted with a trigram reordered http://www-i6.informatik.rwth-aachen.de/web/Software /index.html bu 8 duo wo men 9 chu zu 7 10 bu 11 1 4 duo 12 source language model. Each path of the lattice is a permutation fππ1J = fπ1 , ..., fπJ for a given source sentence f1J . πj is the permutation position of word fj . The weight model used in the decoder is: hslm (fππ1J , f1J ) = log p(fππ1J |f1J ) = J X (5) log p(fπj |fπj−1 , fπj−2 )(6) j=1 4. Improved chunk reordering system Two methods will be reported to imp"
2007.iwslt-1.3,2002.tmi-tutorials.2,0,0.274077,"pairs. In Section 3, the baseline systems are introduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presented. Section 5 describes the experiments and the analysis. Finally, Section 6 is the conclusion. 2. Related work In the previous chunk level reordering work, [12] has represented the reorderings generated with some rules in a weighted lattice. The lattice is weighted with language model trained on reordered source data. The information from the reordering rules is not used. The previous work to input a graph to SMT system was done by [13]. Another work with weighted graph is done by [14]. In their N-grambased SMT system, reordering is handled by a statistical machine reordering (SMR) system, which translate an original source language to a reordered source language. The output of the SMR system is a weighted graph. Their reordering is done at word class level. Another work is to use multiple reordered inputs instead of single input to the SMT system. [9] represents reordered sentences in a N-best list. 3. Baseline system 3.1. The baseline phrase-based SMT system In statistical machine translation, we are given a source languag"
2007.iwslt-1.3,W07-0720,0,0.0495149,"roduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presented. Section 5 describes the experiments and the analysis. Finally, Section 6 is the conclusion. 2. Related work In the previous chunk level reordering work, [12] has represented the reorderings generated with some rules in a weighted lattice. The lattice is weighted with language model trained on reordered source data. The information from the reordering rules is not used. The previous work to input a graph to SMT system was done by [13]. Another work with weighted graph is done by [14]. In their N-grambased SMT system, reordering is handled by a statistical machine reordering (SMR) system, which translate an original source language to a reordered source language. The output of the SMR system is a weighted graph. Their reordering is done at word class level. Another work is to use multiple reordered inputs instead of single input to the SMT system. [9] represents reordered sentences in a N-best list. 3. Baseline system 3.1. The baseline phrase-based SMT system In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is t"
2007.iwslt-1.3,J90-2002,0,0.420238,"ed sentences in a N-best list. 3. Baseline system 3.1. The baseline phrase-based SMT system In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability:  ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) I,eI1 = argmax I,eI1  P r(eI1 ) · P r(f1J |eI1 ) (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation [15]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [16], we obtain:  P M I J exp m=1 λm"
2007.iwslt-1.3,P02-1038,1,0.109097,"o statistical machine translation [15]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [16], we obtain:  P M I J exp m=1 λm hm (e1 , f1 )  P P r(eI1 |f1J ) = P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 e0 I1 0 (3) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: (M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 m=1 This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy p"
2007.iwslt-1.3,P03-1021,0,0.0659479,"ormalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: (M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 m=1 This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [17]. The log linear model is a natural framework to integrate many models. During the search of the baseline system we are using the following models: • phrase translation models (including phrase count features) • word-based translation models • word and phrase penalty • target language model (6-gram) • jump reordering model (assigning costs based on the jump width) All the experiments in the paper are evaluated without rescoring. More details about the baseline system can be found in [18]. Figure 1: An example of source reordering. source ke yi dan shi wo men chu zu che bu duo POS v c r v n d m"
2007.iwslt-1.3,2000.eamt-1.5,1,0.801713,"ernatively, one can train them with respect to the final translation quality measured by an error criterion [17]. The log linear model is a natural framework to integrate many models. During the search of the baseline system we are using the following models: • phrase translation models (including phrase count features) • word-based translation models • word and phrase penalty • target language model (6-gram) • jump reordering model (assigning costs based on the jump width) All the experiments in the paper are evaluated without rescoring. More details about the baseline system can be found in [18]. Figure 1: An example of source reordering. source ke yi dan shi wo men chu zu che bu duo POS v c r v n d m chunks v c r NP VP English gloss yes but we taxi not many used reordering rules NP VP → VP NP r NP VP → r VP NP r NP VP → VP r NP Reordering Lattice: chu zu che 5 bu 6 duo che wo men 0 ke yi 1 dan shi 2 3 3.2. Chunking reordering system The baseline reordering system we use was described in [12]. The reordering is done in preprocessing stage on the source language side. A source sentence is firstly parsed into chunks. These chunks will be reordered by some rules which are automatically"
2007.iwslt-1.3,2006.amta-papers.25,0,0.0378225,"ing data as bilingual corpora. The corpus statistics are shown in Table 1. The scaling factors are optimized for the BLEU score. The translation is evaluated case-insensitive and with punctuation marks. 5.2. Evaluation criteria WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence. PER (position-independent word error rate). The PER compares the words in the hypothesis and references ignoring the word order. TER (translation error rate). The TER [20] is computed as the number of edits needed to change a system output so that it exactly matches a given reference. The edits include insertions, deletions, substitutions and shifts. BLEU. This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences [21]. The BLEU score measures accuracy. 5.3. Results In Table 2, the translation results for the IWSLT05 eval data are reported. The experiments are run comparing to the baseline which is the source reordering weighed only by the source language model. T"
2007.iwslt-1.3,P02-1040,0,0.104406,"Missing"
2007.iwslt-1.3,2006.iwslt-evaluation.15,1,\N,Missing
2008.iwslt-papers.8,W99-0604,1,0.531725,"Missing"
2008.iwslt-papers.8,2002.tmi-tutorials.2,0,0.085219,"Missing"
2008.iwslt-papers.8,N03-1017,0,0.0338709,"Missing"
2008.iwslt-papers.8,J99-4005,0,0.179726,"Missing"
2008.iwslt-papers.8,J03-1005,1,0.615064,"Missing"
2008.iwslt-papers.8,P07-2045,1,0.0120572,"Missing"
2008.iwslt-papers.8,J04-4002,1,0.39413,"Missing"
2008.iwslt-papers.8,2007.mtsummit-papers.43,0,0.0219142,"Missing"
2008.iwslt-papers.8,W06-3602,0,0.0295213,"Missing"
2008.iwslt-papers.8,P05-1033,0,0.0294416,"Missing"
2008.iwslt-papers.8,P07-1019,0,0.292006,"Missing"
C04-1006,J93-2003,0,0.0180943,"Missing"
C04-1006,P03-1012,0,0.0604065,"Missing"
C04-1006,P03-1011,0,0.0257173,"Missing"
C04-1006,J00-2004,0,0.217992,"Missing"
C04-1006,P00-1056,1,0.699934,"hereas in language modeling typically integer counts are used. Additionally, we want to allow for discounting values d greater than one. The backing-off distribution β(f, e¯) is estimated using relative frequencies: β(f, e¯) = N (f, e¯) P N (f˜, e¯) f˜ Here, N (f, e¯) denotes the count of the event that the source language word f and the target language base form e¯ occur together. These counts are computed by summing the lexicon counts N (f, e) over all full-form words e which share the same base form e¯. 5 Results 5.1 Evaluation Criteria We use the same evaluation criterion as described in (Och and Ney, 2000). The generated word alignment is compared to a reference alignment which is produced by human experts. The annotation scheme explicitly takes the ambiguity of the word alignment into account. There are two different kinds of alignments: sure alignments (S) which are used for alignments that are unambiguous and possible alignments (P ) which are used for alignments that might or might not exist. The P relation is used especially to align words within idiomatic expressions, free translations, and missing function words. It is guaranteed that the sure alignments are a subset of the possible alig"
C04-1006,J03-1002,1,0.114909,"l language processing. Obvious applications are the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). These applications depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). The alignment describes the mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. In (Och and Ney, 2003), it is shown that the statistical approach performs very well compared to alternative approaches, e.g. based on the Dice coefficient or the competitive linking algorithm (Melamed, 2000). A central component of the statistical translation models is the lexicon. It models the word translation probabilities. The standard training procedure of the statistical models uses the EM algorithm. Typically, the models are trained for one translation direction only. Here, we will perform a simultaneous training of both translation directions, source-to-target and target-to-source. After each iteration of"
C04-1006,W02-1012,0,0.215898,"Missing"
C04-1006,C96-2141,1,0.951397,"l corpora are an important knowledge source for many tasks in natural language processing. Obvious applications are the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). These applications depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). The alignment describes the mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. In (Och and Ney, 2003), it is shown that the statistical approach performs very well compared to alternative approaches, e.g. based on the Dice coefficient or the competitive linking algorithm (Melamed, 2000). A central component of the statistical translation models is the lexicon. It models the word translation probabilities. The standard training procedure of the statistical models uses the EM algorithm. Typically, the models are trained for one translation direction only. Here, we will perform a simultaneous training of both translation directio"
C04-1006,J97-3002,0,0.190502,"Missing"
C04-1030,J90-2002,0,0.427447,"significant improvements compared to the unconstrained search. 1 Introduction In statistical machine translation, we are given a source language (‘French’) sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language (‘English’) sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. It can be further decomposed into alignment and lexicon model. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. An alternative to the classical sourcechannel approach is the direct"
C04-1030,J99-4005,0,0.599269,"ls or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003). In this paper, we will investigate the reordering problem for phrase-based translation approaches. As the word order in source and target language may differ, the search algorithm has to allow certain reorderings. If arbitrary reorderings are allowed, the search problem is NP-hard (Knight, 1999). To obtain an efficient search algorithm, we can either restrict the possible reorderings or we have to use an approximation algorithm. Note that in the latter case we cannot guarantee to find an optimal solution. The remaining part of this work is structured as follows: in the next section, we will review the baseline translation system, namely the alignment template approach. Afterward, we will describe different reordering constraints. We will begin with the IBM constraints for phrase-based translation. Then, we will describe constraints based on inversion transduction grammars (ITG). In t"
C04-1030,N03-1017,0,0.32893,"Missing"
C04-1030,W02-1018,0,0.0915666,"Missing"
C04-1030,P02-1038,1,0.858868,"lation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. It can be further decomposed into alignment and lexicon model. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. An alternative to the classical sourcechannel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a loglinear model (Och and Ney, 2002), we obtain: Ã P r(eI1 |f1J ) = exp ! M X λm hm (eI1 , f1J ) · Z(f1J ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ( eˆI1 = argmax eI1 M X ) λm hm (eI1 , f1J ) m=1 This approach is a generalization of the source-channel approach. It has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measu"
C04-1030,W99-0604,1,0.401442,"nslation system, namely the alignment template approach. Afterward, we will describe different reordering constraints. We will begin with the IBM constraints for phrase-based translation. Then, we will describe constraints based on inversion transduction grammars (ITG). In the following, we will call these the ITG constraints. In Section 4, we will present results for two Japanese–English translation tasks. 2 Alignment Template Approach In this section, we give a brief description of the translation system, namely the alignment template approach. The key elements of this translation approach (Och et al., 1999) are the alignment templates. These are pairs of source and target language phrases with an alignment within the phrases. The alignment templates are build at the level of word classes. This improves the generalization capability of the alignment templates. We use maximum entropy to train the model scaling factors (Och and Ney, 2002). As feature functions we use a phrase translation model as well as a word translation model. Additionally, we use two language model feature functions: a word-based trigram model and a class-based five-gram model. Furthermore, we use two heuristics, namely the wor"
C04-1030,P03-1021,0,0.209602,"= exp ! M X λm hm (eI1 , f1J ) · Z(f1J ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ( eˆI1 = argmax eI1 M X ) λm hm (eI1 , f1J ) m=1 This approach is a generalization of the source-channel approach. It has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003). In this paper, we will investigate the reordering problem for phrase-based translation approaches. As the word order in source and target language may differ, the search algorithm has to allow certain reorderings. If arbitrary reorderings are allowed, the search problem is NP-hard (Knight, 1999). To obtain an efficient search algorithm, we can either restrict the possible reorderings or we have to use an approximation algorithm. Note that in the latter case we cannot guarantee to find an optimal solution. The remaining part of this work is structured as follows: in the next section, we will"
C04-1030,P02-1040,0,0.113983,"eletion operations that have to be performed to convert the generated sentence into the reference sentence. PER (position-independent word error rate). A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. BLEU. This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2002). The BLEU score measures accuracy, i.e. large BLEU scores are better. NIST. This score is similar to BLEU. It is a weighted n-gram precision in combination with a penalty for too short sentences (Doddington, 2002). The NIST score measures accuracy, i.e. large NIST scores are better. Note that for each source sentence, we have as many as 16 references available. We compute all the preceding criteria with respect to multiple references. 4.3 System Comparison In Table 3 and Table 4, we show the translation results for the BTEC task. First, we observe that the overall quality is rather high on th"
C04-1030,takezawa-etal-2002-toward,1,0.296878,"to the left of the current position jc , e.g. positions (a) and (d). Somewhere in between there has to be an covered position j whose successor position j + 1 is uncovered, e.g. (b) and (c). Therefore, any reordering that violates Equation 1 generates the pattern on the left-hand side in Figure 4, thus it violates the ITG constraints. 4 Results 4.1 Corpus Statistics To investigate the effect of reordering constraints, we have chosen two Japanese–English tasks, because the word order in Japanese and English is rather different. The first task is the Basic Travel Expression Corpus (BTEC) task (Takezawa et al., 2002). The corpus statistics are shown in Table 1. This corpus consists of phrasebook entries. The second task is the Spoken Language DataBase (SLDB) task (Morimoto et al., 1994). This task consists of transcription of spoken dialogs in the domain of hotel reservation. Here, we use domain-specific training data in addition to the BTEC corpus. The corpus statistics of this additional corpus are shown in Table 2. The development corpus is the same for both tasks. 4.2 Evaluation Criteria WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations"
C04-1030,J03-1005,1,0.779472,"a sequence of word classes as used in the alignment templates. 3.1 IBM Constraints In this section, we describe restrictions on the phrase reordering in spirit of the IBM constraints (Berger et al., 1996). First, we briefly review the IBM constraints at the word level. The target sentence is produced word by word. We keep a coverage vector to mark the already translated (covered) source positions. The next target word has to be the translation of one of the first k uncovered, i.e. not translated, source positions. The IBM constraints are illustrated in Figure 1. For further details see e.g. (Tillmann and Ney, 2003). For the phrase-based translation approach, we use the same idea. The target sentence is produced phrase by phrase. Now, we allow skipping of up to k phrases. If we set k = 0, we obtain a search that is monotone at the phrase level as a special case. Q(1, ∅, $) = 1  with inversion target positions without inversion target positions The search problem can be solved using dynamic programming. We define a auxiliary function Q(j, S, e). Here, the source position j is the first unprocessed source position; with unprocessed, we mean this source position is neither translated nor skipped. We use th"
C04-1030,J97-3002,0,0.799973,"the language model history. The symbol $ is used to mark the sentence start and the sentence end. The extension to higher-order n-gram language models is straightforward. We use M to denote the maximum phrase length in the source language. We obtain the following dynamic programming equations: source positions source positions Figure 2: Illustration of monotone and inverted concatenation of two consecutive blocks. setting k = 0 results in a search algorithm that is monotone at the phrase level. 3.2 ITG Constraints Q(j, S, e) = max In this section, we describe the ITG conn straints (Wu, 1995; Wu, 1997). Here, we interj−1 max max Q(j 0 , S, e0 ) · p(fj 0 |˜ e) · p(˜ e|e0 ), pret the input sentence as a sequence of blocks. e0 ,˜ e j−M ≤j 0 <j o 0 0 , e0 ) · p(f j +l−1 |˜ 0 ) , In the beginning, each alignment template is a max Q(j, S e ) · p(˜ e |e j0 block of its own. Then, the reordering process (j 0 ,l)∈S 0 S=S 0 {(j 0 ,l)}  can be interpreted as follows: we select two consecutive blocks and merge them to a single max0 Q(j 0 , S 0 , e) j−M ≤j <j block by choosing between two options: either S 0 :S=S 0 ∪{(j 0 ,j−j 0 )}∧|S 0 |<k keep the target phrases in monotone order or Q(J + 2, ∅, $) ="
C04-1030,P03-1019,1,0.776962,"entence word by word or phrase the position to be translated next jn . Then, by phrase. The idea is to start with the beam it is not allowed to move from an uncovered search decoder for unconstrained search and position to a covered one. modify it in such a way that it will produce Now, we sketch the proof that these cononly reorderings that do not violate the ITG straints are equivalent to the ITG constraints. constraints. Now, we describe one way to obIt is easy to see that the constraint in Equatain such a decoder. It has been pointed out tion 1 avoids the pattern on the left-hand side in (Zens and Ney, 2003) that the ITG conin Figure 4. To be precise: after placing the straints can be characterized as follows: a refirst two phrases at (b,1) and (d,2), it avoids ordering violates the ITG constraints if and the placement of the third phrase at (a,3). only if it contains (3, 1, 4, 2) or (2, 4, 1, 3) as Similarly, the constraint in Equation 2 avoid a subsequence. This means, if we select four the pattern on the right-hand side in Figcolumns and the corresponding rows from the ure 4. Therefore, if we enforce the constraints alignment matrix and we obtain one of the two in Equation 1 and Equation 2, we"
C04-1032,J93-2003,0,0.0320223,"particular the state occupation probabilities, will be used to determine the costs of aligning a specific source word to a target word. We will evaluate the suggested alignment methods on the German–English Verbmobil task and the French–English Canadian Hansards task. We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003). 2 Statistical Word Alignment Models In this section, we will give an overview of the commonly used statistical word alignment techniques. They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993). We are given a source language sentence f1J := f1 ...fj ...fJ which has to be translated into a target language sentence eI1 := e1 ...ei ...eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two knowledge sources allows for an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 ). Into the translation model, the word alignment A is introduced as a hidden variable: X P r(f1J |eI1 ) = P r(f1J ,"
C04-1032,P03-1012,0,0.0477676,"Missing"
C04-1032,P03-1011,0,0.0400771,"Missing"
C04-1032,J00-2004,0,0.0627208,"Missing"
C04-1032,P00-1056,1,0.805812,"the alignment are minimal. Using state occupation probabilities for word alignment modeling results in a number of advantages. First of all, in calculation of these probabilities with the models IBM-1, IBM-2 and HMM the EM-algorithm is performed exact, i.e. the summation over all alignments is efficiently performed in the Estep. For the HMM this is done using the Baum-Welch algorithm (Baum, 1972). So far, an efficient algorithm to compute the sum over all alignments in the fertility models IBM-3 to IBM-5 is not known. Therefore, this sum is approximated using a subset of promising alignments (Och and Ney, 2000). In both cases, the resulting estimates are more precise than the ones obtained by the maximum approximation, i. e. by considering only the Viterbi alignment. Instead of using the state occupation probabilities from only one training direction as costs (Equation 1), we can interpolate the state occupation probabilities from the sourceto-target and the target-to-source training for each pair (i,j) of positions in a sentence pair (f1J , eI1 ). This will improve the estimation of the local alignment costs. Having such symmetrized costs, we can employ the graph alignment algorithms (cf. Section 4"
C04-1032,J03-1002,1,0.261441,"which avoids this constraint and produces symmetric word alignments. This algorithm considers the alignment problem as a task of finding the edge cover with minimal costs in a bipartite graph. The parameters of the IBM models and HMM, in particular the state occupation probabilities, will be used to determine the costs of aligning a specific source word to a target word. We will evaluate the suggested alignment methods on the German–English Verbmobil task and the French–English Canadian Hansards task. We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003). 2 Statistical Word Alignment Models In this section, we will give an overview of the commonly used statistical word alignment techniques. They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993). We are given a source language sentence f1J := f1 ...fj ...fJ which has to be translated into a target language sentence eI1 := e1 ...ei ...eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two"
C04-1032,C96-2141,1,0.935974,"aligned bilingual corpora provide important knowledge for many natural language processing tasks, such as the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). The solutions of these problems depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). An alignment describes a mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. However, all these models constrain the alignments so that a source word can be aligned to at most one target word. This constraint is useful to reduce the computational complexity of the model training, but makes it hard to align phrases in the target language (English) such as ‘the day after tomorrow’ to one word in the source language (German) ‘¨ ubermorgen’. We will present a word alignment algorithm which avoids this constraint and produces symmetric word alignments. This algorithm considers the alignment problem as a task of finding the edge c"
C04-1032,J97-3002,0,0.0795518,"Missing"
D07-1055,W05-0909,0,0.0366622,"ation of the Bleu score as some of the training criteria are motivated by this. The Bleu score is a combination of the geometric mean of n-gram precisions and a brevity penalty for too short translation hypotheses. The Bleu score for a translation hypothˆ esis eI1 and a reference translation eˆI1 is computed as: Evaluation Metrics The automatic evaluation of machine translation is currently an active research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation system. As this is exactly what we will need in our experiments an"
D07-1055,J90-2002,0,0.168761,"Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics such as the Bleu score. One reason for the popularity of the MAP decision rule might be that, compared to the MBR rule, its computation is simpler. The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  pλM (eI1 |f1J ) = P 1 M 0I0 , f J ) exp λ h (e 1 1 m=1 m m I 0 ,e0 I1 0 (1) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in case of the MAP decision rule during the search process and obtain: 0 ( 0 Here, L(eI1 , e0 I1 ) denotes the loss function under consideration. It measures the loss (or errors) of a candidate translation eI1 assuming the correct trans0 lation is e0 I1 . In the following, we will call this decision rule the MBR rule (Kumar and Byrne, 2004). This decision rule is optimal in"
D07-1055,E06-1032,0,0.00743824,"ctive research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation system. As this is exactly what we will need in our experiments and as Bleu is currently the most popular metric, we have chosen it as our primary evaluation metric. Nevertheless, most of the 526 ˆ = BP(I, I)  1 ˆ exp (1 − I/I) P ˆ Precn (eI1 , eˆI1 ) = w1n if I ≥ Iˆ if I &lt; Iˆ ˆ min{C(w1n |eI1 ), C(w1n |ˆ eI1 )} P w1n C(w1n |eI1 ) Here, C(w1n |eI1 ) denotes the number of occurrences of an n-gram w1n in a sentence eI1 . The denominators of the n-gram precisions e"
D07-1055,P07-2026,1,0.773732,"meters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The pa"
D07-1055,koen-2004-pharaoh,0,0.0375308,"rule is optimal in the sense that any other decision rule will result (on average) in at least as many errors as the MBR rule. Despite this, most SMT systems do not use the MBR decision rule. The most common approach is to use the maximum aposteriori (MAP) decision rule. Thus, we select the hypothesis which maximizes the posterior probability P r(eI1 |f1J ): 525 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Koehn, 2004; Mauser et al., 2006) including the following models: an n-gram language model, a phrase translation model and a wordbased lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty, phrase penalty and a distortion penalty. In the following, we will discuss the so-called training problem (Ney, 2001): how do we train the free parameters λM 1 of the model? The current state-of-the-art is to use minimum error rate training (MERT) as described in (Och, 2003). The free parameters are tuned to directly optimize the evaluation criterio"
D07-1055,N04-1022,0,0.613871,"focus is on the training problem. We will compare a variety of training criteria for statistical machine translation. In particular, we are considering criteria for the log-linear parameters or model scaling factors. We will introduce new training criteria based on maximum likelihood estimation and expected loss computation. We will show that some achieve significantly better results than the standard minimum error rate training of (Och, 2003). Additionally, we will compare two decision rules, the common maximum a-posteriori (MAP) decision rule and the minimum Bayes risk (MBR) decision rule (Kumar and Byrne, 2004). We will show that the minimum Bayes risk decision rule results in better translation quality than the maximum aposteriori decision rule for several training criteria. The remaining part of this paper is structured as follows: first, we will describe related work in Sec. 2. Then, we will briefly review the baseline system, Bayes decision rule for statistical machine translation and automatic evaluation metrics for machine translation in Sec. 3 and Sec. 4, respectively. The novel training criteria are described in Sec. 5 and Sec. 6. Experimental results are reported in Sec. 7 and conclusions a"
D07-1055,C04-1072,0,0.0616683,"n |ˆ eI1 )} P w1n C(w1n |eI1 ) Here, C(w1n |eI1 ) denotes the number of occurrences of an n-gram w1n in a sentence eI1 . The denominators of the n-gram precisions evaluate to the number of n-grams in the hypothesis, i.e. I − n + 1. The n-gram counts for the Bleu score computation are usually collected over a whole document. For our purposes, a sentence-level computation is preferable. A problem with the sentence-level Bleu score is that the score is zero if not at least one fourgram matches. As we would like to avoid this problem, we use the smoothed sentence-level Bleu score as suggested in (Lin and Och, 2004). Thus, we increase the nominator and denominator of Precn (·, ·) by one for n &gt; 1. Note that we will use the sentence-level Bleu score only during training. The evaluation on the development and test sets will be carried out using the standard Bleu score, i.e. at the corpus level. As the MERT baseline does not require the use of the sentence-level Bleu score, we use the standard Bleu score for training the baseline system. In the following, we will describe several criteria for training the log-linear parameters λM 1 of our model. For notational convenience, we assume that there is just one r"
D07-1055,2006.iwslt-evaluation.15,1,0.721706,"al in the sense that any other decision rule will result (on average) in at least as many errors as the MBR rule. Despite this, most SMT systems do not use the MBR decision rule. The most common approach is to use the maximum aposteriori (MAP) decision rule. Thus, we select the hypothesis which maximizes the posterior probability P r(eI1 |f1J ): 525 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Koehn, 2004; Mauser et al., 2006) including the following models: an n-gram language model, a phrase translation model and a wordbased lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty, phrase penalty and a distortion penalty. In the following, we will discuss the so-called training problem (Ney, 2001): how do we train the free parameters λM 1 of the model? The current state-of-the-art is to use minimum error rate training (MERT) as described in (Och, 2003). The free parameters are tuned to directly optimize the evaluation criterion. Except for the MERT"
D07-1055,W01-1405,1,0.91741,"ents over a state-of-the-art minimum error rate training baseline on a large ChineseEnglish translation task. We present novel training criteria based on maximum likelihood estimation and expected loss computation. Additionally, we compare the maximum a-posteriori decision rule and the minimum Bayes risk decision rule. We show that, not only from a theoretical point of view but also in terms of translation quality, the minimum Bayes risk decision rule is preferable. 1 Introduction Once we specified the Bayes decision rule for statistical machine translation, we have to address three problems (Ney, 2001): • the search problem, i.e. how to find the best translation candidate among all possible target language sentences; • the modeling problem, i.e. how to structure the dependencies of source and target language sentences; • the training problem, i.e. how to estimate the free parameters of the models from the training data. Here, the main focus is on the training problem. We will compare a variety of training criteria for statistical machine translation. In particular, we are considering criteria for the log-linear parameters or model scaling factors. We will introduce new training criteria bas"
D07-1055,P02-1038,1,0.703222,"teria. The remaining part of this paper is structured as follows: first, we will describe related work in Sec. 2. Then, we will briefly review the baseline system, Bayes decision rule for statistical machine translation and automatic evaluation metrics for machine translation in Sec. 3 and Sec. 4, respectively. The novel training criteria are described in Sec. 5 and Sec. 6. Experimental results are reported in Sec. 7 and conclusions are given in Sec. 8. 2 Related Work The most common modeling approach in statistical machine translation is to use a log-linear combination of several sub-models (Och and Ney, 2002). In (Och and Ney, 2002), the log-linear weights were tuned to maximize the mutual information criterion (MMI). The current state-of-the-art is to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004)"
D07-1055,P03-1021,0,0.637155,"ies of source and target language sentences; • the training problem, i.e. how to estimate the free parameters of the models from the training data. Here, the main focus is on the training problem. We will compare a variety of training criteria for statistical machine translation. In particular, we are considering criteria for the log-linear parameters or model scaling factors. We will introduce new training criteria based on maximum likelihood estimation and expected loss computation. We will show that some achieve significantly better results than the standard minimum error rate training of (Och, 2003). Additionally, we will compare two decision rules, the common maximum a-posteriori (MAP) decision rule and the minimum Bayes risk (MBR) decision rule (Kumar and Byrne, 2004). We will show that the minimum Bayes risk decision rule results in better translation quality than the maximum aposteriori decision rule for several training criteria. The remaining part of this paper is structured as follows: first, we will describe related work in Sec. 2. Then, we will briefly review the baseline system, Bayes decision rule for statistical machine translation and automatic evaluation metrics for machine"
D07-1055,P02-1040,0,0.109912,"on metrics. In the following, we will briefly review the computation of the Bleu score as some of the training criteria are motivated by this. The Bleu score is a combination of the geometric mean of n-gram precisions and a brevity penalty for too short translation hypotheses. The Bleu score for a translation hypothˆ esis eI1 and a reference translation eˆI1 is computed as: Evaluation Metrics The automatic evaluation of machine translation is currently an active research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation"
D07-1055,N04-1023,0,0.0454727,"Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The parameters are estimated iteratively using an annealing technique that minimizes the risk of an expected-BLEU approximation, which is similar to the one presented in this paper. 3 Baseline System In statistical machine translation, we are given a source language sentence f1J = f"
D07-1055,P06-2101,0,0.397507,"a. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The parameters are estimated iteratively using an annealing technique that minimizes the risk of an expected-BLEU approximation, which is similar to the one presented in this paper. 3 Baseline System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Statistical decision theory tells us that among all possible target language sentences, we should choose the sentence which minimize"
D07-1055,P06-1091,0,0.0247565,"). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The parameters are estimated iteratively using an annealing technique that minimizes the risk of an expected-BLEU approximatio"
D07-1055,2003.mtsummit-papers.51,0,0.0386609,"of the training criteria are motivated by this. The Bleu score is a combination of the geometric mean of n-gram precisions and a brevity penalty for too short translation hypotheses. The Bleu score for a translation hypothˆ esis eI1 and a reference translation eˆI1 is computed as: Evaluation Metrics The automatic evaluation of machine translation is currently an active research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation system. As this is exactly what we will need in our experiments and as Bleu is currently the"
D07-1055,W05-0836,0,0.0251486,"s to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error"
D07-1055,W06-3110,1,0.937433,"to the case of multiple references. (3) 5 5.1 Maximum Likelihood Sentence-Level Computation A popular approach for training parameters is maximum likelihood estimation (MLE). Here, the goal is to maximize the joint likelihood of the parameters and the training data. For log-linear models, this results in a nice optimization criterion which is convex and has a single optimum. It is equivalent to the maximum mutual information (MMI) criterion. We obtain the following training criterion: I J FM L−N (λM 1 , (e1 , f1 )) = Here, we use the n-gram posterior probability pλM (w1n |f1J ) as defined in (Zens and Ney, 2006). 1 The n-gram posterior distribution is smoothed using a uniform distribution over all possible n-grams. 1 As an alternative to the sentence-level MLE, we performed experiments with an n-gram level MLE. Here, we limit the order of the n-grams and assume conditional independence among the n-gram probabilities. We define the log-likelihood (LLH) of a target language sentence eI1 given a source language sentence f1J as: 527 1 1 1 I J I J FM L−S (λM 1 , (e1 , f1 )) = log pλM (e1 |f1 ) 5.2 N -gram Level Computation log pλM (w1n |f1J ) n=1 wn ∈eI pλM (w1n |f1J ) 1 A problem that we often face in pr"
D12-1089,D07-1090,1,0.269774,"• The 109 -French-English bilingual corpus with about one billion tokens from the Workshop on Statistical Machine Translation (WMT).2 These enormous data sets yield translation models that are expensive to store and process. Even with 1 2 LDC catalog No. LDC2006T13 http://www.statmt.org/wmt11/translation-task.html The most resource-intensive components of a statistical machine translation system are the language model and the phrase table. Recently, compact representations of the language model have attracted the attention of the research community, for instance in Talbot and Osborne (2007), Brants et al. (2007), Pauls and Klein (2011) or Heafield (2011), to name a few. In this paper, we address the other problem of any statistical machine translation system: large phrase tables. Johnson et al. (2007) has shown that large portions of the phrase table can be removed without loss in translation quality. This motivated us to perform a systematic comparison of different pruning methods. However, we found that many existing methods employ ad-hoc heuristics without theoretical foundation. The pruning criterion introduced in this work is inspired by the very successful and still state-of-theart language mod"
D12-1089,J93-2003,0,0.0650262,"ine translation system similar to (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon (Zens et al., 2004). The feature weights were tuned on a development set by applying minimum error rate training (MERT) under the Bleu criterion (Och, 2003; Macherey et al., 2008). We ran MERT once with the full phrase table and then kept the feature weights fixed, i. e., we did not rerun MERT after pruning to avoid adding unnecessary noise. We extract phrases up to a length of six words. The baseline system already includes phrase table pruning by removing singletons and keeping up to 30 target languag"
D12-1089,chen-etal-2008-improving,0,0.0154414,"translation model quality. Furthermore, a comparison to other methods is missing. Here we close this gap and perform a systematic comparison. The same idea of significance-based pruning was exploited in (Yang and Zheng, 2009; Tomeh et al., 2009) for hierarchical statistical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to generate. Duan et al. (2011), Sanchis-Trilles et al. (2011) and Tomeh et al. (2011) modify the phrase extraction methods in order to reduce the phrase table size. The work in this paper is independent of the way the phrase extraction is done, so those approaches are complementary to our work. 3 Pruning Using Simple Statistics In this section, we will review existing pruning"
D12-1089,N09-1015,0,0.139572,"uality. Furthermore, a comparison to other methods is missing. Here we close this gap and perform a systematic comparison. The same idea of significance-based pruning was exploited in (Yang and Zheng, 2009; Tomeh et al., 2009) for hierarchical statistical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to generate. Duan et al. (2011), Sanchis-Trilles et al. (2011) and Tomeh et al. (2011) modify the phrase extraction methods in order to reduce the phrase table size. The work in this paper is independent of the way the phrase extraction is done, so those approaches are complementary to our work. 3 Pruning Using Simple Statistics In this section, we will review existing pruning methods based on sim"
D12-1089,J07-2003,0,0.0368358,"Missing"
D12-1089,2011.mtsummit-papers.20,0,0.15905,"hierarchical statistical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to generate. Duan et al. (2011), Sanchis-Trilles et al. (2011) and Tomeh et al. (2011) modify the phrase extraction methods in order to reduce the phrase table size. The work in this paper is independent of the way the phrase extraction is done, so those approaches are complementary to our work. 3 Pruning Using Simple Statistics In this section, we will review existing pruning methods based on simple phrase table statistics. There are two common classes of these methods: absolute phrase table pruning and relative phrase table pruning. 3.1 Absolute pruning Absolute pruning methods rely only on the statistics of a single phra"
D12-1089,2007.mtsummit-papers.22,0,0.303356,"t large parts of the phrase table can be removed without affecting translation quality. Their pruning criterion relies on statistical significance tests. However, it is unclear how this significance-based pruning criterion is related to translation model quality. Furthermore, a comparison to other methods is missing. Here we close this gap and perform a systematic comparison. The same idea of significance-based pruning was exploited in (Yang and Zheng, 2009; Tomeh et al., 2009) for hierarchical statistical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to generate. Duan et al. (2011), Sanchis-Trilles et al. (2011) and Tomeh et al. (2011) modify the phrase extraction methods in order to reduce"
D12-1089,N07-2006,0,0.486677,"Missing"
D12-1089,W11-2123,0,0.0225503,"about one billion tokens from the Workshop on Statistical Machine Translation (WMT).2 These enormous data sets yield translation models that are expensive to store and process. Even with 1 2 LDC catalog No. LDC2006T13 http://www.statmt.org/wmt11/translation-task.html The most resource-intensive components of a statistical machine translation system are the language model and the phrase table. Recently, compact representations of the language model have attracted the attention of the research community, for instance in Talbot and Osborne (2007), Brants et al. (2007), Pauls and Klein (2011) or Heafield (2011), to name a few. In this paper, we address the other problem of any statistical machine translation system: large phrase tables. Johnson et al. (2007) has shown that large portions of the phrase table can be removed without loss in translation quality. This motivated us to perform a systematic comparison of different pruning methods. However, we found that many existing methods employ ad-hoc heuristics without theoretical foundation. The pruning criterion introduced in this work is inspired by the very successful and still state-of-theart language model pruning criterion based on entropy measu"
D12-1089,D07-1103,0,0.871256,"e expensive to store and process. Even with 1 2 LDC catalog No. LDC2006T13 http://www.statmt.org/wmt11/translation-task.html The most resource-intensive components of a statistical machine translation system are the language model and the phrase table. Recently, compact representations of the language model have attracted the attention of the research community, for instance in Talbot and Osborne (2007), Brants et al. (2007), Pauls and Klein (2011) or Heafield (2011), to name a few. In this paper, we address the other problem of any statistical machine translation system: large phrase tables. Johnson et al. (2007) has shown that large portions of the phrase table can be removed without loss in translation quality. This motivated us to perform a systematic comparison of different pruning methods. However, we found that many existing methods employ ad-hoc heuristics without theoretical foundation. The pruning criterion introduced in this work is inspired by the very successful and still state-of-theart language model pruning criterion based on entropy measures (Stolcke, 1998). We motivate its derivation by stating the desiderata for a good phrase table pruning criterion: • Soundness: The criterion should"
D12-1089,N03-1017,0,0.0121617,"65 M 232 M 210 M 962 M 827 M 20 18 16 14 Table 3: Training data statistics. Number of words in the training data (M=millions). 12 Prob Thres Hist 10 8 1 • French-English For each pair, we train two separate system, one for each direction. Thus it can happen that a phrase is pruned for X-to-Y, but not for Y-to-X. These four language pairs represent a nice range of training corpora sizes, as shown in Table 3. 6.2 Baseline System Pruning experiments were performed on top of the following baseline system. We used a phrasebased statistical machine translation system similar to (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel e"
D12-1089,P07-2045,1,0.0199804,"are commonly deficient in at least one of them. We thus designed a novel pruning criterion that not only meets these objectives, it also performs very well in empirical evaluations. The novel contributions of this paper are: 1. a systematic description of existing phrase table pruning methods. 2. a new, theoretically sound phrase table pruning criterion. 3. an experimental comparison of several pruning methods for several language pairs. 2 Related Work The most basic pruning methods rely on probability and count cutoffs. We will cover the techniques that are implemented in the Moses toolkit (Koehn et al., 2007) and the Pharaoh decoder (Koehn, 2004) in Section 3. We are not aware of any work that analyzes their efficacy in a systematic way. It is thus not surprising that some of them perform poorly, as our experimental results will show. The work of Johnson et al. (2007) is promising as it shows that large parts of the phrase table can be removed without affecting translation quality. Their pruning criterion relies on statistical significance tests. However, it is unclear how this significance-based pruning criterion is related to translation model quality. Furthermore, a comparison to other methods"
D12-1089,koen-2004-pharaoh,0,0.0554099,"em. We thus designed a novel pruning criterion that not only meets these objectives, it also performs very well in empirical evaluations. The novel contributions of this paper are: 1. a systematic description of existing phrase table pruning methods. 2. a new, theoretically sound phrase table pruning criterion. 3. an experimental comparison of several pruning methods for several language pairs. 2 Related Work The most basic pruning methods rely on probability and count cutoffs. We will cover the techniques that are implemented in the Moses toolkit (Koehn et al., 2007) and the Pharaoh decoder (Koehn, 2004) in Section 3. We are not aware of any work that analyzes their efficacy in a systematic way. It is thus not surprising that some of them perform poorly, as our experimental results will show. The work of Johnson et al. (2007) is promising as it shows that large parts of the phrase table can be removed without affecting translation quality. Their pruning criterion relies on statistical significance tests. However, it is unclear how this significance-based pruning criterion is related to translation model quality. Furthermore, a comparison to other methods is missing. Here we close this gap and"
D12-1089,D08-1076,0,0.0173581,"l language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon (Zens et al., 2004). The feature weights were tuned on a development set by applying minimum error rate training (MERT) under the Bleu criterion (Och, 2003; Macherey et al., 2008). We ran MERT once with the full phrase table and then kept the feature weights fixed, i. e., we did not rerun MERT after pruning to avoid adding unnecessary noise. We extract phrases up to a length of six words. The baseline system already includes phrase table pruning by removing singletons and keeping up to 30 target language phrases per source phrase. We found that this does not affect transla977 2 4 Number of Phrases [millions] 8 Figure 1: Comparison of probability-based pruning methods for German-English. tion quality significantly4 . All pruning experiments are done on top of this. 6.3"
D12-1089,W04-3243,0,0.0373733,"ility of the contingency table via the hypergeometric distribution:     N (f˜) N −N (f˜) · N (f˜,˜ e) N (˜ e)−N (f˜,˜ e)   ph (N (f˜, e˜)) = (4) N N (˜ e) The p-value is then calculated as the sum of all probabilities that are at least as extreme. The lower the p-value, the less likely this phrase pair occurred with the observed frequency by chance; we thus prune a phrase pair (f˜, e˜) if:   ∞ X  ph (k) &gt; τF (5) k=N (f˜,˜ e) for some pruning threshold τF . More details of this approach can be found in Johnson et al. (2007). The idea of using Fisher’s exact test was first explored by Moore (2004) in the context of word alignment. 5 In this section, we will derive a novel entropy-based pruning criterion. 5.1 Significance Pruning In this section, we briefly review significance pruning following Johnson et al. (2007). The idea of significance pruning is to test whether a source phrase f˜ and a target phrase e˜ co-occur more frequently in a bilingual corpus than they should just by chance. Using some simple statistics derived from the bilingual corpus, namely • N (f˜) the count of the source phrase f˜ • N (˜ e) the count of the target phrase e˜ • N (f˜, e˜) the co-occurence count of the s"
D12-1089,J04-4002,0,0.0312374,"2 M 827 M 20 18 16 14 Table 3: Training data statistics. Number of words in the training data (M=millions). 12 Prob Thres Hist 10 8 1 • French-English For each pair, we train two separate system, one for each direction. Thus it can happen that a phrase is pruned for X-to-Y, but not for Y-to-X. These four language pairs represent a nice range of training corpora sizes, as shown in Table 3. 6.2 Baseline System Pruning experiments were performed on top of the following baseline system. We used a phrasebased statistical machine translation system similar to (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using"
D12-1089,P03-1021,0,0.0216351,"ws data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon (Zens et al., 2004). The feature weights were tuned on a development set by applying minimum error rate training (MERT) under the Bleu criterion (Och, 2003; Macherey et al., 2008). We ran MERT once with the full phrase table and then kept the feature weights fixed, i. e., we did not rerun MERT after pruning to avoid adding unnecessary noise. We extract phrases up to a length of six words. The baseline system already includes phrase table pruning by removing singletons and keeping up to 30 target language phrases per source phrase. We found that this does not affect transla977 2 4 Number of Phrases [millions] 8 Figure 1: Comparison of probability-based pruning methods for German-English. tion quality significantly4 . All pruning experiments are d"
D12-1089,P02-1040,0,0.103712,"of six words. The baseline system already includes phrase table pruning by removing singletons and keeping up to 30 target language phrases per source phrase. We found that this does not affect transla977 2 4 Number of Phrases [millions] 8 Figure 1: Comparison of probability-based pruning methods for German-English. tion quality significantly4 . All pruning experiments are done on top of this. 6.3 Results In this section, we present the experimental results. Translation results are reported on the WMT’07 news commentary blind set. We will show translation quality measured with the Bleu score (Papineni et al., 2002) as a function of the phrase table size (number of phrases). Being in the upper left corner of these figures is desirable. First, we show a comparison of several probability-based pruning methods in Figure 1. We compare • Prob. Absolute pruning based on Eq. (2). • Thres. Threshold pruning based on Eq. (3). • Hist. Histogram pruning as described in Section 3.2.5 We observe that these three methods perform equally well. There is no difference between absolute and relative pruning methods, except that the two relative methods (Thres and Hist) are limited by 4 The Bleu score drops are as follows:"
D12-1089,P11-1027,0,0.00914444,"lish bilingual corpus with about one billion tokens from the Workshop on Statistical Machine Translation (WMT).2 These enormous data sets yield translation models that are expensive to store and process. Even with 1 2 LDC catalog No. LDC2006T13 http://www.statmt.org/wmt11/translation-task.html The most resource-intensive components of a statistical machine translation system are the language model and the phrase table. Recently, compact representations of the language model have attracted the attention of the research community, for instance in Talbot and Osborne (2007), Brants et al. (2007), Pauls and Klein (2011) or Heafield (2011), to name a few. In this paper, we address the other problem of any statistical machine translation system: large phrase tables. Johnson et al. (2007) has shown that large portions of the phrase table can be removed without loss in translation quality. This motivated us to perform a systematic comparison of different pruning methods. However, we found that many existing methods employ ad-hoc heuristics without theoretical foundation. The pruning criterion introduced in this work is inspired by the very successful and still state-of-theart language model pruning criterion bas"
D12-1089,2011.eamt-1.35,0,0.125555,"ical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to generate. Duan et al. (2011), Sanchis-Trilles et al. (2011) and Tomeh et al. (2011) modify the phrase extraction methods in order to reduce the phrase table size. The work in this paper is independent of the way the phrase extraction is done, so those approaches are complementary to our work. 3 Pruning Using Simple Statistics In this section, we will review existing pruning methods based on simple phrase table statistics. There are two common classes of these methods: absolute phrase table pruning and relative phrase table pruning. 3.1 Absolute pruning Absolute pruning methods rely only on the statistics of a single phrase pair (f˜, e˜). Hence, they a"
D12-1089,D07-1049,0,0.011536,"rillion words of web data.1 • The 109 -French-English bilingual corpus with about one billion tokens from the Workshop on Statistical Machine Translation (WMT).2 These enormous data sets yield translation models that are expensive to store and process. Even with 1 2 LDC catalog No. LDC2006T13 http://www.statmt.org/wmt11/translation-task.html The most resource-intensive components of a statistical machine translation system are the language model and the phrase table. Recently, compact representations of the language model have attracted the attention of the research community, for instance in Talbot and Osborne (2007), Brants et al. (2007), Pauls and Klein (2011) or Heafield (2011), to name a few. In this paper, we address the other problem of any statistical machine translation system: large phrase tables. Johnson et al. (2007) has shown that large portions of the phrase table can be removed without loss in translation quality. This motivated us to perform a systematic comparison of different pruning methods. However, we found that many existing methods employ ad-hoc heuristics without theoretical foundation. The pruning criterion introduced in this work is inspired by the very successful and still state-"
D12-1089,2009.mtsummit-papers.17,0,0.54556,"g that some of them perform poorly, as our experimental results will show. The work of Johnson et al. (2007) is promising as it shows that large parts of the phrase table can be removed without affecting translation quality. Their pruning criterion relies on statistical significance tests. However, it is unclear how this significance-based pruning criterion is related to translation model quality. Furthermore, a comparison to other methods is missing. Here we close this gap and perform a systematic comparison. The same idea of significance-based pruning was exploited in (Yang and Zheng, 2009; Tomeh et al., 2009) for hierarchical statistical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to gener"
D12-1089,2011.iwslt-papers.10,0,0.248205,"fferent approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or would be costly to generate. Duan et al. (2011), Sanchis-Trilles et al. (2011) and Tomeh et al. (2011) modify the phrase extraction methods in order to reduce the phrase table size. The work in this paper is independent of the way the phrase extraction is done, so those approaches are complementary to our work. 3 Pruning Using Simple Statistics In this section, we will review existing pruning methods based on simple phrase table statistics. There are two common classes of these methods: absolute phrase table pruning and relative phrase table pruning. 3.1 Absolute pruning Absolute pruning methods rely only on the statistics of a single phrase pair (f˜, e˜). Hence, they are independent of other"
D12-1089,C96-2141,0,0.185429,"., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon (Zens et al., 2004). The feature weights were tuned on a development set by applying minimum error rate training (MERT) under the Bleu criterion (Och, 2003; Macherey et al., 2008). We ran MERT once with the full phrase table and then kept the feature weights fixed, i. e., we did not rerun MERT after pruning to avoid adding unnecessary noise. We extract phrases up to a length of six words. The baseline system already includes phrase table pruning by removing singletons and keeping up to 30 target language phrases per source phrase. We found that this does not affect t"
D12-1089,P09-2060,0,0.0457469,"is thus not surprising that some of them perform poorly, as our experimental results will show. The work of Johnson et al. (2007) is promising as it shows that large parts of the phrase table can be removed without affecting translation quality. Their pruning criterion relies on statistical significance tests. However, it is unclear how this significance-based pruning criterion is related to translation model quality. Furthermore, a comparison to other methods is missing. Here we close this gap and perform a systematic comparison. The same idea of significance-based pruning was exploited in (Yang and Zheng, 2009; Tomeh et al., 2009) for hierarchical statistical machine translation. 973 A different approach to phrase table pruning was undertaken by Eck et al. (2007a; 2007b). They rely on usage statistics from translating sample data, so it is not self-contained. However, it could be combined with the methods proposed here. Another approach to phrase table pruning is triangulation (Chen et al., 2008; Chen et al., 2009). This requires additional bilingual corpora, namely from the source language as well as from the target language to a third bridge language. In many situations this does not exist or wou"
D12-1089,W06-3108,1,0.466934,"erformed on top of the following baseline system. We used a phrasebased statistical machine translation system similar to (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon (Zens et al., 2004). The feature weights were tuned on a development set by applying minimum error rate training (MERT) under the Bleu criterion (Och, 2003; Macherey et al., 2008). We ran MERT once with the full phrase table and then kept the feature weights fixed, i. e., we did not rerun MERT after pruning to avoid adding unnecessary noise. We extract phrases up to a length of six words. The baseline system already"
D12-1089,2008.iwslt-papers.8,1,0.856044,"14 Table 3: Training data statistics. Number of words in the training data (M=millions). 12 Prob Thres Hist 10 8 1 • French-English For each pair, we train two separate system, one for each direction. Thus it can happen that a phrase is pruned for X-to-Y, but not for Y-to-X. These four language pairs represent a nice range of training corpora sizes, as shown in Table 3. 6.2 Baseline System Pruning experiments were performed on top of the following baseline system. We used a phrasebased statistical machine translation system similar to (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon ("
D12-1089,2002.tmi-tutorials.2,0,0.0380388,"lish 42 M 45 M 56 M 65 M 232 M 210 M 962 M 827 M 20 18 16 14 Table 3: Training data statistics. Number of words in the training data (M=millions). 12 Prob Thres Hist 10 8 1 • French-English For each pair, we train two separate system, one for each direction. Thus it can happen that a phrase is pruned for X-to-Y, but not for Y-to-X. These four language pairs represent a nice range of training corpora sizes, as shown in Table 3. 6.2 Baseline System Pruning experiments were performed on top of the following baseline system. We used a phrasebased statistical machine translation system similar to (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2004; Zens and Ney, 2008). We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alig"
D12-1089,C04-1006,1,0.80557,". We trained a 4gram language model on the target side of the bilingual corpora and a second 4-gram language model on the provided monolingual news data. All language models used Kneser-Ney smoothing. The baseline system uses the common phrase translation models, such as p(˜ e|f˜) and p(f˜|˜ e), lexical models, word and phrase penalty, distortion penalty as well as a lexicalized reordering model (Zens and Ney, 2006). The word alignment was trained with six iterations of IBM model 1 (Brown et al., 1993) and 6 iterations of the HMM alignment model (Vogel et al., 1996) using a symmetric lexicon (Zens et al., 2004). The feature weights were tuned on a development set by applying minimum error rate training (MERT) under the Bleu criterion (Och, 2003; Macherey et al., 2008). We ran MERT once with the full phrase table and then kept the feature weights fixed, i. e., we did not rerun MERT after pruning to avoid adding unnecessary noise. We extract phrases up to a length of six words. The baseline system already includes phrase table pruning by removing singletons and keeping up to 30 target language phrases per source phrase. We found that this does not affect transla977 2 4 Number of Phrases [millions] 8 F"
D18-1374,P15-2030,0,0.018922,"passed through matrix multiplication and a rectified linear unit (RELU) (Nair and Hinton, 2010). Afterwards, the resulting vector is converted into the space of dimensionality equal to the number of entities via an output layer. This way, scores are obtained over the entity space, which are used to choose the highest scored entities for predictions. The loss function is the cross-entropy (CE) between the soft-maxed activations and a uniform distribution over the target entities. XML-CNN Convolutional neural networks (CNNs) have been successfully applied to a range of NLP problems (Kim, 2014; Bitvai and Cohn, 2015). Recently Liu et al. (2017) demonstrated how CNNs can be effective for XML problems. We depict their architecture in Figure 3(b). The input sequence is embedded in V dimensions, and passed through a convolutional layer, a fully connected layer and an output layer. After the convolutional layer the authors employ dynamic pooling which helps retain information about where in the input sequence the convolutions got triggered. The loss function is binary cross entropy (BCE), which considers labels individually rather than jointly. BCE is given by the formula BCE(p, y) = Pj=M j=1 yj log(σ(pj )) +"
D18-1374,D15-1003,0,0.0136495,"n of CG-IDF@k, the normalized cumulative 3374 1. N(C, F ) obtained by putting the raw cooccurrences of the context entity C (corresponding to a row) and the future entity F (corresponding to a column). 2. P(F |C) obtained by normalizing N(C, F ) matrix row-wise. 3. PPMI(C, F ) (positive pointwise mutual information) aims to show how much more likely an entity F is to occur for a context C compared to observing them independently (Jurafsky and Martin, 2000). PPMI is a popular preprocessing step on the co-occurrence matrix before applying dimensionality reduction, such as SVD (see Section 5.2) (Herbelot and Vecchi, 2015). Figure 1: Percentage of documents for which each target entity occurs. 5.2 Figure 2: A heatmap showing what percentage of times a context entity (row) is followed by a particular target entity (column). instance, USA is more likely to be followed by Research than the other way around. 5 Baselines and Models In this section we describe the models that we applied to the entity recommendation problem. 5.1 Linear Models Let us represent input entities via n-hot vector representation, i.e., vector entries corresponding to entities present in the input set are set to one, whereas other entries are"
D18-1374,J00-4006,0,0.01736,"caling to larger output spaces is possible but requires modifications which we leave for future work. 7 j=1 To facilitate interpretability, we use a normalized version of CG-IDF@k, the normalized cumulative 3374 1. N(C, F ) obtained by putting the raw cooccurrences of the context entity C (corresponding to a row) and the future entity F (corresponding to a column). 2. P(F |C) obtained by normalizing N(C, F ) matrix row-wise. 3. PPMI(C, F ) (positive pointwise mutual information) aims to show how much more likely an entity F is to occur for a context C compared to observing them independently (Jurafsky and Martin, 2000). PPMI is a popular preprocessing step on the co-occurrence matrix before applying dimensionality reduction, such as SVD (see Section 5.2) (Herbelot and Vecchi, 2015). Figure 1: Percentage of documents for which each target entity occurs. 5.2 Figure 2: A heatmap showing what percentage of times a context entity (row) is followed by a particular target entity (column). instance, USA is more likely to be followed by Research than the other way around. 5 Baselines and Models In this section we describe the models that we applied to the entity recommendation problem. 5.1 Linear Models Let us repre"
D18-1374,D14-1181,0,0.00491557,"t vector is passed through matrix multiplication and a rectified linear unit (RELU) (Nair and Hinton, 2010). Afterwards, the resulting vector is converted into the space of dimensionality equal to the number of entities via an output layer. This way, scores are obtained over the entity space, which are used to choose the highest scored entities for predictions. The loss function is the cross-entropy (CE) between the soft-maxed activations and a uniform distribution over the target entities. XML-CNN Convolutional neural networks (CNNs) have been successfully applied to a range of NLP problems (Kim, 2014; Bitvai and Cohn, 2015). Recently Liu et al. (2017) demonstrated how CNNs can be effective for XML problems. We depict their architecture in Figure 3(b). The input sequence is embedded in V dimensions, and passed through a convolutional layer, a fully connected layer and an output layer. After the convolutional layer the authors employ dynamic pooling which helps retain information about where in the input sequence the convolutions got triggered. The loss function is binary cross entropy (BCE), which considers labels individually rather than jointly. BCE is given by the formula BCE(p, y) = Pj"
D18-1374,P18-1223,0,0.0614246,"Missing"
E03-1032,J90-2002,0,0.139099,"will present some results. Finally, we will describe the implemented prototype system. 2 Statistical Machine Translation We are given a source language ('French') sentence = f3 . . . ff, which is to be translated into a target language ( 'English') sentence ef = e l ... 6, ... el-. Among all possible target language sentences, we will choose the sentence of unknown length / with the highest probability: = argmax {Pr (ei f )} (1) argmax {Pr (e)) • Pr(fil lef)} (2) The decomposition into two knowledge sources in Eq. 2 is the so-called source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model Pr (ef ) and translation model Pr(filef)- The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Here, we maximize over all possible target language sentences. 3 Interactive Machine Translation In a statistical approach, the problem of finding an extension ef+1 of a given prefix 61 can be described"
E03-1032,C96-1067,0,0.600538,"n such an environment, the main goal of the machine translation system is not to produce translations that are understandable for an inexperienced recipient but to support a professional human posteditor. Typically, a better quality of the produced machine translation text yields a reduced post-editing effort. From an application point of view, many additional aspects have to be considered: the user interface, the used formats and the additional support tools such as lexicons, terminological databases or translation memories. The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine tr"
E03-1032,1997.mtsummit-papers.1,0,0.757582,"ranslation memories. The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine translation system and a text editor into a single application. The human translator types the translation of a given source text. For each prefix of a word, the machine translation system computes the most probable extension of this word and presents this to the user. The human translator either accepts this translation by press387 ing a certain key or ignores the suggestion and continues typing. Rather than single-word predictions, as in the TransType approach, it is preferable that the suggested extensio"
E03-1032,W02-1020,0,0.173018,"n. The server performs the actual translations as well as all time-consuming operations such as computing the extensions. The client includes only the user interface and can therefore run on a small computer. Client and server are connected via Internet or Intranet. There is ongoing research to experimentally study the productivity gain of such a system for professional human translators. 9 Related Work As already mentioned, previous work towards interactive machine translation has been carried out in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). In (Foster et al., 2002) a so-called ""user model"" has been introduced to maximize the expected benefit of the human translator. This user model consists of two components. The first component models the benefit of a certain extension. The second component models the acceptance probability of this extension. The user model is used to determine the length of the proposed extension measured in characters. The resulting decision rule is more centered on the human user than the one in Eq. 3. It takes into account, e.g., the time the user needs to read the extension (at least approximatively). In principle, the decision ru"
E03-1032,W00-0507,0,0.482506,"The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine translation system and a text editor into a single application. The human translator types the translation of a given source text. For each prefix of a word, the machine translation system computes the most probable extension of this word and presents this to the user. The human translator either accepts this translation by press387 ing a certain key or ignores the suggestion and continues typing. Rather than single-word predictions, as in the TransType approach, it is preferable that the suggested extension consists of multiple w"
E03-1032,W99-0604,1,0.231989,"ciency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr Cf by introducing two hidden variables z and a fc for the K alignment templates and the alignment of the alignment temnode S (n): plates: Pr(fiilef) = E Pr(af"
E03-1032,W02-1021,1,0.618849,"larger than a fraction of a second is not acceptable. The search algorithms developed so far are not able to achieve this efficiency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr Cf by introducing two hidden variabl"
N04-1033,J90-2002,0,0.660544,"rforms the alignment template system. 1 m=1 Introduction In statistical machine translation, we are given a source language (‘French’) sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language (‘English’) sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ª © (1) eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 . The target language 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ) ( M X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 m=1 This approach is a generalization of the source-channel approach. It has the adv"
N04-1033,N03-1017,0,0.219939,"ven for sentences of thirty words, the translation takes only about 1.5 seconds. Recently, phrase-based translation approaches became more and more popular. Some examples are the alignment template system in (Och et al., 1999; Och and Ney, 2002) that we used for comparison. In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work. (Marcu and Wong, 2002) presents a joint probability model for phrase-based translation. It does not use the word alignment for extracting the phrases, but directly generates a phrase alignment. In (Koehn et al., 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length. (Tomas and Casacuberta, 2003) describes a linear interpolation of a phrase-based and an alignment template-based approach. 10 Conclusions We described a phrase-based translation approach. The basic idea of this approach is to remember all bilingual phrases that have been seen in the word-aligned training corpus. As refinements of the baseline model, we described two simple heuristics: the word penalty feature and the phrase penalty featur"
N04-1033,W02-1018,0,0.0518119,"sentence as a function of the sentence length. The translation times were measured for the translation of the 5432 test sentences of the Canadian Hansards task. We see a clear linear dependency. Even for sentences of thirty words, the translation takes only about 1.5 seconds. Recently, phrase-based translation approaches became more and more popular. Some examples are the alignment template system in (Och et al., 1999; Och and Ney, 2002) that we used for comparison. In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work. (Marcu and Wong, 2002) presents a joint probability model for phrase-based translation. It does not use the word alignment for extracting the phrases, but directly generates a phrase alignment. In (Koehn et al., 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length. (Tomas and Casacuberta, 2003) describes a linear interpolation of a phrase-based and an alignment template-based approach. 10 Conclusions We described a phrase-based translation approach. The basic idea of this approach is to remember all bilingua"
N04-1033,P02-1038,1,0.816091,"iversity {zens,ney}@cs.rwth-aachen.de Abstract model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. It can be further decomposed into alignment and lexicon model. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model (Och and Ney, 2002), we obtain: Ã M ! X P r(eI1 |f1J ) = exp λm hm (eI1 , f1J ) · Z(f1J ) In statistical machine translation, the currently best performing systems are based in some way on phrases or word groups. We describe the baseline phrase-based translation system and various refinements. We describe a highly efficient monotone search algorithm with a complexity linear in the input sentence length. We present translation results for three tasks: Verbmobil, Xerox and the Canadian Hansards. For the Xerox task, it takes less than 7 seconds to translate the whole test set consisting of more than 10K words. The"
N04-1033,W99-0604,1,0.730051,"anslation approach, this disambiguation is addressed by the language model only, which is often not capable of doing this. One way to incorporate the context into the translation model is to learn translations for whole phrases instead of single words. Here, a phrase is simply a sequence of words. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. 2.2 P r(f˜1K |˜ eK 1 ) This criterion is identical to the alignment template criterion described in (Och et al., 1999). It means that two phrases are considered to be translations of each other, if the words are aligned only within the phrase pair and not to words outside. The phrases have to be contiguous. Translation Model To use phrases in the translation model, we introduce the hidden variable S. This is a segmentation of the sentence pair (f1J ; eI1 ) into K phrases (f˜1K ; e˜K 1 ). We use a one-toone phrase alignment, i.e. one source phrase is translated by exactly one target phrase. Thus, we obtain: X P r(f1J |eI1 ) = P r(f1J , S|eI1 ) (3) S = S ≈ P r(S|eI1 ) · P r(f1J |S, eI1 ) (4) n o eK ) (5) max P"
N04-1033,P03-1021,0,0.320919,"ributions, we use the generic symbol p(·). Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ) ( M X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 m=1 This approach is a generalization of the source-channel approach. It has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003). The remaining part of this work is structured as follows: in the next section, we will describe the baseline phrase-based translation model and the extraction of bilingual phrases. Then, we will describe refinements of the baseline model. In Section 4, we will describe a monotone search algorithm. Its complexity is linear in the sentence length. The next section contains the statistics of the corpora that were used. Then, we will investigate the degree of monotonicity and present the translation results for three tasks: Verbmobil, Xerox and Canadian Hansards. 2 2.1 Phrase-Based Translation M"
N04-1033,2001.mtsummit-papers.68,0,0.0284051,"erations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2001). BLEU measures accuracy, i.e. large BLEU scores are better. • NIST score: This score is similar to BLEU. It is a weighted ngram precision in combination with a penalty for too short sentences (Doddington, 2002). NIST measures accuracy, i.e. large NIST scores are better. For the Verbmobil task, we have multiple references available. Therefore on this task, we compute all the preceding criteria with respect to multiple references. To indicate this, we will precede the acronyms with an m (multiple) if multiple references are used. For the other two tasks, only single references are used. 7.2 Tra"
N04-1033,J03-1005,1,0.50875,"from left to right. The second variant allows reordering according to the so-called IBM constraints (Berger et al., 1996). Thus up to three words may be skipped and translated later. This system will be denoted by IBM. The third variant implements special German-English reordering constraints. These constraints are represented by a finite state automaton and optimized to handle the reorderings of the German verb group. The abbreviation for this variant is GE. It is only used for the German-English Verbmobil task. This is just an extremely brief description of these systems. For details, see (Tillmann and Ney, 2003). Phrase-Based System (PB). For the phrase-based system, we use the following feature functions: a trigram language model, the phrase translation model and the word-based lexicon model. The latter two feature functions are used for both directions: p(f |e) and p(e|f ). Additionally, we use the word and phrase penalty feature functions. The model scaling factors are optimized on the development corpus with respect to mWER similar to (Och, 2003). We use the Downhill Simplex algorithm from (Press et al., 2002). We do not perform the optimization on N -best lists but we retranslate the whole devel"
N04-1033,2002.tmi-tutorials.2,0,0.0328015,"large test corpus size for this task also affects the translation speed. In Fig. 1, we see the average translation time per sentence as a function of the sentence length. The translation times were measured for the translation of the 5432 test sentences of the Canadian Hansards task. We see a clear linear dependency. Even for sentences of thirty words, the translation takes only about 1.5 seconds. Recently, phrase-based translation approaches became more and more popular. Some examples are the alignment template system in (Och et al., 1999; Och and Ney, 2002) that we used for comparison. In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work. (Marcu and Wong, 2002) presents a joint probability model for phrase-based translation. It does not use the word alignment for extracting the phrases, but directly generates a phrase alignment. In (Koehn et al., 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length. (Tomas and Casacuberta, 2003) describes a linear interpolation of a phrase-based and an alignment template-based approac"
N04-1033,P02-1040,0,\N,Missing
N07-1062,P05-1032,0,0.102916,"this combinatorial problem exploiting the prefix tree data structure of the phrase-table. This algorithm enables the use of significantly larger input word graphs in a more efficient way resulting in improved translation quality. The remaining part is structured as follows: we will first discuss related work in Sec. 2. Then, in Sec. 3, we will describe the phrase-table representation. Afterwards, we will present applications in speech translation and online MT in Sec. 4 and 5, respectively. Experimental results will be presented in Sec. 6 followed by the conclusions in Sec. 7. 2 Related Work (Callison-Burch et al., 2005) and (Zhang and Vogel, 2005) presented data structures for a compact representation of the word-aligned bilingual data, such that on-the-fly extraction of long phrases is possible. The motivation in (Callison-Burch et al., 2005) is that there are some long source phrases in the test data that also occur in the training data. However, the more interesting question is if these long phrases really help to improve the translation quality. We have investigated this and our results are in line with (Koehn et al., 2003) showing that the translation quality does not improve if we utilize phrases beyon"
N07-1062,P05-1033,0,0.0186306,"ively expensive beforehand. This results in more efficient decoding and improved translation quality. We have shown that this data structure scales very well to large data tasks like the Chinese-English NIST task. The implementation of the described data structure as well as the phrase-match algorithm for confusion networks is available as open source software in the MOSES toolkit1 . Not only standard phrase-based systems can benefit from this data structure. It should be rather straightforward to apply this data structure as well as the phrase-match algorithm to the hierarchical approach of (Chiang, 2005). As the number of rules in this approach is typically larger than the number of phrases in a standard phrase-based system, the gains should be even larger. The language model is another model with high memory requirements. It would be interesting to investigate if the described techniques and data structures are applicable for reducing the memory requirements of language models. Some aspects of the phrase-match algorithm are similar to the composition of finite-state automata. An efficient implementation of on-demand loading (not only on-demand computation) for a 1 http://www.statmt.org/moses"
N07-1062,N03-1017,0,0.00902819,"esented in Sec. 6 followed by the conclusions in Sec. 7. 2 Related Work (Callison-Burch et al., 2005) and (Zhang and Vogel, 2005) presented data structures for a compact representation of the word-aligned bilingual data, such that on-the-fly extraction of long phrases is possible. The motivation in (Callison-Burch et al., 2005) is that there are some long source phrases in the test data that also occur in the training data. However, the more interesting question is if these long phrases really help to improve the translation quality. We have investigated this and our results are in line with (Koehn et al., 2003) showing that the translation quality does not improve if we utilize phrases beyond a certain length. Furthermore, the suffix array data structure of (Callison-Burch et al., 2005) requires a fair amount of memory, about 2 GB in their example, whereas our implementation will use only a tiny amount of memory, e.g. less than 20 MB for the large Chinese-English NIST task. 3 Efficient Phrase-table Representation In this section, we will describe the proposed representation of the phrase-table. A prefix tree, also called trie, is an ordered tree data structure used to store an associative array wher"
N07-1062,P03-1021,0,0.0164504,"phrase-table is reduced to less than 20 MB using ondemand loading. This makes the MT system usable on devices with limited hardware resources. 6 Experimental Results 6.1 Translation System For the experiments, we use a state-of-the-art phrase-based statistical machine translation system as described in (Zens and Ney, 2004). We use a log-linear combination of several models: a fourgram language model, phrase-based and word-based translation models, word, phrase and distortion penalty and a lexicalized distortion model. The model scaling factors are optimized using minimum error rate training (Och, 2003). 6.2 Empirical Analysis for a Large Data Task In this section, we present an empirical analysis of the described data structure for the large data track of the Chinese-English NIST task. The corpus statistics are shown in Tab. 1. The translation quality is measured using two accuracy measures: the BLEU and the NIST score. Additionally, we use the two error rates: the word error rate (WER) and the position-independent word error rate (PER). These evaluation criteria are computed with respect to four reference translations. In Tab. 2, we present the translation quality as a Table 2: NIST task:"
N07-1062,N04-1033,1,0.83917,"we can avoid the filtering step and directly translate the source sentence. An additional advantage is that we load only small parts of the full phrase-table into memory. This reduces the memory requirements significantly, e.g. for the Chinese– English NIST task, the memory requirement of the phrase-table is reduced to less than 20 MB using ondemand loading. This makes the MT system usable on devices with limited hardware resources. 6 Experimental Results 6.1 Translation System For the experiments, we use a state-of-the-art phrase-based statistical machine translation system as described in (Zens and Ney, 2004). We use a log-linear combination of several models: a fourgram language model, phrase-based and word-based translation models, word, phrase and distortion penalty and a lexicalized distortion model. The model scaling factors are optimized using minimum error rate training (Och, 2003). 6.2 Empirical Analysis for a Large Data Task In this section, we present an empirical analysis of the described data structure for the large data track of the Chinese-English NIST task. The corpus statistics are shown in Tab. 1. The translation quality is measured using two accuracy measures: the BLEU and the NI"
N07-1062,2005.eamt-1.39,0,0.149157,"ing the prefix tree data structure of the phrase-table. This algorithm enables the use of significantly larger input word graphs in a more efficient way resulting in improved translation quality. The remaining part is structured as follows: we will first discuss related work in Sec. 2. Then, in Sec. 3, we will describe the phrase-table representation. Afterwards, we will present applications in speech translation and online MT in Sec. 4 and 5, respectively. Experimental results will be presented in Sec. 6 followed by the conclusions in Sec. 7. 2 Related Work (Callison-Burch et al., 2005) and (Zhang and Vogel, 2005) presented data structures for a compact representation of the word-aligned bilingual data, such that on-the-fly extraction of long phrases is possible. The motivation in (Callison-Burch et al., 2005) is that there are some long source phrases in the test data that also occur in the training data. However, the more interesting question is if these long phrases really help to improve the translation quality. We have investigated this and our results are in line with (Koehn et al., 2003) showing that the translation quality does not improve if we utilize phrases beyond a certain length. Furtherm"
N07-2015,2006.iwslt-evaluation.7,0,0.0281587,"f n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moderate success. Although complex models, such as features based on shallow parsing or treebank-based syntactic analyses, were applied to the n-best candidates, the “simpler” ones were more promising (e.g. IBM model 1 on sentence-level). In the following section 2, we describe our SMT system and explain how an improved n-best extraction method is capable of generating a very large number of distinct candidates from the word graph. In section 3, we show our experiments related to n-best list reranking with various sizes and the"
N07-2015,N03-1017,0,0.0040397,"l machine translation (SMT). We present a method that allows for fast extraction of very large n-best lists based on the k shortest paths algorithm by (Eppstein, 1998). We will argue that, despite being able to generate a much larger amount of hypotheses than previously reported in the literature, there is no significant gain of such a method in terms of translation quality. In recent years, phrase-based approaches evolved as the dominating method for feasible machine translation systems. Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al., 2003). As a by-product of the decoding process, one can extract n-best translations from a word graph and use these fully generated hypotheses for additional reranking. In the past, several groups report on using n-best lists with n ranging from 1 000 to 10 000. The advantage of n-best reranking is clear: we can apply Related work The idea of n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a"
N07-2015,2006.iwslt-evaluation.15,1,0.888483,"Missing"
N07-2015,N04-1021,0,0.0748485,"ed in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moderate success. Although complex models, such as features based on shallow parsing or treebank-based syntactic analyses, were applied to the n-best candidates, the “simpler” ones were more promising (e.g. IBM model 1 on sentence-level). In the following section 2, we describe our SMT system and explain how an improved n-best extraction method is capable of generating a very large number of distinct candidates from the word graph. In section 3, we show our experiments related to n-best list reranking with various sizes and the corresponding performance in terms of MT evaluation measures"
N07-2015,W02-1021,1,0.842256,"as the dominating method for feasible machine translation systems. Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al., 2003). As a by-product of the decoding process, one can extract n-best translations from a word graph and use these fully generated hypotheses for additional reranking. In the past, several groups report on using n-best lists with n ranging from 1 000 to 10 000. The advantage of n-best reranking is clear: we can apply Related work The idea of n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moder"
N07-2015,W05-0834,1,0.945714,"or feasible machine translation systems. Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al., 2003). As a by-product of the decoding process, one can extract n-best translations from a word graph and use these fully generated hypotheses for additional reranking. In the past, several groups report on using n-best lists with n ranging from 1 000 to 10 000. The advantage of n-best reranking is clear: we can apply Related work The idea of n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moderate success. Although com"
P03-1019,J90-2002,0,0.238007,"Missing"
P03-1019,J99-4005,0,0.130616,"Missing"
P03-1019,niessen-etal-2000-evaluation,1,0.15214,"m number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the target sentence. • PER (position-independent word error rate): A shortcoming of the WER is the fact that it requires a perfect word order. The PER compares the words in the two sentences ignoring the word order. • mWER (multi-reference word error rate): For each test sentence, not only a single reference translation is used, as for the WER, but a whole set of reference translations. For each translation hypothesis, the WER to the most similar sentence is calculated (Nießen et al., 2000). • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences (Papineni et al., 2001). BLEU measures accuracy, i.e. large BLEU scores are better. • SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary. Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000). 6.2 Translation Results In this section, we will present the translation results f"
P03-1019,P00-1056,1,0.168114,"Missing"
P03-1019,W02-1021,1,0.213289,"ry size of the target language. 3.2 Pruning Although the described search algorithm has a polynomial-time complexity, even with a bigram language model the search space is very large. A full search is possible but time consuming. The situation gets even worse when a trigram language model is used. Therefore, pruning techniques are obligatory to reduce the translation time. Pruning is applied to hypotheses that translate the same subsequence fjjlr of the source sentence. We Generation of Word Graphs The generation of word graphs for a bottom-top search with the IBM constraints is described in (Ueffing et al., 2002). These methods cannot be applied to the CYK-style search for the ITG constraints. Here, the idea for the generation of word graphs is the following: assuming we already have jr word graphs for the source sequences fjkl and fk+1 , then we can construct a word graph for the sequence fjjlr by concatenating the partial word graphs either in monotone or inverted order. Now, we describe this idea in a more formal way. A word graph is a directed acyclic graph (dag) with one start and one end node. The edges are annotated with target language words or phrases. We also allow -transitions. These are e"
P03-1019,P02-1038,1,0.0852491,"s Statistics In the following sections we will present results on two tasks. Therefore, in this section we will show the corpus statistics for each of these tasks. 4.1 Verbmobil The first task we will present results on is the Verbmobil task (Wahlster, 2000). The domain of this corpus is appointment scheduling, travel planning, and hotel reservation. It consists of transcriptions of spontaneous speech. Table 2 shows the corpus statistics of this corpus. The training corpus (Train) was used to train the IBM model parameters. The remaining free parameters, i.e. pm and the model scaling factors (Och and Ney, 2002), were adjusted on the development corpus (Dev). The resulting system was evaluated on the test corpus (Test). 3.4 Extended ITG constraints In this section, we will extend the ITG constraints described in Sec. 2.1. This extension will go beyond basic reordering constraints. We already mentioned that the use of consecutive phrases within the ITG approach is straightforward. The only thing we have to change is the initialization of the Q-table. Now, we will extend this idea to phrases that are non-consecutive in the source language. For this purpose, we adopt the view of the ITG constraints as a"
P03-1019,2001.mtsummit-papers.68,0,0.0144805,"the WER is the fact that it requires a perfect word order. The PER compares the words in the two sentences ignoring the word order. • mWER (multi-reference word error rate): For each test sentence, not only a single reference translation is used, as for the WER, but a whole set of reference translations. For each translation hypothesis, the WER to the most similar sentence is calculated (Nießen et al., 2000). • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences (Papineni et al., 2001). BLEU measures accuracy, i.e. large BLEU scores are better. • SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary. Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000). 6.2 Translation Results In this section, we will present the translation results for both the IBM constraints and the baseline ITG constraints. We used a single-word based search with IBM Model 4. The initialization for the ITG constraints was done with monotone IBM Model 4 translations. So,"
P03-1019,P96-1021,0,0.389257,"possible to translate this verb-group correctly, because the distance between the two parts is too large (more than four words). As we see in the second example, in German the verb of a subordinate clause is placed at the end (“¨ubernachten”). The IBM search is not able to perform the necessary long-range reordering, as it is done with the ITG search. 7 Related Work The ITG constraints were introduced in (Wu, 1995). The applications were, for instance, the segmentation of Chinese character sequences into Chinese “words” and the bracketing of the source sentence into sub-sentential chunks. In (Wu, 1996) the baseline ITG constraints were used for statistical machine translation. The resulting algorithm is similar to the one presented in Sect. 3.1, but here, we use monotone translation hypotheses of the full IBM Model 4 as initialization, whereas in (Wu, 1996) a single-word based lexicon model is used. In (Vilar, 1998) a model similar to Wu’s method was considered. 8 Conclusions We have described the ITG constraints in detail and compared them to the IBM constraints. We draw the following conclusions: especially for long sentences the ITG constraints allow for higher flexibility in word-reorde"
P03-1019,J97-3002,0,0.935426,"is method. A permutation derived by the above method can be represented as a binary tree where the inner nodes are colored either black or white. At black nodes the resulting sequences of the children are inverted. At white nodes they are kept in monotone order. This representation is equivalent to without inversion with inversion target positions 1999). Therefore, we have to restrict the possible reorderings in some way to make the search problem feasible. Here, we will discuss two such constraints in detail. The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997). In the following, we will call these the ITG constraints. The second constraints are the IBM constraints (Berger et al., 1996). In the next section, we will describe these constraints from a theoretical point of view. Then, we will describe the resulting search algorithm and its extension for word graph generation. Afterwards, we will analyze the Viterbi alignments produced during the training of the alignment models. Then, we will compare the translation results when restricting the search to either of these constraints. source positions Figure 1: Illustration of monotone and inverted conca"
P03-1019,P02-1040,0,\N,Missing
P06-2061,E03-1032,1,0.951737,"two works considered two parallel N -best lists, generated by MT and ASR systems, Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). 467 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467–474, c Sydney, July 2006. 2006 Association for Computational Linguistics language model P r(eI1 ), the translation model P r(f1J |eI1 ) and the acoustic model P r(xT1 |eI1 ). Another approach for modeling the posterior probability P r(eI1 |"
P06-2061,P03-1021,0,0.00655466,"the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM 1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT and the ASR systems, the search result of each system will be represented as a large word graph. We consider MT and ASR word graphs as FSA. Then, we are able to use FSA algorithms to integrate MT and ASR word graphs. The FSA implementation of the search allows us to use standard optimized algorithms, e.g. available from an open"
P06-2061,J93-2003,0,0.0146367,"t an appropriate search method for building a real-time prediction engine. In this paper, we study the incorporation of MT models and ASR models using finite-state automata. We also propose some transducers based on MT models for rescoring the ASR word graphs. 1 Related Work The idea of incorporating ASR and MT models was independently initiated by two groups: researchers at IBM (Brown et al., 1994), and researchers involved in the TransTalk project (Dymetman et al., 1994; Brousseau et al., 1995). In (Brown et al., 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al., 1993) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N -best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system where translation models were generated for each source language sentence. The better performing of the two is the N -best rescoring. Recently,"
P06-2061,1997.mtsummit-papers.1,0,0.0577533,"est lists. The other two works considered two parallel N -best lists, generated by MT and ASR systems, Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). 467 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467–474, c Sydney, July 2006. 2006 Association for Computational Linguistics language model P r(eI1 ), the translation model P r(f1J |eI1 ) and the acoustic model P r(xT1 |eI1 ). Another approach for modeling the posterior pr"
P06-2061,P04-1065,1,0.797963,"ch in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT and the ASR systems, the search result of each system will be represented as a large word graph. We consider MT and ASR word graphs as FSA. Then, we are able to use FSA algorithms to integrate MT and ASR word graphs. The FSA implementation of the search allows us to use standard optimized algorithms, e.g. available from an open source toolkit (Kanthak and Ney, 2004). The recognition process is performed in two steps. First, the baseline ASR system generates a word graph in the FSA format for a given utterance xT1 . Second, the translation models rescore each word graph based on the corresponding source language sentence. For each utterance, the decision about the best sentence is made according to the recognition and the translation models. Speech-Enabled CAT Models In a speech-enabled computer-assisted translation system, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 ="
P06-2061,W05-0831,1,0.839149,"icon entry: the input label is a target word e, the output label is a source word f , and the weight is − log p(f |e). The null-emitter transducer, as its name states, emits the null word with a pre-defined probability after each input word. The fertility transducer is also a simple transducer to map zero or several 1. a linear acceptor, i.e. a sequence of nodes with one incoming arc and one outgoing arc, the words of source language text are placed consecutively in the arcs of the acceptor, 2. an acceptor containing possible permutations. To limit the permutations, we used an approach as in (Kanthak et al., 2005). Each of these two acceptors results in different constraints for the generation of the hypotheses. The first acceptor restricts the system to generate exactly the same source language sentence, while the second acceptor forces the system to generate the hypotheses that are a reordered variant of the source language sentence. The experiments conducted do not show any significant difference in the recognition results among the two source language acceptors, except that the second acceptor is much slower than the first acceptor. Therefore, we use the first model in our experiments. Table 4 show"
P06-2061,C96-2141,1,0.674347,"Missing"
P06-2061,N04-1033,1,0.892863,"Missing"
P06-2061,knight-al-onaizan-1998-translation,0,0.021181,"ways: 4.7 Fertility-Based Transducer In (Brown et al., 1993), three alignment models are described that include fertility models, these are IBM Models 3, 4, and 5. The fertility-based alignment models have a more complicated structure than the simple IBM Model 1. The fertility model estimates the probability distribution for aligning multiple source words to a single target word. The fertility model provides the probabilities p(φ|e) for aligning a target word e to φ source words. In this section, we propose a method for rescoring ASR word graphs based on the lexicon and fertility models. In (Knight and Al-Onaizan, 1998), some transducers are described to build a finite-state based translation system. We use the same transducers for rescoring ASR word graphs. Here, we have three transducers: lexicon, null-emitter, and fertility. The lexicon transducer is formed by one node and a number of self loops for each target language word, similar to IBM Model 1 transducer in Section 4.5. On each arc of the lexicon transducer, there is a lexicon entry: the input label is a target word e, the output label is a source word f , and the weight is − log p(f |e). The null-emitter transducer, as its name states, emits the nul"
P06-2061,2005.iwslt-1.20,1,0.88101,"Missing"
P06-2061,P02-1038,1,0.457971,"Each of the terms hm (eI1 , f1J , xT1 ) denotes one of the various models which are involved in the recognition procedure. Each individual model is weighted by its scaling factor λm . As there is no direct dependence between f1J and xT1 , the hm (eI1 , f1J , xT1 ) is in one of these two forms: hm (eI1 , xT1 ) and hm (eI1 , f1J ). Due to the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM 1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT"
P06-2061,C04-1030,1,\N,Missing
P07-2026,J90-2002,0,0.620324,"if eI1 = else 0 e0 I1 Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics as for example the BLEU score. One reason for the popularity of the MAP decision rule might be that, compared to the MBR rule, its computation is simpler. 3.2 Baseline System The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): ˆ = BP(I, I)  1 ˆ exp (1 − I/I) P ˆ Precn (eI1 , eˆI1 ) = w1n 0 (1) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in case of the MAP decision rule during the search process. Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Matusov et al., 2006) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon"
P07-2026,N04-1022,0,0.099366,"ike the BLEU and NIST score that measure precision and fluency of a given translation hypothesis. 101 The remaining part of this paper is structured as follows: after a short overview of related work in Sec. 2, we describe the MBR decoder in Sec. 3. We present the experimental results in Sec. 4 and conclude in Sec. 5. 2 Related Work MBR decoder for automatic speech recognition (ASR) have been reported to yield improvement over the widely used maximum a-posteriori probability (MAP) decoder (Goel and Byrne, 2003; Mangu et al., 2000; Stolcke et al., 1997). For MT, MBR decoding was introduced in (Kumar and Byrne, 2004). It was shown that MBR is preferable over MAP decoding for different evaluation criteria. Here, we focus on the performance of MBR decoding for the BLEU score on various translation tasks. 3 Implementation of Minimum Bayes Risk Decoding for the BLEU Score 3.1 Bayes Decision Rule In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Statistical decision theory tells us that among all possible target language sentences, we should choose the sentence which min"
P07-2026,P02-1038,1,0.615861,"penalty BP(·, ·) for too short translation hypotheses. ˆ ˆ · BLEU(eI1 , eˆI1 ) = BP(I, I) 4 Y ˆ Precn (eI1 , eˆI1 )1/4 n=1 I0 L0−1 (eI1 , e0 1 ) =  1 0 if eI1 = else 0 e0 I1 Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics as for example the BLEU score. One reason for the popularity of the MAP decision rule might be that, compared to the MBR rule, its computation is simpler. 3.2 Baseline System The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): ˆ = BP(I, I)  1 ˆ exp (1 − I/I) P ˆ Precn (eI1 , eˆI1 ) = w1n 0 (1) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in case of the MAP decision rule during the search process. Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translat"
P07-2026,P03-1021,0,0.119728,"rule during the search process. Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Matusov et al., 2006) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty, phrase penalty and a distortion penalty. The model scaling factors λM 1 are optimized with respect to the BLEU score as described in (Och, 2003). 102 P C(w1n |eI1 ) Here, C(w1n |eI1 ) denotes the number of occurrences of an n-gram w1n in a sentence eI1 . The denominator of the n-gram precisions evaluate to the number of n-grams in the hypothesis, i.e. I − n + 1. As loss function for the MBR decoder, we use: ˆ I 0 ,e0 I1 ˆ min{C(w1n |eI1 ), C(w1n |ˆ eI1 )} w1n ˆ L[eI1 , eˆI1 ] = 1 − BLEU(eI1 , eˆI1 ) . P  M I, fJ) exp λ h (e m=1 m m 1 1 P  P r(eI1 |f1J ) = P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 if Iˆ ≥ I if Iˆ &lt; I While the original BLEU score was intended to be used only for aggregate counts over a whole test set, we use the BLEU"
P07-2026,P02-1040,0,0.0787877,"e will call this decision rule the MBR rule (Kumar and Byrne, 2004). Proceedings of the ACL 2007 Demo and Poster Sessions, pages 101–104, c Prague, June 2007. 2007 Association for Computational Linguistics Although it is well known that this decision rule is optimal, most SMT systems do not use it. The most common approach is to use the MAP decision rule. Thus, we select the hypothesis which maximizes the posterior probability P r(eI1 |f1J ): n o ˆ eˆI1 = argmax P r(eI1 |f1J ) I,eI1 This decision rule is equivalent to the MBR criterion under a 0-1 loss function: 3.3 BLEU Score The BLEU score (Papineni et al., 2002) measures the agreement between a hypothesis eI1 generated by ˆ the MT system and a reference translation eˆI1 . It is the geometric mean of n-gram precisions Precn (·, ·) in combination with a brevity penalty BP(·, ·) for too short translation hypotheses. ˆ ˆ · BLEU(eI1 , eˆI1 ) = BP(I, I) 4 Y ˆ Precn (eI1 , eˆI1 )1/4 n=1 I0 L0−1 (eI1 , e0 1 ) =  1 0 if eI1 = else 0 e0 I1 Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics as for example the BLEU score. One reason for the popularity of the MAP decision rule"
P07-2045,N03-2002,0,0.152204,"nfusion networks. This input type has been used successfully for speech to text translation (Shen et al. 2006). Every factor on the target language can have its own language model. Since many factors, like lemmas and POS tags, are less sparse than surface forms, it is possible to create a higher order language models for these factors. This may encourage more syntactically correct output. In Figure 3 we apply two language models, indicated by the shaded arrows, one over the words and another over the lemmas. Moses is also able to integrate factored language models, such as those described in (Bilmes and Kirchhoff 2003) and (Axelrod 2006). 4 Confusion Network Decoding Machine translation input currently takes the form of simple sequences of words. However, there are increasing demands to integrate machine translation technology into larger information processing systems with upstream NLP/speech processing tools (such as named entity recognizers, speech recognizers, morphological analyzers, etc.). These upstream processes tend to generate multiple, erroneous hypotheses with varying confidence. Current MT systems are designed to process only one input hypothesis, making them vulnerable to errors in the input."
P07-2045,koen-2004-pharaoh,0,0.148177,"to be duplicated. This has also hindered effective comparisons of the different elements of the systems. By providing a free and complete toolkit, we hope that this will stimulate the development of the field. For this system to be adopted by the community, it must demonstrate performance that is comparable to the best available systems. Moses has shown that it achieves results comparable to the most competitive and widely used statistical machine translation systems in translation quality and run-time (Shen et al. 2006). It features all the capabilities of the closed sourced Pharaoh decoder (Koehn 2004). Apart from providing an open-source toolkit for SMT, a further motivation for Moses is to extend phrase-based translation with factors and confusion network decoding. The current phrase-based approach to statistical machine translation is limited to the mapping of small text chunks without any explicit use of linguistic information, be it morphological, syntactic, or semantic. These additional sources of information have been shown to be valuable when integrated into pre-processing or post-processing steps. Moses also integrates confusion network decoding, which allows the translation of amb"
P07-2045,D07-1091,1,0.158367,"Missing"
P07-2045,N03-1017,1,0.161374,"informatik.rwth-aachen.de. 5 redpony@umd.edu. 6 bojar@ufal.ms.mff.cuni.cz. 7 07aec_2@williams.edu. 8 evh4@cornell.edu 2 Abstract We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks. 1 Motivation Phrase-based statistical machine translation (Koehn et al. 2003) has emerged as the dominant paradigm in machine translation research. However, until now, most work in this field has been carried out on proprietary and in-house research systems. This lack of openness has created a high barrier to entry for researchers as many of the components required have had to be duplicated. This has also hindered effective comparisons of the different elements of the systems. By providing a free and complete toolkit, we hope that this will stimulate the development of the field. For this system to be adopted by the community, it must demonstrate performance that is co"
P07-2045,P03-1021,0,0.176468,"ent data structures in Moses for the memory-intensive translation model and language model allow the exploitation of much larger data resources with limited hardware. 177 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 177–180, c Prague, June 2007. 2007 Association for Computational Linguistics 2 Toolkit 3 The toolkit is a complete out-of-the-box translation system for academic research. It consists of all the components needed to preprocess data, train the language models and the translation models. It also contains tools for tuning these models using minimum error rate training (Och 2003) and evaluating the resulting translations using the BLEU score (Papineni et al. 2002). Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling. Also, since these tasks are often CPU intensive, the toolkit has been designed to work with Sun Grid Engine parallel environment to increase throughput. In order to unify the experimental stages, a utility has been developed to run repeatable experiments. This uses the tools contained in Moses and requires minimal changes to set up and customiz"
P07-2045,J03-1002,0,0.164868,"L 2007 Demo and Poster Sessions, pages 177–180, c Prague, June 2007. 2007 Association for Computational Linguistics 2 Toolkit 3 The toolkit is a complete out-of-the-box translation system for academic research. It consists of all the components needed to preprocess data, train the language models and the translation models. It also contains tools for tuning these models using minimum error rate training (Och 2003) and evaluating the resulting translations using the BLEU score (Papineni et al. 2002). Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling. Also, since these tasks are often CPU intensive, the toolkit has been designed to work with Sun Grid Engine parallel environment to increase throughput. In order to unify the experimental stages, a utility has been developed to run repeatable experiments. This uses the tools contained in Moses and requires minimal changes to set up and customize. The toolkit has been hosted and developed under sourceforge.net since inception. Moses has an active research community and has reached over 1000 downloads as of 1st March 2007. The main online pre"
P07-2045,P02-1040,0,0.148118,"d language model allow the exploitation of much larger data resources with limited hardware. 177 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 177–180, c Prague, June 2007. 2007 Association for Computational Linguistics 2 Toolkit 3 The toolkit is a complete out-of-the-box translation system for academic research. It consists of all the components needed to preprocess data, train the language models and the translation models. It also contains tools for tuning these models using minimum error rate training (Och 2003) and evaluating the resulting translations using the BLEU score (Papineni et al. 2002). Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling. Also, since these tasks are often CPU intensive, the toolkit has been designed to work with Sun Grid Engine parallel environment to increase throughput. In order to unify the experimental stages, a utility has been developed to run repeatable experiments. This uses the tools contained in Moses and requires minimal changes to set up and customize. The toolkit has been hosted and developed under sourceforge.net since inception. Mo"
P07-2045,N07-1062,1,0.152186,"up gigabytes of disk space, but for the translation of a single sentence only a tiny fraction of this table is needed. Moses implements an efficient representation of the phrase translation table. Its key properties are a prefix tree structure for source words and on demand loading, i.e. only the fraction of the phrase table that is needed to translate a sentence is loaded into the working memory of the decoder. For the Chinese-English NIST task, the memory requirement of the phrase table is reduced from 1.7 gigabytes to less than 20 mega bytes, with no loss in translation quality and speed (Zens and Ney 2007). The other large data resource for statistical machine translation is the language model. Almost unlimited text resources can be collected from the Internet and used as training data for language modeling. This results in language models that are too large to easily fit into memory. The Moses system implements a data structure for language models that is more efficient than the canonical SRILM (Stolcke 2002) implementation used in most systems. The language model on disk is also converted into this binary format, resulting in a minimal loading time during start-up of the decoder. An even more"
P07-2045,D08-1076,0,\N,Missing
P07-2045,2006.iwslt-evaluation.8,1,\N,Missing
P12-2006,2006.iwslt-papers.6,0,0.0588331,"Missing"
P12-2006,W11-2123,0,0.0949861,"Missing"
P12-2006,N03-1017,0,0.0610843,"Missing"
P12-2006,P07-2045,1,0.0181414,"Missing"
P12-2006,2007.mtsummit-papers.43,0,0.0352097,"Missing"
P12-2006,W06-3109,0,0.267098,"Missing"
P12-2006,P02-1040,0,0.0844948,"Missing"
P12-2006,2006.amta-papers.25,0,0.151541,"Missing"
P12-2006,2008.iwslt-papers.8,1,0.94228,"Missing"
W04-1118,J90-2002,0,0.458153,"Missing"
W04-1118,J93-2003,0,0.01137,"ment Models The alignment model P r(f1J , aJ1 |eI1 ) introduces a ‘hidden’ alignment a = aJ1 , which describes 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). a mapping from a source position j to a target position aj . The relationship between the translation model and the alignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a si"
W04-1118,P02-1038,1,0.242537,"ased on phrases circumvents the problem of word segmentation to a certain degree. This method will be referred to as “translation with no segmentation” (see Section 5.2). visit a for hangzhou to go also will they Figure 2: Example of a word aligned sentence pair and some possible alignment templates. In the Chinese–English DARPA TIDES evaluations in June 2002 and May 2003, carried out by NIST (NIST, 2003), the alignment template approach performed very well and was ranked among the best translation systems. Further details on the alignment template approach are described in (Och et al., 1999; Och and Ney, 2002). 3 Task and Corpus Statistics In Section 5.3, we will present results for a Chinese–English translation task. The domain of this task is news articles. As bilingual training data, we use a corpus composed of the English translations of a Chinese Treebank. This corpus is provided by the Linguistic Data Consortium (LDC), catalog number LDC2002E17. In addition, we use a bilingual dictionary with 10K Chinese word entries provided by Stephan Vogel (LDC, 2003b). Table 1 shows the corpus statistics of this task. We have calculated both the number of words and the number of characters in the corpus."
W04-1118,J03-1002,1,0.0116123,"rly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). a mapping from a source position j to a target position aj . The relationship between the translation model and the alignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a simpler model serve as starting point for a more complex model. The result of the training procedure is the Viterbi alignment of the final training iteration for the whole training corpus. 2.3 Alignment Template Approach In the translatio"
W04-1118,W99-0604,1,0.924603,"ignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a simpler model serve as starting point for a more complex model. The result of the training procedure is the Viterbi alignment of the final training iteration for the whole training corpus. 2.3 Alignment Template Approach In the translation approach from Section 2.1, one disadvantage is that the contextual information is only taken into account by the language model. The single-word based lexicon model does not consider the surrounding words. One way to incorporate the"
W04-1118,P97-1041,0,0.0175549,"Missing"
W04-1118,2001.mtsummit-papers.68,0,0.0289267,"erations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2001). The BLEU score measures accuracy, i.e. large BLEU scores are better. 5.2 Summary: Three Translation Methods In the experiments, we compare the following three translation methods: • Translation with no segmentation: Each Chinese character is interpreted as a single word. • Translation with learned segmentation: It uses the self-learned dictionary. • Translation with LDC segmentation: The predefined LDC dictionary is used. The core contribution of this paper is the method we called “translation with learned segmentation”, which consists of three steps: • The input is a sequence of Chinese cha"
W04-1118,P98-2206,0,0.016446,"Missing"
W04-1118,C96-2141,1,0.240752,"dden’ alignment a = aJ1 , which describes 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). a mapping from a source position j to a target position aj . The relationship between the translation model and the alignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a simpler model serve as starting point for a more complex model. The res"
W04-1118,P02-1040,0,\N,Missing
W04-1118,C98-2201,0,\N,Missing
W05-0831,W00-0508,0,0.172433,"Missing"
W05-0831,2004.iwslt-evaluation.13,1,0.903041,"the reordering problem from the view of the model. Without reordering both in training and during search, sentences can only be translated properly into a language with similar word order. In (Bangalore et al., 2000) weighted reordering has been applied to target sentences since defining a permutation model on the source side is impractical in combination with speech recognition. In order to reduce the computational complexity, this approach considers only a set of plausible reorderings seen on training data. Most other phrase-based statistical approaches like the Alignment Template system of Bender et al. (2004) rely on (local) reorderings which are implicitly memorized with each pair of source and target phrases in training. Additional reorderings on phrase level are fully integrated into the decoding process, which increases the complexity of the system and makes it hard to modify. Zens et al. (2003) reviewed two types of reordering constraints for this type of translation systems. In our work we follow a phrase-based translation approach, applying source sentence reordering on word level. We compute a reordering graph ondemand and take it as input for monotonic translation. This approach is modula"
W05-0831,P04-1065,1,0.437186,"Missing"
W05-0831,knight-al-onaizan-1998-translation,0,0.507961,"Missing"
W05-0831,N03-1019,0,0.120471,"Missing"
W05-0831,C04-1032,1,0.655504,"he empty phrase. Therefore, for language pairs with big differences in word order, probability estimates may be poor. This problem can be solved by reordering either source or target training sentences such that alignments become monotonic for all sentences. We suggest the following consistent source sentence reordering and alignment monotonization approach in which we compute optimal, minimum-cost alignments. First, we estimate a cost matrix C for each sentence pair (f1J , eI1 ). The elements of this matrix cij are the local costs of aligning a source word fj to a target word ei . Following (Matusov et al., 2004), we compute these local costs by interpolating state occupation probabilities from the source-to-target and target-to-source training of the HMM and IBM-4 models as trained by the GIZA++ toolkit (Och et al., 2003). For a given alignment A ⊆ I × J, we define the costs of this alignment c(A) as the sum of the local costs of all aligned word pairs: X c(A) = cij (1) A∈A ∼ = argmax max e˜J 1 (fj , e˜j ). Mapping the bilingual language model to a WFST T is canonical and it has been shown in (Kanthak et al., 2004) that the search problem can then be rewritten using finite-state terminology: j−1 p(fj"
W05-0831,J03-1002,1,0.0715111,"Missing"
W05-0831,P02-1040,0,0.119703,"Missing"
W05-0831,J97-3002,0,0.168153,"well-known in the field of machine translation and were first described in (Berger et al., 1996). The idea behind these constraints is to deviate from monotonic translation by postponing translations of a limited number of words. More specifically, at each state we can translate any of the first l yet uncovered word positions. The implementation using a bit vector is straightforward. For consistency, we associate window size with the parameter l for all constraints presented here. 4.3 1000 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997). These constraints are inspired by bilingual bracketing. They proved to be quite useful for machine translation, e.g. see (Bender et al., 2004). Here, we interpret the input sentence as a sequence of segments. In the beginning, each word is a segment of its own. Longer segments are constructed by recursively combining two adjacent segments. At each 1 both covered and uncovered train dev test sentences words singletons vocabulary sentences words sentence length (avg/max) sentences words sentence length (avg/max) Chinese English 20 000 182 904 160 523 3 525 2 948 7 643 6 982 506 3 515 3 595 6.9"
W05-0831,2002.tmi-tutorials.2,0,0.0628056,"ermutations as a finite-state automaton requires at least 2J states. Therefore, we opt for computing the permutation automaton on-demand while applying beam pruning in the search. 4.1 Lazy Permutation Automata For on-demand computation of an automaton in the flavor described in (Kanthak et al., 2004) it is sufficient to specify a state description and an algorithm that calculates all outgoing arcs of a state from the state description. In our case, each state represents a permutation of a subset of the source words f1J , which are already translated. This can be described by a bit vector bJ1 (Zens et al., 2002). Each bit of the state bit vector corresponds to an arc of the linear input automaton and is set to one if the arc has been used on any path from the initial to the current state. The bit vectors of two states connected by an arc differ only in a single bit. Note that bit vectors elegantly solve the problem of recombining paths in the automaton as states with the same bit vectors can be merged. As a result, a fully minimized permutation automaton has only a single initial and final state. Even with on-demand computation, complexity using full permutations is unmanagable for long sentences. We"
W05-0831,P03-1019,1,0.772763,"Missing"
W05-0831,J04-2004,0,\N,Missing
W05-0831,2004.iwslt-evaluation.1,0,\N,Missing
W05-0834,N03-1019,0,0.0563219,"tical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate. • The rest cost estimation is not efficient. It has an exponential worst-case time complexity. We will describe an algorithm with linear worstcase complexity. Apart from (Ueffing et al., 2002), publications on weighted finite state transducer approaches to machine translation, e.g. (Bangalore and Riccardi, 2001; Kumar and Byrne, 2003), deal with word graphs. But to our knowledge, there are no publications that give a detailed analysis and evaluation of the quality of word graphs for machine translation. We will fill this gap and give a systematic description and an assessment of the quality of word graphs for phrase-based machine translation. We will show that even for hard tasks with very large vocabulary and long sentences the graph error rate drops significantly. The remaining part is structured as follows: first we will give a brief description of the translation system in Section 2. In Section 3, we will give a defini"
W05-0834,P02-1038,1,0.395242,"achine translation system usually produces the single-best translation hypotheses for a source sentence. For some applications, we are also interested in alternative translations. The simplest way to represent these alternatives is a list with the N -best translation candidates. These N -best lists have one major disadvantage: the high redundancy. The translation alternatives may differ only by a single word, but still both are listed completely. Usually, the size of the N -best list is in the range of a few • Discriminative Training. The training of the model scaling factors as described in (Och and Ney, 2002) was done on N -best lists. Using word graphs instead could further improve the results. Also, the phrase translation probabilities could be trained discrimatively, rather than only the scaling factors. • Confidence Measures. Word graphs can be used to derive confidence measures, such as the posterior probability (Ueffing and Ney, 2004). 191 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 191–198, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 • Interactive Machine Translation. Some interactive machine translation systems make use of word gr"
W05-0834,E03-1032,1,0.863799,"N -best lists. Using word graphs instead could further improve the results. Also, the phrase translation probabilities could be trained discrimatively, rather than only the scaling factors. • Confidence Measures. Word graphs can be used to derive confidence measures, such as the posterior probability (Ueffing and Ney, 2004). 191 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 191–198, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 • Interactive Machine Translation. Some interactive machine translation systems make use of word graphs, e.g. (Och et al., 2003). State Of The Art. Although there are these many applications, there are only few publications directly devoted to word graphs. The only publication, we are aware of, is (Ueffing et al., 2002). The shortcomings of (Ueffing et al., 2002) are: • They use single-word based models only. Current state of the art statistical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate"
W05-0834,P03-1021,0,0.323432,"ity P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a wordbased lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. With the exception of the language model, all models can be considered as within-phrase models as they depend only on a single phrase pair, but not on the context outside of the phrase. The model scaling factors are optimized with respect to some evaluation criterion (Och, 2003). We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible. In our case, we assume that local reorderings are sufficient. Within a certain window, all possible permutations of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. More details of this reordering approach are described in (Kanthak et al., 2005). 3 Word Graphs 3.1 Definition A word graph is a directed acyclic graph G ="
W05-0834,W02-1021,1,0.69194,". • Confidence Measures. Word graphs can be used to derive confidence measures, such as the posterior probability (Ueffing and Ney, 2004). 191 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 191–198, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 • Interactive Machine Translation. Some interactive machine translation systems make use of word graphs, e.g. (Och et al., 2003). State Of The Art. Although there are these many applications, there are only few publications directly devoted to word graphs. The only publication, we are aware of, is (Ueffing et al., 2002). The shortcomings of (Ueffing et al., 2002) are: • They use single-word based models only. Current state of the art statistical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate. • The rest cost estimation is not efficient. It has an exponential worst-case time complexity. We will describe an algorithm with linear worstcase complexity. Apart from (Ueffing et al., 2002"
W05-0834,2004.iwslt-evaluation.1,0,0.0279902,"Missing"
W05-0834,N04-1033,1,0.861442,"e translation. We will present experimental results in Section 5 for two Chinese– English tasks: the first one, the IWSLT task, is in the domain of basic travel expression found in phrasebooks. The vocabulary is limited and the sentences are short. The second task is the NIST Chinese– English large data track task. Here, the domain is news and therefore the vocabulary is very large and the sentences are with an average of 30 words quite long. 2 Translation System In this section, we give a brief description of the translation system. We use a phrase-based translation approach as described in (Zens and Ney, 2004). The posterior probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a wordbased lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. With the exception of the language model, all models can be considered as within-phrase models as they depend only on a single phrase pair, but not on the context outside of the phrase. The model scaling factors are optimized with respect to som"
W05-0834,N01-1018,0,0.0117441,"urrent state of the art statistical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate. • The rest cost estimation is not efficient. It has an exponential worst-case time complexity. We will describe an algorithm with linear worstcase complexity. Apart from (Ueffing et al., 2002), publications on weighted finite state transducer approaches to machine translation, e.g. (Bangalore and Riccardi, 2001; Kumar and Byrne, 2003), deal with word graphs. But to our knowledge, there are no publications that give a detailed analysis and evaluation of the quality of word graphs for machine translation. We will fill this gap and give a systematic description and an assessment of the quality of word graphs for phrase-based machine translation. We will show that even for hard tasks with very large vocabulary and long sentences the graph error rate drops significantly. The remaining part is structured as follows: first we will give a brief description of the translation system in Section 2. In Section"
W05-0834,2002.tmi-tutorials.2,0,0.168978,"the exception of the language model, all models can be considered as within-phrase models as they depend only on a single phrase pair, but not on the context outside of the phrase. The model scaling factors are optimized with respect to some evaluation criterion (Och, 2003). We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible. In our case, we assume that local reorderings are sufficient. Within a certain window, all possible permutations of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. More details of this reordering approach are described in (Kanthak et al., 2005). 3 Word Graphs 3.1 Definition A word graph is a directed acyclic graph G = (V, E) with one designated root node n0 ∈ V . The edges are labeled with words and optionally with scores. We will use (n, n0 , w) to denote an edge from node n to node n0 with word label w. Each path through the word graph represents a translation candidate. If the word graph contains scores, we accumulate the edge scores along a path to get"
W05-0834,W05-0831,1,0.923386,"se. The model scaling factors are optimized with respect to some evaluation criterion (Och, 2003). We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible. In our case, we assume that local reorderings are sufficient. Within a certain window, all possible permutations of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. More details of this reordering approach are described in (Kanthak et al., 2005). 3 Word Graphs 3.1 Definition A word graph is a directed acyclic graph G = (V, E) with one designated root node n0 ∈ V . The edges are labeled with words and optionally with scores. We will use (n, n0 , w) to denote an edge from node n to node n0 with word label w. Each path through the word graph represents a translation candidate. If the word graph contains scores, we accumulate the edge scores along a path to get the sentence or string score. The score information the word graph has to contain depends on the application. If we want to use the word graph as a word filter, we do not need any"
W05-0834,knight-al-onaizan-1998-translation,0,0.0184284,".2 Generation In this section, we analyze the search process in detail. Later, in Section 5, we will show the (experimental) complexity of each step. We start with the source language sentence that is represented as a linear graph. Then, we introduce reorderings into this graph as described in (Kanthak et al., 2005). The type of reordering should depend on the language pair. In our case, we assume that only local reorderings are required. Within a certain window, all possible reorderings of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Knight and Al-Onaizan, 1998) and (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. This translation process consists of the following steps that will be described afterward: 1. segment into phrase 2. translate the individual phrases 3. split the phrases into words 4. apply the language model Now, we will describe each step. The first step is the segmentation into phrases. This can be imagined as introducing “short-cuts” into the graph. The phrase segmentation does not affect the number of nodes, because only additional edges are added to the graph. In t"
W06-3108,J96-1002,0,0.0212931,"ails of this reordering model. The classes our model predicts will be defined in Section 4.2. Then, the feature functions will be defined right phrase orientation target positions target positions left phrase orientation i j’ i j j source positions j’ source positions Figure 1: Illustration of the phrase orientation. in Section 4.3. The training criterion and the training events of the maximum entropy model will be described in Section 4.4. Then, the reordering model has the form 4.2 A well-founded framework for directly modeling the probability p(cj,j ′ |f1J , eI1 , i, j) is maximum entropy (Berger et al., 1996). In this framework, we have a set of N feature functions hn (f1J , eI1 , i, j, cj,j ′ ), n = 1, . . . , N . Each feature function hn is weighted with a factor λn . The resulting model is: Class Definition Ideally, this model predicts the start position of the next phrase. But as predicting the exact position is rather difficult, we group the possible start positions into classes. In the simplest case, we use only two classes. One class for the positions to the left and one class for the positions to the right. As a refinement, we can use four classes instead of two: 1) one position to the lef"
W06-3108,J90-2002,0,0.432383,". . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model"
W06-3108,P03-1021,0,0.0328867,"e posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distancebased, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. This very simple reordering model is widely used, for instance in (Och"
W06-3108,P02-1040,0,0.1059,"irable properties of an appropriate reordering model. The main point is that these are fulfilled not only on the training data, but on unseen test data. There seems to be no overfitting problem. In Table 5, we present the results for four orientation classes. The final error rates are a factor 2-4 larger than for two orientation classes. Despite that we observe the same tendencies as for two orientation classes. Again, using more features always helps to improve the performance. 5.3 Translation Results For the translation experiments on the BTEC task, we report the two accuracy measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) as well as the two error rates: word error rate (WER) and position-independent word error rate (PER). These criteria are computed with respect to 16 references. In Table 6, we show the translation results for the BTEC task. In these experiments, the reordering model uses two orientation classes, i.e. it predicts either a left or a right orientation. The features for the maximum-entropy based reordering model are based on the source and target language words within a window of one. The word-class based features are not used for the translation experiments. The maxim"
W06-3108,2005.iwslt-1.8,0,0.383621,"ed corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from the data sparseness problem, because most of the phrases occur only once in the training"
W06-3108,koen-2004-pharaoh,0,0.668221,"odels as well as the contribution of the individual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from"
W06-3108,H05-1021,0,0.0974603,"eordering model: the costs 55 Proceedings of the Workshop on Statistical Machine Translation, pages 55–63, c New York City, June 2006. 2006 Association for Computational Linguistics for phrase movements are linear in the distance. This approach is also used in the publicly available Pharaoh decoder (Koehn, 2004). The idea of predicting the orientation is adopted from (Tillmann and Zhang, 2005) and (Koehn et al., 2005). Here, we use the maximum entropy principle to combine a variety of different features. A reordering model in the framework of weighted finite state transducers is described in (Kumar and Byrne, 2005). There, the movements are defined at the phrase level, but the window for reordering is very limited. The parameters are estimated using an EM-style method. None of these methods try to generalize from the words or phrases by using word classes or part-ofspeech information. The approach presented here has some resemblance to the bracketing transduction grammars (BTG) of (Wu, 1997), which have been applied to a phrase-based machine translation system in (Zens et al., 2004). The difference is that, here, we do not constrain the phrase reordering. Nevertheless the inverted/monotone concatenation"
W06-3108,P02-1038,1,0.276814,"the phrase reordering. Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here. In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the fol"
W06-3108,J03-1002,1,0.00801402,"there is only a single optimum and no convergence problems occur. To train the model parameters λN 1 , we use the Generalized Iterative Scaling (GIS) algorithm (Darroch and Ratcliff, 1972). In practice, the training procedure tends to result in an overfitted model. To avoid overfitting, (Chen and Rosenfeld, 1999) have suggested a smoothing method where a Gaussian prior distribution of the parameters is assumed. This method tried to avoid very large lambda values and prevents features that occur only once for a specific class from getting a value of infinity. We train IBM Model 4 with GIZA++ (Och and Ney, 2003) in both translation directions. Then the alignments are symmetrized using a refined heuristic as described in (Och and Ney, 2003). This wordaligned bilingual corpus is used to train the reordering model parameters, i.e. the feature weights λN 1 . Each alignment link defines an event for the maximum entropy training. An exception are the oneto-many alignments, i.e. one source word is aligned to multiple target words. In this case, only the topmost alignment link is considered because the other ones cannot occur at a phrase boundary. Many-toone and many-to-many alignments are handled in a simil"
W06-3108,W99-0604,1,0.683914,"f the reordering models as well as the contribution of the individual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may"
W06-3108,E99-1010,0,0.0739474,"Missing"
W06-3108,takezawa-etal-2002-toward,0,0.0187671,". This wordaligned bilingual corpus is used to train the reordering model parameters, i.e. the feature weights λN 1 . Each alignment link defines an event for the maximum entropy training. An exception are the oneto-many alignments, i.e. one source word is aligned to multiple target words. In this case, only the topmost alignment link is considered because the other ones cannot occur at a phrase boundary. Many-toone and many-to-many alignments are handled in a similar way. 5 Experimental Results 5.1 Statistics The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task (Takezawa et al., 2002). This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. We use the Arabic-English, the Chinese-English and the Japanese-English data. The corpus statistics are shown in Table 1. As the BTEC is a rather clean corpus, the preprocessing consisted mainly of tokenization, i.e., separating punctuation marks from words. Additionally, we replaced contractions such as it’s or I’m in the English corpus and we removed the case information. For Arabic, we removed the diacritics and we split common prefixes: Al, w, f, b, l. There was"
W06-3108,P05-1069,0,0.14547,"dual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from the data sparseness problem, because most of the phrases occu"
W06-3108,J97-3002,0,0.301989,"and (Koehn et al., 2005). Here, we use the maximum entropy principle to combine a variety of different features. A reordering model in the framework of weighted finite state transducers is described in (Kumar and Byrne, 2005). There, the movements are defined at the phrase level, but the window for reordering is very limited. The parameters are estimated using an EM-style method. None of these methods try to generalize from the words or phrases by using word classes or part-ofspeech information. The approach presented here has some resemblance to the bracketing transduction grammars (BTG) of (Wu, 1997), which have been applied to a phrase-based machine translation system in (Zens et al., 2004). The difference is that, here, we do not constrain the phrase reordering. Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here. In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probabili"
W06-3108,N04-1033,1,0.81184,"linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distancebased, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. This very simple reordering model is widely used, for instance in (Och et al., 1999; Koehn, 2004; Zens et al., 2005). 4 The Reordering Model 3 Baseli"
W06-3108,C04-1030,1,0.587047,"riety of different features. A reordering model in the framework of weighted finite state transducers is described in (Kumar and Byrne, 2005). There, the movements are defined at the phrase level, but the window for reordering is very limited. The parameters are estimated using an EM-style method. None of these methods try to generalize from the words or phrases by using word classes or part-ofspeech information. The approach presented here has some resemblance to the bracketing transduction grammars (BTG) of (Wu, 1997), which have been applied to a phrase-based machine translation system in (Zens et al., 2004). The difference is that, here, we do not constrain the phrase reordering. Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here. In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly"
W06-3108,2005.iwslt-1.20,1,0.601289,"as the contribution of the individual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from the data sparseness"
W06-3108,2005.iwslt-1.1,0,\N,Missing
W06-3110,C04-1046,0,0.060751,"Missing"
W06-3110,J90-2002,0,0.360601,"hest probability: ˆ eˆI1 = argmax I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M J ′I ′ exp m=1 λm hm (e 1 , f1 ) ′ I ′ ,e′ I1 (2) The denominator is a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a"
W06-3110,koen-2004-pharaoh,0,0.14022,"., 2003). The outcome was that the confidence measures did not result in improvements of the translation quality measured with the BLEU and NIST scores. Here, we focus on how the ideas and methods commonly used for confidence estimation can be adapted and/or extended to improve translation quality. So far, always word-level posterior probabilities were used. Here, we will generalize this idea to ngrams. In addition to the n-gram posterior probabilities, we introduce a sentence-length model based on posterior probabilities. The common phrasebased translation systems, such as (Och et al., 1999; Koehn, 2004), do not use an explicit sentence length model. Only the simple word penalty goes into that direction. It can be adjusted to prefer longer or shorter translations. Here, we will explicitly model the sentence length. The novel contributions of this work are to introduce n-gram posterior probabilities and sentence length posterior probabilities. Using these methods, we achieve significant improvements of translation quality. The remaining part of this paper is structured as follows: first, we will briefly describe the baseline system, which is a state-of-the-art phrase-based statistical machine"
W06-3110,P02-1038,1,0.509641,"orkshop on Statistical Machine Translation, pages 72–77, c New York City, June 2006. 2006 Association for Computational Linguistics 2 Baseline System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M J ′I ′ exp m=1 λm hm (e 1 , f1 ) ′ I ′ ,e′ I1 (2) The denominator is a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final t"
W06-3110,W99-0604,1,0.688342,"f, is (Blatz et al., 2003). The outcome was that the confidence measures did not result in improvements of the translation quality measured with the BLEU and NIST scores. Here, we focus on how the ideas and methods commonly used for confidence estimation can be adapted and/or extended to improve translation quality. So far, always word-level posterior probabilities were used. Here, we will generalize this idea to ngrams. In addition to the n-gram posterior probabilities, we introduce a sentence-length model based on posterior probabilities. The common phrasebased translation systems, such as (Och et al., 1999; Koehn, 2004), do not use an explicit sentence length model. Only the simple word penalty goes into that direction. It can be adjusted to prefer longer or shorter translations. Here, we will explicitly model the sentence length. The novel contributions of this work are to introduce n-gram posterior probabilities and sentence length posterior probabilities. Using these methods, we achieve significant improvements of translation quality. The remaining part of this paper is structured as follows: first, we will briefly describe the baseline system, which is a state-of-the-art phrase-based statis"
W06-3110,N04-1021,0,0.0492858,"tence length model. Only the simple word penalty goes into that direction. It can be adjusted to prefer longer or shorter translations. Here, we will use the posterior probability of a specific target sentence length I as length model: X p(I|f1J ) = p(eI1 |f1J ) (6) eI1 Note that the sum is carried out only over target sentences eI1 with the a specific length I. Again, the candidate target language sentences are limited to an N -best list. 5 Rescoring/Reranking A straightforward application of the posterior probabilities is to use them as additional features in a rescoring/reranking approach (Och et al., 2004). The use of N -best lists in machine translation has several advantages. It alleviates the effects of the huge search space which is represented in word graphs by using a compact excerpt of the N best hypotheses generated by the system. N -best lists are suitable for easily applying several rescoring techniques since the hypotheses are already fully generated. In comparison, word graph rescoring techniques need specialized tools which can traverse the graph accordingly. The n-gram posterior probabilities can be used similar to an n-gram language model: We use a linear interpolation with weigh"
W06-3110,P03-1021,0,0.0966035,"|f1J ) = P M J ′I ′ exp m=1 λm hm (e 1 , f1 ) ′ I ′ ,e′ I1 (2) The denominator is a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. 3 N-Gram Posterior Probabilities The idea is similar to the word posterior probabilities: we sum the sentence posterior probabilities for each occurrence of an n-gram. 73 Let δ(·, ·) denote the Kronecker function. Th"
W06-3110,P02-1040,0,0.121019,"art of the bilingual training cori J pus and additional monolingual English data from C(ei−n+1 , f1 ) J (8) p(ei |ei−1 the GigaWord corpus. The total amount of lani−n+1 , f1 ) = i−1 C(ei−n+1 , f1J ) guage model training data was about 600M running Note that the models do not require smoothing as words. We use a fourgram language model with long as they are applied to the same N -best list they modified Kneser-Ney smoothing as implemented in the SRILM toolkit (Stolcke, 2002). are trained on. To measure the translation quality, we use the If the models are used for unseen sentences, BLEU score (Papineni et al., 2002) and the NIST smoothing is important to avoid zero probabilities. We use a linear interpolation with weights αn and score (Doddington, 2002). The BLEU score is the the smoothed (n − 1)-gram model as generalized geometric mean of the n-gram precision in combination with a brevity penalty for too short sendistribution. tences. The NIST score is the arithmetic mean of i J) C(e , f a weighted n-gram precision in combination with a i−n+1 1 J pn (ei |ei−1 (9) i−n+1 , f1 ) = αn · i−1 J brevity penalty for too short sentences. Both scores C(ei−n+1 , f1 ) are computed case-sensitive with respect to fou"
W06-3110,2005.eamt-1.35,1,0.757443,"nce length posterior probabilities and do a third search pass, etc.. 7.2 Computer Assisted Translation In the computer assisted translation (CAT) framework, the goal is to improve the productivity of human translators. The machine translation system takes not only the current source language sentence but also the already typed partial translation into account. Based on this information, the system suggest completions of the sentence. Word-level posterior probabilities have been used to select the most appropriate completion of the system, for more details see e.g. (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). The n-gram based posterior probabilities as described in this work, might be better suited for this task as they explicitly model the dependency on the previous words, i.e. the given prefix. 8 Conclusions We introduced n-gram and sentence length posterior probabilities and demonstrated their usefulness for rescoring purposes. We performed systematic experiments on the Chinese-English NIST task and showed significant improvements of the translation quality. The improvements were consistent among several evaluation sets. An interesting property of the introduced methods is that they do not req"
W06-3110,2003.mtsummit-papers.52,1,0.467669,"Missing"
W06-3110,N04-1033,1,0.268558,"rmalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. 3 N-Gram Posterior Probabilities The idea is similar to the word posterior probabilities: we sum the sentence posterior probabilities for each occurrence of an n-gram. 73 Let δ(·, ·) denote the Kronecker function. Then, we define the fractional count C(en1 , f1J ) of an ngram en1 for a source sentence f1J as:"
W06-3110,2005.iwslt-1.20,1,0.725103,"hat depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. 3 N-Gram Posterior Probabilities The idea is similar to the word posterior probabilities: we sum the sentence posterior probabilities for each occurrence of an n-gram. 73 Let δ(·, ·) denote the Kronecker function. Then, we define the fractional count C(en1 , f1J ) of an ngram en1 for a source sentence f1J as: C(en1 , f1J ) = X X"
W06-3110,W03-0413,0,\N,Missing
W06-3111,1998.amta-tutorials.6,0,0.037147,"Missing"
W06-3111,J93-2003,0,0.0250703,"Missing"
W06-3111,J93-1004,0,0.172538,"a combination of the two approaches leads to better translation performance. 1 Introduction Current statistical machine translation systems use bilingual sentences to train the parameters of the translation models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dyn"
W06-3111,ma-2006-champollion,0,0.0123684,"roaches leads to better translation performance. 1 Introduction Current statistical machine translation systems use bilingual sentences to train the parameters of the translation models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dynamic programmin"
W06-3111,J03-1002,1,0.0102698,"ine translation system in Section 2. Then, in Section 3, we will describe the refined binary segmentation method. In Section 4.1, we will introduce the methods to extract bilingual sentences from document aligned texts. The experimental results will be presented in Section 4. 2 Monotone I,eI1 = argmax I,eI1 (1) Figure 1: Two Types of Alignment The IBM model 1 (IBM-1) (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution: X J I 1 YX · p(fj |ei ) IJ (2) We use the IBM-1 to train the lexicon parameters p(f |e), the training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the phrase-based translation approach (Zens et al., 2005) is applied. Pairs of source and target language phrases are extracted from the bilingual training corpus and a beam search algorithm is implemented to generate the translation hypothesis with maximum probability. 3 Binary Segmentation Method 3.1 The decomposition into two knowledge sources in Equation 1 allows independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 . The translation model can be further extended to a statistical alignment mode"
W06-3111,P02-1040,0,0.0718853,"Missing"
W06-3111,W03-0304,0,0.012923,"arameters of the translation models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dynamic programming, the initial alignments are then refined to produce shorter segments using binary segmentation. But on the Chinese-English FBIS training corpus, the alignment accura"
W06-3111,J97-3002,0,0.0854975,"Missing"
W06-3111,2005.eamt-1.37,1,0.927694,"models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dynamic programming, the initial alignments are then refined to produce shorter segments using binary segmentation. But on the Chinese-English FBIS training corpus, the alignment accuracy and recall are l"
W06-3111,2005.iwslt-1.20,1,0.870918,"In Section 4.1, we will introduce the methods to extract bilingual sentences from document aligned texts. The experimental results will be presented in Section 4. 2 Monotone I,eI1 = argmax I,eI1 (1) Figure 1: Two Types of Alignment The IBM model 1 (IBM-1) (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution: X J I 1 YX · p(fj |ei ) IJ (2) We use the IBM-1 to train the lexicon parameters p(f |e), the training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the phrase-based translation approach (Zens et al., 2005) is applied. Pairs of source and target language phrases are extracted from the bilingual training corpus and a beam search algorithm is implemented to generate the translation hypothesis with maximum probability. 3 Binary Segmentation Method 3.1 The decomposition into two knowledge sources in Equation 1 allows independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 . The translation model can be further extended to a statistical alignment model with the following equation: P r(f1J |eI1 ) = D j=1 i=1 © ª P r(eI1 |f1J ) © ª P r(eI1 ) · P r(f1J |eI1 ) C p(f1"
W07-0401,J96-1002,0,0.0424164,"Missing"
W07-0401,J90-2002,0,0.442192,"ons with the chunk-level source reordering model. 3.1 The Baseline Phrase-based SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax I,eI1 = argmax I,eI1   P r(eI1 |f1J ) P r(eI1 ) · P r(f1J |eI1 ) (1) (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model (Och and Ney, 2002), we obtain: P"
W07-0401,2006.iwslt-papers.4,0,0.41497,"erns can be applied to any input source sentence so that the rewritten source and target sentences have similar word order. Both methods need a parser to generate trees of source sentences and are applied only as a preprocessing step. Another kind of source reordering methods besides full parsing is based on Part-Of-Speech (POS) tags or word classes. (Costa-juss`a and Fonollosa, 2006) view the source reordering as a translation task that translate the source language into a reordered source language. Then, the reordered source sentence is taken as the single input to the standard SMT system. (Chen et al., 2006) automatically extract rules from word alignments. These rules are defined at the POS level and the scores of matching rules are used as additional feature functions during rescor2 ing. (Crego and Mari˜no, 2006) integrate source-side reordering into SMT decoding. They automatically learn rewrite patterns from word alignment and represent the patterns with POS tags. To our knowledge no work is reported on the reordering with shallow parsing. Decoding lattices were already used in (Zens et al., 2002; Kanthak et al., 2005). Those approaches used linguistically uninformed word-level reorderings. 3"
W07-0401,P05-1066,0,0.717146,"ules, how they are defined and how to extract them. In Section 5, we explain how to apply the rules and how to generate reordering lattice. In Section 6, we present some results that show that the chunk-level source reordering is helpful for phrase-based statistical machine translation. Finally, we conclude this paper and discuss future work in Section 7. 2 Related Work Beside the reordering methods during decoding, an alternative approach is to reorder the input source sentence to match the word order of the target sentence. Some reordering methods are carried out on syntactic source trees. (Collins et al., 2005) describe a method for reordering German for German-toEnglish translation, where six transformations are applied to the surface string of the parsed source sentence. (Xia and McCord, 2004) propose an approach for translation from French-to-English. This approach automatically extracts rewrite patterns by parsing the source and target sides of the training corpus. These rewrite patterns can be applied to any input source sentence so that the rewritten source and target sentences have similar word order. Both methods need a parser to generate trees of source sentences and are applied only as a p"
W07-0401,W06-1609,0,0.315258,"Missing"
W07-0401,2006.amta-papers.4,0,0.087248,"Missing"
W07-0401,P06-1121,0,0.00765324,"he POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system,"
W07-0401,P03-1011,0,0.0306488,"eordering at the chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic f"
W07-0401,N04-1014,0,0.00604591,"performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a ful"
W07-0401,W05-0831,1,0.775387,"red source sentence is taken as the single input to the standard SMT system. (Chen et al., 2006) automatically extract rules from word alignments. These rules are defined at the POS level and the scores of matching rules are used as additional feature functions during rescor2 ing. (Crego and Mari˜no, 2006) integrate source-side reordering into SMT decoding. They automatically learn rewrite patterns from word alignment and represent the patterns with POS tags. To our knowledge no work is reported on the reordering with shallow parsing. Decoding lattices were already used in (Zens et al., 2002; Kanthak et al., 2005). Those approaches used linguistically uninformed word-level reorderings. 3 System Overview In this section, we will describe the phrase-based SMT system which we use for the experiments. Then, we will give an outline of the extentions with the chunk-level source reordering model. 3.1 The Baseline Phrase-based SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the hi"
W07-0401,E03-1076,0,0.0308904,"uistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains. In this paper, we present a strategy to reorder a source sentence using rules based on syntactic chunks. It is possible to integrate reordering rules directly into the search process, but here, we consider a more modular approach: easy to exchange reordering strategy. To avoid hard decisions before SMT, we generate a source-reordering latti"
W07-0401,N04-1021,0,0.0401596,"reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains. In this paper, we present a strategy to reorder a source sentence using rules based on syntactic chunks. It is possible to integrate reordering rules directly into the search process, but here, we consider a more modular approach: easy to exchange reordering strategy. To avoid hard decisions before SMT, we generate a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Then, the dec"
W07-0401,P03-1021,0,0.0258214,"tagging ′ (3) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (4) eˆI1 = argmax I,eI1 m=1 The log-linear model has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). The log-linear model is a natural framework to integrate many models. The baseline system uses the following models: • phrase translation model • phrase count features • word-based translation model • word and phrase penalty • target language model (6-gram) • distortion model (assigning costs based on the jump width) All the experiments in the paper are evaluated without rescoring. More details about the baseline system can be found in (Mauser et al., 2006) 3.2 Standard Translation Process Source Sentence Reordering Framework Encouraged by the work of (Xia and McCord, 2004) and (Crego and Ma"
W07-0401,P02-1040,0,0.108076,"et, the chunker has found 4 414 chunks, of which 2 879 are correct. Following the criteria of CoNLL-2000, the chunker is evaluated using the F-score, which is a combination of precision and recall. The result is shown in Table 3. The accuracy is evaluated at the word level, the other three metrics are evaluated at the chunk level. The results at the chunk level are worse than at the word level, because a chunk is counted as correct only if the chunk tag and the chunk boundaries are both correct. 6.2 Translation Results For the translation experiments, we report the two accuracy measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) as well as the two error rates word error rate (WER) and positionindependent word error rate (PER). We perform translation experiments on the Basic Traveling Expression Corpus (BTEC) for the Chinese-English task. It is a speech translation task in the domain of tourism-related information. We report results on the IWSLT 2004, 2005 and 2006 evaluation test sets. There are 16 reference translations for the IWSLT 2004 and 2005 tasks and 7 reference translations for the IWSLT 2006 task. Table 4 shows the corpus statistics of the task. A training corpus is used to train"
W07-0401,popovic-ney-2006-pos,1,0.723734,"Missing"
W07-0401,N04-1023,0,0.0246519,". (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains. In this paper, we present a strategy to reorder a source sentence using rules based on syntactic chunks. It is possible to integrate reordering rules directly into the search process, but here, we consider a more modular approach: easy to exchange reordering strategy. To avoid hard decisions before SMT, we generate a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Then, the decoder uses the reordered"
W07-0401,P97-1037,1,0.748365,"Missing"
W07-0401,P96-1021,0,0.568755,"Missing"
W07-0401,J97-3002,0,0.0884327,"he experiments also show that the reordering at the chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al."
W07-0401,2006.iwslt-evaluation.15,1,0.872897,"Missing"
W07-0401,C04-1073,0,0.843508,"that the chunk-level source reordering is helpful for phrase-based statistical machine translation. Finally, we conclude this paper and discuss future work in Section 7. 2 Related Work Beside the reordering methods during decoding, an alternative approach is to reorder the input source sentence to match the word order of the target sentence. Some reordering methods are carried out on syntactic source trees. (Collins et al., 2005) describe a method for reordering German for German-toEnglish translation, where six transformations are applied to the surface string of the parsed source sentence. (Xia and McCord, 2004) propose an approach for translation from French-to-English. This approach automatically extracts rewrite patterns by parsing the source and target sides of the training corpus. These rewrite patterns can be applied to any input source sentence so that the rewritten source and target sentences have similar word order. Both methods need a parser to generate trees of source sentences and are applied only as a preprocessing step. Another kind of source reordering methods besides full parsing is based on Part-Of-Speech (POS) tags or word classes. (Costa-juss`a and Fonollosa, 2006) view the source"
W07-0401,P04-1083,0,0.0139731,"he chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in rera"
W07-0401,P01-1067,0,0.196377,"ents also show that the reordering at the chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use"
W07-0401,2001.mtsummit-papers.45,1,0.83032,"l source sentence as the input to the translation system. The use of a lattice avoids hard decisions before translation. To generate the reordering lattice, the source sentence is first POS tagged and chunk parsed. Then, reordering rules are applied to the chunks to generate the reordering lattice. Reordering rules are the key information for source reordering. They are automatically learned from the training data. The details of these two modules will be introduced in Section 5. 4 Reordering Rules There has been much work on learning and applying reordering rules on source language, such as (Nießen and Ney, 2001; Xia and McCord, 2004; Collins et al., 2005; Chen et al., 2006; Crego and Mari˜no, 2006; Popovi´c and Ney, 2006). The reordering rules could be composed of words, POS tags or syntactic tags of phrases. In our work, a rule is composed of chunk tags and POS tags. There is Table 1: Examples of reordering rules. (lhs: chunk and POS tag sequence, rhs: permutation ) no. lhs rhs 1. N P0 P P1 u2 n3 0123 2. N P0 P P1 u2 n3 3012 3. DN P0 N P1 V P2 012 4. DN P0 N P1 V P2 102 5. DN P0 N P1 m2 012 6. DN P0 N P1 m2 ad3 3012 7. DN P0 N P1 m2 ad3 v4 4 3 0 1 2 Figure 2: Illustration of three kinds of phrases:"
W07-0401,2002.tmi-tutorials.2,0,0.375381,"e. Then, the reordered source sentence is taken as the single input to the standard SMT system. (Chen et al., 2006) automatically extract rules from word alignments. These rules are defined at the POS level and the scores of matching rules are used as additional feature functions during rescor2 ing. (Crego and Mari˜no, 2006) integrate source-side reordering into SMT decoding. They automatically learn rewrite patterns from word alignment and represent the patterns with POS tags. To our knowledge no work is reported on the reordering with shallow parsing. Decoding lattices were already used in (Zens et al., 2002; Kanthak et al., 2005). Those approaches used linguistically uninformed word-level reorderings. 3 System Overview In this section, we will describe the phrase-based SMT system which we use for the experiments. Then, we will give an outline of the extentions with the chunk-level source reordering model. 3.1 The Baseline Phrase-based SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose t"
W07-0401,P02-1038,1,0.173932,"ne translation (Brown et al., 1990). It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model (Och and Ney, 2002), we obtain: P  M I, fJ) exp λ h (e m=1 m m 1 1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e 1 1 m=1 m m I ′ ,e′ I1 Translation Proces with Source Reordering source text sentences source text sentences POS tagging ′ (3) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (4) eˆI1 = argmax I,eI1 m=1 The log-linear model has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling"
W07-0401,J03-1002,1,0.00578346,"xtraction algorithm ˜K (Zens et al., 2002) to (F1K , eI1 , a 1 ). Discarding the cross phrases, we keep the other phrases as rules. In a cross phrase, at least two chunk-word alignments overlap on the target language side. An example of a cross phrase is illustrated in Figure 2(c). Figure 2(a) and (b) illustrate the phrases for reordering rules, which could be monotone phrases or reordering phrases. 5 Reordering Lattice Generation 5.1 The extraction of reordering rules is based on the word alignment and the source sentence chunks. Here, we train word alignments in both directions with GIZA++ (Och and Ney, 2003). To get alignment with high accuracy, we use the intersection alignment here. For a given word-aligned sentence pair J (f1 , eI1 , aJ1 ), the source word sequence f1J is first parsed into a chunk sequence F1K . Accordingly, the word-to-word alignment aJ1 is changed to a chunk-to-word alignment a ˜K 1 which is the combination of the target words aligned to the source words in a chunk. It is defined as: a ˜k = {i|i = aj ∧ j ∈ [jk , jk+1 − 1]} The first step of chunk parsing is word segmentation. Then, a POS tagger is usually needed for further syntactic analysis. In our experiments, we use the"
W07-0401,W03-1709,0,0.0317502,"For a given word-aligned sentence pair J (f1 , eI1 , aJ1 ), the source word sequence f1J is first parsed into a chunk sequence F1K . Accordingly, the word-to-word alignment aJ1 is changed to a chunk-to-word alignment a ˜K 1 which is the combination of the target words aligned to the source words in a chunk. It is defined as: a ˜k = {i|i = aj ∧ j ∈ [jk , jk+1 − 1]} The first step of chunk parsing is word segmentation. Then, a POS tagger is usually needed for further syntactic analysis. In our experiments, we use the tool of “Inst. of Computing Tech., Chinese Lexical Analysis System (ICTCLAS)” (Zhang et al., 2003), which does the two tasks in one pass. Referring to the description of the chunking task in CoNLL-20001 , instead of English, a Chinese chunker is processed and evaluated. Each word is assigned a chunk tag, which contains the name of the chunk type and ”B” for the first word of the chunk and ”I” for each other word in the chunk. The ”O” chunk tag is used for tokens which are not part of any chunk. We use the maximum entropy tool YAS1 4 Parsing the Source Sentence http://www.cnts.ua.ac.be/conll2000/chunking/ Figure 3: Example of applying rules. The left part is the used rules. The right part i"
