2020.aacl-main.77,N19-1423,0,0.00777534,"ying graph based ranking is SEAL (Wang and Cohen, 2007) • SEISA. SEISA (He and Xin, 2011) is an entity set expansion system developed by Microsoft after SEAL and outperforms traditional graph-based methods by an original unsupervised similarity metric. We implement its Dynamic Thresholding algorithm to sort expanded concepts. • EMB. Embedding based method mainly utilizes context information to examine the similarity between expanded concepts and seeds according to (Mamou et al., 2018). For each expanded concept e, we calculate the sum of its cosine similarities with course concepts M in BERT (Devlin et al., 2019) and use the average as golden standard to rank the expanded concept list. • PUL. PU learning is a semi-supervised learning model regarding set expansion as a binary classification task. We employ the same setting as (Wang et al., 2017) to classify and sort concepts. • PIP. It is a pipeline method for course concept expansion (Yu et al., 2019a), which first uses an online clustering method during candidate generation and then classify them to obtain final expansion results. We follow the workflow of this work to sort expanded concepts. 4.1.4 Evaluation Metrics Our objective is to generate a ra"
2020.aacl-main.77,I17-1088,1,0.731139,"ed as N t the likelihood can be formalized as P (ct0 ∈ N t ⊂ Lt |K t , t0 ). The expansion set is refreshed as Ect+1 = Ect ∪ N t until its size reaches the preset upper limit τ or cannot find new candidates (He and Xin, 2011). 2.3 Preliminaries 2.1 base KB as an external source, the task is to return a ranked list of expanded concepts Ec . In this formulation, a course corpus is defined as D = {C j }|n| , which is composed of n courses’ j=1 video subtitles in the same subject area. Course concepts are the subjects taught in the course (such |M| as LSTM in Figure 1), denoted as M = {ci }i=1 . (Pan et al., 2017). Knowledge base KB = (E, R) is consist of concepts E and relations R, which is utilized as an external source to obtain expansion candidates. Though other source (such as Web tables) can also take on this role, we still employ a KB to search for expansion candidates like the prior work, i.e., Ec ⊂ E. Interactive MOOC Environment The workflow above has been experimentally proven to be effective in many concept expansion tasks (Shen et al., 2018; Rastogi et al., 2019). However, such methods only consider the course concepts’ semantic information, which makes their expansion results hard to matc"
2020.aacl-main.77,C10-1112,0,0.0130339,"(The overlap rises from 0.005 to 0.091), which indicates that our model can provide more high-quality concepts. 5 Related Work Our work follows the task of concept expansion in MOOCs (Yu et al., 2019a), a particular type of set expansion problem, which takes several seeds as input and expands the entity set. Set expansion was born to serve knowledge acquisition applications on the Internet. Google Sets was a pioneer which leaded a series of early research, e.g. Bayesian Sets (Ghahramani and Heller, 2006), SEAL (Wang and Cohen, 2007), SEISA (He and Xin, 2011) and others (Sarmento et al., 2007; Shi et al., 2010; Wang et al., 2015). These efforts utilize web tables as a resource and mainly serves for search engines. Recently, more related research has turned its attention to other application fields, such as news mining (Redondo-Garc´ıa et al., 2014), knowledge graphs (Zhang et al., 2017), education assistance (Yu et al., 2019a), etc. Meanwhile, corpus-based expansion methods snowball, and iterative bootstrapping became a common solution (Shen et al., 2017; Yu et al., 2019b; Yan et al., 2019), which expands the set in round and select high-quality results to extract feature iteratively. ExpanRL is in"
2020.aacl-main.77,D18-2004,0,0.062772,"24 user behaviors from a real MOOC website. 2 Problem Formulation Following (Yu et al., 2019a), Course Concept Expansion is formally defined as: given the course corpus D, course concepts M, and a knowledge 2 A course from the University of London in Coursera. 2.2 Basic Model for Concept Expansion The general idea of concept expansion is first to characterize the concept set according to its representative elements, then find new candidates and rank them to expand the set. Seed Selection Stage. A group of representative concepts are called seeds and formalized to K ⊂ Ec (Wang and Cohen, 2007; Mamou et al., 2018). While the expansion process is often carried out iteratively, we also formalize the expansion set of round t to Ect . Seed selection is to calculate the possibility that each concept in Ect becomes a seed, i.e., P (ci ∈ K t ⊂ Ect |t), where K t contains the seeds of t-th round. Based on these seeds, we can extract features of the current set and search for candidate concepts for expansion from external sources. Expansion Stage. After finding a new list of candi t dates L = c1 , ..., ct0 , ..., c|Lt |, expansion stage aims to calculate the likelihood of ct0 to be a expanded concept. The top"
2020.aacl-main.77,D17-1059,0,0.0276969,"larity metric. We implement its Dynamic Thresholding algorithm to sort expanded concepts. • EMB. Embedding based method mainly utilizes context information to examine the similarity between expanded concepts and seeds according to (Mamou et al., 2018). For each expanded concept e, we calculate the sum of its cosine similarities with course concepts M in BERT (Devlin et al., 2019) and use the average as golden standard to rank the expanded concept list. • PUL. PU learning is a semi-supervised learning model regarding set expansion as a binary classification task. We employ the same setting as (Wang et al., 2017) to classify and sort concepts. • PIP. It is a pipeline method for course concept expansion (Yu et al., 2019a), which first uses an online clustering method during candidate generation and then classify them to obtain final expansion results. We follow the workflow of this work to sort expanded concepts. 4.1.4 Evaluation Metrics Our objective is to generate a ranked list of expanded concepts. Thus, we use the Mean Average Precision(MAP) as our evaluation metric, which is the preferred metric in information retrieval for evaluating ranked lists. 4.2 Overall Evaluation Table 2 summarizes the com"
2020.aacl-main.77,D19-1028,0,0.0601988,"Missing"
2020.aacl-main.77,P19-1421,1,0.5905,"lassrooms, these concepts are often considerately introduced by teachers. ∗ 1 Corresponding author. https://www.coursera.org However, in the era of Massive Open Online Courses (MOOCs), thousands of courses are prerecorded for with millions of students with various backgrounds (Shah, 2019), which makes it infeasible to pick out these essential concepts manually. Therefore, there is a clear need to automatically discover course-related concepts so that they can easily acquire additional knowledge and achieve better educational outcomes. This task is formally defined as Course Concept Expansion (Yu et al., 2019a), a special type of Concept Expansion or Set Expansion (Wang and Cohen, 2007), which refers to the task of expanding a small set of seed concepts into a complete set of concepts that belong to the same course or subject from external resources. Despite abundant efforts in related topics (He and Xin, 2011; Shen et al., 2017; Yan et al., 2019), existing methods still face three challenges when applied to MOOCs. First, distinct from the task of enriching a certain concept set, the purpose of course concept expansion is to benefit students’ learning, making the context information insufficient t"
2020.acl-main.285,W17-5029,0,0.01302,"ught in the course videos. For each video, we extract 10 most representative course concepts from subtitles (Pan et al., 2017b). We also record the concept description from Wikidata and search top 10 related papers for each concept via AMiner3 (Tang et al., 2008) as external resource. Moreover, as many NLP types of research are interested in discovering semantic relationships among concepts, we further build a novel concept taxonomy with prerequisite chains as a concept graph (Gordon et al., 2016). Concept Taxonomy. A solid concept taxonomy is favorable for further research in course content (Gordon et al., 2017). However, existing taxonomies like ConceptNet (Liu and Singh, 2004) or Wiki Taxonomy (Ponzetto and Strube, 2007) cannot be directly applied to course concepts because course concepts are mostly academic terms and the non-academic categories greatly interfere with the quality of taxonomy. Thus, we select a crosslingual term taxonomy from CNCTST4 as a basis and lead manual annotation to build a serviceable course concept taxonomy for MOOCCube. Prerequisite Chain. Prerequisite relation is defined as: If concept A can help understanding concept B, then there is a prerequisite relation from A to B"
2020.acl-main.285,P16-1082,0,0.195076,"ikidata2 as an external resource. 1 2 2.3 Concept and Concept Graph Course concepts refer to the knowledge concepts taught in the course videos. For each video, we extract 10 most representative course concepts from subtitles (Pan et al., 2017b). We also record the concept description from Wikidata and search top 10 related papers for each concept via AMiner3 (Tang et al., 2008) as external resource. Moreover, as many NLP types of research are interested in discovering semantic relationships among concepts, we further build a novel concept taxonomy with prerequisite chains as a concept graph (Gordon et al., 2016). Concept Taxonomy. A solid concept taxonomy is favorable for further research in course content (Gordon et al., 2017). However, existing taxonomies like ConceptNet (Liu and Singh, 2004) or Wiki Taxonomy (Ponzetto and Strube, 2007) cannot be directly applied to course concepts because course concepts are mostly academic terms and the non-academic categories greatly interfere with the quality of taxonomy. Thus, we select a crosslingual term taxonomy from CNCTST4 as a basis and lead manual annotation to build a serviceable course concept taxonomy for MOOCCube. Prerequisite Chain. Prerequisite re"
2020.acl-main.285,D15-1193,0,0.0605022,"Missing"
2020.acl-main.285,P17-1133,1,0.842146,"p: //moocdata.cn/data/MOOCCube. 1 Introduction Massive open online courses (MOOCs) boom swiftly in recent years and have provided convenient education for over 100 million users worldwide (Shah, 2019). As a multi-media, large-scale online interactive system, MOOC is an excellent platform for advanced application research (Volery and Lord, 2000). Since MOOC is committed to helping students learn implicit knowledge concepts from diverse courses, many efforts from NLP and AI raise topics to build novel applications for assistance. From extracting course concepts and their prerequisite relations (Pan et al., 2017b; Roy et al., 2019; Li et al., 2019) to analyzing student behaviors (Zhang et al., 2019; Feng et al., 2019), MOOC-related topics, tasks, and methods snowball in recent years. Despite the plentiful research interests, the resource from real MOOCs is still impoverished. ∗ † Equal Contribution. Corresponding author. Most of the publicly available datasets are designed for a specific task or method, e.g., Zhang et al.(2019) build a MOOC enrollment dataset for course recommendation and (Yu et al., 2019) is only for course concept expansion, which merely contains a subset of MOOC elements. Conseque"
2020.acl-main.285,I17-1088,1,0.833296,"p: //moocdata.cn/data/MOOCCube. 1 Introduction Massive open online courses (MOOCs) boom swiftly in recent years and have provided convenient education for over 100 million users worldwide (Shah, 2019). As a multi-media, large-scale online interactive system, MOOC is an excellent platform for advanced application research (Volery and Lord, 2000). Since MOOC is committed to helping students learn implicit knowledge concepts from diverse courses, many efforts from NLP and AI raise topics to build novel applications for assistance. From extracting course concepts and their prerequisite relations (Pan et al., 2017b; Roy et al., 2019; Li et al., 2019) to analyzing student behaviors (Zhang et al., 2019; Feng et al., 2019), MOOC-related topics, tasks, and methods snowball in recent years. Despite the plentiful research interests, the resource from real MOOCs is still impoverished. ∗ † Equal Contribution. Corresponding author. Most of the publicly available datasets are designed for a specific task or method, e.g., Zhang et al.(2019) build a MOOC enrollment dataset for course recommendation and (Yu et al., 2019) is only for course concept expansion, which merely contains a subset of MOOC elements. Conseque"
2020.acl-main.285,P19-1421,1,0.843803,"applications for assistance. From extracting course concepts and their prerequisite relations (Pan et al., 2017b; Roy et al., 2019; Li et al., 2019) to analyzing student behaviors (Zhang et al., 2019; Feng et al., 2019), MOOC-related topics, tasks, and methods snowball in recent years. Despite the plentiful research interests, the resource from real MOOCs is still impoverished. ∗ † Equal Contribution. Corresponding author. Most of the publicly available datasets are designed for a specific task or method, e.g., Zhang et al.(2019) build a MOOC enrollment dataset for course recommendation and (Yu et al., 2019) is only for course concept expansion, which merely contains a subset of MOOC elements. Consequently, they are not feasible enough to support ideas that demand more types of information. Moreover, these datasets only contain a small size of specific entities or relation instances, e.g., prerequisite relation of TutorialBank (Fabbri et al., 2018) only has 794 cases, making it insufficient for advanced models (such as graph neural networks). Therefore, we present MOOCCube, a data repository that integrates courses, concepts, student behaviors, relationships, and external resources. Compared with"
2020.acl-main.522,C18-1075,0,0.0384593,"d teacher model. 3.2 Knowledge Collection Open-domain trigger knowledge elaborates whether a word triggers an event from the perspective of word sense. Whether the trigger is densely labeled or unseen/sparsely labeled, open-domain trigger knowledge will identify them without distinction. For instance in S3 in Figure 1, although hacked is a rare word and has not been labeled, judging from word sense, open-domain trigger knowledge successfully identifies hacked as a trigger word. We adopt a light-weight pipeline method, called Trigger From WordNet (TFW), to collect opendomain trigger knowledge (Araki and Mitamura, 2018). S + = T F W (S) (1) TFW uses WordNet as the intermediary. It has two steps, 1) disambiguate word into WordNet sense, 2) determine whether a sense triggers an event. For the first step, we adopt IMS (Zhong and Ng, 2010) to disambiguate word into word sense in WordNet (Miller et al., 1990). We obtain the input features by POS tagger and dependency parser in Stanford CoreNLP (Manning et al., 2014). For the second step, we adopt the simple dictionary-lookup approach proposed in (Araki and Mitamura, 2018) to determine whether a sense triggers an event. TFW is not limited to particular domains, wh"
2020.acl-main.522,K18-2017,0,0.0165638,"owledge is implied in the dependency parse tree. The closer in tree, the more important of the word for the trigger (McClosky et al., 2011). Our baseline (Nguyen and Grishman, 2018) is the best syntactic knowledge enhanced model, which exploits structure dependency tree information via graph convolutions networks. 3) Argument knowledge. Event arguments play an important role in ED. Our baseline ANN-S2 (Liu et al., 2017) designs a supervised attention to leverage the event argument knowledge. For the adaption of our model, we obtain entity annotations by Stanford CoreNLP, syntactic by NLP-Cube(Boro et al., 2018) and argument by CAMR (Wang et al., 2015). The marking contents are: 1) For entity, we tag three basic entity types, People, Location and Organization. 2) For 5893 Table 4: Performance on domain adaption. We train our model on two source domains bn and nw, and test our model on three target domains bc, cts and wl. Methods MaxEnt Joint Nguyen’s CNN PLMEE EKD (ours) In-Domain (bn+nw) P R F 74.5 59.4 66.0 73.5 62.7 67.7 69.2 67.0 68.0 77.1 65.7 70.1 77.8 76.1 76.9 P 70.1 70.3 70.2 72.9 80.8 bc R 54.5 57.2 65.2 67.1 65.1 F 61.3 63.1 67.6 69.9 72.1 P 66.4 64.9 68.3 70.8 71.7 cts R 49.9 50.8 58.2 64"
2020.acl-main.522,C18-1057,1,0.818756,"se a novel teacher-student model (EKD) that can learn from both labeled and unlabeled data, so as to improve ED performance by reducing the in-built biases in annotations. • Experiments on benchmark ACE2005 show that our method surpasses nine strong baselines which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities. 2 2.1 Related Work Event Detection Traditional feature-based methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al"
2020.acl-main.522,P15-1017,0,0.705045,"anded data itself is unevenly distributed, and we cannot expect to alleviate the long tail problem with built-in bias data. In the paper, we empower the model with external knowledge called Open-Domain Trigger Knowledge to provides extra semantic support on unseen/sparsely labeled trigger words and improve trigger identification. Open-Domain Trig5887 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5887–5897 c July 5 - 10, 2020. 2020 Association for Computational Linguistics Table 1: F score on unseen/sparsely and densely labeled triggers. DMBERT (Chen et al., 2015) refers to a supervised-only model with dynamic multi-pooling to capture contextual features; BOOTSTRAP (He and Sun, 2017) expands training data via bootstrapping. DGBERT expands training data with Freebase (Chen et al., 2017). Method DMBERTsup−only BOOTSTRAPsemi−sup DGBERTdistant−sup Unseen 54.4 56.6 54.7 Sparse 72.5 73.6 72.8 also show that the proposed EKD architecture is very flexible, and can be conveniently adapted to distill other knowledge, such as entity, syntactic and argument. Our contributions can be summarized as: • To the best of our knowledge, we are the first to leverage the we"
2020.acl-main.522,I17-1036,0,0.330221,", so as to improve ED performance by reducing the in-built biases in annotations. • Experiments on benchmark ACE2005 show that our method surpasses nine strong baselines which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities. 2 2.1 Related Work Event Detection Traditional feature-based methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labe"
2020.acl-main.522,N18-2058,0,0.169854,"exical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sparsely labeled data and turn to overfitting densely labeled data. With open-domain trigger knowledge, our model is able to perceive the unseen/sparsely labeled trigger words from abundant unlabeled data, and thus successfully improve the recall of the trigger words. 5888"
2020.acl-main.522,P84-1044,0,0.626481,"Missing"
2020.acl-main.522,D19-1243,0,0.0502999,"Missing"
2020.acl-main.522,C16-1215,0,0.0133674,"hod surpasses nine strong baselines which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities. 2 2.1 Related Work Event Detection Traditional feature-based methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sp"
2020.acl-main.522,P13-1008,0,0.569162,"nseen/sparsely labeled triggers word. Experiments • We propose a novel teacher-student model (EKD) that can learn from both labeled and unlabeled data, so as to improve ED performance by reducing the in-built biases in annotations. • Experiments on benchmark ACE2005 show that our method surpasses nine strong baselines which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities. 2 2.1 Related Work Event Detection Traditional feature-based methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rule"
2020.acl-main.522,D18-1127,0,0.0626215,"s incorporate opendomain trigger knowledge, for fair competition, we compare our methods with two data-driven methods and five state-of-the-art knowledge-enhanced methods, including: DMCNN proposes a dynamic multi-pooling layer above CNN model to improve event detection (Chen et al., 2015). DLRNN exploits document information via recurrent neural networks (Duan et al., 2017). ANN-S2 exploits argument information to improve ED via supervised attention mechanisms (Liu et al., 2017).GMLATT adopts a gated cross-lingual attention to exploit the complement information conveyed by multilingual data (Liu et al., 2018a). GCN-ED exploits structure dependency tree information via graph convolutions networks and entity mentionguided pooling (Nguyen and Grishman, 2018). Lu’s DISTILL proposes a -learning approach to distill generalization knowledge to handle overfitting (Lu et al., 2019). TS-DISTILL exploits the entity ground-truth and uses an adversarial imitation based knowledge distillation approach for ED (Liu et al., 2019). AD-DMBERT adopts an adversarial imitation model to expend more training data (Wang et al., 2019b). DRMM employs an alternative dual attention mechanism to effectively integrate image in"
2020.acl-main.522,P17-1164,0,0.100401,"Missing"
2020.acl-main.522,P19-1429,0,0.213231,"Missing"
2020.acl-main.522,P14-5010,0,0.00243929,"open-domain trigger knowledge successfully identifies hacked as a trigger word. We adopt a light-weight pipeline method, called Trigger From WordNet (TFW), to collect opendomain trigger knowledge (Araki and Mitamura, 2018). S + = T F W (S) (1) TFW uses WordNet as the intermediary. It has two steps, 1) disambiguate word into WordNet sense, 2) determine whether a sense triggers an event. For the first step, we adopt IMS (Zhong and Ng, 2010) to disambiguate word into word sense in WordNet (Miller et al., 1990). We obtain the input features by POS tagger and dependency parser in Stanford CoreNLP (Manning et al., 2014). For the second step, we adopt the simple dictionary-lookup approach proposed in (Araki and Mitamura, 2018) to determine whether a sense triggers an event. TFW is not limited to particular domains, which is able to provide unlimited candidate triggers. With the support of the lexical database, TFW has high efficiency and can be applied to large-scale knowledge collection. Finally, we obtain a total of 733,848 annotated sentences from New York Times (Sandhaus, 2008) 5889 Supervised Loss Labeled Data S5 Troops were trying to break up stone-throwing protests, but not use live fire. Feature Encod"
2020.acl-main.522,P11-1163,0,0.0464032,"sees unseen/sparsely triggers. 4.5 Knowledge-Agnostic Then, to evaluate whether EKD (ours) can distill other knowledge types, we conduct experiments on the three most commonly used knowledge in ED scenario: 1) Entity knowledge. Entity type is an important feature for trigger disambiguation in ED (Zhang et al., 2007). We compare with (Liu et al., 2019), which distills ground-truth entity type knowledge via an adversarial teacher-student model. 2) Syntactic knowledge. Syntactic knowledge is implied in the dependency parse tree. The closer in tree, the more important of the word for the trigger (McClosky et al., 2011). Our baseline (Nguyen and Grishman, 2018) is the best syntactic knowledge enhanced model, which exploits structure dependency tree information via graph convolutions networks. 3) Argument knowledge. Event arguments play an important role in ED. Our baseline ANN-S2 (Liu et al., 2017) designs a supervised attention to leverage the event argument knowledge. For the adaption of our model, we obtain entity annotations by Stanford CoreNLP, syntactic by NLP-Cube(Boro et al., 2018) and argument by CAMR (Wang et al., 2015). The marking contents are: 1) For entity, we tag three basic entity types, Peop"
2020.acl-main.522,C10-1077,0,0.197255,"sed methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sparsely labeled data and turn to overfitting densely labeled data. With open-domain trigger knowledge, our model is able to perceive the unseen/sparsely labeled trigger words from abundant unlabeled data, and thus successfully improve the recall o"
2020.acl-main.522,N16-1034,0,0.182034,"ize the prediction probability P (Yi |Si ) on labeled corpus L, 2) minimize the prediction prob0 ability discrepancy between the teacher P (Yk |Sk+ ) 0 and student model P (Yk |Sk− ) on both L and U , where NT stand for the total number of sentences in both labeled and unlabeled data. S + and S − stand for the enhanced and weakened variant of the raw sentence S, we will explain them in detail in the Section 3.5. Y = {y1 , y2 , . . . , yn } stands for the golden event type label, where each y ∈ Y belongs to the 33 event types pre-defined in ACE and a ”NEGATIVE” event type (Chen et al., 2015; 0 Nguyen et al., 2016; Feng et al., 2018). Y is the pseudo label proposed by pre-trained teacher model. 3.2 Knowledge Collection Open-domain trigger knowledge elaborates whether a word triggers an event from the perspective of word sense. Whether the trigger is densely labeled or unseen/sparsely labeled, open-domain trigger knowledge will identify them without distinction. For instance in S3 in Figure 1, although hacked is a rare word and has not been labeled, judging from word sense, open-domain trigger knowledge successfully identifies hacked as a trigger word. We adopt a light-weight pipeline method, called Tri"
2020.acl-main.522,P10-1081,0,0.347002,"sed methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sparsely labeled data and turn to overfitting densely labeled data. With open-domain trigger knowledge, our model is able to perceive the unseen/sparsely labeled trigger words from abundant unlabeled data, and thus successfully improve the recall o"
2020.acl-main.522,P14-2012,0,0.0129714,"ills 5892 the knowledge into the model. During testing, our model needs no more engineering work for knowledge collection. Table 3: Performance of test set with or without opendomain trigger knowledge Test Set without knowledge with knowledge 4.3 P 78.8 79.1 R 78.1 78.0 F 78.4 78.6 Domain Adaption Scenario We use ACE2005 to simulate a domain adaption scenario. ACE2005 is a multi-domain dataset, with six domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and webblogs (wl). Following the common practice (Plank and Moschitti, 2013; Nguyen and Grishman, 2014), we adopt the union of bc and nw as source domains, and bc, ct, wl as three target domains. The event types and vocabulary distribution are quite different between the source and target domains (Plank and Moschitti, 2013). For evaluation, we split source domain data into train/test 4:1 and report the average results on ten runs as the final result. For baselines, MaxEnt and Joint (Li et al., 2013) are two feature-enriched methods, exploiting both lexical and global features to enhance the domain adaption ability. Nguyen’s CNN (Nguyen and Grishman, 2015) integrates the feature and neural appro"
2020.acl-main.522,P15-2060,0,0.223278,"on practice (Plank and Moschitti, 2013; Nguyen and Grishman, 2014), we adopt the union of bc and nw as source domains, and bc, ct, wl as three target domains. The event types and vocabulary distribution are quite different between the source and target domains (Plank and Moschitti, 2013). For evaluation, we split source domain data into train/test 4:1 and report the average results on ten runs as the final result. For baselines, MaxEnt and Joint (Li et al., 2013) are two feature-enriched methods, exploiting both lexical and global features to enhance the domain adaption ability. Nguyen’s CNN (Nguyen and Grishman, 2015) integrates the feature and neural approaches and proposes a joint CNN for domain adaption. We also compare with supervised SOTA PLMEE (Yang et al., 2019), which exploits the pre-trained language model BERT for event extraction. As illustrated in Table 4, our method achieves the best adaptation performance on both bc and wl target domains and achieve comparable performance on cts target domain. The superior of domain adaption may come from the open-domain trigger knowledge. The open-domain trigger knowledge is not subject to specific domains, which will detect all the event-oriented trigger wo"
2020.acl-main.522,P13-1147,0,0.0176185,"hows EKD (our) already distills 5892 the knowledge into the model. During testing, our model needs no more engineering work for knowledge collection. Table 3: Performance of test set with or without opendomain trigger knowledge Test Set without knowledge with knowledge 4.3 P 78.8 79.1 R 78.1 78.0 F 78.4 78.6 Domain Adaption Scenario We use ACE2005 to simulate a domain adaption scenario. ACE2005 is a multi-domain dataset, with six domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and webblogs (wl). Following the common practice (Plank and Moschitti, 2013; Nguyen and Grishman, 2014), we adopt the union of bc and nw as source domains, and bc, ct, wl as three target domains. The event types and vocabulary distribution are quite different between the source and target domains (Plank and Moschitti, 2013). For evaluation, we split source domain data into train/test 4:1 and report the average results on ten runs as the final result. For baselines, MaxEnt and Joint (Li et al., 2013) are two feature-enriched methods, exploiting both lexical and global features to enhance the domain adaption ability. Nguyen’s CNN (Nguyen and Grishman, 2015) integrates"
2020.acl-main.522,P18-1096,0,0.0189421,"tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sparsely labeled data and turn to overfitting densely labeled data. With open-domain trigger knowledge, our model is able to perceive the unseen/sparsely labeled trigger words from abundant unlabeled data, and thus successfully improve the recall of the trigger words. 5888 2.2 Knowledge Distillation Knowledge Distillation, initially proposed by (Hinton et al., 2015), has been widely adopted in NLP to distill external knowledge into the model (Laine and Aila, 2016; Saito et al., 2017; Ruder and Plank, 2018). The main idea is to adopt a student model to learn from a robust pre-trained teacher model. (Lee et al., 2018; Gong et al., 2018) reinforces the connection between teacher and student model by singular value decomposition and the laplacian regularized least squares. (Tarvainen and Valpola, 2017; Huang et al., 2018) stabilize the teacher model by a lazy-updated mechanism to enable student model not susceptible to external disturbances. (Liu et al., 2019) uses an adversarial imitation approach to enhance the learning procedure. Unlike previous methods that relied on golden annotations, our met"
2020.acl-main.522,N19-1105,0,0.739033,"al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sparsely labeled data and turn to overfitting densely labeled data. With open-domain trigger knowledge, our model is able to perceive the unseen/sparsely labeled trigger words from abundant unlabeled data, and thus successfully improve the recall of the trigger words. 5888 2.2 Knowledge Distillation Knowledge Distillation, initially proposed by (Hinton et al., 2015), has been w"
2020.acl-main.522,P18-4009,0,0.0180243,"h knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities. 2 2.1 Related Work Event Detection Traditional feature-based methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled data and the homogeneity of the generated data, previous methods perform badly on unseen/sparsely labeled data and turn to overfitting densely labeled"
2020.acl-main.522,P19-1522,0,0.524491,"the in-built biases in annotations. • Experiments on benchmark ACE2005 show that our method surpasses nine strong baselines which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities. 2 2.1 Related Work Event Detection Traditional feature-based methods exploit both lexical and global features to detect events (Li et al., 2013). As neural networks become popular in NLP (Cao et al., 2018), data-driven methods use various superior DMCNN, DLRNN and PLMEE model (Duan et al., 2017; Nguyen and Grishman, 2018; Yang et al., 2019) for end-to-end event detection. Recently, weakly-supervised methods (Judea and Strube, 2016; Huang et al., 2017; Zeng et al., 2018; Yang et al., 2018) has been proposed to generate more labeled data. (Gabbard et al., 2018) identifies informative snippets of text as expending annotated data via curated training. (Liao and Grishman, 2010a; Ferguson et al., 2018) rely on sophisticated pre-defined rules to bootstrap from the paralleling news streams. (Wang et al., 2019a) limits the data range of adversarial learning to trigger words appearing in labeled data. Due to the long tail issue of labeled"
2020.acl-main.522,P19-1279,0,0.0579952,"Missing"
2020.acl-main.522,P18-2066,0,0.255399,"Missing"
2020.acl-main.522,N15-1040,0,0.0132405,"e tree. The closer in tree, the more important of the word for the trigger (McClosky et al., 2011). Our baseline (Nguyen and Grishman, 2018) is the best syntactic knowledge enhanced model, which exploits structure dependency tree information via graph convolutions networks. 3) Argument knowledge. Event arguments play an important role in ED. Our baseline ANN-S2 (Liu et al., 2017) designs a supervised attention to leverage the event argument knowledge. For the adaption of our model, we obtain entity annotations by Stanford CoreNLP, syntactic by NLP-Cube(Boro et al., 2018) and argument by CAMR (Wang et al., 2015). The marking contents are: 1) For entity, we tag three basic entity types, People, Location and Organization. 2) For 5893 Table 4: Performance on domain adaption. We train our model on two source domains bn and nw, and test our model on three target domains bc, cts and wl. Methods MaxEnt Joint Nguyen’s CNN PLMEE EKD (ours) In-Domain (bn+nw) P R F 74.5 59.4 66.0 73.5 62.7 67.7 69.2 67.0 68.0 77.1 65.7 70.1 77.8 76.1 76.9 P 70.1 70.3 70.2 72.9 80.8 bc R 54.5 57.2 65.2 67.1 65.1 F 61.3 63.1 67.6 69.9 72.1 P 66.4 64.9 68.3 70.8 71.7 cts R 49.9 50.8 58.2 64.0 61.3 F 56.9 57.0 62.8 67.2 66.1 P 59.4"
2020.acl-main.522,P10-4014,0,0.0225434,"main trigger knowledge will identify them without distinction. For instance in S3 in Figure 1, although hacked is a rare word and has not been labeled, judging from word sense, open-domain trigger knowledge successfully identifies hacked as a trigger word. We adopt a light-weight pipeline method, called Trigger From WordNet (TFW), to collect opendomain trigger knowledge (Araki and Mitamura, 2018). S + = T F W (S) (1) TFW uses WordNet as the intermediary. It has two steps, 1) disambiguate word into WordNet sense, 2) determine whether a sense triggers an event. For the first step, we adopt IMS (Zhong and Ng, 2010) to disambiguate word into word sense in WordNet (Miller et al., 1990). We obtain the input features by POS tagger and dependency parser in Stanford CoreNLP (Manning et al., 2014). For the second step, we adopt the simple dictionary-lookup approach proposed in (Araki and Mitamura, 2018) to determine whether a sense triggers an event. TFW is not limited to particular domains, which is able to provide unlimited candidate triggers. With the support of the lexical database, TFW has high efficiency and can be applied to large-scale knowledge collection. Finally, we obtain a total of 733,848 annotat"
2020.emnlp-main.129,buyko-etal-2010-genereg,0,0.0403765,"erent ways. The early MUC series datasets (Grishman and Sundheim, 1996) define event extraction as a slot-filling task. The TDT corpus (Allan, 2012) and some recent datasets (Minard et al., 2016; Araki and Mitamura, 2018; Sims et al., 2019; Liu et al., 2019) follow the open-domain paradigm, which does not require models to classify events into pre-defined event types for better coverage but limits the downstream application of the extracted events. Some datasets are developed for ED on specific domains, like the biomedical domain (Pyysalo et al., 2007; Kim et al., 2008; Thompson et al., 2009; Buyko et al., 2010; N´edellec et al., 2013), literature (Sims et al., 2019), Twitter (Ritter et al., 2012; Guo et al., 2013) and breaking news (Pustejovsky et al., 2003). These datasets are also typically small-scale due to the inherent complexity of event annotation, but their different settings are complementary to our work. 7 Conclusion and Future work In this paper, we present a massive general domain event detection dataset (MAVEN), which significantly alleviates the data scarcity and low coverage problems of existing datasets. We conduct a thorough evaluation of the state-of-the-art ED models on MAVEN. Th"
2020.emnlp-main.129,P17-1038,0,0.0587272,"vember 16–20, 2020. 2020 Association for Computational Linguistics ern sophisticated models. Moreover, the covered event types in existing datasets are limited. The ACE 2005 English dataset only contains 8 event types and 33 specific subtypes. The Rich ERE ontology (Song et al., 2015) used by TAC KBP challenges (Ellis et al., 2015, 2016) covers 9 event types and 38 subtypes. The coverage of these datasets is low for general domain events, which results in the models trained on these datasets cannot be easily transferred and applied on general applications. Recent research (Huang et al., 2016; Chen et al., 2017) has shown that the existing datasets suffering from the data scarcity and low coverage problems are now inadequate for benchmarking emerging methods, i.e., the evaluation results are difficult to reflect the effectiveness of novel methods. To tackle these issues, some works adopt the distantly supervised methods (Mintz et al., 2009) to automatically annotate data with existing event facts in knowledge bases (Chen et al., 2017; Zeng et al., 2018; Araki and Mitamura, 2018) or use bootstrapping methods to generate new data (Ferguson et al., 2018; Wang et al., 2019b). However, the generated data"
2020.emnlp-main.129,P15-1017,0,0.690388,"uld recognize that the word “founded” is the trigger of a Found event. ED ∗ Elect: 183 问ure: 142 Transfer-Ownership: 127 Phone-Write: 123 Start-Position: 118 Trial-Hearing: 109 Charge-Indict: 106 The Other 20 Types (&lt;100 instances): 889 Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn) Due to the rising requirement of event understanding, many efforts have been devoted to ED in recent years. The advanced models have been continuously proposed, including the feature-based models (Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013; Araki and Mitamura, 2015) and advanced neural models (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Feng et al., 2016; Ghaeini et al., 2016; Liu et al., 2017; Zhao et al., 2018; Chen et al., 2018; Ding et al., 2019; Yan et al., 2019). Nevertheless, the benchmark datasets for ED are upgraded slowly. As event annotation is complex and expensive, the existing datasets are mostly small-scale. As shown in Figure 1, the most widely-used ACE 2005 English dataset (Walker et al., 2006) only contains 599 documents and 5, 349 annotated instances. Due to the inherent data imbalance problem, 20 of its 33 event types only have fewer than 100 annotated inst"
2020.emnlp-main.129,D18-1158,0,0.305267,"osition: 118 Trial-Hearing: 109 Charge-Indict: 106 The Other 20 Types (&lt;100 instances): 889 Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn) Due to the rising requirement of event understanding, many efforts have been devoted to ED in recent years. The advanced models have been continuously proposed, including the feature-based models (Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013; Araki and Mitamura, 2015) and advanced neural models (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Feng et al., 2016; Ghaeini et al., 2016; Liu et al., 2017; Zhao et al., 2018; Chen et al., 2018; Ding et al., 2019; Yan et al., 2019). Nevertheless, the benchmark datasets for ED are upgraded slowly. As event annotation is complex and expensive, the existing datasets are mostly small-scale. As shown in Figure 1, the most widely-used ACE 2005 English dataset (Walker et al., 2006) only contains 599 documents and 5, 349 annotated instances. Due to the inherent data imbalance problem, 20 of its 33 event types only have fewer than 100 annotated instances. As recent neural methods are typically data-hungry, these small-scale datasets are not sufficient for training and stably benchmarking mod"
2020.emnlp-main.129,N18-1076,0,0.0271789,"mains a challenging task and requires further research efforts. We also discuss further directions for general domain ED with empirical analyses. The source code and dataset can be obtained from https:// github.com/THU-KEG/MAVEN-dataset. 1 End-Position: 212 Transfer-Money: 198 Attack: 1543 Figure 1: Data distribution of the most widely-used ACE 2005 English dataset. It contains 33 event types, 599 documents and 5, 349 instances in total. is the first stage to extract event knowledge from text (Ahn, 2006) and also fundamental to various NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018; Yang et al., 2019). Introduction Event detection (ED) is an important task of information extraction, which aims to identify event triggers (the words or phrases evoking events in text) and classify event types. For instance, in the sentence “Bill Gates founded Microsoft in 1975”, an ED model should recognize that the word “founded” is the trigger of a Found event. ED ∗ Elect: 183 问ure: 142 Transfer-Ownership: 127 Phone-Write: 123 Start-Position: 118 Trial-Hearing: 109 Charge-Indict: 106 The Other 20 Types (&lt;100 instances): 889 Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn) Due to the r"
2020.emnlp-main.129,N19-1423,0,0.0330633,"eural network baseline, which adopts the widely-used bi-directional long shortterm memory network to learn textual representations, and then uses the hidden states at the positions of trigger candidates for classifying event types. (3) MOGANED (Yan et al., 2019) is an advanced graph neural network (GNN) model. It proposes a multi-order graph attention network to effectively model the multi-order syntactic relations in dependency trees and improve ED. (4) DMBERT (Wang et al., 2019b) is a vanilla BERTbased model. It takes advantage of the effective pretrained language representation model BERT (Devlin et al., 2019) and also adopts the dynamic multi-pooling mechanism to aggregate features for ED. We use the BERTBASE architecture in our experiments. (5) Different from the above tokenlevel classification models, BiLSTM+CRF and BERT+CRF are sequence labeling models. To verify the effectiveness of modeling multiple event correlations, the two models both adopt the conditional random field (CRF) (Lafferty et al., 2001) as their output layers, which can model structured output dependencies. And they use BiLSTM and BERTBASE as their feature extractors respectively. As we manually tune hyperparameters and some t"
2020.emnlp-main.129,D19-1033,1,0.851706,"Hearing: 109 Charge-Indict: 106 The Other 20 Types (&lt;100 instances): 889 Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn) Due to the rising requirement of event understanding, many efforts have been devoted to ED in recent years. The advanced models have been continuously proposed, including the feature-based models (Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013; Araki and Mitamura, 2015) and advanced neural models (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Feng et al., 2016; Ghaeini et al., 2016; Liu et al., 2017; Zhao et al., 2018; Chen et al., 2018; Ding et al., 2019; Yan et al., 2019). Nevertheless, the benchmark datasets for ED are upgraded slowly. As event annotation is complex and expensive, the existing datasets are mostly small-scale. As shown in Figure 1, the most widely-used ACE 2005 English dataset (Walker et al., 2006) only contains 599 documents and 5, 349 annotated instances. Due to the inherent data imbalance problem, 20 of its 33 event types only have fewer than 100 annotated instances. As recent neural methods are typically data-hungry, these small-scale datasets are not sufficient for training and stably benchmarking mod1652 Proceedings of"
2020.emnlp-main.129,D16-1264,0,0.124091,"Missing"
2020.emnlp-main.129,P19-1276,0,0.0175457,"traction models (Ji and Grishman, 2008; Li et al., 2013; Chen et al., 2015; Feng et al., 2016; Liu et al., 2017; Zhao et al., 2018; Yan et al., 2019) are developed on these datasets. Our MAVEN follows the effective framework and extends it to numerous general domain event types and data instances. There are also various datasets defining the ED task in different ways. The early MUC series datasets (Grishman and Sundheim, 1996) define event extraction as a slot-filling task. The TDT corpus (Allan, 2012) and some recent datasets (Minard et al., 2016; Araki and Mitamura, 2018; Sims et al., 2019; Liu et al., 2019) follow the open-domain paradigm, which does not require models to classify events into pre-defined event types for better coverage but limits the downstream application of the extracted events. Some datasets are developed for ED on specific domains, like the biomedical domain (Pyysalo et al., 2007; Kim et al., 2008; Thompson et al., 2009; Buyko et al., 2010; N´edellec et al., 2013), literature (Sims et al., 2019), Twitter (Ritter et al., 2012; Guo et al., 2013) and breaking news (Pustejovsky et al., 2003). These datasets are also typically small-scale due to the inherent complexity of event a"
2020.emnlp-main.129,D18-1156,0,0.0338402,"Missing"
2020.emnlp-main.129,P19-1353,0,0.0176268,"of ED and event extraction models (Ji and Grishman, 2008; Li et al., 2013; Chen et al., 2015; Feng et al., 2016; Liu et al., 2017; Zhao et al., 2018; Yan et al., 2019) are developed on these datasets. Our MAVEN follows the effective framework and extends it to numerous general domain event types and data instances. There are also various datasets defining the ED task in different ways. The early MUC series datasets (Grishman and Sundheim, 1996) define event extraction as a slot-filling task. The TDT corpus (Allan, 2012) and some recent datasets (Minard et al., 2016; Araki and Mitamura, 2018; Sims et al., 2019; Liu et al., 2019) follow the open-domain paradigm, which does not require models to classify events into pre-defined event types for better coverage but limits the downstream application of the extracted events. Some datasets are developed for ED on specific domains, like the biomedical domain (Pyysalo et al., 2007; Kim et al., 2008; Thompson et al., 2009; Buyko et al., 2010; N´edellec et al., 2013), literature (Sims et al., 2019), Twitter (Ritter et al., 2012; Guo et al., 2013) and breaking news (Pustejovsky et al., 2003). These datasets are also typically small-scale due to the inherent co"
2020.emnlp-main.129,P19-1429,0,0.374622,"Missing"
2020.emnlp-main.129,W15-0812,0,0.406914,"problem, 20 of its 33 event types only have fewer than 100 annotated instances. As recent neural methods are typically data-hungry, these small-scale datasets are not sufficient for training and stably benchmarking mod1652 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 1652–1671, c November 16–20, 2020. 2020 Association for Computational Linguistics ern sophisticated models. Moreover, the covered event types in existing datasets are limited. The ACE 2005 English dataset only contains 8 event types and 33 specific subtypes. The Rich ERE ontology (Song et al., 2015) used by TAC KBP challenges (Ellis et al., 2015, 2016) covers 9 event types and 38 subtypes. The coverage of these datasets is low for general domain events, which results in the models trained on these datasets cannot be easily transferred and applied on general applications. Recent research (Huang et al., 2016; Chen et al., 2017) has shown that the existing datasets suffering from the data scarcity and low coverage problems are now inadequate for benchmarking emerging methods, i.e., the evaluation results are difficult to reflect the effectiveness of novel methods. To tackle these issues, so"
2020.emnlp-main.129,L16-1699,0,0.0619031,"Missing"
2020.emnlp-main.129,P09-1113,0,0.125379,"2016) covers 9 event types and 38 subtypes. The coverage of these datasets is low for general domain events, which results in the models trained on these datasets cannot be easily transferred and applied on general applications. Recent research (Huang et al., 2016; Chen et al., 2017) has shown that the existing datasets suffering from the data scarcity and low coverage problems are now inadequate for benchmarking emerging methods, i.e., the evaluation results are difficult to reflect the effectiveness of novel methods. To tackle these issues, some works adopt the distantly supervised methods (Mintz et al., 2009) to automatically annotate data with existing event facts in knowledge bases (Chen et al., 2017; Zeng et al., 2018; Araki and Mitamura, 2018) or use bootstrapping methods to generate new data (Ferguson et al., 2018; Wang et al., 2019b). However, the generated data are inevitably noisy and homogeneous due to the limited number and low diversity of event facts and seed data instances. In this paper, we present MAVEN, a humanannotated massive general domain event detection dataset constructed from English Wikipedia and FrameNet (Baker et al., 1998), which can alleviate the data scarcity and low c"
2020.emnlp-main.129,P18-2066,0,0.180224,"-Write: 123 Start-Position: 118 Trial-Hearing: 109 Charge-Indict: 106 The Other 20 Types (&lt;100 instances): 889 Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn) Due to the rising requirement of event understanding, many efforts have been devoted to ED in recent years. The advanced models have been continuously proposed, including the feature-based models (Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013; Araki and Mitamura, 2015) and advanced neural models (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Feng et al., 2016; Ghaeini et al., 2016; Liu et al., 2017; Zhao et al., 2018; Chen et al., 2018; Ding et al., 2019; Yan et al., 2019). Nevertheless, the benchmark datasets for ED are upgraded slowly. As event annotation is complex and expensive, the existing datasets are mostly small-scale. As shown in Figure 1, the most widely-used ACE 2005 English dataset (Walker et al., 2006) only contains 599 documents and 5, 349 annotated instances. Due to the inherent data imbalance problem, 20 of its 33 event types only have fewer than 100 annotated instances. As recent neural methods are typically data-hungry, these small-scale datasets are not sufficient for training and stab"
2020.emnlp-main.129,N19-1105,1,0.947896,"research (Huang et al., 2016; Chen et al., 2017) has shown that the existing datasets suffering from the data scarcity and low coverage problems are now inadequate for benchmarking emerging methods, i.e., the evaluation results are difficult to reflect the effectiveness of novel methods. To tackle these issues, some works adopt the distantly supervised methods (Mintz et al., 2009) to automatically annotate data with existing event facts in knowledge bases (Chen et al., 2017; Zeng et al., 2018; Araki and Mitamura, 2018) or use bootstrapping methods to generate new data (Ferguson et al., 2018; Wang et al., 2019b). However, the generated data are inevitably noisy and homogeneous due to the limited number and low diversity of event facts and seed data instances. In this paper, we present MAVEN, a humanannotated massive general domain event detection dataset constructed from English Wikipedia and FrameNet (Baker et al., 1998), which can alleviate the data scarcity and low coverage problems: (1) Our MAVEN dataset contains 111, 611 different events, 118, 732 event mentions, which is twenty times larger than the most widely-used ACE 2005 dataset, and 4, 480 annotated documents in total. To the best of our"
2020.emnlp-main.129,D19-1584,1,0.922895,"research (Huang et al., 2016; Chen et al., 2017) has shown that the existing datasets suffering from the data scarcity and low coverage problems are now inadequate for benchmarking emerging methods, i.e., the evaluation results are difficult to reflect the effectiveness of novel methods. To tackle these issues, some works adopt the distantly supervised methods (Mintz et al., 2009) to automatically annotate data with existing event facts in knowledge bases (Chen et al., 2017; Zeng et al., 2018; Araki and Mitamura, 2018) or use bootstrapping methods to generate new data (Ferguson et al., 2018; Wang et al., 2019b). However, the generated data are inevitably noisy and homogeneous due to the limited number and low diversity of event facts and seed data instances. In this paper, we present MAVEN, a humanannotated massive general domain event detection dataset constructed from English Wikipedia and FrameNet (Baker et al., 1998), which can alleviate the data scarcity and low coverage problems: (1) Our MAVEN dataset contains 111, 611 different events, 118, 732 event mentions, which is twenty times larger than the most widely-used ACE 2005 dataset, and 4, 480 annotated documents in total. To the best of our"
2020.emnlp-main.129,D19-1582,0,0.510191,"-Indict: 106 The Other 20 Types (&lt;100 instances): 889 Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn) Due to the rising requirement of event understanding, many efforts have been devoted to ED in recent years. The advanced models have been continuously proposed, including the feature-based models (Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013; Araki and Mitamura, 2015) and advanced neural models (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Feng et al., 2016; Ghaeini et al., 2016; Liu et al., 2017; Zhao et al., 2018; Chen et al., 2018; Ding et al., 2019; Yan et al., 2019). Nevertheless, the benchmark datasets for ED are upgraded slowly. As event annotation is complex and expensive, the existing datasets are mostly small-scale. As shown in Figure 1, the most widely-used ACE 2005 English dataset (Walker et al., 2006) only contains 599 documents and 5, 349 annotated instances. Due to the inherent data imbalance problem, 20 of its 33 event types only have fewer than 100 annotated instances. As recent neural methods are typically data-hungry, these small-scale datasets are not sufficient for training and stably benchmarking mod1652 Proceedings of the 2020 Conferenc"
2020.emnlp-main.129,C96-1079,0,\N,Missing
2020.emnlp-main.129,W06-0901,0,\N,Missing
2020.emnlp-main.129,P98-1013,0,\N,Missing
2020.emnlp-main.129,C98-1013,0,\N,Missing
2020.emnlp-main.129,P09-2093,0,\N,Missing
2020.emnlp-main.129,P06-4018,0,\N,Missing
2020.emnlp-main.129,P13-1024,0,\N,Missing
2020.emnlp-main.129,P08-1030,0,\N,Missing
2020.emnlp-main.129,P13-1008,0,\N,Missing
2020.emnlp-main.129,D14-1162,0,\N,Missing
2020.emnlp-main.129,P15-2060,0,\N,Missing
2020.emnlp-main.129,D15-1247,0,\N,Missing
2020.emnlp-main.129,doddington-etal-2004-automatic,0,\N,Missing
2020.emnlp-main.129,N16-1034,0,\N,Missing
2020.emnlp-main.129,P16-1025,0,\N,Missing
2020.emnlp-main.129,P17-1164,0,\N,Missing
2020.emnlp-main.129,N18-2058,0,\N,Missing
2020.emnlp-main.129,C18-1075,0,\N,Missing
2020.emnlp-main.129,D18-1259,0,\N,Missing
2020.emnlp-main.129,W13-2001,0,\N,Missing
2020.emnlp-main.129,P19-1521,0,\N,Missing
2020.emnlp-main.129,P16-2060,0,\N,Missing
2020.emnlp-main.129,P18-1201,0,\N,Missing
2020.emnlp-main.459,D19-1522,0,0.0916921,"cepts related to singer in Wikidata, then use the entities corresponding to these concepts to build the entity list. After that, we expand the entity list appropriately, and finally use the triples containing entities in the entity list to form the final dataset. The statistics of our five datasets are listed in Table 2. 4.2 Experiment Setup Baseline Models In our experiments, we select some KGE models and multi-hop reasoning models for comparison. For embedding-based models, we compared with TransE (Bordes et al., 2013), DistMult (Yang et al., 2015), ConvE (Dettmers et al., 2018) and TuckER (Balazevic et al., 2019). For multi-hop reasoning, we evaluate the following five models 1 , Neural Logical Programming (NeuralLP) (Yang et al., 2017), Neural Theorem Prover (NTP) (Rockt¨aschel and Riedel, 2017), MINERVA (Das et al., 2018), MultiHopKG (Lin et al., 2018) and CPL 2 (Fu et al., 2019) . Besides, our model has three variations, DacKGR (sample), DacKGR (top) and DacKGR (avg), which use sample, top-one and average strategy (introduced in Section 3.3) respectively. Evaluation Protocol For every triple (es , rq , eo ) in the test set, we convert it to a triple query (es , rq , ?), and then use embedding-based"
2020.emnlp-main.459,N18-1165,0,0.0178678,"y of their predictions. 5.2 Multi-Hop Reasoning Different from embedding-based models, multihop reasoning for KGs aims to predict the tail entity for every triple query (es , rq , ?) and meanwhile provide a reasoning path to support the prediction. Before multi-hop reasoning task is formalized, there are some models on relation path reasoning task, which aims to predict the relation between entities like (es , ?, eo ) using path information. DeepPath (Xiong et al., 2017) first adopts reinforcement learning (RL) framework for relation path reasoning, which inspires much later work (e.g., DIVA (Chen et al., 2018) and AttnPath (Wang et al., 2019)). MINERVA (Das et al., 2018) is the first model that uses REINFORCE algorithm to do the multihop reasoning task. To make the training process of RL models stable, Shen et al. propose M-Walk to solve the reward sparsity problem using off-policy learning. MultiHopKG (Lin et al., 2018) further improves MINERVA using action dropout and reward shaping. Lv et al. (2019) propose MetaKGR to address the new task that multi-hop reasoning on few-shot relations. In order to adapt RL models to a dynamically growing KG, Fu et al. (2019) propose CPL to do multi-hop reasoning"
2020.emnlp-main.459,D19-1269,0,0.0620329,"gh paths between them as reasoning evidence, which makes it difficult for the agent to carry out the reasoning process. As shown in the lower part of Figure 1, there is no evidential path between Mark Twain and English since the relation publish area is missing. From Table 1 we can learn that some sampled KG datasets are actually sparse. Besides, some domain-specific KGs (e.g., WD-singer) do not have abundant knowledge and also face the problem of sparsity. As the performance of most existing multi-hop reasoning methods drops significantly on sparse KGs, some preliminary efforts, such as CPL (Fu et al., 2019), explore to introduce additional text information to ease the sparsity of KGs. Although these explorations have achieved promising results, they are still limited to those specific KGs whose entities have additional text information. Thus, reasoning over sparse KGs is still an important but not fully resolved problem, and requires a more generalized approach to this problem. In this paper, we propose a multi-hop reasoning model named DacKGR, along with two dynamic strategies to solve the two problems mentioned above: Dynamic Anticipation makes use of the limited information in a sparse KG to"
2020.emnlp-main.459,D15-1038,0,0.0305378,"glish Figure 1: An illustration of multi-hop reasoning task over sparse KG. The missing relations (black dashed arrows) between entities can be inferred from existing triples (solid black arrows) through reasoning paths (bold arrows). However, some relations in the reasoning path are missing (red dashed arrows) in sparse KG, which makes multi-hop reasoning difficult. their further development and adaption for related downstream tasks. Knowledge graphs (KGs) represent the world knowledge in a structured way, and have been proven to be helpful for many downstream NLP tasks like query answering (Guu et al., 2015), dialogue generation (He et al., 2017) and machine reading comprehension (Yang et al., 2019). Despite their wide applications, many KGs still face serious incompleteness (Bordes et al., 2013), which limits Corresponding Author isa child Mark Twain Roughing It American child? spouse Introduction ∗ isa Olivia Langdon To alleviate this issue, some embedding-based models (Bordes et al., 2013; Dettmers et al., 2018) are proposed, most of which embed entities and relations into a vector space and make link predictions to complete KGs. These models focus on efficiently predicting knowledge but lack"
2020.emnlp-main.459,P17-1162,0,0.0279627,"-hop reasoning task over sparse KG. The missing relations (black dashed arrows) between entities can be inferred from existing triples (solid black arrows) through reasoning paths (bold arrows). However, some relations in the reasoning path are missing (red dashed arrows) in sparse KG, which makes multi-hop reasoning difficult. their further development and adaption for related downstream tasks. Knowledge graphs (KGs) represent the world knowledge in a structured way, and have been proven to be helpful for many downstream NLP tasks like query answering (Guu et al., 2015), dialogue generation (He et al., 2017) and machine reading comprehension (Yang et al., 2019). Despite their wide applications, many KGs still face serious incompleteness (Bordes et al., 2013), which limits Corresponding Author isa child Mark Twain Roughing It American child? spouse Introduction ∗ isa Olivia Langdon To alleviate this issue, some embedding-based models (Bordes et al., 2013; Dettmers et al., 2018) are proposed, most of which embed entities and relations into a vector space and make link predictions to complete KGs. These models focus on efficiently predicting knowledge but lack necessary interpretability. In order to"
2020.emnlp-main.459,D18-1362,0,0.336179,"al., 2019). Despite their wide applications, many KGs still face serious incompleteness (Bordes et al., 2013), which limits Corresponding Author isa child Mark Twain Roughing It American child? spouse Introduction ∗ isa Olivia Langdon To alleviate this issue, some embedding-based models (Bordes et al., 2013; Dettmers et al., 2018) are proposed, most of which embed entities and relations into a vector space and make link predictions to complete KGs. These models focus on efficiently predicting knowledge but lack necessary interpretability. In order to solve this problem, Das et al. (2018) and Lin et al. (2018) propose multihop reasoning models, which use the REINFORCE algorithm (Williams, 1992) to train an agent to search over KGs. These models can not only give the predicted result but also an interpretable path to indicate the reasoning process. As shown in the upper part of Figure 1, for a triple query (Olivia Langdon, child, ?), multi-hop reasoning models can predict the tail entity Susy Clemens through a reasoning path (bold arrows). Although existing multi-hop reasoning models have achieved good results, they still suffer two problems on sparse KGs: (1) Insufficient information. Compared with"
2020.emnlp-main.459,D19-1334,1,0.818399,"like (es , ?, eo ) using path information. DeepPath (Xiong et al., 2017) first adopts reinforcement learning (RL) framework for relation path reasoning, which inspires much later work (e.g., DIVA (Chen et al., 2018) and AttnPath (Wang et al., 2019)). MINERVA (Das et al., 2018) is the first model that uses REINFORCE algorithm to do the multihop reasoning task. To make the training process of RL models stable, Shen et al. propose M-Walk to solve the reward sparsity problem using off-policy learning. MultiHopKG (Lin et al., 2018) further improves MINERVA using action dropout and reward shaping. Lv et al. (2019) propose MetaKGR to address the new task that multi-hop reasoning on few-shot relations. In order to adapt RL models to a dynamically growing KG, Fu et al. (2019) propose CPL to do multi-hop reasoning and fact extraction jointly. In addition to the above RL-based reasoning models, there are some other neural symbolic models for multi-hop reasoning. NTP (Rockt¨aschel and Riedel, 2017) and NeuralLP (Yang et al., 2017) are two end-to-end reasoning models that can learn logic rules from KGs automatically. Compared with KGE models, multi-hop reasoning models sacrifice some accuracy for interpretabi"
2020.emnlp-main.459,N18-2053,0,0.0223203,"ories (Wang et al., 2017): (1) Translation-based models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015; Sun et al., 2018) formalize the relation as a translation from a head entity to a tail entity, and often use distance-based score functions derived from these translation operations. (2) Tensor-factorization based models (Nickel et al., 2011; Yang et al., 2015; Balazevic et al., 2019) formulate KGE as a three-way tensor decomposition task and define the score function according to the decomposition operations. (3) Neural network models (Socher et al., 2013; Dettmers et al., 2018; Nguyen et al., 2018; Shang et al., 2019) usually design neural network modules to enhance the expressive abilities. Generally, given a triple query (es , rq , ?), KGE models select the entity eo , whose score function f (es , rq , eo ) has the highest score as the final prediction. Although KGE models are efficient, they lack interpretability of their predictions. 5.2 Multi-Hop Reasoning Different from embedding-based models, multihop reasoning for KGs aims to predict the tail entity for every triple query (es , rq , ?) and meanwhile provide a reasoning path to support the prediction. Before multi-hop reasoning"
2020.emnlp-main.459,D15-1174,0,0.0908108,"Missing"
2020.emnlp-main.459,D19-1264,0,0.0203564,"-Hop Reasoning Different from embedding-based models, multihop reasoning for KGs aims to predict the tail entity for every triple query (es , rq , ?) and meanwhile provide a reasoning path to support the prediction. Before multi-hop reasoning task is formalized, there are some models on relation path reasoning task, which aims to predict the relation between entities like (es , ?, eo ) using path information. DeepPath (Xiong et al., 2017) first adopts reinforcement learning (RL) framework for relation path reasoning, which inspires much later work (e.g., DIVA (Chen et al., 2018) and AttnPath (Wang et al., 2019)). MINERVA (Das et al., 2018) is the first model that uses REINFORCE algorithm to do the multihop reasoning task. To make the training process of RL models stable, Shen et al. propose M-Walk to solve the reward sparsity problem using off-policy learning. MultiHopKG (Lin et al., 2018) further improves MINERVA using action dropout and reward shaping. Lv et al. (2019) propose MetaKGR to address the new task that multi-hop reasoning on few-shot relations. In order to adapt RL models to a dynamically growing KG, Fu et al. (2019) propose CPL to do multi-hop reasoning and fact extraction jointly. In"
2020.emnlp-main.459,D17-1060,0,0.0187415,"ose score function f (es , rq , eo ) has the highest score as the final prediction. Although KGE models are efficient, they lack interpretability of their predictions. 5.2 Multi-Hop Reasoning Different from embedding-based models, multihop reasoning for KGs aims to predict the tail entity for every triple query (es , rq , ?) and meanwhile provide a reasoning path to support the prediction. Before multi-hop reasoning task is formalized, there are some models on relation path reasoning task, which aims to predict the relation between entities like (es , ?, eo ) using path information. DeepPath (Xiong et al., 2017) first adopts reinforcement learning (RL) framework for relation path reasoning, which inspires much later work (e.g., DIVA (Chen et al., 2018) and AttnPath (Wang et al., 2019)). MINERVA (Das et al., 2018) is the first model that uses REINFORCE algorithm to do the multihop reasoning task. To make the training process of RL models stable, Shen et al. propose M-Walk to solve the reward sparsity problem using off-policy learning. MultiHopKG (Lin et al., 2018) further improves MINERVA using action dropout and reward shaping. Lv et al. (2019) propose MetaKGR to address the new task that multi-hop r"
2020.emnlp-main.459,P19-1226,0,0.0265119,"tions (black dashed arrows) between entities can be inferred from existing triples (solid black arrows) through reasoning paths (bold arrows). However, some relations in the reasoning path are missing (red dashed arrows) in sparse KG, which makes multi-hop reasoning difficult. their further development and adaption for related downstream tasks. Knowledge graphs (KGs) represent the world knowledge in a structured way, and have been proven to be helpful for many downstream NLP tasks like query answering (Guu et al., 2015), dialogue generation (He et al., 2017) and machine reading comprehension (Yang et al., 2019). Despite their wide applications, many KGs still face serious incompleteness (Bordes et al., 2013), which limits Corresponding Author isa child Mark Twain Roughing It American child? spouse Introduction ∗ isa Olivia Langdon To alleviate this issue, some embedding-based models (Bordes et al., 2013; Dettmers et al., 2018) are proposed, most of which embed entities and relations into a vector space and make link predictions to complete KGs. These models focus on efficiently predicting knowledge but lack necessary interpretability. In order to solve this problem, Das et al. (2018) and Lin et al."
2020.emnlp-main.515,D19-1609,0,0.0126103,"ment Graph Alignment unifies the two KGs’ representations of each channel into a unified vector space by reducing the distance between the seed equivalent entities. We separately train the four channels and ensemble their outputs afterward for final evaluation (see Section 3.5). Following Li et al. (2019), we generate negative samples of (e, e0 ) ∈ ψ s by searching the nearest entities of e (or e0 ) in the entity embedding space. We denote the final output k k hL e of the channel GC as the entity embedding e . k For each channel GC , we optimize the following objective function: 2 As shown by Andor et al. (2019), BERT embedding can be used for simple numerical computation. 6358 Lk = X ( X k k [d(ek , e0 ) − d(ek− , e0 ) + γ]+ (e,e0 )∈ψ s e− ∈NS(e) + X k k [d(ek , e0 ) − d(e, e0 − ) + γ]+ ) e0− ∈NS(e0 ) (3) where ψ s is the seed set of equivalent entities, NS(e) denotes the negative samples of e; [·]+ = max{·, 0}, d(·, ·) = 1 − cos(·, ·) is the cosine distance, and γ is a margin hyperparameter. 3.5 Channel Ensemble We use the entity embedding of each channel 0 to infer the similarity matrices Sk ∈ R|E|×|E | k (k ∈ {1, 2, 3, 4}), where Ske,e0 = cos(ek , e0 ) is the cosine similarity score between e ∈ E"
2020.emnlp-main.515,C18-1057,1,0.846295,"demonstrate the effectiveness of our method. Source code and data can be found at https://github.com/ thunlp/explore-and-evaluate. 1 Introduction The prosperity of data mining has spawned Knowledge Graphs (KGs) in many domains that are often complementary to each other. Entity Alignment (EA) provides an effective way to integrate the complementary knowledge in these KGs into a unified KG by linking equivalent entities, thus benefiting knowledge-driven applications such as Question Answering (Yang et al., 2017, 2018), Recommendation (Cao et al., 2019b) and Information Extraction (Kumar, 2017; Cao et al., 2018). However, EA is a non-trivial task that it could be formulated as * Corresponding author. a quadratic assignment problem (Yan et al., 2016), which is NP-complete (Garey and Johnson, 1990). A KG comprises a set of triples, with each triple consisting of a subject, predicate, and object. There are two types of triples: (1) relation triples, in which both the subject and object are entities, and the predicate is often called relation (see Figure 1(a)); and (2) attribute triples, in which the subject is an entity and the object is a value, which is either a number or literal string (see Figure 1("
2020.emnlp-main.515,P17-1149,1,0.908382,"Missing"
2020.emnlp-main.515,P19-1140,1,0.800608,"ent subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at https://github.com/ thunlp/explore-and-evaluate. 1 Introduction The prosperity of data mining has spawned Knowledge Graphs (KGs) in many domains that are often complementary to each other. Entity Alignment (EA) provides an effective way to integrate the complementary knowledge in these KGs into a unified KG by linking equivalent entities, thus benefiting knowledge-driven applications such as Question Answering (Yang et al., 2017, 2018), Recommendation (Cao et al., 2019b) and Information Extraction (Kumar, 2017; Cao et al., 2018). However, EA is a non-trivial task that it could be formulated as * Corresponding author. a quadratic assignment problem (Yan et al., 2016), which is NP-complete (Garey and Johnson, 1990). A KG comprises a set of triples, with each triple consisting of a subject, predicate, and object. There are two types of triples: (1) relation triples, in which both the subject and object are entities, and the predicate is often called relation (see Figure 1(a)); and (2) attribute triples, in which the subject is an entity and the object is a val"
2020.emnlp-main.515,N19-1423,0,0.00910856,"two GNN layers. Next, we describe attributed value encoder and mean aggregator in details. 3.3.1 Attributed Value Encoder Attributed value encoder can selectively gather discriminative information from the initial feature of attributes and values to the central entity. As an example, we show how to obtain e’s first layer hidden state h1e . The same method applies to all the entities. We obtain the sequence of attribute features {a1 , · · · , an } and value features {v1 , · · · , vn } given the attribute triples {(e, a1 , v1 ), · · · , (e, an , vn )} of e as inputs. Specifically, we use BERT (Devlin et al., 2019) to obtain the features of both literal and digital values2 . BERT is a language model that is pre-trained on a more than 3000M words corpora. It is popularly used as a feature extractor in NLP tasks. By adding (1) oj = LeakyReLU(uT [h0e ; aj ]), where j ∈ {1, · · · , n}, W1 ∈ RDh1 ×(Da +Dv ) and u ∈ R(De +Da )×1 are learnable matrices, σ is the ELU(·) function, and h0e is the initial entity feature. 3.3.2 Mean Aggregator Mean aggregator layer utilizes the features of the target entity and its neighbors to generate the entity embedding. The neighbor entities of e are defined by relation triple"
2020.emnlp-main.515,2020.acl-main.89,0,0.0330725,"Missing"
2020.emnlp-main.515,D19-1274,1,0.887955,"2019) and MultiKE (Zhang et al., 2019) encode values as extra entity embeddings. However, the diversity of attributes and uninformative values limit the performance of the above methods. 2.2 GNN-based Methods Following Graph Convolutional Networks (Kipf and Welling, 2017), many GNN-based models are proposed because of GNN’s strong ability to model graph structure. These methods present promising results on EA because GNN can propagate the alignment signal to the entity’s distant neighbors. Previous GNN-based methods focus on extending GNN’s ability to model relation types (Wu et al., 2019a,b; Li et al., 2019), aligning entities via matching subgraphs (Xu et al., 2019; Wu et al., 2020), and reducing the heterogeneity between KGs (Cao et al., 2019a). With the exception of Wang et al. (2018) that have incorporated attributes as the initial feature of entities, most of the current GNN-based methods fail to incorporate the attributes and values to further improve the performance of EA. In this paper, we add values as nodes into graph and use an attributed value encoder to conduct attribute-aware value aggregation. 3 Methodology The key idea of AttrGNN is to use graph partition and attributed value enco"
2020.emnlp-main.515,D18-1259,0,0.067005,"Missing"
2020.emnlp-main.515,D18-1032,0,0.0846666,"ic assignment problem (Yan et al., 2016), which is NP-complete (Garey and Johnson, 1990). A KG comprises a set of triples, with each triple consisting of a subject, predicate, and object. There are two types of triples: (1) relation triples, in which both the subject and object are entities, and the predicate is often called relation (see Figure 1(a)); and (2) attribute triples, in which the subject is an entity and the object is a value, which is either a number or literal string (see Figure 1(c)), and the predicate is often called attribute. Most of the previous EA models (Sun et al., 2017; Wang et al., 2018; Wu et al., 2019a) rely on the structure assumption that, the adjacencies of two equivalent entities in KGs usually contain equivalent entities (Wang et al., 2018) (see Figure 1(a)). These models mainly focus on modeling KG structure defined by the relation triples. However, we argue that attribute triples can also provide important clues for judging whether two entities are the same, based on the attribute assumption that: equivalent entities often share similar attributes and values in KGs. For example, in Figure 1(b), the equivalent entities e and e0 share the attribute Area with similar v"
2020.emnlp-main.515,D19-1023,0,0.144565,"em (Yan et al., 2016), which is NP-complete (Garey and Johnson, 1990). A KG comprises a set of triples, with each triple consisting of a subject, predicate, and object. There are two types of triples: (1) relation triples, in which both the subject and object are entities, and the predicate is often called relation (see Figure 1(a)); and (2) attribute triples, in which the subject is an entity and the object is a value, which is either a number or literal string (see Figure 1(c)), and the predicate is often called attribute. Most of the previous EA models (Sun et al., 2017; Wang et al., 2018; Wu et al., 2019a) rely on the structure assumption that, the adjacencies of two equivalent entities in KGs usually contain equivalent entities (Wang et al., 2018) (see Figure 1(a)). These models mainly focus on modeling KG structure defined by the relation triples. However, we argue that attribute triples can also provide important clues for judging whether two entities are the same, based on the attribute assumption that: equivalent entities often share similar attributes and values in KGs. For example, in Figure 1(b), the equivalent entities e and e0 share the attribute Area with similar values of 153, 909"
2020.emnlp-main.515,2020.acl-main.578,0,0.297622,"gs. However, the diversity of attributes and uninformative values limit the performance of the above methods. 2.2 GNN-based Methods Following Graph Convolutional Networks (Kipf and Welling, 2017), many GNN-based models are proposed because of GNN’s strong ability to model graph structure. These methods present promising results on EA because GNN can propagate the alignment signal to the entity’s distant neighbors. Previous GNN-based methods focus on extending GNN’s ability to model relation types (Wu et al., 2019a,b; Li et al., 2019), aligning entities via matching subgraphs (Xu et al., 2019; Wu et al., 2020), and reducing the heterogeneity between KGs (Cao et al., 2019a). With the exception of Wang et al. (2018) that have incorporated attributes as the initial feature of entities, most of the current GNN-based methods fail to incorporate the attributes and values to further improve the performance of EA. In this paper, we add values as nodes into graph and use an attributed value encoder to conduct attribute-aware value aggregation. 3 Methodology The key idea of AttrGNN is to use graph partition and attributed value encoder to deal with various types of attribute triples. In this section, we firs"
2020.emnlp-main.515,P19-1304,0,0.133774,"a entity embeddings. However, the diversity of attributes and uninformative values limit the performance of the above methods. 2.2 GNN-based Methods Following Graph Convolutional Networks (Kipf and Welling, 2017), many GNN-based models are proposed because of GNN’s strong ability to model graph structure. These methods present promising results on EA because GNN can propagate the alignment signal to the entity’s distant neighbors. Previous GNN-based methods focus on extending GNN’s ability to model relation types (Wu et al., 2019a,b; Li et al., 2019), aligning entities via matching subgraphs (Xu et al., 2019; Wu et al., 2020), and reducing the heterogeneity between KGs (Cao et al., 2019a). With the exception of Wang et al. (2018) that have incorporated attributes as the initial feature of entities, most of the current GNN-based methods fail to incorporate the attributes and values to further improve the performance of EA. In this paper, we add values as nodes into graph and use an attributed value encoder to conduct attribute-aware value aggregation. 3 Methodology The key idea of AttrGNN is to use graph partition and attributed value encoder to deal with various types of attribute triples. In thi"
2021.acl-long.215,P19-1282,0,0.0596829,"Missing"
2021.acl-long.215,N18-2028,0,0.0255352,"Missing"
2021.acl-long.215,P19-1586,0,0.0728149,"hing has been improved by deep learning models, such as distributed representation based models (Ebraheem et al., 2018), attention based models (Mudgal et al., 2018; Fu et al., 2019, 2020), and pre-trained language model based models (Li et al., 2020). Nevertheless, these modern neural EM models suffer from two limitations as follows. Low-Resource Training. Supervised deep learning EM relies on large amounts of labeled training data, which is extremely costly in reality. Attempts have been made to leverage external data via transfer learning (Zhao and He, 2019; Thirumuruganathan et al., 2018; Kasai et al., 2019; Loster et al., 2021) and pre-trained language model based methods (Li et al., 2020). Other attempts have also been made to improve labeling efficiency via active learning (Nafa et al., 2020) and crowdsourcing techniques (Gokhale et al., 2014; Wang et al., 2012). However, external information may introduce noises, and active learning and crowdsourcing still require additional labeling work. Lack of Interpretability. It is important to know why two entity records are equivalent (Chen et al., 2020), however, deep learning EM lacks inter2770 Proceedings of the 59th Annual Meeting of the Associat"
2021.acl-long.215,C14-1124,0,0.0310932,"on 6 public datasets and 3 industrial datasets show that our method is highly efficient and outperforms SOTA EM models in most cases. Our codes and datasets can be obtained from https:// github.com/THU-KEG/HIF-KAT. 1 ?&quot; Data Mining: Concepts and Techniques ?# Data mining: Concepts & Techniques by Jiawei Han Entity Matching (EM) aims at identifying whether two records from different sources refer to the same real-world entity. This is a fundamental research task in knowledge graph integration (Dong et al., 2014; Daniel et al., 2020; Christophides et al., 2015; Christen, 2012) and text mining (Zhao et al., 2014). In real applications, it is not easy to decide whether two records with ad hoc linguistic descriptions refer to the same entity. In Figure 1, e2 and e3 refer to the same publication, while e1 refers to a different Corresponding to L.Hou (houlei@tsinghua.edu.cn) missing Venue Conference (redundant) SIGMOD Conference International Conference on Management of Data J. Han, J. Pei, SIGMOD M. Kamber Record misplaced ACM SIGMOD Record missing missing Figure 1: Published papers as entity records. Introduction ∗ Author one. Venues of e2 and e3 have different expressions; Authors of e3 is misplaced in"
2021.acl-long.356,P08-1092,0,0.0486285,"by this work, Perez-Beltrachini et al. (2019) uses a convolutional encoder and a hierarchical decoder, and utilizes the Latent Dirichlet Allocation model (LDA) to render the decoder topic-aware. HierSumm (Liu and Lapata, 2019) adopts a learning-based model for the extractive stage, and computes the attention between paragraphs to model the dependencies across multiple paragraphs. However, these works view Wikipedia abstracts as plain text and do not explore the underlying topical information in Wikipedia articles. There are also works that focus on generating other aspects of Wikipedia text. Biadsy et al. (2008) utilizes the key-value pairs in Wikipedia infoboxes to generate high-quality biographies. Hayashi et al. (2021) investigates the structure of Wikipedia and builds an aspect-based summarization dataset by manually labeling aspects and identifying the aspect of input paragraphs with a ﬁnetuned RoBERTa model (Liu et al., 2019). Our model also utilizes the structure of Wikipedia, but we generate the compact abstract rather than individual aspects, which requires the fusion of aspects and poses a greater challenge to understand the connection and difference among topics. 3 Problem Deﬁnition Deﬁnit"
2021.acl-long.356,P15-1153,0,0.17172,"l extractive models (Yasunaga et al., 2017; Yin et al., 2019) utilizing the graph convolutional network (Kipf and Welling, 2017) to better capture inter-document relations. However, these models are not suitable for Wikipedia abstract generation. The reason is that the input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little success due to the limited scale of datasets. Liu et al. (2018) proposes an extractive-then-abstractive model and contributes WikiSum, a large-scale dataset for Wikipedia abstract generation, inspiring a branch of further studies (Perez-Beltrachini et al., 2019; Liu and Lapata, 2019; Li et al., 2020). The above models generally view the abstract as plain text, ignoring the fact that Wikipedia abstracts describe certain entities, and the structure of Wikipedia articles could help generate comprehensive abstracts. We observe that humans tend to describe entities in a certain"
2021.acl-long.356,J10-3005,0,0.0162267,"ics in the gold abstract, however, CV-S2D+T makes several factual errors like the release date and actors and HierSumm suffers from redundancy. TWAG covers all three topics in the gold abstract and discovers extra facts, proving itself to be competent in generating comprehensive abstracts. 5.5 Human Evaluation We follow the experimental setup of (PerezBeltrachini et al., 2019) and conduct a human evaluation consisting of two parts. A total of 45 examples (15 from each domain) are randomly selected from the test set for evaluation. The ﬁrst part is a question-answering (QA) scheme proposed in (Clarke and Lapata, 2010) in order to examine factoid information in summaries. We create 2-5 questions3 based on the golden sum3 Example questions are listed in the Appendix C, and the whole evaluation set is included in the our code repository. 4630 Model TF-S2S CV-S2D+T HierSumm BART TWAG (ours) Company Score Non-0 Film Score Non-0 Animal Score Non-0 .075 .237 .255 .591 .665 .000 .040 .213 .452 .669 .000 .382 .000 .342 .543 .694 .660 .896 .813 .903 .000 .143 .327 .796 .918 .000 .576 .000 .653 .868 Table 6: Human evaluation results in QA scheme. Score represents the mean score and non-0 represents the percentage of"
2021.acl-long.356,P19-1102,0,0.018135,"st, early abstractive models using sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015) achieve less success. Inspired by the recent success of single-document abstractive models (See et al., 2017; Paulus et al., 2018; Gehrmann et al., 2018; Huang et al., 2020), some works (Liu et al., 2018; Zhang et al., 2018) try to transfer single-document models to multi-document settings to alleviate the limitations of small-scale datasets. Speciﬁcally, Liu et al. (2018) deﬁnes Wikipedia generation problem and contributes the large-scale WikiSum dataset. Fabbri et al. (2019) constructs a middle-scale dataset named Multi4624 News and proposes an extractive-then-abstractive model by appending a sequence-to-sequence model after the extractive step. Li et al. (2020) models inter-document relations with explicit graph representations, and incorporates pre-trained language models to better handle long input documents. of size n as input, and outputs a Wikipedia abstract S = (s1 , s2 , . . . , sm ) with m sentences. The goal is to ﬁnd an optimal abstract S ∗ that best concludes the input, i.e., 2.2 Previous works generally view S as plain text, ignoring the semantics in"
2021.acl-long.356,D08-1019,0,0.319585,"2004; Wan, 2008). Recently, there also emerge neural extractive models (Yasunaga et al., 2017; Yin et al., 2019) utilizing the graph convolutional network (Kipf and Welling, 2017) to better capture inter-document relations. However, these models are not suitable for Wikipedia abstract generation. The reason is that the input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little success due to the limited scale of datasets. Liu et al. (2018) proposes an extractive-then-abstractive model and contributes WikiSum, a large-scale dataset for Wikipedia abstract generation, inspiring a branch of further studies (Perez-Beltrachini et al., 2019; Liu and Lapata, 2019; Li et al., 2020). The above models generally view the abstract as plain text, ignoring the fact that Wikipedia abstracts describe certain entities, and the structure of Wikipedia articles could help generate comprehensive abstracts. We observe that hu"
2021.acl-long.356,D18-1443,0,0.0241351,"els, e.g., Yasunaga et al. (2017) builds a discourse graph and represents textual units upon the graph convolutional network (GCN) (Kipf and Welling, 2017), and Yin et al. (2019) adopts the entity linking technique to capture global dependencies between sentences and ranks the sentences with a neural graph-based model. In contrast, early abstractive models using sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015) achieve less success. Inspired by the recent success of single-document abstractive models (See et al., 2017; Paulus et al., 2018; Gehrmann et al., 2018; Huang et al., 2020), some works (Liu et al., 2018; Zhang et al., 2018) try to transfer single-document models to multi-document settings to alleviate the limitations of small-scale datasets. Speciﬁcally, Liu et al. (2018) deﬁnes Wikipedia generation problem and contributes the large-scale WikiSum dataset. Fabbri et al. (2019) constructs a middle-scale dataset named Multi4624 News and proposes an extractive-then-abstractive model by appending a sequence-to-sequence model after the extractive step. Li et al. (2020) models inter-document relations with explicit graph representations, and incorp"
2021.acl-long.356,P16-1145,0,0.0285628,"ract sentence, and decode the sentence from topic-aware representations with a Pointer-Generator network. We evaluate our model on the WikiCatSum dataset, and the results show that TWAG outperforms various existing baselines and is capable of generating comprehensive abstracts. Our code and dataset can be accessed at https://github.com/THU-KEG/TWAG 1 Introduction Wikipedia, one of the most popular crowd-sourced online knowledge bases, has been widely used as the valuable resources in natural language processing tasks such as knowledge acquisition (Lehmann et al., 2015) and question answering (Hewlett et al., 2016; Rajpurkar et al., 2016) due to its high quality and wide coverage. Within a Wikipedia article, its abstract is the overview of the whole content, and thus becomes the most frequently used part in various tasks. However, the abstract is often contributed by experts, which is labor-intensive and prone to be incomplete. In this paper, we aim to automatically generate Wikipedia abstracts based on the related documents ∗ Corresponding Author collected from referred websites or search engines, which is essentially a multi-document summarization problem. This problem is studied in both extractive a"
2021.acl-long.356,2020.acl-main.457,0,0.0180074,"al. (2017) builds a discourse graph and represents textual units upon the graph convolutional network (GCN) (Kipf and Welling, 2017), and Yin et al. (2019) adopts the entity linking technique to capture global dependencies between sentences and ranks the sentences with a neural graph-based model. In contrast, early abstractive models using sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015) achieve less success. Inspired by the recent success of single-document abstractive models (See et al., 2017; Paulus et al., 2018; Gehrmann et al., 2018; Huang et al., 2020), some works (Liu et al., 2018; Zhang et al., 2018) try to transfer single-document models to multi-document settings to alleviate the limitations of small-scale datasets. Speciﬁcally, Liu et al. (2018) deﬁnes Wikipedia generation problem and contributes the large-scale WikiSum dataset. Fabbri et al. (2019) constructs a middle-scale dataset named Multi4624 News and proposes an extractive-then-abstractive model by appending a sequence-to-sequence model after the extractive step. Li et al. (2020) models inter-document relations with explicit graph representations, and incorporates pre-trained la"
2021.acl-long.356,2020.acl-main.703,0,0.0318688,"Missing"
2021.acl-long.356,2020.acl-main.555,0,0.0712133,"en noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little success due to the limited scale of datasets. Liu et al. (2018) proposes an extractive-then-abstractive model and contributes WikiSum, a large-scale dataset for Wikipedia abstract generation, inspiring a branch of further studies (Perez-Beltrachini et al., 2019; Liu and Lapata, 2019; Li et al., 2020). The above models generally view the abstract as plain text, ignoring the fact that Wikipedia abstracts describe certain entities, and the structure of Wikipedia articles could help generate comprehensive abstracts. We observe that humans tend to describe entities in a certain domain from several topics when writing Wikipedia abstracts. As illustrated in Figure 1, the abstract of the Arctic Fox contains its adaption, biology taxonomy and geographical distribution, which is consistent with 4623 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th"
2021.acl-long.356,P19-1500,0,0.0592974,"arious sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little success due to the limited scale of datasets. Liu et al. (2018) proposes an extractive-then-abstractive model and contributes WikiSum, a large-scale dataset for Wikipedia abstract generation, inspiring a branch of further studies (Perez-Beltrachini et al., 2019; Liu and Lapata, 2019; Li et al., 2020). The above models generally view the abstract as plain text, ignoring the fact that Wikipedia abstracts describe certain entities, and the structure of Wikipedia articles could help generate comprehensive abstracts. We observe that humans tend to describe entities in a certain domain from several topics when writing Wikipedia abstracts. As illustrated in Figure 1, the abstract of the Arctic Fox contains its adaption, biology taxonomy and geographical distribution, which is consistent with 4623 Proceedings of the 59th Annual Meeting of the Association for Computational Lingui"
2021.acl-long.356,2021.ccl-1.108,0,0.0931986,"Missing"
2021.acl-long.356,W04-3252,0,0.112776,"ne to be incomplete. In this paper, we aim to automatically generate Wikipedia abstracts based on the related documents ∗ Corresponding Author collected from referred websites or search engines, which is essentially a multi-document summarization problem. This problem is studied in both extractive and abstractive manners. The extractive models attempt to select relevant textual units from input documents and combine them into a summary. Graph-based representations are widely exploited to capture the most salient textual units and enhance the quality of the ﬁnal summary (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Wan, 2008). Recently, there also emerge neural extractive models (Yasunaga et al., 2017; Yin et al., 2019) utilizing the graph convolutional network (Kipf and Welling, 2017) to better capture inter-document relations. However, these models are not suitable for Wikipedia abstract generation. The reason is that the input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Fili"
2021.acl-long.356,P17-1099,0,0.718089,". In this paper, we try to utilize the topical information of entities within its domain (Wikipedia categories) to improve the quality of the generated abstract. We propose a novel two-stage Topic-guided Wikipedia Abstract Generation model (TWAG). TWAG ﬁrst divides input documents by paragraph and assigns a topic for each paragraph with a classiﬁer-based topic detector. Then, it generates the abstract in a sentence-wise manner, i.e., predicts the topic distribution of each abstract sentence to determine its topic-aware representation, and decodes the sentence with a Pointer-Generator network (See et al., 2017). We evaluate TWAG on the WikiCatSum (PerezBeltrachini et al., 2019) dataset, a subset of the WikiSum containing three distinct domains. Experimental results show that it signiﬁcantly improves the quality of abstract compared with several strong baselines. In conclusion, the contributions of our work are as follows: • We propose TWAG, a two-stage neural abstractive Wikipedia abstract generation model utilizing the topic information in Wikipedia, which is capable of generating comprehensive abstracts. • We simulate the way humans recognize entities, using a classiﬁer to divide input documents i"
2021.acl-long.356,D08-1079,0,0.213239,"is paper, we aim to automatically generate Wikipedia abstracts based on the related documents ∗ Corresponding Author collected from referred websites or search engines, which is essentially a multi-document summarization problem. This problem is studied in both extractive and abstractive manners. The extractive models attempt to select relevant textual units from input documents and combine them into a summary. Graph-based representations are widely exploited to capture the most salient textual units and enhance the quality of the ﬁnal summary (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Wan, 2008). Recently, there also emerge neural extractive models (Yasunaga et al., 2017; Yin et al., 2019) utilizing the graph convolutional network (Kipf and Welling, 2017) to better capture inter-document relations. However, these models are not suitable for Wikipedia abstract generation. The reason is that the input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and St"
2021.acl-long.356,K17-1045,0,0.114005,"ed on the related documents ∗ Corresponding Author collected from referred websites or search engines, which is essentially a multi-document summarization problem. This problem is studied in both extractive and abstractive manners. The extractive models attempt to select relevant textual units from input documents and combine them into a summary. Graph-based representations are widely exploited to capture the most salient textual units and enhance the quality of the ﬁnal summary (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Wan, 2008). Recently, there also emerge neural extractive models (Yasunaga et al., 2017; Yin et al., 2019) utilizing the graph convolutional network (Kipf and Welling, 2017) to better capture inter-document relations. However, these models are not suitable for Wikipedia abstract generation. The reason is that the input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little suc"
2021.acl-long.356,D14-1162,0,0.0865622,"Missing"
2021.acl-long.356,P19-1504,0,0.0866944,"input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little success due to the limited scale of datasets. Liu et al. (2018) proposes an extractive-then-abstractive model and contributes WikiSum, a large-scale dataset for Wikipedia abstract generation, inspiring a branch of further studies (Perez-Beltrachini et al., 2019; Liu and Lapata, 2019; Li et al., 2020). The above models generally view the abstract as plain text, ignoring the fact that Wikipedia abstracts describe certain entities, and the structure of Wikipedia articles could help generate comprehensive abstracts. We observe that humans tend to describe entities in a certain domain from several topics when writing Wikipedia abstracts. As illustrated in Figure 1, the abstract of the Arctic Fox contains its adaption, biology taxonomy and geographical distribution, which is consistent with 4623 Proceedings of the 59th Annual Meeting of the Association fo"
2021.acl-long.356,W00-1009,0,0.482438,"t generation model utilizing the topic information in Wikipedia, which is capable of generating comprehensive abstracts. • We simulate the way humans recognize entities, using a classiﬁer to divide input documents into topics, and then perform topicRelated Work Multi-document Summarization Multi-document summarization is a classic and challenging problem in natural language processing, which aims to distill an informative and coherent summary from a set of input documents. Compared with single-document summarization, the input documents may contain redundant or even contradictory information (Radev, 2000). Early high-quality multi-document summarization datasets are annotated by humans, e.g., datasets for Document Understanding Conference (DUC) and Text Analysis Conference (TAC). These datasets are too small to build neural models, and most of the early works take an extractive method, attempting to build graphs with interparagraph relations and choose the most salient textual units. The graph could be built with various information, e.g., TF-IDF similarity (Erkan and Radev, 2004), discourse relation (Mihalcea and Tarau, 2004), document-sentence two-layer relations (Wan, 2008), multi-modal (Wa"
2021.acl-long.356,D16-1264,0,0.0267583,"ode the sentence from topic-aware representations with a Pointer-Generator network. We evaluate our model on the WikiCatSum dataset, and the results show that TWAG outperforms various existing baselines and is capable of generating comprehensive abstracts. Our code and dataset can be accessed at https://github.com/THU-KEG/TWAG 1 Introduction Wikipedia, one of the most popular crowd-sourced online knowledge bases, has been widely used as the valuable resources in natural language processing tasks such as knowledge acquisition (Lehmann et al., 2015) and question answering (Hewlett et al., 2016; Rajpurkar et al., 2016) due to its high quality and wide coverage. Within a Wikipedia article, its abstract is the overview of the whole content, and thus becomes the most frequently used part in various tasks. However, the abstract is often contributed by experts, which is labor-intensive and prone to be incomplete. In this paper, we aim to automatically generate Wikipedia abstracts based on the related documents ∗ Corresponding Author collected from referred websites or search engines, which is essentially a multi-document summarization problem. This problem is studied in both extractive and abstractive manners. T"
2021.acl-long.356,P09-1024,0,0.144242,"mmary. Graph-based representations are widely exploited to capture the most salient textual units and enhance the quality of the ﬁnal summary (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Wan, 2008). Recently, there also emerge neural extractive models (Yasunaga et al., 2017; Yin et al., 2019) utilizing the graph convolutional network (Kipf and Welling, 2017) to better capture inter-document relations. However, these models are not suitable for Wikipedia abstract generation. The reason is that the input documents collected from various sources are often noisy and lack intrinsic relations (Sauper and Barzilay, 2009), which makes the relation graph hard to build. The abstractive models aim to distill an informative and coherent summary via sentence-fusion and paraphrasing (Filippova and Strube, 2008; Banerjee et al., 2015; Bing et al., 2015), but achieve little success due to the limited scale of datasets. Liu et al. (2018) proposes an extractive-then-abstractive model and contributes WikiSum, a large-scale dataset for Wikipedia abstract generation, inspiring a branch of further studies (Perez-Beltrachini et al., 2019; Liu and Lapata, 2019; Li et al., 2020). The above models generally view the abstract as"
2021.acl-long.487,W06-0901,0,0.0254063,"-shot classes, our method achieves the best performance (the number is 5 in Figure 4). We argue that the number of predefined classes is proportional to the amount of information hidden in weak supervision. Therefore, with more predefined classes, we can also find more high-quality undefined classes. Task-Agnostic Ability In this section, we answer whether our assumption of O class is task-agnostic and effective for few-shot token-level classification tasks other than NER. We conduct experiments on two tasks of widespread concern: Slot Tagging (Hou et al., 2020) and Event Argument Extraction (Ahn, 2006). Slot Tagging aims to discover user intent from task6243 Table 4: Case Study of the Found undefined Classes O1 O2 O3 O4 O5 Annotated Words gentleman; journalist; president; ambassador; I; he; they; businessmen from; and those Huwei people who; the harbour; this land, which; over the river; with the great outdoors; outsides; to nature; the skyline; some; a major; the small number; supplied; not only one of the; empty; large; increase of; was at the tail; believe; comfort; attacked or threatened; arrest; geared; talks; not dealing; discussions; agreement; stop; have; do; discussion; take; seek;"
2021.acl-long.487,D19-1025,1,0.835779,"for undefined class detection. In the absence of labeled examples and metadata, our proposed zero-shot method creatively use the weakly supervised signal of the predefined classes to find undefined classes. • We conduct extensive experiments on four benchmarks as compared with five state-ofthe-art baselines. The results under both 1shot and 5-shots settings demonstrate the effectiveness of MUCO. Further studies show that our method can also be conveniently adapted to other domains. 2 Related Work Few-shot NER aims to recognize new categories with just a handful of examples (Feng et al., 2018; Cao et al., 2019). Four groups of methods are adopted to handle the low-resource issue: knowledge enhanced, cross-lingual enhanced, crossdomain enhanced, and active learning. Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue. Cross-lingual (Feng et al., 2018; Rahimi et al., 2019) and cross-domain enhanced methods (Wang et al., 2018; Zhou et al., 2019) respectively use labeled data from a count"
2021.acl-long.487,2020.acl-main.128,0,0.531683,"mber of data for optimization. Recently, prototypical Corresponding author. O3 S2: Newton is a polymath. He was born in Lincolnshire. Introduction ∗ Undefined classes S1: Emeneya was born in local hospital and died in Paris network (Snell et al., 2017) shows potential on fewshot NER. The basic idea is to learn prototypes for each predefined entity class and an other class, then classify examples based on which prototypes they are closest to (Fritzler et al., 2019). Most existing studies focus on the predefined classes and leverage the label semantic to reveal their dependency for enhancement (Hou et al., 2020). However, they ignore the massive semantics hidden in the words of other class (O-class for short). In this paper, we propose to learn from O-class words, rather than using predefined entity classes only, to improve few-shot NER. In fact, O-class contains rich semantics and can provide stand-by knowledge for named entity identification and disambiguation. As shown in Figure 1(a), if we can detect an undefined class consisting of references to named entities (such as pronouns), then due to their interchangeability (Katz and Fodor, 1963), we will obtain prior knowledge for named entity identifi"
2021.acl-long.487,N16-1030,0,0.0119786,"ways to handle O class (single prototype vs. multiple prototypes). Named Entity Recognition (NER) seeks to locate and classify named entities from sentences into predefined classes (Yadav and Bethard, 2019). Humans can immediately recognize new entity types given just one or a few examples(Lake et al., 2015). Although neural NER networks have achieved superior performance when provided large-scale of training examples (Li et al., 2019), it remains a non-trivial task to learn from limited new samples, also known as few-shot NER (Fritzler et al., 2019). Traditional NER models, such as LSTM+CRF (Lample et al., 2016), fail in few-shot settings. They calculate the transition probability matrix based on statistics, which requires a large number of data for optimization. Recently, prototypical Corresponding author. O3 S2: Newton is a polymath. He was born in Lincolnshire. Introduction ∗ Undefined classes S1: Emeneya was born in local hospital and died in Paris network (Snell et al., 2017) shows potential on fewshot NER. The basic idea is to learn prototypes for each predefined entity class and an other class, then classify examples based on which prototypes they are closest to (Fritzler et al., 2019). Most e"
2021.acl-long.487,C16-1017,0,0.0233037,"The results under both 1shot and 5-shots settings demonstrate the effectiveness of MUCO. Further studies show that our method can also be conveniently adapted to other domains. 2 Related Work Few-shot NER aims to recognize new categories with just a handful of examples (Feng et al., 2018; Cao et al., 2019). Four groups of methods are adopted to handle the low-resource issue: knowledge enhanced, cross-lingual enhanced, crossdomain enhanced, and active learning. Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue. Cross-lingual (Feng et al., 2018; Rahimi et al., 2019) and cross-domain enhanced methods (Wang et al., 2018; Zhou et al., 2019) respectively use labeled data from a counterpart language or a different domain as external supervised signals to avoid overfitting. When the language or domain discrepancy is large, these two methods will inevitably face the problem of performance degradation (Huang et al., 2017). Active learning methods (Wei et al., 2019) explicitly expand corpus"
2021.acl-long.487,W12-4304,0,0.0294515,"Missing"
2021.acl-long.487,W13-3516,0,0.0178525,"Missing"
2021.acl-long.487,P19-1015,0,0.0226112,"ains. 2 Related Work Few-shot NER aims to recognize new categories with just a handful of examples (Feng et al., 2018; Cao et al., 2019). Four groups of methods are adopted to handle the low-resource issue: knowledge enhanced, cross-lingual enhanced, crossdomain enhanced, and active learning. Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue. Cross-lingual (Feng et al., 2018; Rahimi et al., 2019) and cross-domain enhanced methods (Wang et al., 2018; Zhou et al., 2019) respectively use labeled data from a counterpart language or a different domain as external supervised signals to avoid overfitting. When the language or domain discrepancy is large, these two methods will inevitably face the problem of performance degradation (Huang et al., 2017). Active learning methods (Wei et al., 2019) explicitly expand corpus by selecting the most informative examples for manual annotation, which need extra human-laboring. Different from previous methods, we focus on mining the rich semantics in th"
2021.acl-long.487,W03-0419,0,0.0940599,"Missing"
2021.acl-long.487,D19-1045,0,0.0174467,"rge, these two methods will inevitably face the problem of performance degradation (Huang et al., 2017). Active learning methods (Wei et al., 2019) explicitly expand corpus by selecting the most informative examples for manual annotation, which need extra human-laboring. Different from previous methods, we focus on mining the rich semantics in the O class to improve few-shot NER. 6237 2.1 Prototypical Network Prototypical network (Snell et al., 2017), initially proposed for image classification, has been successfully applied to sentence-level classification tasks, such as text classification (Sun et al., 2019) and relation extraction (Gao et al., 2019). However, there is a dilemma to adapt prototypical network for token-level classification tasks such as NER. Prototypical network assumes that each class has uniform semantic and vectors belong to the same class should cluster in the space. However, in NER, data in O class contain multiple semantics and thus violate the uniform semantic hypothesis in prototypical network. To handle the issue, Deng et al. (2020) first trains a binary classifier to distinguish O class from other predefined classes, and then adopt traditional prototypical network method"
2021.acl-long.487,N18-1001,0,0.0386562,"Missing"
2021.acl-long.487,P17-1113,0,0.0207965,"t additional classes, including he and professor, we will have more evidence about where Newton may appear. In addition, if we can detect an undefined class that composed of Action (O1 ), we may cap6236 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6236–6247 August 1–6, 2021. ©2021 Association for Computational Linguistics ture underlined relations between different named entities, which is important evidence when distinguishing the named entity type (Ghosh et al., 2016; Zheng et al., 2017). for knowledge transfer. Our contributions can be summarized as follows: • We propose a novel approach MUCO to leverage rich semantics in O class to improve fewshot NER. To the best of our knowledge, this is the first work exploring O-class in this task. Nevertheless, it is challenging to detect related undefined classes from O class words due to two reasons: 1) Miscellaneous Semantics. O-class contains miscellaneous types of words. Based on our observations, although there are massive related yet undefined classes, the noise maybe even more, such as function and stop words. These noisy class"
2021.acl-long.487,P19-1336,0,0.0323287,"Missing"
2021.acl-long.491,W13-2322,0,0.111426,"Missing"
2021.acl-long.491,D13-1185,0,0.0173718,"2006) and similar datasets (Ellis et al., 2015, 2016; Getman et al., 2017; Wang et al., 2020), these PLM-based works solely focus on better finetuning rather than pre-training for EE. In this paper, we study pre-training to better utilize rich event knowledge in large-scale unsupervised data. Event Schema Induction. Supervised EE models cannot generalize to continually-emerging new event types and argument roles. To this end, Chambers and Jurafsky (2011) explore to induce event schemata from raw text by unsupervised clustering. Following works introduce more features like coreference chains (Chambers, 2013) and entities (Nguyen et al., 2015; Sha et al., 2016). Recently, Huang and Ji (2020) move to the semi6284 Event Semantic Pre-training Unsupervised Corpora Trigger-Argument Pair Discrimination attack CNN&apos;s Kelly Wallace reports on today&apos;s attack in Netanya. Text Encoder The army said two soldiers were also among the dead. Trigger Replacement … Netanya reports CNN&apos;s Kelly Wallace today&apos;s reports Argument Replacement AMR Parsing Event Structure Pre-training Parsed AMR Graphs ARG0 ARG1 ARG1 attack-01 time ARG1 today dead ARG1 ARG1 soldier quant today Netanya say-01 army time mod 2 also Subgraph Sa"
2021.acl-long.491,P11-1098,0,0.0297505,"ang et al., 2019a,b; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020). Although achieving remarkable performance in benchmarks such as ACE 2005 (Walker et al., 2006) and similar datasets (Ellis et al., 2015, 2016; Getman et al., 2017; Wang et al., 2020), these PLM-based works solely focus on better finetuning rather than pre-training for EE. In this paper, we study pre-training to better utilize rich event knowledge in large-scale unsupervised data. Event Schema Induction. Supervised EE models cannot generalize to continually-emerging new event types and argument roles. To this end, Chambers and Jurafsky (2011) explore to induce event schemata from raw text by unsupervised clustering. Following works introduce more features like coreference chains (Chambers, 2013) and entities (Nguyen et al., 2015; Sha et al., 2016). Recently, Huang and Ji (2020) move to the semi6284 Event Semantic Pre-training Unsupervised Corpora Trigger-Argument Pair Discrimination attack CNN&apos;s Kelly Wallace reports on today&apos;s attack in Netanya. Text Encoder The army said two soldiers were also among the dead. Trigger Replacement … Netanya reports CNN&apos;s Kelly Wallace today&apos;s reports Argument Replacement AMR Parsing Event Structur"
2021.acl-long.491,P17-1038,0,0.0187182,"tune general PLMs (e.g, BERT (Devlin et al., 2019)) for EE. Benefiting from the strong general language understanding ability learnt from large-scale unsupervised data, these PLM-based methods have achieved state-ofthe-art performance in various public benchmarks. Although leveraging unsupervised data with pretraining has gradually become a consensus for EE and NLP community, there still lacks a pre-training method orienting event modeling to take full advantage of rich event knowledge lying in largescale unsupervised data. The key challenge here is to find reasonable self-supervised signals (Chen et al., 2017; Wang et al., 2019a) for the diverse semantics and complex structures of events. Fortunately, previous work (Aguilar et al., 2014; Huang et al., 2016) has suggested that sentence semantic structures, such as abstract meaning representation (AMR) (Banarescu et al., 2013), contain broad and diverse semantic and structure information relating to events. As shown in Figure 1, the parsed AMR structure covers not only the annotated event (Attack) but also the event that is not defined in the ACE 2005 schema (Report). Considering the fact that the AMR structures of large-scale unsupervised data can"
2021.acl-long.491,P15-1017,0,0.34232,"1 CNN’s Kelly Wallace attack-01 Introduction ∗ Event Schema report-01 classify event types (Attack), as well as event argument extraction task to identify entities serving as event arguments (“today” and “Netanya”) and classify their argument roles (Time-within and Place) (Ahn, 2006). By explicitly capturing the event structure in the text, EE can benefit various downstream tasks such as information reˇ trieval (Glavaˇs and Snajder, 2014) and knowledge base population (Ji and Grishman, 2011). Existing EE methods mainly follow the supervised-learning paradigm to train advanced neural networks (Chen et al., 2015; Nguyen et al., 2016; Nguyen and Grishman, 2018) with humanannotated datasets and pre-defined event schemata. These methods work well in lots of public benchmarks such as ACE 2005 (Walker et al., 2006) and TAC KBP (Ellis et al., 2016), yet they still suffer from data scarcity and limited generalizability. Since annotating event data and defining event schemata are especially expensive and laborintensive, existing EE datasets typically only contain thousands of instances and cover limited event types. Thus they are inadequate to train large neural models (Wang et al., 2020) and develop methods"
2021.acl-long.491,2020.emnlp-main.444,0,0.0363461,"et al., 2018; Oord et al., 2018; Hjelm et al., 2019; Chen et al., 2020; He et al., 2020) and graph (Qiu et al., 2020; You et al., 2020; Zhu et al., 2020). In the context of NLP, many established representation learning works can be viewed as contrastive learning methods, such as Word2Vec (Mikolov et al., 2013), BERT (Devlin et al., 2019; Kong et al., 2020) and ELECTRA (Clark et al., 2020). Similar to this work, contrastive learning is also widely-used to help specific tasks, including question answering (Yeh and Chen, 2019), discourse modeling (Iter et al., 2020), natural language inference (Cui et al., 2020) and relation extraction (Peng et al., 2020). 3 Methodology The overall CLEVE framework is illustrated in Figure 2. As shown in the illustration, our contrastive pre-training framework CLEVE consists of two components: event semantic pre-training and event structure pre-training, of which details are introduced in Section 3.2 and Section 3.3, respectively. At the beginning of this section, we first introduce the required preprocessing in Section 3.1, including the AMR parsing and how we modify the parsed AMR structures for our pre-training. 3.1 Preprocessing CLEVE relies on AMR structures (Ban"
2021.acl-long.491,P09-2093,0,0.0217807,"y. Meanwhile, the pre-trained representations can also directly help extract events and discover new event schemata without any known event schema or annotated instances, leading to better generalizability. This is a challenging unsupervised setting named “liberal event extraction” (Huang et al., 2016). Experiments on the widely-used ACE 2005 and the large MAVEN datasets indicate that CLEVE can achieve significant improvements in both settings. 2 Related Work Event Extraction. Most of the existing EE works follow the supervised learning paradigm. Traditional EE methods (Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013) rely on manually-crafted features to extract events. In recent years, the neural models become mainstream, which automatically learn effective features with neural networks, including convolutional neural networks (Nguyen and Grishman, 2015; Chen et al., 2015), recurrent neural networks (Nguyen et al., 2016), graph convolutional networks (Nguyen and Grishman, 2018; Lai et al., 2020). With the recent successes of BERT (Devlin et al., 2019), PLMs have also been used for EE (Wang et al., 2019a,b; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020). Although achieving rem"
2021.acl-long.491,2020.acl-main.740,0,0.0611314,"Missing"
2021.acl-long.491,P16-1025,0,0.155473,"unsupervised data, these PLM-based methods have achieved state-ofthe-art performance in various public benchmarks. Although leveraging unsupervised data with pretraining has gradually become a consensus for EE and NLP community, there still lacks a pre-training method orienting event modeling to take full advantage of rich event knowledge lying in largescale unsupervised data. The key challenge here is to find reasonable self-supervised signals (Chen et al., 2017; Wang et al., 2019a) for the diverse semantics and complex structures of events. Fortunately, previous work (Aguilar et al., 2014; Huang et al., 2016) has suggested that sentence semantic structures, such as abstract meaning representation (AMR) (Banarescu et al., 2013), contain broad and diverse semantic and structure information relating to events. As shown in Figure 1, the parsed AMR structure covers not only the annotated event (Attack) but also the event that is not defined in the ACE 2005 schema (Report). Considering the fact that the AMR structures of large-scale unsupervised data can be easily obtained with automatic parsers (Wang et al., 2015), we propose CLEVE, an event-oriented contrastive pre-training framework utilizing AMR str"
2021.acl-long.491,2020.emnlp-main.53,0,0.264824,"notated datasets and pre-defined event schemata. These methods work well in lots of public benchmarks such as ACE 2005 (Walker et al., 2006) and TAC KBP (Ellis et al., 2016), yet they still suffer from data scarcity and limited generalizability. Since annotating event data and defining event schemata are especially expensive and laborintensive, existing EE datasets typically only contain thousands of instances and cover limited event types. Thus they are inadequate to train large neural models (Wang et al., 2020) and develop methods that can generalize to continually-emerging new event types (Huang and Ji, 2020). Inspired by the success of recent pre-trained language models (PLMs) for NLP tasks, some pio6283 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6283–6297 August 1–6, 2021. ©2021 Association for Computational Linguistics neering work (Wang et al., 2019a; Wadden et al., 2019) attempts to fine-tune general PLMs (e.g, BERT (Devlin et al., 2019)) for EE. Benefiting from the strong general language understanding ability learnt from large-scale unsupervised data, these PLM-base"
2021.acl-long.491,P18-1201,0,0.019335,"employ a PLM as the text encoder and encourage the representations of the word pairs connected by the ARG, time, location edges in AMR structures to be closer in the semantic space than other unrelated words, since these pairs usually refer to the trigger-argument pairs of the same events (as shown in Figure 1) (Huang et al., 2016). This is done by contrastive learning with the connected word pairs as positive samples and unrelated words as negative samples. Moreover, considering event structures are also helpful in extracting events (Lai et al., 2020) and generalizing to new event schemata (Huang et al., 2018), we need to learn transferable event structure representations. Hence we further introduce a graph neural network (GNN) as the graph encoder to encode AMR structures as structure representations. The graph encoder is contrastively pre-trained on the parsed AMR structures of large unsupervised corpora with AMR subgraph discrimination as the objective. By fine-tuning the two pre-trained models on downstream EE datasets and jointly using the two representations, CLEVE can benefit the conventional supervised EE suffering from data scarcity. Meanwhile, the pre-trained representations can also dire"
2021.acl-long.491,2020.acl-main.439,0,0.0207388,"in various domains, such as computer vision (Wu et al., 2018; Oord et al., 2018; Hjelm et al., 2019; Chen et al., 2020; He et al., 2020) and graph (Qiu et al., 2020; You et al., 2020; Zhu et al., 2020). In the context of NLP, many established representation learning works can be viewed as contrastive learning methods, such as Word2Vec (Mikolov et al., 2013), BERT (Devlin et al., 2019; Kong et al., 2020) and ELECTRA (Clark et al., 2020). Similar to this work, contrastive learning is also widely-used to help specific tasks, including question answering (Yeh and Chen, 2019), discourse modeling (Iter et al., 2020), natural language inference (Cui et al., 2020) and relation extraction (Peng et al., 2020). 3 Methodology The overall CLEVE framework is illustrated in Figure 2. As shown in the illustration, our contrastive pre-training framework CLEVE consists of two components: event semantic pre-training and event structure pre-training, of which details are introduced in Section 3.2 and Section 3.3, respectively. At the beginning of this section, we first introduce the required preprocessing in Section 3.1, including the AMR parsing and how we modify the parsed AMR structures for our pre-training. 3.1 Pr"
2021.acl-long.491,2020.findings-emnlp.326,0,0.0290477,"he golden trigger-argument pairs and event structures of ACE 2005 training set instead of the AMR structures of NYT. Similarly, the on ACE (AMR) model is pre-trained with the parsed AMR structures of ACE 2005 training set. We also compare CLEVE with various baselines, including: (1) feature-based method, the top-performing JointBeam (Li et al., 2013); (2) vanilla neural model DMCNN (Chen et al., 2015); (3) the model incorporating syntactic knowledge, dbRNN (Sha et al., 2018); (4) stateof-the-art models on ED and EAE respectively, including GatedGCN (Lai et al., 2020) and SemSynGTN (Pouran Ben Veyseh et al., 2020); (5) a stateof-the-art EE model RCEE ER (Liu et al., 2020), which tackle EE with machine reading comprehension (MRC) techniques. The last four models adopt PLMs to learn representations. On MAVEN, we compare CLEVE with the official ED baselines set by Wang et al. (2020), including DMCNN (Chen et al., 2015), BiLSTM (Hochreiter and Schmidhuber, 1997), BiLSTM+CRF, MOGANED (Yan et al., 2019), DMBERT (Wang et al., 2019a), BERT+CRF. Evaluation Results The evaluation results are shown in Table 1 and Table 2. We can observe that: (1) CLEVE achieves significant improvements to its basic model RoBERTa"
2021.acl-long.491,N16-1049,0,0.0182403,"16; Getman et al., 2017; Wang et al., 2020), these PLM-based works solely focus on better finetuning rather than pre-training for EE. In this paper, we study pre-training to better utilize rich event knowledge in large-scale unsupervised data. Event Schema Induction. Supervised EE models cannot generalize to continually-emerging new event types and argument roles. To this end, Chambers and Jurafsky (2011) explore to induce event schemata from raw text by unsupervised clustering. Following works introduce more features like coreference chains (Chambers, 2013) and entities (Nguyen et al., 2015; Sha et al., 2016). Recently, Huang and Ji (2020) move to the semi6284 Event Semantic Pre-training Unsupervised Corpora Trigger-Argument Pair Discrimination attack CNN&apos;s Kelly Wallace reports on today&apos;s attack in Netanya. Text Encoder The army said two soldiers were also among the dead. Trigger Replacement … Netanya reports CNN&apos;s Kelly Wallace today&apos;s reports Argument Replacement AMR Parsing Event Structure Pre-training Parsed AMR Graphs ARG0 ARG1 ARG1 attack-01 time ARG1 today dead ARG1 ARG1 soldier quant today Netanya say-01 army time mod 2 also Subgraph Sampling say-01 quant 2 AMR Subgraph Discrimination rep"
2021.acl-long.491,2020.emnlp-main.128,0,0.0362011,"005 training set instead of the AMR structures of NYT. Similarly, the on ACE (AMR) model is pre-trained with the parsed AMR structures of ACE 2005 training set. We also compare CLEVE with various baselines, including: (1) feature-based method, the top-performing JointBeam (Li et al., 2013); (2) vanilla neural model DMCNN (Chen et al., 2015); (3) the model incorporating syntactic knowledge, dbRNN (Sha et al., 2018); (4) stateof-the-art models on ED and EAE respectively, including GatedGCN (Lai et al., 2020) and SemSynGTN (Pouran Ben Veyseh et al., 2020); (5) a stateof-the-art EE model RCEE ER (Liu et al., 2020), which tackle EE with machine reading comprehension (MRC) techniques. The last four models adopt PLMs to learn representations. On MAVEN, we compare CLEVE with the official ED baselines set by Wang et al. (2020), including DMCNN (Chen et al., 2015), BiLSTM (Hochreiter and Schmidhuber, 1997), BiLSTM+CRF, MOGANED (Yan et al., 2019), DMBERT (Wang et al., 2019a), BERT+CRF. Evaluation Results The evaluation results are shown in Table 1 and Table 2. We can observe that: (1) CLEVE achieves significant improvements to its basic model RoBERTa on both ACE 2005 and MAVEN. The p-values under the t-test a"
2021.acl-long.491,2021.ccl-1.108,0,0.0684993,"Missing"
2021.acl-long.491,2020.acl-main.522,1,0.754155,"(Ji and Grishman, 2008; Gupta and Ji, 2009; Li et al., 2013) rely on manually-crafted features to extract events. In recent years, the neural models become mainstream, which automatically learn effective features with neural networks, including convolutional neural networks (Nguyen and Grishman, 2015; Chen et al., 2015), recurrent neural networks (Nguyen et al., 2016), graph convolutional networks (Nguyen and Grishman, 2018; Lai et al., 2020). With the recent successes of BERT (Devlin et al., 2019), PLMs have also been used for EE (Wang et al., 2019a,b; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020). Although achieving remarkable performance in benchmarks such as ACE 2005 (Walker et al., 2006) and similar datasets (Ellis et al., 2015, 2016; Getman et al., 2017; Wang et al., 2020), these PLM-based works solely focus on better finetuning rather than pre-training for EE. In this paper, we study pre-training to better utilize rich event knowledge in large-scale unsupervised data. Event Schema Induction. Supervised EE models cannot generalize to continually-emerging new event types and argument roles. To this end, Chambers and Jurafsky (2011) explore to induce event schemata from raw text by"
2021.acl-long.491,P15-1019,0,0.0450974,"Missing"
2021.acl-long.491,N19-1105,1,0.917634,"only contain thousands of instances and cover limited event types. Thus they are inadequate to train large neural models (Wang et al., 2020) and develop methods that can generalize to continually-emerging new event types (Huang and Ji, 2020). Inspired by the success of recent pre-trained language models (PLMs) for NLP tasks, some pio6283 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6283–6297 August 1–6, 2021. ©2021 Association for Computational Linguistics neering work (Wang et al., 2019a; Wadden et al., 2019) attempts to fine-tune general PLMs (e.g, BERT (Devlin et al., 2019)) for EE. Benefiting from the strong general language understanding ability learnt from large-scale unsupervised data, these PLM-based methods have achieved state-ofthe-art performance in various public benchmarks. Although leveraging unsupervised data with pretraining has gradually become a consensus for EE and NLP community, there still lacks a pre-training method orienting event modeling to take full advantage of rich event knowledge lying in largescale unsupervised data. The key challenge here is to"
2021.acl-long.491,2020.emnlp-main.129,1,0.921459,"ced neural networks (Chen et al., 2015; Nguyen et al., 2016; Nguyen and Grishman, 2018) with humanannotated datasets and pre-defined event schemata. These methods work well in lots of public benchmarks such as ACE 2005 (Walker et al., 2006) and TAC KBP (Ellis et al., 2016), yet they still suffer from data scarcity and limited generalizability. Since annotating event data and defining event schemata are especially expensive and laborintensive, existing EE datasets typically only contain thousands of instances and cover limited event types. Thus they are inadequate to train large neural models (Wang et al., 2020) and develop methods that can generalize to continually-emerging new event types (Huang and Ji, 2020). Inspired by the success of recent pre-trained language models (PLMs) for NLP tasks, some pio6283 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6283–6297 August 1–6, 2021. ©2021 Association for Computational Linguistics neering work (Wang et al., 2019a; Wadden et al., 2019) attempts to fine-tune general PLMs (e.g, BERT (Devlin et al., 2019)) for EE. Benefiting from the st"
2021.acl-long.491,D19-1584,1,0.881831,"only contain thousands of instances and cover limited event types. Thus they are inadequate to train large neural models (Wang et al., 2020) and develop methods that can generalize to continually-emerging new event types (Huang and Ji, 2020). Inspired by the success of recent pre-trained language models (PLMs) for NLP tasks, some pio6283 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6283–6297 August 1–6, 2021. ©2021 Association for Computational Linguistics neering work (Wang et al., 2019a; Wadden et al., 2019) attempts to fine-tune general PLMs (e.g, BERT (Devlin et al., 2019)) for EE. Benefiting from the strong general language understanding ability learnt from large-scale unsupervised data, these PLM-based methods have achieved state-ofthe-art performance in various public benchmarks. Although leveraging unsupervised data with pretraining has gradually become a consensus for EE and NLP community, there still lacks a pre-training method orienting event modeling to take full advantage of rich event knowledge lying in largescale unsupervised data. The key challenge here is to"
2021.acl-long.491,2020.emnlp-main.196,0,0.527338,"f two components: event semantic pre-training and event structure pre-training, of which details are introduced in Section 3.2 and Section 3.3, respectively. At the beginning of this section, we first introduce the required preprocessing in Section 3.1, including the AMR parsing and how we modify the parsed AMR structures for our pre-training. 3.1 Preprocessing CLEVE relies on AMR structures (Banarescu et al., 2013) to build broad and diverse self-supervision signals for learning event knowledge from largescale unsupervised corpora. To do this, we use automatic AMR parsers (Wang et al., 2015; Xu et al., 2020) to parse the sentences in unsupervised corpora into AMR structures. Each AMR structure is a directed acyclic graph with concepts as nodes and semantic relations as edges. Moreover, each node typically only corresponds to at most one word, and a multi-word entity will be represented as a list of nodes connected with name and op (conjunction operator) edges. Considering pretraining entity representations will naturally benefits event argument extraction, we merge these lists into single nodes representing multi-word entities (like the “CNN’s Kelly Wallace” in Figure 1) during both event semanti"
2021.acl-long.491,D19-1582,0,0.0155406,"al., 2015); (3) the model incorporating syntactic knowledge, dbRNN (Sha et al., 2018); (4) stateof-the-art models on ED and EAE respectively, including GatedGCN (Lai et al., 2020) and SemSynGTN (Pouran Ben Veyseh et al., 2020); (5) a stateof-the-art EE model RCEE ER (Liu et al., 2020), which tackle EE with machine reading comprehension (MRC) techniques. The last four models adopt PLMs to learn representations. On MAVEN, we compare CLEVE with the official ED baselines set by Wang et al. (2020), including DMCNN (Chen et al., 2015), BiLSTM (Hochreiter and Schmidhuber, 1997), BiLSTM+CRF, MOGANED (Yan et al., 2019), DMBERT (Wang et al., 2019a), BERT+CRF. Evaluation Results The evaluation results are shown in Table 1 and Table 2. We can observe that: (1) CLEVE achieves significant improvements to its basic model RoBERTa on both ACE 2005 and MAVEN. The p-values under the t-test are 4×10−8 , 2×10−8 and 6 × 10−4 for ED on ACE 2005, EAE on ACE 2005, and ED on MAVEN, respectively. It also outperforms or achieves comparable results with 6288 ED Metric (B-Cubed) P R EAE F1 P R ED F1 LiberalEE 55.7 45.1 49.8 36.2 26.5 30.6 RoBERTa RoBERTa+VGAE 44.3 24.9 31.9 24.2 17.3 20.2 47.0 26.8 34.1 25.6 17.9 21.1 CLEVE w/o"
2021.acl-long.534,D19-1274,1,0.830408,"369 .585 .451 .365 .603 .394 .620 Table 6: Results of Link Prediction. Bold fonts denote the best scores and underlines highlight the second best. Figure 4: Macro F1 variance when we search the best thresholds for open-world triple classification. dataset construction, although we utilize two sets of triples to minimize rule leakage. Actually, inference of rules may be more important than we thought to improve the reliability and interpretability of knowledge-driven models. This also motivates us to incorporate rule knowledge into KGC training for advanced reasoning ability (Guo et al., 2018; Li et al., 2019b). (2) KGC models perform better on InferWiki16k than InferWiki64k, due to the higher structure density and rule confidence. (3) Models have higher hit@10 and lower hit@1 on InferWiki than other datasets (e.g., CoDEx). This agrees with an intuition that most entities are irrelevant, making it trivial to judge these corrupted triples as in triple classification. And, only a small portion of entities is difficult to predict, which requires strong inference ability. Besides, hit@1 varies a lot, so that we can better compare among models. Impacts of Inferential Path Length Figure 5 presents Hit@1"
2021.acl-long.534,D19-1405,0,0.0246164,"369 .585 .451 .365 .603 .394 .620 Table 6: Results of Link Prediction. Bold fonts denote the best scores and underlines highlight the second best. Figure 4: Macro F1 variance when we search the best thresholds for open-world triple classification. dataset construction, although we utilize two sets of triples to minimize rule leakage. Actually, inference of rules may be more important than we thought to improve the reliability and interpretability of knowledge-driven models. This also motivates us to incorporate rule knowledge into KGC training for advanced reasoning ability (Guo et al., 2018; Li et al., 2019b). (2) KGC models perform better on InferWiki16k than InferWiki64k, due to the higher structure density and rule confidence. (3) Models have higher hit@10 and lower hit@1 on InferWiki than other datasets (e.g., CoDEx). This agrees with an intuition that most entities are irrelevant, making it trivial to judge these corrupted triples as in triple classification. And, only a small portion of entities is difficult to predict, which requires strong inference ability. Besides, hit@1 varies a lot, so that we can better compare among models. Impacts of Inferential Path Length Figure 5 presents Hit@1"
2021.acl-long.534,P19-1140,1,0.924127,"h Predicate location placeOfBirth nationality travelMonth travelMonth Tail ? (Ans: Florida) Atlanta U.S.A. ? (Ans: October) Jan., Feb., Mar., Apr., May., Jun., Jul., Aug., Sep., Nov., Dec. Table 1: Low-quality examples in FB15k237. We only present related triples. Ans denotes the missing entity. Introduction Knowledge Graph Completion (KGC) aims to predict missing links in KG by inferring new knowledge from existing ones. Attributed to its reasoning ability, KGC models are crucial in alleviating the KG’s incompleteness issue and benefiting many downstream applications, such as recommendation (Cao et al., 2019b) and information extraction (Hu et al., 2021; Cao et al., 2020a). However, the KGC performance on existing benchmarks are still unsatisfactory — 0.51 Hit Ratio@1 and 187 Mean Rank of the top-ranked model (Wang et al., 2019) on the widely used FB15k237 (Toutanova and Chen, 2015). Do we have a slow progress of models (Akrami et al., 2020)? Or should we blame for the low-quality of benchmarks? In this paper, we re-think the task of KGC and construct a new benchmark dubbed InferWiki that highlights three fundamental objectives: Test triples should be inferential: this is the essential requiremen"
2021.acl-long.534,2020.acl-main.100,1,0.88272,"Month Tail ? (Ans: Florida) Atlanta U.S.A. ? (Ans: October) Jan., Feb., Mar., Apr., May., Jun., Jul., Aug., Sep., Nov., Dec. Table 1: Low-quality examples in FB15k237. We only present related triples. Ans denotes the missing entity. Introduction Knowledge Graph Completion (KGC) aims to predict missing links in KG by inferring new knowledge from existing ones. Attributed to its reasoning ability, KGC models are crucial in alleviating the KG’s incompleteness issue and benefiting many downstream applications, such as recommendation (Cao et al., 2019b) and information extraction (Hu et al., 2021; Cao et al., 2020a). However, the KGC performance on existing benchmarks are still unsatisfactory — 0.51 Hit Ratio@1 and 187 Mean Rank of the top-ranked model (Wang et al., 2019) on the widely used FB15k237 (Toutanova and Chen, 2015). Do we have a slow progress of models (Akrami et al., 2020)? Or should we blame for the low-quality of benchmarks? In this paper, we re-think the task of KGC and construct a new benchmark dubbed InferWiki that highlights three fundamental objectives: Test triples should be inferential: this is the essential requirement of KGC. Each test triple should have supportive samples in the"
2021.acl-long.534,D18-1362,0,0.0292892,"negative yet non-inferential from training data. Since KGC models output real-value scores for triples, we classify scores into labels by choosing one or two thresholds per relation type on valid. Accuracy, precision, recall, and F1 are measurements. 4.2 Models For comprehensive comparison, we choose three types of representative models as baselines: (1) Knowledge Graph Embedding models, including TransE (Bordes et al., 2013), ComplEx (Trouillon et al., 2016), RotatE (Sun et al., 2019), ConvE (Dettmers et al., 2018), and TuckER (Balazevic et al., 2019), (2) multihop reasoning model Multihop (Lin et al., 2018), and (3) rule-based AnyBURL (Meilicke et al., 2019). Note that the latter two are specially designed for link prediction. The detailed implementation including parameters and thresholds can be found in Appendix F. 4.3 Triple Classification Results Table 4 shows micro scores for triple classification. We can see that all of the baselines perform 6860 TransE ComplEx RotatE ConvE TuckER Acc .823 .812 .852 .881 .862 InferWiki64k Prec Recall .782 .895 .779 .872 .808 .924 .864 .906 .897 .817 F1 .835 .823 .862 .884 .855 InferWiki16k Prec Recall .736 .926 .835 .778 .769 .891 .887 .911 .836 899 Acc .7"
2021.acl-long.534,2020.emnlp-main.669,0,0.149026,"bserve two major issues of current KGC datasets: unpredictable and meaningless test triples, which may hinder evaluating and advancing stateof-the-arts. As shown in Table 1, the first example of inferring the location for David (i.e., Florida) is even impossible for humans — not to mention machines — merely based on his birthplace and nationality (i.e., Atlanta and USA). In contrast, the second one is predictable but meaningless to find the missing month from a list of months within a year. The above cases are very common in existing datasets, e.g., YAGO3-10 (Dettmers et al., 2018) and CoDEx (Safavi and Koutra, 2020), mainly due to their construction process: first collecting a highfrequency subset of entities and then randomly splitting their triples into train/test. In this setting, KGC models may be over- or under-estimated, as we are even unsure if a human can perform better. Test triples may be inferred positive, negative, or unknown. Following open-world assumption: what is not observed in KG is not necessar6855 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6855–6865 August 1–6"
2021.acl-long.534,D15-1034,0,0.0366778,"Missing"
2021.emnlp-main.341,P19-1259,0,0.0143442,"onduct experiments for the two forms https://github.com/shijx12/TransferNet 4150 et al., 2020) learn a soft distribution for intermediate relations and can be optimized using only the final answer. However, it is not clear how to extend them to the text form. Question answering over text corpus is also known as “reading comprehension”. For simple questions, whose answer can be retrieved directly from the text, pretrained models (Devlin et al., 2018; Lan et al., 2019) have performed better than humans (Zhang et al., 2020). For multi-hop questions that are much more challenging, existing works (Ding et al., 2019; Fang et al., 2019; Tu et al., 2020; Zhao et al., 2019a) usually convert the text into a rule-based or learning-based entity graph, and then use graph neural networks (Kipf and Welling, 2016) to perform implicit reasoning. Similar to PullNet, they are weak in interpretability. Besides, most of them build the graph by just connecting relevant entities, missing the important edge textual information. 3 3.1 Methodology Preliminary We conduct multi-hop reasoning on a relation graph, which takes entities as nodes and relations between them as edges. The relations can be of different forms, specifi"
2021.emnlp-main.341,N19-1246,0,0.0396885,"Missing"
2021.emnlp-main.341,N19-1028,0,0.0133161,"constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color. Introduction Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017) or structured knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved (Yang et al., 2018; Dua et al., 2019; Zhang et al., 2017; Talmor and Berant,"
2021.emnlp-main.341,D13-1160,0,0.0893291,"Missing"
2021.emnlp-main.341,P17-1171,0,0.0184387,"tion Figure 1: Answering a multi-hop question over the relation graph. The relations are constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color. Introduction Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017) or structured knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far f"
2021.emnlp-main.341,P17-1147,0,0.0240817,"Melinda Gates Foundation Figure 1: Answering a multi-hop question over the relation graph. The relations are constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color. Introduction Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017) or structured knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at mult"
2021.emnlp-main.341,P17-1003,0,0.0383861,"Missing"
2021.emnlp-main.341,D16-1147,0,0.480206,"efined threshold τ and only consider relations that start from these entities. Besides, if there are too many relations meeting this condition, we will only preserve top ω of them, sorting based on their subject entity score. By doing so, we just need to consider at most ω relations at each step. We use the same method to process the mixed form, by simply regarding the label predicates as one-word sentences. 4 4.1 Experiments Datasets MetaQA (Zhang et al., 2017) is a largescale dataset of multi-hop question answering t Wi,j = ptri,j,k . (12) over knowledge graph, which extends Wikik=1 Movies (Miller et al., 2016) from single-hop to multi-hop. It contains more than 400k questions, We gather the probabilities by summing them Pup. which are generated using dozens of templates and max is another feasible option, but we find is have up to 3 hops. Its knowledge graph is from the more efficient and more stable. movie domain, including 43k entities, 9 predicates, 3.5.2 Text Form and 135k triples. In the text form, relations are represented with natBesides the label from, we also constructed the ural language descriptions. The graph is built by text form of MetaQA by extracting the text corextracting the co-oc"
2021.emnlp-main.341,D18-1051,0,0.028381,"ntelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017) or structured knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved (Yang et al., 2018; Dua et al., 2019; Zhang et al., 2017; Talmor and Berant, 2018). In this paper, we focus on multi-hop QA based on relation graphs, which consists of entities and their relations. As shown in Figure 1, the relations can be represented by two forms: Corresponding author. • Label form, also known as knowledge graph (e.g., Freebase (Bollacker et al., 2008), Wikidata (Vrandeˇci´c and Krötzsch, 2014)"
2021.emnlp-main.341,P16-2033,0,0.172806,"Missing"
2021.emnlp-main.341,D16-1264,0,0.0439615,"soft Corporation Bill & Melinda Gates Foundation Figure 1: Answering a multi-hop question over the relation graph. The relations are constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color. Introduction Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017) or structured knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the enti"
2021.emnlp-main.341,D19-1242,0,0.456018,"t form, whose search space is even much huger. The second strand is to collect evidences by using graph neural networks (Sun et al., 2 Related Work 2018, 2019). They can handle both the two relation In this paper we focus on multi-hop question anforms and achieve state-of-the-art performance. Alswering over the graph structure that is either though they prevail over the path-based models in knowledge graph or built from text corpus. In performance, they are weak in interpretability since previous works, GraftNet (Sun et al., 2018) and their intermediate reasoning process is black-box PullNet (Sun et al., 2019) have a similar setting to neural network layers. ours but they mostly aim at the mixed form, which In this paper, we propose a novel model for includes both label relations and text relations. multi-hop QA, dubbed TransferNet, which has They first retrieve a question-specific subgraph and the following advantages: 1) Generality. It can then use graph convolutional networks (Kipf and deal with the label form, the text form, and their Welling, 2016) to implicitly infer the answer encombinations in a unified framework. 2) Effectivetity. These GCN-based methods are usually weak ness. TransferNet"
2021.emnlp-main.341,D18-1455,0,0.109529,"tly proposed for the label form. So, it is not clear how to adapt them to the text form, whose search space is even much huger. The second strand is to collect evidences by using graph neural networks (Sun et al., 2 Related Work 2018, 2019). They can handle both the two relation In this paper we focus on multi-hop question anforms and achieve state-of-the-art performance. Alswering over the graph structure that is either though they prevail over the path-based models in knowledge graph or built from text corpus. In performance, they are weak in interpretability since previous works, GraftNet (Sun et al., 2018) and their intermediate reasoning process is black-box PullNet (Sun et al., 2019) have a similar setting to neural network layers. ours but they mostly aim at the mixed form, which In this paper, we propose a novel model for includes both label relations and text relations. multi-hop QA, dubbed TransferNet, which has They first retrieve a question-specific subgraph and the following advantages: 1) Generality. It can then use graph convolutional networks (Kipf and deal with the label form, the text form, and their Welling, 2016) to implicitly infer the answer encombinations in a unified framewo"
2021.emnlp-main.341,N19-1029,0,0.0392859,"Missing"
2021.emnlp-main.341,C18-1171,0,0.0304481,"Missing"
2021.emnlp-main.341,N18-1059,0,0.113523,"iang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved (Yang et al., 2018; Dua et al., 2019; Zhang et al., 2017; Talmor and Berant, 2018). In this paper, we focus on multi-hop QA based on relation graphs, which consists of entities and their relations. As shown in Figure 1, the relations can be represented by two forms: Corresponding author. • Label form, also known as knowledge graph (e.g., Freebase (Bollacker et al., 2008), Wikidata (Vrandeˇci´c and Krötzsch, 2014)), whose relations are manually-defined constrained predicates (e.g., Spouse, CEO). • Text form, whose relations are free texts retrieved from textual corpus. We can easily build the graph by extracting the co-occuring sentences of two entities. Since the label form"
2021.emnlp-main.341,N19-1301,0,0.0358789,"Missing"
2021.emnlp-main.341,D18-1259,0,0.0180182,"knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved (Yang et al., 2018; Dua et al., 2019; Zhang et al., 2017; Talmor and Berant, 2018). In this paper, we focus on multi-hop QA based on relation graphs, which consists of entities and their relations. As shown in Figure 1, the relations can be represented by two forms: Corresponding author. • Label form, also known as knowledge graph (e.g., Freebase (Bollacker et al., 2008), Wikidata (Vrandeˇci´c and Krötzsch, 2014)), whose relations are manually-defined constrained predicates (e.g., Spouse, CEO). • Text form, whose relations are free texts retrieved from textual corpus. We can easily build the graph by extracting"
2021.emnlp-main.341,P15-1128,0,0.213168,"The relations are constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color. Introduction Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017) or structured knowledge base (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019). Along with the fast development of deep learning, especially the pretraining technology (Devlin et al., 2018; Lan et al., 2019), state-of-the-art models have been shown comparative with human per∗ What organization did the wife of Bill Gates found? formance on simple questions that only need a single hop (Petrochuk and Zettlemoyer, 2018; Zhang et al., 2020), e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved (Yang et al., 2018; Dua et al., 2019; Zhang et al., 201"
2021.emnlp-main.700,N18-1165,0,0.0193961,"g triple completion. Most of We explore two methods to give each rule an the existing multi-hop reasoning models are based interpretability score, namely manual annotation on the reinforcement learning (RL) framework. and automatic generation by rule mining methods. Among them, DeepPath (Xiong et al., 2017) is the The former is the focus of this paper. Specifically, first work to formally propose and solve the task we invite annotators to manually annotate inter- of multi-hop reasoning using RL, which inspires pretability scores for all possible rules to establish much later work, e.g., DIVA (Chen et al., 2018), a manually-annotated benchmark (A-benchmark). and AttnPath (Wang et al., 2019). MINERVA (Das This labeling process also faces a challenge, i.e., et al., 2018) is an end-to-end model with a wide interpretability is highly subjective and hard to an- impact that solves multi-hop reasoning task. On notate. Different annotators may give various ex- the basis of this model, M-Walk (Shen et al., 2018) planations. To reduce the variations, we provide and MultiHop (Lin et al., 2018) solve the problem the annotators with a number of interpretable op- of reward sparsity through off-policy learning and"
2021.emnlp-main.700,D19-1269,0,0.0166075,"re some other models such as the DIVINE (Li annotate and take their average score as the final re- and Cheng, 2019), R2D2 (Hildebrandt et al., 2020), sult. In addition to A-benchmark, we also provide RLH (Wan et al., 2020) and RuleGuider (Lei et al., 8900 Dataset # Entity # Relation # Triple WD15K 15,817 182 176,524 Table 1: Statistics of WD15K. The three columns denote the number of entities, relations and triples, respectively. 2020) models that improve multi-hop reasoning from the four directions of imitation learning, debate dynamics, hierarchical RL, and rule guidance, respectively. CPL (Fu et al., 2019) and DacKGR (Lv et al., 2020) enhance the effect of models by adding additional triples to KG. 2.2 Rule-based Reasoning Similar to multi-hop reasoning, rule-based reasoning can also perform interpretable triple completion, except that they give the corresponding rules instead of specific paths. Rule-based reasoning can be divided into two categories, namely, neuralbased models and rule mining models. Among them, neural-based models (Yang et al., 2017; Rocktäschel and Riedel, 2017; Sadeghian et al., 2019; Minervini et al., 2020) give the corresponding rules while performing triple completion, w"
2021.emnlp-main.700,2020.emnlp-main.10,0,0.0424178,"while rule mining models (Galárraga et al., 2015; Omran et al., 2018; Ho et al., 2018; Meilicke et al., 2019) first mine the rules and then use them for completion. 2.3 Interpretability Evaluation Few research work targets interpretability evaluation, although they admit the importance. Most multi-hop reasoning models rely on case study (Hildebrandt et al., 2020; Wan et al., 2020) to present the interpretability quality, while RuleGuider(Lei et al., 2020) samples tests and computes their differences for evaluation. There are some works in other areas (Gilpin et al., 2018; Yang and Kim, 2019; Jhamtani and Clark, 2020) to test interpretability, but they cannot be directly applied to multi-hop reasoning tasks for knowledge graphs. 3 Preliminary predict the correct tail entity t, but also give a path (h, r, t) ← (h, r1 , e1 ) ∧ (e1 , r2 , e2 ) ∧ · · · ∧ (en−1 , rn , t) as an explanation. Rule-based reasoning can be considered as generalized multi-hop reasoning and can also be evaluated on our benchmark. Given a triple query (h, r, ?), it needs to predict the tail entity t and give some Horn rules with confidence as an explanation, where the rule f is of the following form: r(X, Y ) ← r1 (X, A1 ) ∧ · · · ∧ rn"
2021.emnlp-main.700,2020.emnlp-main.688,0,0.0645641,"et al., 2017; Rocktäschel and Riedel, 2017; Sadeghian et al., 2019; Minervini et al., 2020) give the corresponding rules while performing triple completion, while rule mining models (Galárraga et al., 2015; Omran et al., 2018; Ho et al., 2018; Meilicke et al., 2019) first mine the rules and then use them for completion. 2.3 Interpretability Evaluation Few research work targets interpretability evaluation, although they admit the importance. Most multi-hop reasoning models rely on case study (Hildebrandt et al., 2020; Wan et al., 2020) to present the interpretability quality, while RuleGuider(Lei et al., 2020) samples tests and computes their differences for evaluation. There are some works in other areas (Gilpin et al., 2018; Yang and Kim, 2019; Jhamtani and Clark, 2020) to test interpretability, but they cannot be directly applied to multi-hop reasoning tasks for knowledge graphs. 3 Preliminary predict the correct tail entity t, but also give a path (h, r, t) ← (h, r1 , e1 ) ∧ (e1 , r2 , e2 ) ∧ · · · ∧ (en−1 , rn , t) as an explanation. Rule-based reasoning can be considered as generalized multi-hop reasoning and can also be evaluated on our benchmark. Given a triple query (h, r, ?), it needs to"
2021.emnlp-main.700,D19-1266,0,0.0250642,"h the highest and lowest interpretability scores. Besides, we also analyze the relation between interpretability scores and confidence scores. Due to space constraints, we put these contents in Appendix B. 5 5.1 Experiments Experimental Setup Models. We choose two types of multi-hop reasoning models and rule-based reasoning models to evaluate their interpretability. For multi-hop reasoning, we use the following five models: MINERVA where c(f ) is the confidence score of rule f . We (Das et al., 2018), MultiHop (Lin et al., 2018), DIcan regard it as a three-classification task, where the VINE (Li and Cheng, 2019), R2D2 (Hildebrandt type of prediction is Type(f ), and the golden type et al., 2020) and RuleGuider (Lei et al., 2020). For is the annotation result. We use Micro-F1 score rule-based reasoning, we evaluate the interpretabilto find the best h1 and h2 , i.e., we search the best h1 and h2 that can get the highest Micro-F1 score. ity on the following four models: AMIE+ (Galárraga et al., 2015), NeuralLP (Yang et al., 2017), Finally, for every rules f ∈ F, if f ∈ / F ∗ , S(f ) = RuLES (Ho et al., 2018) and AnyBURL (Meilicke 0. Otherwise, we can obtain Type(f ) according et al., 2019). We choose th"
2021.emnlp-main.700,D17-1060,0,0.0265611,"isting multi-hop reasoning models in terms of performance and interpretability, which points us to a possible future research direction, i.e., how to better incorporate rules into multi-hop reasoning. 2 2.1 Related Work Multi-Hop Reasoning Multi-hop reasoning models can give interpretable paths while performing triple completion. Most of We explore two methods to give each rule an the existing multi-hop reasoning models are based interpretability score, namely manual annotation on the reinforcement learning (RL) framework. and automatic generation by rule mining methods. Among them, DeepPath (Xiong et al., 2017) is the The former is the focus of this paper. Specifically, first work to formally propose and solve the task we invite annotators to manually annotate inter- of multi-hop reasoning using RL, which inspires pretability scores for all possible rules to establish much later work, e.g., DIVA (Chen et al., 2018), a manually-annotated benchmark (A-benchmark). and AttnPath (Wang et al., 2019). MINERVA (Das This labeling process also faces a challenge, i.e., et al., 2018) is an end-to-end model with a wide interpretability is highly subjective and hard to an- impact that solves multi-hop reasoning t"
2021.findings-acl.153,2020.emnlp-demos.22,0,0.0410419,"ould achieve higher scores on these metrics. We use the “Filtered” setting for all the evaluations, which filters out other true answers from the prediction results to get the final rank for each test case. 5.4 Hyperparameter Settings According to Ruffinelli et al. (2020), performances of KGE methods are sensitive to hyperparameters. Following them, we run 30 quasi-random trails for all models from predefined hyperparameter spaces. We list the hyperparameter spaces we use in Appendix A.5. We run all trails for 100 epochs. For all single-view KE methods, we use the implementations from LibKGE (Broscheit et al., 2020), which utilizes the Ax framework to perform quasi-random hyperparameter search. For AttH, we use the implementation from the authors1 . For JOIE, we use the implementation from the authors2 . We use TransE as the backend and adopt the suggested hyperparameter space from the paper. 6 Experimental Results In this section, we provide the experimental results and further propose several future directions. 6.1 Knowledge Abstraction The results of knowledge abstraction are shown in Table 4. From the results, we can see that AttH has 1 2 https://github.com/HazyResearch/KGEmb https://github.com/Junhe"
2021.findings-acl.153,2020.acl-main.617,0,0.0496769,"Missing"
2021.findings-acl.153,P15-1067,0,0.0372355,") and YAGO39K (Lv et al., 2018). However, they do not provide the full concept graphs with logical relations. Thirdly, some datasets provide the full concept graphs (Hao et al., 2019), but both the scale and the depth of the concept hierarchy are limited. For example, the entity numbers of DB111K-174 (Hao et al., 2019) and our dataset KACC-M are similar, but KACC-M has 38 times more concepts than DB111K-174 (see Table 1). 2.2 Knowledge Embedding Methods Existing knowledge embedding (KE) methods can be categorized as translation models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015; Ji et al., 2015; Sun et al., 2019), tensor factorization based models (Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016; Balaˇzevi´c et al., 2019), and neural models (Socher et al., 2013; Dettmers et al., 2018; Nguyen et al., 2018). These methods are typically designed for single-view KGs. Although they can be directly applied to EC-KGs by ignoring different characteristics between entity graphs and concept graphs, they cannot take full advantage of the information in EC-KGs. Several works (Krompaß et al., 2015; Xie et al., 2016; Ma et al., 2017; Moon et al., 2017) incorporate the type informat"
2021.findings-acl.153,D18-1222,1,0.91582,"EC-KG is shown in Figure 1. During the last decade, there are massive works focusing on learning representations for KGs such as TransE (Bordes et al., 2013), DistMult (Yang et al., 2015), ComplEx (Trouillon et al., 2016), and TuckER (Balaˇzevi´c et al., 2019). Though they have achieved promising results on knowledge graph completion, most of them focus on a single graph, especially the entity graph. Beyond modeling a single graph of KGs, recent studies demonstrate that jointly modeling the two graphs in the EC-KG can improve the understanding of each one (Xie et al., 2016; Moon et al., 2017; Lv et al., 2018; Hao et al., 2019). They also propose 1751 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1751–1763 August 1–6, 2021. ©2021 Association for Computational Linguistics several tasks on the EC-KG, such as link prediction and entity typing. These tasks focus on partial aspects of knowledge abstraction, concretization, and completion, which are essential abilities for humans to recognize the world and acquire knowledge. For example, in entity typing, a model may link the entity “Da Vinci” to the concept “painter” which reflects the model’s abstraction ability. Ho"
2021.findings-acl.153,N18-2053,0,0.0200075,"concept hierarchy are limited. For example, the entity numbers of DB111K-174 (Hao et al., 2019) and our dataset KACC-M are similar, but KACC-M has 38 times more concepts than DB111K-174 (see Table 1). 2.2 Knowledge Embedding Methods Existing knowledge embedding (KE) methods can be categorized as translation models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015; Ji et al., 2015; Sun et al., 2019), tensor factorization based models (Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016; Balaˇzevi´c et al., 2019), and neural models (Socher et al., 2013; Dettmers et al., 2018; Nguyen et al., 2018). These methods are typically designed for single-view KGs. Although they can be directly applied to EC-KGs by ignoring different characteristics between entity graphs and concept graphs, they cannot take full advantage of the information in EC-KGs. Several works (Krompaß et al., 2015; Xie et al., 2016; Ma et al., 2017; Moon et al., 2017) incorporate the type information into KE methods to help the completion of entity graphs. ETE (Moon 1752 et al., 2017) further conducts entity typing, which can be seen as a simplified version of our knowledge abstraction task. Though types of entities can be"
2021.findings-acl.153,2020.emnlp-main.669,0,0.0266774,"on abstraction and concretization tasks, they are not competitive to some general KGE models on logical relations. Moreover, all methods have drastic performance degradation on multi-hop tasks, and the knowledge transfer between the entity graph and the concept graph is still obscure. Finally, we present useful insights for future model design. 2 2.1 Related Work Knowledge Graph Datasets Existing datasets for knowledge graph completion are usually subgraphs of large-scale KGs, such as FB15K, FB15K-237, WN18, WN18RR and CoDEx (Bordes et al., 2013; Toutanova et al., 2015; Dettmers et al., 2018; Safavi and Koutra, 2020). These datasets are all single-view KGs, in which FB15K, FB15K-237, and CoDEx focus on the entity view while WN18 and WN18RR can be regarded as concept view KGs. Several datasets try to link the two views in different ways. Firstly, some datasets provide additional type information to the entity graph, such as FB15K+, FB15K-ET and YAGO43K-ET (Xie et al., 2016; Moon et al., 2017). Secondly, some datasets provide concept hierarchies for the entity graph, such as Probase (Wu et al., 2012) and YAGO39K (Lv et al., 2018). However, they do not provide the full concept graphs with logical relations."
2021.findings-acl.153,D15-1174,0,0.541521,"archies perform better than general KGE models on abstraction and concretization tasks, they are not competitive to some general KGE models on logical relations. Moreover, all methods have drastic performance degradation on multi-hop tasks, and the knowledge transfer between the entity graph and the concept graph is still obscure. Finally, we present useful insights for future model design. 2 2.1 Related Work Knowledge Graph Datasets Existing datasets for knowledge graph completion are usually subgraphs of large-scale KGs, such as FB15K, FB15K-237, WN18, WN18RR and CoDEx (Bordes et al., 2013; Toutanova et al., 2015; Dettmers et al., 2018; Safavi and Koutra, 2020). These datasets are all single-view KGs, in which FB15K, FB15K-237, and CoDEx focus on the entity view while WN18 and WN18RR can be regarded as concept view KGs. Several datasets try to link the two views in different ways. Firstly, some datasets provide additional type information to the entity graph, such as FB15K+, FB15K-ET and YAGO43K-ET (Xie et al., 2016; Moon et al., 2017). Secondly, some datasets provide concept hierarchies for the entity graph, such as Probase (Wu et al., 2012) and YAGO39K (Lv et al., 2018). However, they do not provide"
C18-1024,D15-1103,0,0.01993,"ey propose an embedding based method which combines a global model with a context model. A global model that scores based on aggregated context information and a context model that aggregates the scores of individual contexts (Yaghoobzadeh et al., 2017). Fine-grained entity typing in text is related to our task. Different from the works mentioned above, it 290 seeks to detect local types of an entity mention inside an individual sentence, and the same entity could have different types in different sentences (Ling and Weld, 2012; Yosef et al., 2012; Gillick et al., 2014; Dong et al., 2015; Del Corro et al., 2015; Yogatama et al., 2015; Ren et al., 2016b; Ren et al., 2016a; Shimaoka et al., 2017; Rabinovich and Dan, 2017). 6 Conclusion In this paper, we propose an attributed and predictive entity embedding method to address the task of fine-grained entity typing in KB. It combines the advantages of attributed network embedding method and semi-supervised learning. Specifically, it employs a deep neural network architecture to integrate structure and attribute information of an entity. We jointly predict a labeled entity’s neighbors and types, and model the structure of type hierarchy in a margin-based"
C18-1024,Q14-1037,0,0.0605156,"Missing"
C18-1024,P17-3010,0,0.0211633,"py loss function: L (y, y∗ ) = K X     −y∗(i) log y(i) − 1 − y∗(i) log 1 − y(i) (2) i=1 The key difficulty in computing P (t|e) is to learn a good representation ~v (e) for entity e. Several models have achieved the state-of-the-art performance. However, these models still face the following non-trivial challenges: • Entity attributes and link structure are typically regraded as separated features without considering their correlations. Recent research shows the importance of integrating link structure and entity attributes for learning more informative representations (Liao et al., 2017; Li et al., 2017). Could we seamlessly integrate entity attributes and link structure into a unified entity network? Since the link structure and entity attributes offer different sources of information, how shall we capture the complex non-linear relationship between them? • The type information of the labeled entities in E l is only used in the learning phase of the type predictor, but totally ignored in the representation learning phase. Recent research shows incorporating labeled information in representation learning could enhance the predictive power of the learning embeddings for specific tasks (Tang et"
C18-1024,Q15-1023,0,0.0605066,"Missing"
C18-1024,C14-1199,0,0.0730698,"Missing"
C18-1024,N15-1054,0,0.151356,"model as APE, and compare it with three sets of methods: • Entity typing methods: We compare APE with five state-of-the-art entity typing methods. FIGMENT uses entity representation learned from annotated corpus for type inference (Yaghoobzadeh and Sch¨utze, 2015). CUTE employs a multi-label hierarchical classification method to address entity typing task (Xu et al., 2016). MuLR uses multi-level representations of entities (character, word and entity) to make type inference in KB (Yaghoobzadeh and Sch¨utze, 2017). Global utilizes entity text description to infer missing entity type instances (Neelakantan and Chang, 2015). Corpus designs global and context model to make type inference jointly (Yaghoobzadeh et al., 2017). • Network Embedding methods: Attributed and predictive network embedding methods can learn informative entity representations, so we compare APE with them. PTE learns predictive text embeddings from heterogeneous network (Tang et al., 2015a). Planetoid is a semi-supervised network embedding method which makes neighbor and label prediction jointly (Yang et al., 2016). ASNE integrates structural and attribute information via a deep neural architecture (Liao et al., 2017). • APE’s variants: If we"
C18-1024,P17-2052,0,0.0189774,"that scores based on aggregated context information and a context model that aggregates the scores of individual contexts (Yaghoobzadeh et al., 2017). Fine-grained entity typing in text is related to our task. Different from the works mentioned above, it 290 seeks to detect local types of an entity mention inside an individual sentence, and the same entity could have different types in different sentences (Ling and Weld, 2012; Yosef et al., 2012; Gillick et al., 2014; Dong et al., 2015; Del Corro et al., 2015; Yogatama et al., 2015; Ren et al., 2016b; Ren et al., 2016a; Shimaoka et al., 2017; Rabinovich and Dan, 2017). 6 Conclusion In this paper, we propose an attributed and predictive entity embedding method to address the task of fine-grained entity typing in KB. It combines the advantages of attributed network embedding method and semi-supervised learning. Specifically, it employs a deep neural network architecture to integrate structure and attribute information of an entity. We jointly predict a labeled entity’s neighbors and types, and model the structure of type hierarchy in a margin-based way. Experiments on real world datasets demonstrate the effectiveness of the proposed model. Acknowledgements T"
C18-1024,W09-1119,0,0.354005,"Missing"
C18-1024,D16-1144,0,0.650086,"e glue that holds our mental world together (Murphy, 2004). Types in KB are usually organized as a hierarchical structure, namely type hierarchy. Entity typing assigns types (e.g., Person, Athlete, BasketballPlayer) to an entity (e.g., Yao Ming) in KB, and is a fundamental task in knowledge base construction. Traditional entity typing focuses on a small set of types, such as Person, Location and Organization (Ratinov and Roth, 2009; Nadeau and Sekine, 2007), while fine-grained entity typing assigns more specific types to an entity, which normally forms a type-path in the type hierarchy in KB (Ren et al., 2016a). As shown in Fig. 1, Yao Ming is associated with a type-path /Thing/Agent/Person/Athlete/BasketballPlayer. Fine-grained types (e.g., Athlete and BasketballPlayer) are more informative than coarse-grained types (e.g., Person), because they provide more specific semantic information about the entity (Xu et al., 2016). Characterizing an entity with fine-grained types (type-paths) benefits many real applications, such as knowledge base completion (Dong et al., 2014), entity linking (Ling et al., 2015; Durrett and Klein, 2014), relation extraction (Liu et al., 2014), and question answering (Yahy"
C18-1024,E17-1119,0,0.0115347,"model. A global model that scores based on aggregated context information and a context model that aggregates the scores of individual contexts (Yaghoobzadeh et al., 2017). Fine-grained entity typing in text is related to our task. Different from the works mentioned above, it 290 seeks to detect local types of an entity mention inside an individual sentence, and the same entity could have different types in different sentences (Ling and Weld, 2012; Yosef et al., 2012; Gillick et al., 2014; Dong et al., 2015; Del Corro et al., 2015; Yogatama et al., 2015; Ren et al., 2016b; Ren et al., 2016a; Shimaoka et al., 2017; Rabinovich and Dan, 2017). 6 Conclusion In this paper, we propose an attributed and predictive entity embedding method to address the task of fine-grained entity typing in KB. It combines the advantages of attributed network embedding method and semi-supervised learning. Specifically, it employs a deep neural network architecture to integrate structure and attribute information of an entity. We jointly predict a labeled entity’s neighbors and types, and model the structure of type hierarchy in a margin-based way. Experiments on real world datasets demonstrate the effectiveness of the propose"
C18-1024,D15-1083,0,0.333481,"Missing"
C18-1024,E17-1055,0,0.0649728,"Missing"
C18-1024,P15-2048,0,0.0442802,"ing based method which combines a global model with a context model. A global model that scores based on aggregated context information and a context model that aggregates the scores of individual contexts (Yaghoobzadeh et al., 2017). Fine-grained entity typing in text is related to our task. Different from the works mentioned above, it 290 seeks to detect local types of an entity mention inside an individual sentence, and the same entity could have different types in different sentences (Ling and Weld, 2012; Yosef et al., 2012; Gillick et al., 2014; Dong et al., 2015; Del Corro et al., 2015; Yogatama et al., 2015; Ren et al., 2016b; Ren et al., 2016a; Shimaoka et al., 2017; Rabinovich and Dan, 2017). 6 Conclusion In this paper, we propose an attributed and predictive entity embedding method to address the task of fine-grained entity typing in KB. It combines the advantages of attributed network embedding method and semi-supervised learning. Specifically, it employs a deep neural network architecture to integrate structure and attribute information of an entity. We jointly predict a labeled entity’s neighbors and types, and model the structure of type hierarchy in a margin-based way. Experiments on rea"
C18-1024,C12-2133,0,0.294177,"0.643 0.653 0.518 0.683 0.681 0.525 0.678 0.673 Stru+T+P+C 0.492 0.649 0.657 0.531 0.694 0.689 0.545 0.702 0.711 Table 4: Type macro average F1 on test for all, frequent and infrequent types, #training/test means the average entity number for each type. Type infrequent frequent all Figure 3: Performance on different labeled data proportion. 4.3.3 # training 1013 13,513 8,673 # test 417 5,217 3,462 FIGMENT 0.327 0.620 0.557 MuLR 0.374 0.718 0.636 Corpus 0.447 0.783 0.675 CUTE 0.418 0.730 0.652 APE 0.461 0.792 0.681 Results of Frequent/Infrequent Types We use type macro average F1 proposed by (Yosef et al., 2012) to evaluate the performance on frequent types and infrequent types. Note that it is different from Ma-F1 reported in Table 2. The results for infrequent types (occur less than 2,000 times) and frequent types (occur more than 10,000 times) are shown in Table 4. Generally, the performance on infrequent types is worse than frequent ones. Our model consistently outperforms the other methods on infrequent types, which demonstrates its ability on dealing with rare types. 5 Related Work Fine-grained entity typing in KB is an important sub-task of knowledge base completion. One way to address this pr"
C18-1057,P17-1149,1,0.665717,"h Convolution Decoder Figure 2: Framework of NCEL. The inputs of a set of mentions in a document are listed in the left side. The words in red indicate the current mention mi , where mi−1 , mi+1 are neighbor mentions, and Φ(mi ) = {ei1 , ei2 , ei3 } denotes the candidate entity set for mi . 3 Feature Extraction The main goal of NCEL is to find a solution for collective entity linking using an end-to-end neural model, rather than to improve the measurements of local textual similarity or global mention/entity relatedness. Therefore, we use joint embeddings of words and entities at sense level (Cao et al., 2017) to represent mentions and its contexts for feature extraction. In this section, we give a brief description of our embeddings followed by our features used in the neural model. 3.1 Learning Joint Embeddings of Word and Entity Following (Cao et al., 2017), we use Wikipedia articles, hyperlinks, and entity outlinks to jointly learn word/mention and entity embeddings in a unified vector space, so that similar words/mentions and entities have similar vectors. To address the ambiguity of words/mentions, (Cao et al., 2017) represents each word/mention with multiple vectors, and each vector denotes"
C18-1057,C12-1028,0,0.0206839,"vance between candidates and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Co"
C18-1057,D11-1071,0,0.0225205,"main phases: (i) candidate generation obtains a set of referent entities in KB for each mention, and (ii) named entity disambiguation selects the possible candidate entity by solving a ranking problem. The key challenge lies in the ranking model that computes the relevance between candidates and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semant"
C18-1057,D13-1184,0,0.041381,"onding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Corresponding author. This work is license"
C18-1057,Q15-1011,0,0.221198,"andidate generation obtains a set of referent entities in KB for each mention, and (ii) named entity disambiguation selects the possible candidate entity by solving a ranking problem. The key challenge lies in the ranking model that computes the relevance between candidates and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity re"
C18-1057,Q14-1037,0,0.0266306,"on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Corresponding author. This work is licensed under a Creative Common"
C18-1057,K17-1008,0,0.148188,"global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Corresponding author. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 675 Proceedings of the 27th International Conference on Computational Linguistics, pages 675–686 Santa Fe, New Mexico, USA, August 20-26, 2018. information of consistent topic “cricket” among adjacent mentions England, Hussain, and Essex. Although the gl"
C18-1057,D17-1277,0,0.755279,"(Yamada et al., 2017; Gupta et al., 2017) or merely use word/entity embeddings for feature extraction and rely on another modules for collective disambiguation, which thus cannot fully utilize the power of NN models for collective EL (Globerson et al., 2016; Guo and Barbosa, 2017; Phan et al., 2018). The second drawback of the global approach has been alleviated through approximate optimization techniques, such as PageRank/random walks (Pershina et al., 2015), graph pruning (Hoffart et al., 2011), ranking SVMs (Ratinov et al., 2011), or loopy belief propagation (LBP) (Globerson et al., 2016; Ganea and Hofmann, 2017). However, these methods are not differentiable and thus difficult to be integrated into neural network models (the solution for the first limitation). To overcome the third issue of inadequate training data, (Gupta et al., 2017) has explored a massive amount of hyperlinks in Wikipedia, but these potential annotations for EL contain much noise, which may distract a naive disambiguation model (Chisholm and Hachey, 2015). In this paper, we propose a novel Neural Collective Entity Linking model (NCEL), which performs global EL combining deep neural networks with Graph Convolutional Network (GCN)"
C18-1057,D17-1284,0,0.0530058,"EL training data is usually expensive to obtain or only available in narrow domains, which results in possible overfitting issue or domain bias. To mitigate the first limitation, recent EL studies introduce neural network (NN) models due to its amazing feature abstraction and generalization ability. In such models, words/entities are represented by low dimensional vectors in a continuous space, and features for mention as well as candidate entities are automatically learned from data (Nguyen et al., 2016). However, existing NN-based methods for EL are either local models (Yamada et al., 2017; Gupta et al., 2017) or merely use word/entity embeddings for feature extraction and rely on another modules for collective disambiguation, which thus cannot fully utilize the power of NN models for collective EL (Globerson et al., 2016; Guo and Barbosa, 2017; Phan et al., 2018). The second drawback of the global approach has been alleviated through approximate optimization techniques, such as PageRank/random walks (Pershina et al., 2015), graph pruning (Hoffart et al., 2011), ranking SVMs (Ratinov et al., 2011), or loopy belief propagation (LBP) (Globerson et al., 2016; Ganea and Hofmann, 2017). However, these m"
C18-1057,P13-2006,0,0.333159,"es and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Corresponding autho"
C18-1057,D13-1041,0,0.123394,"es and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Corresponding autho"
C18-1057,D11-1072,0,0.747804,"Missing"
C18-1057,P14-1036,0,0.0173926,"n texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local model (Eshel et al., 2017). For example (Figure 1), an EL model seemly cannot find sufficient disambiguation clues for the mention England from its surrounding words, unless it utilizes the coherence ∗ Corresponding author. This work is licensed under a Creative Commons Attribution 4.0 Int"
C18-1057,Q15-1036,0,0.0368524,"a set of referent entities in KB for each mention, and (ii) named entity disambiguation selects the possible candidate entity by solving a ranking problem. The key challenge lies in the ranking model that computes the relevance between candidates and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are"
C18-1057,Q14-1019,0,0.0258057,"inks, respectively, and NTEE (Yamada et al., 2017) achieves the best performance based on joint embeddings of words and entities. 2. Iterative model: AIDA (Hoffart et al., 2011) links entities by iteratively finding a dense subgraph. 3. Loopy Belief Propagation: Globerson (Globerson et al., 2016) and PBoH (Ganea et al., 2016) introduce LBP (Murphy et al., 1999) techniques for collective inference, and Ganea (Ganea and Hofmann, 2017) solves the global training problem via truncated fitting LBP. 4. PageRank/Random Walk: Boosting (Kulkarni et al., 2009), AGDISTISG (Usbeck et al., 2014), Babelfy (Moro et al., 2014), WAT (Piccinno and Ferragina, 2014), xLisa (Zhang and Rettinger, 2014) and WNED (Guo and Barbosa, 2017) performs PageRank (Page et al., 1999) or random walk (Tong et al., 2006) on the mention-entity graph and use the convergence score for disambiguation. 3 Our codes can be found in https://github.com/TaoMiner/NCEL 681 For fairly comparison, we report the original scores of the baselines in the papers. Following these methods, we evaluate NCEL on the following five datasets: (1) CoNLL-YAGO (Hoffart et al., 2011): the CoNLL 2003 shared task including testa of 4791 mentions in 216 documents, and"
C18-1057,N15-1026,0,0.31709,"ion as well as candidate entities are automatically learned from data (Nguyen et al., 2016). However, existing NN-based methods for EL are either local models (Yamada et al., 2017; Gupta et al., 2017) or merely use word/entity embeddings for feature extraction and rely on another modules for collective disambiguation, which thus cannot fully utilize the power of NN models for collective EL (Globerson et al., 2016; Guo and Barbosa, 2017; Phan et al., 2018). The second drawback of the global approach has been alleviated through approximate optimization techniques, such as PageRank/random walks (Pershina et al., 2015), graph pruning (Hoffart et al., 2011), ranking SVMs (Ratinov et al., 2011), or loopy belief propagation (LBP) (Globerson et al., 2016; Ganea and Hofmann, 2017). However, these methods are not differentiable and thus difficult to be integrated into neural network models (the solution for the first limitation). To overcome the third issue of inadequate training data, (Gupta et al., 2017) has explored a massive amount of hyperlinks in Wikipedia, but these potential annotations for EL contain much noise, which may distract a naive disambiguation model (Chisholm and Hachey, 2015). In this paper, w"
C18-1057,P11-1138,0,0.445414,"n et al., 2016). However, existing NN-based methods for EL are either local models (Yamada et al., 2017; Gupta et al., 2017) or merely use word/entity embeddings for feature extraction and rely on another modules for collective disambiguation, which thus cannot fully utilize the power of NN models for collective EL (Globerson et al., 2016; Guo and Barbosa, 2017; Phan et al., 2018). The second drawback of the global approach has been alleviated through approximate optimization techniques, such as PageRank/random walks (Pershina et al., 2015), graph pruning (Hoffart et al., 2011), ranking SVMs (Ratinov et al., 2011), or loopy belief propagation (LBP) (Globerson et al., 2016; Ganea and Hofmann, 2017). However, these methods are not differentiable and thus difficult to be integrated into neural network models (the solution for the first limitation). To overcome the third issue of inadequate training data, (Gupta et al., 2017) has explored a massive amount of hyperlinks in Wikipedia, but these potential annotations for EL contain much noise, which may distract a naive disambiguation model (Chisholm and Hachey, 2015). In this paper, we propose a novel Neural Collective Entity Linking model (NCEL), which perf"
C18-1057,spitkovsky-chang-2012-cross,0,0.0303845,"linking system outputs NIL for a mention when no assignment score is higher than a threshold. This is application-specific and thus outside of the scope of this work. 677 2.1 Candidate Generation Similar to previous work (Ganea and Hofmann, 2017), we use the prior probability pˆ(ei |mj ) of entity ei conditioned on mention mj both as a local feature and to generate candidate entities: Φ(mj ) = {ei |ˆ p(ei |mj ) > 0}. We compute pˆ(·) based on statistics of mention-entity pairs from: (i) Wikipedia page titles, redirect titles and hyperlinks, (ii) the dictionary derived from a large Web Corpus (Spitkovsky and Chang, 2012), and (iii) the YAGO dictionary with a uniform distribution (Hoffart et al., 2011). We pick up the maximal prior if a mention-entity pair occurs in different resources. In experiments, to optimize for memory and run time, we keep only top n entities based on pˆ(ei |mj ). In the following two sections, we will present the key components of NECL, namely feature extraction and neural network for collective entity linking. … yorkshire m i 1 … Hussain, considered mi surplus to England’s one-day requirements , struck 158, his first championshi p century of the season, m i+1 as Essex reached… surrey"
C18-1057,K16-1025,0,0.146034,"ntities in KB for each mention, and (ii) named entity disambiguation selects the possible candidate entity by solving a ranking problem. The key challenge lies in the ranking model that computes the relevance between candidates and the corresponding mentions based on the information both in texts and KBs (Nguyen et al., 2016). In terms of the features used for ranking, we classify existing EL models into two groups: local models to resolve mentions independently relying on textual context information from the surrounding words (Chen and Ji, 2011; Chisholm and Hachey, 2015; Lazic et al., 2015; Yamada et al., 2016), and global (collective) models, which are the main focus of this paper, that encourage the target entities of all mentions in a document to be topically coherent (Han et al., 2011; Cassidy et al., 2012; He et al., 2013b; Cheng and Roth, 2013; Durrett and Klein, 2014; Huang et al., 2014). Global models usually build an entity graph based on KBs to capture coherent entities for all identified mentions in a document, where the nodes are entities, and edges denote their relations. The graph provides highly discriminative semantic signals (e.g., entity relatedness) that are unavailable to local m"
C18-1057,Q17-1028,0,0.462228,"ts. 3. The annotated EL training data is usually expensive to obtain or only available in narrow domains, which results in possible overfitting issue or domain bias. To mitigate the first limitation, recent EL studies introduce neural network (NN) models due to its amazing feature abstraction and generalization ability. In such models, words/entities are represented by low dimensional vectors in a continuous space, and features for mention as well as candidate entities are automatically learned from data (Nguyen et al., 2016). However, existing NN-based methods for EL are either local models (Yamada et al., 2017; Gupta et al., 2017) or merely use word/entity embeddings for feature extraction and rely on another modules for collective disambiguation, which thus cannot fully utilize the power of NN models for collective EL (Globerson et al., 2016; Guo and Barbosa, 2017; Phan et al., 2018). The second drawback of the global approach has been alleviated through approximate optimization techniques, such as PageRank/random walks (Pershina et al., 2015), graph pruning (Hoffart et al., 2011), ranking SVMs (Ratinov et al., 2011), or loopy belief propagation (LBP) (Globerson et al., 2016; Ganea and Hofmann, 20"
D15-1077,D11-1072,0,\N,Missing
D15-1077,C10-1032,0,\N,Missing
D15-1077,E06-1002,0,\N,Missing
D15-1077,D09-1025,0,\N,Missing
D15-1077,P13-1024,1,\N,Missing
D15-1077,P11-1138,0,\N,Missing
D15-1077,C12-1028,1,\N,Missing
D15-1077,P13-1128,0,\N,Missing
D15-1077,D07-1074,0,\N,Missing
D15-1077,D11-1011,0,\N,Missing
D15-1077,D11-1071,1,\N,Missing
D15-1077,I11-1113,0,\N,Missing
D15-1091,E12-1021,0,0.0409975,"Missing"
D15-1091,D09-1026,0,0.173322,"Missing"
D15-1091,W09-0210,0,0.663536,"med and Xing, 2008)) or external resources (e.g., table of contents at Wikipedia event pages 1 ). Similarly, in academic fields, “call for papers (CFP)” of conferences 2 lists main topics that conference organizers would like to focus on. Clearly, these prior topics can be represented as sets of words, which are available in many real-world applications. They can serve as weakly supervised information to enhance the unsupervised DPMM for text clustering. Standard DPMM (Neal, 2000; Ranganathan, 2006) lacks a mechanism for incorporating prior knowledge. Some existing work (Vlachos et al., 2008; Vlachos et al., 2009) added knowledge of observed instance-level constraints (must-links and cannot-links between documents) to DPMM. (Ahmed and Xing, 2008) proposed recurrent Chinese Restaurant Process to incorporate previous documents with known topic clusters. We focus on incorporating topic-level knowledge, which is more challenging, as seed/prior topics could be latent rather than observable. Particularly, we construct our novel TSDPMM (Topic Seeded DPMM) based on a principled seeded P´olya urn (sPU) scheme. Our model inherits the nonparametric property of DPMM and has additional technical merits. Importantly"
D18-1021,P17-1019,0,0.0307064,"ness, and cross-lingual entity linking. The results, both qualitatively and quantitatively, demonstrate the signiﬁcance of our method. 1 Introduction Multi-lingual knowledge bases (KB) store millions of entities and facts in various languages, and provide rich background structural knowledge for understanding texts. On the other hand, text corpus contains huge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics m"
D18-1021,P14-1006,0,0.0192455,"gual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetx"
D18-1021,P17-1042,0,0.0188047,", 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetxe et al. (2017) starts from a small bilingual lexicon and using a self-learning approach to induce the structural similarity of embedding spaces. Vulic and Moens (2015, 2016) collect comparable documents on same themes from multi-lingual Wikipedia, shufﬂe and merge them to build “pseudo bilingual documents” as training corpora. However, the quality of “pseudo bilingual documents” are difﬁcult to control, resulting in poor performance in several cross-lingual tasks (Vulic and Moens, 2016). Another remedy matches linguistic distribu• We proposed a novel method that jointly learns representations of not only cr"
D18-1021,W16-1614,0,0.0760808,"ation in different languages. For instance, two different meanings of word center in English are expressed by two different words in Chinese: center as the activity-specific building is expressed by 中心, center as the basketball player role is 中 锋. Our main challenge is the limited availability of parallel corpus, which is usually either expensive to obtain, or only available for certain narrow domains (Gouws et al., 2015). Many work has been done to alleviate the problem. One school of methods uses adversarial technique or domain adaption to match linguistic distribution (Zhang et al., 2017b; Barone, 2016; Cao et al., 2016). These methods do not require parallel corpora. The weakness is that the training process is unstable and that the high complexity restricts the methods only to small-scale data. Another line of work uses pre-existing multi-lingual resources to automatically generate “pseudo bilingual documents” (Vulic and Moens, 2015, 2016). However, negative results have been observed due to the occasional poor quality of training data (Vulic and Moens, 2016). All above methods only focus on words. We consider both words and entities, which Joint representation learning of words and entit"
D18-1021,D11-1072,0,0.345336,"Missing"
D18-1021,N15-1059,0,0.0262499,"and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetxe et al. (2017) starts from a small bilingual lexicon and using a self-learning approach to induce the structural similarity of embedding spaces. Vulic and Moens (2015, 2016) collect comparable documents on same themes from multi-lingual Wikipedia, shufﬂe and merge them to build “pseudo bilingual documents” as training corpora. However, the quality of “pseudo bilingual documents” are difﬁcult to control, resulting in po"
D18-1021,P11-1055,0,0.0450081,"ing (Barone, 2016; Zhang et al., 2017b; Lample et al., 2018), domain adaption (Cao et al., 2016). However, these methods suffer from the instability of training process and the high complexity. This either limits the scalability of vocabulary size or relies on a strong distribution assumption. Inspired by Vulic and Moens (2016), we generate highly qualiﬁed comparable sentences via distant supervision, which is one of the most promising approaches to addressing the issue of sparse training data, and performs well in relation extraction (Lin et al., 2017a; Mintz et al., 2009; Zeng et al., 2015; Hoffmann et al., 2011; Surdeanu et al., 2012). Our comparable sentences may further beneﬁt many other cross-lingual analysis, such as information retrieval (Dong et al., 2014). We use multi-lingual Wikipedia as KB including a set of entities E y = {eyi } and their articles. We concatenate these articles together, and form y ⟩. Hytext corpus Dy = ⟨w1y , . . . , wiy , . . . , w|D| per links in articles are denoted by Anchors Ay = {⟨wiy , eyj ⟩}, which indicates that word wiy refers to entity eyj . G y = (E y , Ry ) is the mono-lingual Entity Network (EN), where Ry = {⟨eyi , eyj ⟩} if there is a link between eyi , ey"
D18-1021,C16-1171,0,0.142029,"rent languages. For instance, two different meanings of word center in English are expressed by two different words in Chinese: center as the activity-specific building is expressed by 中心, center as the basketball player role is 中 锋. Our main challenge is the limited availability of parallel corpus, which is usually either expensive to obtain, or only available for certain narrow domains (Gouws et al., 2015). Many work has been done to alleviate the problem. One school of methods uses adversarial technique or domain adaption to match linguistic distribution (Zhang et al., 2017b; Barone, 2016; Cao et al., 2016). These methods do not require parallel corpora. The weakness is that the training process is unstable and that the high complexity restricts the methods only to small-scale data. Another line of work uses pre-existing multi-lingual resources to automatically generate “pseudo bilingual documents” (Vulic and Moens, 2015, 2016). However, negative results have been observed due to the occasional poor quality of training data (Vulic and Moens, 2016). All above methods only focus on words. We consider both words and entities, which Joint representation learning of words and entities beneﬁts many NL"
D18-1021,C18-1057,1,0.732516,"on mechanisms, knowledge attention and cross-lingual attention, to select informative data in comparable sentences. Our contributions can be concluded as follows: • We did qualitative analysis to have an intuitive impression of our embeddings, and quantitative analysis in three tasks: word translation, entity relatedness, and crosslingual entity linking. Experiment results show that our method demonstrates signiﬁcant improvements in all three tasks. 2 Related Work Jointly representation learning of words and entities attracts much attention in the ﬁelds of Entity Linking (Zhang et al., 2017a; Cao et al., 2018), Relation Extraction (Weston et al., 2013b) and so on, yet little work focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as"
D18-1021,P17-1149,1,0.0940722,"guages, and provide rich background structural knowledge for understanding texts. On the other hand, text corpus contains huge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics makes the parallel data issue more challenging. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. The basic idea is to capture mutually complementary knowledge in a shared seman"
D18-1021,D15-1077,1,0.905689,"Missing"
D18-1021,C12-1089,0,0.0596731,"t improvements in all three tasks. 2 Related Work Jointly representation learning of words and entities attracts much attention in the ﬁelds of Entity Linking (Zhang et al., 2017a; Cao et al., 2018), Relation Extraction (Weston et al., 2013b) and so on, yet little work focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel co"
D18-1021,P14-2037,0,0.0166923,"k focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra p"
D18-1021,C14-1192,0,0.0124692,"ing process and the high complexity. This either limits the scalability of vocabulary size or relies on a strong distribution assumption. Inspired by Vulic and Moens (2016), we generate highly qualiﬁed comparable sentences via distant supervision, which is one of the most promising approaches to addressing the issue of sparse training data, and performs well in relation extraction (Lin et al., 2017a; Mintz et al., 2009; Zeng et al., 2015; Hoffmann et al., 2011; Surdeanu et al., 2012). Our comparable sentences may further beneﬁt many other cross-lingual analysis, such as information retrieval (Dong et al., 2014). We use multi-lingual Wikipedia as KB including a set of entities E y = {eyi } and their articles. We concatenate these articles together, and form y ⟩. Hytext corpus Dy = ⟨w1y , . . . , wiy , . . . , w|D| per links in articles are denoted by Anchors Ay = {⟨wiy , eyj ⟩}, which indicates that word wiy refers to entity eyj . G y = (E y , Ry ) is the mono-lingual Entity Network (EN), where Ry = {⟨eyi , eyj ⟩} if there is a link between eyi , eyj . We use interlanguage links in Wikipedia as cross-lingual links en zh zh Ren−zh = {⟨een i , ei′ ⟩}, indicating ei , ei′ refer to the same thing in Engl"
D18-1021,E14-1049,0,0.0294359,"s requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetxe et al. (2017) starts from a small bilingual lexicon and using a self-learning approach to induce the structural similarity of embedding spaces. Vulic and Moens (2015, 2016) collect comparable documents on"
D18-1021,P17-1004,1,0.0472832,"lines are cross-lingual links. tion via adversarial training (Barone, 2016; Zhang et al., 2017b; Lample et al., 2018), domain adaption (Cao et al., 2016). However, these methods suffer from the instability of training process and the high complexity. This either limits the scalability of vocabulary size or relies on a strong distribution assumption. Inspired by Vulic and Moens (2016), we generate highly qualiﬁed comparable sentences via distant supervision, which is one of the most promising approaches to addressing the issue of sparse training data, and performs well in relation extraction (Lin et al., 2017a; Mintz et al., 2009; Zeng et al., 2015; Hoffmann et al., 2011; Surdeanu et al., 2012). Our comparable sentences may further beneﬁt many other cross-lingual analysis, such as information retrieval (Dong et al., 2014). We use multi-lingual Wikipedia as KB including a set of entities E y = {eyi } and their articles. We concatenate these articles together, and form y ⟩. Hytext corpus Dy = ⟨w1y , . . . , wiy , . . . , w|D| per links in articles are denoted by Anchors Ay = {⟨wiy , eyj ⟩}, which indicates that word wiy refers to entity eyj . G y = (E y , Ry ) is the mono-lingual Entity Network (EN)"
D18-1021,D17-1277,0,0.0700897,"Missing"
D18-1021,W15-1521,0,0.0215281,"presentation learning of words and entities attracts much attention in the ﬁelds of Entity Linking (Zhang et al., 2017a; Cao et al., 2018), Relation Extraction (Weston et al., 2013b) and so on, yet little work focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual reso"
D18-1021,P17-1021,0,0.0296582,"ingual entity linking. The results, both qualitatively and quantitatively, demonstrate the signiﬁcance of our method. 1 Introduction Multi-lingual knowledge bases (KB) store millions of entities and facts in various languages, and provide rich background structural knowledge for understanding texts. On the other hand, text corpus contains huge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics makes the parallel d"
D18-1021,D13-1136,0,0.144022,"ross-lingual attention, to select informative data in comparable sentences. Our contributions can be concluded as follows: • We did qualitative analysis to have an intuitive impression of our embeddings, and quantitative analysis in three tasks: word translation, entity relatedness, and crosslingual entity linking. Experiment results show that our method demonstrates signiﬁcant improvements in all three tasks. 2 Related Work Jointly representation learning of words and entities attracts much attention in the ﬁelds of Entity Linking (Zhang et al., 2017a; Cao et al., 2018), Relation Extraction (Weston et al., 2013b) and so on, yet little work focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual"
D18-1021,D14-1015,0,0.0152179,"d Work Jointly representation learning of words and entities attracts much attention in the ﬁelds of Entity Linking (Zhang et al., 2017a; Cao et al., 2018), Relation Extraction (Weston et al., 2013b) and so on, yet little work focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existin"
D18-1021,P09-1113,0,0.0343801,"ngual links. tion via adversarial training (Barone, 2016; Zhang et al., 2017b; Lample et al., 2018), domain adaption (Cao et al., 2016). However, these methods suffer from the instability of training process and the high complexity. This either limits the scalability of vocabulary size or relies on a strong distribution assumption. Inspired by Vulic and Moens (2016), we generate highly qualiﬁed comparable sentences via distant supervision, which is one of the most promising approaches to addressing the issue of sparse training data, and performs well in relation extraction (Lin et al., 2017a; Mintz et al., 2009; Zeng et al., 2015; Hoffmann et al., 2011; Surdeanu et al., 2012). Our comparable sentences may further beneﬁt many other cross-lingual analysis, such as information retrieval (Dong et al., 2014). We use multi-lingual Wikipedia as KB including a set of entities E y = {eyi } and their articles. We concatenate these articles together, and form y ⟩. Hytext corpus Dy = ⟨w1y , . . . , wiy , . . . , w|D| per links in articles are denoted by Anchors Ay = {⟨wiy , eyj ⟩}, which indicates that word wiy refers to entity eyj . G y = (E y , Ry ) is the mono-lingual Entity Network (EN), where Ry = {⟨eyi ,"
D18-1021,N16-1083,0,0.0126709,"word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetxe et al. (2017) starts from a small bilingual lexicon and using a self-"
D18-1021,W14-1613,0,0.0240869,"pus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetxe et al. (2017) starts from a small bilingual lexicon and using a self-learning approach to induce the structural similarity of embedding spaces. Vulic and Moens (2015, 2016) collect comparable documents on same themes from mult"
D18-1021,K16-1025,0,0.105095,"d facts in various languages, and provide rich background structural knowledge for understanding texts. On the other hand, text corpus contains huge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics makes the parallel data issue more challenging. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. The basic idea is to capture mutually complementary knowledg"
D18-1021,Q17-1028,0,0.154248,"nces are not translated paired sentences, but sentences with the same topic in different languages. As shown in the middle layer (Figure 1), the pair of sentences are comparable sentences: (1) “Lawrence Michael Foust was an American basketball player who spent 12 seasons in NBA”, (2) “拉里·福斯特 (Lawrence Foust) 是 (was) 美国 (American) NBA 联盟 (association) 的 (of) 前 (former) 职业 (professional) 篮球 (basketball) 运动员 (player)”. Inspired by the distant supervision technique in relation extraction, we assume that sentence en sen k in Wikipedia articles of entity ei explicitly en or implicitly describes ei (Yamada et al., 2017), en and that sen k shall express a relation between ei en en en and ej if another entity ej is in sk . Meanwhile, we ﬁnd a comparable sentence szh k′ in another language which satisﬁes szh containing ezh k′ j′ Cross-lingual Supervision Data Generation This section introduces how to build a bilingual entity network G en−zh and comparable sentences S en−zh from a multi-lingual KB. 230 where xyi is either a word or an entity, and C(xyi ) denotes: (i) contextual words in a pre-deﬁned window of xyi if xyi ∈ Dy , (ii) neighbor entities that linked to xyi if xyi ∈ G y , (iii) contextual words of wjy"
D18-1021,P15-2093,1,0.857664,"sk of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy is to use existing multi-lingual resources (i.e. multilingual KB). Camacho-Collados et al. (2015) combines several KBs (Wikipedia, WordNet and BabelNet) and leverages multi-lingual synsets to learn word embeddings at sense level through an extra post-processing step. Artetxe et al. (2017) starts from a small bili"
D18-1021,P17-1132,0,0.0240495,"three tasks: word translation, entity relatedness, and cross-lingual entity linking. The results, both qualitatively and quantitatively, demonstrate the signiﬁcance of our method. 1 Introduction Multi-lingual knowledge bases (KB) store millions of entities and facts in various languages, and provide rich background structural knowledge for understanding texts. On the other hand, text corpus contains huge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Associ"
D18-1021,D15-1203,0,0.0622039,"a adversarial training (Barone, 2016; Zhang et al., 2017b; Lample et al., 2018), domain adaption (Cao et al., 2016). However, these methods suffer from the instability of training process and the high complexity. This either limits the scalability of vocabulary size or relies on a strong distribution assumption. Inspired by Vulic and Moens (2016), we generate highly qualiﬁed comparable sentences via distant supervision, which is one of the most promising approaches to addressing the issue of sparse training data, and performs well in relation extraction (Lin et al., 2017a; Mintz et al., 2009; Zeng et al., 2015; Hoffmann et al., 2011; Surdeanu et al., 2012). Our comparable sentences may further beneﬁt many other cross-lingual analysis, such as information retrieval (Dong et al., 2014). We use multi-lingual Wikipedia as KB including a set of entities E y = {eyi } and their articles. We concatenate these articles together, and form y ⟩. Hytext corpus Dy = ⟨w1y , . . . , wiy , . . . , w|D| per links in articles are denoted by Anchors Ay = {⟨wiy , eyj ⟩}, which indicates that word wiy refers to entity eyj . G y = (E y , Ry ) is the mono-lingual Entity Network (EN), where Ry = {⟨eyi , eyj ⟩} if there is"
D18-1021,D12-1042,0,0.0208627,"g et al., 2017b; Lample et al., 2018), domain adaption (Cao et al., 2016). However, these methods suffer from the instability of training process and the high complexity. This either limits the scalability of vocabulary size or relies on a strong distribution assumption. Inspired by Vulic and Moens (2016), we generate highly qualiﬁed comparable sentences via distant supervision, which is one of the most promising approaches to addressing the issue of sparse training data, and performs well in relation extraction (Lin et al., 2017a; Mintz et al., 2009; Zeng et al., 2015; Hoffmann et al., 2011; Surdeanu et al., 2012). Our comparable sentences may further beneﬁt many other cross-lingual analysis, such as information retrieval (Dong et al., 2014). We use multi-lingual Wikipedia as KB including a set of entities E y = {eyi } and their articles. We concatenate these articles together, and form y ⟩. Hytext corpus Dy = ⟨w1y , . . . , wiy , . . . , w|D| per links in articles are denoted by Anchors Ay = {⟨wiy , eyj ⟩}, which indicates that word wiy refers to entity eyj . G y = (E y , Ry ) is the mono-lingual Entity Network (EN), where Ry = {⟨eyi , eyj ⟩} if there is a link between eyi , eyj . We use interlanguage"
D18-1021,D15-1174,0,0.0359593,"ge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics makes the parallel data issue more challenging. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. The basic idea is to capture mutually complementary knowledge in a shared semantic space, which enables joint inference among cross-lingual knowledge base and texts without additional translations. We achieve"
D18-1021,P17-1179,0,0.0418929,"Missing"
D18-1021,P15-2118,0,0.0754233,"y either expensive to obtain, or only available for certain narrow domains (Gouws et al., 2015). Many work has been done to alleviate the problem. One school of methods uses adversarial technique or domain adaption to match linguistic distribution (Zhang et al., 2017b; Barone, 2016; Cao et al., 2016). These methods do not require parallel corpora. The weakness is that the training process is unstable and that the high complexity restricts the methods only to small-scale data. Another line of work uses pre-existing multi-lingual resources to automatically generate “pseudo bilingual documents” (Vulic and Moens, 2015, 2016). However, negative results have been observed due to the occasional poor quality of training data (Vulic and Moens, 2016). All above methods only focus on words. We consider both words and entities, which Joint representation learning of words and entities beneﬁts many NLP tasks, but has not been well explored in cross-lingual settings. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. It captures mutually complementary knowledge, and enables cross-lingual inferences among knowledge bases and texts. Our method does not requi"
D18-1021,N16-1156,0,0.0217522,"Missing"
D18-1021,D14-1167,0,0.100342,"lions of entities and facts in various languages, and provide rich background structural knowledge for understanding texts. On the other hand, text corpus contains huge amount of statistical information complementary to KBs. Many researchers leverage both types of resources to improve various natural language processing (NLP) tasks, such as machine reading (Yang and Mitchell, 2017), question answering (He et al., 2017; Hao et al., 2017). Most existing work jointly models KB and text corpus to enhance each other by learning word and entity representations in a uniﬁed vector space. For example, Wang et al. (2014); Yamada et al. (2016); Cao et al. (2017) utilize the co-occurrence information to align similar words and entities with similar embedding vectors. Toutanova et al. (2015); ∗ Corresponding author. 227 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 227–237 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics makes the parallel data issue more challenging. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. The basic idea is to capture mutually"
D18-1021,D13-1141,0,0.0258456,"ee tasks. 2 Related Work Jointly representation learning of words and entities attracts much attention in the ﬁelds of Entity Linking (Zhang et al., 2017a; Cao et al., 2018), Relation Extraction (Weston et al., 2013b) and so on, yet little work focuses on cross-lingual settings. Inspiringly, we investigate the task of crosslingual word embedding models (Ruder et al., 2017), and classify them into three groups according to parallel corpora used as supervisions: (i) methods requiring parallel corpus with aligned words as constraint for bilingual word embedding learning (Klementiev et al., 2012; Zou et al., 2013; Wu et al., 2014; Luong et al., 2015; Ammar et al., 2016; Soricut and Ding, 2016). (ii) methods using parallel sentences (i.e. translated sentence pairs) as the semantic composition of multi-lingual words (Gouws et al., 2015; Kociský et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2014; Shi et al., 2015; Mogadala and Rettinger, 2016). (iii) methods requiring bilingual lexicon to map words from one language into the other (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xiao and Guo, 2014). The major weakness of these methods is the limited availability of parallel corpora. One remedy"
D18-1222,P15-1067,0,0.143848,"asets can be obtained from https:// github.com/davidlvxin/TransC. 1 Bob Chris David Instances Knowledge graphs (KGs) aim at semantically representing the world’s truth in the form of machinereadable graphs composed of triple facts. Knowledge graph embedding encodes each element (entities and relations) in knowledge graph into a continuous low-dimensional vector space. The learned representations make the knowledge graph essentially computable and have been proved to be helpful for knowledge graph completion and information extraction (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b; Ji et al., 2015, 2016). corresponding author Associate Professor Assistant Professor Academic Staff Member Staff Member Concepts Figure 1: An example of concepts, instances, and isA transitivity. Introduction ∗ IsA Transitivity Professor In recent years, various knowledge graph embedding methods have been proposed, among which the translation-based models are simple and effective with good performances. Inspired by word2vec (Mikolov et al., 2013), given a triple (h, r, t), TransE learns vector embeddings h, r and t which satisfy r ≈ t − h. Afterwards, TransH (Wang et al., 2014), TransR/CTransR (Lin et al., 2"
D18-1222,D15-1082,1,0.85985,"Missing"
D18-1222,N15-1118,0,0.0724923,"Missing"
D18-1222,P16-1219,0,0.0158387,"types of entities and relations at the same time. Each relation-entity pair (r, e) will have a mapping matrix Mre to map entity embedding into relation vector space. And the projected vectors could be defined as h⊥ = Mrh h and t⊥ = Mrt t. The loss function of TransD is fr (h, t) = ||h⊥ + r − t⊥ ||22 . (4) There are many other translation-based models in recent years. For example, TranSparse (Ji et al., 2016) simplifies TransR by enforcing the sparseness on the projection matrix, PTransE (Lin et al., 2015a) considers relation paths as translations between entities for representation learning, (Xiao et al., 2016a) proposes a manifold-based embedding principle (ManifoldE) for precise link prediction, TransF (Feng et al., 2016) regards relation as translation between head entity vector and tail entity vector with flexible magnitude, (Xiao et al., 2016b) proposes a new generative model TransG, and KG2E (He et al., 2015) uses Gaussian embedding to model the data uncertainty. All these models can be seen in (Wang et al.). 2.2 3 External Information Learning Models External information like textual information is significant for knowledge representation. TEKE (Wang and Li, 2016) uses external context infor"
D18-2024,P15-1067,0,0.573991,"nce and Technology, Beijing Normal University, Beijing, China Abstract knowledge embedding (KE) approaches have been proposed to embed both entities and relations in KGs into a continuous low-dimensional space, such as linear models (Bordes et al., 2011, 2012, 2014), latent factor models (Sutskever et al., 2009; Jenatton et al., 2012; Yang et al., 2015; Liu et al., 2017), neural models (Socher et al., 2013; Dong et al., 2014), matrix factorization models (Nickel et al., 2011, 2012, 2016; Trouillon et al., 2016), and translation models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015; Ji et al., 2015). These models have achieved great performance on benchmark datasets. However, there exist two main issues which may lead to difficulty in full utilization and further development. On the one hand, the existing implementations are scattered and unsystematic to some extent. For example, the interfaces of these model implementations are inconsistent with each other. On the other hand, these model implementations mainly focus on model validation and are often time-consuming, which makes it difficult to apply them for realworld applications. Hence, it becomes urgent to develop an efficient and eff"
D19-1274,C18-1057,1,0.815118,"nd its neighbors in two heterogeneous KGs (Dashed circles in the same color means prior alignments). Recently, many Knowledge Graphs (KGs) (e.g., DBpedia (Lehmann et al., 2015), YAGO (Rebele et al., 2016) and BabelNet (Navigli and Ponzetto, 2012)) have emerged to provide structural knowledge for different applications. These separately constructed KGs contain heterogeneous but complementary contents; thus integrating KGs from different sources or languages into a unified KG becomes essential to better benefit knowledgedriven applications, ranging from information extraction (Han et al., 2018; Cao et al., 2018) to question answering (Cui et al., 2017). Corresponding author New York (state) adjo Introduction ∗ locatedIn New York City Entity alignment aims at integrating complementary knowledge graphs (KGs) from different sources or languages, which may benefit many knowledge-driven applications. It is challenging due to the heterogeneity of KGs and limited seed alignments. In this paper, we propose a semi-supervised entity alignment method by joint Knowledge Embedding model and Cross-Graph model (KECG). It can make better use of seed alignments to propagate over the entire graphs with KG-based constr"
D19-1274,P15-1067,0,0.0359519,"pair (ei , ej ) ∈ S, where ei ∈ E1 , ej ∈ E2 , K2 is the number of negative samples, we choose K2 entities that are nearest to ej in E2 as the negative samples of ei , and vice versa for ej . After that, The goal of our knowledge embedding model is to model inner-graph relationships, making entities more distinguishable. Here, we use TransE (Bordes et al., 2013), which is one of the most representative translation-based methods, as our knowledge embedding model. It is worth mentioning that other advanced KG learning methods can also be applied to our knowledge embedding model such as TransD (Ji et al., 2015), which is left for future work as our main idea is to joint cross-graph embeddings and knowledge embeddings for entity alignment. Objective OK . Formally, given a relational triplet (eh , r, et ), TransE wants eh +r ' et . So it defines the score function f (eh , r, et ) = ||eh +r−et ||2 to measure the plausibility of (eh , r, et ), where ||· ||2 means 2-norm. Following TransE, we utilize a margin-based ranking loss function as the training objective of the knowledge embedding model, defined as: OK = X X (eh ,r,et )∈T (e0h ,r 0 ,e0t )∈T 0 [f (eh , r, et ) + γ2 −f (e0h , r0 , e0t )]+ (5) where"
D19-1274,D18-1032,0,0.691601,"ed models (Hao et al., 2016; Chen et al., 2017; Sun et al., 2017; Zhu et al., 2017; Sun et al., 2018; Chen et al., 2018) utilize existing KG representation learning methods to learn embeddings of entities and relations in different KGs, and then align them into a unified vector space. This type of method can not only preserve KG structures, but also implicitly complete KG with the missing links from existing knowledge. However, KG-based methods require a sufficient number of seed alignments, which is usually expensive to obtain. To alleviate the burden of seed alignments, graph-based methods (Wang et al., 2018) utilize Graph Convolutional Network (GCN) (Kipf and Welling, 2017) to enhance entity embeddings with their neighbors’ information, thus can make better use of seed alignments to propagate them over 2723 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2723–2732, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics the entire graph. However, GCN-based models are sensitive to structural differences of KGs (Vaswani et al., 2017) and may not perf"
D19-1334,N18-1165,0,0.0352096,"ng et al. (2018) predict new facts under a challenging setting where only one training triple for a given relation r is available, which can be seen as a one-shot scenario. Although these models are effective, they lack interpretability for their decisions. Multi-Hop Reasoning over KGs aims to learn symbolic inference rules from relational paths in G and has been formulated as sequential decision problems in recent years. DeepPath (Xiong et al., 2017) first applies RL to search reasoning paths in KGs for a given query, which inspires much later work (e.g., MINERVA (Das et al., 2018) and DIVA (Chen et al., 2018)). Because it is hard to train an RL model, ReinforceWalk (Shen et al., 2018) proposes to solve the reward sparsity problem using off-policy learning. MultiHop (Lin et al., 2018) further extends MINERVA with reward shaping and action dropout, achieveing the state-of-the-art performance. These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop reasoning over KGs, there are also some multi-hop QA methods in recent years. Yang et al. (2018) proposes a high quality dataset, which greatly promotes the develop"
D19-1334,P19-1259,0,0.0136091,"(Shen et al., 2018) proposes to solve the reward sparsity problem using off-policy learning. MultiHop (Lin et al., 2018) further extends MINERVA with reward shaping and action dropout, achieveing the state-of-the-art performance. These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop reasoning over KGs, there are also some multi-hop QA methods in recent years. Yang et al. (2018) proposes a high quality dataset, which greatly promotes the development of this field. After that, many methods like CogQA (Ding et al., 2019) and DFGN (Xiao et al., 2019) are also proposed. Meta-Learning tries to solve the problem of “fast adaptation on a new training task”. It has been proved to be very successful on few-shot task (Lake et al., 2015; Gu et al., 2018). Previous metalearning models mainly focus on computer vision and imitation learning domains. In this paper, we propose a new model (Meta-KGR) using the metalearning algorithm MAML (Finn et al., 2017) for 3377 rLra ✓ Meta-Learning Algorithm 1 Meta-Learning for multi-hop reasoning over knowledge graphs &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; Fast Adaptation &lt;lat"
D19-1334,D18-1398,0,0.0413263,"These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop reasoning over KGs, there are also some multi-hop QA methods in recent years. Yang et al. (2018) proposes a high quality dataset, which greatly promotes the development of this field. After that, many methods like CogQA (Ding et al., 2019) and DFGN (Xiao et al., 2019) are also proposed. Meta-Learning tries to solve the problem of “fast adaptation on a new training task”. It has been proved to be very successful on few-shot task (Lake et al., 2015; Gu et al., 2018). Previous metalearning models mainly focus on computer vision and imitation learning domains. In this paper, we propose a new model (Meta-KGR) using the metalearning algorithm MAML (Finn et al., 2017) for 3377 rLra ✓ Meta-Learning Algorithm 1 Meta-Learning for multi-hop reasoning over knowledge graphs &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; Fast Adaptation &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; &lt;latexit rLrb &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; ✓ r3 &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; rLrc &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; ✓⇤ &lt;latexit sha1_base"
D19-1334,D18-1514,1,0.731523,"ing methods, which leverage the symbolic compositionality of relations in KGs to achieve explainable reasoning results. For example, when queried with (Mark Twain, nationality, ?), multi-hop reasoning models can give not only the target entity America but also multi-hop explainable paths (Mark Twain, bornIn, Florida) ∧ (Florida, locatedIn, America) as well. Most previous work assumes that there are enough triples to train an effective and robust reasoning models for each relation in KGs. However, as shown in Figure 1, a large portion of KG relations are actually long-tail (Xiong et al., 2018; Han et al., 2018) and only contain few triples, which can be called few-shot relations. Some pilot experiments show that the performance of 3376 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3376–3381, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics previous multi-hop reasoning models, e.g., MINERVA (Das et al., 2018) and MultiHop (Lin et al., 2018), on these few-shot relations will drop significantly. Note that, there are some knowledge graph embeddin"
D19-1334,D18-1362,0,0.357769,"me knowledge graph embedding methods (Bordes et al., 2013; Corresponding Author 0 2000 4000 6000 Relation frequency 8000 10000 Figure 1: The histogram of relation frequency in the real-world knowledge graph Wikidata. Introduction ∗ 400 Dettmers et al., 2018) have been proposed to embed entities and relations into semantic spaces to capture inner connections, and then use the learned embeddings for final predictions. Although these embedding-based methods have shown strong abilities in predicting target entities for queries, they only give answers and lack interpretability for their decisions (Lin et al., 2018). In order to make models more intuitive, Das et al. (2018) and Lin et al. (2018) propose multi-hop reasoning methods, which leverage the symbolic compositionality of relations in KGs to achieve explainable reasoning results. For example, when queried with (Mark Twain, nationality, ?), multi-hop reasoning models can give not only the target entity America but also multi-hop explainable paths (Mark Twain, bornIn, Florida) ∧ (Florida, locatedIn, America) as well. Most previous work assumes that there are enough triples to train an effective and robust reasoning models for each relation in KGs. H"
D19-1334,D15-1174,0,0.0874501,"te the meta policy network with parameters θ. Usually, we will go over many tasks in a batch and update θ as follows: X DQ θ = θ − β∇θ Lr (θr0 ), (5) Tr where β is the meta-learning rate. We detail the meta-learning algorithm in Algorithm 1. After previous meta-learning steps, Meta-KGR can fast adapt to a relation-specific policy network for every few-shot relation by using θ as wellinitialized parameters θ∗ . #Ent #Rel #Triples 14,448 3,078 63,524 2,951 200 37 170 30 268,039 4,076 115,454 2,680 Table 2: Statistics of datasets. 5 5.1 Experiments Datasets We use two typical datasets FB15K-237 (Toutanova et al., 2015) and NELL-995 (Xiong et al., 2017) for training and evaluation. Specifically, we set K = 137 and K = 114 to select few-shot relations from FB15K-237 and NELL995 respectively. Besides, we rebuild NELL-995 to generate few-shot relations in valid and test set. Statistics are given separately for normal relations and few-shot relations in Table 2. 5.2 Baselines We compare with four multi-hop reasoning models in experiments: (1) Neural Logical Programming (NerualLP) (Yang et al., 2017); (2) NTP-λ (Rockt¨aschel and Riedel, 2017); (3) MINERVA (Das et al., 2018) and (4) MultiHop (Lin et al., 2018). Fo"
D19-1334,P19-1617,0,0.0179871,"to solve the reward sparsity problem using off-policy learning. MultiHop (Lin et al., 2018) further extends MINERVA with reward shaping and action dropout, achieveing the state-of-the-art performance. These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop reasoning over KGs, there are also some multi-hop QA methods in recent years. Yang et al. (2018) proposes a high quality dataset, which greatly promotes the development of this field. After that, many methods like CogQA (Ding et al., 2019) and DFGN (Xiao et al., 2019) are also proposed. Meta-Learning tries to solve the problem of “fast adaptation on a new training task”. It has been proved to be very successful on few-shot task (Lake et al., 2015; Gu et al., 2018). Previous metalearning models mainly focus on computer vision and imitation learning domains. In this paper, we propose a new model (Meta-KGR) using the metalearning algorithm MAML (Finn et al., 2017) for 3377 rLra ✓ Meta-Learning Algorithm 1 Meta-Learning for multi-hop reasoning over knowledge graphs &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(null)&lt;/latexit&gt; Fast Adaptation &lt;latexit sha1_base64=&quot;(null)&quot;&gt;(nu"
D19-1334,D17-1060,0,0.176655,"al., 2016; Shi and Weninger, 2018) incorporate additional entity descriptions to learn embeddings for unseen entities, which can be seen as zero-shot scenarios. Xiong et al. (2018) predict new facts under a challenging setting where only one training triple for a given relation r is available, which can be seen as a one-shot scenario. Although these models are effective, they lack interpretability for their decisions. Multi-Hop Reasoning over KGs aims to learn symbolic inference rules from relational paths in G and has been formulated as sequential decision problems in recent years. DeepPath (Xiong et al., 2017) first applies RL to search reasoning paths in KGs for a given query, which inspires much later work (e.g., MINERVA (Das et al., 2018) and DIVA (Chen et al., 2018)). Because it is hard to train an RL model, ReinforceWalk (Shen et al., 2018) proposes to solve the reward sparsity problem using off-policy learning. MultiHop (Lin et al., 2018) further extends MINERVA with reward shaping and action dropout, achieveing the state-of-the-art performance. These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop r"
D19-1334,D18-1223,0,0.311594,"ose multi-hop reasoning methods, which leverage the symbolic compositionality of relations in KGs to achieve explainable reasoning results. For example, when queried with (Mark Twain, nationality, ?), multi-hop reasoning models can give not only the target entity America but also multi-hop explainable paths (Mark Twain, bornIn, Florida) ∧ (Florida, locatedIn, America) as well. Most previous work assumes that there are enough triples to train an effective and robust reasoning models for each relation in KGs. However, as shown in Figure 1, a large portion of KG relations are actually long-tail (Xiong et al., 2018; Han et al., 2018) and only contain few triples, which can be called few-shot relations. Some pilot experiments show that the performance of 3376 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3376–3381, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics previous multi-hop reasoning models, e.g., MINERVA (Das et al., 2018) and MultiHop (Lin et al., 2018), on these few-shot relations will drop significantly. Note that, there are some knowl"
D19-1334,D18-1259,0,0.0386084,"nspires much later work (e.g., MINERVA (Das et al., 2018) and DIVA (Chen et al., 2018)). Because it is hard to train an RL model, ReinforceWalk (Shen et al., 2018) proposes to solve the reward sparsity problem using off-policy learning. MultiHop (Lin et al., 2018) further extends MINERVA with reward shaping and action dropout, achieveing the state-of-the-art performance. These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop reasoning over KGs, there are also some multi-hop QA methods in recent years. Yang et al. (2018) proposes a high quality dataset, which greatly promotes the development of this field. After that, many methods like CogQA (Ding et al., 2019) and DFGN (Xiao et al., 2019) are also proposed. Meta-Learning tries to solve the problem of “fast adaptation on a new training task”. It has been proved to be very successful on few-shot task (Lake et al., 2015; Gu et al., 2018). Previous metalearning models mainly focus on computer vision and imitation learning domains. In this paper, we propose a new model (Meta-KGR) using the metalearning algorithm MAML (Finn et al., 2017) for 3377 rLra ✓ Meta-Learn"
D19-1502,C18-1024,1,0.799556,"e inference. For example, (Neelakantan and Chang, 2015) and (Xu et al., 2016) exploit various kinds of information to construct the feature representation of an entity, such as entity textual description, property and category. After that, a predict function is learned to infer whether entity e is an instance of type t. (Yaghoobzadeh et al., 2017) focus on the names of entities and the context of entity mentions (in text), and design two scoring models for pairs of entities and types. All these works ignore the internal relations among entities, and assign types for each entity in isolation. (Jin et al., 2018) viewed the internal relations 4969 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 4969–4978, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics among entities as the structural information, and constructed an Entity Graph, further proposed a network embedding framework to learn the correlation among entities. It will be profitable to enrich entity features to entity graph structures, as recent studies have suggested to bring both node fea"
D19-1502,N15-1054,0,0.0231931,"riable t and the Y-axis represents the function value. (d). Classification accuracy using different λ(t) functions for training on FIGER dataset. Table 4: Typing performance on FIGER. Methods Strict Ma-F1 Mi-F1 CUTE MuLR FIGMENT APE 0.531 0.548 0.563 0.515 0.743 0.776 0.785 0.722 0.782 0.812 0.819 0.756 HMGCNno cat HMGCNno prop HMGCNno co HMGCNf lat HMGCN 0.546 0.552 0.557 0.564 0.570 0.773 0.781 0.784 0.789 0.798 0.805 0.814 0.821 0.827 0.836 isting methods do type inference by utilizing entity’s inherent feature (textual description, property and category) or mention in text (anchor text). (Neelakantan and Chang, 2015) use text description as entity feature representation, then design a global objective function to predict missing entity types in a KB. (Xu et al., 2016) use property and category information, along with a multi-label hierarchical classifier, to assign DBpedia types to Chinese entities. (Yaghoobzadeh and Sch¨utze, 2015)first propose FIGMENT to address this problem. They only used contextual information to assign types for entities in KB. After that, they present FIGMENT-Multi to learn multi-level representations of entities on three complementary levels (character, word and entity) (Yaghoobza"
D19-1502,W09-1119,0,0.202175,"Missing"
D19-1502,D16-1144,0,0.13967,"e type inference. HMGCNno prop only use GCNco and GCNcat to make type inference. HMGCNno co only use GCNcat and GCNprop to make type inference. HMGCNf lat ignores the correlation between types, i.e., removes hierarchical recursive regularization. Table 1: Statistics of the datasets. Dataset FIGER DB-1 DB-2 DB-3 #Entities #Types 200,000 102 210,000 48 210,000 48 210,000 48 Metrics: To evaluate the performance of our proposed method, we use Accuracy (Strict-F1), Micro-averaged F1 (Mi-F1) and Macro-averaged F1 (Ma-F1), which have been used in many finegrained typing systems (Ling and Weld, 2012; Ren et al., 2016; Yaghoobzadeh et al., 2017). 4.2 Methods for Comparison Baseline: we compare HMGCN with four state-of-the-art of methods and three variants of HMGCN: • CUTE: (Xu et al., 2016) utilizes three kinds of entity features: category, property and property-value pair, and employs a hierarchical multi-label classification method. Parameter Settings: HMGCN is implemented based on the original GCN model (Kipf and Welling, 2016). In our implementation, both GCNco , GCNcat and GCNprop have two hidden layers. Namely, there are two separate parameter vectors, W(1) and W(2) , that need training. Table 2 pres"
D19-1502,D18-1032,0,0.0398818,"ty graph, then apply graph-based algorithm. The difficulties lie in two facts: • Firstly, it is hard to effectively integrate entity features and structural information. Although network embedding methods, in terms of attributed network embedding, can take both graph structure and features into consideration (Huang et al., 2017), the node features are usually only served as auxiliary information in structure learning (Yang et al., 2016; Liao et al., 2017). • Secondly, it is not easy to effectively integrate different connectivity matrix which capture different kinds of structural information (Wang et al., 2018; Zhuang and Ma, 2018). We propose a Hierarchical Multi GCN model (HMGCN) to encode heterogeneous structural information in an ensemble manner, as illustrated in Figure 2. We construct three undirected entity graphs to capture different kinds of semantic correlations between entities, i.e., co-occurrence graph Aco , category-based graph Acat , and property-based graph Aprop . Aco encodes the topical relevance between entities, and is derived from textual anchor texts. Acat is constructed through similarity computation based on category information, based on the assumption that entities with si"
D19-1502,D15-1083,0,0.0909476,"Missing"
D19-1502,E17-1055,0,0.0286617,"Missing"
D19-1502,C12-2133,0,0.186506,"able when the proportion is over 0.5, as illustrated in Figure 3(a). This shows that our model can achieve a satisfactory result, even with not enough labeled data, and this advantage is benefited from the information diffusion of the GCN model, i.e., similar entities should share information between each other. Results of Frequent/Infrequent Types. We evaluate the performance on frequent types (f requency &gt; 3, 000; 15 types) and infrequent types (f requency &lt; 200; 36 types). The classification measure is the type macro average F1 (F1 of entities assigned to a type, then averaged over types) (Yosef et al., 2012). Note that it is different from Ma-F1 reported in Table 3. Generally, the performance on infrequent types is worse than frequent ones. Our model consistently outperforms the other methods on infrequent types, which demonstrates its ability on dealing with rare types. The results for infrequent and frequent types in FIGER dataset are illustrated in Figure 3(b). Effect of Regularization Weight λ(t). Our model uses a weight function λ(t) to balance the trade-off between the supervised loss and unsupervised consistency regularizer. We devised several different weight functions (Zhuang and Ma, 201"
D19-1584,P13-1008,0,0.810312,"al., 2018) in recent years, EAE becomes the bottleneck of EE. † Org Time Seller Steve Jobs sold Buyer Pixar to Disney in Timewithin 2006. Figure 1: An example of the concept hierarchy. Introduction ∗ Person indicates equal contribution Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (C"
D19-1584,C10-1077,0,0.409617,"is well-studied (Nguyen and Grishman, 2018; Zhao et al., 2018) in recent years, EAE becomes the bottleneck of EE. † Org Time Seller Steve Jobs sold Buyer Pixar to Disney in Timewithin 2006. Figure 1: An example of the concept hierarchy. Introduction ∗ Person indicates equal contribution Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et"
D19-1584,P17-1038,0,0.138572,") rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019). However, the existing methods all treat argument roles as independent of each other, regardless of the fact that some argument roles are conceptually closer than others. Taking Figure 1 as an example, “Seller” is conceptually closer to “Buyer” than “Time-within”, because they share the same superordinate concepts “Person” and “Org” in the concept hierarchy. Intuitively, the concept hierarchy will provide extra informa5777 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Pr"
D19-1584,P10-1081,0,0.697552,"is well-studied (Nguyen and Grishman, 2018; Zhao et al., 2018) in recent years, EAE becomes the bottleneck of EE. † Org Time Seller Steve Jobs sold Buyer Pixar to Disney in Timewithin 2006. Figure 1: An example of the concept hierarchy. Introduction ∗ Person indicates equal contribution Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et"
D19-1584,P15-1017,0,0.611756,"t al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019). However, the existing methods all treat argument roles as independent of each other, regardless of the fact that some argument roles are conceptually closer than others. Taking Figure 1 as an example, “Seller” is conceptually closer to “Buyer” than “Time-within”, because they share the same supero"
D19-1584,D15-1166,0,0.0125031,"tention score for each hidden embedding to model its correlation with the specific superordinate concept. As an argument role can belong to more than one superordinate concept, we set a logic union module to combine the scores from different superordinate modules together. For each argument role, we hierarchically compose its superordinate concept modules into the integrated hierarchical modular attention component to build its role-oriented embedding. Superordinate Concept Module For a specific superordinate concept c, we represent its semantic features with a trainable vector uc . Following Luong et al. (2015), we adopt a multi-layer perceptron to calculate the attention scores. We first calculate the hidden state, hci = tanh(Wa [hi ; uc ]). (3) Then, we apply a softmax operation to get the attention score for the hidden embedding hi , exp(Wb hci ) sci = Pn c , j=1 exp(Wb hj ) (4) where Wa and Wb are trainable matrices shared among different superordinate concept modules. Logic Union Module Given an argument role r ∈ R, we denote its k superordinate concepts as c1 , c2 , . . . , ck , and the corresponding attention n X sri hi . (6) i=1 2.3 Argument Role Classifier We concatenate the instance embedd"
D19-1584,N18-1076,0,0.0621074,"ller”. Most event extraction (EE) methods treat EE as a two-stage problem, including event detection (ED, to identify the trigger word and determine the event type) and EAE. As ED is well-studied (Nguyen and Grishman, 2018; Zhao et al., 2018) in recent years, EAE becomes the bottleneck of EE. † Org Time Seller Steve Jobs sold Buyer Pixar to Disney in Timewithin 2006. Figure 1: An example of the concept hierarchy. Introduction ∗ Person indicates equal contribution Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguy"
D19-1584,N19-1423,0,0.0182971,"der We denote an instance as an n-word sequence x = {w1 , . . . , t, . . . , a, . . . , wn }, where t, a denote the trigger word and the candidate argument respectively. The trigger word is detected by the previous event detection models (independent of our work) and each named entity in the sentence is a candidate argument. Sentence Encoder is adopted to encode the word sequence into hidden embeddings,  {h1 , h2 . . . , hn } = E w1 , . . . , t, . . . , a, . . . , wn , (1) 5778 where E(·) is the neural network to encode the sentence. In this paper, we select CNN (Chen et al., 2015) and BERT (Devlin et al., 2019) as encoders. Feature Aggregator aggregates the hidden embeddings into an instance embedding. Our method is independent of the feature aggregator mechanism. Here, we follow Chen et al. (2015) and use dynamic multi-pooling as the feature aggregator: scores for hi are sci 1 , sci 2 , . . . , sci k computed by Eq. (4). As information about all the superordinate concepts should be retained in the role-oriented embedding, we calculate the mean of the attention scores as the role-oriented attention score, sri k 1 X cj = si , k (5) j=1 [x1,pt ]i = max{[h1 ]i , . . . , [hpt ]i }, [xpt +1,pa ]i = max{["
D19-1584,N16-1034,0,0.62235,"018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019). However, the existing methods all treat argument roles as independent of each other, regardless of the fact that some argument roles are conceptually closer than others. Taking Figure 1 as an example, “Seller” is conceptually closer to “Buyer” than “Time-within”, because they share the same superordinate concepts “Person” and “Org” in the concept"
D19-1584,D18-1247,1,0.781371,"score Superordinate modules, corresponding to the superordinate concepts of the argument role to classify. Argument Role Classifier, varies with the argument role to classify. Figure 2: The overall architecture of HMEAE. Take the argument role “Seller” as an example. tion about the correlation between argument roles and help the argument role classification. To leverage the concept hierarchy information to improve EAE, we propose the Hierarchical Modular Event Argument Extraction (HMEAE) model. Inspired by the previous hierarchical classification works (Qiu et al., 2011; Shimura et al., 2018; Han et al., 2018) and the neural module networks (NMNs) (Andreas et al., 2016), HMEAE adopts the NMNs to enable a flexible network architecture imitating the concept hierarchical structure, which can provide effective inductive bias for better classification performance. As Figure 1 shows, we divide the concepts into two types: the superordinate concepts representing more abstractive concepts, and the finegrained argument roles. An argument role can belong to more than one superordinate concept, e.g., “Seller” belongs to both “Person” and “Org”. As shown in Figure 2, we set a neural module network for each con"
D19-1584,D09-1016,0,0.244851,"e event type) and EAE. As ED is well-studied (Nguyen and Grishman, 2018; Zhao et al., 2018) in recent years, EAE becomes the bottleneck of EE. † Org Time Seller Steve Jobs sold Buyer Pixar to Disney in Timewithin 2006. Figure 1: An example of the concept hierarchy. Introduction ∗ Person indicates equal contribution Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-mo"
D19-1584,P11-2105,0,0.0152203,"ng att score input embeddings + ATT att score Superordinate modules, corresponding to the superordinate concepts of the argument role to classify. Argument Role Classifier, varies with the argument role to classify. Figure 2: The overall architecture of HMEAE. Take the argument role “Seller” as an example. tion about the correlation between argument roles and help the argument role classification. To leverage the concept hierarchy information to improve EAE, we propose the Hierarchical Modular Event Argument Extraction (HMEAE) model. Inspired by the previous hierarchical classification works (Qiu et al., 2011; Shimura et al., 2018; Han et al., 2018) and the neural module networks (NMNs) (Andreas et al., 2016), HMEAE adopts the NMNs to enable a flexible network architecture imitating the concept hierarchical structure, which can provide effective inductive bias for better classification performance. As Figure 1 shows, we divide the concepts into two types: the superordinate concepts representing more abstractive concepts, and the finegrained argument roles. An argument role can belong to more than one superordinate concept, e.g., “Seller” belongs to both “Person” and “Org”. As shown in Figure 2, we"
D19-1584,P16-1116,0,0.285339,"BERT and HMEAE (BERT) are the same as the BERTBASE model. To utilize the event type information in our model, we append a special token into each input sequence for BERT to indicate the event type. Additional hyperparameters used in our experiments are shown in Table 2. Learning Rate Batch Size Kernel Size Warmup Rate uc dimension Wb dimension 6e-05 50 3 0.1 900 900 Table 2: Hyperparameter settings for BERT models. 3.2 Overall Evaluation Results We compare our models with various state-of-theart baselines on ACE 2005: (1) Feature-based methods, including Li’s joint (Li et al., 2013) and RBPB (Sha et al., 2016). (2) Vanilla neural network methods, including DMCNN (Chen et al., 2015) and JRNN (Nguyen et al., 2016). (3) Neural network with syntax information, like dbRNN (Sha et al., 2018) enhancing the recurrent neural network with dependency bridges to consider syntactically related information. On TAC KBP 2016, we compare our models with the top systems (Dubbin et al., 2016; Hsi et al., 2016; Ferguson et al., 2016) of the competition as well as DMCNN and DMBERT. 5780 Barry Diller on Wednesday quit as chief of Vivendi Universal Entertainment Argument Role Classification P R F1 Method Li’s Joint (Li e"
D19-1584,D18-1093,0,0.0221031,"embeddings + ATT att score Superordinate modules, corresponding to the superordinate concepts of the argument role to classify. Argument Role Classifier, varies with the argument role to classify. Figure 2: The overall architecture of HMEAE. Take the argument role “Seller” as an example. tion about the correlation between argument roles and help the argument role classification. To leverage the concept hierarchy information to improve EAE, we propose the Hierarchical Modular Event Argument Extraction (HMEAE) model. Inspired by the previous hierarchical classification works (Qiu et al., 2011; Shimura et al., 2018; Han et al., 2018) and the neural module networks (NMNs) (Andreas et al., 2016), HMEAE adopts the NMNs to enable a flexible network architecture imitating the concept hierarchical structure, which can provide effective inductive bias for better classification performance. As Figure 1 shows, we divide the concepts into two types: the superordinate concepts representing more abstractive concepts, and the finegrained argument roles. An argument role can belong to more than one superordinate concept, e.g., “Seller” belongs to both “Person” and “Org”. As shown in Figure 2, we set a neural module n"
D19-1584,P18-1201,0,0.114469,"(Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019). However, the existing methods all treat argument roles as independent of each other, regardless of the fact that some argument roles are conceptually closer than others. Taking Figure 1 as an example, “Seller” is conceptually closer to “Buyer” than “Time-within”, because they share the same superordinate concepts “Person” and “Org” in the concept hierarchy. Intuitively, the concept hierarchy will provide extra informa5777 Proceedings of the 2019 Conference on Empirical Methods"
D19-1584,N19-1105,1,0.884827,"ted features and patterns. With the ongoing development of neural networks, various neural networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018). Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019). However, the existing methods all treat argument roles as independent of each other, regardless of the fact that some argument roles are conceptually closer than others. Taking Figure 1 as an example, “Seller” is conceptually closer to “Buyer” than “Time-within”, because they share the same superordinate concepts “Person” and “Org” in the concept hierarchy. Intuitively, the concept hierarchy will provide extra informa5777 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 5777"
D19-1584,P18-2066,0,0.173398,"1 Argument Role Instance Event argument extraction (EAE) aims to identify the entities serving as event arguments and classify the roles they play in an event. For instance, given that the word “sold” triggers a Transfer-Ownership event in the sentence “Steve Jobs sold Pixar to Disney”, EAE aims to identify that “Steve Jobs” is an event argument and its argument role is “Seller”. Most event extraction (EE) methods treat EE as a two-stage problem, including event detection (ED, to identify the trigger word and determine the event type) and EAE. As ED is well-studied (Nguyen and Grishman, 2018; Zhao et al., 2018) in recent years, EAE becomes the bottleneck of EE. † Org Time Seller Steve Jobs sold Buyer Pixar to Disney in Timewithin 2006. Figure 1: An example of the concept hierarchy. Introduction ∗ Person indicates equal contribution Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments. Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al.,"
I17-1024,P12-1092,0,0.26475,"pe embedding models, and achieves more stable performance when trained on smaller data. 1 Figure 1: Relatedness among senses of the word “book”. To enhance the expression ability of the embedding model, recent research has a rising enthusiasm for representing words at sense level. That is, an individual word is represented as multiple vectors, where each vector corresponds to one of its meanings. Pervious work mostly focus on using clustering to induce word senses (each cluster refers to one of the senses) and then learn the word sense representations respectively (Reisinger and Mooney, 2010; Huang et al., 2012; Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). However, the above approaches ignore the relatedness among the word senses. Hence the following limitations arise in the usage of hard clustering. First of all, many clustering errors will be caused by using hard clustering based method because the senses of the polysemous word actuIntroduction Word embedding, representing words in a low dimentional vector space, plays an increasing important role in various IR and NLP related tasks, such as language modeling (Bengio et al., 2006; ∗ Corresponding author. 233 Proceedings of"
I17-1024,S13-2049,0,0.0189139,"from more data sparsity issue as compared to the Skip-gram model. Thirdly, the embedding quality is considerably sensitive to the clustering results due to the isolation of different sense clusters. To address this problem, we learn the embedding vectors of the word senses with some common features if the senses are related. Instead of clearly cutting the sense cluster boundaries, one occurrence of the word will be assigned into multiple sense clusters with different probabilities, which agrees with a classic task of word sense annotation, Graded Word Sense Assignment (Erk and McCarthy, 2009; Jurgens and Klapaftis, 2013). Actually, the senses of a polysemous word are related not only by the contiguity of meaning within a semantic field1 , but also by the extended relationship between the original meaning and the extended meaning (Von Engelhardt and Zimmermann, 1988). We investigate the relatedness of the synsets (word senses) in WordNet (Miller, 1995) through the Wu & Palmer measure2 (Wu and Palmer, 1994), and present an interesting example of the word “book” in Figure 1. The right side is the similarity matrix of its 11 nominal synsets, where si denotes the ith synset. Each tile represents a similarity value"
I17-1024,D15-1200,0,0.253581,"ained on smaller data. 1 Figure 1: Relatedness among senses of the word “book”. To enhance the expression ability of the embedding model, recent research has a rising enthusiasm for representing words at sense level. That is, an individual word is represented as multiple vectors, where each vector corresponds to one of its meanings. Pervious work mostly focus on using clustering to induce word senses (each cluster refers to one of the senses) and then learn the word sense representations respectively (Reisinger and Mooney, 2010; Huang et al., 2012; Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). However, the above approaches ignore the relatedness among the word senses. Hence the following limitations arise in the usage of hard clustering. First of all, many clustering errors will be caused by using hard clustering based method because the senses of the polysemous word actuIntroduction Word embedding, representing words in a low dimentional vector space, plays an increasing important role in various IR and NLP related tasks, such as language modeling (Bengio et al., 2006; ∗ Corresponding author. 233 Proceedings of the The 8th International Joint Conference on Natural Language Proces"
I17-1024,P17-1149,1,0.885707,"Missing"
I17-1024,D14-1110,1,0.878368,"Missing"
I17-1024,D14-1113,0,0.396051,"stable performance when trained on smaller data. 1 Figure 1: Relatedness among senses of the word “book”. To enhance the expression ability of the embedding model, recent research has a rising enthusiasm for representing words at sense level. That is, an individual word is represented as multiple vectors, where each vector corresponds to one of its meanings. Pervious work mostly focus on using clustering to induce word senses (each cluster refers to one of the senses) and then learn the word sense representations respectively (Reisinger and Mooney, 2010; Huang et al., 2012; Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). However, the above approaches ignore the relatedness among the word senses. Hence the following limitations arise in the usage of hard clustering. First of all, many clustering errors will be caused by using hard clustering based method because the senses of the polysemous word actuIntroduction Word embedding, representing words in a low dimentional vector space, plays an increasing important role in various IR and NLP related tasks, such as language modeling (Bengio et al., 2006; ∗ Corresponding author. 233 Proceedings of the The 8th International Joint Conference on"
I17-1024,N10-1013,0,0.0366961,"Missing"
I17-1024,P13-1045,0,0.0293059,"Missing"
I17-1024,C14-1016,0,0.0207572,"and achieves more stable performance when trained on smaller data. 1 Figure 1: Relatedness among senses of the word “book”. To enhance the expression ability of the embedding model, recent research has a rising enthusiasm for representing words at sense level. That is, an individual word is represented as multiple vectors, where each vector corresponds to one of its meanings. Pervious work mostly focus on using clustering to induce word senses (each cluster refers to one of the senses) and then learn the word sense representations respectively (Reisinger and Mooney, 2010; Huang et al., 2012; Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). However, the above approaches ignore the relatedness among the word senses. Hence the following limitations arise in the usage of hard clustering. First of all, many clustering errors will be caused by using hard clustering based method because the senses of the polysemous word actuIntroduction Word embedding, representing words in a low dimentional vector space, plays an increasing important role in various IR and NLP related tasks, such as language modeling (Bengio et al., 2006; ∗ Corresponding author. 233 Proceedings of the The 8th Interna"
I17-1024,P10-1040,0,0.15214,"Missing"
I17-1024,D09-1046,0,\N,Missing
I17-1088,P14-1119,0,0.00568372,"nfrequent course concepts are from other prerequisite or related courses (e.g., “uniform distribution” is from mathematical courses and “divide-and-conquer” is from courses about algorithms); (3) a disambiguated course concept tends to be expressed in various ways, which produces many scattered infrequent terms. For example, “Q sort” is a colloquial expression referring to quick sort, and “partition exchange sort” is another name for quick sort. They both have infrequent presence in course videos. Handling infrequency errors remains an open challenge for state-of-the-art keyphrase extractors (Hasan and Ng, 2014). In MOOCs, the lowfrequency problem makes it difficult for video captions to provide reliable statistical information (e.g., tf-idf, c-value, and co-occurrence) for extracting and ranking terms, and results in the ignoring of many course-relevant yet infrequent concepts. For example, in Figure 1, we can correctly extract the frequent concept “quick sort” using tf-idf, but fail to extract “partition exchange sort” due to its infrequent presence, even if these two concepts have the same meaning. The above problem can be addressed if we know the semantic relationship between “quick sort” and “pa"
I17-1088,C00-1047,0,0.0180532,"Coursera 2 with different domains and different languages, and compare our method with state-of-the-art keyphrase extractors. In summary, our contributions include: a) the first attempt, to the best of our knowledge, to systematically investigate the problem of course concept extraction in MOOCs; b) proposal of an efficient model for course concept extraction via semantic representation learning, and ranking candidates through graph-based propagation; c) design of four novel datasets using real courses of different disciplines from XuetangX and Coursera to evaluate our proposed method. tion (Hisamitsu et al., 2000; Li et al., 2013), the problem of course concept extraction in MOOCs is far from solved. The most challenging issue in the MOOC context is the low-frequency problem. Course video captions often contain many course concepts with low frequency, primarily for three reasons: (1) course video captions are relatively short documents, containing small numbers of words; (2) many infrequent course concepts are from other prerequisite or related courses (e.g., “uniform distribution” is from mathematical courses and “divide-and-conquer” is from courses about algorithms); (3) a disambiguated course conce"
I17-1088,W03-1028,0,0.0465675,"istributed representations of words, namely word embeddings (Mikolov et al., 2013b,a), provides us with powerful tools to represent semantic relations between words. In our 2 876 https://www.coursera.org/ architecture of our model consists of three parts: (1) candidate concepts extraction, (2) candidate concepts ranking, and (3) postprocessing. Candidate concepts extraction pre-processes the input corpus and extracts candidate course concepts. Considering that most concepts are noun phrases consisting of nouns, adjectives and some variants of verbs, and end with a noun word (Liu et al., 2010; Hulth, 2003; Li et al., 2013), we obtain candidate course concepts by extracting all noun phrases in the course corpus. The input text is first tokenized and annotated with part-ofspeech (POS) tags. Next, we employ the linguistic pattern ((A|N )+ |(A|N )∗ (N P )?(A|N )∗ )N , introduced by Justeson and Katz (1995), to extract all k-gram noun phrases as our candidates, where A, N , and P denote the adjectives, nouns, and prepositions, respectively. Candidate concepts ranking, which is the most important part of our method, involves ranking the extracted candidates based on their phraseness and informativen"
I17-1088,W09-2902,0,0.0471544,"traction of important and topical phrases from the body of a document” (Turney, 2000). Generally, keyphrase extraction techniques can be classified into two groups: supervised approaches and unsupervised approaches. In supervised machinelearning approaches, the training phase usually includes a classification task: each phrase in the document is either a keyphrase or not (You et al., 2013). Different learning algorithms have been employed to train the classifier, including na¨ıve bayes (Frank et al., 1999; Witten et al., 1999), decision trees (Turney, 2000), maximum entropy (Yih et al., 2006; Kim and Kan, 2009) and support vector machines (Lopez and Romary, 2010; Kim and Kan, 2009). Unsupervised approaches usually involve assigning a saliency score to each candidate phrase, by considering various features (Wan and Xiao, 2008). Generally speaking, the information such as tf-idf, co-occurrence, or neighbor documents are frequently used in unsupervised keyphrase extraction. For example, TextRank (Mihalcea and Tarau, 2004) is a wellknown method that ranks keywords based on the co-occurrence graph. Huang et al. (2006) utilize co-occurrence information to construct a semantic network for each document and"
I17-1088,S10-1040,0,0.0383241,"Missing"
I17-1088,D10-1036,0,0.30906,"stem may display the definition of “unstable sorting” and “uniform distribution”; while for a science student, the system could recommend advanced concepts or potential applications of “quick sort”. Course concepts were previously provided by the teacher, but only at a coarse level—it is timeconsuming and tedious to annotate all fine-grained concepts in all videos of a course. Our goal is to automatically identify all course concepts from each video clip. Despite quite a few studies on related research topics, including keyphrase extraction (Salton and Buckley, 1988; Mihalcea and Tarau, 2004; Liu et al., 2010) and term extracIntroduction In contrast with traditional courses that have limited numbers of students, each online course in a MOOC platform may draw more than 100,000 registrants (Seaton et al., 2014). The students have very diverse backgrounds; and knowledge presented in MOOCs is well understood by certain students, but might be difficult to others. In MOOCs, we use course concepts to refer to the knowledge concepts taught in the course videos, and related topics that help students better understand course videos. Identifying course concepts at a fine level is very important, as students w"
I17-1088,J90-1003,0,0.373902,"ionally challenging, and (2) low-SR candidate pairs may introduce noise during propagation. In the following subsections, we introduce the essential building blocks of CCG, i.e., the calculation of phraseness and the representation of semantic relatedness. 3 where pmi(fi , bi ) is the PMI of the prefix fi and the suffix bi , defined as follows. 3.1 Phraseness Measurement Phraseness examines the likelihood of a multiword term to be a semantically and syntactically correct phrase. There exists several mechanisms such as Log-likelihood (LL) (Dunning, 1993) and Pointwise Mutual Information (PMI) (Church and Hanks, 1990) to measure the phraseness of a term. These methods are mostly based on the assumption that if the constituents of a multi-word candidate term form a collocation, rather than cooccurring by chance, it is more likely to be considered as a phrase (Korkontzelos et al., 2008). In our paper, we propose a simple PMI-based approach, which utilizes local mutual frequencies in the course corpus, to calculate the phraseness score for each candidate. Specifically, for a kgram candidate c = {w1 , · · · , wk } ∈ T , where k > 1, we split c into fi = {w1 , · · · , wi } (prefix) and bi = {wi+1 , · · · , wk }"
I17-1088,S10-1055,0,0.0209618,"he body of a document” (Turney, 2000). Generally, keyphrase extraction techniques can be classified into two groups: supervised approaches and unsupervised approaches. In supervised machinelearning approaches, the training phase usually includes a classification task: each phrase in the document is either a keyphrase or not (You et al., 2013). Different learning algorithms have been employed to train the classifier, including na¨ıve bayes (Frank et al., 1999; Witten et al., 1999), decision trees (Turney, 2000), maximum entropy (Yih et al., 2006; Kim and Kan, 2009) and support vector machines (Lopez and Romary, 2010; Kim and Kan, 2009). Unsupervised approaches usually involve assigning a saliency score to each candidate phrase, by considering various features (Wan and Xiao, 2008). Generally speaking, the information such as tf-idf, co-occurrence, or neighbor documents are frequently used in unsupervised keyphrase extraction. For example, TextRank (Mihalcea and Tarau, 2004) is a wellknown method that ranks keywords based on the co-occurrence graph. Huang et al. (2006) utilize co-occurrence information to construct a semantic network for each document and derive the importance of phrases by analyzing the n"
I17-1088,J93-1003,0,0.0355612,"1) the propagation on a fully connected CCG is computationally challenging, and (2) low-SR candidate pairs may introduce noise during propagation. In the following subsections, we introduce the essential building blocks of CCG, i.e., the calculation of phraseness and the representation of semantic relatedness. 3 where pmi(fi , bi ) is the PMI of the prefix fi and the suffix bi , defined as follows. 3.1 Phraseness Measurement Phraseness examines the likelihood of a multiword term to be a semantically and syntactically correct phrase. There exists several mechanisms such as Log-likelihood (LL) (Dunning, 1993) and Pointwise Mutual Information (PMI) (Church and Hanks, 1990) to measure the phraseness of a term. These methods are mostly based on the assumption that if the constituents of a multi-word candidate term form a collocation, rather than cooccurring by chance, it is more likely to be considered as a phrase (Korkontzelos et al., 2008). In our paper, we propose a simple PMI-based approach, which utilizes local mutual frequencies in the course corpus, to calculate the phraseness score for each candidate. Specifically, for a kgram candidate c = {w1 , · · · , wk } ∈ T , where k > 1, we split c int"
I17-1088,W04-3252,0,0.162695,"on-science student, the system may display the definition of “unstable sorting” and “uniform distribution”; while for a science student, the system could recommend advanced concepts or potential applications of “quick sort”. Course concepts were previously provided by the teacher, but only at a coarse level—it is timeconsuming and tedious to annotate all fine-grained concepts in all videos of a course. Our goal is to automatically identify all course concepts from each video clip. Despite quite a few studies on related research topics, including keyphrase extraction (Salton and Buckley, 1988; Mihalcea and Tarau, 2004; Liu et al., 2010) and term extracIntroduction In contrast with traditional courses that have limited numbers of students, each online course in a MOOC platform may draw more than 100,000 registrants (Seaton et al., 2014). The students have very diverse backgrounds; and knowledge presented in MOOCs is well understood by certain students, but might be difficult to others. In MOOCs, we use course concepts to refer to the knowledge concepts taught in the course videos, and related topics that help students better understand course videos. Identifying course concepts at a fine level is very impor"
I17-1088,vivaldi-rodriguez-2010-finding,0,0.0793189,"Missing"
I17-1088,R09-1086,0,0.0630841,"Missing"
P13-1063,W09-1604,0,0.0372182,"Missing"
P13-1063,P10-1013,0,0.0738972,"0 4.1 300 4.3 Some approaches of knowledge extraction from the open Web have been proposed (Wu et al., 2012; Yates et al., 2007). Here we focus on the extraction inside Wikipedia. 5.1 Monolingual Infobox Extraction KYLIN is the first system to autonomously extract the missing infoboxes from the corresponding article texts by using a self-supervised learning method (Wu and Weld, 2007). KYLIN performs well when enough training data are available. Such techniques as shrinkage and retraining are proposed to increase the recall from English Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 500 0.3 # Number of the target training articles. Table 7: Results of Significance Test. 4.5 Overall Analysis As shown in above experiments, we can see that WikiCiKE outperforms both KE-Mon and KE-Tr. When only 30 target training samples are available, WikiCiKE reaches comparable performance of KE-Mon using 300-500 target training samples. Among all of the 72 attributes in TEMPLATE PERSON of Ch"
P13-1063,W06-2810,0,\N,Missing
P13-1063,N07-4013,0,\N,Missing
P15-2057,W07-0201,0,0.0345266,"ki articles, they are still too high-level and incomplete. Take the “Earthquake” category as an example, its corresponding Wiki article 2 only contains Introduction As a free-access online encyclopedia, written collaboratively by people all over the world, Wikipedia (abbr. to Wiki) offers a surplus of rich information. Millions of articles cover various concepts and instances 1 . Wiki has been widely used for various knowledge discovery tasks. Some good examples include knowledge mining from Wiki infoboxes (Lin et al., 2011; Wang et al., 2013), and taxonomy deriving from Wiki category system (Zesch and Gurevych, 2007). We observe that, in addition to Wiki’s infoboxes and category system, Wiki articles’ Contents tables (CT for short) also provide valuable structured topic knowledge with different levels of granularity. For example, in the article “2010 Haiti Earthquake”, shown in Fig.1, the left Contents zone is a CT formed in a topic hierarchy for1 2 http://en.wikipedia.org/wiki/Encyclopedia 346 http://en.wikipedia.org/wiki/Earthquake Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Paper"
P15-2057,W11-2206,0,0.015835,"(CTH). While there also exist manually built CTH represented by CT in corresponding Wiki articles, they are still too high-level and incomplete. Take the “Earthquake” category as an example, its corresponding Wiki article 2 only contains Introduction As a free-access online encyclopedia, written collaboratively by people all over the world, Wikipedia (abbr. to Wiki) offers a surplus of rich information. Millions of articles cover various concepts and instances 1 . Wiki has been widely used for various knowledge discovery tasks. Some good examples include knowledge mining from Wiki infoboxes (Lin et al., 2011; Wang et al., 2013), and taxonomy deriving from Wiki category system (Zesch and Gurevych, 2007). We observe that, in addition to Wiki’s infoboxes and category system, Wiki articles’ Contents tables (CT for short) also provide valuable structured topic knowledge with different levels of granularity. For example, in the article “2010 Haiti Earthquake”, shown in Fig.1, the left Contents zone is a CT formed in a topic hierarchy for1 2 http://en.wikipedia.org/wiki/Encyclopedia 346 http://en.wikipedia.org/wiki/Earthquake Proceedings of the 53rd Annual Meeting of the Association for Computational Li"
P15-2057,P13-1063,1,0.804832,"e also exist manually built CTH represented by CT in corresponding Wiki articles, they are still too high-level and incomplete. Take the “Earthquake” category as an example, its corresponding Wiki article 2 only contains Introduction As a free-access online encyclopedia, written collaboratively by people all over the world, Wikipedia (abbr. to Wiki) offers a surplus of rich information. Millions of articles cover various concepts and instances 1 . Wiki has been widely used for various knowledge discovery tasks. Some good examples include knowledge mining from Wiki infoboxes (Lin et al., 2011; Wang et al., 2013), and taxonomy deriving from Wiki category system (Zesch and Gurevych, 2007). We observe that, in addition to Wiki’s infoboxes and category system, Wiki articles’ Contents tables (CT for short) also provide valuable structured topic knowledge with different levels of granularity. For example, in the article “2010 Haiti Earthquake”, shown in Fig.1, the left Contents zone is a CT formed in a topic hierarchy for1 2 http://en.wikipedia.org/wiki/Encyclopedia 346 http://en.wikipedia.org/wiki/Earthquake Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7t"
P17-1133,D15-1077,1,0.836588,"enotes a word and m is the length of the word sequence. Our method consists of two steps: (1) entity annotation, and (2) representation learning. Entity Annotation. We first automatically annotate the entities in W to obtain an entity set E and an entity-annotated Wikipedia corpus W 0 = hx1 · · · xi · · · xm0 i, where xi corresponds to a word w ∈ W or an entity e ∈ E. Note that m0 &lt; m because multiple adjacent words could be labeled as one entity. Many entity linking tools are available for entity annotation, e.g. TAGME (Ferragina and Scaiella, 2010), AIDA (Yosef et al., 2011) and TremenRank (Cao et al., 2015). However, the rich hyperlinks created by Wiki editors provide a more natural way. In our experiments, we simply use the hyperlinks in Wikipedia articles as annotated entities. Representation Learning. We then learn word embeddings (Mikolov et al., 2013b,a) on W 0 to obtain low-dimensional, real-valued vector repreva = ( ve , if a ≡ e and e ∈ E vg1 + · · · + vgN , otherwise (1) It means that if a is a Wikipedia entity, we can directly obtain its semantic representations; otherwise, we obtain its vector via the vector addition of its individual word vectors. In this way, a has no corresponding"
P17-1133,D11-1142,0,0.0500848,"course dependencies. Gordon et al. (2016) utilize cross-entropy to learn concept dependencies in scientific corpus. Besides local statistical information, our method also utilize external knowledge to enrich concept semantics, which is more informativeness. 1454 Our work is also related to the study of automatic relation extraction. Different research lines have been proposed around this topic, including hypernym-hyponym relation extraction (Ritter et al., 2009; Wei et al., 2012), entity relation extraction (Zhou et al., 2006; Fan et al., 2014; Lin et al., 2015) and open relation extraction (Fader et al., 2011). However, previous works mainly focus on factual relations, the extraction of cognitive relations (e.g. prerequisite relations) has not been well studied yet. 6 Conclusions and Future Work We conducted a new investigation on automatically inferring prerequisite relations among concepts in MOOCs. We precisely define the problem and propose several useful features from different aspects, i.e., contextual, structural and semantic features. Moreover, we apply an embeddingbased method that jointly learns the semantic representations of Wikipedia concepts and MOOC concepts to help implement the fea"
P17-1133,P14-1079,0,0.0256877,"on based framework to discover concept prerequisite relations from course dependencies. Gordon et al. (2016) utilize cross-entropy to learn concept dependencies in scientific corpus. Besides local statistical information, our method also utilize external knowledge to enrich concept semantics, which is more informativeness. 1454 Our work is also related to the study of automatic relation extraction. Different research lines have been proposed around this topic, including hypernym-hyponym relation extraction (Ritter et al., 2009; Wei et al., 2012), entity relation extraction (Zhou et al., 2006; Fan et al., 2014; Lin et al., 2015) and open relation extraction (Fader et al., 2011). However, previous works mainly focus on factual relations, the extraction of cognitive relations (e.g. prerequisite relations) has not been well studied yet. 6 Conclusions and Future Work We conducted a new investigation on automatically inferring prerequisite relations among concepts in MOOCs. We precisely define the problem and propose several useful features from different aspects, i.e., contextual, structural and semantic features. Moreover, we apply an embeddingbased method that jointly learns the semantic representati"
P17-1133,P16-1082,0,0.0988633,"d on these Wikipedia features plus some textbook features, Wang et al. (Wang et al., 2016) proposed a method to construct a concept map from textbooks, which jointly learns the key concepts and their prerequisite relations. However, the investigation of only Wikipedia concepts is also the bottleneck of their studies. In our work, we propose more general features to infer prerequisite relations among concepts, regardless of whether the concept is in Wikipedia or not. Liang et al. (2017) propose an optimization based framework to discover concept prerequisite relations from course dependencies. Gordon et al. (2016) utilize cross-entropy to learn concept dependencies in scientific corpus. Besides local statistical information, our method also utilize external knowledge to enrich concept semantics, which is more informativeness. 1454 Our work is also related to the study of automatic relation extraction. Different research lines have been proposed around this topic, including hypernym-hyponym relation extraction (Ritter et al., 2009; Wei et al., 2012), entity relation extraction (Zhou et al., 2006; Fan et al., 2014; Lin et al., 2015) and open relation extraction (Fader et al., 2011). However, previous wor"
P17-1133,D15-1193,0,0.651453,"Missing"
P17-1133,P06-1016,0,0.0479453,"opose an optimization based framework to discover concept prerequisite relations from course dependencies. Gordon et al. (2016) utilize cross-entropy to learn concept dependencies in scientific corpus. Besides local statistical information, our method also utilize external knowledge to enrich concept semantics, which is more informativeness. 1454 Our work is also related to the study of automatic relation extraction. Different research lines have been proposed around this topic, including hypernym-hyponym relation extraction (Ritter et al., 2009; Wei et al., 2012), entity relation extraction (Zhou et al., 2006; Fan et al., 2014; Lin et al., 2015) and open relation extraction (Fader et al., 2011). However, previous works mainly focus on factual relations, the extraction of cognitive relations (e.g. prerequisite relations) has not been well studied yet. 6 Conclusions and Future Work We conducted a new investigation on automatically inferring prerequisite relations among concepts in MOOCs. We precisely define the problem and propose several useful features from different aspects, i.e., contextual, structural and semantic features. Moreover, we apply an embeddingbased method that jointly learns the sem"
P17-1133,W12-2037,0,0.187113,"planning. Liu et al. (2011) studied learning-dependency between knowledge units, a special text fragment containing concepts, using a classification-based method. In the area of education, researchers have tried to find general prerequisite structures from students’ test performance (Vuong et al., 2011; Scheines et al., 2014; Huang et al., 2015). Different from them, we focus on more finegrained prerequisite relations, i.e., the prerequisite relations among course concepts. Among the few related works of mining prerequisite relations among concepts, Liang et al. (2015) and Talukdar and Cohen (Talukdar and Cohen, 2012) studied prerequisite relationships between Wikipedia articles. They assumed that hyperlinks between Wikipedia pages indicate a prerequisite relationship and design several useful features. Based on these Wikipedia features plus some textbook features, Wang et al. (Wang et al., 2016) proposed a method to construct a concept map from textbooks, which jointly learns the key concepts and their prerequisite relations. However, the investigation of only Wikipedia concepts is also the bottleneck of their studies. In our work, we propose more general features to infer prerequisite relations among con"
P17-1149,P14-2013,0,0.037015,"Missing"
P17-1149,D15-1077,1,0.895996,"Missing"
P17-1149,D14-1110,0,0.0679262,"Missing"
P17-1149,D07-1074,0,0.119191,"Missing"
P17-1149,P05-1045,0,0.00358486,"entity ej . Example As shown in Figure 1, Independence Day (m1 ) has two mention senses s11 , s12 , and July 4th (m2 ) has one mention sense s22 . Based on the assumption in Section 1, we have s∗2 = s12 = s22 referring to entity Independence Day (US) (e2 ). 3 An Overview of Our Method Given a knowledge base KB, an annotated text corpus D0 and a set of anchors A, we aim to jointly learn word, entity and mention sense representations: w, e, s. As shown in Figure 2, our framework contains two key components: 1 Generally, the mention boundary can be obtained by using NER tools like Standford NER (Finkel et al., 2005). In this paper, we use Wikipedia anchors as annotations of Wikipedia text corpus for the concentration of our main purpose. 1624 211 cluster center is clustering the average of all the context vecIndependence (f ilm)the context323 nearest distance context vector to sense 472(3) and (4) 422 204 336 tion has andenotes embedding (sense vector) and 1, 6 1 for max model. Conclusion (WSD) use4.6 context information to language ter isthe larger than a the threshold, we create atl clus462 dings e.same Note that ssense m that mention We jointly train (2), by373 using a un 413 on Software Engineering,"
P17-1149,N16-1150,0,0.0537076,"Missing"
P17-1149,D11-1072,0,0.51378,"Missing"
P17-1149,P12-1092,0,0.0460393,"film: Independence Day (film). Second, an entity often has various aliases when mentioned in various contexts, which implies a much larger size of mention vocabulary compared with entities. For example, in Figure 1, the documents d2 and d3 describes the same entity Independence Day (US) (e2 ) with distinct mentions: independence day and July 4th. We observe tens of millions of mentions referring to 5 millions of entities in Wikipedia. To address these issues, we propose to learn multiple embeddings for mentions inspired by the Word Sense Disambiguation (WSD) task (Reisinger and Mooney, 2010; Huang et al., 2012; 1623 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1623–1633 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1149 Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). The basic idea behind it is to consider entities in KBs that can provide a meaning repository of mentions (i.e. words or phrases) in texts. That is, each mention has one or multiple meanings, namely mention senses, and each sense corresponds to an entity. Furthermore, we assume that diff"
P17-1149,D15-1200,0,0.0220958,"ct mentions: independence day and July 4th. We observe tens of millions of mentions referring to 5 millions of entities in Wikipedia. To address these issues, we propose to learn multiple embeddings for mentions inspired by the Word Sense Disambiguation (WSD) task (Reisinger and Mooney, 2010; Huang et al., 2012; 1623 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1623–1633 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1149 Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). The basic idea behind it is to consider entities in KBs that can provide a meaning repository of mentions (i.e. words or phrases) in texts. That is, each mention has one or multiple meanings, namely mention senses, and each sense corresponds to an entity. Furthermore, we assume that different mentions referring to the same entity express the same meaning and share a common mention sense embedding, which largely reduces the size of mention vocabulary to be learned. For example, the mentions Independence Day in d2 and July 4th in d3 have a common mention sense embedding during training since t"
P17-1149,D14-1113,0,0.0387774,"Day (US) (e2 ) with distinct mentions: independence day and July 4th. We observe tens of millions of mentions referring to 5 millions of entities in Wikipedia. To address these issues, we propose to learn multiple embeddings for mentions inspired by the Word Sense Disambiguation (WSD) task (Reisinger and Mooney, 2010; Huang et al., 2012; 1623 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1623–1633 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1149 Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). The basic idea behind it is to consider entities in KBs that can provide a meaning repository of mentions (i.e. words or phrases) in texts. That is, each mention has one or multiple meanings, namely mention senses, and each sense corresponds to an entity. Furthermore, we assume that different mentions referring to the same entity express the same meaning and share a common mention sense embedding, which largely reduces the size of mention vocabulary to be learned. For example, the mentions Independence Day in d2 and July 4th in d3 have a common mention sense embedding"
P17-1149,N15-1026,0,0.14064,"Missing"
P17-1149,N10-1013,0,0.0108623,": Independence Day (US) or a film: Independence Day (film). Second, an entity often has various aliases when mentioned in various contexts, which implies a much larger size of mention vocabulary compared with entities. For example, in Figure 1, the documents d2 and d3 describes the same entity Independence Day (US) (e2 ) with distinct mentions: independence day and July 4th. We observe tens of millions of mentions referring to 5 millions of entities in Wikipedia. To address these issues, we propose to learn multiple embeddings for mentions inspired by the Word Sense Disambiguation (WSD) task (Reisinger and Mooney, 2010; Huang et al., 2012; 1623 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1623–1633 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1149 Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). The basic idea behind it is to consider entities in KBs that can provide a meaning repository of mentions (i.e. words or phrases) in texts. That is, each mention has one or multiple meanings, namely mention senses, and each sense corresponds to an entity. Furthermore,"
P17-1149,C14-1016,0,0.0310231,"ntity Independence Day (US) (e2 ) with distinct mentions: independence day and July 4th. We observe tens of millions of mentions referring to 5 millions of entities in Wikipedia. To address these issues, we propose to learn multiple embeddings for mentions inspired by the Word Sense Disambiguation (WSD) task (Reisinger and Mooney, 2010; Huang et al., 2012; 1623 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1623–1633 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1149 Tian et al., 2014; Neelakantan et al., 2014; Li and Jurafsky, 2015). The basic idea behind it is to consider entities in KBs that can provide a meaning repository of mentions (i.e. words or phrases) in texts. That is, each mention has one or multiple meanings, namely mention senses, and each sense corresponds to an entity. Furthermore, we assume that different mentions referring to the same entity express the same meaning and share a common mention sense embedding, which largely reduces the size of mention vocabulary to be learned. For example, the mentions Independence Day in d2 and July 4th in d3 have a comm"
P17-1149,D15-1174,0,0.0378085,"Bridging Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding Yixin Cao1 , Lifu Huang2 , Heng Ji2 , Xu Chen1 , Juanzi Li1∗ Tsinghua National Laboratory for Information Science and Technology Dept. of Computer Science and Technology, Tsinghua University, China 100084 {caoyixin2011,successcx,lijuanzi2008}@gmail.com 2 Dept. of Computer Science, Rensselaer Polytechnic Institute, USA 12180 {huangl7,jih}@rpi.edu 1 Abstract Networks (DNN). These methods suffer from the problems of expensive training and great limitations on the size of word and entity vocabulary (Han et al., 2016; Toutanova et al., 2015; Wu et al., 2016). The other is to learn word and entity embeddings separately, and then align similar words and entities into a common space with the help of Wikipedia hyperlinks, so that they share similar representations (Wang et al., 2014; Yamada et al., 2016). Integrating text and knowledge into a unified semantic space has attracted significant research interests recently. However, the ambiguity in the common space remains a challenge, namely that the same mention phrase usually refers to various entities. In this paper, to deal with the ambiguity of entity mentions, we propose a novel"
P17-1149,D14-1167,0,0.445264,"gy, Tsinghua University, China 100084 {caoyixin2011,successcx,lijuanzi2008}@gmail.com 2 Dept. of Computer Science, Rensselaer Polytechnic Institute, USA 12180 {huangl7,jih}@rpi.edu 1 Abstract Networks (DNN). These methods suffer from the problems of expensive training and great limitations on the size of word and entity vocabulary (Han et al., 2016; Toutanova et al., 2015; Wu et al., 2016). The other is to learn word and entity embeddings separately, and then align similar words and entities into a common space with the help of Wikipedia hyperlinks, so that they share similar representations (Wang et al., 2014; Yamada et al., 2016). Integrating text and knowledge into a unified semantic space has attracted significant research interests recently. However, the ambiguity in the common space remains a challenge, namely that the same mention phrase usually refers to various entities. In this paper, to deal with the ambiguity of entity mentions, we propose a novel Multi-Prototype Mention Embedding model, which learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base. In addition, we further design an efficient language m"
P17-1149,D13-1136,0,0.0163966,"tative and quantitative analysis demonstrate the high quality of the word, entity and multi-prototype mention embeddings. Using entity linking as a study case, we apply our disambiguation method as well as the multi-prototype mention embeddings on the benchmark dataset, and achieve state-of-the-art performance. 1 Independence Day (film) Text Figure 1: Examples. Jointly learning text and knowledge representations in a unified vector space greatly benefits many Natural Language Processing (NLP) tasks, such as knowledge graph completion (Han et al., 2016; Wang and Li, 2016), relation extraction (Weston et al., 2013), word sense disambiguation (Mancini et al., 2016), entity classification (Huang et al., 2017) and linking (Huang et al., 2015). Existing work can be roughly divided into two categories. One is encoding words and entities into a unified vector space using Deep Neural Corresponding author. e1 uses alien technology… m1 e2 Independence Day (US) … holds annual Independence m2 d2 Day celebrations and other Knowledge Base festivals … … bands played it during Mention d3 public events, such as July 4th m1 Independence Day celebrations. m2 July 4th Introduction ∗ Entity … action film &apos;&apos;Independence d1"
P17-1149,K16-1025,0,0.381344,"sity, China 100084 {caoyixin2011,successcx,lijuanzi2008}@gmail.com 2 Dept. of Computer Science, Rensselaer Polytechnic Institute, USA 12180 {huangl7,jih}@rpi.edu 1 Abstract Networks (DNN). These methods suffer from the problems of expensive training and great limitations on the size of word and entity vocabulary (Han et al., 2016; Toutanova et al., 2015; Wu et al., 2016). The other is to learn word and entity embeddings separately, and then align similar words and entities into a common space with the help of Wikipedia hyperlinks, so that they share similar representations (Wang et al., 2014; Yamada et al., 2016). Integrating text and knowledge into a unified semantic space has attracted significant research interests recently. However, the ambiguity in the common space remains a challenge, namely that the same mention phrase usually refers to various entities. In this paper, to deal with the ambiguity of entity mentions, we propose a novel Multi-Prototype Mention Embedding model, which learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base. In addition, we further design an efficient language model based approach to"
P19-1140,C18-1057,1,0.816626,"re 1: Illustration of the structural differences (dashed lines and ellipse) between different KGs. Introduction Knowledge Graphs (KGs) store the world knowledge in the form of directed graphs, where nodes denote entities and edges are their relations. Since it was proposed, many KGs are constructed (e.g., YAGO (Rebele et al., 2016)) to provide structural knowledge for different applications and languages. These KGs usually contain complementary contents, attracting researchers to integrate them into a unified KG, which shall benefit many knowledge driven tasks, such as information extraction (Cao et al., 2018a) and recommendation (Wang et al., 2018a). It is non-trivial to align different KGs due to their distinct surface forms, which makes the symbolic based methods (Suchanek et al., 2011) not always effective. Instead, recent work utilizes general KG embedding methods (e.g., TransE (Bordes et al., 2013)) and align equivalent entities into a unified vector space based on a few seed alignments (Chen et al., 2017; Sun et al., 2017; Zhu et al., 2017; Chen et al., 2018; Sun et al., 2018; Wang et al., 2018b). The assumption is that entities and their counterparts in different KGs should have similar st"
P19-1140,D18-1021,1,0.856141,"re 1: Illustration of the structural differences (dashed lines and ellipse) between different KGs. Introduction Knowledge Graphs (KGs) store the world knowledge in the form of directed graphs, where nodes denote entities and edges are their relations. Since it was proposed, many KGs are constructed (e.g., YAGO (Rebele et al., 2016)) to provide structural knowledge for different applications and languages. These KGs usually contain complementary contents, attracting researchers to integrate them into a unified KG, which shall benefit many knowledge driven tasks, such as information extraction (Cao et al., 2018a) and recommendation (Wang et al., 2018a). It is non-trivial to align different KGs due to their distinct surface forms, which makes the symbolic based methods (Suchanek et al., 2011) not always effective. Instead, recent work utilizes general KG embedding methods (e.g., TransE (Bordes et al., 2013)) and align equivalent entities into a unified vector space based on a few seed alignments (Chen et al., 2017; Sun et al., 2017; Zhu et al., 2017; Chen et al., 2018; Sun et al., 2018; Wang et al., 2018b). The assumption is that entities and their counterparts in different KGs should have similar st"
P19-1140,P17-1149,1,0.846504,"rom YAGO3 to DBpedia are grounded to 92,923 new ground rule triples, which is shocking and not informative. Further investigation finds that the rule (a, team, b) ⇒ (a, affiliation, b) alone contributes 92,743 ground rule triples. Although the rule is logically correct, it is suspicious such a rule that establishes similar relations between entities would benefit entity alignment. We will deal with such noise in future. 6 Related Work Merging different KGs into a unified one has attracted much attention since it shall benefit many Knowledge-driven applications, such as information extraction (Cao et al., 2017a, 2018b), question answering (Zhang et al., 2015) and recommendation (Cao et al., 2019). Early approaches for entity alignment leverage various features to overcome the heterogeneity between KGs, such as machine translation and external lexicons (Suchanek et al., 2011; Wang et al., 2013). Following the success of KG representation learning, recent work embeds entities in different KGs into a low-dimensional vector space with the help of seed alignments (Chen et al., 2017). However, the limited seeds and structural differences take great negative impacts on the quality of KG embeddings, which"
P19-1140,D15-1077,1,0.879704,"Missing"
P19-1140,I17-1024,1,0.8572,"rom YAGO3 to DBpedia are grounded to 92,923 new ground rule triples, which is shocking and not informative. Further investigation finds that the rule (a, team, b) ⇒ (a, affiliation, b) alone contributes 92,743 ground rule triples. Although the rule is logically correct, it is suspicious such a rule that establishes similar relations between entities would benefit entity alignment. We will deal with such noise in future. 6 Related Work Merging different KGs into a unified one has attracted much attention since it shall benefit many Knowledge-driven applications, such as information extraction (Cao et al., 2017a, 2018b), question answering (Zhang et al., 2015) and recommendation (Cao et al., 2019). Early approaches for entity alignment leverage various features to overcome the heterogeneity between KGs, such as machine translation and external lexicons (Suchanek et al., 2011; Wang et al., 2013). Following the success of KG representation learning, recent work embeds entities in different KGs into a low-dimensional vector space with the help of seed alignments (Chen et al., 2017). However, the limited seeds and structural differences take great negative impacts on the quality of KG embeddings, which"
P19-1140,D18-1032,0,0.1473,"fferences (dashed lines and ellipse) between different KGs. Introduction Knowledge Graphs (KGs) store the world knowledge in the form of directed graphs, where nodes denote entities and edges are their relations. Since it was proposed, many KGs are constructed (e.g., YAGO (Rebele et al., 2016)) to provide structural knowledge for different applications and languages. These KGs usually contain complementary contents, attracting researchers to integrate them into a unified KG, which shall benefit many knowledge driven tasks, such as information extraction (Cao et al., 2018a) and recommendation (Wang et al., 2018a). It is non-trivial to align different KGs due to their distinct surface forms, which makes the symbolic based methods (Suchanek et al., 2011) not always effective. Instead, recent work utilizes general KG embedding methods (e.g., TransE (Bordes et al., 2013)) and align equivalent entities into a unified vector space based on a few seed alignments (Chen et al., 2017; Sun et al., 2017; Zhu et al., 2017; Chen et al., 2018; Sun et al., 2018; Wang et al., 2018b). The assumption is that entities and their counterparts in different KGs should have similar structures and thus similar embeddings. Ho"
P19-1140,D16-1019,0,0.0312459,"ly, and γ1 &gt; 0 and γ2 &gt; 0 are margin hyper-parameters separating positive and negative entity and relation alignments. During the experiments, by calculating cosine similarity, we select 25 entities closest to the corresponding entity in the same KG as negative samples (Sun et al., 2018). Negative samples will be re-calculated every 5 epochs. 1456 Rule Knowledge Constraints Since we have changed the KG structure by adding new triplets (i.e., grounded rules), we also introduce the triplet loss to hold the grounded rules as valid in the unified vector space. Taking KG G as an example, following Guo et al. (2016), we define the loss function as follows: Lr = X X [γr − I(g + ) + I(g − )]+ g + ∈G(K)g − ∈G − (K) + X X are extracted from multilingual DBpedia and include 15,000 entity pairs as seed alignments. DWY100K consists of two large-scale crossresource datasets: DWY-WD (DBpedia to Wikidata) and DWY-YG (DBpedia to YAGO3). Each dataset includes 100,000 alignments of entities in advance. As for the seed alignments of relations, we employ the official relation alignment list published by DBpedia for DWY100K. As for DWY-YG, we manually align the relations because there are only a small set of relation ty"
P19-1421,P18-2023,0,0.0152933,"n correlation coefficient is applied to assess inter-annotator agreement. A candidate is labeled as a related concept only if the two annotators are in agreement. For each dataset, we split it into training (400), validation (200) and test set (200). Table 1 presents the detailed statistics, where #courses, #videos, |M|, 1-Label and 0-Label are the number of courses, videos, course concepts, positive and negative labels. We can only obtain #deletions from game for Chinese datasets. 4.2 Experiment Settings Basic Setting. We choose GloVe (Pennington et al., 2014) as our English word embedding, (Li et al., 2018) as our Chinese word embedding. We 10 The datasets will be publicly available later. The three courses: Algorithms (Princeton), Algorithms (Stanford), Data Structure and Algorithm (UC San Diego). 11 DSA ZH EN 1 3 490 465 305 201 398 232 402 568 0.696 0.734 6939 - PSY ZH EN 1 1 57 478 575 470 237 246 563 554 0.712 0.681 4920 - Table 1: Datasets Statistics follow the same process of (Cho et al., 2014) to train the path encoder and (Pan et al., 2017a) to get prerequisite features for classifier in Section 3.2. Baseline Methods. We compare our models (simple candidate generation results denoted as"
P19-1421,P10-2066,0,0.0545836,"to involve human interactions. How to properly leverage the feedback from MOOC users to obtain a better performance for concept expansion remains a challenging issue. To address the above problems, we propose a three-stage course concept expansion model. Inspired by the idea of concept space (Hori, 1997), we first build an accurate boundary for a given course to alleviate the semantic drift during candidate concept generation from an external knowledge base. Then we transform the expansion into a binary classification problem as previous positive unlabeled learning methods for set expansion (Li et al., 2010; Wang et al., 2017). Three types of features are proposed to incorporate heterogeneous information into classifier to identify high-quality concepts among candidates. Finally, we design a lightweight but attractive top-student game to subtly collect MOOC users’ feedback and iteratively optimize the expansion results. For evaluation, we compare the proposed method with 4 representative set expansion methods on real courses from Coursera and XuetangX, and further conduct online evaluation in the game mechanism. Contributions. Our contributions include: a) the first attempt, to the best of our k"
P19-1421,D15-1193,0,0.365065,"Missing"
P19-1421,D18-2004,0,0.125422,"Missing"
P19-1421,P17-1133,1,0.64153,"ch tree that achieves an O(log log n) competitive ratio. (Demaine et al., 2007) 1 MOOCs, teachers need to keep a moderate length of the course to face with thousands of students with various backgrounds (Jordan, 2015), making it infeasible to manually pick out these helpful concepts. Therefore, there is a clear need to automatically identify course-related concepts, so that the students can easily acquire additional knowledge and achieve better educational outcomes. Although much work concerned with extracting course concepts from teaching materials (Kay and Holden, 2002) or course subtitles (Pan et al., 2017b) has been done, the research in finding the concepts absent in course materials, which we call Course Concept Expansion, has not been explored. Despite abundant work on related topics, including concept expansion or set expansion (Wang and Cohen, 2007; Wang et al., 2015; Adrian and Manna, 2018), it is far from sufficient to directly apply these methods in the MOOC environments due to the following challenges. First, unlike the set expansion for a clear general category (e.g., country), course concepts are often the combinations of multiple categories, which is easy to cause semantic drift (C"
P19-1421,I17-1088,1,0.371848,"ch tree that achieves an O(log log n) competitive ratio. (Demaine et al., 2007) 1 MOOCs, teachers need to keep a moderate length of the course to face with thousands of students with various backgrounds (Jordan, 2015), making it infeasible to manually pick out these helpful concepts. Therefore, there is a clear need to automatically identify course-related concepts, so that the students can easily acquire additional knowledge and achieve better educational outcomes. Although much work concerned with extracting course concepts from teaching materials (Kay and Holden, 2002) or course subtitles (Pan et al., 2017b) has been done, the research in finding the concepts absent in course materials, which we call Course Concept Expansion, has not been explored. Despite abundant work on related topics, including concept expansion or set expansion (Wang and Cohen, 2007; Wang et al., 2015; Adrian and Manna, 2018), it is far from sufficient to directly apply these methods in the MOOC environments due to the following challenges. First, unlike the set expansion for a clear general category (e.g., country), course concepts are often the combinations of multiple categories, which is easy to cause semantic drift (C"
P19-1421,D17-1059,0,0.371902,"interactions. How to properly leverage the feedback from MOOC users to obtain a better performance for concept expansion remains a challenging issue. To address the above problems, we propose a three-stage course concept expansion model. Inspired by the idea of concept space (Hori, 1997), we first build an accurate boundary for a given course to alleviate the semantic drift during candidate concept generation from an external knowledge base. Then we transform the expansion into a binary classification problem as previous positive unlabeled learning methods for set expansion (Li et al., 2010; Wang et al., 2017). Three types of features are proposed to incorporate heterogeneous information into classifier to identify high-quality concepts among candidates. Finally, we design a lightweight but attractive top-student game to subtly collect MOOC users’ feedback and iteratively optimize the expansion results. For evaluation, we compare the proposed method with 4 representative set expansion methods on real courses from Coursera and XuetangX, and further conduct online evaluation in the game mechanism. Contributions. Our contributions include: a) the first attempt, to the best of our knowledge, systematic"
P19-1421,D14-1162,0,0.0960387,"ledge. Thus, each dataset is doubly annotated, and pearson correlation coefficient is applied to assess inter-annotator agreement. A candidate is labeled as a related concept only if the two annotators are in agreement. For each dataset, we split it into training (400), validation (200) and test set (200). Table 1 presents the detailed statistics, where #courses, #videos, |M|, 1-Label and 0-Label are the number of courses, videos, course concepts, positive and negative labels. We can only obtain #deletions from game for Chinese datasets. 4.2 Experiment Settings Basic Setting. We choose GloVe (Pennington et al., 2014) as our English word embedding, (Li et al., 2018) as our Chinese word embedding. We 10 The datasets will be publicly available later. The three courses: Algorithms (Princeton), Algorithms (Stanford), Data Structure and Algorithm (UC San Diego). 11 DSA ZH EN 1 3 490 465 305 201 398 232 402 568 0.696 0.734 6939 - PSY ZH EN 1 1 57 478 575 470 237 246 563 554 0.712 0.681 4920 - Table 1: Datasets Statistics follow the same process of (Cho et al., 2014) to train the path encoder and (Pan et al., 2017a) to get prerequisite features for classifier in Section 3.2. Baseline Methods. We compare our model"
P19-1421,W12-2037,0,0.0227967,"as input and output the same sequence. Thus, we can obtain a fixed-length vector representation of path(e) from the final hidden state of the RNN encoder. Prerequisite Features. The course concepts also have an unique relationship called Prerequisite (Margolis and Laurence, 1999). Prerequisite concept pair (A, B) means if someone wants to study A, he/she is better to understand B in advance (e.g., Binary Tree is a prerequisite concept to Black-Red Tree), which indicates how concepts in the course are connected. There are a few previous efforts to extract prerequisite relations from Wikipedia (Talukdar and Cohen, 2012; Liang et al., 2015), textbooks (Yosef et al., 2011; Wang et al., 2016) and MOOCs (Pan et al., 2017a). In this paper, we select five features from (Pan et al., 2017a) that only rely on the course text, and P v(a, b) is the combination of these five features reflecting the prerequisite likelihood of a to b. Since these features can only measure the relationship between the two concepts that exist in the course, we calculate the prerequisite feature of e 4295 concept ei ’s (denoted as del(ei )). using its search root phrasePci as follows: cos he, ci i ∗ P f (e) = cj ∈M P v(ci , cj ) |M| (2) Par"
W03-1712,P98-1013,0,0.0220879,"Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (Miller et al., 1993) and Chinese HowNet (Dong and Dong, 2001). For Chinese, many attentions have been naturally paid to researches on semantics, because Chinese is a meaning-combined language, its syntax"
W03-1712,P00-1033,0,0.0277277,"g and comparing kinds of parsing models. At present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge. For example, the Penn Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (M"
W03-1712,J93-2004,0,0.0342503,"ncy is addressed, and congruence is defined to measure the consistency of tagged corpus.. Finally, we will compare our corpus with other well-known corpora. 1 Introduction As basic research tools for investigators in natural language processing, large annotated corpora play an important role in investigating diverse language phenomena, building statistical language models, evaluating and comparing kinds of parsing models. At present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge. For example, the Penn Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which prod"
W03-1712,C92-4194,0,\N,Missing
W03-1712,C98-1013,0,\N,Missing
