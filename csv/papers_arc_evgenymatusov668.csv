2021.iwslt-1.5,Without Further Ado: Direct and Simultaneous Speech Translation by {A}pp{T}ek in 2021,2021,-1,-1,4,0.952381,5733,parnia bahar,Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021),0,"This paper describes the offline and simultaneous speech translation systems developed at AppTek for IWSLT 2021. Our offline ST submission includes the direct end-to-end system and the so-called posterior tight integrated model, which is akin to the cascade system but is trained in an end-to-end fashion, where all the cascaded modules are end-to-end models themselves. For simultaneous ST, we combine hybrid automatic speech recognition with a machine translation approach whose translation policy decisions are learned from statistical word alignments. Compared to last year, we improve general quality and provide a wider range of quality/latency trade-offs, both due to a data augmentation method making the MT model robust to varying chunk sizes. Finally, we present a method for ASR output segmentation into sentences that introduces a minimal additional delay."
2020.iwslt-1.3,Start-Before-End and End-to-End: Neural Speech Translation by {A}pp{T}ek and {RWTH} {A}achen {U}niversity,2020,-1,-1,6,0.952381,5733,parnia bahar,Proceedings of the 17th International Conference on Spoken Language Translation,0,"AppTek and RWTH Aachen University team together to participate in the offline and simultaneous speech translation tracks of IWSLT 2020. For the offline task, we create both cascaded and end-to-end speech translation systems, paying attention to careful data selection and weighting. In the cascaded approach, we combine high-quality hybrid automatic speech recognition (ASR) with the Transformer-based neural machine translation (NMT). Our end-to-end direct speech translation systems benefit from pretraining of adapted encoder and decoder components, as well as synthetic data and fine-tuning and thus are able to compete with cascaded systems in terms of MT quality. For simultaneous translation, we utilize a novel architecture that makes dynamic decisions, learned from parallel data, to determine when to continue feeding on input or generate output words. Experiments with speech and text input show that even at low latency this architecture leads to superior translation results."
2020.iwslt-1.29,Neural Simultaneous Speech Translation Using Alignment-Based Chunking,2020,-1,-1,3,1,5734,patrick wilken,Proceedings of the 17th International Conference on Spoken Language Translation,0,"In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between latency and quality. We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words. The model is composed of two main components: one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. We train the components jointly and in a manner consistent with the inference conditions. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input. Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7{\%} BLEU absolute."
2020.amta-user.10,Flexible Customization of a Single Neural Machine Translation System with Multi-dimensional Metadata Inputs,2020,-1,-1,1,1,5736,evgeny matusov,Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 2: User Track),0,None
W19-7302,The Challenges of Using Neural Machine Translation for Literature,2019,-1,-1,1,1,5736,evgeny matusov,Proceedings of the Qualities of Literary Machine Translation,0,None
W19-5209,Customizing Neural Machine Translation for Subtitling,2019,0,2,1,1,5736,evgeny matusov,Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers),0,"In this work, we customized a neural machine translation system for translation of subtitles in the domain of entertainment. The neural translation model was adapted to the subtitling content and style and extended by a simple, yet effective technique for utilizing inter-sentence context for short sentences such as dialog turns. The main contribution of the paper is a novel subtitle segmentation algorithm that predicts the end of a subtitle line given the previous word-level context using a recurrent neural network learned from human segmentation decisions. This model is combined with subtitle length and duration constraints established in the subtitling industry. We conducted a thorough human evaluation with two post-editors (English-to-Spanish translation of a documentary and a sitcom). It showed a notable productivity increase of up to 37{\%} as compared to translating from scratch and significant reductions in human translation edit rate in comparison with the post-editing of the baseline non-adapted system without a learned segmentation model."
W18-6530,Generating {E}-Commerce Product Titles and Predicting their Quality,2018,0,3,8,0,27677,jose souza,Proceedings of the 11th International Conference on Natural Language Generation,0,"E-commerce platforms present products using titles that summarize product information. These titles cannot be created by hand, therefore an algorithmic solution is required. The task of automatically generating these titles given noisy user provided titles is one way to achieve the goal. The setting requires the generation process to be fast and the generated title to be both human-readable and concise. Furthermore, we need to understand if such generated titles are usable. As such, we propose approaches that (i) automatically generate product titles, (ii) predict their quality. Our approach scales to millions of products and both automatic and human evaluations performed on real-world data indicate our approaches are effective and applicable to existing e-commerce scenarios."
P18-2052,Learning from Chunk-based Feedback in Neural Machine Translation,2018,10,0,3,0,5803,pavel petrushkov,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We empirically investigate learning from partial feedback in neural machine translation (NMT), when partial feedback is collected by asking users to highlight a correct chunk of a translation. We propose a simple and effective way of utilizing such feedback in NMT training. We demonstrate how the common machine translation problem of domain mismatch between training and deployment can be reduced solely based on chunk-level user feedback. We conduct a series of simulation experiments to test the effectiveness of the proposed method. Our results show that chunk-level feedback outperforms sentence based feedback by up to 2.61{\%} BLEU absolute."
N18-3012,Can Neural Machine Translation be Improved with User Feedback?,2018,0,4,3,0,1027,julia kreutzer,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",0,"We present the first real-world application of methods for improving neural machine translation (NMT) with human reinforcement, based on explicit and implicit user feedback collected on the eBay e-commerce platform. Previous work has been confined to simulation experiments, whereas in this paper we work with real logged feedback for offline bandit learning of NMT parameters. We conduct a thorough analysis of the available explicit user judgments{---}five-star ratings of translation quality{---}and show that they are not reliable enough to yield significant improvements in bandit learning. In contrast, we successfully utilize implicit task-based feedback collected in a cross-lingual search task to improve task-specific and machine translation quality metrics."
W17-2004,Human Evaluation of Multi-modal Neural Machine Translation: A Case-Study on {E}-Commerce Listing Titles,2017,25,2,3,0,4092,iacer calixto,Proceedings of the Sixth Workshop on Vision and Language,0,"In this paper, we study how humans perceive the use of images as an additional knowledge source to machine-translate user-generated product listings in an e-commerce company. We conduct a human evaluation where we assess how a multi-modal neural machine translation (NMT) model compares to two text-only approaches: a conventional state-of-the-art attention-based NMT and a phrase-based statistical machine translation (PBSMT) model. We evaluate translations obtained with different systems and also discuss the data set of user-generated product listings, which in our case comprises both product listings and associated images. We found that humans preferred translations obtained with a PBSMT system to both text-only and multi-modal NMT over 56{\%} of the time. Nonetheless, human evaluators ranked translations from a multi-modal NMT model as better than those of a text-only NMT over 88{\%} of the time, which suggests that images do help NMT in this use-case."
E17-2101,Using Images to Improve Machine-Translating {E}-Commerce Product Listings.,2017,25,5,3,0,4092,iacer calixto,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"In this paper we study the impact of using images to machine-translate user-generated e-commerce product listings. We study how a multi-modal Neural Machine Translation (NMT) model compares to two text-only approaches: a conventional state-of-the-art attentional NMT and a Statistical Machine Translation (SMT) model. User-generated product listings often do not constitute grammatical or well-formed sentences. More often than not, they consist of the juxtaposition of short phrases or keywords. We train our models end-to-end as well as use text-only and multi-modal NMT models for re-ranking $n$-best lists generated by an SMT model. We qualitatively evaluate our user-generated training data also analyse how adding synthetic data impacts the results. We evaluate our models quantitatively using BLEU and TER and find that (i) additional synthetic data has a general positive impact on text-only and multi-modal NMT models, and that (ii) using a multi-modal NMT model for re-ranking n-best lists improves TER significantly across different n-best list sizes."
D17-1148,Neural Machine Translation Leveraging Phrase-based Models in a Hybrid Search,2017,19,5,2,0,13895,leonard dahlmann,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we introduce a hybrid search for attention-based neural machine translation (NMT). A target phrase learned with statistical MT models extends a hypothesis in the NMT beam search when the attention of the NMT model focuses on the source words translated by this phrase. Phrases added in this way are scored with the NMT model, but also with SMT features including phrase-level translation probabilities and a target language model. Experimental results on German-to-English news domain and English-to-Russian e-commerce domain translation tasks show that using phrase-based models in NMT search improves MT quality by up to 2.3{\%} BLEU absolute as compared to a strong NMT baseline."
2016.amta-researchers.10,Guided Alignment Training for Topic-Aware Neural Machine Translation,2016,20,35,2,0,4648,wenhu chen,Conferences of the Association for Machine Translation in the Americas: MT Researchers' Track,0,"In this paper, we propose an effective way for biasing the attention mechanism of a sequence-to-sequence neural machine translation (NMT) model towards the well-studied statistical word alignment models. We show that our novel guided alignment training approach improves translation quality on real-life e-commerce texts consisting of product titles and descriptions, overcoming the problems posed by many unknown words and a large type/token ratio. We also show that meta-data associated with input texts such as topic or category information can significantly improve translation quality when used as an additional signal to the decoder part of the network. With both novel features, the BLEU score of the NMT system on a product title set improves from 18.6 to 21.3{\%}. Even larger MT quality gains are obtained through domain adaptation of a general domain NMT system to e-commerce data. The developed NMT system also performs well on the IWSLT speech translation task, where an ensemble of four variant systems outperforms the phrase-based baseline by 2.1{\%} BLEU absolute."
W13-2219,Omnifluent {E}nglish-to-{F}rench and {R}ussian-to-{E}nglish Systems for the 2013 {W}orkshop on {S}tatistical {M}achine {T}ranslation,2013,9,3,1,1,5736,evgeny matusov,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes Omnifluent TM Translate xe2x80x90 a state-of-the-art hybrid MT system capable of high-quality, high-speed translations of text and speech. The system participated in the English-to-French and Russian-to-English WMT evaluation tasks with competitive results. The features which contributed the most to high translation quality were training data sub-sampling methods, document-specific models, as well as rule-based morphological normalization for Russian. The latter improved the baseline Russian-to-English BLEU score from 30.1 to 31.3% on a heldout test set."
P13-2073,Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation,2013,27,23,4,0,25936,ahmed kholy,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs. One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations. In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT. The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table. We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study."
I13-1167,Selective Combination of Pivot and Direct Statistical Machine Translation Models,2013,35,7,4,0,25936,ahmed kholy,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"In this paper, we propose a selective combination approach of pivot and direct statistical machine translation (SMT) models to improve translation quality. We work with Persian-Arabic SMT as a case study. We show positive results (from 0.4 to 3.1 BLEU on different direct training corpus sizes) in addition to a large reduction of pivot translation model size."
2012.amta-commercial.11,Incremental Re-Training of a Hybrid {E}nglish-{F}rench {MT} System with Customer Translation Memory Data,2012,-1,-1,1,1,5736,evgeny matusov,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Commercial MT User Program,0,"In this paper, we present SAIC{'}s hybrid machine translation (MT) system and show how it was adapted to the needs of our customer {--} a major global fashion company. The adaptation was performed in two ways: off-line selection of domain-relevant parallel and monolingual data from a background database, as well as on-line incremental adaptation with customer parallel and translation memory data. The translation memory was integrated into the statistical search using two novel features. We show that these features can be used to produce nearly perfect translations of data that fully or to a large extent partially matches the TM entries, without sacrificing on the translation quality of the data without TM matches. We also describe how the human post-editing effort was reduced due to significantly better MT quality after adaptation, but also due to improved formatting and readability of the MT output."
2010.iwslt-evaluation.2,{A}pp{T}ek{'}s {APT} machine translation system for {IWSLT} 2010,2010,0,4,1,1,5736,evgeny matusov,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we describe AppTek{'}s new APT machine translation system that we employed in the IWSLT 2010 evaluation campaign. This year, we participated in the Arabic-to-English and Turkish-to-English BTEC tasks. We discuss the architecture of the system, the preprocessing steps and the experiments carried out during the campaign. We show that competitive translation quality can be obtained with a system that can be turned into a real-life product without much effort."
2010.amta-papers.29,Improving Reordering in Statistical Machine Translation from {F}arsi,2010,-1,-1,1,1,5736,evgeny matusov,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In this paper, we propose a novel model for scoring reordering in phrase-based statistical machine translation (SMT) and successfully use it for translation from Farsi into English and Arabic. The model replaces the distance-based distortion model that is widely used in most SMT systems. The main idea of the model is to penalize each new deviation from the monotonic translation path. We also propose a way for combining this model with manually created reordering rules for Farsi which try to alleviate the difference in sentence structure between Farsi and English/Arabic by changing the position of the verb. The rules are used in the SMT search as soft constraints. In the experiments on two general-domain translation tasks, the proposed penalty-based model improves the BLEU score by up to 1.5{\%} absolute as compared to the baseline of monotonic translation, and up to 1.2{\%} as compared to using the distance-based distortion model."
W09-0407,The {RWTH} System Combination System for {WMT} 2009,2009,18,20,2,1,29312,gregor leusch,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"RWTH participated in the System Combination task of the Fourth Workshop on Statistical Machine Translation (WMT 2009). Hypotheses from 9 Germanxe2x86x92English MT systems were combined into a consensus translation. This consensus translation scored 2.1% better in Bleu and 2.3% better in Ter (abs.) than the best single system. In addition, cross-lingual output from 10 French, German, and Spanishxe2x86x92English systems was combined into a consensus translation, which gave an improvement of 2.0% in Bleu/3.5% in Ter (abs.) over the best single system."
W09-0410,The {RWTH} Machine Translation System for {WMT} 2009,2009,40,10,4,0,5059,maja popovic,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"RWTH participated in the shared translation task of the Fourth Workshop of Statistical Machine Translation (WMT 2009) with the German-English, French-English and Spanish-English pair in each translation direction. The submissions were generated using a phrase-based and a hierarchical statistical machine translation systems with appropriate morpho-syntactic enhancements. pos-based reorderings of the source language for the phrase-based systems and splitting of German compounds for both systems were applied. For some tasks, a system combination was used to generate a final hypothesis. An additional English hypothesis was produced by combining all three final systems for translation into English."
2009.eamt-1.31,Are Unaligned Words Important for Machine Translation?,2009,13,9,2,0.952381,7420,yuqi zhang,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"In this paper, we deal with the problem of a large number of unaligned words in automatically learned word alignments for machine translation (MT). These unaligned words are the reason for ambiguous phrase pairs extracted by a statistical phrase-based MT system. In translation, this phrase ambiguity causes deletion and insertion errors. We present hard and optional deletion approaches to remove the unaligned words in the source language sentences. Improvements in translation quality are achieved both on large and small vocabulary tasks with the presented methods."
D08-1088,Complexity of Finding the {BLEU}-optimal Hypothesis in a Confusion Network,2008,14,10,2,1,29312,gregor leusch,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Confusion networks are a simple representation of multiple speech recognition or translation hypotheses in a machine translation system. A typical operation on a confusion network is to find the path which minimizes or maximizes a certain evaluation metric. In this article, we show that this problem is generally NP-hard for the popular BLEU metric, as well as for smaller variants of BLEU. This also holds for more complex representations like generic word graphs. In addition, we give an efficient polynomial-time algorithm to calculate unigram BLEU on confusion networks, but show that even small generalizations of this data structure render the problem to be NP-hard again.n n Since finding the optimal solution is thus not always feasible, we introduce an approximating algorithm based on a multi-stack decoder, which finds a (not necessarily optimal) solution for n-gram BLEU in polynomial time."
C08-1115,Tighter Integration of Rule-Based and Statistical {MT} in Serial System Combination,2008,11,10,3,0,28492,nicola ueffing,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Recent papers have described machine translation (MT) based on an automatic post-editing or serial combination strategy whereby the input language is first translated into the target language by a rule-based MT (RBMT) system, then the target language output is automatically post-edited by a phrase-based statistical machine translation (SMT) system. This approach has been shown to improve MT quality over RBMT or SMT alone. In this previous work, there was a very loose coupling between the two systems: the SMT system only had access to the final 1-best translations from RBMT. Furthermore, the previous work involved European language pairs and relatively small training corpora. In this paper, we describe a more tightly integrated serial combination for the Chinese-to-English MT task. We will present experimental evaluation results on the 2008 NIST constrained data track where a significant gain in terms of both automatic and subjective metrics is achieved through the tighter coupling of the two systems."
2008.iwslt-evaluation.16,The {RWTH} machine translation system for {IWSLT} 2008.,2008,0,6,4,0.714286,5800,david vilar,Proceedings of the 5th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"RWTH{'}s system for the 2008 IWSLT evaluation consists of a combination of different phrase-based and hierarchical statistical machine translation systems. We participated in the translation tasks for the Chinese-to-English and Arabic-to-English language pairs. We investigated different preprocessing techniques, reordering methods for the phrase-based system, including reordering of speech lattices, and syntax-based enhancements for the hierarchical systems. We also tried the combination of the Arabic-to-English and Chinese-to-English outputs as an additional submission."
mauser-etal-2006-training,Training a Statistical Machine Translation System without {GIZA}++,2006,11,3,2,0,42680,arne mauser,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The IBM Models (Brown et al., 1993) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA++ Toolkit (Och and Ney, 2003). Several methods have been developed to overcome the asymmetry of the alignment generated by the IBM Models. A remaining disadvantage, however, is the high model complexity. This paper describes a word alignment training procedure for statistical machine translation that uses a simple and clear statistical model, different from the IBM models. The main idea of the algorithm is to generate a symmetric and monotonic alignment between the target sentence and a permutation graph representing different reorderings of the words in the source sentence. The quality of the generated alignment is shown to be comparable to the standard GIZA++ training in an SMT setup."
E06-1005,Computing Consensus Translation for Multiple Machine Translation Systems Using Enhanced Hypothesis Alignment,2006,14,161,1,1,5736,evgeny matusov,11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper describes a novel method for computing a consensus translation from the outputs of multiple machine translation (MT) systems. The outputs are combined and a possibly new translation hypothesis can be generated. Similarly to the well-established ROVER approach of (Fiscus, 1997) for combining speech recognition hypotheses, the consensus translation is computed by voting on a confusion network. To create the confusion network, we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering. The context of a whole document of translations rather than a single sentence is taken into account to produce the alignment. The proposed alignment and voting approach was evaluated on several machine translation tasks, including a large vocabulary task. The method was also tested in the framework of multi-source and speech translation. On all tasks and conditions, we achieved significant improvements in translation quality, increasing e. g. the BLEU score by as much as 15% relative."
2006.iwslt-papers.1,Automatic sentence segmentation and punctuation prediction for spoken language translation,2006,13,56,1,1,5736,evgeny matusov,Proceedings of the Third International Workshop on Spoken Language Translation: Papers,0,"This paper studies the impact of automatic sentence segmentation and punctuation prediction on the quality of machine translation of automatically recognized speech. We present a novel sentence segmentation method which is specifically tailored to the requirements of machine translation algorithms and is competitive with state-of-the-art approaches for detecting sentence-like units. We also describe and compare three strategies for predicting punctuation in a machine translation framework, including the simple and effective implicit punctuation generation by a statistical phrase-based machine translation system. Our experiments show the robust performance of the proposed sentence segmentation and punctuation prediction approaches on the IWSLT Chinese-to-English and TC-STAR English-to-Spanish speech translation tasks in terms of translation quality."
2006.iwslt-evaluation.15,The {RWTH} statistical machine translation system for the {IWSLT} 2006 evaluation,2006,26,48,3,0,42680,arne mauser,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We give an overview of the RWTH phrase-based statistical machine translation system that was used in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2006. The system was ranked first with respect to the BLEU measure in all language pairs it was used Using a two-pass aproach, we first generate the N best translation candidates. The second pass consists of rescoring and reranking these candidates. We will give a description of the search algorithm as well as of the models used in each pass. We will also describe our method for dealing with punctuation restoration, in order to overcome the difficulties of spoken language translation. This work also includes a brief description of the system combination done by the partners participating in the European TC-Star project."
W05-0831,Novel Reordering Approaches in Phrase-Based Statistical Machine Translation,2005,16,80,3,0,49189,stephan kanthak,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"This paper presents novel approaches to reordering in phrase-based statistical machine translation. We perform consistent reordering of source sentences in training and estimate a statistical translation model. Using this model, we follow a phrase-based monotonic machine translation approach, for which we develop an efficient and flexible reordering framework that allows to easily introduce different reordering constraints. In translation, we apply source sentence reordering on word level and use a reordering automaton as input. We show how to compute reordering automata on-demand using IBM or ITG constraints, and also introduce two new types of reordering constraints. We further add weights to the reordering automata. We present detailed experimental results and show that reordering significantly improves translation quality."
2005.mtsummit-papers.34,Statistical Machine Translation of {E}uropean Parliamentary Speeches,2005,-1,-1,2,0.454545,5800,david vilar,Proceedings of Machine Translation Summit X: Papers,0,"In this paper we present the ongoing work at RWTH Aachen University for building a speech-to-speech translation system within the TC-Star project. The corpus we work on consists of parliamentary speeches held in the European Plenary Sessions. To our knowledge, this is the first project that focuses on speech-to-speech translation applied to a real-life task. We describe the statistical approach used in the development of our system and analyze its performance under different conditions: dealing with syntactically correct input, dealing with the exact transcription of speech and dealing with the (noisy) output of an automatic speech recognition system. Experimental results show that our system is able to perform adequately in each of these conditions."
2005.iwslt-1.18,Integrated {C}hinese Word Segmentation in Statistical Machine Translation,2005,12,36,2,0,4017,jia xu,Proceedings of the Second International Workshop on Spoken Language Translation,0,"A Chinese sentence is represented as a sequence of characters, and words are not separated from each other. In statistical machine translation, the conventional approach is to segment the Chinese character sequence into words during the pre-processing. The training and translation are performed afterwards. However, this method is not optimal for two reasons: 1. The segmentations may be erroneous. 2. For a given character sequence, the best segmentation depends on its context and translation. In order to minimize the translation errors, we take different segmentation alternatives instead of a single segmentation into account and integrate the segmentation process with the search for the best translation. The segmentation decision is only taken during the generation of the translation. With this method we are able to translate Chinese text at the character level. The experiments on the IWSLT 2005 task showed improvements in the translation performance using two translation systems: a phrase-based system and a finite state transducer based system. For the phrase-based system, the improvement of the BLEU score is 1.5% absolute."
2005.iwslt-1.19,Evaluating Machine Translation Output with Automatic Sentence Segmentation,2005,9,44,1,1,5736,evgeny matusov,Proceedings of the Second International Workshop on Spoken Language Translation,0,"This paper presents a novel automatic sentence segmentation method for evaluating machine translation output with possibly erroneous sentence boundaries. The algorithm can process translation hypotheses with segment boundaries which do not correspond to the reference segment boundaries, or a completely unsegmented text stream. Thus, the method is especially useful for evaluating translations of spoken language. The evaluation procedure takes advantage of the edit distance algorithm and is able to handle multiple reference translations. It efficiently produces an optimal automatic segmentation of the hypotheses and thus allows application of existing well-established evaluation measures. Experiments show that the evaluation measures based on the automatically produced segmentation correlate with the human judgement at least as well as the evaluation measures which are based on manual sentence boundaries."
2005.iwslt-1.20,The {RWTH} Phrase-based Statistical Machine Translation System,2005,24,46,5,0.543478,30618,richard zens,Proceedings of the Second International Workshop on Spoken Language Translation,0,"We give an overview of the RWTH phrase-based statistical machine translation system that was used in the evaluation campaign of the International Workshop on Spoken Language Translation 2005. We use a two pass approach. In the first pass, we generate a list of the N best translation candidates. The second pass consists of rescoring and reranking this N -best list. We will give a description of the search algorithm as well as the models that are used in each pass. We participated in the supplied data tracks for manual transcriptions for the following translation directions: Arabic-English, Chinese-English, English-Chinese and Japanese-English. For Japanese-English, we also participated in the C-Star track. In addition, we performed translations of automatic speech recognition output for ChineseEnglish and Japanese-English. For both language pairs, we translated the single-best ASR hypotheses. Additionally, we translated Chinese ASR lattices."
2005.eamt-1.25,Efficient statistical machine translation with constrained reordering,2005,-1,-1,1,1,5736,evgeny matusov,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,None
C04-1006,Improved Word Alignment Using a Symmetric Lexicon Model,2004,11,22,2,0,30618,richard zens,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Word-aligned bilingual corpora are an important knowledge source for many tasks in natural language processing. We improve the well-known IBM alignment models, as well as the Hidden-Markov alignment model using a symmetric lexicon model. This symmetrization takes not only the standard translation direction from source to target into account, but also the inverse translation direction from target to source. We present a theoretically sound derivation of these techniques. In addition to the symmetrization, we introduce a smoothed lexicon model. The standard lexicon model is based on full-form words only. We propose a lexicon smoothing method that takes the word base forms explicitly into account. Therefore, it is especially useful for highly inflected languages such as German. We evaluate these methods on the German-English Verbmobil task and the French-English Canadian Hansards task. We show statistically significant improvements of the alignment quality compared to the best system reported so far. For the Canadian Hansards task, we achieve an improvement of more than 30% relative."
C04-1032,Symmetric Word Alignments for Statistical Machine Translation,2004,11,68,1,1,5736,evgeny matusov,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper, we address the word alignment problem for statistical machine translation. We aim at creating a symmetric word alignment allowing for reliable one-to-many and many-to-one word relationships. We perform the iterative alignment training in the source-to-target and the target-to-source direction with the well-known IBM and HMM alignment models. Using these models, we robustly estimate the local costs of aligning a source word and a target word in each sentence pair. Then, we use efficient graph algorithms to determine the symmetric alignment with minimal total costs (i. e. maximal alignment probability). We evaluate the automatic alignments created in this way on the German--English Verbmobil task and the French--English Canadian Hansards task. We show statistically significant improvements of the alignment quality compared to the best results reported so far. On the Verbmobil task, we achieve an improvement of more than 1% absolute over the baseline error rate of 4.7%."
2004.iwslt-papers.7,Statistical machine translation of spontaneous speech with scarce resources,2004,15,7,1,1,5736,evgeny matusov,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,This paper deals with the task of statistical machine translation of spontaneous speech using a limited amount of training data. We propose a method for selecting relevant additional training data from other sources that may come from other domains. We present two ways to solve the data sparseness problem by including morphological information into the EM training of word alignments. We show that the use of part-of-speech information for harmonizing word order between source and target sentences yields significant improvements in the BLEU score.
2004.iwslt-evaluation.13,Alignment templates: the {RWTH} {SMT} system,2004,18,33,3,0,47115,oliver bender,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we describe the RWTH statistical machine translation (SMT) system which is based on log-linear model combination. All knowledge sources are treated as feature functions which depend on the source language sentence, the target language sentence and possible hidden variables. The main feature of our approach are the alignment templates which take shallow phrase structures into account: a phrase level alignment between phrases and a word level alignment between single words within the phrases. Thereby, we directly consider word contexts and local reorderings. In order to incorporate additional models (the IBM-1 statistical lexicon model, a word deletion model, and higher order language models), we perform n-best list rescoring. Participating in the International Workshop on Spoken Language Translation (IWSLT 2004), we evaluate our system on the Basic Travel Expression Corpus (BTEC) Chinese-to-English and Japanese-to-English tasks."
