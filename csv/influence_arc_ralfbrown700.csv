1994.amta-1.10,H93-1038,1,0.792898,"Missing"
1994.amta-1.10,1993.tmi-1.4,1,0.733597,"Missing"
1995.tmi-1.17,A94-1016,1,0.686167,"Missing"
1996.amta-1.35,C96-1030,1,0.87856,"Missing"
1996.amta-1.35,1995.tmi-1.17,1,0.904059,"Missing"
1996.amta-1.35,A94-1016,1,0.893947,"Missing"
1996.amta-1.35,H94-1005,0,0.213367,"Missing"
1997.mtsummit-systems.9,C96-1030,1,0.80687,"2. MT Technology used in DIPLOMAT The MT component of DIPLOMAT is the Pangloss-Lite (PanLite) system [3]. PanLite is a standalone C++ re-implementation of several major components from the Pangloss machine translation system [7]. Pangloss was a joint project between three sites: the Computing Research Laboratory of New Mexico State University, the Information Sciences Institute of the University of Southern California, and the Center for Machine Translation of Carnegie Mellon University. It was funded by the U.S. Department of Defense. PanLite incorporates the Pangloss Example-Based MT (EBMT) [1] and Transfer-Based MT engines, and its statistical language modeller [2], as well as the newly-implemented iCelos morphological analyzer, within the Multi-Engine MT architecture [4] developed during the course of the Pangloss project (described further below). Due to improved design and the C++ implementation, PanLite runs very quickly. For example, the EBMT engine formerly required several minutes to translate a typical newswire sentence; it now requires under 10 seconds (and this with a much larger corpus). 261 To allow its use in the widest variety of applications, PanLite has been designe"
1997.mtsummit-systems.9,1995.tmi-1.17,1,0.835188,"gloss-Lite (PanLite) system [3]. PanLite is a standalone C++ re-implementation of several major components from the Pangloss machine translation system [7]. Pangloss was a joint project between three sites: the Computing Research Laboratory of New Mexico State University, the Information Sciences Institute of the University of Southern California, and the Center for Machine Translation of Carnegie Mellon University. It was funded by the U.S. Department of Defense. PanLite incorporates the Pangloss Example-Based MT (EBMT) [1] and Transfer-Based MT engines, and its statistical language modeller [2], as well as the newly-implemented iCelos morphological analyzer, within the Multi-Engine MT architecture [4] developed during the course of the Pangloss project (described further below). Due to improved design and the C++ implementation, PanLite runs very quickly. For example, the EBMT engine formerly required several minutes to translate a typical newswire sentence; it now requires under 10 seconds (and this with a much larger corpus). 261 To allow its use in the widest variety of applications, PanLite has been designed to translate strings provided either on the standard input or via netwo"
1997.mtsummit-systems.9,1996.amta-1.35,1,0.281065,"tian-Creole/English and Korean/English systems. The full DIPLOMAT system also involves research in speech understanding and synthesis, as well as wearable computer systems. The speech understanding system used is the well-known SPHINX II HMM-based continuous speech recognition system [5,8]; the speech synthesis system is a newly-developed subword concatenative system [6]. The user interface uses the UNICODE multilingual character encoding standard to facilitate rapid addition of new languages. 2. MT Technology used in DIPLOMAT The MT component of DIPLOMAT is the Pangloss-Lite (PanLite) system [3]. PanLite is a standalone C++ re-implementation of several major components from the Pangloss machine translation system [7]. Pangloss was a joint project between three sites: the Computing Research Laboratory of New Mexico State University, the Information Sciences Institute of the University of Southern California, and the Center for Machine Translation of Carnegie Mellon University. It was funded by the U.S. Department of Defense. PanLite incorporates the Pangloss Example-Based MT (EBMT) [1] and Transfer-Based MT engines, and its statistical language modeller [2], as well as the newly-imple"
1997.mtsummit-systems.9,A94-1016,1,0.807649,"om the Pangloss machine translation system [7]. Pangloss was a joint project between three sites: the Computing Research Laboratory of New Mexico State University, the Information Sciences Institute of the University of Southern California, and the Center for Machine Translation of Carnegie Mellon University. It was funded by the U.S. Department of Defense. PanLite incorporates the Pangloss Example-Based MT (EBMT) [1] and Transfer-Based MT engines, and its statistical language modeller [2], as well as the newly-implemented iCelos morphological analyzer, within the Multi-Engine MT architecture [4] developed during the course of the Pangloss project (described further below). Due to improved design and the C++ implementation, PanLite runs very quickly. For example, the EBMT engine formerly required several minutes to translate a typical newswire sentence; it now requires under 10 seconds (and this with a much larger corpus). 261 To allow its use in the widest variety of applications, PanLite has been designed to translate strings provided either on the standard input or via network sockets, and to produce as output either the best composite string or the full chart of scored alternative"
1997.tmi-1.13,C88-1016,0,0.23682,"Missing"
1997.tmi-1.13,C96-1030,1,0.916193,"Missing"
1997.tmi-1.13,1995.tmi-1.17,1,0.715311,"Missing"
1997.tmi-1.13,1996.amta-1.35,1,0.774626,"Missing"
1997.tmi-1.13,H94-1005,0,0.125381,"Missing"
1997.tmi-1.13,C96-1006,0,0.059497,"Missing"
1997.tmi-1.13,W96-0107,0,0.0404715,"Missing"
1997.tmi-1.13,1992.tmi-1.15,0,0.169583,"Missing"
1997.tmi-1.13,P80-1044,0,0.280624,"Missing"
1997.tmi-1.13,1995.tmi-1.28,0,0.0820832,"Missing"
1999.tmi-1.3,C96-1030,1,0.932908,"se and permitting recursive matches that replace the matched text with the associated tag, substantial reductions in the required amount of pre-translated text can be achieved. A modest investment of time - on the order of two person-weeks - adding linguistic knowledge reduces the required example text by a factor of six or more, while retaining comparable translation quality. This reduction makes EBMT more attractive for so-called &quot;low-density&quot; languages for which little data is available. 1 Introduction The example-based machine translation engine used in the Pangloss and DIPLOMAT projects (Brown 1996) has, until now, been purely lexical. Unlike other EBMT systems which include parsers and perform similarity matching on parse trees (Nagao 1984; Sato 1992), find the most similar complete sentences and modify their stored translations to generate a translation (Veale & Way 1997), or produce an optimal partition of the input (Maruyama & Watanabe 1992; Nirenburg et al. 1993), the DIPLOMAT EBMT engine performs overlapping partial exact matches, finding all occurrences within the example base of any contiguous phrase from the input to be translated. The resulting partial translations of the input"
1999.tmi-1.3,1997.tmi-1.13,1,0.898756,"grammar capturing the most frequent phenomena, generated by a non-linguist, should suffice. As this paper shows, that indeed proves to be the case. 22 2 Method The basic matching algorithm is to search the example base for contiguous occurrences of successive words in the input to be translated, using an inverted index which lists all occurrences for each unique word. In this manner, the largest phrases from the input which are contained in each sentence in the example base are found. For each match, the corresponding translation is determined by performing a word-level alignment (Brown 1996; Brown 1997) of the two halves of the translation example (a process which may fail or produce alignments which are deemed too poor to be usable). This partial exact matching is extended by allowing equivalence classes. Certain words can be used interchangeably, forming an equivalence class such as numbers, weekdays, or country names. Substituting any other member of the equivalence class yields a well-formed (though occasionally semantically anomalous) sentence. Equivalence classes are applied by replacing any matching words or phrases with the name of the equivalence class, appending a disambiguating nu"
1999.tmi-1.3,H93-1038,0,0.0724208,"Missing"
1999.tmi-1.3,H94-1005,0,0.0911653,"of Indexing Translation Example the indexed corpus, the test text was translated and evaluated for both coverage of the input and average match length. Match length serves - in lieu of manual evaluation as an approximate indicator of translation quality, since longer segments include more contextual information and are thus less likely to be translated using the wrong sense. Moreover, longer matches are more likely to be at least partially correct even when the word-level alignment is incorrect. For the Spanish system, the primary source of translation examples is the UN Multilingual Corpus (Graff & Finch 1994). A total of 5397 term/translation pairs in 94 equivalence classes (the bulk of them numbers and names of various kinds, such as days of the week, months, animals, flowers, trees, minerals, chemical elements, companies, organizations, countries, honorifics, political/military ranks, given names, and surnames) were generated and manually translated. Some 450 grammar rules were produced, many derived from an early version of the French grammar rules. To produce a set of entries with morphological information, a file of Spanish words and their morphological analysis that had been produced during"
1999.tmi-1.3,1992.tmi-1.15,0,0.183563,"etaining comparable translation quality. This reduction makes EBMT more attractive for so-called &quot;low-density&quot; languages for which little data is available. 1 Introduction The example-based machine translation engine used in the Pangloss and DIPLOMAT projects (Brown 1996) has, until now, been purely lexical. Unlike other EBMT systems which include parsers and perform similarity matching on parse trees (Nagao 1984; Sato 1992), find the most similar complete sentences and modify their stored translations to generate a translation (Veale & Way 1997), or produce an optimal partition of the input (Maruyama & Watanabe 1992; Nirenburg et al. 1993), the DIPLOMAT EBMT engine performs overlapping partial exact matches, finding all occurrences within the example base of any contiguous phrase from the input to be translated. The resulting partial translations of the input are made available as candidates for use in a multiengine machine translation system (Frederking et al. 1994). While this approach has the advantage of being very quick at run-time and very easy to provide with examples (no linguists are required to build a parser, only translators to generate examples if they are not already available), it has the"
2001.mtsummit-ebmt.1,1999.tmi-1.3,1,0.89912,"ustering techniques to determine equivalence classes of individual words which can be used interchangeably, thus converting translation examples into templates. This paper describes the combination of these two approaches to further increase the coverage (or conversely, decrease the required training text) of an EBMT system. Preliminary results show that a reduction in required training text by a factor of twelve is possible for translation from French into English. 1 Introduction Lexicalist Example-Based Machine Translation (EBMT) systems such as those of Veale and Way (1997) and the author (Brown, 1999) have the advantage that they require little or no additional knowledge beyond the parallel text forming the example base, but the disadvantage that the example base must be quite large to provide good coverage of unrestricted texts. Since parallel texts of the required size are often dicult or (for lessused languages) even impossible to obtain, there have been several e orts to reduce the data needs by generalizing the training examples into templates and then perform template matching (see Figure 1). Three approaches to generalization have been used: manually-generated equivalence classes,"
2001.mtsummit-ebmt.1,C00-1019,1,0.919269,"m template matching (see Figure 1). Three approaches to generalization have been used: manually-generated equivalence classes, automatically-extracted equivalence classes, and transfer-rule induction. The EBMT systems mentioned above both convert translation examples into templates using manually-created information, such as from a machine-readable dictionary with part-of-speech information, to replace words with tokens indicating the class of word which may occur in a particular location. More recently, the author added automatically-generated equivalence classes using word-level clustering (Brown, 2000) and Cicekli and Guvenir (2001) have implemented transfer-rule induction from parallel text. This paper reports the results of combining the latter two approaches, using transfer-rule induction followed by word-level clustering to nd not only single words but also transfer rules which can be combined into equivalence classes. 2 Transfer-Rule Induction To induce a set of grammar rules from a parallel corpus, we make the same assumption used by Cicekli and Guvenir (2000; 2001) and van Zaanen (2000): when two sentence pairs in the corpus have some part in common but di er in some other part, th"
2001.mtsummit-ebmt.1,H94-1005,0,0.0270054,"consisted of a subset (up to 1.1 million words in 19730 sentence pairs) of the Hansard corpus made available by the Linguistic Data Consortium (Linguistic Data Consortium, 1997) and a bilingual dictionary formed by combining the ARTFL French-English dictionary (ARTFL Project, 1998) with a probabilistic dictionary extracted from the Hansard corpus. The test data consisted of 45,320 words of French text from a disjoint portion of the Hansard corpus. The data for the Spanish-English experiments consisted of up to one million words of parallel text drawn primarily from the UN Multilingual Corpus(Gra and Finch, 1994) available from the Linguistic Data Consortium and a bilingual dictionary derived from the Collins Spanish-English Cluster French 507 NE NE 524 SONT FURENT 568 CETTE CETTE 575 PROCHAIN DERNIER 659 UNE UNE UNE UN UN LE LE LE LE LE LA LA LA 678 VALEUR SE CURITE PRODUCTION PLUS NE CESSITE LIVRAISON FA CON DATE CROISSANCE CONSTRUCTION English NOT NO ARE WERE THIS THAT NEXT LAST THE AN A THE A THE OF IT IN A THE OF IN VALUE SECURITY PRODUCTION MORE NEED DELIVERY WAY DATE GROWTH CONSTRUCTION MARKETING COMMERCIALISATION 1085 POINTS POINTS LIVRES POUNDS ANS YEARS 1150 VALABLES VALID TARD LATER 119"
2001.mtsummit-ebmt.1,C00-2139,0,0.100877,"Missing"
2001.mtsummit-ebmt.1,H01-1002,1,0.772907,"Missing"
2001.mtsummit-papers.69,C96-1030,1,0.886417,"Missing"
2001.mtsummit-papers.69,hogan-frederking-1998-evaluation,1,\N,Missing
2001.mtsummit-papers.69,C00-1019,1,\N,Missing
2001.mtsummit-papers.69,H01-1002,1,\N,Missing
2001.mtsummit-road.7,J90-2002,0,0.143628,"Several low-cost or rapid deployment MT methods have been proposed, most of which are data-intensive, depending on the existence of large corpora (Somers 1997; Al-Onaizan et al., 1999). An alternative approach for low-density languages is to learn MT rules or statistics from a smaller amount of data that is systematically elicited from a native speaker (Nirenburg, 1998; Nirenburg and Raskin, 1998; Jones and Havrilla, 1998). The NICE project (Native language Interpretation and Communication Environment) plans to combine into a multi-engine system both corpus-based MT (Al-Onaizan, et al. 1999; Brown, et al. 1990; Brown, 1996) and a new elicitation-based approach for automatic inference of transfer rules when a corpus is not available. Our vision for MT of the future includes an MT system that is omnivorous in the sense that it will use whatever resources (texts, linguists, native speakers) are most readily available and, in the extreme case, can be trained easily by a native speaker. For corpus-based MT, we are using the EBMT engine that was developed for the Diplomat and Tongues systems (Brown, 1996)1. In addition, we plan to develop statistical techniques for robust MT with sparse data using expone"
2001.mtsummit-road.7,C96-1030,1,0.787634,"rapid deployment MT methods have been proposed, most of which are data-intensive, depending on the existence of large corpora (Somers 1997; Al-Onaizan et al., 1999). An alternative approach for low-density languages is to learn MT rules or statistics from a smaller amount of data that is systematically elicited from a native speaker (Nirenburg, 1998; Nirenburg and Raskin, 1998; Jones and Havrilla, 1998). The NICE project (Native language Interpretation and Communication Environment) plans to combine into a multi-engine system both corpus-based MT (Al-Onaizan, et al. 1999; Brown, et al. 1990; Brown, 1996) and a new elicitation-based approach for automatic inference of transfer rules when a corpus is not available. Our vision for MT of the future includes an MT system that is omnivorous in the sense that it will use whatever resources (texts, linguists, native speakers) are most readily available and, in the extreme case, can be trained easily by a native speaker. For corpus-based MT, we are using the EBMT engine that was developed for the Diplomat and Tongues systems (Brown, 1996)1. In addition, we plan to develop statistical techniques for robust MT with sparse data using exponential models a"
2001.mtsummit-road.7,jones-havrilla-1998-twisted,0,0.0712645,"ng indigenous people to give up their languages. MT additionally facilitates the design of educational programs in endangered languages, which can be a tool for their documentation and preservation. Several low-cost or rapid deployment MT methods have been proposed, most of which are data-intensive, depending on the existence of large corpora (Somers 1997; Al-Onaizan et al., 1999). An alternative approach for low-density languages is to learn MT rules or statistics from a smaller amount of data that is systematically elicited from a native speaker (Nirenburg, 1998; Nirenburg and Raskin, 1998; Jones and Havrilla, 1998). The NICE project (Native language Interpretation and Communication Environment) plans to combine into a multi-engine system both corpus-based MT (Al-Onaizan, et al. 1999; Brown, et al. 1990; Brown, 1996) and a new elicitation-based approach for automatic inference of transfer rules when a corpus is not available. Our vision for MT of the future includes an MT system that is omnivorous in the sense that it will use whatever resources (texts, linguists, native speakers) are most readily available and, in the extreme case, can be trained easily by a native speaker. For corpus-based MT, we are u"
2001.mtsummit-road.7,P98-2160,0,0.151102,"the internet without requiring indigenous people to give up their languages. MT additionally facilitates the design of educational programs in endangered languages, which can be a tool for their documentation and preservation. Several low-cost or rapid deployment MT methods have been proposed, most of which are data-intensive, depending on the existence of large corpora (Somers 1997; Al-Onaizan et al., 1999). An alternative approach for low-density languages is to learn MT rules or statistics from a smaller amount of data that is systematically elicited from a native speaker (Nirenburg, 1998; Nirenburg and Raskin, 1998; Jones and Havrilla, 1998). The NICE project (Native language Interpretation and Communication Environment) plans to combine into a multi-engine system both corpus-based MT (Al-Onaizan, et al. 1999; Brown, et al. 1990; Brown, 1996) and a new elicitation-based approach for automatic inference of transfer rules when a corpus is not available. Our vision for MT of the future includes an MT system that is omnivorous in the sense that it will use whatever resources (texts, linguists, native speakers) are most readily available and, in the extreme case, can be trained easily by a native speaker. Fo"
2001.mtsummit-road.7,sheremetyeva-nirenburg-2000-towards,0,0.0663845,"systems can be quickly trained for new languages by native speakers, so that speakers of minor languages can participate in education, health care, government, and internet without having to give up their languages. Keywords Low-density languages, minor languages, feature detection, version space learning 1. Introduction and Motivation Recently, efforts in machine translation have spread in two directions. Long-term, high-cost development cycles have given way to research on how to build MT systems for new languages quickly and cheaply (Somers, 1997; Nirenburg, 1998; Nirenburg & Raskin 1998; Sherematyeva & Nirenburg, 2000, Jones & Havrilla 1998). Rapid deployment of MT can be useful in situations such as crises in which time and money are short, but more importantly, lowering the cost of MT has, in turn, opened the option of building MT systems for languages that do not have enough speakers to financially support a costly development process. (See Frederking, to appear; Frederking, Rudnicky, Hogan 1997; and the SALTMIL discussion group, http://193.2.100.60/SALTMIL). There is now increasing awareness of the importance of MT for low-density languages as a way of providing access to government, education, healthc"
2001.mtsummit-road.7,1997.tc-1.13,0,0.046319,"gorithm. Our vision for MT in the future is one in which systems can be quickly trained for new languages by native speakers, so that speakers of minor languages can participate in education, health care, government, and internet without having to give up their languages. Keywords Low-density languages, minor languages, feature detection, version space learning 1. Introduction and Motivation Recently, efforts in machine translation have spread in two directions. Long-term, high-cost development cycles have given way to research on how to build MT systems for new languages quickly and cheaply (Somers, 1997; Nirenburg, 1998; Nirenburg & Raskin 1998; Sherematyeva & Nirenburg, 2000, Jones & Havrilla 1998). Rapid deployment of MT can be useful in situations such as crises in which time and money are short, but more importantly, lowering the cost of MT has, in turn, opened the option of building MT systems for languages that do not have enough speakers to financially support a costly development process. (See Frederking, to appear; Frederking, Rudnicky, Hogan 1997; and the SALTMIL discussion group, http://193.2.100.60/SALTMIL). There is now increasing awareness of the importance of MT for low-densit"
2001.mtsummit-road.7,C98-2155,0,\N,Missing
2002.amta-tutorials.1,W99-0905,0,\N,Missing
2002.amta-tutorials.1,1987.mtsummit-1.11,0,\N,Missing
2002.amta-tutorials.1,1995.tmi-1.28,0,\N,Missing
2002.amta-tutorials.1,P98-1069,0,\N,Missing
2002.amta-tutorials.1,C98-1066,0,\N,Missing
2002.amta-tutorials.1,C92-2101,0,\N,Missing
2002.amta-tutorials.1,C00-2131,0,\N,Missing
2002.amta-tutorials.1,P95-1033,0,\N,Missing
2002.amta-tutorials.1,C96-1078,0,\N,Missing
2002.amta-tutorials.1,J97-2004,0,\N,Missing
2002.amta-tutorials.1,1993.tmi-1.5,0,\N,Missing
2002.amta-tutorials.1,C96-1030,1,\N,Missing
2002.tmi-papers.3,1997.tmi-1.13,1,0.720485,"requently combines the equivalent of multiple English words into one compound word. If one can decompose the compound words, various other processing and uses of the parallel text will be simplified and/or enhanced. Examples of such applications are information retrieval, where it is used in stemming (Braschler & Sch¨auble 2000), and subsentential alignment as used in statistical and example-based machine translation (Brown et al. 1990; Brown 1999). Any algorithms which assume one-to-one correspondences between words, such as Competitive Linking (Melamed 1997) or automated lexicon extraction (Brown 1997), will also be improved by decompounding of compound words. Finally, text normalization for a variety of applications, such as speech recognition (Adda et al. 1997; Adda-Decker et al. 2000), can benefit from decompounding. In this paper, we will describe a method which takes advantage of the ”cognateness” of portions of a compound word with the corresponding individual words in the other language. We then extend the method to work even when there is no cognate relation, provided that a bilingual lexicon is available or can be statistially extracted from the parallel text. Cognate Letters ae k"
2002.tmi-papers.3,1999.tmi-1.3,1,0.772213,"n, a large proportion of the tokens (typically Latin- or Greek-derived medical terms) in the text can be treated as cognates – except that the German version frequently combines the equivalent of multiple English words into one compound word. If one can decompose the compound words, various other processing and uses of the parallel text will be simplified and/or enhanced. Examples of such applications are information retrieval, where it is used in stemming (Braschler & Sch¨auble 2000), and subsentential alignment as used in statistical and example-based machine translation (Brown et al. 1990; Brown 1999). Any algorithms which assume one-to-one correspondences between words, such as Competitive Linking (Melamed 1997) or automated lexicon extraction (Brown 1997), will also be improved by decompounding of compound words. Finally, text normalization for a variety of applications, such as speech recognition (Adda et al. 1997; Adda-Decker et al. 2000), can benefit from decompounding. In this paper, we will describe a method which takes advantage of the ”cognateness” of portions of a compound word with the corresponding individual words in the other language. We then extend the method to work even w"
2002.tmi-papers.3,P97-1063,0,0.0153066,"as cognates – except that the German version frequently combines the equivalent of multiple English words into one compound word. If one can decompose the compound words, various other processing and uses of the parallel text will be simplified and/or enhanced. Examples of such applications are information retrieval, where it is used in stemming (Braschler & Sch¨auble 2000), and subsentential alignment as used in statistical and example-based machine translation (Brown et al. 1990; Brown 1999). Any algorithms which assume one-to-one correspondences between words, such as Competitive Linking (Melamed 1997) or automated lexicon extraction (Brown 1997), will also be improved by decompounding of compound words. Finally, text normalization for a variety of applications, such as speech recognition (Adda et al. 1997; Adda-Decker et al. 2000), can benefit from decompounding. In this paper, we will describe a method which takes advantage of the ”cognateness” of portions of a compound word with the corresponding individual words in the other language. We then extend the method to work even when there is no cognate relation, provided that a bilingual lexicon is available or can be statistially extracted"
2002.tmi-papers.3,W99-0626,0,0.0615647,"Missing"
2003.mtsummit-papers.4,C96-1030,1,\N,Missing
2003.mtsummit-papers.4,J93-2003,0,\N,Missing
2003.mtsummit-papers.4,J90-2002,0,\N,Missing
2003.mtsummit-papers.4,P02-1040,0,\N,Missing
2003.mtsummit-papers.4,P02-1039,0,\N,Missing
2003.mtsummit-papers.4,P91-1024,0,\N,Missing
2003.mtsummit-papers.4,2001.mtsummit-ebmt.1,1,\N,Missing
2004.eamt-1.5,1999.tmi-1.3,1,0.93927,"eds are presently limited to English and Spanish, one goal of the project is to provide a model that is extensible for use by different agencies in other countries and other domains. Lacking sufficient resources to develop a knowledge- or transfer-based machine translation (MT) system, and requiring an approach that can be quickly adapted to other domains and languages, we chose to use CMU’s Pangloss-Lite (Panlite) MultiEngine Machine Translation (MEMT) system (Frederking & Brown, 1996) and rely primarily on the Example-Based MT engine, which has been undergoing continuous enhancements (e.g., Brown, 1999; Brown, 2000; Brown et al., 2003). Panlite was the underlying translation system in the rapiddeployment speech-to-speech DIPLOMAT project (www.lti.cs.cmu.edu/Research/Diplomat/; Frederking et al., 1997); it therefore seemed to be an ideal choice. Nonetheless, the use of Panlite in the context of this project has been challenging for a variety of reasons. In the first place, the lack of domain-specific parallel data has made it necessary to exercise a great deal of creativity in building the linguistic data resources. Secondly, after the data has been obtained, there are still challenges to be"
2004.eamt-1.5,2003.mtsummit-papers.4,1,0.923673,"to English and Spanish, one goal of the project is to provide a model that is extensible for use by different agencies in other countries and other domains. Lacking sufficient resources to develop a knowledge- or transfer-based machine translation (MT) system, and requiring an approach that can be quickly adapted to other domains and languages, we chose to use CMU’s Pangloss-Lite (Panlite) MultiEngine Machine Translation (MEMT) system (Frederking & Brown, 1996) and rely primarily on the Example-Based MT engine, which has been undergoing continuous enhancements (e.g., Brown, 1999; Brown, 2000; Brown et al., 2003). Panlite was the underlying translation system in the rapiddeployment speech-to-speech DIPLOMAT project (www.lti.cs.cmu.edu/Research/Diplomat/; Frederking et al., 1997); it therefore seemed to be an ideal choice. Nonetheless, the use of Panlite in the context of this project has been challenging for a variety of reasons. In the first place, the lack of domain-specific parallel data has made it necessary to exercise a great deal of creativity in building the linguistic data resources. Secondly, after the data has been obtained, there are still challenges to be met in using and managing the dat"
2004.eamt-1.5,C00-1019,1,0.847125,"ntly limited to English and Spanish, one goal of the project is to provide a model that is extensible for use by different agencies in other countries and other domains. Lacking sufficient resources to develop a knowledge- or transfer-based machine translation (MT) system, and requiring an approach that can be quickly adapted to other domains and languages, we chose to use CMU’s Pangloss-Lite (Panlite) MultiEngine Machine Translation (MEMT) system (Frederking & Brown, 1996) and rely primarily on the Example-Based MT engine, which has been undergoing continuous enhancements (e.g., Brown, 1999; Brown, 2000; Brown et al., 2003). Panlite was the underlying translation system in the rapiddeployment speech-to-speech DIPLOMAT project (www.lti.cs.cmu.edu/Research/Diplomat/; Frederking et al., 1997); it therefore seemed to be an ideal choice. Nonetheless, the use of Panlite in the context of this project has been challenging for a variety of reasons. In the first place, the lack of domain-specific parallel data has made it necessary to exercise a great deal of creativity in building the linguistic data resources. Secondly, after the data has been obtained, there are still challenges to be met in using"
2004.eamt-1.5,1996.amta-1.35,1,0.903197,"to borders with Guatemala and Mexico. The Dominican Republic is primarily and officially Spanish speaking.2,3 While our translation needs are presently limited to English and Spanish, one goal of the project is to provide a model that is extensible for use by different agencies in other countries and other domains. Lacking sufficient resources to develop a knowledge- or transfer-based machine translation (MT) system, and requiring an approach that can be quickly adapted to other domains and languages, we chose to use CMU’s Pangloss-Lite (Panlite) MultiEngine Machine Translation (MEMT) system (Frederking & Brown, 1996) and rely primarily on the Example-Based MT engine, which has been undergoing continuous enhancements (e.g., Brown, 1999; Brown, 2000; Brown et al., 2003). Panlite was the underlying translation system in the rapiddeployment speech-to-speech DIPLOMAT project (www.lti.cs.cmu.edu/Research/Diplomat/; Frederking et al., 1997); it therefore seemed to be an ideal choice. Nonetheless, the use of Panlite in the context of this project has been challenging for a variety of reasons. In the first place, the lack of domain-specific parallel data has made it necessary to exercise a great deal of creativity"
2004.eamt-1.5,H94-1005,0,0.0416755,"l soon run in the Dominican Republic too. The presence of the prototype system at universities will allow our colleagues in the client countries to collect data from actual future users prior to fielding the system at actual ports of entry. It will also give us an opportunity to collect more authentic data. formal documents and some newswire. They diverge widely in content and style from text in our domain and we have found that they provide little translation help. A baseline version of the system, trained on a hand-refined version of the EnglishSpanish United Nations (U.N.) parallel corpus (Graff & Finch, 1994) with some additional parallel text obtained from the Pan American Health Organization (PAHO) and a statistically-derived dictionary based on that corpus, produces translations that are virtually useless in the context of our project, and is particularly ill-suited to the translation of dialogues. If suitable monolingual data were available, it would be possible to create a parallel corpus through manual or semi-automatic translation, but very little of that data is to be found either. In the Dominican Republic, computerized access to a database of traveler information is available at major po"
2004.eamt-1.5,cavalli-sforza-etal-2004-developing,1,\N,Missing
2005.eamt-1.21,1997.tmi-1.13,1,0.813788,"Missing"
2005.eamt-1.21,2003.mtsummit-papers.4,1,0.883484,"Missing"
2005.eamt-1.21,C00-1019,1,0.93939,"Missing"
2005.eamt-1.21,1994.amta-1.10,1,0.69518,"Missing"
2005.eamt-1.21,P02-1040,0,0.0771603,"Missing"
2005.mtsummit-ebmt.2,W03-0301,0,0.0118635,"ropean Parliament texts. The Chinese-English system was trained on slightly less than two million sentence pairs drawn primarily from the UN Chinese-English corpus available from the Linguistic Data Consortium. The test sets were the 993-sentence test set from the 2002 DARPA TIDES Machine Translation Evaluation for tuning and the 919-sentence test set from the 2003 MT Evaluation as unseen data, both primarily newswire text. The Romanian-English system was trained on the parallel corpus provided to participants in the shared word-alignment task for the 2003 and 2005 Workshops on Parallel Text (Mihalcea and Pedersen, 2003), approximately one million words per 5 Results For all four language pairs, each of the two classes of context alone and in combination resulted in improved performance when pitted against the original implementation without context awareness (Table 1). The “real-world” performance on previously-unseen data using the optimal parameters determined on the tuning set was rather mixed (Table 2) for intersentential context and the combination of local and intersentential, but local context still provided a statistically significant improvement in two of three cases (statistically-significant diffe"
2005.mtsummit-ebmt.2,2001.mtsummit-ebmt.1,1,0.845404,"Missing"
2005.mtsummit-ebmt.2,H92-1045,0,0.0877192,"Missing"
2005.mtsummit-ebmt.2,2003.mtsummit-papers.18,0,0.0410473,"Missing"
2007.mtsummit-papers.49,C96-1030,1,0.82196,"hat we go beyond simple phrasal backoff and include rewrite rules that dynamically account for any differences in morphological features. The rewrite rules adapt the English translation in order to more closely match the source text. Lastly, we demonstrate that our technique scales well with the size of training data and provides additional improvement even with a corpus of 1.4 million sentence pairs. Panlite and the EBMT Engine In our research we employ CMU’s Example-Based MT (EBMT) engine (Brown, 2000a) which was developed as part of the The Pangloss-Lite (Panlite) MT system (Frederking and Brown, 1996). Given an input sentence, the EBMT engine retrieves lexical matches from an indexed corpus. These examples, as well as word-for-word translations from a bilingual lexicon, are stored in a lattice from which the final translation is extracted with the help of a language model using a search process equivalent to the decoder in a statistical MT system. BAMA In order to analyze the Arabic text, we use the Buckwalter Arabic Morphological Analyzer (BAMA). This analyzer identifies all possible combinations of stems and affixes for a word. For each analysis the stems and affixes are annotated with t"
2007.mtsummit-papers.49,1999.tmi-1.3,1,0.943943,"Missing"
2007.mtsummit-papers.49,C00-1019,1,0.901042,"ty is explicitly permitted and resolved by the context of the phrasal match. Our approach is novel in that we go beyond simple phrasal backoff and include rewrite rules that dynamically account for any differences in morphological features. The rewrite rules adapt the English translation in order to more closely match the source text. Lastly, we demonstrate that our technique scales well with the size of training data and provides additional improvement even with a corpus of 1.4 million sentence pairs. Panlite and the EBMT Engine In our research we employ CMU’s Example-Based MT (EBMT) engine (Brown, 2000a) which was developed as part of the The Pangloss-Lite (Panlite) MT system (Frederking and Brown, 1996). Given an input sentence, the EBMT engine retrieves lexical matches from an indexed corpus. These examples, as well as word-for-word translations from a bilingual lexicon, are stored in a lattice from which the final translation is extracted with the help of a language model using a search process equivalent to the decoder in a statistical MT system. BAMA In order to analyze the Arabic text, we use the Buckwalter Arabic Morphological Analyzer (BAMA). This analyzer identifies all possible co"
2007.mtsummit-papers.49,1996.amta-1.35,1,0.707195,"h is novel in that we go beyond simple phrasal backoff and include rewrite rules that dynamically account for any differences in morphological features. The rewrite rules adapt the English translation in order to more closely match the source text. Lastly, we demonstrate that our technique scales well with the size of training data and provides additional improvement even with a corpus of 1.4 million sentence pairs. Panlite and the EBMT Engine In our research we employ CMU’s Example-Based MT (EBMT) engine (Brown, 2000a) which was developed as part of the The Pangloss-Lite (Panlite) MT system (Frederking and Brown, 1996). Given an input sentence, the EBMT engine retrieves lexical matches from an indexed corpus. These examples, as well as word-for-word translations from a bilingual lexicon, are stored in a lattice from which the final translation is extracted with the help of a language model using a search process equivalent to the decoder in a statistical MT system. BAMA In order to analyze the Arabic text, we use the Buckwalter Arabic Morphological Analyzer (BAMA). This analyzer identifies all possible combinations of stems and affixes for a word. For each analysis the stems and affixes are annotated with t"
2007.mtsummit-papers.49,P05-1071,0,0.0405995,"t to determine the correct stem. Within the 13 analyses for wktAby there are still 3 possible stems with 4 different meanings. There is also a problem with stem changes, such as in the common broken plurals, which are formed by modifying the stem rather than adding a plural affix. From our example we know that kitAb is book, but the plural form is kutub. Generally, a human can determine the correct word by the meaning and context of a sentence. However, this is a difficult task for a computer. Though there are analyzers that look at the surrounding context and select the most likely analysis (Habash and Rambow, 2005), we would prefer to not make such decisions early on and potentially remove good candidates.4 Instead, we preserve the ambiguity of the analysis and allow the system to select the best one at runtime. Furthermore, not requiring a more advanced analyzer makes the system&apos;s requirements fairly low and the transition to another language much easier. Without a more sophisticated morphological analyzer, we cannot strip the affixes because we do not always know which part of the word is the stem. Even if we could identify the stem, that is not always good enough because sometimes the stem changes fo"
2007.mtsummit-papers.49,N04-4015,0,0.0537866,"inexact matching of morphological features, and adapting the English translation. For example, if we have a phrase where the noun and adjectives are marked for definiteness, we allow it to match the corresponding indefinite phrase (and possibly make a correction by inserting “the” into the English translation). Our method consists of three main parts: 1) generalization, 2) filtering and adaptation, and 3) rescoring. Previous Work Although our approach is new, there have been several attempts to apply an understanding of Arabic morphology to machine translation. (Nießen and Ney, 2000; YoungSuk Lee, 2004; Sadat and Habash, 2006; Zollmann et al., 2006) all present techniques that select a morphological analysis and split the source text in a manner that closely reflects the English translation. The latter three specifically address techniques for Arabic. (Sadat and Habash, 2006) provides additional insight by studying the effect of different morphological preprocessing decisions and the size of the training data. They conclude that an Englishlike segmentation scheme works well in Arabic on small data sets, but for large datasets minimal segmentation -splitting only conjunction clitics and part"
2007.mtsummit-papers.49,C00-2162,0,0.0339481,"c phrases as a whole, allowing inexact matching of morphological features, and adapting the English translation. For example, if we have a phrase where the noun and adjectives are marked for definiteness, we allow it to match the corresponding indefinite phrase (and possibly make a correction by inserting “the” into the English translation). Our method consists of three main parts: 1) generalization, 2) filtering and adaptation, and 3) rescoring. Previous Work Although our approach is new, there have been several attempts to apply an understanding of Arabic morphology to machine translation. (Nießen and Ney, 2000; YoungSuk Lee, 2004; Sadat and Habash, 2006; Zollmann et al., 2006) all present techniques that select a morphological analysis and split the source text in a manner that closely reflects the English translation. The latter three specifically address techniques for Arabic. (Sadat and Habash, 2006) provides additional insight by studying the effect of different morphological preprocessing decisions and the size of the training data. They conclude that an Englishlike segmentation scheme works well in Arabic on small data sets, but for large datasets minimal segmentation -splitting only conjunct"
2007.mtsummit-papers.49,J04-2003,0,0.0274338,"morphological analysis and split the source text in a manner that closely reflects the English translation. The latter three specifically address techniques for Arabic. (Sadat and Habash, 2006) provides additional insight by studying the effect of different morphological preprocessing decisions and the size of the training data. They conclude that an Englishlike segmentation scheme works well in Arabic on small data sets, but for large datasets minimal segmentation -splitting only conjunction clitics and particles -- should be performed. Conceptually, the most similar work to ours is that of (Nießen and Ney, 2004) and (Yang and Kirchhoff, 2006). (Nießen and Ney, 2004) describes a statistical translation system that uses a generalized hierarchical lexicon with morphological features for German-English translation. (Yang and Kirchhoff, 2006) take this one step further and describe a statistical system that generalizes over the phrase table through a back-off model with examples in German-English and Finnish-English translation. However, this latter work only uses stemming and compound splitting. To the best of our knowledge, all published research that addresses morphology in Arabic machine translation h"
2007.mtsummit-papers.49,N06-2013,0,0.0277175,"ching of morphological features, and adapting the English translation. For example, if we have a phrase where the noun and adjectives are marked for definiteness, we allow it to match the corresponding indefinite phrase (and possibly make a correction by inserting “the” into the English translation). Our method consists of three main parts: 1) generalization, 2) filtering and adaptation, and 3) rescoring. Previous Work Although our approach is new, there have been several attempts to apply an understanding of Arabic morphology to machine translation. (Nießen and Ney, 2000; YoungSuk Lee, 2004; Sadat and Habash, 2006; Zollmann et al., 2006) all present techniques that select a morphological analysis and split the source text in a manner that closely reflects the English translation. The latter three specifically address techniques for Arabic. (Sadat and Habash, 2006) provides additional insight by studying the effect of different morphological preprocessing decisions and the size of the training data. They conclude that an Englishlike segmentation scheme works well in Arabic on small data sets, but for large datasets minimal segmentation -splitting only conjunction clitics and particles -- should be perfo"
2007.mtsummit-papers.49,E06-1006,0,0.0610892,"Missing"
2007.mtsummit-papers.49,N06-2051,0,0.0116414,"eatures, and adapting the English translation. For example, if we have a phrase where the noun and adjectives are marked for definiteness, we allow it to match the corresponding indefinite phrase (and possibly make a correction by inserting “the” into the English translation). Our method consists of three main parts: 1) generalization, 2) filtering and adaptation, and 3) rescoring. Previous Work Although our approach is new, there have been several attempts to apply an understanding of Arabic morphology to machine translation. (Nießen and Ney, 2000; YoungSuk Lee, 2004; Sadat and Habash, 2006; Zollmann et al., 2006) all present techniques that select a morphological analysis and split the source text in a manner that closely reflects the English translation. The latter three specifically address techniques for Arabic. (Sadat and Habash, 2006) provides additional insight by studying the effect of different morphological preprocessing decisions and the size of the training data. They conclude that an Englishlike segmentation scheme works well in Arabic on small data sets, but for large datasets minimal segmentation -splitting only conjunction clitics and particles -- should be performed. Conceptually, the"
2008.amta-papers.2,W05-0909,0,0.0555803,"ithm of (Melamed, 1997). 4.3 Performance was evaluated using the mteval-v11b.pl script made available by NIST. This script reports both the BLEU metric (Papineni et al., 2002) and the variant thereof proposed by George Doddington at NIST (Doddington, 2002). Parameters were tuned to maximize the value of the BLEU metric. BLEU measures the proportion of n-gram overlap between the MT system’s output and one or more human reference translations. The NIST metric modifies the n-gram matching to assign different weights to individual n-grams depending on their information content. The METEOR metric (Banerjee and Lavie, 2005) has not yet been integrated into our workflow, but that integration is planned for the near future. The statistical significance of the results was tested with the Wilcoxon Signed-Rank Test (Wilcoxon, 1945), a nonparametric alternative to the paired t-test. Unlike the t-test, the Signed-Rank test does not assume normal distribution of values in the population, nor does it assume that the scale of measurement is an equal-interval scale. To generate the values used for the Signed-Rank test, the test outputs were uniformly split into either 10 or 20 segments, depending on the total number of sen"
2008.amta-papers.2,H94-1028,0,0.0387999,"o be consistently beneficial, inter-sentential context was helpful less often, and the combination of the two bonuses could even harm performance. L¨u et al (2007) applied similar sentence-specific weighting to a Statistical MT (SMT) system. In their offline version, they first select a subcorpus of sentences which are similar to the sentences in the test data or target domain, then boost the weights of selected sentences by increasing their counts within Introduction Corpus-based machine translation systems have made considerable strides since the original Statistical MT (Brown et al., 1990; Berger et al., 1994) and Example-Based MT (Nagao, 1981; Nagao, 1984) systems, but still typically treat both the training data and the test input as isolated, entirely independent sentences. In practice, however, both the training and test data consists of a series of complete documents rather than isolated sentences. While a number of researchers have added contextual information to the translation process in recent years, one area which has not been explored is the use of document-level context to affect the MT system’s translations, This paper presents a method for adjusting phrasal translation scores in an EB"
2008.amta-papers.2,C96-1030,1,0.8287,"Missing"
2008.amta-papers.2,C00-1019,1,0.794637,"for the Signed-Rank test, the test outputs were uniformly split into either 10 or 20 segments, depending on the total number of sentences in the test set, and each segment was individually scored with the mteval script. Bootstrapping as described by (Zhang et al., 2004) was not used because the test sets are sufficiently large to provide enough truly independent samples for statistical significance tests. System Training For the experiments described below, the EBMT system was trained as a straight-forward stringmatching EBMT system, without generalized matching through clustering such as in (Brown, 2000) or structural matching such as in (Phillips et al., 2007). GIZA++ (Al-Onaizan et al., 1999) word alignments were used for the Arabic-English data to drive the subsential aligner; for French-English, 1 Evaluation Metrics 5 Results Tables 1 and 2 present the results of runs for Arabicto-English and French-to-English, respectively. For each data set, the tables show the NIST and BLEU scores of the baseline system (no document boundaries in the input text), the enhanced system with arbitrary uniformly-spaced document boundaries, and Available at http://www.statmt.org/europarl/ 50 [8th AMTA confer"
2008.amta-papers.2,2005.mtsummit-ebmt.2,1,0.651666,"ssary, limit the number of candidate translations for a source-language n-gram to the k top-scoring alternatives 6. place the final translation candidates in a lattice and apply a stack decoder to determine the best overall translation Figure 2: Translation process in pseudo-code locally-weighted bags of words. al (Phillips and Cavalli-Sforza, 2006; Phillips et al., 2007). See Figure 2 for pseudo-code; the boldfaced portions indicate the modifications to support document similarity. The EBMT system used for the experiments described in the next section functions in the same manner as those of Brown (2005) and Phillips et 48 [8th AMTA conference, Hawaii, 21-25 October 2008] search caused by altered scores (runs using document boundaries are occasionally marginally faster than those without). Our method modifies steps 2 and 3(c) in the following ways. In Step 2, the baseline system orders n-gram matches by the number of additional words which match in that training example (the amount of available local context) and selects instances in decreasing order of context until a particular level of context would result in more than maxdups instances. This final level is then uniformly subsampled to pro"
2008.amta-papers.2,2007.tmi-papers.6,0,0.114625,"Missing"
2008.amta-papers.2,W08-0302,0,0.014002,"retrieval query to determine which submodels contain similar sentences and weight each submodel according to the total number of retrieved training sentences. Other researchers have investigated methods of subsampling the training data to generate a test setspecific corpus. One example is the work by Hildebrand et al (2005), which applied information retrieval techniques to select sentences similar to the test set. Such an approach substantially improves performance, but is not suitable for production systems since it requires retraining for each input file desiring adaptation. More recently, Gimpel and Smith (2008) added within-sentence contextual features to phrase-based SMT (Koehn et al., 2003). These contextual features are added to the source-language side of the phrase table, allowing for better prediction of translations without major modifications to the decoder (in fact, Gimpel and Smith were able to avoid modifications entirely by appending a unique identifier to each token of input prior to computing the phrase table). As with Brown’s intra-sentential context, only the current sentence is considered. Statistical MT systems are also becoming more EBMT-like, performing on-the-fly lookups or phra"
2008.amta-papers.2,2005.eamt-1.19,0,0.0563584,"es, or alternative representations such as the entire corpus (effectively appending the selected subcorpus to the training data). For their online variant, they produce several translation models using the offline variant to generate adapted corpora, then use each input sentence as an information retrieval query to determine which submodels contain similar sentences and weight each submodel according to the total number of retrieved training sentences. Other researchers have investigated methods of subsampling the training data to generate a test setspecific corpus. One example is the work by Hildebrand et al (2005), which applied information retrieval techniques to select sentences similar to the test set. Such an approach substantially improves performance, but is not suitable for production systems since it requires retraining for each input file desiring adaptation. More recently, Gimpel and Smith (2008) added within-sentence contextual features to phrase-based SMT (Koehn et al., 2003). These contextual features are added to the source-language side of the phrase table, allowing for better prediction of translations without major modifications to the decoder (in fact, Gimpel and Smith were able to av"
2008.amta-papers.2,N03-1017,0,0.00521976,"submodel according to the total number of retrieved training sentences. Other researchers have investigated methods of subsampling the training data to generate a test setspecific corpus. One example is the work by Hildebrand et al (2005), which applied information retrieval techniques to select sentences similar to the test set. Such an approach substantially improves performance, but is not suitable for production systems since it requires retraining for each input file desiring adaptation. More recently, Gimpel and Smith (2008) added within-sentence contextual features to phrase-based SMT (Koehn et al., 2003). These contextual features are added to the source-language side of the phrase table, allowing for better prediction of translations without major modifications to the decoder (in fact, Gimpel and Smith were able to avoid modifications entirely by appending a unique identifier to each token of input prior to computing the phrase table). As with Brown’s intra-sentential context, only the current sentence is considered. Statistical MT systems are also becoming more EBMT-like, performing on-the-fly lookups or phrase-table generation rather than using a static phrase table. Examples include Vogel"
2008.amta-papers.2,2005.mtsummit-papers.11,0,0.0170256,"ely, index lookups are very quick compared to actually retrieving, aligning, and merging the matches found by the index lookup. The cost of the additional index lookups for each sentence and accumulation of match counts is only a few percent of the total run-time, and is often overshadowed by changes in run-time resulting from differences in the decoder’s 49 [8th AMTA conference, Hawaii, 21-25 October 2008] even when trained on a corpus annotated with document boundaries, since by default every training document is scored equally. For French-English, the training data was the Europarl corpus (Koehn, 2005), version 3 1 . All sentence pairs of the designated training portion were used, except those where the source and target differed by more than a factor of 2.5 in length and the shorter of the two was at least eight tokens in length, or the source sentence exceeded 255 tokens. This provided a total of 1.3 million sentence pairs (43.5 million source tokens) of training data. The language model for the decoder was trained solely on the target half of the parallel corpus. To tune parameters, a 40-sentence subset of the “devtest2006.fr” file was used, consisting of eight contiguous five-sentence g"
2008.amta-papers.2,D07-1036,0,0.0369971,"Missing"
2008.amta-papers.2,P97-1063,0,0.012101,"me development test sets for the WMT08 evaluation. Each of these data sets has a single reference translation. Two versions of the test sets were prepared: one without document boundaries and one with document boundaries arbitrarily placed every five sentences (“test2006”) or every ten sentences (“test2007”) since the original document boundaries were not available. 4.2 we used a much faster heuristic approach driven by a bilingual lexicon generated with an algorithm that roughly corresponds to an amalgamation of the GIZA++ IBM Model 1 and HMM phases with the competitive linking algorithm of (Melamed, 1997). 4.3 Performance was evaluated using the mteval-v11b.pl script made available by NIST. This script reports both the BLEU metric (Papineni et al., 2002) and the variant thereof proposed by George Doddington at NIST (Doddington, 2002). Parameters were tuned to maximize the value of the BLEU metric. BLEU measures the proportion of n-gram overlap between the MT system’s output and one or more human reference translations. The NIST metric modifies the n-gram matching to assign different weights to individual n-grams depending on their information content. The METEOR metric (Banerjee and Lavie, 200"
2008.amta-papers.2,P02-1040,0,0.0795587,"e prepared: one without document boundaries and one with document boundaries arbitrarily placed every five sentences (“test2006”) or every ten sentences (“test2007”) since the original document boundaries were not available. 4.2 we used a much faster heuristic approach driven by a bilingual lexicon generated with an algorithm that roughly corresponds to an amalgamation of the GIZA++ IBM Model 1 and HMM phases with the competitive linking algorithm of (Melamed, 1997). 4.3 Performance was evaluated using the mteval-v11b.pl script made available by NIST. This script reports both the BLEU metric (Papineni et al., 2002) and the variant thereof proposed by George Doddington at NIST (Doddington, 2002). Parameters were tuned to maximize the value of the BLEU metric. BLEU measures the proportion of n-gram overlap between the MT system’s output and one or more human reference translations. The NIST metric modifies the n-gram matching to assign different weights to individual n-grams depending on their information content. The METEOR metric (Banerjee and Lavie, 2005) has not yet been integrated into our workflow, but that integration is planned for the near future. The statistical significance of the results was t"
2008.amta-papers.2,2007.mtsummit-papers.49,1,0.851725,"nslation pair, using • local context bonus • optional source-specific weight • optional corpus position-specific weight • document similarity score for the training instance 4. perform a weighted merge of all equivalent translation pairs 5. if necessary, limit the number of candidate translations for a source-language n-gram to the k top-scoring alternatives 6. place the final translation candidates in a lattice and apply a stack decoder to determine the best overall translation Figure 2: Translation process in pseudo-code locally-weighted bags of words. al (Phillips and Cavalli-Sforza, 2006; Phillips et al., 2007). See Figure 2 for pseudo-code; the boldfaced portions indicate the modifications to support document similarity. The EBMT system used for the experiments described in the next section functions in the same manner as those of Brown (2005) and Phillips et 48 [8th AMTA conference, Hawaii, 21-25 October 2008] search caused by altered scores (runs using document boundaries are occasionally marginally faster than those without). Our method modifies steps 2 and 3(c) in the following ways. In Step 2, the baseline system orders n-gram matches by the number of additional words which match in that train"
2008.amta-papers.2,2005.mtsummit-papers.33,0,0.0887974,"Missing"
2008.amta-papers.2,zhang-etal-2004-interpreting,0,0.0164405,"nificance of the results was tested with the Wilcoxon Signed-Rank Test (Wilcoxon, 1945), a nonparametric alternative to the paired t-test. Unlike the t-test, the Signed-Rank test does not assume normal distribution of values in the population, nor does it assume that the scale of measurement is an equal-interval scale. To generate the values used for the Signed-Rank test, the test outputs were uniformly split into either 10 or 20 segments, depending on the total number of sentences in the test set, and each segment was individually scored with the mteval script. Bootstrapping as described by (Zhang et al., 2004) was not used because the test sets are sufficiently large to provide enough truly independent samples for statistical significance tests. System Training For the experiments described below, the EBMT system was trained as a straight-forward stringmatching EBMT system, without generalized matching through clustering such as in (Brown, 2000) or structural matching such as in (Phillips et al., 2007). GIZA++ (Al-Onaizan et al., 1999) word alignments were used for the Arabic-English data to drive the subsential aligner; for French-English, 1 Evaluation Metrics 5 Results Tables 1 and 2 present the"
2008.amta-papers.2,J90-2002,0,\N,Missing
2010.eamt-1.27,J93-2003,0,0.0213917,"nglish translation tasks. 1 Introduction In general, corpus-based machine translation systems prefer longer units because they naturally convey local context and local reordering. This was achieved by phrases in Phrase-Based Statistical Machine Translation (Koehn et al., 2007; Vogel et al., 2003) and surface form matches in lexical Example-Based Machine Translation (Brown, 2005; Veale and Way, 1997). These systems use phrasal alignment to find translations of matched n-grams for an input sentence. However, because the alignment algorithms used in these systems purely depend on word alignment (Brown et al., 1993) they cannot address structural translations, other than hoping for structural parallelism between source and target. For example, these algorithms cannot reliably find ’an/the office’ as a translation of ’sa-moo-sil’ in c 2010 European Association for Machine Translation. Korean to English translation because Korean does not have articles. For this reason, we investigated the chunk as our translation unit. The chunk was pioneered by Abney (1991). It is a continuous and non-recursive syntactic segment around a head, comparable to a morphologically complex word in synthetic languages, and is no"
2010.eamt-1.27,2005.mtsummit-ebmt.2,1,0.884299,"nsertion or deletion words between two distant languages. In this work, we used syntactic chunks as translation units to alleviate this problem, improve alignments and show improvement in BLEU for Korean to English and Chinese to English translation tasks. 1 Introduction In general, corpus-based machine translation systems prefer longer units because they naturally convey local context and local reordering. This was achieved by phrases in Phrase-Based Statistical Machine Translation (Koehn et al., 2007; Vogel et al., 2003) and surface form matches in lexical Example-Based Machine Translation (Brown, 2005; Veale and Way, 1997). These systems use phrasal alignment to find translations of matched n-grams for an input sentence. However, because the alignment algorithms used in these systems purely depend on word alignment (Brown et al., 1993) they cannot address structural translations, other than hoping for structural parallelism between source and target. For example, these algorithms cannot reliably find ’an/the office’ as a translation of ’sa-moo-sil’ in c 2010 European Association for Machine Translation. Korean to English translation because Korean does not have articles. For this reason, w"
2010.eamt-1.27,Y04-1013,0,0.0729874,"section 2, our approaches for chunk alignment and translation in section 3. In section 4, we describe our experiments, and we discuss our conclusions in section 5. Koehn and Knight (2002) decomposed the translation model into sentence level reordering (SLR), chunk mapping (CM) and word translations (W): p(f |e) = p(SLR|e) × 2 Related Work Some researchers have studied exploiting chunks in translation. Le et al. (2000) used chunk alignment to get better word alignment. Given a human dictionary and chunked English sentences, they got corresponding Chinese sentences chunked via chunk projection. Hwang et al. (2004) used chunk alignment to extract Korean dependency parse trees given Japanese dependency parse trees and a human dictionary. They first aligned words by consulting a Japanese-Korean dictionary to find chunk boundaries and alignment and then they aligned the remaining words. They finally extracted bilingual knowledge from the aligned chunk pairs. Zhou et al. (2004) extract chunk pairs automatically to use in an SMT system. Their chunk detection is based on the assumption that the most frequently co-occurring word sequence may be a potential chunk. After aligning chunks using their cooccurrence"
2010.eamt-1.27,2005.eamt-1.21,1,0.828115,"face form matching over the source half of the training set. Then it finds their translations using a phrasal aligner, and combines them to form hypothesis translations. The aligner provides several feature values to a standard beam decoder. 2 Next, the EBMT system collects some 1 The Korean sentence is missing a subject. And there is an error on the Korean sentence chunking. [order to] and [related/about] should be merged into one chunk. However this error was overcome by consistent chunk translation sequence pair extraction. 2 The aligner’s feature scores include uni-directional SPA scores (Kim et al., 2005), number of untranslated words on both source and target sides and so on. Figure 1: Chunk Translation Sequence Pair Extraction Lang. Kr-En Cn-En Data Dev Unseen Dev Unseen Moses 0.2222 0.2289 0.2610 0.2533 EBMT 0.2382 0.2502 0.2538 0.2295 Table 1: Baseline System vs. Moses more feature values outside the aligner to be used in decoding. Finally, the translation with the highest score is chosen as the best hypothesis translation. The score is calculated as a combination of feature values with their weights tuned in a separate tuning process in a log linear model. The performance of this EBMT sys"
2010.eamt-1.27,W00-1314,0,0.0680159,"or the Romance languages. In this paper, we show that we obtain significant improvements using chunks for translation in both Korean to English and Chinese to English. We discuss related work in section 2, our approaches for chunk alignment and translation in section 3. In section 4, we describe our experiments, and we discuss our conclusions in section 5. Koehn and Knight (2002) decomposed the translation model into sentence level reordering (SLR), chunk mapping (CM) and word translations (W): p(f |e) = p(SLR|e) × 2 Related Work Some researchers have studied exploiting chunks in translation. Le et al. (2000) used chunk alignment to get better word alignment. Given a human dictionary and chunked English sentences, they got corresponding Chinese sentences chunked via chunk projection. Hwang et al. (2004) used chunk alignment to extract Korean dependency parse trees given Japanese dependency parse trees and a human dictionary. They first aligned words by consulting a Japanese-Korean dictionary to find chunk boundaries and alignment and then they aligned the remaining words. They finally extracted bilingual knowledge from the aligned chunk pairs. Zhou et al. (2004) extract chunk pairs automatically t"
2010.eamt-1.27,2007.tmi-papers.14,0,0.0168459,"ependency parse trees and a human dictionary. They first aligned words by consulting a Japanese-Korean dictionary to find chunk boundaries and alignment and then they aligned the remaining words. They finally extracted bilingual knowledge from the aligned chunk pairs. Zhou et al. (2004) extract chunk pairs automatically to use in an SMT system. Their chunk detection is based on the assumption that the most frequently co-occurring word sequence may be a potential chunk. After aligning chunks using their cooccurrence similarity, they extracted chunk pairs and reported a significant improvement. Ma et al. (2007) studied an adaptable monolingual chunking approach. They learned word alignment on a parallel corpus and used this alignment information to find chunk boundaries in both languages. Wu (1997) studied the inversion transduction grammar (ITG) formalism for bilingual parsing for a parallel corpus. In this parse tree pair, the method naturally provides bilingual bracketing and alignment to extract aligned chunk pairs. However, it remains difficult to write a broad bilingual ITG grammar to deal with long sentences. Watanabe et al. (2003) built a chunk-based statistical translation system. They deco"
2010.eamt-1.27,2003.mtsummit-papers.51,0,0.0409428,"mostly likely to have benefits by Dev 82.58 94.53 74.11 86.23 69.80 79.08 Table 4: Training Set Coverage for Korean Table 3: Test sets for Korean-English translation evaluation metric. type token type token type token translating chunks which are longer than one word by properly dealing with word deletion/insertion as explained. For Chinese-English translation, we used 340,000 sentence pairs for training and 230 sentences with 4 references for parameter tuning. To measure performance on an unseen data set, we used 919 sentences with 4 references from NIST Machine Translation Evaluation 2003 (NIST, 2003). The Chinese training data was drawn from the FBIS Chinese-English parallel text by (NIST, 2003). We used sentence pairs with 70 or fewer words in the source side. On average, the Chinese sentences are 26.8 words long and 18.1 chunks long and chunks are composed of 1.5 words. And the English sentences are 33.9 words long and 18 chunks long and chunks are 1.8 words long. Table 5 shows Chinese to English training data. Both Korean-English and Chinese-English language pairs shows chunk level correspondence is higher than word level correspondence. Table 6 shows Chinese-English test sets for tran"
2010.eamt-1.27,J03-1002,0,0.0260674,"vel template first and then use chunk mapping and word translation to generate a target translation. Whereas the method is good, each step could be prone to error, and errors could compound. Our system relies on chunks as the basic unit when it can find evidence of good chunk level translations, but otherwise it falls back to a word/phrase-based model. 3 ciently large corpus for chunk alignment. But in reality, it is hard to build such a large corpus for many languages. Instead, we investigated a new method that induces chunk alignment from word alignment. For chunk alignment, we used GIZA++ (Och and Ney, 2003) that works on a chunk annotated corpus. We created a chunk unit which will be used as a basic unit in GIZA++ by concatenating all the words in the chunk placing a special delimiter character between adjacent words. The GIZA++ was modified to use word alignment information in chunk alignment in this way: • Let f and e be chunks and f be f1n = f1 f2 ...fn and e be em 1 = e1 e2 ...em . • T (f |e) in IBM models is C(f , e) k C(fk , e) (2) C ′ (f , e) ′ k C (fk , e) (3) T (f |e) = P • We redefine it as, T (f |e) = P Chunk-Based System where 3.1 Chunk Detection C ′ (f , e) = C(f , e) × F (f , e) In"
2010.eamt-1.27,P02-1040,0,0.0791975,"Missing"
2010.eamt-1.27,C02-1092,0,0.0415757,"Missing"
2010.eamt-1.27,2006.iwslt-evaluation.4,0,0.0147995,"ge parallel corpus in which we can find reasonable statistical evidence to align chunks. However, our approach allows a relatively smaller corpus by boosting chunk alignment with word alignment information, making it practical for low and medium resource conditions. Last, in decoding, our method combines target chunks as well as target fragments which are not chunks. Unlike the lexical EBMT system by Brown (2005), this chunk-based system is a hybrid system that combines a typical string-based EBMT system and a chunk-based EBMT system. It is close to the EBMT system by Veale and Way (1997) and Stroppa and Way (2006) in that it uses constituent-like units but different in that the work is fully extended to include chunks at all levels. Our work also differs from the ChunkMT work (Koehn and Knight, 2002), in which the translation was decomposed into sentence label chunk reordering, chunk mapping and word translation. When an input is given, they build a sentence level template first and then use chunk mapping and word translation to generate a target translation. Whereas the method is good, each step could be prone to error, and errors could compound. Our system relies on chunks as the basic unit when it c"
2010.eamt-1.27,2003.mtsummit-papers.53,0,0.0240114,"training corpus. However, they still cannot properly deal with systematic translation for insertion or deletion words between two distant languages. In this work, we used syntactic chunks as translation units to alleviate this problem, improve alignments and show improvement in BLEU for Korean to English and Chinese to English translation tasks. 1 Introduction In general, corpus-based machine translation systems prefer longer units because they naturally convey local context and local reordering. This was achieved by phrases in Phrase-Based Statistical Machine Translation (Koehn et al., 2007; Vogel et al., 2003) and surface form matches in lexical Example-Based Machine Translation (Brown, 2005; Veale and Way, 1997). These systems use phrasal alignment to find translations of matched n-grams for an input sentence. However, because the alignment algorithms used in these systems purely depend on word alignment (Brown et al., 1993) they cannot address structural translations, other than hoping for structural parallelism between source and target. For example, these algorithms cannot reliably find ’an/the office’ as a translation of ’sa-moo-sil’ in c 2010 European Association for Machine Translation. Kore"
2010.eamt-1.27,P03-1039,0,0.668756,"they extracted chunk pairs and reported a significant improvement. Ma et al. (2007) studied an adaptable monolingual chunking approach. They learned word alignment on a parallel corpus and used this alignment information to find chunk boundaries in both languages. Wu (1997) studied the inversion transduction grammar (ITG) formalism for bilingual parsing for a parallel corpus. In this parse tree pair, the method naturally provides bilingual bracketing and alignment to extract aligned chunk pairs. However, it remains difficult to write a broad bilingual ITG grammar to deal with long sentences. Watanabe et al. (2003) built a chunk-based statistical translation system. They decomposed the P translation model P (J|E) = P (J, A|E) P P A P (J, J , E|E) to P (J|E) = J E where J and E are the chunked sentences for J and E respectively. Then they decomposed P (J, J , E|E) further to P P P (J, J , E|E) = A A P (J, J , A, A, E|E) where A is chunk alignment and A is word alignment for each chunk translation. Y p(CMi |e, SLR) i × Y (Wij |CMi , SLR, e) (1) j Sentence level chunk reordering defines how source and target chunks are connected and chunk mapping defines an alignment of source to target POSs. Finally word"
2010.eamt-1.27,J97-3002,0,0.641506,"ey finally extracted bilingual knowledge from the aligned chunk pairs. Zhou et al. (2004) extract chunk pairs automatically to use in an SMT system. Their chunk detection is based on the assumption that the most frequently co-occurring word sequence may be a potential chunk. After aligning chunks using their cooccurrence similarity, they extracted chunk pairs and reported a significant improvement. Ma et al. (2007) studied an adaptable monolingual chunking approach. They learned word alignment on a parallel corpus and used this alignment information to find chunk boundaries in both languages. Wu (1997) studied the inversion transduction grammar (ITG) formalism for bilingual parsing for a parallel corpus. In this parse tree pair, the method naturally provides bilingual bracketing and alignment to extract aligned chunk pairs. However, it remains difficult to write a broad bilingual ITG grammar to deal with long sentences. Watanabe et al. (2003) built a chunk-based statistical translation system. They decomposed the P translation model P (J|E) = P (J, A|E) P P A P (J, J , E|E) to P (J|E) = J E where J and E are the chunked sentences for J and E respectively. Then they decomposed P (J, J , E|E)"
2010.eamt-1.27,koen-2004-pharaoh,0,\N,Missing
2010.eamt-1.27,P07-2045,0,\N,Missing
2010.eamt-1.40,2003.mtsummit-papers.4,1,0.745755,"Missing"
2010.eamt-1.40,C00-1019,1,0.620774,"es is observed, even above the empirically found N . 1 Introduction An EBMT system uses a parallel corpus to translate new input source sentences. In the Translation Model (TM), the input sentence to be translated is matched against the source sentences. When a match is found, the corresponding translation in the target language is obtained through subsentential alignment. In our EBMT system, the final target translation is obtained from these partial target translations with a beam-search decoder using a target Language Model (LM). EBMT systems require large amounts of data to function well (Brown, 2000). c 2010 European Association for Machine Translation. Generalization using equivalence classes (Veale and Way, 1997; Brown, 2000) reduces the amount of pre-translated text required and improves translation quality. Translation templates (or short reusable sequences) are generalizations of source and target sentences where sequences of one or more words are replaced by variables. Various methods have been proposed to create such templates in EBMT and differ in the way the templates are created. Some systems required a full template to match the input source sentence for target sentence generat"
2010.eamt-1.40,N06-2011,1,0.896727,"Missing"
2010.eamt-1.40,koen-2004-pharaoh,0,0.0771191,"Missing"
2011.mtsummit-papers.2,P05-1033,0,0.0146365,"describe two techniques that improve the training procedure and allow us to leverage the strengths of instance-based modeling. First, during training we approximate our model with a second-order Taylor series. Second, we discount models based on the magnitude of their approximation. By reducing error in training, our model now consistently outperforms the standard SMT model with gains ranging from 0.51 to 3.77 BLEU on GermanEnglish and Czech-English test sets. 1 Introduction Machine translation research over the years has explored the use of simple phrases (Och and Ney, 2004), Hiero grammars (Chiang, 2005), and complex S-CFG rules (Zollmann and Venugopal, 2006). These more specialized translation units can more accurately describe the translation process, but they are also less likely to occur in the corpus. The increased data sparsity makes it difﬁcult to estimate the standard SMT features which are typically computed as relative frequencies. A signiﬁcant challenge in building data-driven MT systems is identifying the right level of abstraction–to model translation units that both adequately reﬂect the data and can be estimated well. Our approach pushes this trend of translation unit reﬁnement"
2011.mtsummit-papers.2,W07-0717,0,0.19035,"lation instance from Moses Cunei Development BLEU NIST 30.46 6.7781 33.10 7.0221 Test BLEU NIST 27.82 6.9530 31.59 7.3256 Table 6: Multi-Genre Evaluation of Czech-English 45 Development BLEU NIST 19.12 5.9616 18.98 5.9694 Test BLEU NIST 20.60 6.5102 21.11 6.5639 Table 5: Newswire Evaluation of German-English EBMT into an SMT world. However, the most similar research to ours comes from the other end of the spectrum–training an SMT model that can adapt to new domains. When dealing with corpora in multiple domains, perhaps the most natural extension of the SMT model is to build multiple models. (Foster and Kuhn, 2007) and (Lu et al., 2007) describe mixturemodel approaches in which the corpus is partitioned and traditional SMT models are built on each component. (Lu et al., 2007) weight each component based on its TF-IDF similarity to the test set. (Foster and Kuhn, 2007) explore multiple distance metrics and ﬁnds that an EM approach maximizing the likelihood of the test set provides the best mixture weights. An alternative technique has been to compute a single model, but uniquely weight sections or sentences of the corpora. An early approach by (Hildebrand et al., 2005) uses TF-IDF to compute the similari"
2011.mtsummit-papers.2,2005.eamt-1.19,0,0.064743,"T model is to build multiple models. (Foster and Kuhn, 2007) and (Lu et al., 2007) describe mixturemodel approaches in which the corpus is partitioned and traditional SMT models are built on each component. (Lu et al., 2007) weight each component based on its TF-IDF similarity to the test set. (Foster and Kuhn, 2007) explore multiple distance metrics and ﬁnds that an EM approach maximizing the likelihood of the test set provides the best mixture weights. An alternative technique has been to compute a single model, but uniquely weight sections or sentences of the corpora. An early approach by (Hildebrand et al., 2005) uses TF-IDF to compute the similarity between sentences in the training corpus and sentences in the test set. This work actually ﬁlters the training corpus so that it is maximally similar to the test set. Later, (Lu et al., 2007) extended this idea and used TF-IDF to re-weight the training corpus based on the test set. More recent work has focused on learning weights for the corpus. (Shah et al., 2010) performs sampling to learn weights for the corpora and alignments. (Matsoukas et al., 2009) uses a perceptron model with several simple feature functions to assign a weight to each sentence pai"
2011.mtsummit-papers.2,2005.mtsummit-papers.11,0,0.0221683,"ﬁrst-order and second-order approximations is quite important–it does not guarantee that a better λ will be found during training, but it does indicate we are more likely to ﬁnd one. 5 Comparison to Moses To demonstrate the effectiveness of our model when properly trained, we now compare it to a traditional SMT model. Moses is a widely-used and freelyavailable SMT toolkit (Koehn et al., 2007). We trained Cunei and Moses on the same data and compared their performance in German to English and Czech to English translation. The corpora for both language pairs included version 6 of the Europarl (Koehn, 2005) and the 2011 edition of parallel news commentary released by the 2011 Workshop on Statistical Machine Translation5 (WMT). In addition, the Czech to English corpus included CzEng 0.9 ˇ (Bojar and Zabokrtsk´ y, 2009) which is a collection of many different texts including works of ﬁction, websites, subtitles, and technical documentation. The available data in Czech and English was quite large, so we sampled one quarter of the parallel text for training.6 For monolingual data we com5 http://www.statmt.org/wmt11/ Both Moses and Cunei are capable of handling the full dataset, but in the course of"
2011.mtsummit-papers.2,D07-1036,0,0.16816,"unei Development BLEU NIST 30.46 6.7781 33.10 7.0221 Test BLEU NIST 27.82 6.9530 31.59 7.3256 Table 6: Multi-Genre Evaluation of Czech-English 45 Development BLEU NIST 19.12 5.9616 18.98 5.9694 Test BLEU NIST 20.60 6.5102 21.11 6.5639 Table 5: Newswire Evaluation of German-English EBMT into an SMT world. However, the most similar research to ours comes from the other end of the spectrum–training an SMT model that can adapt to new domains. When dealing with corpora in multiple domains, perhaps the most natural extension of the SMT model is to build multiple models. (Foster and Kuhn, 2007) and (Lu et al., 2007) describe mixturemodel approaches in which the corpus is partitioned and traditional SMT models are built on each component. (Lu et al., 2007) weight each component based on its TF-IDF similarity to the test set. (Foster and Kuhn, 2007) explore multiple distance metrics and ﬁnds that an EM approach maximizing the likelihood of the test set provides the best mixture weights. An alternative technique has been to compute a single model, but uniquely weight sections or sentences of the corpora. An early approach by (Hildebrand et al., 2005) uses TF-IDF to compute the similarity between sentences i"
2011.mtsummit-papers.2,D09-1074,0,0.60798,"pute a single model, but uniquely weight sections or sentences of the corpora. An early approach by (Hildebrand et al., 2005) uses TF-IDF to compute the similarity between sentences in the training corpus and sentences in the test set. This work actually ﬁlters the training corpus so that it is maximally similar to the test set. Later, (Lu et al., 2007) extended this idea and used TF-IDF to re-weight the training corpus based on the test set. More recent work has focused on learning weights for the corpus. (Shah et al., 2010) performs sampling to learn weights for the corpora and alignments. (Matsoukas et al., 2009) uses a perceptron model with several simple feature functions to assign a weight to each sentence pair in the corpus. These weights are learned as part of a discriminative Cunei the troubled us behemoths to touch their state shackles . Moses the troubled us behemoths swath of its government bonds . the crisis-hit us major banks are breaking free from their state shackles . Reference Cunei the countries must significantly more lecturers . Moses the countries must have a far more teachers to come . Reference the states must employ significantly more lecturers . Cunei right or wrong , i did n’t"
2011.mtsummit-papers.2,J03-1002,0,0.00306688,"ish was quite large, so we sampled one quarter of the parallel text for training.6 For monolingual data we com5 http://www.statmt.org/wmt11/ Both Moses and Cunei are capable of handling the full dataset, but in the course of this research we needed to run many bined the English text from all the above parallel corpora with years 2010 and 2011 of web-crawled news text released by WMT. Statistics describing our training resources are shown in Table 3. We applied generic tokenization applicable to Western languages to all the training resources. We then aligned the parallel corpora using GIZA++ (Och and Ney, 2003) in both directions. With the SRILM toolkit (Stolcke, 2002) and the monolingual resources, we built a single 5-gram English language model using Kneser-Ney smoothing. The resulting corpus, word alignments, and language model were provided to Moses and Cunei for training. Each system used its respective phrase extraction and model estimation routines. Speciﬁcally, Moses used MERT and Cunei utilized the methods described in this paper for training. In our ﬁrst experiment, we selected text from a limited newswire domain. SMT is usually quite good at translating this type of data as the sentences"
2011.mtsummit-papers.2,J04-4002,0,0.0221176,"approach is effective training. We describe two techniques that improve the training procedure and allow us to leverage the strengths of instance-based modeling. First, during training we approximate our model with a second-order Taylor series. Second, we discount models based on the magnitude of their approximation. By reducing error in training, our model now consistently outperforms the standard SMT model with gains ranging from 0.51 to 3.77 BLEU on GermanEnglish and Czech-English test sets. 1 Introduction Machine translation research over the years has explored the use of simple phrases (Och and Ney, 2004), Hiero grammars (Chiang, 2005), and complex S-CFG rules (Zollmann and Venugopal, 2006). These more specialized translation units can more accurately describe the translation process, but they are also less likely to occur in the corpus. The increased data sparsity makes it difﬁcult to estimate the standard SMT features which are typically computed as relative frequencies. A signiﬁcant challenge in building data-driven MT systems is identifying the right level of abstraction–to model translation units that both adequately reﬂect the data and can be estimated well. Our approach pushes this tren"
2011.mtsummit-papers.2,P02-1040,0,0.0881604,"models computed with λ. 0.6 0.4 0.2 0 0-2 2-4 02 2 4 4-8 4 8 6-8 6 8 8-10 8 10 10-15 10 0 15 15-20 15 5 20 20-25 20 25 25-30 25 30 30-50 30 50 50-100 50 0 100 100 Binned Distance Magnitudes Figure 1: Average Modeling Error Increases Proportionally to Distance Magnitude (x-Axis Not to Scale) 4 Improvement in Training The motivation behind implementing these techniques was that reducing the approximation error would stabilize and improve training. Training is a notoriously difﬁcult task in machine translation and is an even more complex challenge with our model. In particular, the use of BLEU (Papineni et al., 2002) as the objective function results in a very bumpy error surface with many local minima. An additional, signiﬁcant source of error due to approximations made during training is not something we can afford. Table 2 shows ﬁve randomized runs of training the same Czech-English system evaluated on the multigenre test set described at the end of §5. The ﬁrstorder and second-order approximations identiﬁed by the same run were initialized with the same random seed. All runs were initialized with the same λ valRun 1 Run 2 Run 3 Run 4 Run 5 First Order BLEU 30.03 29.97 30.16 30.14 30.37 Second Order BL"
2011.mtsummit-papers.2,W10-1721,1,0.88085,"the standard SMT features which are typically computed as relative frequencies. A signiﬁcant challenge in building data-driven MT systems is identifying the right level of abstraction–to model translation units that both adequately reﬂect the data and can be estimated well. Our approach pushes this trend of translation unit reﬁnement to its logical end and models each instance of translation. An instance of translation is 40 We have presented this approach to translation before, but with performance that was on par with or indistinguishable from state-of-the-art SMT (Phillips and Brown, 2009; Phillips, 2010). In particular, the complexity of our model presents speciﬁc challenges in training. We have learned since that our training procedures did not fully leverage the capabilities of our model. In this paper we describe two new techniques for more effectively training our model. First, we utilize a second-order Taylor series to approximate the model during training. Second, we present a method for discounting models based on the magnitude of their approximation. We then proceed to show that by reducing error in training, our model outperforms the standard SMT model by 0.51 BLEU on German-English"
2011.mtsummit-papers.2,W10-1759,0,0.0992789,"he test set provides the best mixture weights. An alternative technique has been to compute a single model, but uniquely weight sections or sentences of the corpora. An early approach by (Hildebrand et al., 2005) uses TF-IDF to compute the similarity between sentences in the training corpus and sentences in the test set. This work actually ﬁlters the training corpus so that it is maximally similar to the test set. Later, (Lu et al., 2007) extended this idea and used TF-IDF to re-weight the training corpus based on the test set. More recent work has focused on learning weights for the corpus. (Shah et al., 2010) performs sampling to learn weights for the corpora and alignments. (Matsoukas et al., 2009) uses a perceptron model with several simple feature functions to assign a weight to each sentence pair in the corpus. These weights are learned as part of a discriminative Cunei the troubled us behemoths to touch their state shackles . Moses the troubled us behemoths swath of its government bonds . the crisis-hit us major banks are breaking free from their state shackles . Reference Cunei the countries must significantly more lecturers . Moses the countries must have a far more teachers to come . Refer"
2011.mtsummit-papers.2,P06-2101,0,0.0648521,"Missing"
2011.mtsummit-papers.2,W06-3119,0,0.0280392,"training procedure and allow us to leverage the strengths of instance-based modeling. First, during training we approximate our model with a second-order Taylor series. Second, we discount models based on the magnitude of their approximation. By reducing error in training, our model now consistently outperforms the standard SMT model with gains ranging from 0.51 to 3.77 BLEU on GermanEnglish and Czech-English test sets. 1 Introduction Machine translation research over the years has explored the use of simple phrases (Och and Ney, 2004), Hiero grammars (Chiang, 2005), and complex S-CFG rules (Zollmann and Venugopal, 2006). These more specialized translation units can more accurately describe the translation process, but they are also less likely to occur in the corpus. The increased data sparsity makes it difﬁcult to estimate the standard SMT features which are typically computed as relative frequencies. A signiﬁcant challenge in building data-driven MT systems is identifying the right level of abstraction–to model translation units that both adequately reﬂect the data and can be estimated well. Our approach pushes this trend of translation unit reﬁnement to its logical end and models each instance of translat"
brown-2004-modified,2003.mtsummit-papers.4,1,\N,Missing
brown-2004-modified,1999.mtsummit-1.37,0,\N,Missing
C00-1019,1999.tmi-1.8,0,0.0363306,"te a pseudo-document containing the words of the contexts in which that word appears, and use the word itself as the document identi er. After the pseudo-documents are clustered, retrieving the identi er for each document in a particular cluster produces the list of words occurring in suciently similar contexts to be considered equivalent for the purposes of generalizing an EBMT system. By itself, this approach only produces a monolingual clustering, but we require a bilingual clustering for proper generalization since di erent senses of a word will appear in di ering contexts. The method of Barrachina and Vilar (1999) provides the means for injecting bilingual information into the clustering process. Using a bilingual dictionary |which may be created from the corpus using statistical methods, such as those of Peter Brown et al (1990) or the author&apos;s own previous work (Brown, 1997) |and the parallel text, create a rough mapping between the words in the source-language half of each translation example in the corpus and the target-language half of that example. Whenever there is exactly one possible translation candidate listed for a word by the mapping, generate a bilingual word pair consisting of the word a"
C00-1019,1997.tmi-1.13,1,0.820998,"in suciently similar contexts to be considered equivalent for the purposes of generalizing an EBMT system. By itself, this approach only produces a monolingual clustering, but we require a bilingual clustering for proper generalization since di erent senses of a word will appear in di ering contexts. The method of Barrachina and Vilar (1999) provides the means for injecting bilingual information into the clustering process. Using a bilingual dictionary |which may be created from the corpus using statistical methods, such as those of Peter Brown et al (1990) or the author&apos;s own previous work (Brown, 1997) |and the parallel text, create a rough mapping between the words in the source-language half of each translation example in the corpus and the target-language half of that example. Whenever there is exactly one possible translation candidate listed for a word by the mapping, generate a bilingual word pair consisting of the word and its translation. This word pair will be treated as an indivisible token in further processing, adding bilingual information to the clustering process. Forming pairs in this manner causes each distinct translation of a word to be treated as a separate sense; althoug"
C00-1019,1999.tmi-1.3,1,0.941211,"w texts can be matched. Gaijin variablizes the well-formed segment mappings between source and target sentences that it is able to nd, using a closed set of markers to segment the input into phrases. The author&apos;s system performs its generalization using equivalence classes (both syntactic and semantic) and a production-rule grammar. First, any occurrences of terms contained in an equivalence class are replaced by a token giving the name of the equivalence class, and then the grammar rules are used to replace patterns of words and tokens by more general tokens (such as <NP> for noun phrases). (Brown, 1999) showed that one can reduce the corpus size by as much as an order of magnitude in this way. Given that explicit, manually-generated equivalence classes reduce the need for example text, an obvious extension would be to attempt to generate these classes automatically from the corpus of pre-translated examples. This paper describes one approach to automated extraction of equivalence classes, using clustering techniques. The remainder of this paper describes how to perform bilingual word clustering using standard monolingual document clustering techniques by converting the problem space; the var"
C00-1019,1999.tmi-1.10,0,0.158906,"Missing"
C00-1019,resnik-1998-parallel,0,0.0363655,"Missing"
C00-1019,J90-2002,0,\N,Missing
C10-2037,P01-1008,0,0.060723,"is to find those n-gram candidate translations from a large target corpus that contain as many potential word and phrase translations of the source text from the dictionary and fewer spurious content words. The overlap decoder combines the target n-gram translation candidates by finding maximal left and right overlaps with the translation candidates of the previous and following n-grams. When the overlap decoder does not find coherent sequences of overlapping target n-grams, more candidate transla321 tions are obtained by substituting words or phrases in the target n-grams by their synonyms. Barzilay and McKeown (2001) and CallisonBurch et al. (2006) extracted paraphrases from monolingual parallel corpus where multiple translations were present for the same source. The synonym generation in Carbonell et al. (2006) differs from the above in that it does not require parallel resources containing multiple translations for the same source language. In Carbonell et al. (2006), a list of paired left and right contexts that contain the desired word or phrase are extracted from the monolingual corpus. The same corpus is used to find other words and phrases that fit the paired contexts in the list. The idea is based"
C10-2037,2003.mtsummit-papers.4,1,0.889386,"Missing"
C10-2037,C00-1019,1,0.652291,"al Profiles for Word Substitution in Machine Translation Rashmi Gangadharaiah rgangadh@cs.cmu.edu Ralf D. Brown ralf@cs.cmu.edu Jaime Carbonell jgc@cs.cmu.edu Language Technologies Institute, Carnegie Mellon University Abstract corpus. When matches are found, the corresponding translations in the target language are obtained through sub-sentential alignment. In our EBMT system, the final translation is obtained by combining the partial target translations using a statistical target Language Model. EBMT systems, like other data-driven approaches, require large amounts of data to function well (Brown, 2000). Out-of-vocabulary (OOV) words present a significant challenge for Machine Translation. For low-resource languages, limited training data increases the frequency of OOV words and this degrades the quality of the translations. Past approaches have suggested using stems or synonyms for OOV words. Unlike the previous methods, we show how to handle not just the OOV words but rare words as well in an Example-based Machine Translation (EBMT) paradigm. Presence of OOV words and rare words in the input sentence prevents the system from finding longer phrasal matches and produces low quality translati"
C10-2037,N06-1003,0,0.0551967,"Missing"
C10-2037,P08-2015,0,0.100552,"s the method adopted in this paper. Section 4 describes the experimental setup. Section 5 reports the results obtained with the new framework for English-Chinese and English-Haitian translation systems. Section 6 concludes and suggests possible future work. 2 Related Work Orthographic and morpho-syntactic techniques for preprocessing training and test data have been shown to reduce OOV word rates. Popovi´c and Ney (2004) demonstrated this on rich morphological languages in an SMT system. They introduced different types of transformations to the verbs to reduce the number of unseen word forms. Habash (2008) addresses spelling, nametransliteration OOVs and morphological OOVs in an Arabic-English Machine Translation system. Phrases with the OOV replacements in the phrase table of a phrase-based SMT system were “recycled” to create new phrases in which the replacements were replaced by the OOV words. Yang and Kirchhoff (2006) proposed a backoff model for phrase-based SMT that translated word forms in the source language by hierarchical morphological phrase level abstractions. If an unknown word was found, the word was first stemmed and the phrase table entries for words sharing the same stem were m"
C10-2037,koen-2004-pharaoh,0,0.0755058,"Missing"
C10-2037,D09-1040,0,0.293466,"on. When data is limited, the number of OOV words increases, leading to the poor performance of the translation models and the language models due to the absence of longer sequences of source word matches and less reliable language model estimates. Introduction An EBMT system makes use of a parallel corpus to translate new sentences. Each input sentence is matched against the source side of a training Approaches in the past have suggested using stems or synonyms for OOV words as replacements (Yang and Kirchhoff, 2006). Similarity measures have been used to find words that are closely related (Marton et al., 2009). For morpho320 Coling 2010: Poster Volume, pages 320–328, Beijing, August 2010 logically rich languages, the OOV word is morphologically analyzed and the stem is used as its replacement (Popovi´c and Ney, 2004). This paper presents a simpler method inspired by the Context-based MT approach (Carbonell et al., 2006) to improve translation quality. The method requires a large source language monolingual corpus and does not require any other language dependent resources to obtain replacements. Approaches suggested in the past only concentrated on finding replacements for the OOV words and not the"
C10-2037,P02-1040,0,0.0924833,"gual corpus. The corresponding target phrasal translations are obtained through subsentential alignment. When an input lattice is given instead of an input sentence, the system performs the same matching process for all possible phrases obtained from the input lattice. Hence, the system also finds matches for source phrases that contain the replacements for the OOV/rareword. Only the top C ranking replacement candi同 一 箭 hawks 一箭 三 雕 一 箭 三雕 “ three birds ” We would like to select those feature weights (~λ) which would lead to the least expected loss in translation quality (Eqn 3). −log(BLEU ) (Papineni et al., 2002) is used to calculate the expected loss over a development set. As this objective function has many local minima and is piecewise constant, the surface is smoothed using the L2norm regularization. Powell’s algorithm (Powell, 1964) with grid-based line optimization is used to find the best weights. 7 different random guesses are used to initialize the algorithm. 3.7 移动 Tuning feature weights min Eλ [L(ttune )] + τ ∗ ||λ||2 基地 一 where, f~i,j is the feature vector for the j th replacement candidate of wordi , S is the number of replacements, ~λ is the weight vector indicating the importance of th"
C10-2037,popovic-ney-2004-towards,0,0.301374,"Missing"
C10-2037,W07-0705,0,0.0180861,"hrase-based SMT that translated word forms in the source language by hierarchical morphological phrase level abstractions. If an unknown word was found, the word was first stemmed and the phrase table entries for words sharing the same stem were modified by replacing the words with their stems. If a phrase entry or a single word phrase was found, the corresponding translation was used, otherwise the model backed off to the next level and applied compound splitting to the unknown word. The phrase table included phrasal entries based on full word forms as well as stemmed and split counterparts. Vilar et al. (2007) performed the translation process treating both the source and target sentences as a string of letters. Hence, there are no unknown words when carrying out the actual translation of a test corpus. The word-based system did most of the translation work and the letterbased system translated the OOV words. The method proposed in this work to handle OOV and rare words is very similar to the method adopted by Carbonell et al. (2006) to generate word and phrasal synonyms in their Contextbased MT system. Context-based MT does not require parallel text but requires a large monolingual target language"
C10-2037,E06-1006,0,0.426321,"ion systems either ignore these unknown words or leave them untranslated in the final target translation. When data is limited, the number of OOV words increases, leading to the poor performance of the translation models and the language models due to the absence of longer sequences of source word matches and less reliable language model estimates. Introduction An EBMT system makes use of a parallel corpus to translate new sentences. Each input sentence is matched against the source side of a training Approaches in the past have suggested using stems or synonyms for OOV words as replacements (Yang and Kirchhoff, 2006). Similarity measures have been used to find words that are closely related (Marton et al., 2009). For morpho320 Coling 2010: Poster Volume, pages 320–328, Beijing, August 2010 logically rich languages, the OOV word is morphologically analyzed and the stem is used as its replacement (Popovi´c and Ney, 2004). This paper presents a simpler method inspired by the Context-based MT approach (Carbonell et al., 2006) to improve translation quality. The method requires a large source language monolingual corpus and does not require any other language dependent resources to obtain replacements. Approac"
C10-2037,N03-1017,0,\N,Missing
C10-2037,I05-3027,0,\N,Missing
C88-1021,J81-4001,0,\N,Missing
C88-1021,P83-1025,1,\N,Missing
C90-3008,C88-1021,1,0.914405,"u.edu Topics: User Interaction, Disambiguation Abstract We describe a semi-automatic semantic disambiguator integrated in a knowledge-based machine translation system. It is used to bridge the analysis and generation stages in machine translation. The user interface of the disambiguator is built on mouse-based multiple-selection menus. 1. Introduction Extraction and representation of text meaning is a central concern of natural language application developers. This goal still largely eludes computational linguists. Many problems remain unresolved. They include referential ambiguity resolution [4, 12], determining the nature of semantic dependency relations (as, tbr instance, in compound nouns in English [8]), treatment of novel language and ill-formed input [21], metaphor and metonymy [6, 7], discourse and pragmatic meanings [11, 14, 17], etc. Another set of tasks includes work on representation languages both for text meaning proper and for ontological domain models that underlie semantic analysis of texts [1, 7, 13, 15], problems of acquiring and working with domains and sublanguages of realistic s~e [15, 16] and taking into account requirements of particular applications, such as machi"
C90-3008,J86-3001,0,\N,Missing
C96-1030,H94-1005,0,0.160331,"Missing"
C96-1030,1992.tmi-1.15,0,0.148006,"sp data structures stored in files or sent from the main Pangloss module via Unix pipes. P a n E B M T consists of approximately 13,300 lines of code, including the code for a glossary mode which will not be described here. P a n E B M T uses a re-processed version of the bilingual dictionary used by Pangloss's dictionary translation engine (Figure 2). The re-processing consists of removing various high-frequency words and splitting all nmlti-word definitions into a list of single words, needed to find one-to-one associations. In constrast with other work on examplebased translation, such as (Maruyama and Watanabe, 1992) or early Pangloss E B M T experiments (Nirenburg et al., 1993), P a n E B M T does not find an optimal partitioning of the input. Instead, it attempts to produce translations of every word sequence in the input sentence which appears in its corpus. The final selection of the &quot;correct&quot; cover for the input is left for the statistical language model, as is the case for all of the other translation engines in Pangloss. An advantage of this approach is that; it avoids discarding possible chunks merely because they are not part of the &quot;optimal&quot; cover for the input, instead selecting the input cover"
C96-1030,H94-1024,0,0.0311241,"Missing"
carbonell-etal-2002-automatic,2001.mtsummit-road.7,1,\N,Missing
D14-1069,zampieri-gebre-2014-varclass,0,0.148698,"Missing"
D14-1069,W13-1728,0,0.0705808,"tically. 2 x = P (ngram) 3 Related Work Although n-gram statistics as a basis for language identification has been in use for two decades since Cavnar and Trenkle (1994) and Dunning (1994), little work has been done on trying to optimize the values used for those n-gram statistics. Where some form of frequency mapping is used, it is often implicit (as in Cavnar and Trenkle’s use of ranks instead of frequencies) and generally goes unremarked as such. Vogel and Tresner-Kirsch (2012) use the logarithm of the frequency for some experimental runs, reporting that it improved accuracy in some cases. Gebre et al (2013) used logarithmic termfrequency scaling of words in an English-language Method The selected modification to the scoring algorithm is to apply a non-linear mapping which spreads out the lower probability values while compacting the higher ones. This low-end spreading of 627 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 627–632, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics code the maximum distortion penalty at 400; this was corrected to set the maximum penalty equal to the maximum size of any loaded fi"
D14-1069,2005.mtsummit-papers.11,0,0.0148824,"ined on a maximum of 1,000,000 bytes per model, as reported optimal in (Brown, 2013). The other programs were trained on a maximum of 2,500,000 bytes per model; libtextcat and whatlang used default model sizes of 400 and 3500, respectively, while mguesser was set to the previouslyreported 1500 n-grams per model. After some experimentation, YALI was set to use 5-grams, with 3500 n-grams per model to match whatlang. Data The data used for the experiments described in this paper comes predominantly from Bible translations, Wikipedia, and the Europarl corpus of European parliamentary proceedings (Koehn, 2005). The 1459 files of the training corpus generate 1483 models in 1368 languages. A number of training files generate models in both UTF-8 and ISO 8859-1, numerous languages have multiple training files in different writing systems, and several have multiple files for different regional variants (e.g. European and Brazilian Portugese). The text for a language is split into training, test, and possibly a disjoint development set. The amount of text per language varies, with quartiles of 1.19/1.47/2.22 million bytes. In general, every thirtieth line of text is reserved for the test set; some small"
D14-1069,P12-3005,0,0.174791,"Missing"
D14-1069,E12-3006,0,0.0321397,"and have been packaged into the LTI LangID Corpus (Brown, 2014b). This smaller corpus contains 781 languages, 119 of them with development sets, and a total of 649,589 lines in the test files. The languages are a strict subset of those in the larger corpus, but numerous languages have had Wikipedia text substituted for non-redistributable Bible translations. ity of each n-gram as it is encountered in the input. Models are formed by finding the highestfrequency n-grams of the configured lengths, with some filtering as described in (Brown, 2012). 4.5 YALI YALI (Yet Another Language Identifier) (Majlis, 2012) is an identifier written in Perl. It performs minor text normalization by collapsing multiple blanks into a single blank and removing leading and trailing blanks from lines. Thereafter, it uses a sliding window to generate byte n-grams of a (configurable) fixed length, and sums the probabilities for each n-gram in each trained model. As with whatlang, this effectively computes the inner products between the input and the models. Mapping was added by applying the mapping function to the model probabilities as they are read in from disk. As with LangDetect, disambiguating digits were used to al"
frederking-etal-2002-field,A94-1016,1,\N,Missing
frederking-etal-2002-field,C96-1030,1,\N,Missing
H01-1002,C96-1030,1,0.936318,"Missing"
H01-1002,1997.tmi-1.13,1,0.865412,"Missing"
H01-1002,1999.tmi-1.3,1,0.855174,"Missing"
H01-1002,C00-1019,1,0.91282,"Missing"
H01-1002,H94-1005,0,0.346482,"Missing"
H01-1002,hogan-frederking-1998-evaluation,1,0.902648,"Missing"
H01-1066,hogan-frederking-1998-evaluation,0,\N,Missing
H01-1066,C96-1030,1,\N,Missing
monson-etal-2004-data,2001.mtsummit-road.7,1,\N,Missing
monson-etal-2004-data,carbonell-etal-2002-automatic,1,\N,Missing
N06-2011,P02-1040,0,0.0811447,"Missing"
N06-2011,J90-2002,0,0.552015,"Missing"
N06-2011,1997.tmi-1.13,1,0.685111,"o equivalence classes and provides an outline of the Standard GAC algorithm. Section 3 describes the spectral clustering algorithm used. Sec41 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 41–44, c New York, June 2006. 2006 Association for Computational Linguistics tion 4 lists results obtained in a full evaluation of the algorithm. Section 5 concludes and discusses directions for future work. 2 Term vectors for clustering Using a bilingual dictionary, usually created using statistical methods such as those of (Brown et. al., 1990) or (Brown, 1997), and the parallel text, a rough mapping between source and target words can be created. This word pair is then treated as an indivisible token for future processing. For each such word pair we then accumulate counts for each token in the surrounding context of its occurrences (N words, currently 3, immediately prior to and N words immediately following). The counts are weighted with respect to distance from occurrence, with a linear decay (from 1 to 1/N) to give greatest importance to the words immediately adjacent to the word pair being examined. These counts form a pseudo-document for each"
N06-2011,C00-1019,1,\N,Missing
P02-1052,P98-1004,0,0.0163193,"age word   are said to cooccur if  occurs in a source language sentence and   occurs in the corresponding target language sentence. Cooccurrence scores then are then counts for all word pairs  and  , where  is in the source language vocabulary and   is in the target language vocabulary. Often, the scores also take into account the marginal probabilites of each word and sometimes also the conditional probabilities of one word given the other. Aside from the classic statistical approach of (Brown et al., 1990; Brown et al., 1993), a number of other algorithms have been developed. Ahrenberg et al. (1998) use morphological information on both the source and the target languages. This information serves to build equivalence classes of words based on suffices. A different approach was proposed by Gaussier (1998). This approach models word alignments as flow networks. Determining the word alignments then amounts to solving the network, for which there are known algorithms. Brown (1998) describes an algorithm that starts with ‘anchors’, words that are unambiguous translations of each other. From these anchors, alignments are expanded in both directions, so that entire segments can be aligned. The"
P02-1052,J90-2002,0,0.0242962,"ccurrences in sentence-aligned bilingual data. A source language word  and a target language word   are said to cooccur if  occurs in a source language sentence and   occurs in the corresponding target language sentence. Cooccurrence scores then are then counts for all word pairs  and  , where  is in the source language vocabulary and   is in the target language vocabulary. Often, the scores also take into account the marginal probabilites of each word and sometimes also the conditional probabilities of one word given the other. Aside from the classic statistical approach of (Brown et al., 1990; Brown et al., 1993), a number of other algorithms have been developed. Ahrenberg et al. (1998) use morphological information on both the source and the target languages. This information serves to build equivalence classes of words based on suffices. A different approach was proposed by Gaussier (1998). This approach models word alignments as flow networks. Determining the word alignments then amounts to solving the network, for which there are known algorithms. Brown (1998) describes an algorithm that starts with ‘anchors’, words that are unambiguous translations of each other. From these a"
P02-1052,P98-1074,0,0.0142098,"is in the source language vocabulary and   is in the target language vocabulary. Often, the scores also take into account the marginal probabilites of each word and sometimes also the conditional probabilities of one word given the other. Aside from the classic statistical approach of (Brown et al., 1990; Brown et al., 1993), a number of other algorithms have been developed. Ahrenberg et al. (1998) use morphological information on both the source and the target languages. This information serves to build equivalence classes of words based on suffices. A different approach was proposed by Gaussier (1998). This approach models word alignments as flow networks. Determining the word alignments then amounts to solving the network, for which there are known algorithms. Brown (1998) describes an algorithm that starts with ‘anchors’, words that are unambiguous translations of each other. From these anchors, alignments are expanded in both directions, so that entire segments can be aligned. The algorithm that this work was based on is the Competitive Linking algorithm. We used it to test our improved dictionary. Competitive Linking was described by Melamed (1997; 1998; 2000). It computes all possible"
P02-1052,melamed-1998-empirical,0,\N,Missing
P02-1052,J93-2003,0,\N,Missing
P02-1052,J00-2004,0,\N,Missing
P02-1052,P97-1063,0,\N,Missing
P02-1052,C98-1071,0,\N,Missing
P02-1052,C98-1004,0,\N,Missing
W02-0711,A94-1016,1,\N,Missing
W02-0711,C96-1030,1,\N,Missing
W02-0711,frederking-etal-2002-field,1,\N,Missing
W05-0813,2005.eamt-1.21,1,0.807615,"ignments. 1.4 Anchor Context If the adjacent words of the source fragment and the candidate target fragment are translations of each other, we expect that this alignment is more likely to be correct. We boost SFT with the anchor context alignment score SACp , SACp = P (si−1 ↔ tj−1 ) ∗ P (si+k ↔ tj+l ) (13) SFT ← (SFT )λ ∗ (SACp )1−λ (14) Empirically, we found this combination gives the best score for French-English when λ = 0.6 and for Romanian-English when λ = 0.8, and leads to better results than the similar formula SFT ← λ ∗ SFT + (1 − λ) ∗ SACp (15) 2 Experimental Design In previous work (Kim et al., 2005), we tested our alignment method on a set of French-English sentence pairs taken from the Canadian Hansard corpus and on a set of English-Chinese sentence pairs, and compared the results to human alignments. For the present workshop, we chose to use the RomanianEnglish data which had been made available. 89 Due to a lack of time prior to the period of the shared task, we merely re-used the parameters which had been tuned for French-English, rather than tuning the alignment parameters specifically for the development data. SPA was run under three experimental conditions. In the first, labeled “"
W05-0813,W02-1018,0,0.0296941,"ranslation (EBMT) system’s performance, since subsentential alignment is critical in locating the correct translation for a matched fragment of the input. Unlike most algorithms in the literature, this new Symmetric Probabilistic Alignment (SPA) algorithm treats the source and target languages in a symmetric fashion. 1. A fixed bilingual probabilistic dictionary is available. 2. Fragments (word sequences) are translated independently of surrounding context. 3. Contiguous fragments of source language text are translated into contiguous fragments in the target language text. Unlike the work of (Marcu and Wong, 2002), our alignment algorithm is not generative and does not use the idea of a bag of concepts from which the phrases in the sentence pair arise. It is, rather, intended to find the corresponding target-language phrase given a specific source-language phrase of interest, as required by our EBMT system after finding a match between the input and the training data (Brown, 2004). In this short paper, we outline our basic algorithm and some extensions for using context and positional information, and compare its alignment accuracy on the Romanian-English data for the shared task with IBM Model 4 and t"
W05-0813,W03-0301,0,0.143462,"Missing"
W05-0813,2003.mtsummit-papers.4,1,\N,Missing
W05-0813,brown-2004-modified,1,\N,Missing
W05-0813,C00-1019,1,\N,Missing
W05-0813,P02-1040,0,\N,Missing
W09-4633,P04-1075,0,0.099874,"gies are prone to outliers, which are common in MT systems. Instances can also be queried based on expected future error. This strategy is better resistant to outliers as it uses the unlabeled pool when estimating the future error. Density-weighted sampling strategy is also very common and is based on the idea that informative instances are those that are uncertain and representative of the input distribution. In this paper we will investigate these last two strategies. Although active learning has been well studied in many natural language processing tasks, such as, Named-Entity Recognition (Shen et al., 2004), Parsing (Thompson et al., 1999), Word-sense disambiguation (Chen et al., 2006), not much work has been done in using these techniques to improve machine translation. (Eck et al., 2005) used a weighting scheme to select more informative sentences, wherein the importance is estimated using the unseen n-grams in the sentences that were previously selected. The length of the source sentence and actual frequency of the n-grams is used in their weighting scheme. Their experiments were based on the assumption that target sentences are not available at selection time, hence, no information from the"
W09-4633,N06-1016,0,0.0181974,"e queried based on expected future error. This strategy is better resistant to outliers as it uses the unlabeled pool when estimating the future error. Density-weighted sampling strategy is also very common and is based on the idea that informative instances are those that are uncertain and representative of the input distribution. In this paper we will investigate these last two strategies. Although active learning has been well studied in many natural language processing tasks, such as, Named-Entity Recognition (Shen et al., 2004), Parsing (Thompson et al., 1999), Word-sense disambiguation (Chen et al., 2006), not much work has been done in using these techniques to improve machine translation. (Eck et al., 2005) used a weighting scheme to select more informative sentences, wherein the importance is estimated using the unseen n-grams in the sentences that were previously selected. The length of the source sentence and actual frequency of the n-grams is used in their weighting scheme. Their experiments were based on the assumption that target sentences are not available at selection time, hence, no information from the target half of the data was used. Sentences were also weighted based on TF-IDF w"
W09-4633,P02-1040,0,0.0862527,"o easily port an MT system onto small devices that have less memory and storage capacity. In this paper, we propose using Active Learning strategies to sample the most informative sentence pairs. There has not been much progress in the application of active learning theory in machine translation due to the complexity of the translation models. We use a poolbased strategy to selectively sample instances from a parallel corpora which not only outperformed a random selector but also a previously used sampling strategy (Eck et al., 2005) in an EBMT framework (Brown, 2000) by about one BLEU point (Papineni et al., 2002). 1 Introduction An EBMT system uses source-target sentence pairs present in a parallel corpus to translate new input source sentences. The input sentence to be translated is matched against the source sentences present in the corpus. When a match is found, the corresponding translation in the target language is obtained through sub-sentential alignKristiina Jokinen and Eckhard Bick (Eds.) NODALIDA 2009 Conference Proceedings, pp. 227–230 Jaime Carbonell Carnegie Mellon University Pittsburgh, PA jgc@cs.cmu.edu ment. The translation is generated from the partial target phrasal matches using a d"
W09-4633,2005.iwslt-1.7,0,0.309278,"quality translations. Reducing the amount of training data also enables one to easily port an MT system onto small devices that have less memory and storage capacity. In this paper, we propose using Active Learning strategies to sample the most informative sentence pairs. There has not been much progress in the application of active learning theory in machine translation due to the complexity of the translation models. We use a poolbased strategy to selectively sample instances from a parallel corpora which not only outperformed a random selector but also a previously used sampling strategy (Eck et al., 2005) in an EBMT framework (Brown, 2000) by about one BLEU point (Papineni et al., 2002). 1 Introduction An EBMT system uses source-target sentence pairs present in a parallel corpus to translate new input source sentences. The input sentence to be translated is matched against the source sentences present in the corpus. When a match is found, the corresponding translation in the target language is obtained through sub-sentential alignKristiina Jokinen and Eckhard Bick (Eds.) NODALIDA 2009 Conference Proceedings, pp. 227–230 Jaime Carbonell Carnegie Mellon University Pittsburgh, PA jgc@cs.cmu.edu m"
W10-1758,2005.mtsummit-papers.11,0,0.00488182,"or training, we used all of the glossary, all but the last 300 phrase pairs of the medical phrasebook (these had previously been used for development and testing of a “toy” system), and the first 12,500 sentence pairs of the newswire text. Tuning was performed using the next 217 sentence pairs of the newswire text, and the test set consisted of the final 800 sentence pairs of the newswire text. The target language model was built solely from the target half of the training corpus, as we did not have any additional Haitian Creole text. The French-to-English system was built using the Europarl (Koehn, 2005) version 3 data for French and English. As is usual practice, text from the fourth quarter of 2000 was omitted from the training set. Tuning was performed using 200 sentences from the “devtest2006” file and all 2000 sentences of “test2007” were used as the final test set. Two target language models were built and interpolated during decoding; the first was trained on the target half of the bilingal corpus, and the second was built using the Canadian Hansards text released by ISI (Natural Language Group, 2001). For French-English, we determined the best value of β for the Rouge-S scoring to be"
W10-1758,2007.mtsummit-papers.3,0,0.360773,"nted. 1 • the size of the sample of retrieved training instances for a given input phrase which are aligned, • the weight of source features for ranking training instances during sampling, and • the minimum alignment score to accept a translation instance Introduction Structured perceptrons are a relatively recent (Collins, 2002) update of the classic perceptron algorithm which permit the prediction of vectors of values. Initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (Arun and Koehn, 2007), and found to have performance similar to the Margin-Infused Relaxed Algorithm (MIRA) by Crammer and Singer (2003; 2006) and Minimum-Error Rate Training (MERT) by Och (2003). Parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as BLEU (Papineni et al., 2002) or METEOR (Banerjee and Lavie, 2005). When we recently added new features to the CMU-EBMT translation system (Brown, 1996; Decoder parameters which are important to tune, but which are generally not"
W10-1758,P04-1077,0,0.0156025,"ng rate of the update step, i.e. w ~ ←w ~ + SΦoracle × (Φoracle − Φtop1 ) Structured Perceptrons (3) As can be seen, the difference between Equations 2 and 3 is simply the additional factor of SΦoracle . The structured perceptron algorithm can be applied to tasks where the goal is to select the best among competing hypotheses, where each hypoth385 While we initially used sentence-level smoothed BLEU as the objective function, we found it to perform very poorly (the full BLEU scores on the Haitian Creole tuning set were well below 0.10), and instead adopted the Rouge-S (skip bigrams) metric by Lin and Och (2004a) with a maximum skip distance of four words, which was found to best correlate with human quality judgements (Lin and Och, 2004b). In early testing, we found that both the feature weights and performance as measured by the average objective score over the tuning set oscillated wildly. Analyzing the results, it became apparent that the update function was overly aggressive. Unlike the binary features used in (Arun and Koehn, 2007), our continuous-valued features have different operating ranges for each feature, e.g. the total distance moved as a result of reordering could reach 100 on a long"
W10-1758,W05-0909,0,0.00746625,"developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (Arun and Koehn, 2007), and found to have performance similar to the Margin-Infused Relaxed Algorithm (MIRA) by Crammer and Singer (2003; 2006) and Minimum-Error Rate Training (MERT) by Och (2003). Parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as BLEU (Papineni et al., 2002) or METEOR (Banerjee and Lavie, 2005). When we recently added new features to the CMU-EBMT translation system (Brown, 1996; Decoder parameters which are important to tune, but which are generally not mentioned in the literature include • how many alternative translations of a phrase to consider during decoding, • the size of the reordering window, and • the rank of the language model (4-gram, 5gram, etc.) In addition, it is desirable to tune parameters such as beam width to minimize translation time without degrading performance. 1 Source code for CMU-EBMT is available from http://cmu-ebmt.sourceforge.net. 2 Coordinate ascent is"
W10-1758,C04-1072,0,0.0199803,"ng rate of the update step, i.e. w ~ ←w ~ + SΦoracle × (Φoracle − Φtop1 ) Structured Perceptrons (3) As can be seen, the difference between Equations 2 and 3 is simply the additional factor of SΦoracle . The structured perceptron algorithm can be applied to tasks where the goal is to select the best among competing hypotheses, where each hypoth385 While we initially used sentence-level smoothed BLEU as the objective function, we found it to perform very poorly (the full BLEU scores on the Haitian Creole tuning set were well below 0.10), and instead adopted the Rouge-S (skip bigrams) metric by Lin and Och (2004a) with a maximum skip distance of four words, which was found to best correlate with human quality judgements (Lin and Och, 2004b). In early testing, we found that both the feature weights and performance as measured by the average objective score over the tuning set oscillated wildly. Analyzing the results, it became apparent that the update function was overly aggressive. Unlike the binary features used in (Arun and Koehn, 2007), our continuous-valued features have different operating ranges for each feature, e.g. the total distance moved as a result of reordering could reach 100 on a long"
W10-1758,P03-1021,0,0.0240393,"ng, and • the minimum alignment score to accept a translation instance Introduction Structured perceptrons are a relatively recent (Collins, 2002) update of the classic perceptron algorithm which permit the prediction of vectors of values. Initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (Arun and Koehn, 2007), and found to have performance similar to the Margin-Infused Relaxed Algorithm (MIRA) by Crammer and Singer (2003; 2006) and Minimum-Error Rate Training (MERT) by Och (2003). Parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as BLEU (Papineni et al., 2002) or METEOR (Banerjee and Lavie, 2005). When we recently added new features to the CMU-EBMT translation system (Brown, 1996; Decoder parameters which are important to tune, but which are generally not mentioned in the literature include • how many alternative translations of a phrase to consider during decoding, • the size of the reordering window, and • the rank of the l"
W10-1758,C96-1030,1,0.383687,"in the log-linear models used by statistical machine translation (Arun and Koehn, 2007), and found to have performance similar to the Margin-Infused Relaxed Algorithm (MIRA) by Crammer and Singer (2003; 2006) and Minimum-Error Rate Training (MERT) by Och (2003). Parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as BLEU (Papineni et al., 2002) or METEOR (Banerjee and Lavie, 2005). When we recently added new features to the CMU-EBMT translation system (Brown, 1996; Decoder parameters which are important to tune, but which are generally not mentioned in the literature include • how many alternative translations of a phrase to consider during decoding, • the size of the reordering window, and • the rank of the language model (4-gram, 5gram, etc.) In addition, it is desirable to tune parameters such as beam width to minimize translation time without degrading performance. 1 Source code for CMU-EBMT is available from http://cmu-ebmt.sourceforge.net. 2 Coordinate ascent is described in more detail in Section 7. 384 Proceedings of the Joint 5th Workshop on S"
W10-1758,P02-1040,0,0.0881809,"on of vectors of values. Initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (Arun and Koehn, 2007), and found to have performance similar to the Margin-Infused Relaxed Algorithm (MIRA) by Crammer and Singer (2003; 2006) and Minimum-Error Rate Training (MERT) by Och (2003). Parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as BLEU (Papineni et al., 2002) or METEOR (Banerjee and Lavie, 2005). When we recently added new features to the CMU-EBMT translation system (Brown, 1996; Decoder parameters which are important to tune, but which are generally not mentioned in the literature include • how many alternative translations of a phrase to consider during decoding, • the size of the reordering window, and • the rank of the language model (4-gram, 5gram, etc.) In addition, it is desirable to tune parameters such as beam width to minimize translation time without degrading performance. 1 Source code for CMU-EBMT is available from http://cmu-ebmt.sou"
W10-1758,2008.amta-papers.2,1,0.877955,"Missing"
W10-1758,D08-1024,0,0.045347,"Missing"
W10-1758,W02-1001,0,0.476883,"es the performance of the resulting algorithm to standard minimum error-rate training (MERT). In addition, preliminary results for combining MERT or structured-perceptron tuning of the log-linear feature weights with coordinate ascent of other translation system parameters are presented. 1 • the size of the sample of retrieved training instances for a given input phrase which are aligned, • the weight of source features for ranking training instances during sampling, and • the minimum alignment score to accept a translation instance Introduction Structured perceptrons are a relatively recent (Collins, 2002) update of the classic perceptron algorithm which permit the prediction of vectors of values. Initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (Arun and Koehn, 2007), and found to have performance similar to the Margin-Infused Relaxed Algorithm (MIRA) by Crammer and Singer (2003; 2006) and Minimum-Error Rate Training (MERT) by Och (2003). Parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weight"
W10-1758,W10-1721,0,\N,Missing
