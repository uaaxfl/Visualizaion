2020.acl-main.402,P11-1119,0,0.0682516,"Missing"
2020.acl-main.402,P19-1455,0,0.043848,"Missing"
2020.acl-main.402,N18-2008,0,0.0288682,"ed content or its pragmatic content (Barrett et al., 1993). An utterance such as “Okay sure” or “Ya right” (say) can be considered as “agreement” or- in case of sarcasm- “disagreement”. For expressive DAs such as “greeting”, “thanking”, “apologizing” etc., the speaker’s feeling or emotion can assist in recognizing true communicative intent and vice-versa. Thus, it is important to consider the speaker’s emotion when deciding on the DA. There is considerable work on ER (Cowie et al., 2001), (Jain et al., 2018), (Zhang et al., 2018), etc. and adapting the Virtual Agents (VAs) to act accordingly (Huang et al., 2018), (Zhou et al., 2018), (Fung et al., 2018), etc. But very little research has been done, that addresses the impact of emotion while deciding the DA of an utterance (Novielli and Strapparava, 2013), (Bosma and Andr´e, 2004). As DAs primarily dictate the flow of any dialogue conversation (be it human-human or human-computer), such synergy of ER and DAC is required. Research too has shown the benefit of utilizing the combination of text and nonverbal cues (Poria et al., 2017b), (Poria et al., 2017a) etc., for solving various Natural Language Processing (NLP) tasks. The main advantage of integrati"
2020.acl-main.402,W13-3214,0,0.0273457,"nd single task DAC variants. 1 Introduction Dialogue Act Classification (DAC) is concerned with deciding the type i.e., communicative intention (question, statement, command etc.) of the speaker’s utterance. DAC is very important in the context of discourse structure, which in turn supports intelligent dialogue systems, conversational speech transcription and so on. Considerable works have been done on classical Machine Learning (ML) based DAC (Jurafsky et al., 1997), (Stolcke et al., 2000), (Verbree et al., 2006), etc. and Deep ∗ The authors have contributed equally. Learning (DL) based DAC (Kalchbrenner and Blunsom, 2013), (Papalampidi et al., 2017), (Liu et al., 2017), (Ribeiro et al., 2019), (Ortega et al., 2019), (Saha et al., 2019) etc. Humans are emotional entities. A speaker’s emotional state considerably influences or affects its intended content or its pragmatic content (Barrett et al., 1993). An utterance such as “Okay sure” or “Ya right” (say) can be considered as “agreement” or- in case of sarcasm- “disagreement”. For expressive DAs such as “greeting”, “thanking”, “apologizing” etc., the speaker’s feeling or emotion can assist in recognizing true communicative intent and vice-versa. Thus, it is impo"
2020.acl-main.402,C16-1189,0,0.0172081,"was to construct DA-emotion combinations from the pre-annotated corpus. However, such stringent associations or dis-associations amongst DA-emotion pairs may not truly hold for real life conversations. Related Works The tasks of ER and DAC are extensively explored. Dialogue Act Frameworks: DAC has been investigated since late 90s (Reithinger and Klesen, 1997), (Stolcke et al., 1998) and early 2000’s (Stolcke et al., 2000), (Grau et al., 2004). Much of this research, however, uses chat transcripts with only the text mode, due partly due to unavailability of multi-modal open-source dataset. In (Khanpour et al., 2016), authors apply stacked LSTM to classify speech acts. In (Kumar et al., 2018), the author developed a Hierarchical Network based approach using Bi-LSTMs and the CRF. A contextual self-attention system fused with hierarchical recurrent units was proposed by the authors of (Raheja and Tetreault, 2019) to develop a sequence label classifier. The authors of (Yu et al., 2019) proposed a method for the capture of long-range interactions that span a series of words using a Convolutional Network based approach. In (Saha et al., 2019), authors proposed several ML and DL based 3 Dataset To facilitate an"
2020.acl-main.402,D17-1231,0,0.0214761,"ification (DAC) is concerned with deciding the type i.e., communicative intention (question, statement, command etc.) of the speaker’s utterance. DAC is very important in the context of discourse structure, which in turn supports intelligent dialogue systems, conversational speech transcription and so on. Considerable works have been done on classical Machine Learning (ML) based DAC (Jurafsky et al., 1997), (Stolcke et al., 2000), (Verbree et al., 2006), etc. and Deep ∗ The authors have contributed equally. Learning (DL) based DAC (Kalchbrenner and Blunsom, 2013), (Papalampidi et al., 2017), (Liu et al., 2017), (Ribeiro et al., 2019), (Ortega et al., 2019), (Saha et al., 2019) etc. Humans are emotional entities. A speaker’s emotional state considerably influences or affects its intended content or its pragmatic content (Barrett et al., 1993). An utterance such as “Okay sure” or “Ya right” (say) can be considered as “agreement” or- in case of sarcasm- “disagreement”. For expressive DAs such as “greeting”, “thanking”, “apologizing” etc., the speaker’s feeling or emotion can assist in recognizing true communicative intent and vice-versa. Thus, it is important to consider the speaker’s emotion when dec"
2020.acl-main.402,D14-1162,0,0.0837994,"mage classification model. Initially, each of the frames is preprocessed which includes resizing and normalizing. So, the visual representation of each utterance (F ) is obtained by concatenating the obtained df = 4096 dimensional feature vector for every frame, i.e., F ∈ Rf ×df (Castro et al., 2019), (Illendula and Sheth, 2019), (Poria et al., 2017b), (Poria et al., 2017a). 4.2 Here, we discuss, the process of multi-modal feature extraction. Textual Features. The transcriptions available for each video forms the source of the textual modality2 . To extract textual features, pretrained GloVe (Pennington et al., 2014) embeddings of dimension 300 have been used to obtain representation of words as word vectors. The resultant word embeddings of each word are concatenated to obtain a final utterance representation. While it is indeed possible to use more advanced textual encoding techniques (for e.g., convolutional or recurrent neural network), we decided to use the same pre-trained extractive strategy as in the case of other modalities. Audio Features. To elicit features from the audio, openSMILE (Eyben et al., 2010), an open source software has been used. The features obtained by openSMILE include maxima di"
2020.acl-main.402,P13-1096,0,0.0779492,"Missing"
2020.acl-main.402,P17-1081,0,0.133718,"e et al., 2001), (Jain et al., 2018), (Zhang et al., 2018), etc. and adapting the Virtual Agents (VAs) to act accordingly (Huang et al., 2018), (Zhou et al., 2018), (Fung et al., 2018), etc. But very little research has been done, that addresses the impact of emotion while deciding the DA of an utterance (Novielli and Strapparava, 2013), (Bosma and Andr´e, 2004). As DAs primarily dictate the flow of any dialogue conversation (be it human-human or human-computer), such synergy of ER and DAC is required. Research too has shown the benefit of utilizing the combination of text and nonverbal cues (Poria et al., 2017b), (Poria et al., 2017a) etc., for solving various Natural Language Processing (NLP) tasks. The main advantage of integrating other modalities to text is the usage of behavioral signs present in acoustic (vocal modulations) and visual (facial expression) modalities. In addition, the various modalities offer important signals to better identify the speaker’s communicative intention and emotional state. This will in effect help create sturdy and more reliable DAC models. In this paper, we study the influence of emotion on the identification of DAs, by utilizing the com4361 Proceedings of the 58"
2020.acl-main.402,P19-1050,0,0.0501084,"uce a new dataset (EMOTyDA) consisting of short videos of dialogue conversations manually annotated with its DA along with its pre-annotated emotions. 3.1 Data Collection To gather potentially emotion rich conversations to explore its affect on DAC, we scanned the literature for existing multi-modal ER dataset. During our initial search, we obtained several multi-modal ER datasets which include Youtube (Morency et al., 2011), MOUD (P´erez-Rosas et al., 2013), IEMOCAP (Busso et al., 2008), ICT-MMMO (W¨ollmer et al., 2013), CMU-MOSI (Zadeh et al., 2016), CMU-MOSEI (Zadeh et al., 2018) and MELD (Poria et al., 2019) etc. However, we zeroed down on IEMOCAP and MELD datasets for the further 4362 investigations of our problem statement. The reason behind this choice was that remaining all the datasets mentioned above were particularly monologues involving opinions and product reviews. Whereas our research requires task-independent dyadic or multi-party conversations to analyze its full potential. Both these available datasets are not annotated for their corresponding DAs. Also, benchmark DAC datasets such as Switchboard (SWBD) (Godfrey et al., 1992), ICSI Meeting Recorder (Shriberg et al., 2004) consist of"
2020.acl-main.402,N19-1373,0,0.0177999,"has been investigated since late 90s (Reithinger and Klesen, 1997), (Stolcke et al., 1998) and early 2000’s (Stolcke et al., 2000), (Grau et al., 2004). Much of this research, however, uses chat transcripts with only the text mode, due partly due to unavailability of multi-modal open-source dataset. In (Khanpour et al., 2016), authors apply stacked LSTM to classify speech acts. In (Kumar et al., 2018), the author developed a Hierarchical Network based approach using Bi-LSTMs and the CRF. A contextual self-attention system fused with hierarchical recurrent units was proposed by the authors of (Raheja and Tetreault, 2019) to develop a sequence label classifier. The authors of (Yu et al., 2019) proposed a method for the capture of long-range interactions that span a series of words using a Convolutional Network based approach. In (Saha et al., 2019), authors proposed several ML and DL based 3 Dataset To facilitate and enhance the research in multimodal DAC assisted with user emotion, we introduce a new dataset (EMOTyDA) consisting of short videos of dialogue conversations manually annotated with its DA along with its pre-annotated emotions. 3.1 Data Collection To gather potentially emotion rich conversations to"
2020.acl-main.402,W04-2319,0,0.0556343,"018) and MELD (Poria et al., 2019) etc. However, we zeroed down on IEMOCAP and MELD datasets for the further 4362 investigations of our problem statement. The reason behind this choice was that remaining all the datasets mentioned above were particularly monologues involving opinions and product reviews. Whereas our research requires task-independent dyadic or multi-party conversations to analyze its full potential. Both these available datasets are not annotated for their corresponding DAs. Also, benchmark DAC datasets such as Switchboard (SWBD) (Godfrey et al., 1992), ICSI Meeting Recorder (Shriberg et al., 2004) consist of text and audio-based conversations whereas TRAINS (Heeman and Allen, 1995) consist of solely textbased conversations with no emotional tags. HCRC Map Task corpus (Anderson et al., 1991) additionally encompasses audio modality with the transcripts but the corpus itself has task-oriented conversations and is not annotated for its emotion tags. It is to be noted that task-oriented conversations generally restrict the presence of diverse tags which are commonly encountered in task-independent conversations. To the best of our knowledge, at the time of writing, we were unaware of any si"
2020.acl-main.402,J00-3003,0,0.856075,"Missing"
2020.acl-main.402,P18-1208,0,0.0129908,"d with user emotion, we introduce a new dataset (EMOTyDA) consisting of short videos of dialogue conversations manually annotated with its DA along with its pre-annotated emotions. 3.1 Data Collection To gather potentially emotion rich conversations to explore its affect on DAC, we scanned the literature for existing multi-modal ER dataset. During our initial search, we obtained several multi-modal ER datasets which include Youtube (Morency et al., 2011), MOUD (P´erez-Rosas et al., 2013), IEMOCAP (Busso et al., 2008), ICT-MMMO (W¨ollmer et al., 2013), CMU-MOSI (Zadeh et al., 2016), CMU-MOSEI (Zadeh et al., 2018) and MELD (Poria et al., 2019) etc. However, we zeroed down on IEMOCAP and MELD datasets for the further 4362 investigations of our problem statement. The reason behind this choice was that remaining all the datasets mentioned above were particularly monologues involving opinions and product reviews. Whereas our research requires task-independent dyadic or multi-party conversations to analyze its full potential. Both these available datasets are not annotated for their corresponding DAs. Also, benchmark DAC datasets such as Switchboard (SWBD) (Godfrey et al., 1992), ICSI Meeting Recorder (Shri"
2020.acl-main.570,W08-0601,0,0.0412887,"Missing"
2020.acl-main.570,P19-2058,0,0.0280191,"rocessing (BioNLP) researchers to automatically extract PPI information by exploring various AI techniques. Recent advancements in deep learning (LeCun et al., 2015)(Bengio et al., 2007) have opened up new avenues in solving different well-known problems ranging from computational biology (Alipanahi et al., 2015; Dutta et al., 2019a), machine translations (Cho et al., 2014), image captioning (Chen et al., 2017). Subsequently, there is a notable trend in using deep learning for solving different natural language processing (NLP) tasks in the biomedical and clinical domains (Asada et al., 2018; Alimova and Tutubalina, 2019) including the identification of protein-protein interactions from biomedical corpora (Yadav et al., 2019; Peng and Lu, 2017). Multi-modal deep learning models, combining information from multiple sources/modalities, show promising results compared to the conventional single modal-based models while solving various NLP tasks like sentiment and emotion recognition (Qureshi et al., 2019, 2020), natural language generation, machine translation (Poria et al., 2018; Zhang et al., 2019; Qiao et al., 2019; Fan et al., 2019) etc. There exist few popular multi-modal datasets which are extensively used"
2020.acl-main.570,P18-2108,0,0.125566,"Missing"
2020.acl-main.570,D07-1024,0,0.0607875,"identification. To the best of our knowledge, this is the first attempt in this direction. 4. The results and the comparative study prove the effectiveness of our developed multimodal datasets along with proposed multimodal architecture. 2 Related Works There are few works (Ono et al., 2001; Blaschke et al., 1999; Huang et al., 2004) which focus on rule-based PPI information extraction method such as co-occurrence rules (Stapley and Benoit, 1999) from the biomedical texts. In (Giuliano et al., 2006), relation is extracted from entire sentence by considering the shallow syntactic information. (Erkan et al., 2007) utilize semi-supervised learning and cosine similarity to find the shortest dependency path (SDP) between protein entities. Some important kernel-based methods for PPI extraction task are graph kernel (Airola et al., 2008a), bagof-word (BoW) kernel (Sætre et al., 2007), editdistance kernel (Erkan et al., 2007) and all-path kernel (Airola et al., 2008b). (Yadav et al., 2019) presented an attention-based bidirectional long shortterm memory networks (BiLSTM) model that uses SDP between protein pairs, latent PoS and position 6397 An Instance from HRPD50 Megalin and cubilin: multifunctional endocy"
2020.acl-main.570,L18-1252,0,0.0197431,"2019; Peng and Lu, 2017). Multi-modal deep learning models, combining information from multiple sources/modalities, show promising results compared to the conventional single modal-based models while solving various NLP tasks like sentiment and emotion recognition (Qureshi et al., 2019, 2020), natural language generation, machine translation (Poria et al., 2018; Zhang et al., 2019; Qiao et al., 2019; Fan et al., 2019) etc. There exist few popular multi-modal datasets which are extensively used in solving various problems in NLP like emotion recognition from conversations (Poria et al., 2018; Chen et al., 2018), image captioning (Lin et al., 2014), sentiment analysis (Zadeh et al., 2016), etc. Compared to single modal-based approaches, multi-modal techniques provide a more comprehensive perspective of the 6396 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6396–6407 c July 5 - 10, 2020. 2020 Association for Computational Linguistics dataset under consideration. Despite the popularity of multi-modal approaches in solving traditional NLP tasks, there is a dearth of multi-modal datasets in BioNLP domain especially for the PPI identification task. The avai"
2020.acl-main.570,E06-1051,0,0.106123,"work is a step towards integrating multiomics information with text-mining from biomedical articles for enhancing PPI identification. To the best of our knowledge, this is the first attempt in this direction. 4. The results and the comparative study prove the effectiveness of our developed multimodal datasets along with proposed multimodal architecture. 2 Related Works There are few works (Ono et al., 2001; Blaschke et al., 1999; Huang et al., 2004) which focus on rule-based PPI information extraction method such as co-occurrence rules (Stapley and Benoit, 1999) from the biomedical texts. In (Giuliano et al., 2006), relation is extracted from entire sentence by considering the shallow syntactic information. (Erkan et al., 2007) utilize semi-supervised learning and cosine similarity to find the shortest dependency path (SDP) between protein entities. Some important kernel-based methods for PPI extraction task are graph kernel (Airola et al., 2008a), bagof-word (BoW) kernel (Sætre et al., 2007), editdistance kernel (Erkan et al., 2007) and all-path kernel (Airola et al., 2008b). (Yadav et al., 2019) presented an attention-based bidirectional long shortterm memory networks (BiLSTM) model that uses SDP betw"
2020.acl-main.570,C10-1024,0,0.820758,"th nine existing approaches for HRPD50 dataset. The comparative results for HRPD50 dataset are presented in Table 3. 6.4 The results reported in Table 1 illustrate the supremacy of the proposed multi-modal approach over other baselines. 6.3 Comparison with State-of-the-art Additionally, along with the baselines, we have compared the performance of our multi-modal approach with several existing works reported in the literature. For BioInfer dataset, we have compared our proposed method with nine state-of-theart models. These existing methods are based on different techniques like kernel-based (Choi and Myaeng, 2010; Tikk et al., 2010; Qian and Zhou, 2012; Li et al., 2015), deep neural network-based (Zhao et al., 2016), multi-channel dependencybased convolutional neural network model (Peng and Lu, 2017), semantic feature embedding (Choi, 2018) and shortest dependency path (Hua and Quan, 2016). Along with the aforementioned methods, we have also compared our approach with a recent deep learning-based approach proposed by (Yadav et al., 2019). The comparative performance analysis for BioInfer dataset is tabulated in Table Precision Proposed Model (Yadav et al., 2019) (Hua and Quan, 2016) (Choi, 2018) (Qian"
2020.acl-main.570,I17-2041,0,0.454858,"the proteins. The biomedical and clinical text database is an important resource for learning about physical interactions amongst protein molecules; however, it may not be adequate for exploring biological aspects of these interactions. In the field of Bioinformatics, there are various web-based enriched archives12 that contain multi-omics biological information regarding protein interactions. The integration of multi-omics information from these aforementioned databases helps in understanding the various physiological characteristics (Sun et al., 2019; Ray et al., 2014; Amemiya et al., 2019; Hsieh et al., 2017; Dutta et al., 2020). Hence, in our current work, along with the textual information from biomedical corpora, we have also incorporated structural properties of protein molecules as biological information for solving PPI task. For structural information of proteins, we have considered the atomic structure (3D PDB structure) and underlying nucleotide sequence (FASTA sequence) of protein molecules. In the BioNLP domain, collection of biological data (muti-omics information) from the text corpus is little difficult. To obtain the aforementioned information about other modalities, we need to expl"
2020.acl-main.570,W17-2304,0,0.470782,"learning (LeCun et al., 2015)(Bengio et al., 2007) have opened up new avenues in solving different well-known problems ranging from computational biology (Alipanahi et al., 2015; Dutta et al., 2019a), machine translations (Cho et al., 2014), image captioning (Chen et al., 2017). Subsequently, there is a notable trend in using deep learning for solving different natural language processing (NLP) tasks in the biomedical and clinical domains (Asada et al., 2018; Alimova and Tutubalina, 2019) including the identification of protein-protein interactions from biomedical corpora (Yadav et al., 2019; Peng and Lu, 2017). Multi-modal deep learning models, combining information from multiple sources/modalities, show promising results compared to the conventional single modal-based models while solving various NLP tasks like sentiment and emotion recognition (Qureshi et al., 2019, 2020), natural language generation, machine translation (Poria et al., 2018; Zhang et al., 2019; Qiao et al., 2019; Fan et al., 2019) etc. There exist few popular multi-modal datasets which are extensively used in solving various problems in NLP like emotion recognition from conversations (Poria et al., 2018; Chen et al., 2018), image"
2020.icon-main.25,P18-1063,0,0.119205,"its less storage requirement (opposed to other modes of communication like audio and video). Text summarization is a problem at the very core of natural ∗ * means equal contribution. https://news.gallup.com/poll/179288/new-eracommunication-americans.aspx 1 language processing, and has various applications in the spoken languages, including summarization of conversations, and public speeches. Some works have been done in the field of reinforcement learning based text summarization (Dong et al., 2018; Liu et al., 2018), the most prominent architecture being extractor-abstractor (EXT-ABS) model (Chen and Bansal, 2018). Inspired from this architecture, in this manuscript, we have proposed an extractor-paraphraser system that uses semantic information overlap as the underlying guidance strategy. The model is further enhanced to surpass its limits using reinforcement learning, for which we have proposed a novel semantic overlap based reward function. Word Mover Similarity (WMS) (Clark et al., 2019) is utilized to evaluate semantic similarity across generated sentences and the true ground truth summary sentences. We assume that paraphrasing is a relatively simpler task than abstractive summarization, with the"
2020.icon-main.25,D14-1181,0,0.00422376,"Missing"
2020.icon-main.25,N16-1012,0,0.0306774,"d to tackle both extractive and abstractive summarization. Initial research (Paice, 1990; Kupiec et al., 1995) focused on extractive summarization due to its easier setup. Various techniques ranging from integer linear programming (Galanis et al., 2012), graph based approaches (Mihalcea and Tarau, 2004; Mihalcea, 2004), genetic algorithms (Saini et al., 2019a,b), and neural networks (Nallapati et al., 2017; Zhang et al., 2016) have been adopted to solve the extractive summarization task. The majority of the research in abstractive summarization revolves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot of domain specific summarization techniques have also been explored, like radiology findings summarization (Zhang et al., 2018), across-time summarization (Duan and Jatowt, 2019), movie review summarization (Zhuang et al., 2006), book summarization (Mihalcea and Ceylan, 2007), and customer review based opinion summ"
2020.icon-main.25,P19-1264,0,0.142154,"eches. Some works have been done in the field of reinforcement learning based text summarization (Dong et al., 2018; Liu et al., 2018), the most prominent architecture being extractor-abstractor (EXT-ABS) model (Chen and Bansal, 2018). Inspired from this architecture, in this manuscript, we have proposed an extractor-paraphraser system that uses semantic information overlap as the underlying guidance strategy. The model is further enhanced to surpass its limits using reinforcement learning, for which we have proposed a novel semantic overlap based reward function. Word Mover Similarity (WMS) (Clark et al., 2019) is utilized to evaluate semantic similarity across generated sentences and the true ground truth summary sentences. We assume that paraphrasing is a relatively simpler task than abstractive summarization, with the underlying intuition that paraphrasing is a subproblem within abstractive summarization. To bolster our hypothesis, experiments are conducted on the extractor-abstractor (EXT-ABS) model (Chen and Bansal, 2018) and the Pointer Generator Network (PGN) (See et al., 2017), which is used as the basic abstraction unit in the former architecture. The results are rather staggering and revea"
2020.icon-main.25,D18-1409,0,0.0229837,"Missing"
2020.icon-main.25,C12-1056,0,0.0303599,"setup and the datasets used. A thorough discussion and state the results are provided in Section 5, followed by the conclusion and future work in Section 6. 2 Related Work Automatic text summarization has been extensively researched over more than three decades, and has shown a lot of progress and promise over the course of time. Various approaches have been explored to tackle both extractive and abstractive summarization. Initial research (Paice, 1990; Kupiec et al., 1995) focused on extractive summarization due to its easier setup. Various techniques ranging from integer linear programming (Galanis et al., 2012), graph based approaches (Mihalcea and Tarau, 2004; Mihalcea, 2004), genetic algorithms (Saini et al., 2019a,b), and neural networks (Nallapati et al., 2017; Zhang et al., 2016) have been adopted to solve the extractive summarization task. The majority of the research in abstractive summarization revolves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010)"
2020.icon-main.25,C10-1039,0,0.051052,"(Galanis et al., 2012), graph based approaches (Mihalcea and Tarau, 2004; Mihalcea, 2004), genetic algorithms (Saini et al., 2019a,b), and neural networks (Nallapati et al., 2017; Zhang et al., 2016) have been adopted to solve the extractive summarization task. The majority of the research in abstractive summarization revolves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot of domain specific summarization techniques have also been explored, like radiology findings summarization (Zhang et al., 2018), across-time summarization (Duan and Jatowt, 2019), movie review summarization (Zhuang et al., 2006), book summarization (Mihalcea and Ceylan, 2007), and customer review based opinion summarization (Pecar, 2018). Lately, multi-modal summarization (Jangra et al., 2020a,b; Zhu et al., 2020; Saini et al., 2020) has also gained popularity . Recently, people have also explored reinforcement learning to tackle the problem o"
2020.icon-main.25,W04-1013,0,0.0626996,"r model [Id − ext M2On=2 ]: The ’n-to-1’ paraphraser with n = 2 METEOR WMS 22.81 21.86 21.62 14.28 14.24 18.72 19.39 19.24 16.13 13.36 13.81 12.92 20.38 20.52 21.47 21.34 18.25 13.7 14.56 14.42 14.6 13.52 24.36 24.61 22.22 19.34 20.14 17.99 and the exemplary-extracted sentences assumed as the extractor (generating exemplary-extracted sentences as proposed in Eq. 4). 5 Results Results of different baselines and the proposed approach are discussed in this section. Table 1 illustrates that our proposed techniques perform better than the rest of the systems. We have used ROUGE1, ROUGE-2, ROUGE-L (Lin, 2004), METEOR (Banerjee and Lavie, 2005) and word mover similarity (WMS) (Clark et al., 2019) as evaluation metrics. We believe that ROUGE as an evaluation metric is incapable of judging the quality of an abstractive summary due to its emphasis on syntactic overlap over semantic overlap (Liu et al., 2016; Clark et al., 2019; Novikova et al., 2017). To overcome this, we have also used WMS as an evaluation metric. 195 5.1 Semantic information overlap It is noticed that the proposed paraphraser in model O2O (w/o RL) outperforms the abstractor from EXT − ABS (w/o RL) in terms of ROUGE scores, while sco"
2020.icon-main.25,D16-1230,0,0.0128403,"extractor (generating exemplary-extracted sentences as proposed in Eq. 4). 5 Results Results of different baselines and the proposed approach are discussed in this section. Table 1 illustrates that our proposed techniques perform better than the rest of the systems. We have used ROUGE1, ROUGE-2, ROUGE-L (Lin, 2004), METEOR (Banerjee and Lavie, 2005) and word mover similarity (WMS) (Clark et al., 2019) as evaluation metrics. We believe that ROUGE as an evaluation metric is incapable of judging the quality of an abstractive summary due to its emphasis on syntactic overlap over semantic overlap (Liu et al., 2016; Clark et al., 2019; Novikova et al., 2017). To overcome this, we have also used WMS as an evaluation metric. 195 5.1 Semantic information overlap It is noticed that the proposed paraphraser in model O2O (w/o RL) outperforms the abstractor from EXT − ABS (w/o RL) in terms of ROUGE scores, while scoring marginally less in terms of METEOR. The extractor counterparts EXT − ABS (Ext only) and O2O (Ext only) 4.0 PGN Gold Standard EXT-ABS 3.5 Word Mover Distance (WMD) It is established by the fact that the models using WMS as the reward function attain comparable ROUGE scores as well (while the rev"
2020.icon-main.25,P04-3020,0,0.136144,"are provided in Section 5, followed by the conclusion and future work in Section 6. 2 Related Work Automatic text summarization has been extensively researched over more than three decades, and has shown a lot of progress and promise over the course of time. Various approaches have been explored to tackle both extractive and abstractive summarization. Initial research (Paice, 1990; Kupiec et al., 1995) focused on extractive summarization due to its easier setup. Various techniques ranging from integer linear programming (Galanis et al., 2012), graph based approaches (Mihalcea and Tarau, 2004; Mihalcea, 2004), genetic algorithms (Saini et al., 2019a,b), and neural networks (Nallapati et al., 2017; Zhang et al., 2016) have been adopted to solve the extractive summarization task. The majority of the research in abstractive summarization revolves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot of domain specifi"
2020.icon-main.25,D07-1040,0,0.0653682,"volves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot of domain specific summarization techniques have also been explored, like radiology findings summarization (Zhang et al., 2018), across-time summarization (Duan and Jatowt, 2019), movie review summarization (Zhuang et al., 2006), book summarization (Mihalcea and Ceylan, 2007), and customer review based opinion summarization (Pecar, 2018). Lately, multi-modal summarization (Jangra et al., 2020a,b; Zhu et al., 2020; Saini et al., 2020) has also gained popularity . Recently, people have also explored reinforcement learning to tackle the problem of automatic text summarization in both extractive (Dong et al., 2018; Gao et al., 2019) and abstractive domains (Xiao et al., 2020; Chen and Bansal, 2018). Chen and Bansal (2018) have proposed an extractorabstractor architecture, separating the relevant data searching part and the paraphrasing part to individual modules. In t"
2020.icon-main.25,W04-3252,0,0.027919,"ion and state the results are provided in Section 5, followed by the conclusion and future work in Section 6. 2 Related Work Automatic text summarization has been extensively researched over more than three decades, and has shown a lot of progress and promise over the course of time. Various approaches have been explored to tackle both extractive and abstractive summarization. Initial research (Paice, 1990; Kupiec et al., 1995) focused on extractive summarization due to its easier setup. Various techniques ranging from integer linear programming (Galanis et al., 2012), graph based approaches (Mihalcea and Tarau, 2004; Mihalcea, 2004), genetic algorithms (Saini et al., 2019a,b), and neural networks (Nallapati et al., 2017; Zhang et al., 2016) have been adopted to solve the extractive summarization task. The majority of the research in abstractive summarization revolves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot"
2020.icon-main.25,K16-1028,0,0.115293,"active and abstractive summarization. Initial research (Paice, 1990; Kupiec et al., 1995) focused on extractive summarization due to its easier setup. Various techniques ranging from integer linear programming (Galanis et al., 2012), graph based approaches (Mihalcea and Tarau, 2004; Mihalcea, 2004), genetic algorithms (Saini et al., 2019a,b), and neural networks (Nallapati et al., 2017; Zhang et al., 2016) have been adopted to solve the extractive summarization task. The majority of the research in abstractive summarization revolves around deep learning (See et al., 2017; Chopra et al., 2016; Nallapati et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot of domain specific summarization techniques have also been explored, like radiology findings summarization (Zhang et al., 2018), across-time summarization (Duan and Jatowt, 2019), movie review summarization (Zhuang et al., 2006), book summarization (Mihalcea and Ceylan, 2007), and customer review based opinion summarization (Pecar, 2018)."
2020.icon-main.25,D17-1238,0,0.0366409,"Missing"
2020.icon-main.25,P18-3001,0,0.0144486,"et al., 2016). Liu et al. (2018) proposed a generative adversarial network based model to generate document abstracts. A handful of works however also use ILP (Banerjee et al., 2015) and graph-based (Ganesan et al., 2010) techniques to attempt to solve the problem. A lot of domain specific summarization techniques have also been explored, like radiology findings summarization (Zhang et al., 2018), across-time summarization (Duan and Jatowt, 2019), movie review summarization (Zhuang et al., 2006), book summarization (Mihalcea and Ceylan, 2007), and customer review based opinion summarization (Pecar, 2018). Lately, multi-modal summarization (Jangra et al., 2020a,b; Zhu et al., 2020; Saini et al., 2020) has also gained popularity . Recently, people have also explored reinforcement learning to tackle the problem of automatic text summarization in both extractive (Dong et al., 2018; Gao et al., 2019) and abstractive domains (Xiao et al., 2020; Chen and Bansal, 2018). Chen and Bansal (2018) have proposed an extractorabstractor architecture, separating the relevant data searching part and the paraphrasing part to individual modules. In this work, we have proposed a system inspired from Chen and Bans"
2020.icon-main.25,P17-1099,0,0.479423,"learning, for which we have proposed a novel semantic overlap based reward function. Word Mover Similarity (WMS) (Clark et al., 2019) is utilized to evaluate semantic similarity across generated sentences and the true ground truth summary sentences. We assume that paraphrasing is a relatively simpler task than abstractive summarization, with the underlying intuition that paraphrasing is a subproblem within abstractive summarization. To bolster our hypothesis, experiments are conducted on the extractor-abstractor (EXT-ABS) model (Chen and Bansal, 2018) and the Pointer Generator Network (PGN) (See et al., 2017), which is used as the basic abstraction unit in the former architecture. The results are rather staggering and reveal that the PGN model also paraphrases input document sentences, albeit implicitly. The major contributions of the paper are as follows: • A novel semantic overlap based reward function is proposed for reinforcement of extractorparaphraser model. • To the best of our knowledge, we are the first ever to discover the fact that PGN networks are indeed doing an implicit extraction-paraphrasing operation, revealing the true nature of existing abstractive summarization models. 191 Proc"
2020.icon-main.25,W18-5623,0,0.0245456,"Missing"
2020.icon-main.42,P18-2096,0,0.035607,"Missing"
2020.icon-main.43,P15-1136,0,0.0666516,"Missing"
2020.icon-main.43,D16-1245,0,0.0284791,"Missing"
2020.icon-main.43,P19-1064,0,0.0220793,"Missing"
2020.icon-main.43,D19-1588,0,0.180213,"Missing"
2020.icon-main.43,P19-1066,0,0.0409852,"Missing"
2020.icon-main.43,D17-1018,0,0.0315973,"Missing"
2020.icon-main.43,N18-2108,0,0.0739962,"Missing"
2020.icon-main.43,Q15-1029,0,0.0419669,"Missing"
2020.icon-main.43,D14-1162,0,0.0849669,"2) output of right-LSTM and 3) final embedding have been considered in the c2f-model. Similarly, to strengthen the learning from word context representation we generate word context representation from triplet of embedding outputs. We consider the raw form of embedding 324 outputs from sa layer norm of Layer-6 and output layer norm of Layer-5 and final embedding output from the output layer norm of Layer-6 of DistilBERT. Word context representation means representation of word in the input sentence. Word representation as defined in c2f-model, are generated by character embedding using GloVe(Pennington et al., 2014) vector. Mapping Embedding from WordPiece tokens to Term-tokens : The dimension of embedding matrix generated from DistilBERT is (N one, N 0 , 786). Here, N 0 is the maximum of the number of WordPice tokens for a sample point in the batch. Learning the coreference in context of WordPiece token is complex to understand, and its analysis and explanation seem unusual. So we have mapped the output of WordPiece token to TermToken by averaging the corresponding WordPiece embeddings. Let, in a batch of size B, N be the maximum of number of Term-Tokens in a sample, 0 N be the maximum number of WordPie"
2020.icon-main.43,N18-1202,0,0.0211555,"ion of three vectors: the LSTM states of both the span endpoints and an attention vector computed over those span tokens. The score s(u, v) is computed by the mention score of u (sm (u)), mention score of v (sm (v)), the joint compatibility score (sc (u, v)) of u and v. The mention score of a span signifies the probability of a span to be a mention. The joint compatibility score signifies the probability of the two spans as corefering. The components are computed as follows: Extraction of Embedding from DistilBERT for word context representation Extraction of embeddings from ELMO is shown in (Peters et al., 2018). We have shown the embedding extraction from DistilBERT for word representation in Fig. 1. This extraction of word representation is performed in 4 steps, which are explained below. Conversion of Term-Tokens into WordPiece tokens: DistilBERT takes token embedding and position embeddings as input (Sanh et al., 2019). ....... WPN' WordPiece tokens DistilBERT Tokenizer Sentence formation E1 E2 E3 ....... EN Term-Tokens Figure 1: Word context representation from DistilBERT Collecting outputs from DistilBERT: After, the generation of WordPiece tokens, these are given as input to the DistilBERT for"
2020.icon-main.43,W12-4501,0,0.0320448,".e., 3 EmbOut[i] = [ej,k ]1≤j≤N ; 1≤k≤768 ; ∀1 ≤ i ≤ B where 0 ej,k = ej,k ; (5) l 1X 0 ej+p,k ; l p=1 (6) &if Ψ(j, l) = T rue (7) if W Pj = Ej × ∀ 1 ≤ k ≤ 768 and the function Ψ(j, l) returns True if the WordPiece tokens hW Pj+1 , . . . , W Pj+l i lead to term-token, Ej . Similar procedure is followed to get the embedding output from the rest of the two layers. Formation of the final word context representation: The output from Layer-6, sa layer norm Overview of the proposed system Dataset used and experimental set-up CoNLL-2012 shared task corpus is a standard coreference resolution corpus (Pradhan et al., 2012). We have used the English-based corpus for evaluating the performance of our proposed approach. Our experimental setup is almost similar to that of c2f-model and we have modified some parts of their code to generate word context representation from DistilBERT embeddings, which are: 1) The ELMo embeddings are replaced by the DistilBERT embeddings which are lighter and faster. 2) We have experimented with word context representation, generated from DistilBERT. The two different experimental setups are discussed below: i) D-Coref-Small: In our proposed D-coref model, we have extracted the embedd"
2020.icon-main.43,N16-1114,0,0.0416383,"Missing"
2020.icon-main.43,P15-1137,0,0.0607816,"Missing"
2020.icon-main.62,W14-4012,0,0.084992,"Missing"
2020.icon-main.62,D14-1181,0,0.00577616,"Missing"
2020.icon-main.62,I17-1099,0,0.0228453,"Emotion Corpus, also known as Twitter Emotion Corpus (TEC), was published by (Mohammad and Kiritchenko, 2015), and consists of 21,051 tweets. This resource was created to understand if emotion-word hashtags can successfully be used as emotion labels. Ekman’s basic emotions 461 3 https://data.world/crowdflower/ sentiment-analysis-in-text (Ekman, 1992) have been considered for the annotation process. Tweets were scraped that contained hashtags in the form #emotion corresponding to Ekman’s (Ekman, 1992) 6 basic emotions (like #anger, #disgust). DailyDialogs is a dataset of dialogs published by (Li et al., 2017) spanning over a variety of topics and better structured than any social media data. The SSEC corpus (Schuff et al., 2017) is an annotation of the SemEval 2016 Twitter stance and sentiment corpus (Mohammad et al., 2017) with Plutchik’s emotion labels (Plutchik, 2001). The authors studied the relation between emotion annotation and the other annotation layers like stance and sentiment. The EmoInt dataset published by (Mohammad and Bravo-Marquez, 2017) for evaluation of the WASAA-2017 Shared Task of Emotion Intensity (EmoInt) contains 7,097 tweets annotated with a pair of emotion tag and intensi"
2020.icon-main.62,W17-5205,0,0.0418945,"Missing"
2020.icon-main.62,S18-1001,0,0.0534959,"Missing"
2020.icon-main.62,D14-1162,0,0.0849914,"our severely under-represented classes, namely (disgust, fear, sadness and surprise) and one over-represented class (others). 4 Methodologies We develop various deep learning-based multi-task models for automatic detection of emotion and its intensity. As base learning techniques, we use Convolution Neural Network (CNN) (Kim, 2014), Long Short Term Memory (LSTM) network (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Unit (GRU) network (Cho et al., 2014). We build three separate multi-task models (CNN based, Bi-GRU based and Bi-LSTM based) on top of pre-trained word embedding (GloVe 7 (Pennington et al., 2014)). The embedding layer is initialized with the pre-trained weights and is learned during the training in accordance with our dataset. We employ word attention (Bahdanau et al., 2014) mechanism to focus on the informative words in a document (tweet) and obtain an aggregated representation(document vector) which is passed through two fully-connected layers (100 neurons in each 7 http://nlp.stanford.edu/data/ wordvecs/glove.840B.300d.zip layer) and an output layer (with 7 neurons, one for each class) with Softmax activation. We use the categorical cross-entropy as the loss function. 4.1 Convoluti"
2020.icon-main.62,W17-5203,0,0.0382475,"Missing"
2020.icon-main.62,C16-1287,1,0.892658,"Missing"
2020.icon-main.62,S07-1013,0,0.0863487,"s annotation schemes were introduced to serve the specific purpose for which the corpus is created. (Scherer and Wallbott, 1994) collected questionnaires answered by people with different cultural backgrounds to form The International Survey on Emotion Antecedents and Reactions (ISEAR) dataset. People reported on their emotional events. The dataset contains a total of 7,665 sentences from reports by approximately 3,000 respondents. Sentences are annotated with single labels, chosen from the set of following labels: joy, fear, anger, sadness, disgust, shame, and guilt. The Affective Text task (Strapparava and Mihalcea, 2007) in SemEval 2007 was proposed to focus on the emotion classification of news headlines extracted from news web sites. Given a set of predefined six emotion labels (Paul Ekman’s basic emotions (Ekman, 1992)), classify the titles with the appropriate emotion label and/or with a valence indication (positive/negative). (Aman and Szpakowicz, 2007) published a dataset of blog content consisting of 5,205 sentences from 173 blogs. Each instance is annotated with an emotion label from Ekman’s basic emotions (Ekman, 1992) and also with an intensity score for that emotion. (Alm, 2008) researched the text"
2020.icon-main.62,N16-1174,0,0.0372911,"et al., 2011) and an output layer (with 7 neurons, one for each class) with Softmax activation. 4.4 level). HAtED focuses on each sentence in a tweet individually resulting in sentence vectors which are further attended upon to produce a document vector. The intuition is to focus upon important words in a sentence as well as important sentences in a document (tweet) for a particular emotion. For encoding of the sentences, we leverage Bi-GRU (256 neurons) based word encoder. Without making major changes to the basic architecture of the hierarchical attention framework as in the original work (Yang et al., 2016), we tweaked the last few layers to solve our objective. We pass the document vector through a dense layer (100 neurons with ReLU activation) followed by an output layer (7 neurons with Softmax activation). We use categorical crossentropy loss function for the classification task. Besides HAtED, we also develop two separate Hierarchical Attention-based models considering various sets of emotion classes. They are as follows: Hierarchical Attention Based Deep Neural Framework for Emotion Detection (HAtED) In recent works, Hierarchical attention (Bahdanau et al., 2014) based deep learning systems"
2020.icon-main.62,N16-1000,0,0.21503,"Missing"
2020.sdp-1.27,D18-2029,0,0.0151285,"ext-spans using citation context, we have used an unsupervised approach where we have extracted the top 5 sentences by calculating cosine similarity between each citance and sentences of the RP. These 5 sentences are considered as cited/reference text spans. Note that before calculating the similarity, we have converted the text-space into a (numeric) vector-space for which we have utilized different types of sentence embeddings namely, Albert (Beltagy et al., 2019a), ELMO (Peters et al., 2018), fastText (Athiwaratkun et al., 2018), SciBERT (Beltagy et al., 2019a), Universal Sentence Encoder (Cer et al., 2018), XLNET (Yang et al., 2019), which are capable of capturing the semantics of the sentences. Thus, in total, six systems are developed for Task 1(A). 2.2.2 Section Aim Method Hypothesis Implication Results Total Dataset Description The dataset associated with CL-SciSumm 2020 shared task, consists of 40 annotated scientific articles and their citations for training. In addition to this, a corpus of 1000 documents released as a part of ScicummNet (Yasunaga et al., 2019) dataset for scientific document summarization is readily available for training. For testing, a blind test set of 20 articles us"
2020.sdp-1.27,K16-1028,0,0.0710665,"Missing"
2020.sdp-1.27,N18-1202,0,0.00791843,"ng flowchart is shown in Figure 1. 2.2.1 Task 1(A) For a given reference paper (RP), in order to identify the reference text-spans using citation context, we have used an unsupervised approach where we have extracted the top 5 sentences by calculating cosine similarity between each citance and sentences of the RP. These 5 sentences are considered as cited/reference text spans. Note that before calculating the similarity, we have converted the text-space into a (numeric) vector-space for which we have utilized different types of sentence embeddings namely, Albert (Beltagy et al., 2019a), ELMO (Peters et al., 2018), fastText (Athiwaratkun et al., 2018), SciBERT (Beltagy et al., 2019a), Universal Sentence Encoder (Cer et al., 2018), XLNET (Yang et al., 2019), which are capable of capturing the semantics of the sentences. Thus, in total, six systems are developed for Task 1(A). 2.2.2 Section Aim Method Hypothesis Implication Results Total Dataset Description The dataset associated with CL-SciSumm 2020 shared task, consists of 40 annotated scientific articles and their citations for training. In addition to this, a corpus of 1000 documents released as a part of ScicummNet (Yasunaga et al., 2019) dataset fo"
2020.sdp-1.27,D19-1628,0,0.0300865,"Missing"
2020.sdp-1.27,D14-1181,0,0.0256688,"using MMR and it’s variant for CL-LaySumm 2020. Here, R in second row stands for ‘ROUGE’. λ1 0.25 0.50 0.75 1.00 0.75 0.75 λ2 0.0 0.0 0.0 0.0 0.1 0.2 ROUGE 1-F 0.3876 0.3940 0.4009 0.3971 0.4031 0.4048 4.2 Table 6: Study of parameters used in M M R1 and M M R2 for Lay Summary generation. Here, we have used only ABSTRACT for generating summary. Variant Data CW R + M M R1 CW R + M M R2 ABS ABS R-1 0.3986 0.4033 F1 Scores R-2 R-L 0.1586 0.2187 0.1614 0.2209 Methodology To solve the LongSumm in an extactive way, we have utilized the neural network based approach, i.e., convolution neural network (Kim, 2014). The sentences which are part of the summary are assigned 1 and remaining sentences are assigned 0. In other words, we have posed this task as a binary classification problem where task is to identify whether the given sentence can be a part of the summary or not. Positional embedding is also used along with sentence embedding. The detailed methodology used in our CNN is described below: Table 7: Results attained by applying CWR on the generated summary using abstract (ABS). Here, R in second row stands for ‘ROUGE’. etc., are trivial for paper (S016882782030009X) but are not present in wordne"
2020.sdp-1.27,P19-1204,0,0.0966187,"tabases like wordnet (Miller, 1995) can be important and trivial in the context of the paper. For example words like ”hepatocellular”, ”carcinoma” 246 Variant Data M M R1 M M R2 M M R1 M M R2 M M R1 M M R2 ABS ABS ABS+CON ABS+CON FULL FULL R-1 0.4009 0.4048 0.3837 0.3855 0.2835 0.2875 F1 Scores R-2 0.1679 0.1690 0.1411 0.1394 0.0604 0.0628 4.1 R-L 0.2239 0.2244 0.2050 0.2055 0.1609 0.1592 The training corpus for this task includes 1705 extractive summaries, and 531 abstractive summaries of NLP/ML scientific papers. The extractive summaries are based on video talks from associated conferences (Lev et al., 2019), while the abstractive summaries are from blog posts created by NLP and ML researchers. The test set consists of 22 research papers for both extactive and abstractive summarization and task is to generate a summary of 600 words. In the current paper, we have focused only on the extractive summarization of LongSumm. Table 5: Results attained using MMR and it’s variant for CL-LaySumm 2020. Here, R in second row stands for ‘ROUGE’. λ1 0.25 0.50 0.75 1.00 0.75 0.75 λ2 0.0 0.0 0.0 0.0 0.1 0.2 ROUGE 1-F 0.3876 0.3940 0.4009 0.3971 0.4031 0.4048 4.2 Table 6: Study of parameters used in M M R1 and M"
2020.sdp-1.30,N15-1110,0,0.0277913,"long summarization problem, we have an unsupervised technique similar to CL-SciSumm. To solve the abstractive LongSumm problem, we have used the encoder-decoder based generative model. • Objective of CL-LaySumm is to generate a lay summary that can be understood by a non-technical reader. The generated summary should not contain any technical words or jargon. We have solved this task using the abstractive summarization technique. Here, Fine-tuned BERT based encoder-decoder architecture is used to solve the problem. Introduction Massive amounts of scientific articles are published day by day (Cohan et al., 2015; Cohan and Goharian, 2017, 2018), which impose a big challenge for researchers in various fields to keep themselves upto-date with the new developments. A bibliometric analyst’s study shows that after nine years, the number of published articles will be doubled (Bornmann and Mutz, 2015). The scientific document summarization objective is to provide a summary of the reference paper. This summary should contain all the important facts. Therefore, it reduces the human effort to understand the document. Challenges of each style of the summary are as follows: • Objective of CL-SciSumm is to genera"
2020.sdp-1.30,D18-1443,0,0.0198746,"es. 4 −1.5 ) (2) lrD = ˜lrD .min(step0.5 , step.warmupD where lr = 2e− 3 and warm-up = 20000 for the encoder whereas lrD = 0.1 and warm-up =10000 for decoder. Here the assumption is that the pretrained encoder must be trained with a lower learning rate and a lower learning rate smoothens the decay. This process helps the encoder in training with a better gradient when the decoder is in stable condition. We have used a two-stage fine-tuning approach, first is fine-tuning for extractive summarization and then for abstractive summarization. It has been shown in the literature (Li et al., 2018) (Gehrmann et al., 2018) extractive object helps in obtaining a better abstractive summary. 3.3 Result Our system has the following score (shown in Table 5). LongSumm 2020 In all the previous works of scientific summarization (Cohan and Goharian, 2017, 2018), there is a summary length constraint of a maximum of 250 words. But in the current LongSumm shared task, the generated summary can be the length of between 100-1500 words. 4.1 Dataset This dataset consists of a training set of 1705 papers associated with extractive summaries and 531 papers associated with abstractive summaries. It has a blind test set of 22 file"
2020.sdp-1.30,D18-1205,0,0.0197849,"values are f1 scores. 4 −1.5 ) (2) lrD = ˜lrD .min(step0.5 , step.warmupD where lr = 2e− 3 and warm-up = 20000 for the encoder whereas lrD = 0.1 and warm-up =10000 for decoder. Here the assumption is that the pretrained encoder must be trained with a lower learning rate and a lower learning rate smoothens the decay. This process helps the encoder in training with a better gradient when the decoder is in stable condition. We have used a two-stage fine-tuning approach, first is fine-tuning for extractive summarization and then for abstractive summarization. It has been shown in the literature (Li et al., 2018) (Gehrmann et al., 2018) extractive object helps in obtaining a better abstractive summary. 3.3 Result Our system has the following score (shown in Table 5). LongSumm 2020 In all the previous works of scientific summarization (Cohan and Goharian, 2017, 2018), there is a summary length constraint of a maximum of 250 words. But in the current LongSumm shared task, the generated summary can be the length of between 100-1500 words. 4.1 Dataset This dataset consists of a training set of 1705 papers associated with extractive summaries and 531 papers associated with abstractive summaries. It has a b"
2020.semeval-1.214,N19-1423,0,0.0183621,"n visual media. Each word of the input sequence is represented with word embedding. Part-of-speech (POS) and sentence embedding are added as additional information. Two bidirectional LSTM (Hochreiter and Schmidhuber, 1997) layers are used to capture the sequence information. The last layer of the model is fully-connected and assigns probability using the hidden state of LSTM. Figure 2 shows the overall architecture of the DL-BiLSTM model. We have used different sets of embedding to train the models. WordBERT and SentBERT represent word, and sentence embedding generated using pre-trained BERT (Devlin et al., 2019), respectively. POSEmbd represents one-hot-encoded POS tag. In Model-4, Model-5 and Model-6, we use ELMo (Peters et al., 2018) as word embedding. Below is the list of models and used embeddings: Model-1: DL-BiLSTM + WordBERT Model-2: DL-BiLSTM + WordBERT + POSEmbd Model-3: DL-BiLSTM + WordBERT + POSEmbd + SentBERT Model-4: DL-BiLSTM + ELMo Model-5: DL-BiLSTM + ELMo + POSEmbd Model-6: DL-BiLSTM + ELMo + POSEmbd + SentBERT 4.1 Baseline Models Here, we discuss the baseline models and their implementation. SL-BiLSTM: This model has same architecture as DL-BiLSTM, but the distribution is mapped to"
2020.semeval-1.214,C10-2042,0,0.0259011,"n in visual media. • We show a comparison of our results with baselines and state-of-the-art models and also give a qualitative comparison of different methods. 2 Related Work In text data, the majority of works focus on important keyword identification from long texts. There are mainly two methods for keyword extraction: supervised and unsupervised. Supervised methods generally treat the keyword identification as a classification problem and classify words as either keyword or not (Frank et al., 1999; Tang et al., 2004; Medelyan and Witten, 2006). Unsupervised methods usually utilize TF-IDF (Hasan and Ng, 2010) scores or clustering methods (Liu et al., 2009) for keyword identification. Recently, (Zhang et al., 2016) also proposed a model using RNNs for keyword identification. Different methods are proposed for the emphasis selection in audio. Most works use acoustic features like loudness, pitch to detect emphasized words in audio data (Kochanski et al., 2005; Wang and Narayanan, 2007). Recently, some works are proposed to predict word emphasis in text to improve text-to-speech (TTS) systems (Nakajima et al., 2014; Mass et al., 2018). (Sun, 2002) proposed ensemble-based models for emphasis selection"
2020.semeval-1.214,D09-1027,0,0.0217973,"esults with baselines and state-of-the-art models and also give a qualitative comparison of different methods. 2 Related Work In text data, the majority of works focus on important keyword identification from long texts. There are mainly two methods for keyword extraction: supervised and unsupervised. Supervised methods generally treat the keyword identification as a classification problem and classify words as either keyword or not (Frank et al., 1999; Tang et al., 2004; Medelyan and Witten, 2006). Unsupervised methods usually utilize TF-IDF (Hasan and Ng, 2010) scores or clustering methods (Liu et al., 2009) for keyword identification. Recently, (Zhang et al., 2016) also proposed a model using RNNs for keyword identification. Different methods are proposed for the emphasis selection in audio. Most works use acoustic features like loudness, pitch to detect emphasized words in audio data (Kochanski et al., 2005; Wang and Narayanan, 2007). Recently, some works are proposed to predict word emphasis in text to improve text-to-speech (TTS) systems (Nakajima et al., 2014; Mass et al., 2018). (Sun, 2002) proposed ensemble-based models for emphasis selection in audio. (Shirani et al., 2019) proposed the u"
2020.semeval-1.214,Y14-1022,0,0.234417,"g et al., 2004; Medelyan and Witten, 2006). Unsupervised methods usually utilize TF-IDF (Hasan and Ng, 2010) scores or clustering methods (Liu et al., 2009) for keyword identification. Recently, (Zhang et al., 2016) also proposed a model using RNNs for keyword identification. Different methods are proposed for the emphasis selection in audio. Most works use acoustic features like loudness, pitch to detect emphasized words in audio data (Kochanski et al., 2005; Wang and Narayanan, 2007). Recently, some works are proposed to predict word emphasis in text to improve text-to-speech (TTS) systems (Nakajima et al., 2014; Mass et al., 2018). (Sun, 2002) proposed ensemble-based models for emphasis selection in audio. (Shirani et al., 2019) proposed the use of label distribution learning (LDL) for emphasis selection in short texts in visual media. Here, we show that the use of ensemble models trained with different embeddings performs better than base models. 3 3.1 Approach Problem Definition Given a sentence S with tokens C = {w1 , w2 , ..., wn }, where 1 &lt; |S |&lt; n, emphasis selection is the task to find candidate words in C to emphasize on for conveying the meaning of message in an effective manner. 3.2 Label"
2020.semeval-1.214,N18-1202,0,0.055472,"g are added as additional information. Two bidirectional LSTM (Hochreiter and Schmidhuber, 1997) layers are used to capture the sequence information. The last layer of the model is fully-connected and assigns probability using the hidden state of LSTM. Figure 2 shows the overall architecture of the DL-BiLSTM model. We have used different sets of embedding to train the models. WordBERT and SentBERT represent word, and sentence embedding generated using pre-trained BERT (Devlin et al., 2019), respectively. POSEmbd represents one-hot-encoded POS tag. In Model-4, Model-5 and Model-6, we use ELMo (Peters et al., 2018) as word embedding. Below is the list of models and used embeddings: Model-1: DL-BiLSTM + WordBERT Model-2: DL-BiLSTM + WordBERT + POSEmbd Model-3: DL-BiLSTM + WordBERT + POSEmbd + SentBERT Model-4: DL-BiLSTM + ELMo Model-5: DL-BiLSTM + ELMo + POSEmbd Model-6: DL-BiLSTM + ELMo + POSEmbd + SentBERT 4.1 Baseline Models Here, we discuss the baseline models and their implementation. SL-BiLSTM: This model has same architecture as DL-BiLSTM, but the distribution is mapped to binary labels. Also, for training the SL-BiLSTM model (Shirani et al., 2019), we use negative log-likelihood loss in place of"
2020.semeval-1.214,P19-1112,0,0.681068,"lustering methods (Liu et al., 2009) for keyword identification. Recently, (Zhang et al., 2016) also proposed a model using RNNs for keyword identification. Different methods are proposed for the emphasis selection in audio. Most works use acoustic features like loudness, pitch to detect emphasized words in audio data (Kochanski et al., 2005; Wang and Narayanan, 2007). Recently, some works are proposed to predict word emphasis in text to improve text-to-speech (TTS) systems (Nakajima et al., 2014; Mass et al., 2018). (Sun, 2002) proposed ensemble-based models for emphasis selection in audio. (Shirani et al., 2019) proposed the use of label distribution learning (LDL) for emphasis selection in short texts in visual media. Here, we show that the use of ensemble models trained with different embeddings performs better than base models. 3 3.1 Approach Problem Definition Given a sentence S with tokens C = {w1 , w2 , ..., wn }, where 1 &lt; |S |&lt; n, emphasis selection is the task to find candidate words in C to emphasize on for conveying the meaning of message in an effective manner. 3.2 Label distribution learning (LDL) We use ”IO” scheme for labels, where ”I” represents emphasis and ”O” represents non-emphasi"
2020.semeval-1.214,2020.semeval-1.184,0,0.0562082,"Missing"
2020.semeval-1.214,D16-1080,0,0.298282,"o give a qualitative comparison of different methods. 2 Related Work In text data, the majority of works focus on important keyword identification from long texts. There are mainly two methods for keyword extraction: supervised and unsupervised. Supervised methods generally treat the keyword identification as a classification problem and classify words as either keyword or not (Frank et al., 1999; Tang et al., 2004; Medelyan and Witten, 2006). Unsupervised methods usually utilize TF-IDF (Hasan and Ng, 2010) scores or clustering methods (Liu et al., 2009) for keyword identification. Recently, (Zhang et al., 2016) also proposed a model using RNNs for keyword identification. Different methods are proposed for the emphasis selection in audio. Most works use acoustic features like loudness, pitch to detect emphasized words in audio data (Kochanski et al., 2005; Wang and Narayanan, 2007). Recently, some works are proposed to predict word emphasis in text to improve text-to-speech (TTS) systems (Nakajima et al., 2014; Mass et al., 2018). (Sun, 2002) proposed ensemble-based models for emphasis selection in audio. (Shirani et al., 2019) proposed the use of label distribution learning (LDL) for emphasis select"
2020.semeval-1.253,2020.lrec-1.758,0,0.0731509,"Missing"
2020.semeval-1.253,L18-1550,0,0.0197466,".(2010). Any classical machine learning or deep learning model can not take raw text as its input. Therefore we convert these clean text into the corresponding numerical feature vectors. We have used language specific word embedding models of embedding dimension 300 for each of the language corpora along with TF-IDF/Count models. The language specific embeddings are trained on Common Crawl and Wikipedia data using fastText 2 . These models were trained using CBOW (as described in Mikolov et al. (2013)) with position-weights, in dimension 300, with character n-grams of length 5 as described in Grave et al. (2018). In our case, a vector of a word is being predicted based on context words. For example, we want to predict the vector of a particular word w0 based on its context words w−n , ..., w−1 , w1 , ..., wn . A vector representation h of this context is obtained by considering the average of the corresponding word vectors, which can be defined as: h= n X uwi (1) i=−n;i6=0 4.3 Classification The classical machine learning model has been implemented using scikit-learn 3 and deep learning model has been implemented in Keras 4 on top of Tensorflow. We then fed the produced word vectors to the classifier"
2020.semeval-1.253,W17-3008,0,0.0559911,"Missing"
2020.semeval-1.253,2020.lrec-1.629,0,0.133966,"sion on the creation of reusable benchmarks for evaluating proposed algorithms by exploring issues of evaluation methodology and other processes related to the creation of test collections. The given corpora are developed using the posts and comments over Twitter, a popular social media. Zampieri et al. (2020) organized a multilingual offensive language classification task with a particular focus on Twitter posts. It has released different corpora for the individual languages, e.g., Arabic (Mubarak et al. (2020)), Danish (Sigurbergsson et al. (2020)), English (Rosenthal et al. (2020)), Greek (Pitenis et al. (2020a)) and Turkish (Coltekikin (2020)), and intended to identify and capture the offensive language. All the languages except English have only one task to be performed, e.g., sub-task A which is to identify offensive language. For English, the task has been divided in three different sub-tasks, namely, sub-task B for offense type categorization in which the offense type is categorized into either targeted or untargeted, and sub-task C focuses on identification of target offense. In this paper, different machine learning and deep learning frameworks have been proposed to accomplish the given task"
2020.semeval-1.253,2020.lrec-1.430,0,0.0947071,"Missing"
2021.findings-acl.328,P18-2108,0,0.0859697,"interactions is critical in understanding the biological processes, such as signaling cascades, translations and metabolism, that are regulated by the interactions of proteins that alter proteins to modulate their stability (Elangovan et al., 2020). Majority of the existing works on PPI in the literature primarily focused only on the textual information present in the biomedical article. However, these approaches lack in capturing (1) multiomnics biological information regarding protein interactions, and (2) genetic and structure information of the proteins. A few works (Dutta and Saha, 2020; Asada et al., 2018; Jha et al., 2020; Jha and Saha) have been reported in the literature where the researchers have considered different modalities of the biomedical corpus. However, these multimodal architectures are modality-specific and thus are very complex. Hence, there is a surge to develop a generalized and optimized model that can understand all the modalities rather than developing various architectures for different modalities. Towards this, we explore Graph-based Transformer model (GraphBERT) (Zhang et al., 2020) to learn the modality independent graph representation. This enables the model to acquir"
2021.findings-acl.328,I17-2041,0,0.01465,"iciency of 3741 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3741–3747 August 1–6, 2021. ©2021 Association for Computational Linguistics model in identifying the interacted protein mentions. Related Work: Existing studies have adopted traditional statistical and graphical methods (Miyao et al., 2008; Chang et al., 2016) to identify the protein interactions from the textual content. Later, with the success of deep learning, several techniques based on Convolutional Neural Network (Choi, 2018; Peng and Lu, 2017; Ekbal et al., 2016), Recurrent Neural Network (Hsieh et al., 2017; Ahmed et al., 2019), Long Short Term Memory network (Yadav et al., 2019; Ningthoujam et al., 2019; Yadav et al., 2020), and language models (Yadav et al., 2021) based methods are proposed for extracting the relationships from biomedical literature and clinical records. Fei et al. (2020) proposed a span-graph neural model for jointly extracting overlapping entity relationships from biomedical text. The recent advancement of the Transformer model (Lee et al., 2020; Beltagy et al., 2019) in the biomedical domain has also led to significant performance improvement in biomedical relation extracti"
2021.findings-acl.328,D19-1371,0,0.0243048,"on Convolutional Neural Network (Choi, 2018; Peng and Lu, 2017; Ekbal et al., 2016), Recurrent Neural Network (Hsieh et al., 2017; Ahmed et al., 2019), Long Short Term Memory network (Yadav et al., 2019; Ningthoujam et al., 2019; Yadav et al., 2020), and language models (Yadav et al., 2021) based methods are proposed for extracting the relationships from biomedical literature and clinical records. Fei et al. (2020) proposed a span-graph neural model for jointly extracting overlapping entity relationships from biomedical text. The recent advancement of the Transformer model (Lee et al., 2020; Beltagy et al., 2019) in the biomedical domain has also led to significant performance improvement in biomedical relation extraction task (Giles et al., 2020). Recently, the use of multi-modal dataset in BioNLP domain (Dutta and Saha, 2020; Asada et al., 2018) draws the attention of the researchers due to its better performance than the traditional approaches. In contrast, our model is independent of handling multiple modalities without relying on modalityspecific architectures. 2 Proposed Method In this section, we introduce our proposed method and its detailed implementation. The proposed deep multi-modal archit"
2021.findings-acl.328,C10-1024,0,0.0274306,"subgraph size = 5, hidden size = 32, attention head number = 2, Transformer layers, D = 2, learning rate = 0.01, weight decay = 5e 4, hidden dropout rate = 0.5, attention dropout rate = 0.3, loss = cross entropy, optimizer = adam (Kingma and Ba, 2014). The hyper-parameters are chosen based on the 5-fold cross-validation experiments on both the datasets. Results and Analysis: We have compared the performance (c.f. Table-1,3) of our proposed model with the existing state-of-the-art methods on PPI for both the datasets. These existing methods are based on different techniques like kernel-based (Choi and Myaeng, 2010; Tikk et al., 2010; Qian and Zhou, 2012; Li et al., 2015), deep neural networkbased (Zhao et al., 2016; Yadav et al., 2019), multichannel dependency-based convolutional neural network model (Peng and Lu, 2017), semantic feature embedding (Choi, 2018), shortest dependency path (Hua and Quan, 2016) and a recent deep multimodal approach (Dutta and Saha, 2020). It is to be noted that our results on BioInfer and HPRD50 are not directly comparable with the existing approaches as other methods have utilized different test sets for evaluation. From the above comparative study, it is evident that our"
2021.findings-acl.328,2020.acl-main.570,1,0.698979,"l∗ edge about protein interactions is critical in understanding the biological processes, such as signaling cascades, translations and metabolism, that are regulated by the interactions of proteins that alter proteins to modulate their stability (Elangovan et al., 2020). Majority of the existing works on PPI in the literature primarily focused only on the textual information present in the biomedical article. However, these approaches lack in capturing (1) multiomnics biological information regarding protein interactions, and (2) genetic and structure information of the proteins. A few works (Dutta and Saha, 2020; Asada et al., 2018; Jha et al., 2020; Jha and Saha) have been reported in the literature where the researchers have considered different modalities of the biomedical corpus. However, these multimodal architectures are modality-specific and thus are very complex. Hence, there is a surge to develop a generalized and optimized model that can understand all the modalities rather than developing various architectures for different modalities. Towards this, we explore Graph-based Transformer model (GraphBERT) (Zhang et al., 2020) to learn the modality independent graph representation. This enables"
2021.findings-acl.328,W17-2304,0,0.0942568,"veals that addition of proteinstructure modality increases the efficiency of 3741 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3741–3747 August 1–6, 2021. ©2021 Association for Computational Linguistics model in identifying the interacted protein mentions. Related Work: Existing studies have adopted traditional statistical and graphical methods (Miyao et al., 2008; Chang et al., 2016) to identify the protein interactions from the textual content. Later, with the success of deep learning, several techniques based on Convolutional Neural Network (Choi, 2018; Peng and Lu, 2017; Ekbal et al., 2016), Recurrent Neural Network (Hsieh et al., 2017; Ahmed et al., 2019), Long Short Term Memory network (Yadav et al., 2019; Ningthoujam et al., 2019; Yadav et al., 2020), and language models (Yadav et al., 2021) based methods are proposed for extracting the relationships from biomedical literature and clinical records. Fei et al. (2020) proposed a span-graph neural model for jointly extracting overlapping entity relationships from biomedical text. The recent advancement of the Transformer model (Lee et al., 2020; Beltagy et al., 2019) in the biomedical domain has also led to"
2021.naacl-main.456,S17-2126,0,0.0585515,"Missing"
2021.naacl-main.456,D17-1169,0,0.0269257,"tion the tweet acts. For expressive TAs such as “exIdentification of speech acts is one of the prelimi- pression"", “request"", “threat"" etc., the tweeter’s nary means of determining the communicative in- sentiment and emotion can aid in classifying true tent or pragmatics of a speaker (for example, state- communicative intent and vice-versa. ment, request, question etc.). This is true for diaAdditionally, multi-modal inputs, i.e., the comlogue system, speech transcription, social media bination of text and other nonverbal cues (emojis such as Twitter, MySpace etc. Twitter is one of in tweets) (Felbo et al., 2017) help create reliable the leading micro-blogging services. By 2019, 330 classification models aiding the identification of million users were active monthly and 500 mil- emotional state and sentiment of the tweeter which lion tweets were sent per day1 . Identification of in turn help in determining correct TAs. tweet acts (TAs- speech acts in Twitter) is highly In this paper, we leverage the relationships as beneficial for Twitter as well as tweeters. For Twitdelineated above to predict TAs of tweets in a multiter, it helps decipher a particular subject in terms modal framework. In this multi-"
2021.naacl-main.456,D09-1130,0,0.0462097,"elation of the tweeter. In (Cerisara et al., 2018), SS-Twitter (Thelwall et al., 2012) etc. However, authors proposed a LSTM based study for jointly we chose to use SemEval-2018 dataset for further optimizing SA and TAC in a decentralized social investigation of our task at hand. The reason bemedia platform called Mastodon. However, they hind this choice was that most of the ER datasets modelled their task as a multi-party conversation were annotated with only six Eckman’s (Ekman, pretty different in essence to that of Twitter anal- 1999) or eight Plutchik’s (Plutchik, 1980) emotion ysis. In (Jeong et al., 2009), authors presented a categories. Whereas SemEval-2018 dataset consemi-supervised approach to identify speech acts tains tweets annotated with multi-label 11 emotion in emails and different forums. These works, how- categories which aids the diversity of the problem ever, use datasets that comprise of face-to-face or statement. Intuitively, it was indeed possible to go telephone data that can not directly aid in advanc- the other way round and search for Twitter dataset ing work on endless data in electronic mode such as annotated with TAs such as (Zhang et al., 2011), 5728 Tweet And it pisses"
2021.naacl-main.456,S18-1001,0,0.0193272,"the literature for the latimportance of identification of tweet acts and es- est SA and ER dataset for Twitter in order to gather tablished it to be one of the elementary steps for potentially emotionally rich tweets to explore its detection of rumours in Twitter. In (Saha et al., impact on TAC. Initially, we came across several 2020c), authors proposed an attention based model SA and ER datasets for Twitter such as (Oleri built on top of the Transformer for predicting TAs. and Karagoz, 2016), (Mohammad and Kiritchenko, In (Saha et al., 2020a), authors proposed a capsule 2018), SemEval-2018 (Mohammad et al., 2018), based network built on top of BERT for TAC. All BTD (Wang et al., 2012), TEC (Mohammad, 2012), these works utilized only the textual modality to CBET (Shahraki and Zaiane, 2017), STS-Gold (Moidentify TAs without any sentiment or emotional hammad and Turney, 2013), STS (Go et al., 2009), correlation of the tweeter. In (Cerisara et al., 2018), SS-Twitter (Thelwall et al., 2012) etc. However, authors proposed a LSTM based study for jointly we chose to use SemEval-2018 dataset for further optimizing SA and TAC in a decentralized social investigation of our task at hand. The reason bemedia platfo"
2021.naacl-main.456,L18-1030,0,0.0485504,"Missing"
2021.naacl-main.456,D14-1162,0,0.0856125,"Missing"
2021.naacl-main.456,P17-1001,0,0.0517252,"Missing"
2021.naacl-main.456,2020.acl-main.402,1,0.90301,"peech acts has been studied extensively for dialogue conversations starting from early 2000’s with (Stolcke et al., 2000) being one of the benchmark works where the authors presented varieties of approaches such as Hidden Markov Models, Neural Networks and Decision Trees to identify dialogue acts on a benchmark dialogue data known as the Switchboard (SWBD) (Godfrey et al., 1992) dataset. In (Saha et al., 2021), authors studied the role of emotion in identifying dialogue acts for a dyadic conversation by considering thee textual and the audio modality of the utterances in the conversation. In (Saha et al., 2020b), authors proposed studying the role of emotion in determining dialogue acts on a dyadic and multi-party conversational dataset in a multi-modal framework (incorporating text, audio and video). However, tweets are unstructured and noisy communications with spelling mistakes, random coinages with limitations in expression because of character constraint per tweet. This makes it very different from face-to-face or other conversations. There exist plenty of works which address the task of TAC as a standalone problem. In (Zhang et al., 2011), (Vosoughi and Roy, 2016), authors proposed Machine Le"
2021.naacl-main.456,S12-1033,0,0.0297496,"r Twitter in order to gather tablished it to be one of the elementary steps for potentially emotionally rich tweets to explore its detection of rumours in Twitter. In (Saha et al., impact on TAC. Initially, we came across several 2020c), authors proposed an attention based model SA and ER datasets for Twitter such as (Oleri built on top of the Transformer for predicting TAs. and Karagoz, 2016), (Mohammad and Kiritchenko, In (Saha et al., 2020a), authors proposed a capsule 2018), SemEval-2018 (Mohammad et al., 2018), based network built on top of BERT for TAC. All BTD (Wang et al., 2012), TEC (Mohammad, 2012), these works utilized only the textual modality to CBET (Shahraki and Zaiane, 2017), STS-Gold (Moidentify TAs without any sentiment or emotional hammad and Turney, 2013), STS (Go et al., 2009), correlation of the tweeter. In (Cerisara et al., 2018), SS-Twitter (Thelwall et al., 2012) etc. However, authors proposed a LSTM based study for jointly we chose to use SemEval-2018 dataset for further optimizing SA and TAC in a decentralized social investigation of our task at hand. The reason bemedia platform called Mastodon. However, they hind this choice was that most of the ER datasets modelled th"
2021.naacl-main.456,J00-3003,0,0.15382,"Missing"
C12-1151,M98-1028,0,0.0148658,"Missing"
C12-1151,W09-3539,1,0.927656,"nce and the maintenance costs could be quite steep. Literature shows that most of the works carried out in this direction cover mostly English and European languages. There are also significant amount of works in some of the Asian languages like Chinese, Japanese and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic families. Some works on NER for Indian languages can be found in (Ekbal and Saha, 2011; Ekbal and Bandyopadhyay, 2008; Ekbal et al., 2007; Ekbal and Bandyopadhyay, 2009b, 2007; Ekbal et al., 2008; Li and McCallum, 2004; Patel et al., 2009; Srikanth and Murthy, 2008; Shishtla et al., 2008; Vijayakrishna and Sobha, 2008). However, the works related to NER in Indian languages are still in the nascent stages due to the potential facts such as (Ekbal and Saha, 2011): • Unlike English and most of the European languages, Indian languages lack capitalization information, which plays a very important role in NE identification. • Indian person names are more diverse compared to the other languages and a lot of these words can be found in the dictionary with specific m"
C12-1151,I08-2077,1,0.819781,"quite steep. Literature shows that most of the works carried out in this direction cover mostly English and European languages. There are also significant amount of works in some of the Asian languages like Chinese, Japanese and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic families. Some works on NER for Indian languages can be found in (Ekbal and Saha, 2011; Ekbal and Bandyopadhyay, 2008; Ekbal et al., 2007; Ekbal and Bandyopadhyay, 2009b, 2007; Ekbal et al., 2008; Li and McCallum, 2004; Patel et al., 2009; Srikanth and Murthy, 2008; Shishtla et al., 2008; Vijayakrishna and Sobha, 2008). However, the works related to NER in Indian languages are still in the nascent stages due to the potential facts such as (Ekbal and Saha, 2011): • Unlike English and most of the European languages, Indian languages lack capitalization information, which plays a very important role in NE identification. • Indian person names are more diverse compared to the other languages and a lot of these words can be found in the dictionary with specific meanings. • Indian languages"
C12-1151,M98-1019,0,0.0592266,"ew expressions are constantly being invented. The problem of NER was actually formulated in Message Understanding Conferences (MUCs) [MUC6; MUC7] (Chinchor, 1995, 1998). The issues of correct identification of NEs were specifically addressed and benchmarked by the developers of information extraction system, such as the GATE system (Cunningham, 2002). The existing approaches for NER can be grouped into three main categories, namely rule-based, machine learning based and hybrid approach. Majority of the research focussed on machine learning (ML) approaches (Bikel et al., 1999; Borthwick, 1999; Sekine, 1998; Lafferty et al., 2001a; Yamada et al., 2001) because these are easily trainable, adaptable to different domains and languages as well as their maintenance are also being less expensive. In contrast, rule-based approaches lack the ability of dealing with the problems of robustness and portability. Each new source of text requires significant updates to the rules to maintain optimal performance and the maintenance costs could be quite steep. Literature shows that most of the works carried out in this direction cover mostly English and European languages. There are also significant amount of wo"
C12-1151,I08-5010,0,0.0173918,"mostly English and European languages. There are also significant amount of works in some of the Asian languages like Chinese, Japanese and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic families. Some works on NER for Indian languages can be found in (Ekbal and Saha, 2011; Ekbal and Bandyopadhyay, 2008; Ekbal et al., 2007; Ekbal and Bandyopadhyay, 2009b, 2007; Ekbal et al., 2008; Li and McCallum, 2004; Patel et al., 2009; Srikanth and Murthy, 2008; Shishtla et al., 2008; Vijayakrishna and Sobha, 2008). However, the works related to NER in Indian languages are still in the nascent stages due to the potential facts such as (Ekbal and Saha, 2011): • Unlike English and most of the European languages, Indian languages lack capitalization information, which plays a very important role in NE identification. • Indian person names are more diverse compared to the other languages and a lot of these words can be found in the dictionary with specific meanings. • Indian languages are highly inflectional language providing one of the richest and most challenging sets of l"
C12-1151,I08-5007,0,0.0238583,"ut in this direction cover mostly English and European languages. There are also significant amount of works in some of the Asian languages like Chinese, Japanese and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic families. Some works on NER for Indian languages can be found in (Ekbal and Saha, 2011; Ekbal and Bandyopadhyay, 2008; Ekbal et al., 2007; Ekbal and Bandyopadhyay, 2009b, 2007; Ekbal et al., 2008; Li and McCallum, 2004; Patel et al., 2009; Srikanth and Murthy, 2008; Shishtla et al., 2008; Vijayakrishna and Sobha, 2008). However, the works related to NER in Indian languages are still in the nascent stages due to the potential facts such as (Ekbal and Saha, 2011): • Unlike English and most of the European languages, Indian languages lack capitalization information, which plays a very important role in NE identification. • Indian person names are more diverse compared to the other languages and a lot of these words can be found in the dictionary with specific meanings. • Indian languages are highly inflectional language providing one of the richest and mos"
C12-1151,I08-5009,0,0.0260791,"pean languages. There are also significant amount of works in some of the Asian languages like Chinese, Japanese and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic families. Some works on NER for Indian languages can be found in (Ekbal and Saha, 2011; Ekbal and Bandyopadhyay, 2008; Ekbal et al., 2007; Ekbal and Bandyopadhyay, 2009b, 2007; Ekbal et al., 2008; Li and McCallum, 2004; Patel et al., 2009; Srikanth and Murthy, 2008; Shishtla et al., 2008; Vijayakrishna and Sobha, 2008). However, the works related to NER in Indian languages are still in the nascent stages due to the potential facts such as (Ekbal and Saha, 2011): • Unlike English and most of the European languages, Indian languages lack capitalization information, which plays a very important role in NE identification. • Indian person names are more diverse compared to the other languages and a lot of these words can be found in the dictionary with specific meanings. • Indian languages are highly inflectional language providing one of the richest and most challenging sets of linguistic and statistical featur"
C12-1151,M98-1020,0,\N,Missing
C14-1011,J13-3008,0,0.447496,"-measure over two gold standard data sets. 1 Introduction Web search results clustering (SRC), also known as post-retrieval clustering or ephemeral clustering has received much attention for the past twenty years for easing up user’s effort in web browsing. The key idea behind SRC systems is to return some meaningful labeled clusters from a set of web documents (or web snippets) retrieved from a search engine for a given query. Recently, SRC strategies have been focusing on the introduction of external (exogenous) knowledge to better capture semantics between documents (Scaiella et al., 2012; Marco and Navigli, 2013). Although this research direction has evidenced competitive results, the proposed clustering techniques are based on a single cluster quality measure, which must reflect alone the goodness of a given partitioning. These techniques are usually referred to as single objective optimizations (SOO). In this paper, we hypothesize that improved clustering can be achieved by defining different objective functions over well-known data representations. As such, our study aims to focus on new clustering issues for SRC instead of defining new representation spaces. Recent studies (Maulik et al., 2011) ha"
C14-1011,E14-4001,1,0.286979,"Missing"
C14-1011,P13-2028,1,0.860191,"Missing"
C14-1011,D10-1012,0,0.258366,"he series of decisions made by the partitions on single pairs of objects. The results of OPTIMSRC demonstrate that meta clustering is superior over individual clustering techniques. The latest work, exclusively based on endogenous information (i.e. web snippets returned by the search engine), is proposed by (Moreno et al., 2013). They adapt the K-means algorithm to a third-order similarity measure and propose a stopping criterion to automatically determine the “optimal” number of clusters. Experiments are run over two gold standard data sets, ODP-239 (Carpineto and Romano, 2010) and MORESQUE (Navigli and Crisafulli, 2010), and show improved results over all state-of-the-art text-based SRC techniques so far. A great deal of works have also proposed to include exogenous information to solve the SRC problem. One important work is proposed by (Scaiella et al., 2012) who use Wikipedia articles to build a bipartite graph and apply spectral clustering over it to discover relevant clusters. More recently, (Marco and Navigli, 2013) proposed to include word sense induction based on the Web1T corpus (Brants and Franz, 2006) to improve SRC. In this paper, we exclusively focus on endogenous solutions. 2.2 MOO-based Cluster"
C18-1321,C14-1011,1,0.416417,"Missing"
C18-1321,J13-3008,0,0.0651524,"Missing"
C18-1321,E14-4001,0,0.0605679,"Missing"
C18-1321,P13-2028,0,0.032294,"Missing"
C18-1321,D10-1012,0,0.232371,"roach that computes the agreement of two partitions of objects into varied clusters was proposed in this paper. This is done depending on the information content related to the series of decisions made by the partitions on single pairs of objects. OPTIMSRC results demonstrated that meta clustering is far better than individual clustering techniques. Moreno et al. (2013), adapted the K-means algorithm to a third-order similarity measure and proposed a stopping criterion that determines the optimal number of clusters automatically. Experiments were conducted on two standard data sets, MORESQUE (Navigli and Crisafulli, 2010) and ODP-239 (Carpineto and Romano, 2010), and showed significant improvement over all existing text-based SRC techniques developed by then. Later, Acharya et al. (2014), first defined the SRC task as a multi-objective problem. They defined two objective functions ( separability & compactness), that are optimized parallely with the help of AMOSA (Bandyopadhyay et al., 2008). Their evaluations outperformed knowledge-driven exogenous strategies (Scaiella et al., 2012), text-based endogenous SRC approaches and algorithms. In another work, the multi-view clustering approach proposed by Wahid et al"
C18-1321,W16-2346,0,0.0363668,"Missing"
C18-1321,P17-1142,0,0.0155885,"creased attention over the past few years. These models have been used in various applications: image captioning (You et al., 2016); sentiment analysis (Poria et al., This work is licensed under a Creative Commons Attribution 4.0 International Licence. http://creativecommons.org/licenses/by/4.0/. Licence details: 3793 Proceedings of the 27th International Conference on Computational Linguistics, pages 3793–3805 Santa Fe, New Mexico, USA, August 20-26, 2018. 2016); multimodal machine translation (Specia et al., 2016); visual question answering (Antol et al., 2015); combating human trafficking (Tong et al., 2017); and detection of Cyber-bullying (Zhong et al., 2016). In today’s online environment, the strategic use of multimedia (image, video etc.) has become increasingly important part of creating a successful website. Visual information embedded in web documents provides right-angled information that is free of ambiguities of natural language. It can also improve search ranking and Search engine optimization (SEO) scores on many levels that contribute to search visibility, find-ability, user satisfaction, experience and engagement. As a result, use of multimedia content in web documents has become m"
E17-1109,grouin-2014-biomedical,0,0.0252279,"utperform the dictionary based methods. Some of the recent works in BNER includes the unsupervised model as proposed in (Zhang and Elhadad, 2013), and the system based on CRF (Li et al., 2015a). A two-phase approach based on semi-Markov CRF is proposed in (Yang and Zhou, 2014). In the first phase boundaries of entities are identified while in the second phase semantic labeling is performed to label the detected entities. A CRF based system has been proposed by (Tang et al., 2015), where in the first step boundaries of NEs are identified and in the second step appropriate labels are assigned. (Grouin, 2014) performed experiments on the i2b2/VA-2010 challenge dataset to detect bacteria and biotopes names. They developed a model based on CRFs. An unsupervised approach is proposed in (Han et al., 2016) that made use of clustering based active learning. They have used Shared Nearest Neighbor (SNN) clustering technique. The work reported in (Li et al., 2015a), authors have proposed a parallel CRF algorithm (MapReduce CRF) which provides a mechanism to minimise the time taken for CRF learning. They showed that the proposed approach outperforms other traditional models in terms of time and efficiency."
E17-1109,W04-1219,0,0.045718,"ation guidelines. Therefore the system, developed by targeting a specific domain, often fails to show reasonable accuracy when it is evaluated for some other domains. In our work we attempt to build a system for entity extraction that performs well across various biomedical corpora. Popular existing system mostly rely on rule-based system or supervised machine learning technique to automatically extract entities. They looked upon this problem as in terms of sequence labeling and used algorithm such as hidden markov models (HMM) (Zhao, 2004), support vector machines (SVM) (Kazama et al., 2002; GuoDong and Jian, 2004), maximum entropy Markov model (MEMM) (Finkel et al., 2005) and conditional random fields (CRF) (Ekbal et al., 2013; Settles, 2004; Kim et al., 2005). These supervised learning models is fully dependent on the features that we use for training. Some of the popular features used in the existing studies include linguistic features such as morphological, syntactic and semantic information of words and domain-specific features from biomedical ontologies such as BioThesaurus (Liu et al., 2006) and UMLS (Unified Medical Language System) (Bodenreider, 2004). However, these features heavenly account t"
E17-1109,W02-0301,0,0.116279,"to the uniform annotation guidelines. Therefore the system, developed by targeting a specific domain, often fails to show reasonable accuracy when it is evaluated for some other domains. In our work we attempt to build a system for entity extraction that performs well across various biomedical corpora. Popular existing system mostly rely on rule-based system or supervised machine learning technique to automatically extract entities. They looked upon this problem as in terms of sequence labeling and used algorithm such as hidden markov models (HMM) (Zhao, 2004), support vector machines (SVM) (Kazama et al., 2002; GuoDong and Jian, 2004), maximum entropy Markov model (MEMM) (Finkel et al., 2005) and conditional random fields (CRF) (Ekbal et al., 2013; Settles, 2004; Kim et al., 2005). These supervised learning models is fully dependent on the features that we use for training. Some of the popular features used in the existing studies include linguistic features such as morphological, syntactic and semantic information of words and domain-specific features from biomedical ontologies such as BioThesaurus (Liu et al., 2006) and UMLS (Unified Medical Language System) (Bodenreider, 2004). However, these fe"
E17-1109,W04-1213,0,0.0899452,"m. The challenges as of these kinds are the primary causes behind the low accuracies of the systems developed for entity extraction in biomedi1159 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 1159–1170, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics cal text. The research challenges have been addressed in the literature including in some sharedtask challenges, such as JNLPBA (Joint Workshop on Natural Language Processing in Biomedicine and its Applications) in 2004 (Kim et al., 2004) and BioCreative (Critical Assessment for Information Extraction in Biology Challenge) II GM (gene mention) subtask in 2007 (Smith et al., 2008). Over the years several benchmark corpora have been created that do not conform to the uniform annotation guidelines. Therefore the system, developed by targeting a specific domain, often fails to show reasonable accuracy when it is evaluated for some other domains. In our work we attempt to build a system for entity extraction that performs well across various biomedical corpora. Popular existing system mostly rely on rule-based system or supervised"
E17-1109,I05-1057,0,0.0287701,"er domains. In our work we attempt to build a system for entity extraction that performs well across various biomedical corpora. Popular existing system mostly rely on rule-based system or supervised machine learning technique to automatically extract entities. They looked upon this problem as in terms of sequence labeling and used algorithm such as hidden markov models (HMM) (Zhao, 2004), support vector machines (SVM) (Kazama et al., 2002; GuoDong and Jian, 2004), maximum entropy Markov model (MEMM) (Finkel et al., 2005) and conditional random fields (CRF) (Ekbal et al., 2013; Settles, 2004; Kim et al., 2005). These supervised learning models is fully dependent on the features that we use for training. Some of the popular features used in the existing studies include linguistic features such as morphological, syntactic and semantic information of words and domain-specific features from biomedical ontologies such as BioThesaurus (Liu et al., 2006) and UMLS (Unified Medical Language System) (Bodenreider, 2004). However, these features heavenly account to the problem of data sparsity. In the recent past, there has been huge interest in using large unlabeled corpus to generate word representation feat"
E17-1109,W16-5102,0,0.0181422,"ed function that can efficiently solve the full NER task. The work proposed in (Tohidi et al., 2014) aims to improve the performance of entity extraction using statistical character-based syntax similarity (SCSS) algorithm. This algorithm computes the similarity between the identified candidate entities and a known set of well-known NEs. This set of NEs is created by extracting the most frequently occurring NEs in the GENIA V3.0 corpus. In recent times deep learning based approaches such as Recurrent Neural Network and Bi-directional LSTM have also used for entity extraction(Li et al., 2015b; Limsopatham and Collier, 2016). It is well known that relevant features play an important role for building a high accurate system. In our work, in addition to the standard features we also use the features extracted from the word embedding model. Bengio et al.(Bengio et al., 2003) have proposed a neural network based model for vector representation of words. Distributed representation (also known as word embedding) of a word has been used to improve the performance of various NLP tasks like Part-of-Speech (POS) tagging, NER in news-wire domain (Collobert et al., 2011), parsing (Socher et al., 2013; Turian et al., 2010) et"
E17-1109,N04-1043,0,0.0608219,"portant role for building a high accurate system. In our work, in addition to the standard features we also use the features extracted from the word embedding model. Bengio et al.(Bengio et al., 2003) have proposed a neural network based model for vector representation of words. Distributed representation (also known as word embedding) of a word has been used to improve the performance of various NLP tasks like Part-of-Speech (POS) tagging, NER in news-wire domain (Collobert et al., 2011), parsing (Socher et al., 2013; Turian et al., 2010) etc. Word cluster has been used used by Miller et al.(Miller et al., 2004) to boost the performance of a NER system. Tang et al. (Tang et al., 2012; Tang et al., 2013) have reported that performance of biomedical entity extraction can be improved when word representation is used as a feature to CRF and SVM classifiers. Here we propose a PSO based feature selection technique that determines the most relevant features from a full word embedding set, and use this subset as feature for classifier’s training. Feature selection has been widely used for many tasks such as gene expression (Ding and Peng, 2005), face recognition (Seal et al., 2015) and signal processing (Ala"
E17-1109,W04-1221,0,0.0914003,"ed for some other domains. In our work we attempt to build a system for entity extraction that performs well across various biomedical corpora. Popular existing system mostly rely on rule-based system or supervised machine learning technique to automatically extract entities. They looked upon this problem as in terms of sequence labeling and used algorithm such as hidden markov models (HMM) (Zhao, 2004), support vector machines (SVM) (Kazama et al., 2002; GuoDong and Jian, 2004), maximum entropy Markov model (MEMM) (Finkel et al., 2005) and conditional random fields (CRF) (Ekbal et al., 2013; Settles, 2004; Kim et al., 2005). These supervised learning models is fully dependent on the features that we use for training. Some of the popular features used in the existing studies include linguistic features such as morphological, syntactic and semantic information of words and domain-specific features from biomedical ontologies such as BioThesaurus (Liu et al., 2006) and UMLS (Unified Medical Language System) (Bodenreider, 2004). However, these features heavenly account to the problem of data sparsity. In the recent past, there has been huge interest in using large unlabeled corpus to generate word"
E17-1109,P13-1045,0,0.0532197,"t al., 2015b; Limsopatham and Collier, 2016). It is well known that relevant features play an important role for building a high accurate system. In our work, in addition to the standard features we also use the features extracted from the word embedding model. Bengio et al.(Bengio et al., 2003) have proposed a neural network based model for vector representation of words. Distributed representation (also known as word embedding) of a word has been used to improve the performance of various NLP tasks like Part-of-Speech (POS) tagging, NER in news-wire domain (Collobert et al., 2011), parsing (Socher et al., 2013; Turian et al., 2010) etc. Word cluster has been used used by Miller et al.(Miller et al., 2004) to boost the performance of a NER system. Tang et al. (Tang et al., 2012; Tang et al., 2013) have reported that performance of biomedical entity extraction can be improved when word representation is used as a feature to CRF and SVM classifiers. Here we propose a PSO based feature selection technique that determines the most relevant features from a full word embedding set, and use this subset as feature for classifier’s training. Feature selection has been widely used for many tasks such as gene"
E17-1109,P10-1040,0,0.079586,"tham and Collier, 2016). It is well known that relevant features play an important role for building a high accurate system. In our work, in addition to the standard features we also use the features extracted from the word embedding model. Bengio et al.(Bengio et al., 2003) have proposed a neural network based model for vector representation of words. Distributed representation (also known as word embedding) of a word has been used to improve the performance of various NLP tasks like Part-of-Speech (POS) tagging, NER in news-wire domain (Collobert et al., 2011), parsing (Socher et al., 2013; Turian et al., 2010) etc. Word cluster has been used used by Miller et al.(Miller et al., 2004) to boost the performance of a NER system. Tang et al. (Tang et al., 2012; Tang et al., 2013) have reported that performance of biomedical entity extraction can be improved when word representation is used as a feature to CRF and SVM classifiers. Here we propose a PSO based feature selection technique that determines the most relevant features from a full word embedding set, and use this subset as feature for classifier’s training. Feature selection has been widely used for many tasks such as gene expression (Ding and P"
E17-1109,W04-1216,0,0.055746,"orpora have been created that do not conform to the uniform annotation guidelines. Therefore the system, developed by targeting a specific domain, often fails to show reasonable accuracy when it is evaluated for some other domains. In our work we attempt to build a system for entity extraction that performs well across various biomedical corpora. Popular existing system mostly rely on rule-based system or supervised machine learning technique to automatically extract entities. They looked upon this problem as in terms of sequence labeling and used algorithm such as hidden markov models (HMM) (Zhao, 2004), support vector machines (SVM) (Kazama et al., 2002; GuoDong and Jian, 2004), maximum entropy Markov model (MEMM) (Finkel et al., 2005) and conditional random fields (CRF) (Ekbal et al., 2013; Settles, 2004; Kim et al., 2005). These supervised learning models is fully dependent on the features that we use for training. Some of the popular features used in the existing studies include linguistic features such as morphological, syntactic and semantic information of words and domain-specific features from biomedical ontologies such as BioThesaurus (Liu et al., 2006) and UMLS (Unified Medical Lan"
ekbal-saha-2010-maximum,M98-1014,0,\N,Missing
ekbal-saha-2010-maximum,M98-1021,0,\N,Missing
ekbal-saha-2010-maximum,I08-5008,1,\N,Missing
ekbal-saha-2010-maximum,M98-1019,0,\N,Missing
ekbal-saha-2010-maximum,E99-1001,0,\N,Missing
ekbal-saha-2010-maximum,A00-1034,0,\N,Missing
ekbal-saha-2010-maximum,W09-3539,1,\N,Missing
ekbal-saha-2010-maximum,W03-0419,0,\N,Missing
ekbal-saha-2010-maximum,M98-1012,0,\N,Missing
I11-1011,D08-1031,0,0.0143919,"001100101000011011100101101101111001100 11111001100001000011110100101111101110001101 01000100100101011001000010111100101100001000 10100101101011100011111110010100100010010011 00101111101110101001100000010101001011001001 00011000101110100010000010011000100110000100 76.8 76.7 74.6 72.2 71.4 74.0† 71.4 71.7 64.6 63.6 66.5 66.2 63.8 63.4 71.5 71.8† 67.1 67.6 65.2 70.3† 72.3 72.1 59.7 59.6 59.7† 59.1 60.0 61.2 74.5 74.9† 70.1† 69.1 70.3 73.1† 73.6 74.4 58.4 58.8 54.7† 55.6† 58.1 58.4 gos (2008). The results clearly show that although even larger sets of features have been proposed (Uryupina, 2007; Bengtson and Roth, 2008), the set of features already included in BART is sufficient to achieve results well above the state of the art on the dataset we used. larger datasets and larger sets of features learning a model becomes slower and requires much more memory. This suggests that automatic feature selection may be essential not just to improve performance but also to be able to train a model—i.e., that an efficient coreference resolution system should combine rich linguistic feature sets with automatic feature selection mechanisms. The results in Table 2 also confirm the intuition that, contrary to what is sugge"
I11-1011,W09-2411,0,0.0934369,"Missing"
I11-1011,doddington-etal-2004-automatic,0,0.0770207,"Missing"
I11-1011,J01-4004,0,0.640849,"(MOO) for coreference, that suggests a family of systems, showing reliable performance according to all the desired metrics. A form of MOO was applied to coreference by Munson et al. (2005). Their general conclusion was negative, stating that “ensemble selection seems too unreliable for use in NLP”, but they did see some improvements for coreference. 2 Background: Optimizing for Anaphora Resolution A great number of statistical approaches to anaphora resolution have been proposed in the past ten years. These approaches differ with respect to their underlying models (e.g., mention pair model (Soon et al., 2001) vs. tournament model (Iida et al., 2003; Yang et al., 2005), vs. entity-model (Luo et al., 2004)), machine learners (e.g., decision trees vs. maximum entropy vs. SVMs vs. TiMBL) and their parameters, and with respect to feature sets used. There have been, however, only few attempts at explicit optimization of these aspects, and in those few cases, optimization tends to be done by hand. An early step in this direction was the work by Ng and Cardie (2002), who developed a rich feature set including 53 features, but reported no significant improvement over their baseline when all these features"
I11-1011,S10-1020,1,0.825903,"ts) as the optimization functions). Perhaps the most interesting result of this work is the finding that by working in such a multi-metric space it is possible to find solutions that are better with respect to an individual metric than when trying to optimize for that metric alone—which arguably suggests that indeed both families of metrics capture some fundamental intuition about anaphora, and taking into account both intuitions we avoid local optima. 1 Introduction In anaphora resolution,1 as in other HLT tasks, optimization to a metric is essential to achieve good performance (Hoste, 2005; Uryupina, 2010). However, many evaluation metrics have been proposed for anaphora resolution, each capturing what seems to be a key intuition about the task: from MUC (Vilain et al., 1995) to B3 (Bagga and 1 We use the term ’anaphora resolution’ to refer to the task perhaps most commonly referred to as ’coreference resolution,’ which many including us find a misnomer. For the purposes of the present paper the two terms could be seen as interchangeable. The structure of the paper is as follows. We first review the literature on using genetic algorithms for both single function and multi function opti93 Procee"
I11-1011,P08-4003,1,0.897342,"the system proposed by Soon et al. (2001), commonly used as baseline and relying only on very shallow information. Our reimplementation of the Soon et al. model uses only a subset of features: those marked with an asterisk in Table 1. We also provide in Table 2 typical state-of-the-art figures on the ACE-02 dataset, as presented in an overview by Poon and Domin5 Methods 2 5.1 The choice of the best model and the best machine learner, along with its parameters, is the main direction of our future work. 3 http://sourceforge.net/projects/ carafe The BART System For our experiments, we use BART (Versley et al., 2008), a modular toolkit for anaphora reso96 Table 1: Features used by BART: each feature describes a pair of mentions {Mi , Mj }, i &lt; j, where Mi is a candidate antecedent and Mj is a candidate anaphor MentionType* MentionType Ante Salient MentionType Ante Extra MentionType Ana MentionType2 MentionType Salience FirstSecondPerson PronounLeftRight PronounWordForm SemClassValue BothLocation GenderAgree* NumberAgree* AnimacyAgree* Alias* BetterNames Appositive* Appositive2 Coordination HeadPartOfSpeech SynPos Attributes Relations StringMatch* NonPro StringMatch Pro StringMatch NE StringMatch HeadMatch"
I11-1011,W03-2604,0,0.0420636,"amily of systems, showing reliable performance according to all the desired metrics. A form of MOO was applied to coreference by Munson et al. (2005). Their general conclusion was negative, stating that “ensemble selection seems too unreliable for use in NLP”, but they did see some improvements for coreference. 2 Background: Optimizing for Anaphora Resolution A great number of statistical approaches to anaphora resolution have been proposed in the past ten years. These approaches differ with respect to their underlying models (e.g., mention pair model (Soon et al., 2001) vs. tournament model (Iida et al., 2003; Yang et al., 2005), vs. entity-model (Luo et al., 2004)), machine learners (e.g., decision trees vs. maximum entropy vs. SVMs vs. TiMBL) and their parameters, and with respect to feature sets used. There have been, however, only few attempts at explicit optimization of these aspects, and in those few cases, optimization tends to be done by hand. An early step in this direction was the work by Ng and Cardie (2002), who developed a rich feature set including 53 features, but reported no significant improvement over their baseline when all these features were used with the MUC 6 and MUC 7 corpo"
I11-1011,P04-1018,0,0.0209417,"to all the desired metrics. A form of MOO was applied to coreference by Munson et al. (2005). Their general conclusion was negative, stating that “ensemble selection seems too unreliable for use in NLP”, but they did see some improvements for coreference. 2 Background: Optimizing for Anaphora Resolution A great number of statistical approaches to anaphora resolution have been proposed in the past ten years. These approaches differ with respect to their underlying models (e.g., mention pair model (Soon et al., 2001) vs. tournament model (Iida et al., 2003; Yang et al., 2005), vs. entity-model (Luo et al., 2004)), machine learners (e.g., decision trees vs. maximum entropy vs. SVMs vs. TiMBL) and their parameters, and with respect to feature sets used. There have been, however, only few attempts at explicit optimization of these aspects, and in those few cases, optimization tends to be done by hand. An early step in this direction was the work by Ng and Cardie (2002), who developed a rich feature set including 53 features, but reported no significant improvement over their baseline when all these features were used with the MUC 6 and MUC 7 corpora. They then proceeded to manually select a subset of fe"
I11-1011,H05-1004,0,0.0543821,"coreference resolution system (i.e., BART) with only these N features. 3. This coreference system is evaluated on the development data. The recall, precision and F-measure values of three metrics are calculated. In case of single objective optimization (SOO), the objective function corresponding to a particular chromosome is the F-measure value of a single metric. This objective function is optimized using the search capability of GA. For MOO, the objective functions corresponding to a particular chromosome are FM U C (for the MUC metric), Fφ3 (for CEAF using the φ3 entity alignment function (Luo, 2005)) and Fφ4 (for CEAF using the φ4 entity alignment function). These three objective functions are simultaneously optimized using the search capability of NSGA-II. 4.3 Genetic Operators In case of SOO, a single point crossover operation is used with a user defined crossover probability, µc . A mutation operator is applied to each entry of the chromosome with a mutation probability, µm , where the entry is randomly replaced by either 0 or 1. In this approach, the processes of fitness computation, selection, crossover, and mutation are executed for a maximum number of generations. The best string"
I11-1011,H05-1068,0,0.69205,"C, CEAF or BLANC ). The results on the SEMEVAL-10 dataset clearly show that existing metrics of coreference rely on different intuitions and therefore a system, optimized for a particular metric, might show inferior results for the other ones. For example, the reported BLANC difference between the runs optimized for BLANC and CEAF is around 10 percentage points. This highlights the importance of the multiobjective optimization (MOO) for coreference, that suggests a family of systems, showing reliable performance according to all the desired metrics. A form of MOO was applied to coreference by Munson et al. (2005). Their general conclusion was negative, stating that “ensemble selection seems too unreliable for use in NLP”, but they did see some improvements for coreference. 2 Background: Optimizing for Anaphora Resolution A great number of statistical approaches to anaphora resolution have been proposed in the past ten years. These approaches differ with respect to their underlying models (e.g., mention pair model (Soon et al., 2001) vs. tournament model (Iida et al., 2003; Yang et al., 2005), vs. entity-model (Luo et al., 2004)), machine learners (e.g., decision trees vs. maximum entropy vs. SVMs vs."
I11-1011,P02-1014,0,0.158918,"resolution have been proposed in the past ten years. These approaches differ with respect to their underlying models (e.g., mention pair model (Soon et al., 2001) vs. tournament model (Iida et al., 2003; Yang et al., 2005), vs. entity-model (Luo et al., 2004)), machine learners (e.g., decision trees vs. maximum entropy vs. SVMs vs. TiMBL) and their parameters, and with respect to feature sets used. There have been, however, only few attempts at explicit optimization of these aspects, and in those few cases, optimization tends to be done by hand. An early step in this direction was the work by Ng and Cardie (2002), who developed a rich feature set including 53 features, but reported no significant improvement over their baseline when all these features were used with the MUC 6 and MUC 7 corpora. They then proceeded to manually select a subset of features that did yield better results for the MUC-6/7 datasets. A much larger scale and very systematic effort of manual feature selection over the same dataset was carried out by Uryupina (2007), who evaluated over 600 features. The first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by Hoste (2005), who i"
I11-1011,D08-1068,0,0.0358973,"Missing"
I11-1011,M95-1005,0,0.335391,"solutions that are better with respect to an individual metric than when trying to optimize for that metric alone—which arguably suggests that indeed both families of metrics capture some fundamental intuition about anaphora, and taking into account both intuitions we avoid local optima. 1 Introduction In anaphora resolution,1 as in other HLT tasks, optimization to a metric is essential to achieve good performance (Hoste, 2005; Uryupina, 2010). However, many evaluation metrics have been proposed for anaphora resolution, each capturing what seems to be a key intuition about the task: from MUC (Vilain et al., 1995) to B3 (Bagga and 1 We use the term ’anaphora resolution’ to refer to the task perhaps most commonly referred to as ’coreference resolution,’ which many including us find a misnomer. For the purposes of the present paper the two terms could be seen as interchangeable. The structure of the paper is as follows. We first review the literature on using genetic algorithms for both single function and multi function opti93 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 93–101, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP mization. Next, we di"
I11-1011,I05-1063,0,0.0178361,"howing reliable performance according to all the desired metrics. A form of MOO was applied to coreference by Munson et al. (2005). Their general conclusion was negative, stating that “ensemble selection seems too unreliable for use in NLP”, but they did see some improvements for coreference. 2 Background: Optimizing for Anaphora Resolution A great number of statistical approaches to anaphora resolution have been proposed in the past ten years. These approaches differ with respect to their underlying models (e.g., mention pair model (Soon et al., 2001) vs. tournament model (Iida et al., 2003; Yang et al., 2005), vs. entity-model (Luo et al., 2004)), machine learners (e.g., decision trees vs. maximum entropy vs. SVMs vs. TiMBL) and their parameters, and with respect to feature sets used. There have been, however, only few attempts at explicit optimization of these aspects, and in those few cases, optimization tends to be done by hand. An early step in this direction was the work by Ng and Cardie (2002), who developed a rich feature set including 53 features, but reported no significant improvement over their baseline when all these features were used with the MUC 6 and MUC 7 corpora. They then procee"
I11-1011,C10-1147,0,0.0142034,"imization of anaphora resolution we are aware of was carried out by Hoste (2005), who investigated the possibility of using genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering two different machine learners, TiMBL and Ripper. Her results suggest that such techniques yield improvements on the MUC-6/7 datasets. Recasens and Hovy (2009) carried out an investigation of feature selection for Spanish using the ANCORA corpus. These approaches focused on a single metric only; the one proposal simultaneously to consider multiple metrics, Zhao and Ng (2010) still optimized for each metric individually. The effect of optimization on anaphora resolution was dramatically demonstrated by Uryupina’s contribution to SEMEVAL 2010 Multilingual 3 Optimization with Genetic Algorithms In this section, we review optimization techniques using genetic algorithms (GAs) (Goldberg, 1989). We first discuss single objective optimization, that can optimize according to a single objective function, and then multi-objective optimization (MOO), that can optimize more than one objective function, in particular, a popular MOO technique named Non-dominated Sorting Geneti"
I11-1011,versley-etal-2008-bart-modular,1,\N,Missing
I11-1011,S10-1001,1,\N,Missing
I13-1099,S10-1021,1,0.847757,"ing mention detection models: 1. First Model: In our first model we consider each noun phrase(NP) as a possible candidate of mention. Results of this model are shown in Table 1. 2 Brief Description of BART System Architecture 2. Second Model: In our second model we consider each Named Entity (NE) or pronoun (PRP) as a mention and its results are shown in Table 1. Our starting point of anaphora resolution system is the toolkit from (Versley et al., 2008), originally conceived as a modularized version of previous efforts from (Ponzetto and Strube, 2006; Poesio and Kabadjov, 2004; Versley, 2006; Broscheit et al., 2010). BART’s final aim is to bring together stateof-the-art approaches, including syntax-based and semantic features. The state-of-the-art anaphora resolution system, BART has five main components: preprocessing pipeline, mention factory, feature extraction module, decoder and encoder. In addition, an independent language plugin module handles all the language specific information and is accessible from any component. Each module can be accessed independently and thus adjusted to leverage the system’s performance on a particular language or domain. The preprocessing pipeline converts an input docu"
I13-1099,P04-1018,0,0.0659193,"Missing"
I13-1099,H05-1004,0,0.0388236,"ve mentioned feature combinations. Instances are created following (Soon et al., 2001). We generate a positive training instance from each pair of adjacent coreferent markables. Negative instances are created by pairing the anaphor with any markable occurring between the anaphor and the antecedent. During testing, we perform a closest first clustering of instances deemed coreferent by the classifier. Each text is processed from left to right: each In order to evaluate the anaphora resolution system we use different scorers such as MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF (Luo, 2005) and BLANC (Recasens and Hovy, October 2011). We experiment with the different mention detectors for anaphora resolution. Table 4 shows the MUC recall, precision and F-measure values of the system trained using the training data and evaluated using the development data. Experiments were carried out on a high performance computing facility with the following configuration: Dell machine, 216 cores, 2.66 GHZ Intel Xeon processors, 4 GB RAM/core, and 10 TB storage. 7 http://ltrc.iiit.ac.in/showfile.php? filename=downloads/shallow parser.php 819 Mentions NP NE/PRP PER/PRP CRF Classifier recall 52.5"
I13-1099,P02-1014,0,0.290061,"Missing"
I13-1099,P10-1142,0,0.0522234,"Missing"
I13-1099,poesio-kabadjov-2004-general,1,0.899434,"utpal.sikdar,asif,sriparna}@iitp.ac.in 2 University of Trento, Center for Mind/Brain Sciences, uryupina@unitn.it 3 University of Essex, Language and Computation Group, poesio@essex.ac.uk Abstract Most of these works on supervised machine learning co-reference resolution have been developed for English (Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2003; Luo et al., 2004), due to the availability of large corpora such as ACE (Walker et al., 2006) and OntoNotes (Weischedel et al., 2008). BART, the Beautiful Anaphora Resolution Toolkit (Versley et al., 2008), (Ponzetto and Strube, 2006), (Poesio and Kabadjov, 2004), is the resultant of the project titled ”Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation” carried out at the Johns Hopkins Summer Workshop 2007. It can handle all the preprocessing tasks to perform automatic coreference resolution. A variety of machine learning approaches are used in BART; it mainly uses several machine learning toolkits, including WEKA, MaxEnt and Support Vector Machine (SVM). Literature shows the significant amount of works in the area of anaphora resolution. But these (Pradhan et al., 2012; Ng, 2010; Poesio et al., 2010) are mainy in non-Indian lang"
I13-1099,N06-1025,0,0.147589,"ineering, IIT Patna, India, {utpal.sikdar,asif,sriparna}@iitp.ac.in 2 University of Trento, Center for Mind/Brain Sciences, uryupina@unitn.it 3 University of Essex, Language and Computation Group, poesio@essex.ac.uk Abstract Most of these works on supervised machine learning co-reference resolution have been developed for English (Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2003; Luo et al., 2004), due to the availability of large corpora such as ACE (Walker et al., 2006) and OntoNotes (Weischedel et al., 2008). BART, the Beautiful Anaphora Resolution Toolkit (Versley et al., 2008), (Ponzetto and Strube, 2006), (Poesio and Kabadjov, 2004), is the resultant of the project titled ”Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation” carried out at the Johns Hopkins Summer Workshop 2007. It can handle all the preprocessing tasks to perform automatic coreference resolution. A variety of machine learning approaches are used in BART; it mainly uses several machine learning toolkits, including WEKA, MaxEnt and Support Vector Machine (SVM). Literature shows the significant amount of works in the area of anaphora resolution. But these (Pradhan et al., 2012; Ng, 2010; Poesio et al., 2010)"
I13-1099,W12-4501,1,0.883955,"Missing"
I13-1099,J01-4004,0,0.89698,"ot first person then the corresponding feature is also set to high. The feature also behaves in a similar way if the pair (REj , REi ) appears outside the quotation. Preprocessing and Markable Extraction For the anaphora resolution system, mentions are identified from the datasets based on the gold annotations. These are treated as the markables. Thereafter we convert the markables to the data format used by BART, namely MMAX2s standoff XML format. 3.2 Features for anaphora resolution We view coreference resolution as a binary classification problem. We use the learning framework proposed by (Soon et al., 2001) as a baseline. Each classification instance consists of two markables, i.e. an anaphor and its potential antecedent. Instances are modelled as feature vectors and are used to train a binary classifier. The classifier has to decide, given the features, whether the anaphor and the candidate antecedent are coreferent or not. To improve the performance we define some features specific to the language. Given BART’s flexible architecture, we explore the contribution of some features implemented in BART for co-reference resolution in Bengali. Given a potential antecedent REi and a anaphor REj , we c"
I13-1099,P08-4003,1,0.925741,"Computer Science and Engineering, IIT Patna, India, {utpal.sikdar,asif,sriparna}@iitp.ac.in 2 University of Trento, Center for Mind/Brain Sciences, uryupina@unitn.it 3 University of Essex, Language and Computation Group, poesio@essex.ac.uk Abstract Most of these works on supervised machine learning co-reference resolution have been developed for English (Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2003; Luo et al., 2004), due to the availability of large corpora such as ACE (Walker et al., 2006) and OntoNotes (Weischedel et al., 2008). BART, the Beautiful Anaphora Resolution Toolkit (Versley et al., 2008), (Ponzetto and Strube, 2006), (Poesio and Kabadjov, 2004), is the resultant of the project titled ”Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation” carried out at the Johns Hopkins Summer Workshop 2007. It can handle all the preprocessing tasks to perform automatic coreference resolution. A variety of machine learning approaches are used in BART; it mainly uses several machine learning toolkits, including WEKA, MaxEnt and Support Vector Machine (SVM). Literature shows the significant amount of works in the area of anaphora resolution. But these (Pradhan et al., 2012; N"
I13-1099,M95-1005,0,0.157159,"sion tree learning algorithm (Quinlan, 1993), with the above mentioned feature combinations. Instances are created following (Soon et al., 2001). We generate a positive training instance from each pair of adjacent coreferent markables. Negative instances are created by pairing the anaphor with any markable occurring between the anaphor and the antecedent. During testing, we perform a closest first clustering of instances deemed coreferent by the classifier. Each text is processed from left to right: each In order to evaluate the anaphora resolution system we use different scorers such as MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF (Luo, 2005) and BLANC (Recasens and Hovy, October 2011). We experiment with the different mention detectors for anaphora resolution. Table 4 shows the MUC recall, precision and F-measure values of the system trained using the training data and evaluated using the development data. Experiments were carried out on a high performance computing facility with the following configuration: Dell machine, 216 cores, 2.66 GHZ Intel Xeon processors, 4 GB RAM/core, and 10 TB storage. 7 http://ltrc.iiit.ac.in/showfile.php? filename=downloads/shallow parser.php 819 Menti"
I13-1099,P03-1023,0,0.0856957,"Missing"
L18-1442,D14-1181,0,0.00338329,"ng is fed as the input to the convolutional layer where filter F ∈ Rm×k is convoluted to the context window xi:i+m−1 of h words for each blog-post as follows. In this section we have presented the approach developed for extracting sentiments of users’ posts in medical blogs. 5.1. Network for Identifying Severity Level In this section we propose a method based on CNN that exploits sentiments from health forums (or, medical blogs) in augmentation layer. As presented in Figure-1, the proposed model has four different components which are similar to the conventional CNN components as proposed by (Kim, 2014). The first layer represents the input layer which takes a complete blog post in the form of vector representation (word embedding) and outputs a probability corresponding to the classification types. We use max-pooling over the whole blog post to obtain global features through all the filters. This pooled feature is fed into the fully connected neural network. In the output layer, we use the softmax classifier to automatically classify the post into three out(1) ci = f (F.xi:i+m−1 + b) (2) where f is non-linear function4 and b is a bias term. The feature map f is generated by applying given f"
L18-1442,W10-1915,0,0.0176194,"onducted by Biyani et al. (2013) used online cancer community user data to determine the polarity. They have adapted supervised machine learning techniques using hand-crafted features, which cover both domain-dependent as well as domain-independent features. They identified sentiments on two discourse functions such as expressive and persuasive. A supervised machine learning model (multi-nominal naive Bayes) is developed using frequency-based features. • Adverse Drug Relation: For medical domains, social media texts (corresponding to medical forums) have been utilized in the works such as DS (Leaman et al., 2010; Nikfarjam and Gonzalez, 2011; Liu and Chen, 2013), MedHelp (Yang et al., 2012) and PatientsLikeMe (Wicks et al., 2011). Non-medical social media forums like Twitter (Nikfarjam et al., 2015) have been exploited to capture adverse drug effect. With the availability of the extensive Adverse Drug Reaction (ADR) lexicons such as Side Effect Resource (SIDER)2 (Kuhn et al., 2010), Coding Symbols for a Thesaurus of Adverse Reaction Terms (COSTART), Consumer Health Vocabulary (CHV) (Zeng-Treitler et al., 2008) and Medical Dictionary for Regulatory Activities (MedDRA) (Mozzicato, 2009), some prominent"
L18-1442,R11-1019,0,0.020062,"Missing"
L18-1442,R13-1083,0,0.0439844,"Missing"
N18-2044,R13-1003,0,0.0169051,"online mental health forum into four different categories (crisis/red/amber/green) according to how urgently the post needs the attention. Shickel et al. (2016) introduced the notion of applying sentiment analysis to the mental health domain by defining new polarity classification scheme. They split the traditional ‘neutral’ class into both a dual polarity sentiment (both positive and negative) and a ‘neither positive nor negative’ sentiment class. Some of the other prominent works in the opinion mining in medical setting, includes studies by (Bobicev et al., 2012; Sokolova and Bobicev, 2011; Ali et al., 2013). In the study conducted by (Pestian et al., 2012), authors analyzed the emotions and sentiment of suicide notes. The other study in medical sentiment analysis includes the work of Bobicev et al. (2014), where they analyzed sequences of sentiments (encouragement, gratitude, confusion, facts, and endorsement) in In Vitro Fertilization (IVF) medical forum. In terms of methods, majority of the work utilizes machine learning technique (SVM, naive Bayes, logistic regression) by exploiting features such as features, while certain common features could also lie in the task specific feature space, lea"
N18-2044,P17-1001,0,0.0828406,"Missing"
N18-2044,W14-5907,0,0.0288789,"timent analysis to the mental health domain by defining new polarity classification scheme. They split the traditional ‘neutral’ class into both a dual polarity sentiment (both positive and negative) and a ‘neither positive nor negative’ sentiment class. Some of the other prominent works in the opinion mining in medical setting, includes studies by (Bobicev et al., 2012; Sokolova and Bobicev, 2011; Ali et al., 2013). In the study conducted by (Pestian et al., 2012), authors analyzed the emotions and sentiment of suicide notes. The other study in medical sentiment analysis includes the work of Bobicev et al. (2014), where they analyzed sequences of sentiments (encouragement, gratitude, confusion, facts, and endorsement) in In Vitro Fertilization (IVF) medical forum. In terms of methods, majority of the work utilizes machine learning technique (SVM, naive Bayes, logistic regression) by exploiting features such as features, while certain common features could also lie in the task specific feature space, leading to feature redundancy. Adversarial learning (Goodfellow et al., 2014) is the process of learning a model to correctly classify both unmodified data and adversarial data through the regularization m"
N18-2044,W16-0312,0,0.0781823,"ects (medical condition and medication). The texts in bold indicates the sentiment word. uments (nurse letters, radiology reports, and discharge summaries). They also studied users self reported drug reviews on blogs (WebMD, DrugRating) to asses the possible medical sentiments. Majority of the current research in medical sentiment analysis are focused on understanding the mental health disorder, mainly depression. Several shared tasks (Losada et al., 2017; Hollingshead et al., 2017) have also been organized to study the patient health-related opinions on social media. The challenge defined in Milne et al. (2016) aims to automatically classify the user posts from an online mental health forum into four different categories (crisis/red/amber/green) according to how urgently the post needs the attention. Shickel et al. (2016) introduced the notion of applying sentiment analysis to the mental health domain by defining new polarity classification scheme. They split the traditional ‘neutral’ class into both a dual polarity sentiment (both positive and negative) and a ‘neither positive nor negative’ sentiment class. Some of the other prominent works in the opinion mining in medical setting, includes studies"
N18-2044,W16-0303,0,0.0193889,"ogs (WebMD, DrugRating) to asses the possible medical sentiments. Majority of the current research in medical sentiment analysis are focused on understanding the mental health disorder, mainly depression. Several shared tasks (Losada et al., 2017; Hollingshead et al., 2017) have also been organized to study the patient health-related opinions on social media. The challenge defined in Milne et al. (2016) aims to automatically classify the user posts from an online mental health forum into four different categories (crisis/red/amber/green) according to how urgently the post needs the attention. Shickel et al. (2016) introduced the notion of applying sentiment analysis to the mental health domain by defining new polarity classification scheme. They split the traditional ‘neutral’ class into both a dual polarity sentiment (both positive and negative) and a ‘neither positive nor negative’ sentiment class. Some of the other prominent works in the opinion mining in medical setting, includes studies by (Bobicev et al., 2012; Sokolova and Bobicev, 2011; Ali et al., 2013). In the study conducted by (Pestian et al., 2012), authors analyzed the emotions and sentiment of suicide notes. The other study in medical se"
N18-2044,R11-1019,0,0.0205476,"sify the user posts from an online mental health forum into four different categories (crisis/red/amber/green) according to how urgently the post needs the attention. Shickel et al. (2016) introduced the notion of applying sentiment analysis to the mental health domain by defining new polarity classification scheme. They split the traditional ‘neutral’ class into both a dual polarity sentiment (both positive and negative) and a ‘neither positive nor negative’ sentiment class. Some of the other prominent works in the opinion mining in medical setting, includes studies by (Bobicev et al., 2012; Sokolova and Bobicev, 2011; Ali et al., 2013). In the study conducted by (Pestian et al., 2012), authors analyzed the emotions and sentiment of suicide notes. The other study in medical sentiment analysis includes the work of Bobicev et al. (2014), where they analyzed sequences of sentiments (encouragement, gratitude, confusion, facts, and endorsement) in In Vitro Fertilization (IVF) medical forum. In terms of methods, majority of the work utilizes machine learning technique (SVM, naive Bayes, logistic regression) by exploiting features such as features, while certain common features could also lie in the task specific"
N18-2044,R13-1082,0,0.0138959,"Deng (2015) provides the quantitative assessment of sentiment across the clinical narrative and social media sources. Towards this, they created a domain-specific corpus from MIMIC II database containing clinical doc272 Figure 2: Architecture of proposed methodology 3.1 bigram, trigram, parts of speech. Also, there has been predominant use of general sentiment lexicon, however their analysis shows that it does not help in capturing the medical sentiment. More domain specific knowledge is also embedded using medical knowledge graph such as UMLS to identify the medical condition and treatment (Sokolova et al., 2013). 3 Let us assume that a blog-text P having k sentences and word sequence w = {w1 , w2 , . . . wl } be given. The embedding layer is used to find out the vector representation xi ∈ Rd×V from a d dimensional pre-trained word embedding of vocabulary V . Each word wi ∈ w will be represented by its respective word embedding xi . The hidden units hl learned at the last time step (l) of sequence are considered as the encoding of the medical blog, P . The representations hl generated from the Eq 1 are fed to a fully connected softmax layer to generate the probability distribution over the given class"
P17-2104,N15-2023,0,0.0306458,"on, a linear Support Vector Machine (lSVM)1 is used. In particular, we trained three binary classifiers (one per class)2 using one-vs.-rest, and label a tweet with the class that assigned the highest score. In the second step, we pass tweets through these two optimized components to detect their temporal orientation. Related Work Existing message-/sentence-level temporal classification methods generally fall into two categories: (1) rule-based methods, and (2) supervised machine-learning methods. Rule-based methods mainly rely on manually designed classification rules for each temporal class (Nie et al., 2015). Despite their effectiveness, this kind of method requires substantial efforts in rule design. Most research on machine learning-based sentence temFigure 1: Proposed learning architecture. 1 Trained using the Weka implementation of LIBSVM with linear kernels (polynomial kernels yielded worse performance). 2 Multi-class classification yielded worse performance. 660 The choice of CNN for feature extraction is motivated by: of the CNN model are learned by passing multiple filters over word vectors and then applying the max-over-time pooling operation to generate features which are used in a full"
P17-2104,D15-1303,0,0.0129706,"lar to Kim (2014), we use dropout (Hinton et al., 2012) to regularize the change of parameters by randomly setting some weights to zero that prevents overfitting. • CNNs have been successfully used as feature extractors in various computer vision tasks and achieved better results compared to handcrafted features. Research has shown that CNN feature maps can be used with SVM to yield classification results that outperform the original CNN (Athiwaratkun et al., 2015) 3.2 • Superior accuracies have also been achieved by following a similar line of research in the context of NLP tasks (Kim, 2014; Poria et al., 2015). Income Predictor Model Similar to Preot¸iuc-Pietro et al. (2015), we formulate the income prediction task as regression using user-level temporal orientation as features. First, the tweet temporal orientation classifier is used to label whether a tweet focuses on past, present, or future. Afterwards, at user-level, we produce three categories of temporal orientation (three separate variables summing to one), defined simply as the proportion of a user’s total tweets (tweets(user)all ) classified in the given temporal category (c ∈ { past, present, or future}), as in (1): Convolutional Neural"
P17-2104,D14-1181,0,0.00435547,"Missing"
P17-2104,D14-1121,0,0.0323303,"se it to build a predictive model of income. Our analysis uncovers a correlation between future temporal orientation and income. Finally, we measure the predictive power of future temporal orientation on income by performing regression. 1 Introduction User-generated content in social media such as Twitter has enabled the study of author profiling on an unprecedented scale. Author profiling in social media aims at inferring various attributes of the user from the text that they have written. Most of the prior studies in this field have focused on age, gender prediction (Marquardt et al., 2014; Sap et al., 2014), psychological well-being (Dodds et al., 2011; Choudhury et al., 2013), and a host of other behavioural, psychological and medical phenomena (Kosinski et al., 2013). However, there has been a lack of work looking at the socioeconomic characteristics of Twitter users. In this paper, we focus on automatic estimation of Twitter users’ income from their Twitter language. An income predictor of social media users can be useful for both social science research and a range of 659 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 659–665 c V"
P17-2104,N15-1044,0,0.265038,"income predictor of social media users can be useful for both social science research and a range of 659 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 659–665 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2104 poral classification has revolved around feature engineering for better classification performance. Different kinds of features have been explored such as bag-of-words, time expressions, part-ofspeech tags, and temporal class-specific lexicons (Schwartz et al., 2015). Temporal class specific lexicon creation and feature engineering also cost a lot of human efforts. In addition, creation of a large-scale training data set for supervised machine-learning approaches is also very laborious. ally selected eighty (80) high-precision seed terms (and automatically extracted similar terms) representing past, present, and future to train the CNN. For example, tweets exclusively containing past (resp. present and future) seed terms were marked with weak labels past (resp. present and future). We used the tweet-level temporal classifier to automatically classify a la"
P19-1516,P16-2058,0,0.0435355,"Missing"
P19-1516,P15-1033,0,0.012886,"2016). Let us the consider the input sequence to this layer is E = {e1 , e2 , . . . , en }. A convolution operation is performed over the zero-padded sequence E p . Similar to the character embedding, a set of k filter of size m are applied to the sequence. We obtain convoluted features ct at given time t for t = 1, 2, . . . , n. ct = relu(F [et− m−1 . . . et . . . et+ m−1 ]) 2 (3) 2 Then, we generate the feature vectors C 0 = [c01 , c02 . . . c0n ], by applying max pooling on C. Inspired by the success of stacked attentive RNN in solving other NLP tasks (Wu et al., 2016; Graves et al., 2013; Dyer et al., 2015; Prakash et al., 2016), we use the stacked GRU to encode the input text. The stacked GRU is an extension to GRU model that has multiple hidden GRU layers. The purpose of using multiple GRUs layers is to learn more sophisticated conditional distributions from the data (Bahdanau et al., 2015). In this work, we employ vertical stacking strategy where the output of the previous layer of GRU is fed to the highway layer and corresponding output is passed as input to the next layer of GRU. Let the number of layers in stacked GRU is L then the GRU computes the hidden state for each layer l ∈ L as fol"
P19-1516,C16-1084,0,0.12138,"es such as social media, both EMR and medical case reports offer several advantages of having complete records of patients’ medical history, treatment, conditions and the possible risk factors, and is also not restricted to the patients experiencing ADRs (Harpaz et al., 2012b). Recently, a study conducted by (Sarker and Gonzalez, 2015) utilized the data from MEDLINE case reports and Twitter. They proposed several textual features and investigated how the combination of different datasets would increase the performance of identifying ADRs. With the advancement of the neural network technique, (Huynh et al., 2016) investigated multiple neural network (NN) frameworks for ADR classification on both medical case reports and Twitter dataset. (ii) Social Media: Social media offers a very rich and viable source of information for identifying potential ADRs in a real-time. Leaman et al. (2010) conducted very first study utilizing user comments from their social media post. In total, the dataset contains 6, 890 user comments. The research shows that user comments are highly beneficial in uncovering the ADRs. Further works (Gurulingappa et al., 2012b; Benton et al., 2011; Harpaz et al., 2012a) utilized the lexi"
P19-1516,W10-1915,0,0.257382,"al Drug Administration’s Adverse Event Reporting System (FAERS) (Li et al., 2014). These systems are often under-reported, biased and delayed. To overcome the limitation of a passive reporting system, active methods to ADR monitoring continuously explores frequently updated ADR data sources (Behrman et al., 2011). The quantity and near-instantaneous nature of social media provide potential opportunities for real-time monitoring of Adverse Drug Reaction (ADR). The fact that this data is up-to-date and is generated by patients overcomes the weaknesses of traditional ADR surveillance techniques (Leaman et al., 2010). Thus, social media could complement traditional information sources for more effective pharmacovigilance studies, as well as potentially serve as an early warning system for unknown ADR, which may be important for a clinical decision. Additionally, the high statistically significant correlation (p &lt; 0.001, ρ = 0.75) between FAERS and ADRs (extracted through Twitter data) shows that Twitter is a viable pharmacovigilance data source (Freifeld et al., 2014). With the enormous amount of data generated every day, it is desirable to have an automated ADR extraction system that can ease the work of"
P19-1516,P17-1001,0,0.0174851,"order to capture the common features along the task, we utilize the above feature extractor framework which serves as a Generator model and the feed forward neural network as a Discriminator. 3.4 Task Discriminator Layer Our feature extractor layer is generating two types of features, shared and task-specific. Ideally both feature spaces should be mutually exclusive. To ensure that task-specific features of given task do not exist in the shared space, we exploit the concept of adversarial training (Goodfellow et al., 2014) into shared feature space. We follow the same method as introduced by (Liu et al., 2017) to make the shared feature space uncontaminated by the task-specific features. For achieving the aforementioned strategy, a Task Discriminator D is used to map the attention prioritized shared feature to estimate the task of its origin. In our case, Task Discriminator is a fully connected layer using a softmax layer to produce the probability distribution of the shared features belonging to any task. The shared feature extractor (c.f. 3.3) works as Generator (G) to generate shared features. The shared feature extractor is made to work in an adversarial way, preventing the discriminator from p"
P19-1516,C16-1275,0,0.0526184,"Missing"
P19-1516,E17-1014,0,0.0289778,"included in lexicons. With the emergence of annotated data, several research works have employed supervised machine learning techniques such as Support Vector Machine (SVM) (Sarker and Gonzalez, 2015), Conditional Random Field (CRF) (Nikfarjam et al., 2015) and Random Forest (Zhang et al., 2016). In recent years with the introduction of deep learning techniques, most of the studies utilize deep learning model to predict ADRs. Lee et al. (2017) developed semi-supervised deep learning model on the Twitter corpus. In particular, they used the Convolution Neural Network (CNN) for classification. Stanovsky et al. (2017) used the Recurrent Neural Network integrated with knowledge graph embedding on the CADEC corpus. Their study shows that this integration can make the model more accurate. Tutubalina and Nikolenko (2017) explored the combination of CRF and Recurrent Neural Network (RNN). Their 5236 results show that CRF can assist RNN model in capturing the context well. The most relevant work to this study is the work conducted by Chowdhury et al. (2018). They learned jointly for three tasks: binary classification, ADR labeling, and indication labeling using RNN-attentioncoverage model. 3 Methodology With our"
P19-1516,1983.tc-1.13,0,0.193168,"Missing"
U13-1008,U11-1012,1,0.414703,"Missing"
U13-1008,J13-3008,0,0.0718542,"Missing"
U13-1008,U04-1000,0,\N,Missing
W11-1908,P05-1045,0,0.0191921,"Missing"
W11-1908,H05-1004,0,0.507946,"asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that"
W11-1908,H05-1068,0,0.0196597,"tomatic optimization of both feature selection and of learning parameters, also considering 61 Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 61–65, c Portland, Oregon, 23-24 June 2011. 2011 Association for Computational Linguistics two different machine learners, TimBL and Ripper. Her results suggest that such techniques yield improvements on the MUC-6/7 datasets. Recasens and Hovy (2009) carried out an investigation of feature selection for Spanish using the ANCORA corpus. A form of multi-objective optimization was applied to coreference by Munson et al. (2005). Munson et al. (2005) did not propose to train models so as to simultaneously optimize according to multiple metrics; instead, they used ensemble selection to learn to choose among previously trained models the best model for each example. Their general conclusion was negative, stating that “ensemble selection seems too unreliable for use in NLP”, but they did see some improvements for coreference. Genetic algorithms are known to be more effective for solving MOO than classical methods such as weighted metrics, goal programming (Deb, 2001), because of their population-based nature. A particul"
W11-1908,P02-1014,0,0.480729,"inguistically-rich system for coreference resolution might benefit a lot from feature selection. In particular, we have investigated Non-Dominated Sorting Genetic Algorithm II (Deb et al., 2002) for multiobjective optimization. In subsequent work, we plan to expand the optimization technique to consider also learning parameters optimization, classifier selection, and learning model selection. 4 Results 4.1 Acknowledgments Development set Table 1 compares the performance level obtained using all the features with that of loose reimplementations of the systems proposed by Soon et al. (2001) and Ng and Cardie (2002), commonly used as baselines. Our reimplementation of the Ng & Cardie model uses only a subset of features. The results in Table 1 show that our system with a rich feature set does not outperform simpler baselines (and, in fact, yields poorer results). A similar trend has been observed by Ng and Cardie (2002), where the improvement was only possible after manual feature selection. The last line of Table 1 shows the performance level of the best chromosome found through the MOO technique. As it can be seen, it outperforms all the baselines according to all the measures, leading to an improvemen"
W11-1908,W11-1901,0,0.150736,"Missing"
W11-1908,W09-2411,0,0.0655299,"Missing"
W11-1908,I11-1011,1,0.674013,"one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that have been developed in the area of Genetic Algorithms—so-called multi-objective optimization techniques (MOO) (Deb, 2001). The key idea of our submission is to use MOO techniques to optimize our anaphora resolution system according to three metrics simultaneously: the MUC scorer (a member of what one might call the ’link-based’ cluster of metrics) and the two CEAF metrics (representative of the ’entity-based’ cluster). In a previous study (Saha et al., 2011), we show that our MOO -based approach yields more robust results than single-objective optimization. We test two types of optimization: feature selection and architecture–whether to learn a single model for all types of anaphors, or to learn separate models for pronouns and for other nominals. We also discuss how the default mention extraction techniques of the system we used for this submission, BART (Versley et al., 2008), were modified to handle the all-mention annotation in the OntoNotes corpus. In this paper, we first briefly provide some background on optimization for anaphora resolutio"
W11-1908,J01-4004,0,0.885984,"d split classifiers. We considered 42 features, including 7 classifying mention type, 8 for string matching of different subparts and different levels of exactness, 2 for aliasing, 4 for agreement, 12 for syntactic information including also binding constraints, 3 encoding salience, 1 encoding patterns extracted from the Web, 3 for proximity, and 2 for 1st and 2nd person pronouns. Again because of time considerations, we used decision trees as implemented in Weka as our classification model instead of maximum-entropy or SVMs. Finally, we used a simple mention-pair model without ranking as in (Soon et al., 2001). 3.2 Mention detection BART supports several solutions to the mention detection (MD) task. The users can input precomputed mentions, thus, experimenting with gold boundaries or system boundaries computed by external modules (e.g., CARAFE). BART also has a built-in mention extraction module, computing boundaries heuristically from the output of a parser. For the CoNLL shared task, we use the BART internal MD module, as it corresponds better to the mention detection guidelines of the OntoNotes dataset. We have further adjusted this module to improve the MD accuracy. The process of mention detec"
W11-1908,P08-4003,1,0.950061,"MUC scorer (a member of what one might call the ’link-based’ cluster of metrics) and the two CEAF metrics (representative of the ’entity-based’ cluster). In a previous study (Saha et al., 2011), we show that our MOO -based approach yields more robust results than single-objective optimization. We test two types of optimization: feature selection and architecture–whether to learn a single model for all types of anaphors, or to learn separate models for pronouns and for other nominals. We also discuss how the default mention extraction techniques of the system we used for this submission, BART (Versley et al., 2008), were modified to handle the all-mention annotation in the OntoNotes corpus. In this paper, we first briefly provide some background on optimization for anaphora resolution, on genetic algorithms, and on the method for multiobjective optimization we used, Non-Dominated Sorting Genetic Algorithm II (Deb et al., 2002). After that we discuss our experiments, and present our results. 2 Background 2.1 Optimization for Anaphora Resolution There have only been few attempts at optimization for anaphora resolution, and with a few exceptions, this was done by hand. The first systematic attempt at autom"
W11-1908,M95-1005,0,0.476534,"y Patna ∗ University of Essex uryupina@gmail.com, sriparna@iitp.ac.in, asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metr"
W11-1908,S10-1001,1,\N,Missing
W11-1908,doddington-etal-2004-automatic,0,\N,Missing
W16-4205,U13-1008,1,0.885225,"123], [5523] [1080], [8545] [5523], [3321], [6434] [8545], [3321], [6434], [6755] titioning. However, in order to determine a proper partitioning, optimizing a single cluster validity index is not always sufficient, especially in the situation when we deal with text documents having clusters of different shapes and sizes. The concept of multi-objective optimization (MOO) can be brought into consideration where we need to optimize several objective functions at the same time. The advantage of MOO is that we can generate clusters by optimizing several cluster validity indices. Inspired by this, Ekbal et al. (2013) proposed a MOO-based approach for clustering medical documents for EBM by using the search capability of a simulated annealing based approach, AMOSA (Archived MultiObjective Simulated Annealing based technique) (Bandyopadhyay et al., 2008). However, it has been shown that for some benchmark datasets, AMOSA performs slowly compared to a popular genetic algorithm based MOO technique, NSGA-II (Non-dominated Sorting Genetic Algorithm-II) (Bandyopadhyay et al., 2008). Therefore, an alternative MOO-based approach is needed in order to verify whether we can improve the run-time complexity of AMOSA."
W16-4205,U11-1012,1,0.896402,"Missing"
W16-4206,J81-4005,0,0.760879,"Missing"
W16-4206,D14-1181,0,0.00265422,"the rules. This incurs cost and time as the appropriate set of features or rules can be framed only after analyzing the full records. The advent of deep learning algorithms has facilitated to introduce a new framework where we do not require handcrafted features or rules. These models have the abilities to learn automatically the relevant features by performing composition over the words represented in the form of vectors known as word embedding. In recent times, deep neural network architecture has shown promise for solving various NLP tasks such as text classification (Socher et al., 2013; Kim, 2014), language modeling (Mikolov et al., 2010), question answering (Weston et al., 2015), machine translation (Bahdanau et al., 2014), spoken language understanding (Mesnil et al., 2013) etc. In this paper, we propose a novel system (DI-RNN) based on deep learning for patient data de-identification (PDI). We formulate the task as a sequence labeling problem and develop a technique based on Recurrent Neural Network (RNN) (Mikolov et al., 2010). RNN, unlike other techniques, does not require features to be explicitly generated for classifier’s training or testing. Instead it learns features by itsel"
W16-4206,H05-1026,0,0.0901288,". The underlying idea is that similar words appear in close vicinity of each other. The vector corresponding to each input word wi is produced whose dimensionality is set at the time of learning the neural language model from the given unsupervised corpus. This representation provides the continuousspace representation for each word. Usually, training of the word embedding is done in an unsupervised manner using external natural language text like Wikipedia, news article, bio-medical literature etc. The architecture can be varied by adopting various architectures like shallow neural networks (Schwenk and Gauvain, 2005), RNN (Mikolov et al., 2010; Mikolov et al., 2011), SENNA (Collobert et al., 2011), 34 word2vec (Mikolov et al., 2013) etc. We use three different procedures to learn word embeddings like random number initialization, RNN’s word embedding and continuous bag-of-words (CBOW). For random word embedding we initialize the vector of dimension 100 in the range −0.25 to +0.25. In order to evaluate the impact of RNN we use the word embedding as provided by RNNLM 4 of dimension 80 which is trained on Broadcast news corpus. In addition to this we also use word embedding model trained by CBOW technique as"
W16-4206,D13-1170,0,0.0313007,"minent feature set or the rules. This incurs cost and time as the appropriate set of features or rules can be framed only after analyzing the full records. The advent of deep learning algorithms has facilitated to introduce a new framework where we do not require handcrafted features or rules. These models have the abilities to learn automatically the relevant features by performing composition over the words represented in the form of vectors known as word embedding. In recent times, deep neural network architecture has shown promise for solving various NLP tasks such as text classification (Socher et al., 2013; Kim, 2014), language modeling (Mikolov et al., 2010), question answering (Weston et al., 2015), machine translation (Bahdanau et al., 2014), spoken language understanding (Mesnil et al., 2013) etc. In this paper, we propose a novel system (DI-RNN) based on deep learning for patient data de-identification (PDI). We formulate the task as a sequence labeling problem and develop a technique based on Recurrent Neural Network (RNN) (Mikolov et al., 2010). RNN, unlike other techniques, does not require features to be explicitly generated for classifier’s training or testing. Instead it learns featu"
W16-4206,W00-1308,0,0.0526202,"ication task. Here R,P and F denotes Recall, Precision and F-score respectively. 2. Bag-of-word feature: This feature includes uni-grams, bi-grams, tri-grams of the target token. We use window size of [-2, 2] with respect to the target token. Here, n-gram is referred as the continuous sequence of n items. An n-gram generated having sizes of 1, 2, 3 are known as an uni-gram, bi-gram and tri-gram, respectively. 3. Part-of-Speech (PoS) Information: The PoS information of current word, previous two words and the next two words are used as features. We obtain PoS of words from the Stanford tagger (Toutanova and Manning, 2000). 4. Chunk Information: The chunk information is an important feature to identify the PHI termboundary. We use chunk information obtained from openNLP5 . 5. Combined POS-token and Chunk-token Feature: This feature is generated by the combination of other token features like PoS, Chunk within the context window of [-1, 1]. This is represented as [w0 p−1 , w0 p0 , w0 p1 ] where w0 represents the target word, and p−1 , p0 and p1 represent the previous, current and the next POS or Chunk tags, respectively. We build our model by incorporating the above features. We use the CRF implementation6 of CR"
W16-6311,P98-1041,0,0.081381,"pta et al., 2012). For example, the word khusboo (”fragrance”) can be written in Roman script using different variations such as kushboo, khusbu, khushbu and so on. This type of problem is termed as a non-trivial term matching problem for search engines with the aim to match the native-script or Roman-transliterated query with the documents in multiple scripts after considering the spelling variations. Many single (native) script queries and documents with spelling variations have been studied (French et al., 1997; Zobel and Dart, 1996) as well as transliteration of named entities (NE) in IR (Collier et al., 1998; Wang et al., 2009). It is important for every IR engine to present users with information that are most relevant to the users’ needs. While searching, user has an idea of what s/he wants, but in many instances, due to the variations in query formulations, retrieved results could greatly vary. As a result, understanding the nature of information need behind the queries issued by Web users has become an imD S Sharma, R Sangal and A K Singh. Proc. of the 13th Intl. Conference on Natural Language Processing, pages 81–89, c Varanasi, India. December 2016. 2016 NLP Association of India (NLPAI) por"
W16-6311,gupta-etal-2012-mining,0,0.03166,"as well as Roman scripts, and these should also be matched to the documents written in both the scripts. Transliteration (Lopez, 2008) is the process of phonetically describing the words of a given language using a non-native script. For both the web documents and intended search queries to retrieve those documents, transliteration, especially into Roman script, is generally used. Since no standard ways of spelling any word into a non-native script exist, transliterated contents offer extensive spelling variations; typically, we can transliterate a native term into Roman script in many ways (Gupta et al., 2012). For example, the word khusboo (”fragrance”) can be written in Roman script using different variations such as kushboo, khusbu, khushbu and so on. This type of problem is termed as a non-trivial term matching problem for search engines with the aim to match the native-script or Roman-transliterated query with the documents in multiple scripts after considering the spelling variations. Many single (native) script queries and documents with spelling variations have been studied (French et al., 1997; Zobel and Dart, 1996) as well as transliteration of named entities (NE) in IR (Collier et al., 1"
W16-6325,D14-1181,0,0.00470024,"Missing"
W16-6325,H05-1026,0,0.0222709,"and syntactic variations of words (Mikolov et al., 2013). The vector initially can be generated randomly or can be pre-trained from the large unlabeled corpus in an unsupervised fashion using external resources such as Wikipedia, news article, bio-medical literature etc. Word embedding is learned through sampling word cooccurrence distribution. These techniques are useful to identify similar words which appear in close vicinity in vector space. There are several ways of generating the word-vectors using different architectures such as word2vec (Mikolov et al., 2013), shallow neural networks (Schwenk and Gauvain, 2005), RNN (Mikolov et al., 2010; Mikolov et al., 2011) etc. We learn our word embedding through three different ways such as random number initialization, RNN’s word embedding and continuous bag-of-words (CBOW) based models. In case Sentence Named Entity De-identified Sentence Discussed O Discussed this O this case O case with O with Dr. O Dr. John Doe B-DOCTOR I-DOCTOR XYZ DOCTOR for O for Mr. O Mr. Ness B-PATIENT XYZ PATIENT Table 1: Sample sentence (sequence of words with the corresponding labels using BIO notation) and its corresponding de-identified sentence of random number initialization, w"
W16-6325,W16-4206,1,0.679779,"al., 2013) as well as named entity recognition (Collobert et al., 2011; Lample et al., 2016). Motivated by the success of deep learning techniques, in this paper, we have adopted in particular Recurrent Neural Network (RNN) (Mikolov et al., 2010) architecture to capture PHI terms. RNN has shown advantages over other machine learning 189 and rule based techniques. RNN unlike other techniques does not require features explicitly developed for the classifier learning. The virtue of system learning by itself makes the system adaptable and scalable. This work is an extension of our previous work (Shweta et al., 2016) where we identified only 7 PHI category (Patient, Doctor, Hospital, Location, Date, Age, ID) irrespective of subcategories using only i2b2-2014 training dataset. The current work provide comprehensive experimentation on i2b2-2014 challenge dataset to deidentify 7 categories and 25 subcategories. We have formulated this task as the sequence labeling problem and developed the baseline model using a supervised machine learning technique. Conditional random field (CRF) (Lafferty et al., 2001) along with a set of handcrafted features are used to build the base classifier. In the current study, we"
W16-6325,N16-1030,0,0.0290698,"rned by other hyperparameters which are initialized randomly or can be pre-trained on large unlabeled corpus. Pretraining is much beneficial in improving performance as it effectively captures the linguistic variations and patterns. Recently, there has been significant success of deep learning techniques in solving various natural language processing tasks such as text classification (Kim, 2014), language modeling (Mikolov et al., 2010), machine translation (Bahdanau et al., 2014), spoken language understanding (Mesnil et al., 2013) as well as named entity recognition (Collobert et al., 2011; Lample et al., 2016). Motivated by the success of deep learning techniques, in this paper, we have adopted in particular Recurrent Neural Network (RNN) (Mikolov et al., 2010) architecture to capture PHI terms. RNN has shown advantages over other machine learning 189 and rule based techniques. RNN unlike other techniques does not require features explicitly developed for the classifier learning. The virtue of system learning by itself makes the system adaptable and scalable. This work is an extension of our previous work (Shweta et al., 2016) where we identified only 7 PHI category (Patient, Doctor, Hospital, Loca"
W16-6325,W00-1308,0,0.0482235,"Missing"
Y10-1015,W09-3539,1,0.799203,"erge only very recently. Named Entity (NE) identification in Indian languages in general and Bengali in particular is more difficult and challenging compared to others due to facts such as: (i). missing of capitalization information, (ii). appearance of NEs in the dictionary with some other specific meanings, (iii). free word order nature of the languages, (iv). resource-constrained environment, i.e. non-availability of corpora, annotated corpora, name dictionaries, good morphological analyzers, part of speech (POS) taggers etc. Some of the recent works related to Bengali NER can be found in (Ekbal and Bandyopadhyay, 2009b; Ekbal and Bandyopadhyay, 2009a; Ekbal and Bandyopadhyay, 2008b). Other works related to Indian language NER are reported in the proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages (NERSSEAL)1. 1 http://ltrc.iiit.ac.in/ner-ssea-08 115 116 Regular Papers The concept of combining classifiers is a very emerging topic in the area of machine learning. The primary goal of classifier ensemble 2 is to improve the performance of the individual classifiers. These classifiers could be based on a variety of classification methodologies, and could achieve different rate"
Y10-1015,W03-0419,0,0.0456897,"Missing"
Y10-1019,W03-2201,0,0.0175481,"Missing"
Y10-1019,W09-3539,1,0.806064,"works related to NER in Indian languages have started to emerge only very recently. Named Entity (NE) identification in Indian languages is more difficult and challenging compared to others due to the lack of capitalization information, appearance of NEs in the dictionary as common nouns, relatively free word order nature of the languages, resource-constrained environment, i.e., non-availability of corpus, annotated corpus, name dictionaries, morphological analyzers, part of speech (POS) taggers etc. Some of the works related to Indian languages can be found in (Ekbal and Bandyopadhyay, 2007; Ekbal and Bandyopadhyay, 2009a; Ekbal and Bandyopadhyay, 2009b) for Bengali, in (Li and McCallum, 2004) for Hindi and in (Shishtla et al., 2008) for Telugu. The performance of any classification technique depends on the features of data sets. Feature selection, also known as variable selection, feature reduction, attribute selection or variable subset selection, is the technique, commonly used in machine learning, of selecting a subset of relevant features for building robust learning models. In a machine learning approach, feature selection is an optimization problem that involves choosing an appropriate feature subset."
Y10-1019,nobata-etal-2002-summarization,0,0.0724756,"Missing"
Y10-1019,I08-1045,0,0.0381548,"Missing"
Y10-1019,I08-5010,0,0.0486624,"Missing"
Y10-1019,I08-5007,0,0.0643303,"Missing"
Y10-1019,W03-0419,0,0.0589383,"Missing"
