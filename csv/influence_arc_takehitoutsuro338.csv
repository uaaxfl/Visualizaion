2008.amta-papers.14,2008.amta-papers.8,1,0.661353,"e Japanese Technical Term “ 応用行動分析” lation table, are incorporated. Experimental evaluation results again show that the SVMs based approach to translation candidates validation can contribute to improving the precision of translation candidates in the phrase translation table. 2 Japanese-English Parallel Patent Documents of the IPC (International Patent Classification) Categories in the whole parallel documents and sentences (about 1.8M sentences in total). 3 Techniques of Generating Translation Candidates 3.1 In the NTCIR-7 workshop, the Japanese-English patent translation task is organized (Fujii et al., 2008), where parallel patent documents and sentences are provided by the organizer. Those parallel patent documents are collected from the 10 years of unexamined Japanese patent applications published by the Japanese Patent Office (JPO) and the 10 years patent grant data published by the U.S. Patent & Trademark Office (USPTO) in 1993-2000. The numbers of documents are approximately 3,500,000 for Japanese and 1,300,000 for English. Because the USPTO documents consist of only patent that have been granted, the number of these documents is smaller than that of the JPO documents. From these document se"
2008.amta-papers.14,P98-1069,0,0.726472,"Missing"
2008.amta-papers.14,H05-1061,0,0.183434,"lingual Lexicon for Human in Semi-Automatic Acquisition of Technical Term Translation Lexicon Yohei Morishita Takehito Utsuro Mikio Yamamoto Graduate School of Systems and Information Engineering University of Tsukuba Tsukuba, 305-8573, JAPAN Abstract parallel sentences (Matsumoto and Utsuro, 2000), translation term pair acquisition from comparable corpora (Fung and Yee, 1998), compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006), and translation term pair acquisition by collecting partially bilingual texts through the search engine (Huang et al., 2005). This paper presents an attempt at developing a technique of acquiring translation pairs of technical terms with sufficiently high precision from parallel patent documents. The approach taken in the proposed technique is based on integrating the phrase translation table of a state-of-the-art statistical phrasebased machine translation model, and compositional translation generation based on an existing bilingual lexicon for human use. Our evaluation results clearly show that the agreement between the two individual techniques definitely contribute to improving precision of translation candida"
2008.amta-papers.14,2007.mtsummit-papers.36,0,0.0693889,"higher F-measure. Differ161 ences between those precisions and the baseline are statistically significant at a level of 0.05. With these improvement in precisions, again we can claim that the approach of applying the SVMs learning technique to the task of validating translation candidates definitely contributes to semi-automatic acquisition of technical term bilingual lexicon. 6 Related Works Among the techniques studied so far in the research area of automatic bilingual lexicon compilation as well as empirical approaches to machine translation such as statistical machine translation models, (Itagaki et al., 2007) is most closely related to the approach taken in this paper. (Itagaki et al., 2007) focused on automatic validation of translation pairs available in the phrase translation table learned by a statistical machine translation model. One of the major differences between (Itagaki et al., 2007) and the approach taken in this paper is that we focus on integrating the phrase translation table with compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006). As we showed in the experimental evaluation, translation knowledge resource of an existing"
2008.amta-papers.14,N03-1017,0,0.009985,"ranked in descending order of their scores. 3.2 Phrase Translation Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moeses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, first, word alignment of par156 allel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase translation table and a phrase translation probability is assigned to each pair (Koehn et al., 2003). We finally obtain 76M translation pairs with 33M unique Japanese phrases, i.e., 2.29 English translations per Japanese phrase on average, with Japanese to English phrase translation probabilities P (pE |pJ ) of translating a Japanese phrase pJ into an English phrase pE . For each Japanese phrase, those multiple translation candidates in the phrase translation table are ranked in descending order of Japanese to English phrase translation probabilities. [8th AMTA conference, Hawaii, 21-25 October 2008] Table 2: Number of Translation Candidates generated by Individual Techniques Individual Tech"
2008.amta-papers.14,P07-2045,0,0.0225912,"ates highly 154 confidently suggested by a statistical technique, but rejecting those suggested with less confidence. Based on such requirement from the organization working on compiling bilingual lexicon of technical terms from parallel patent documents, this paper presents an attempt at developing a technique of acquiring translation pairs of technical terms with sufficiently high precision from parallel patent documents. The approach taken in the proposed technique is based on integrating the phrase translation table of a state-of-the-art statistical phrase-based machine translation model (Koehn et al., 2007), and compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006). In this approach, we first simply evaluate translation candidates in the phrase translation table as well as those generated by compositional translation generation based on an existing bilingual lexicon for human use. We also evaluate agreement between translation candidates from those two individual techniques that are different from each other with respect to their approaches as well as resource used in their approaches. Our evaluation results clearly show that the agreeme"
2008.amta-papers.14,E06-1005,0,0.019882,"tagaki et al., 2007) and the approach taken in this paper is that we focus on integrating the phrase translation table with compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006). As we showed in the experimental evaluation, translation knowledge resource of an existing bilingual lexicon for human use definitely contributes to improving the precision of translation candidates both in the agreement of two or three techniques and in validation by SVMs learning. The system combination approaches to machine translation (Rosti et al., 2007; Matusov et al., 2006) are another related research in a broader perspective. One of the major differences between such system combination approaches to the whole sentence MT and the task focused in this paper is apparently in that we concentrate on application of semi-automatic acquisition of technical term bilingual lexicon, where the primary requirement is precision rather than recall of the acquired translation pairs. 7 Conclusion This paper presented an attempt at developing a technique of acquiring translation pairs of technical terms with sufficiently high precision from parallel patent documents. The approa"
2008.amta-papers.14,J03-1002,0,0.00349486,"on pairs in the bilingual constituent lexicons. Then, the score of the concatenated translation candidates is calculated as the product of the scores of their constituents. When more than one translation candidates are generated as in the case of Figure 1, they are ranked in descending order of their scores. 3.2 Phrase Translation Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moeses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, first, word alignment of par156 allel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase translation table and a phrase translation probability is assigned to each pair (Koehn et al., 2003). We finally obtain 76M translation pairs with 33M unique Japanese phrases, i.e., 2.29 English translations per Japanese phrase on average, with Japanese to English phrase translation probabilities P (pE |pJ ) of translating a Japanese phrase pJ into an English phrase pE . For each Japanese phrase, those multiple translation candid"
2008.amta-papers.14,P07-1040,0,0.0142445,"fferences between (Itagaki et al., 2007) and the approach taken in this paper is that we focus on integrating the phrase translation table with compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006). As we showed in the experimental evaluation, translation knowledge resource of an existing bilingual lexicon for human use definitely contributes to improving the precision of translation candidates both in the agreement of two or three techniques and in validation by SVMs learning. The system combination approaches to machine translation (Rosti et al., 2007; Matusov et al., 2006) are another related research in a broader perspective. One of the major differences between such system combination approaches to the whole sentence MT and the task focused in this paper is apparently in that we concentrate on application of semi-automatic acquisition of technical term bilingual lexicon, where the primary requirement is precision rather than recall of the acquired translation pairs. 7 Conclusion This paper presented an attempt at developing a technique of acquiring translation pairs of technical terms with sufficiently high precision from parallel paten"
2008.amta-papers.14,W06-1703,1,0.741184,". Based on such requirement from the organization working on compiling bilingual lexicon of technical terms from parallel patent documents, this paper presents an attempt at developing a technique of acquiring translation pairs of technical terms with sufficiently high precision from parallel patent documents. The approach taken in the proposed technique is based on integrating the phrase translation table of a state-of-the-art statistical phrase-based machine translation model (Koehn et al., 2007), and compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006). In this approach, we first simply evaluate translation candidates in the phrase translation table as well as those generated by compositional translation generation based on an existing bilingual lexicon for human use. We also evaluate agreement between translation candidates from those two individual techniques that are different from each other with respect to their approaches as well as resource used in their approaches. Our evaluation results clearly show that the agreement between the two individual techniques definitely contribute to improving precision of translation candidates. We th"
2008.amta-papers.14,2007.mtsummit-papers.63,0,0.305897,"U.S. Patent & Trademark Office (USPTO) in 1993-2000. The numbers of documents are approximately 3,500,000 for Japanese and 1,300,000 for English. Because the USPTO documents consist of only patent that have been granted, the number of these documents is smaller than that of the JPO documents. From these document sets, patent families are automatically extracted and the fields of “Background of the Invention” and “Detailed Description of the Preferred Embodiments” are selected. This is because the text of those fields is usually translated on a sentence-by-sentence basis. Then, the method of (Utiyama and Isahara, 2007) is applied to the text of those fields, and Japanese and English sentences are aligned. Table 1 shows the distribution 155 3.1.1 Techniques based on a Bilingual Lexicon for Human Use A Bilingual Lexicon: Eijiro As an existing Japanese-English translation lexicon for human use, we use Eijiro (http://www. eijiro.jp/, Ver.79, with 1.6M translation pairs. ). 3.1.2 Compositional Translation Generation In compositional translation generation (Tonoike et al., 2006), translation candidates of a term are compositionally generated by concatenating the translation of the constituents of the term. Here,"
2008.amta-papers.14,C98-1066,0,\N,Missing
2008.amta-papers.8,fujii-etal-2006-test,1,0.857007,"e machine translation systems. Our test collection also includes search topics for cross-lingual patent retrieval, which can be used to evaluate the contribution of machine translation to retrieving patent documents across languages. This paper describes our test collection, methods for evaluating machine translation, and preliminary experiments. 1 Introduction Since the Third NTCIR Workshop in 20011 , which was an evaluation forum for research and development in information retrieval and natural language processing, the Patent Retrieval Task has been performed repeatedly (Fujii et al., 2004; Fujii et al., 2006; Fujii et al., 2007b; Iwayama et al., 2006). In the Sixth NTCIR Workshop (Fujii et al., 2007b), patent documents published over a 10-year period by the Japanese Patent Office (JPO) and the US Patent & Trademark Office (USPTO) were independently used as target document collections. 1 Having explored patent retrieval issues for a long time, we decided to address another issue in patent processing. From among a number of research issues related to patent processing (Fujii et al., 2007a), we selected Machine Translation (MT) of patent documents, which is useful for a number of applications and se"
2008.amta-papers.8,2001.mtsummit-papers.30,1,0.541065,"cations in foreign countries. Reflecting the rapid growth in the use of multilingual corpora, a number of data-driven MT methods have recently been explored, most of which are termed “Statistical Machine Translation (SMT)”. While large bilingual corpora for European languages, Arabic, and Chinese are available for research and development purposes, these corpora are rarely associated with Japanese and therefore it is difficult for explore SMT with respect to Japanese. However, we found that the patent documents used for the NTCIR Workshops can potentially alleviate this data scarcity problem. Higuchi et al. (2001) used “patent families” as a parallel corpus for extracting new translations. A patent family is a set of patent documents for the same or related inventions and these documents are usually filed in more than one country in various languages. Following Higuchi et al’s method, we can produce a bilingual corpus for Japanese and English. In addition, there are a number of SMT engines (decoders) available to the public, such as Pharaoh and Moses2 , which can be applied to bilingual corpora involving any pair of languages. Motivated by the above background, we de2 http://research.nii.ac.jp/ntcir/in"
2008.amta-papers.8,W04-3250,0,0.13242,"Missing"
2008.amta-papers.8,P02-1040,0,0.0861881,"train their MT system, whether it is a data-driven SMT or a conventional knowledge-intensive rule-based MT. Second, the organizers provide the groups with a test data set of sentences in either Japanese or English. Each group is requested to machine translate each sentence from its original language into the other language and submit their translation results to the organizers. Third, the organizers evaluate the submission from each group. We use both intrinsic and extrinsic evaluation methods. In the intrinsic evaluation, we independently use both the Bilingual Evaluation Understudy (BLEU) (Papineni et al., 2002), which was proposed as an automatic evaluation measure for MT, and human judgment. In the extrinsic evaluation, we investigate the contribution of the MT to CLPR. In the Patent Retrieval Task at NTCIR5, aimed at CLPR, search topics in Japanese were translated into English by human experts. We reuse these search topics for the evaluation of the MT. We also analyze the relationship between different evaluation measures. The use of extrinsic evaluation, which is not performed in existing MT-related evaluation activities, such as the NIST MetricsMATR Challenge3 and the IWSLT Workshop4 , is a dist"
2008.amta-papers.8,2007.mtsummit-papers.63,1,0.907449,"Missing"
2009.mtsummit-wpt.1,fujii-etal-2006-test,1,0.835438,"blem. Higuchi et al. (2001) used “patent families” as a parallel corpus for extracting translations. A patent family is a set of patent documents for the same or related inventions and -1- We used both intrinsic and extrinsic evaluation methods. In the intrinsic evaluation, we used both the Bilingual Evaluation Understudy (BLEU) (Papineni et al., 2002), which had been proposed as an automatic evaluation measure for MT, and human judgment. In the extrinsic evaluation, we evaluated the contribution of the MT to Cross-Lingual Information Retrieval (CLIR). In the Patent Retrieval Task at NTCIR-5 (Fujii et al., 2006), aimed at CLIR, search topics in Japanese were translated into English by human experts. We reused these search topics for the evaluation of the MT. We analyzed the relationship between different evaluation measures. The use of extrinsic evaluation, which is not performed in existing MT-related evaluation activities, such as the NIST MetricsMATR Challenge1 and the IWSLT Workshop2 , is a distinctive feature of our research. We executed a preliminary trial and the final evaluation, using the terms “dry run” and “formal run”, respectively. This paper describes only the formal run. 1 2 http://www"
2009.mtsummit-wpt.1,2001.mtsummit-papers.30,1,0.650448,"ation, Patent information, Cross-lingual information retrieval 1 Introduction Reflecting the rapid growth in the use of multilingual corpora, a number of data-driven Machine Translation (MT) methods have recently been explored, most of which are termed “Statistical Machine Translation (SMT)”. While large bilingual corpora for European languages, Arabic, and Chinese are available for research and development purposes, these corpora are rarely associated with Japanese and it is difficult to explore SMT with respect to Japanese. However, patent documents can alleviate this data scarcity problem. Higuchi et al. (2001) used “patent families” as a parallel corpus for extracting translations. A patent family is a set of patent documents for the same or related inventions and -1- We used both intrinsic and extrinsic evaluation methods. In the intrinsic evaluation, we used both the Bilingual Evaluation Understudy (BLEU) (Papineni et al., 2002), which had been proposed as an automatic evaluation measure for MT, and human judgment. In the extrinsic evaluation, we evaluated the contribution of the MT to Cross-Lingual Information Retrieval (CLIR). In the Patent Retrieval Task at NTCIR-5 (Fujii et al., 2006), aimed"
2009.mtsummit-wpt.1,W06-3114,0,0.0263028,"rinsic evaluation. ever, because the reference translations for MRB300 are independent of the counterpart sentences in the training data set, unlike RBMT systems, these SMT systems did not perform effectively. Figure 4 graphs the value for “Human” in Table 2, in which the order of groups is the same as Figures 1–3. In Figure 4, tsbmt and JAPIO, which were not effective in SRB, outperformed the other groups with respect to human rating. BLEU is generally suitable for comparing the effectiveness of SMT methods, but not suitable for evaluating other types of methods (Callison-Burch et al., 2006; Koehn and Monz, 2006). Figures 5 and 6 graph the value for adequacy and fluency, respectively. Although the relative superiority of the groups was almost the same in Figures 5 and 6, differences of the groups are more noticeable in Figure 5. To further analyze this tendency, Figure 7 shows -6- Figure 5: Adequacy for J–E intrinsic evaluation. Figure 6: Fluency for J–E intrinsic evaluation. Table 3: Results of E–J int/ext evaluation. Figure 7: Relationship between BLEU and human rating for J–E intrinsic evaluation. the correlation coefficient (“R”) between human rating and each BLEU type. The value of R for SRB is 0"
2009.mtsummit-wpt.1,P07-2045,0,0.0055351,"Missing"
2009.mtsummit-wpt.1,W04-3250,0,0.139508,"Missing"
2009.mtsummit-wpt.1,N03-2021,0,0.0130034,"E–J int/ext evaluation. Figure 7: Relationship between BLEU and human rating for J–E intrinsic evaluation. the correlation coefficient (“R”) between human rating and each BLEU type. The value of R for SRB is 0.814, which is smaller than those for MRB300 and MRB600. This is mainly due to the two outliers on the right side that correspond to the results for tsbmt and JAPIO. However, the values of R for MRB300 and MRB600 are more than 0.9, showing a high correlation between human rating and BLEU. By using multiple references, the evaluation result by BLEU became similar to that by human rating (Melamed et al., 2003). In such a case, while human judgments are not reusable, we need only reference translations, which are reusable, for evaluating MT methods. We also calculated the values of R for each BLEU type in terms of adequacy and fluency although these values are not shown in Figure 7. For adequacy, the values of R for SRB, MRB300, and MRB600 were 0.733, 0.846, and 0.887, respectively. For fluency, the values of R for SRB, MRB300, and MRB600 were 0.864, 0.940, and 0.951, respectively. This implies that BLEU is highly correlated with fluency more than adequacy. 4.3 E–J Intrinsic Evaluation Table 3 shows"
2009.mtsummit-wpt.1,P02-1040,0,0.079534,"r European languages, Arabic, and Chinese are available for research and development purposes, these corpora are rarely associated with Japanese and it is difficult to explore SMT with respect to Japanese. However, patent documents can alleviate this data scarcity problem. Higuchi et al. (2001) used “patent families” as a parallel corpus for extracting translations. A patent family is a set of patent documents for the same or related inventions and -1- We used both intrinsic and extrinsic evaluation methods. In the intrinsic evaluation, we used both the Bilingual Evaluation Understudy (BLEU) (Papineni et al., 2002), which had been proposed as an automatic evaluation measure for MT, and human judgment. In the extrinsic evaluation, we evaluated the contribution of the MT to Cross-Lingual Information Retrieval (CLIR). In the Patent Retrieval Task at NTCIR-5 (Fujii et al., 2006), aimed at CLIR, search topics in Japanese were translated into English by human experts. We reused these search topics for the evaluation of the MT. We analyzed the relationship between different evaluation measures. The use of extrinsic evaluation, which is not performed in existing MT-related evaluation activities, such as the NIS"
2009.mtsummit-wpt.1,2007.mtsummit-papers.63,1,0.867471,"Missing"
2011.mtsummit-wpt.10,N03-1017,0,0.00497411,"nglish parallel sentences is about 1.8M in total. 4.2 Phrase Translation Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, ﬁrst, word alignment of parallel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase translation table and a phrase translation probability is assigned to each pair (Koehn et al., 2003). We ﬁnally obtain 76M translation pairs with 33M unique Japanese phrases, i.e., 2.29 English translations per Japanese phrase on average, with Japanese to English phrase translation probabilities P (pE |pJ ) of translating a Japanese phrase pJ into an English phrase pE . For each Japanese phrase, those multiple translation candidates in the phrase translation table are ranked in descending order of Japanese to English phrase translation probabilities. 4.3 The Procedure of Developing A Translation Example Database per Semantic Equivalence Class Given the phrase translation tables trained with"
2011.mtsummit-wpt.10,P07-2045,0,0.0933056,"us or not. We realized this procedure by manually examining whether functional expressions within a class can be translated into a single canonical English expression. Then, we proposed how to extract rules for translating functional expressions in Japanese patent documents into English. Here, we used about 1.8M Japanese-English parallel sentences automatically extracted from Japanese-English patent families, which are distributed through the Patent Translation Task at the NTCIR-7 Workshop (Fujii et al., 2008). As a toolkit of a phrase-based SMT (Statistical Machine Translation) model, Moses (Koehn et al., 2007) was applied and Japanese-English translation pairs were obtained in the form of a phrase translation table. Finally, we extracted translation 91 Proceedings of the 4th Workshop on Patent Translation, pages 91-103, MT Summit XIII, Xiamen, China, September 2011 Figure 2: A Part of the Hierarchy of Semantic Equivalence Classes Figure 1: A Part of the Hierarchical Lexicon of Japanese Functional Expressions pairs of Japanese functional expressions from the phrase translation table. Unlike Sakamoto et al. (2009) and Nagasaka et al. (2010), in this paper, in order to address the issue of resolving v"
2011.mtsummit-wpt.10,I08-2094,1,0.850738,"he lexicon compiled by Matsuyoshi et al. (2006) also has a hierarchy of semantic equivalence classes introduced from the viewpoint of paraphrasability. This semantic hierarchy has three abstraction levels, where 435 entries in L2 (headwords with a unique sense) of the hierarchy of surface forms are organized into the top 45 semantic equivalence classes, the middle 128 classes, and the 199 bottom classes. Figure 2 shows examples of the bottom 199 classes, where each of the leaf labels “B13”, “B31”, “B32”, “C11”, . . ., “d11”, “d12”, “d13”, . . . represents a label of the bottom 199 classes. In Matsuyoshi and Sato (2008), the bottom 199 semantic equivalence classes of Japanese functional expressions are designed so that functional expressions within a class are paraphrasable in most contexts of Japanese texts. 3 Ambiguities of A Compound Expression One of the key issues of this paper is whether each compound expression to be translated into English is monosemous or not. Unless each compound expression is monosemous, it is necessary to apply certain disambiguation techniques before translating it into English. Before we discuss how to consider ambiguities of compound expressions in the process of machine trans"
2011.mtsummit-wpt.10,nagasaka-etal-2010-utilizing,1,0.355729,"Missing"
2011.mtsummit-wpt.10,J03-1002,0,0.00295217,"cted. This is because the text of those ﬁelds is usually translated on a sentence-by-sentence basis. Then, the method of Utiyama and Isahara (2007) is applied to the text of those ﬁelds, and Japanese and English sentences are 95 aligned. The number of Japanese and English parallel sentences is about 1.8M in total. 4.2 Phrase Translation Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, ﬁrst, word alignment of parallel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase translation table and a phrase translation probability is assigned to each pair (Koehn et al., 2003). We ﬁnally obtain 76M translation pairs with 33M unique Japanese phrases, i.e., 2.29 English translations per Japanese phrase on average, with Japanese to English phrase translation probabilities P (pE |pJ ) of translating a Japanese phrase pJ into an English phrase pE . For each Japanese phrase, those multiple translation candida"
2011.mtsummit-wpt.10,Y09-2044,1,0.688151,"expressions are also problematic in further applications such as machine translation of Japanese sentences into English. This problem can be partially recognized by the fact that the Japanese language has a large number of variants of functional expressions, where their total number is recently counted as over 10,000 in Matsuyoshi et al. (2006). Based on those recent development in studies on lexicon for processing Japanese functional expressions (Matsuyoshi et al., 2006), this paper studies issues on machine translation of Japanese functional expressions into English. In our previous works, Sakamoto et al. (2009) and Nagasaka et al. (2010) applied the “Sandglass” machine translation architecture (Yamamoto, 2002) to the task of translating Japanese functional expressions into English. In the “Sandglass” MT architecture, variant expressions in the source language are ﬁrst paraphrased into representative expressions, and then, a small number of translation rules are applied to the representative expressions. In Sakamoto et al. (2009) and Nagasaka et al. (2010), we introduced the recently compiled large scale hierarchical lexicon of Japanese functional expressions (Matsuyoshi et al., 2006). We employed th"
2011.mtsummit-wpt.10,W04-0405,0,0.159242,"lected as the most similar translation example. On the other hand, Moses selects a phrase translation table entry with a compound expression “ばかり (bakari) で (de) な く (naku)” that is longer than the one the proposed 100 method selects, and with translation into English as “but also”. The Japanese sentence is a typical example of a functional usage of the compound expression “ばかり (bakari) で (de) なく (naku)”, and only the translation by Moses is judged as correct. 7 Related Works Ambiguities of functional/content usages has been well studied in Tsuchiya et al. (2005), Tsuchiya et al. (2006), and (Shudo et al., 2004). Tsuchiya et al. (2005) reported that, out of about 180 compound expressions which are frequently observed in the newspaper text, one third (about 60 expressions) have this type of ambiguity. Next, Tsuchiya et al. (2006) formalized the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem. The proposed technique performed reasonably well, while its major drawback is in its scale. So far, the proposed technique has not yet been applied to the whole list of over 10,000 Japanese functional exTable 9: An Example where the Proposed Meth"
2011.mtsummit-wpt.10,W06-2404,1,0.854247,"into English as “about” is selected as the most similar translation example. On the other hand, Moses selects a phrase translation table entry with a compound expression “ばかり (bakari) で (de) な く (naku)” that is longer than the one the proposed 100 method selects, and with translation into English as “but also”. The Japanese sentence is a typical example of a functional usage of the compound expression “ばかり (bakari) で (de) なく (naku)”, and only the translation by Moses is judged as correct. 7 Related Works Ambiguities of functional/content usages has been well studied in Tsuchiya et al. (2005), Tsuchiya et al. (2006), and (Shudo et al., 2004). Tsuchiya et al. (2005) reported that, out of about 180 compound expressions which are frequently observed in the newspaper text, one third (about 60 expressions) have this type of ambiguity. Next, Tsuchiya et al. (2006) formalized the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem. The proposed technique performed reasonably well, while its major drawback is in its scale. So far, the proposed technique has not yet been applied to the whole list of over 10,000 Japanese functional exTable 9: An Examp"
2011.mtsummit-wpt.10,2007.mtsummit-papers.63,0,0.0407958,"the U.S. Patent & Trademark Ofﬁce (USPTO) in 1993-2000. The numbers of documents are approximately 3,500,000 for Japanese and 1,300,000 for English. Because the USPTO documents consist of only patent that have been granted, the number of these documents is smaller than that of the JPO documents. From these document sets, patent families are automatically extracted and the ﬁelds of “Background of the Invention” and “Detailed Description of the Preferred Embodiments” are selected. This is because the text of those ﬁelds is usually translated on a sentence-by-sentence basis. Then, the method of Utiyama and Isahara (2007) is applied to the text of those ﬁelds, and Japanese and English sentences are 95 aligned. The number of Japanese and English parallel sentences is about 1.8M in total. 4.2 Phrase Translation Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, ﬁrst, word alignment of parallel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word a"
2011.mtsummit-wpt.10,W07-1109,1,0.704182,"Simc + Simsuf = 3.0 In addition, a channel of the performance data is changed, as a result of play tones are sounded, nothing is not changed (which channel is used both for the designated tone color, etc. to be sounded tone generation is performed by the information may be affected to playing is embedded is very advantageous does not occur at all. pressions. (Shudo et al., 2004) also studied applying manually created rules to the task of resolving functional/content ambiguities, where their approach has limitation in that it requires human cost to create manually and to maintain those rules. Utsuro et al. (2007) and (Nivre and Nilsson, 2004) studied syntactic analysis of functional expressions in sentences. Utsuro et al. (2007) studied how to incorporate the process of analyzing compound noncompositional functional expressions into the framework of Japanese statistical dependency parsing. (Nivre and Nilsson, 2004) also reported improvement of Swedish parsing when multi word units are 101 manually annotated. 8 Concluding Remarks This paper studied issues on machine translation of Japanese functional expressions into English. Unlike our previous works, in order to address the issue of resolving various"
2011.mtsummit-wpt.10,C02-1163,0,0.038127,"into English. This problem can be partially recognized by the fact that the Japanese language has a large number of variants of functional expressions, where their total number is recently counted as over 10,000 in Matsuyoshi et al. (2006). Based on those recent development in studies on lexicon for processing Japanese functional expressions (Matsuyoshi et al., 2006), this paper studies issues on machine translation of Japanese functional expressions into English. In our previous works, Sakamoto et al. (2009) and Nagasaka et al. (2010) applied the “Sandglass” machine translation architecture (Yamamoto, 2002) to the task of translating Japanese functional expressions into English. In the “Sandglass” MT architecture, variant expressions in the source language are ﬁrst paraphrased into representative expressions, and then, a small number of translation rules are applied to the representative expressions. In Sakamoto et al. (2009) and Nagasaka et al. (2010), we introduced the recently compiled large scale hierarchical lexicon of Japanese functional expressions (Matsuyoshi et al., 2006). We employed the semantic equivalence classes of the lexicon and examined each class whether it is monosemous or not"
2013.mtsummit-wpt.2,P98-1069,0,0.259568,"Missing"
2013.mtsummit-wpt.2,H05-1061,0,0.0866477,"Missing"
2013.mtsummit-wpt.2,P07-2045,0,0.0137888,"Missing"
2013.mtsummit-wpt.2,N03-1017,0,0.0282478,"Missing"
2013.mtsummit-wpt.2,Y11-1021,1,0.607898,"Missing"
2013.mtsummit-wpt.2,Y09-2038,0,0.0371089,"Missing"
2013.mtsummit-wpt.2,2008.amta-papers.14,1,0.642218,"Missing"
2013.mtsummit-wpt.2,J03-1002,0,0.0110349,"Missing"
2013.mtsummit-wpt.2,W06-1703,1,0.818206,"Missing"
2013.mtsummit-wpt.2,2007.mtsummit-papers.63,0,0.0559398,"Missing"
2015.mtsummit-wpslt.9,P13-2133,0,0.0198779,"Missing"
2015.mtsummit-wpslt.9,P98-1069,0,0.212135,"Missing"
2015.mtsummit-wpslt.9,W14-4806,0,0.0445517,"Missing"
2015.mtsummit-wpslt.9,H05-1061,0,0.0986113,"Missing"
2015.mtsummit-wpslt.9,2007.mtsummit-papers.36,0,0.0671061,"Missing"
2015.mtsummit-wpslt.9,P07-2045,0,0.0040579,"Missing"
2015.mtsummit-wpslt.9,P08-1113,0,0.0700496,"Missing"
2015.mtsummit-wpslt.9,Y09-2038,0,0.0485123,"Missing"
2015.mtsummit-wpslt.9,P14-1121,0,0.0251573,"Missing"
2015.mtsummit-wpslt.9,2008.amta-papers.14,1,0.773429,"Missing"
2015.mtsummit-wpslt.9,W06-1703,1,0.833726,"Missing"
2015.mtsummit-wpslt.9,2007.mtsummit-papers.63,0,0.1084,"Missing"
2015.mtsummit-wpslt.9,W06-1629,0,0.0613358,"Missing"
2020.aacl-srw.21,P18-2124,0,0.0477946,"Missing"
2020.aacl-srw.21,D15-1075,0,0.0219327,"examples to be the same. The set M is also intended to directly compare the effectiveness of the “hard to answer” and SQuAD1.1 training examples by restricting the numbers of training examples to be the same. All these sets are used to ﬁne-tune the BERT pre-trained model on the MRC task, and the development set of SQuAD1.1 6 We repeat the splitting procedure and the evaluation procedure ten times, where we have almost the same evaluation results we report in this section. 7 https://github.com/facebookresearch/ SpanBERT 8 https://github.com/zihangdai/xlnet 150 tual Entailment” datasets, SICK (Bowman et al., 2015) and SNLI (Marelli et al., 2014). Tsuchiya reported that the cases of SNLI had the correct textual entailment labels predicted when only the hypothesis sentence was provided and without the premise sentence. However, Tsuchiya (2018) also pointed out that, a hidden bias in the SNLI corpus caused much of the high accuracy achieved by the neural network based models that were trained with SNLI. Developing machine reading comprehension datasets requires an expensive and timeconsuming effort to manually create questions from paragraphs and extract spans of text from each paragraph to represent the"
2020.aacl-srw.21,N19-1423,0,0.333891,"h questions and contexts are essential. Moreover, Kaushik and Lipton (2018) also claimed that follow-up papers reporting improvements ought to report performance both on the full task and variations omitting questions and contexts. In view of the point demonstrated in Kaushik and Lipton (2018), we concentrate more on the difﬁculty of every single MRC example, and aim to split the examples into easy ones and hard ones. Given the MRC dataset SQuAD1.1 (where each MRC example denoted as the tuple ⟨Q, C, A⟩ of the question Q, the context C, and the answer A) and the ﬁne-tuned MRC model using BERT (Devlin et al., 2019), there exist contextonly examples that can be correctly answered, where only the context is provided without including the question. By focusing on this fact, this paper proposes a method that splits the MRC examples into binary classes of “easy to answer” or “hard to answer”. A 10-fold cross-validation was applied on approximately 87,600 SQuAD1.1 training examples comprised of 12,500 “easy to answer” and 75,000 “hard to answer” classes. From the comparison of the two classes, the followings are two signiﬁcant ﬁndings. (1) Based Models developed for Machine Reading Comprehension (MRC) are ask"
2020.aacl-srw.21,D18-1453,0,0.0182438,"ference and sentence-level machine reading comprehension. It is concluded that ambiguous instances are useful for high performance, easy to learn instances are aid optimization, and hard to learn instances correspond to data errors. Following the conclusions of Swayamdipta et al. (2020), our future work include applying the framework of Swayamdipta et al. (2020) to the tasks of machine reading comprehension studied in this paper and investigating the difference of our notion of “easy to answer” / “hard to answer” and their notion of “easy to learn” / “hard to learn.” Among other related work, Sugawara et al. (2018) studied splitting 12 MRC datasets into easy and hard subsets according to two types of simple lexical based heuristics and showed that the performance against easy subsets were lower than the whole datasets. Min et al. (2018) also studied to select minimal set of sentences within the context of existing MRC datasets to answer the MRC question. In the task of recognizing textual entailment that classiﬁes the relation between a pair of two sentence as a premise and hypothesis, Tsuchiya (2018) compared two of the “Recognizing Tex8 Conclusion We proposed a method based on BERT (Devlin et al., 201"
2020.aacl-srw.21,D17-1063,0,0.0285977,"on. The approach of active learning, in which the key idea is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns (Settles, 1995, 2010), could be applied to reduce the cost of developing MRC datasets. While there exists no previous study that applies the active learning technique for machine reading comprehension task, other work applied the technique to reduce the cost of developing datasets for other NLP tasks (Sener and Savarese, 2018; Chen et al., 2019), image classiﬁcation (Beluch et al., 2018; Fang et al., 2017), as well as other machine learning tasks, such as predicting molecular energetics in the ﬁeld of chemistry (Smith et al., 2018). Figure 7: Comparison of the Learning Curves for the Exact Match (EM) (1) the model trained with “hard to answer” examples outperformed that trained with “easy to answer” ones, and (2) answers from the “easy to answer” MRC example class tend to be located around the beginning of the context compared with those from the “hard to answer” MRC example class. 7 Related Work Swayamdipta et al. (2020) proposed a general framework of identifying three regions, namely, ambigu"
2020.aacl-srw.21,2020.emnlp-main.746,0,0.0163233,"nd Savarese, 2018; Chen et al., 2019), image classiﬁcation (Beluch et al., 2018; Fang et al., 2017), as well as other machine learning tasks, such as predicting molecular energetics in the ﬁeld of chemistry (Smith et al., 2018). Figure 7: Comparison of the Learning Curves for the Exact Match (EM) (1) the model trained with “hard to answer” examples outperformed that trained with “easy to answer” ones, and (2) answers from the “easy to answer” MRC example class tend to be located around the beginning of the context compared with those from the “hard to answer” MRC example class. 7 Related Work Swayamdipta et al. (2020) proposed a general framework of identifying three regions, namely, ambiguous, easy to learn, and hard to learn within a dataset, and applied the framework to several tasks such as natural language inference and sentence-level machine reading comprehension. It is concluded that ambiguous instances are useful for high performance, easy to learn instances are aid optimization, and hard to learn instances correspond to data errors. Following the conclusions of Swayamdipta et al. (2020), our future work include applying the framework of Swayamdipta et al. (2020) to the tasks of machine reading com"
2020.aacl-srw.21,L18-1239,0,0.0619891,"ﬁne-tune the BERT pre-trained model on the MRC task, and the development set of SQuAD1.1 6 We repeat the splitting procedure and the evaluation procedure ten times, where we have almost the same evaluation results we report in this section. 7 https://github.com/facebookresearch/ SpanBERT 8 https://github.com/zihangdai/xlnet 150 tual Entailment” datasets, SICK (Bowman et al., 2015) and SNLI (Marelli et al., 2014). Tsuchiya reported that the cases of SNLI had the correct textual entailment labels predicted when only the hypothesis sentence was provided and without the premise sentence. However, Tsuchiya (2018) also pointed out that, a hidden bias in the SNLI corpus caused much of the high accuracy achieved by the neural network based models that were trained with SNLI. Developing machine reading comprehension datasets requires an expensive and timeconsuming effort to manually create questions from paragraphs and extract spans of text from each paragraph to represent the answer to each question. The approach of active learning, in which the key idea is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns (S"
2020.aacl-srw.21,2020.tacl-1.5,0,0.0163354,"statistically signiﬁcant (p&lt;0.01) difference, suggesting that the “hard to answer” examples are effective in MRC model training6 . Unfortunately, however, Figure 6 also presents that the performance of Hsml is almost comparable with that of Msml . From this result, our deﬁnite future work includes inventing a technique of automatic selection of MRC training examples from the set U of the complete SQuAD1.1 training example set, which outperform those of the same size randomly sampled from U . Also, although we omit the detailed evaluation results, in addition to BERT, we also applied SpanBERT (Joshi et al., 2020)7 (base & cased) and XLNet (Yang et al., 2019)8 (XLNet-Large, Cased) and obtained the similar results regarding both of Figure 5: Two Sample “Easy to Answer” MRC Examples Training set U : training set of SQuAD1.1 H: “hard to answer” examples M : examples randomly sampled from U E: “easy to answer” examples Hsml : examples randomly sampled from H Msml : examples randomly sampled from U Number of examples 87,599 75,112 12,487 Table 2: Number of Examples in Each Training Set on the performance of each class when used for the MRC model training. The sets shown in Table 2 are evaluated as the MRC m"
2020.aacl-srw.21,D18-1546,0,0.019178,"corresponding natural language answer when provided a question and its related context. In recent years, MRC models using neural networks have been proposed for SQuAD (Pranav et al., 2016, 2018), which is a large-scale, high-quality English MRC dataset. Most recent neural network based MRC models have outperformed human performance (Devlin et al., 2019). Among those existing work, to analyze the difﬁculty of several popular MRC benchmarks such as bAbI (Weston et al., 2016), SQuAD (Pranav et al., 2016), CBT (Hill et al., 2016), CNN (Hermann et al., 2015) and Who-didWhat (Onishi et al., 2016), Kaushik and Lipton (2018) established sensible baselines for these 146 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop, pages 146–152 c December 4 - 7, 2020. 2020 Association for Computational Linguistics Figure 2: Detecting MRC Examples as Answerable without an Input Question Figure 1: An MRC Model using Neural Networks on the performance of training the BERT MRC models with 12,500 “easy to answer” and “hard to answer” examples each, the model trained wit"
2020.aacl-srw.21,marelli-etal-2014-sick,0,0.0336917,"et M is also intended to directly compare the effectiveness of the “hard to answer” and SQuAD1.1 training examples by restricting the numbers of training examples to be the same. All these sets are used to ﬁne-tune the BERT pre-trained model on the MRC task, and the development set of SQuAD1.1 6 We repeat the splitting procedure and the evaluation procedure ten times, where we have almost the same evaluation results we report in this section. 7 https://github.com/facebookresearch/ SpanBERT 8 https://github.com/zihangdai/xlnet 150 tual Entailment” datasets, SICK (Bowman et al., 2015) and SNLI (Marelli et al., 2014). Tsuchiya reported that the cases of SNLI had the correct textual entailment labels predicted when only the hypothesis sentence was provided and without the premise sentence. However, Tsuchiya (2018) also pointed out that, a hidden bias in the SNLI corpus caused much of the high accuracy achieved by the neural network based models that were trained with SNLI. Developing machine reading comprehension datasets requires an expensive and timeconsuming effort to manually create questions from paragraphs and extract spans of text from each paragraph to represent the answer to each question. The app"
2020.aacl-srw.21,P18-1160,0,0.0190867,". Following the conclusions of Swayamdipta et al. (2020), our future work include applying the framework of Swayamdipta et al. (2020) to the tasks of machine reading comprehension studied in this paper and investigating the difference of our notion of “easy to answer” / “hard to answer” and their notion of “easy to learn” / “hard to learn.” Among other related work, Sugawara et al. (2018) studied splitting 12 MRC datasets into easy and hard subsets according to two types of simple lexical based heuristics and showed that the performance against easy subsets were lower than the whole datasets. Min et al. (2018) also studied to select minimal set of sentences within the context of existing MRC datasets to answer the MRC question. In the task of recognizing textual entailment that classiﬁes the relation between a pair of two sentence as a premise and hypothesis, Tsuchiya (2018) compared two of the “Recognizing Tex8 Conclusion We proposed a method based on BERT (Devlin et al., 2019) that splits the training examples from the MRC dataset SQuAD1.1 into classes of “easy to answer” and “hard to answer.” Experimental evaluations of comparing the two models, one of which is trained only with the “easy to ans"
2020.aacl-srw.21,D16-1241,0,0.0227451,"task locates the best corresponding natural language answer when provided a question and its related context. In recent years, MRC models using neural networks have been proposed for SQuAD (Pranav et al., 2016, 2018), which is a large-scale, high-quality English MRC dataset. Most recent neural network based MRC models have outperformed human performance (Devlin et al., 2019). Among those existing work, to analyze the difﬁculty of several popular MRC benchmarks such as bAbI (Weston et al., 2016), SQuAD (Pranav et al., 2016), CBT (Hill et al., 2016), CNN (Hermann et al., 2015) and Who-didWhat (Onishi et al., 2016), Kaushik and Lipton (2018) established sensible baselines for these 146 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop, pages 146–152 c December 4 - 7, 2020. 2020 Association for Computational Linguistics Figure 2: Detecting MRC Examples as Answerable without an Input Question Figure 1: An MRC Model using Neural Networks on the performance of training the BERT MRC models with 12,500 “easy to answer” and “hard to answer” examples"
2020.aacl-srw.21,D16-1264,0,0.116661,"Missing"
2020.fever-1.4,P17-1171,0,0.0499877,"Missing"
2020.fever-1.4,L18-1431,0,0.0768038,"Missing"
2020.fever-1.4,N19-1423,0,0.0355684,"tatistics of training and test datasets Before applying BERT modules, MeCab8 was applied with IPAdic dictionary, and the Japanese text was segmented into a morpheme sequence. Then, within the BERT fine-tuning module, the WordPiece module with 110k shared WordPiece vocabulary was applied, and the Japanese text was further segmented into a subword unit sequence. Finally, the BERT fine-tuning module for machine comprehension9 was applied as well as the finetuned model. The BERT pre-trained model was fine-tuned with the following three types of train5.2 BERT Implementation As the version of BERT (Devlin et al., 2019) implementation which can handle a text in Japanese, the TensorFlow version6 and the Multilingual Cased model7 were used as the pre-trained model. tators, and ii) manually judging whether the answers selected by two out of three annotators are semantically equivalent when exactly the same pair of a question and a context is given to the three annotators (their detailed procedures are omitted for space restriction). Average of AC1 is 0.61 for the sub-procedure i) and 0.92 for the sub-procedure ii), which are sufficiently high. 8 6 http://taku910.github.io/mecab/ (in https://github.com/google-re"
2020.fever-1.4,W18-2605,0,0.0313922,"Missing"
2020.fever-1.4,Q18-1023,0,0.0533652,"Missing"
2020.fever-1.4,D16-1264,0,0.0401506,"Missing"
2020.fever-1.4,P18-2124,0,0.0427305,"Missing"
2020.fever-1.4,D15-1237,0,0.0389047,"Missing"
2020.fever-1.4,D19-1169,0,0.0296548,"Missing"
2020.gamnlp-1.12,Q17-1010,0,0.00577486,"0.001, number of epochs: 50 epochs. The cross-entropy loss between training labels and predicted ones is minimized and optimization is performed using SGD. As the classifier, this paper applies CNN and SVM to all of the four tasks: task 1, task 2, task 3-1, and task 3-2. When applying CNN, the implementation platform within Pytorch9 is employed, where the following three types of 9 https://pytorch.org/ 89 acter level text embeddings11 are used, (iii) both (i) and (ii) are used together. As character level text embeddings12 , we used the one trained with Wikipedia Japanese text13 by FastText (Bojanowski et al., 2017)14 , where the character level text embeddings are kept static during the procedure of training the CNN parameters. When applying SVM15 , the feature representations shown in Figure 1 and Figure 2 are directly used, where 2nd degree polynomial is employed and the hyper parameters C and γ are grid-searched. 6. Evaluation The CNN and SVM models described in the previous section are evaluated with the training and evaluation examples whose numbers are as shown in Table 5. As shown in Figure 3 ∼ Figure 6, the evaluation results are presented as the recall-precision curves16 for the evaluation exam"
2020.gamnlp-1.12,W19-8301,0,0.0343026,"Missing"
2020.gamnlp-1.12,D14-1181,0,0.00245579,"n obtained by manually crafted rules performs the best for the two classes: (a) revealing oneself as a seer, and (b) revealing oneself as a medium. For the class of (b) revealing oneself as a medium, 7 rules without incorporating into CNN/SVM achieved the highest recall. One of the reasons why the CNN models having feature representations with character level text embeddings ((ii) and (iii)) performed much worse than those (a) class of “revealing oneself as a seer” (b) class of “revealing oneself as a medium” 11 For both (ii) and (iii), the fundamental formalization of CNN is based on that of Kim (2014), where one convolution layer (one channel and the filter size as 3, 4, 5), one max-pooling layer (the filter size as 2) and one fully connected layer are used to build the network. We use ReLU activation function, mini-batch size of 10, learning rate: from 0.001 to 0.0001, number of epochs: 100 epochs. The cross-entropy loss between training labels and predicted ones is minimized and optimization is performed using ADAM optimizer (Kingma and Ba, 2015). 12 We compare word level and character level text embeddings, where the character level embeddings outperformed the word level embeddings. 13"
2020.gamnlp-1.12,W19-8305,0,0.0611997,"Missing"
2020.gamnlp-1.12,W19-8304,0,0.0275157,"Missing"
2020.gamnlp-1.12,W19-8302,0,0.0811061,"Missing"
2020.gamnlp-1.12,W19-8303,0,0.0339669,"Missing"
2020.iwslt-1.17,N12-1047,0,0.0426694,"NMT model as T2S feature. In addition, we also use the score generated by a target-to-source right-to-left model as a reranking feature. • Length Feature: We also design a length feature that quantifies the difference between the ratio of each sentence pair and the optimal ratio. The optimal ratio is determined according to the training parallel corpus. 3.4 Reranking Reranking is a method of improving translation quality by rescoring a list of n-best hypotheses. For our submissions, we generate n-best hypotheses through a source-to-target NMT model and then train a reranker using k-best MIRA (Cherry and Foster, 2012). The features we use for reranking are: 3.5 Postprocessing Since we perform NFKC-based text normalization on the training corpus, we also employ a postprocessing algorithm on the generated hypothesis. To be more specific, we change half-width punctuations to full-width punctuations. • Left-to-right NMT Feature: We keep the original perplexity by the original translation model as a L2R reranking feature. 4 Results • Right-to-left NMT Feature: In order to address exposure bias problem, we train a rightto-left (R2L) NMT model using the same Results and ablations for Ja→Zh and Zh→Ja are shown in"
2020.iwslt-1.17,D18-1045,0,0.104694,"uning. For data preprocessing, firstly, various orthodox methods including punctuation normalization, tokenization as well as byte pair encoding (Sennrich et al., 2016a) which have been widely used in recent researches are applied. Besides, we also apply manual rules, aiming to clean the provided parallel data, the monolingual data and the synthetic data which is generated by ourselves for data augmentation. For the sake of a better use of all provided data, we do a back-translation for either the source-side and the target-side monolingual data. Meanwhile, inspired by noised training method (Edunov et al., 2018; Wu et al., 2019; He et al., 2020), we add noise to the source sentences of the synthetic parallel corpus to make the translation models more robust and to improve its generalization ability. In addition, in inference phrase, we apply the model ensemble strategy while top n-best hypotheses are kept for further multi-features reranking process. At last, post-processing is applied to correct the inconsistent punctuation form. This paper is organized as follows: in Section 2, we describe our data preprocessing and data filtering. Details of each component of our systems are described in Section"
2020.iwslt-1.17,N19-4009,0,0.0181098,"rules: 3.1 Baseline System We adopt the base Transformer as our machine translation system following the settings as described in Vaswani et al. (2017), consisting of 6 encoder layers, 6 decoder layers, 8 heads, with an embedding dimension of 512 and feed-forward network dimension of 2048. The dropout probability is 0.2. For all experiments, we adopt the Adam optimizer (Kingma and Ba, 2014) using β1 = 0.9, β2 = 0.98, and "" = 1e-8. The learning rate is scheduled using inverse square root schedule with a maximum learning rate 0.0005 and 4000 warmup steps. We train all our models using fairseq5 (Ott et al., 2019) on two NIVIDA 2080Ti GPUs with a batch size of around 4096 tokens. During training, we employ label smoothing of value 0.1. We average the last 5 model checkpoints and use it for decoding. • Filter out duplicate sentence pairs. • Filter out sentence pairs which have identical source-side and target-side sentences. • Filter out sentence pairs with more than 10 punctuations or imbalanced punctuation ratio. • Filter out sentence pairs which contains half or more tokens that are numbers or letters. • Filter out sentence pairs which contain HTML tags or emoji. • Filter out sentence pairs with wron"
2020.iwslt-1.17,P16-1009,0,0.24387,".) + Filtering(in subwords.) Monolingual data(in sents.) + Filtering(in sents) + Filtering(in subwords.) 2.1 Data Preprocessing The provided parallel training data contains different forms of characters, for example, full-width form and half-width form. To get a normalized form, we remove all the spaces between characters and perform NFKC-based text normalization. Chinese sentences are segmented with the default mode of Jieba1 and Japanese sentences are segmented with Mecab2 using mecab-ipadicNEologd3 dictionary. To limit the size of vocabularies of NMT models, we use byte pair encoding(BPE) (Sennrich et al., 2016b) with 32K split operations separately for both side. Ja 20.9M 9.8M 164.5M 161.5M 17.8M 308.3M Zh 20.9M 9.8M 128.1M 161.5M 17.6M 254.9M Table 1: Statistics of the provided data. Notice that we treat two sides of the provided unfiltered dataset separately as monolingual data, therefore the number of monolingual data in terms of sentence pairs are identical as before data filtering. The same data filtering strategies except those designed for sentence pairs are also employed on monolingual data. Details of the preprocessed dataset in terms of the amount of sentences and BPE subwords are listed"
2020.iwslt-1.17,P16-1162,0,0.353045,".) + Filtering(in subwords.) Monolingual data(in sents.) + Filtering(in sents) + Filtering(in subwords.) 2.1 Data Preprocessing The provided parallel training data contains different forms of characters, for example, full-width form and half-width form. To get a normalized form, we remove all the spaces between characters and perform NFKC-based text normalization. Chinese sentences are segmented with the default mode of Jieba1 and Japanese sentences are segmented with Mecab2 using mecab-ipadicNEologd3 dictionary. To limit the size of vocabularies of NMT models, we use byte pair encoding(BPE) (Sennrich et al., 2016b) with 32K split operations separately for both side. Ja 20.9M 9.8M 164.5M 161.5M 17.8M 308.3M Zh 20.9M 9.8M 128.1M 161.5M 17.6M 254.9M Table 1: Statistics of the provided data. Notice that we treat two sides of the provided unfiltered dataset separately as monolingual data, therefore the number of monolingual data in terms of sentence pairs are identical as before data filtering. The same data filtering strategies except those designed for sentence pairs are also employed on monolingual data. Details of the preprocessed dataset in terms of the amount of sentences and BPE subwords are listed"
2020.iwslt-1.17,D19-1430,0,0.0483611,"ocessing, firstly, various orthodox methods including punctuation normalization, tokenization as well as byte pair encoding (Sennrich et al., 2016a) which have been widely used in recent researches are applied. Besides, we also apply manual rules, aiming to clean the provided parallel data, the monolingual data and the synthetic data which is generated by ourselves for data augmentation. For the sake of a better use of all provided data, we do a back-translation for either the source-side and the target-side monolingual data. Meanwhile, inspired by noised training method (Edunov et al., 2018; Wu et al., 2019; He et al., 2020), we add noise to the source sentences of the synthetic parallel corpus to make the translation models more robust and to improve its generalization ability. In addition, in inference phrase, we apply the model ensemble strategy while top n-best hypotheses are kept for further multi-features reranking process. At last, post-processing is applied to correct the inconsistent punctuation form. This paper is organized as follows: in Section 2, we describe our data preprocessing and data filtering. Details of each component of our systems are described in Section 3. The results of"
2020.iwslt-1.17,D16-1160,0,0.0266344,"t sentence pairs which have identical source-side and target-side sentences. • Filter out sentence pairs with more than 10 punctuations or imbalanced punctuation ratio. • Filter out sentence pairs which contains half or more tokens that are numbers or letters. • Filter out sentence pairs which contain HTML tags or emoji. • Filter out sentence pairs with wrong languages identified by langid.4 3.2 Large-scale Noised Training It is widely known that the performance of a NMT system relies heavily on the amount of parallel training data. Back-translation (Sennrich et al., 2016a) and Self-training (Zhang and Zong, 2016) are effective and commonly used data augmentation techniques to leverage the monolingual data to augment the original parallel dataset. In our case, we leverage both the source-side and target-side monolingual data to help the train• Filter out sentence pairs exceeding length ratio 1.5. • Filter out sentence pairs with less than 3 words or more than 100 word. 1 https://github.com/fxsjy/jieba https://taku910.github.io/mecab 3 https://github.com/neologd/ mecab-ipadic-neologd 4 https://github.com/saffsd/langid.py 2 5 146 https://github.com/pytorch/fairseq ing. Specifically, we train a baseline N"
2020.lrec-1.791,N15-1029,0,0.0607925,"Missing"
2020.lrec-1.791,D17-1296,0,0.0535053,"Missing"
2020.lrec-1.791,N19-1008,0,0.0260231,"Missing"
2020.paclic-1.49,Y15-2008,1,0.70041,"work includes studies on picture book recommendations based on the similarity of storylines of picture books, infants’ interest, and language developmental stages (Hattori et al., 2016; Yasuo et al., 2017). Their approach is based on the texts and pictures of picture books themselves but not on reviews of picture books. 6 7 Conclusion Related Work Previous work on analyzing infants’ developmental reactions detected from reviews on picture book reading includes an earlier work on how to detect infants’ major nine developmental reactions from reviews based on a simple keyword matching approach (Uehara et al., 2015). Further, later works considered on pointing behavior (Uehara et al., 2016) or hand/ﬁnger gestures (Uehara et al., 2017). Some focused on the relationship between characteristics of picture books and infants’ developmental reactions (Baba et al., 2017a) and clustering of picture books (Baba et al., 2017b). The proposed approach is novel when compared to previous works on analyzing infants’ developmental reactions detected from reviews on picture book reading. This is because we focused on the study of Ishikawa and In this work, we studied the infants’ reactions related to the ordering of deve"
A00-2015,P96-1025,0,0.382272,"e. 1. For each piece of evidence, calculate the likelihood ratio of the conditional probability of a decision D = xl (given the presence of that piece of evidence) to the conditional probability of the rest of the decisions D =-,xl: P(D=xl I E = I ) l°g2 P(D='~xl [ E = I ) Decision List Learning A decision list (Yarowsky, 1994) is a sorted list of the decision rules each of which decides the value of a decision D given some evidence E. Each decision rule in a decision list is sorted TOur modeling is slightly different from those of other standard approaches to statistical dependency analysis (Collins, 1996; Fujio and Matsumoto, 1998; Haruno et al., 1998) which simply distinguish the two cases: the case where dependency relation holds between the given two vp chunks or clauses, and the case where dependency relation does not hold. In contrast to those standard approaches, we ignore the case where the head vp chunk of Clause1 modifies that of another subordinate clause which precedes Clause2. This is because we assume that this case is more loosely related to the scope embedding preference of subordinate clauses. 114 Then, a decision list is constructed with pieces of evidence sorted in descendin"
A00-2015,C96-1058,0,0.0289129,"Missing"
A00-2015,W98-1511,1,0.84927,", we employ the decision list learning method of Yarowsky (1994), where optimal combination of those features are selected and sorted in the form of decision rules, according to the strength of correlation between those features and the dependency preference of the two subordinate clauses. We evaluate the proposed method through the experiment on learning dependency preference of Japanese subordinate clauses from the EDR bracketed corpus (section 4). We show that the proposed method outperforms other related methods/models. We also evaluate the estimated dependencies of subordinate clauses in Fujio and Matsumoto (1998)'s framework of the statistical dependency analysis of a whole sentence, in which we successfully increase the precisions of both chunk level and sentence level dependencies thanks to the estimated dependencies of subordinate clauses. 2 2.1 Analyzing Dependencies between Japanese Subordinate Clauses based on Scope Embedding Preference Dependency Analysis of A Japanese S e n t e n c e First, we overview dependency analysis of a Japanese sentence. Since words in a Japanese sentence are not segmented by explicit delimiters, input sentences are first word segmented, 111 Phrase Structure Scope of S"
A00-2015,P98-1083,0,0.305366,"e the likelihood ratio of the conditional probability of a decision D = xl (given the presence of that piece of evidence) to the conditional probability of the rest of the decisions D =-,xl: P(D=xl I E = I ) l°g2 P(D='~xl [ E = I ) Decision List Learning A decision list (Yarowsky, 1994) is a sorted list of the decision rules each of which decides the value of a decision D given some evidence E. Each decision rule in a decision list is sorted TOur modeling is slightly different from those of other standard approaches to statistical dependency analysis (Collins, 1996; Fujio and Matsumoto, 1998; Haruno et al., 1998) which simply distinguish the two cases: the case where dependency relation holds between the given two vp chunks or clauses, and the case where dependency relation does not hold. In contrast to those standard approaches, we ignore the case where the head vp chunk of Clause1 modifies that of another subordinate clause which precedes Clause2. This is because we assume that this case is more loosely related to the scope embedding preference of subordinate clauses. 114 Then, a decision list is constructed with pieces of evidence sorted in descending order with respect to their likelihood ratios,"
A00-2015,utsuro-2000-learning,1,0.581614,"Missing"
A00-2015,P94-1013,0,0.703477,"lem of deciding scope embedding preference as a classification problem, in which various types of linguistic information of each subordinate clause are encoded as features and used for deciding which one of given two subordinate clauses has a broader scope than the other. As in the case of Shirai et al. (1995), we formalize the problem of deciding dependency preference of subordinate clauses by utilizing the correlation of scope embedding preference and dependency preference of Japanese subordinate clauses. Then, as a statistical learning method, we employ the decision list learning method of Yarowsky (1994), where optimal combination of those features are selected and sorted in the form of decision rules, according to the strength of correlation between those features and the dependency preference of the two subordinate clauses. We evaluate the proposed method through the experiment on learning dependency preference of Japanese subordinate clauses from the EDR bracketed corpus (section 4). We show that the proposed method outperforms other related methods/models. We also evaluate the estimated dependencies of subordinate clauses in Fujio and Matsumoto (1998)'s framework of the statistical depend"
A97-1053,J96-1002,0,0.0308303,"Missing"
A97-1053,P93-1005,0,0.0119421,"ing probabilistic subcategorization preference from the EDR Japanese bracketed corpus, as well as those on evaluating the performance of subcategorization preference. 1 Introduction In corpus-based NLP, extraction of linguistic knowledge such as lexical/semantic collocation is one of the most important issues and has been intensively studied in recent years. In those research, extracted lexical/semantic collocation is especially useful in terms of ranking parses in syntactic analysis as well as automatic construction of lexicon for NLP. For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees. As lexical/semantic information, Black (1993) used about 50 semantic categories, while Magerman (1995) used lexicai forms of words. Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree. In those works, lexical/semantic collocation are used for ranking parses in syntactic analysis. *The authors would like to thank Dr. Hang"
A97-1053,P96-1025,0,0.158537,"in recent years. In those research, extracted lexical/semantic collocation is especially useful in terms of ranking parses in syntactic analysis as well as automatic construction of lexicon for NLP. For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees. As lexical/semantic information, Black (1993) used about 50 semantic categories, while Magerman (1995) used lexicai forms of words. Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree. In those works, lexical/semantic collocation are used for ranking parses in syntactic analysis. *The authors would like to thank Dr. Hang Li of NEC C&:C Research Laboratories, Dr. Kentaro Inui of Tokyo Institute of Technology, Dr. Koiti Hasida of Electrotechnical Laboratory, Dr. Tak_ashi Miyata of Nara Institute of Science and Technology, and also anonymous reviewers of ANLP97 for valuable comments on this work. ac. jp On the other hand, in the context of automatic lexicon const"
A97-1053,J93-1003,0,0.0229666,", . . . , fn). (~(e) = {(f,,...,f.) (fl ..... f,)--e} (24) I t&apos;) = max ¢((fl .... ,f~) ~ e) (23) (11.....Y~) Now, the problem of learning probabilistic subcategorization preference is stated as: for every verb-noun collocation e in C, estimating the probability distribution P((fl, 6Resnik (1993) applys the idea of the KL distance to measuring the association of a verb v and its object noun class c. Our definition of ekt corresponds to an extension of Resnik&apos;s association score, which considers dependencies of more than one case-markers in a subcategorization frame. 7Another related measure is Dunning (1993)&apos;s likelihood ratio tests for binomial and multinomial distributions, which are claimed to be effective even with very much smaller volumes of text than is necessary for other tests based on assumed normal distributions. F(e) contains a tuple ( f ) consisting of only one subcategorization frame f only if f can not be divided into several independent partial subcategorization frames. Then, we assume that each element of F ( e ) occurs evenly and estimate the initial conditional probability distribution P ( ( f l , . . . , f,)j I e) of generating e from (fl,..., fn)j as an approximation below: P"
A97-1053,C96-1004,0,0.120287,"ot decidable which superordinate class generates each observed leaf class in the verb-noun collocation. So far, there exist several researches which worked on these two issues in learning collocational knowledge of verbs and also evaluated the results in t e r m s of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argument noun in a treestructured thesaurus. Although they evaluated the obtained abstraction level of the argument noun by its performance in syntactic disambiguation, their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and evaluated the discovered dependencies in the syntactic disambiguation task. They first obtained optimal abstraction levels of the argument nouns by the method in Li and Abe (1995), and then tried to discover dependencies between the classbased case slots. They reported that dependencies 364 were discovered only at the slot-level and not at the class-level. C o m p a r e d with those previous works, this paper proposes to cope with the above two ambiguities in a uniform way. First, we introduce a d a t a structure which rep"
A97-1053,P95-1037,0,0.0571541,"subcategorization preference from the EDR Japanese bracketed corpus, as well as those on evaluating the performance of subcategorization preference. 1 Introduction In corpus-based NLP, extraction of linguistic knowledge such as lexical/semantic collocation is one of the most important issues and has been intensively studied in recent years. In those research, extracted lexical/semantic collocation is especially useful in terms of ranking parses in syntactic analysis as well as automatic construction of lexicon for NLP. For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees. As lexical/semantic information, Black (1993) used about 50 semantic categories, while Magerman (1995) used lexicai forms of words. Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree. In those works, lexical/semantic collocation are used for ranking parses in syntactic analysis. *The authors would like to thank Dr. Hang Li of NEC C&:C Resea"
A97-1053,H93-1054,0,0.461301,"tion 1) is caused by the fact that, only by observing each verb-noun collocation in corpus, it is not decidable which cases are dependent on each other and which cases are optional and independent of other cases. 2) is caused by the fact that, only by observing each verbnoun collocation in corpus, it is not decidable which superordinate class generates each observed leaf class in the verb-noun collocation. So far, there exist several researches which worked on these two issues in learning collocational knowledge of verbs and also evaluated the results in t e r m s of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argument noun in a treestructured thesaurus. Although they evaluated the obtained abstraction level of the argument noun by its performance in syntactic disambiguation, their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and evaluated the discovered dependencies in the syntactic disambiguation task. They first obtained optimal abstraction levels of the argument nouns by the method in Li and Abe (1995), and then tried to discover dependenci"
C00-2102,W99-0613,0,0.088852,"Missing"
C00-2102,W99-0612,0,0.106011,"Missing"
C00-2102,X96-1050,0,0.15947,"Missing"
C00-2102,W95-0107,0,0.0289637,"type to the morpheme MiNE at the current position, considering the patterns of surrounding morphemes. Note that in the supervised learning phase we can use the chunking information on which morphemes constitute a named entity, and which morphemes are in the left/right contexts of the named entity. 3.2 Encoding Schemes of Named Entity Chunking States In this paper, we evaluate the following two schemes of encoding chunking states of named entities. Examples of these encoding schemes are shown in Table 3. The Inside/Outside scheme of encoding chunking states of base noun phrases was studied in Ramshaw and Marcus (1995). This scheme distinguishes the following three states: O { the word at the current position is outside any base noun phrase. I { the word at the current position is inside some base noun phrase. B { the word at the current position marks the beginning of a base noun phrase that immediately follows another base noun phrase. We extend this scheme to named entity chunking by further distinguishing each of the states I and B into eight named entity types.4 Thus, this scheme distinguishes 2  8 + 1 = 17 states. 3.2.2 Start/End Encoding The Start/End scheme of encoding chunking states of named enti"
C00-2102,W98-1120,0,0.338772,"5463 (29.2) 413 (27.4) 747 (4.0) 48 (3.2) 3567 (19.1) 260 (17.2) 502 (2.7) 54 (3.5) 390 (2.1) 15 (1.0) 492 (2.6) 21 (1.4) 18677 1510 Japanese named entity recognition, into which we incorporate several noun phrase chunking techniques (sections 3 and 4) and experimentally evaluate their performance on the IREX workshop's training and test data (section 5). As one of those noun phrase chunking techniques, we propose a method for incorporating richer contextual information as well as patterns of constituent morphemes within a named entity, compared with those considered in the previous research (Sekine et al., 1998; Borthwick, 1999), and show that the proposed method outperforms these approaches. 2 Japanese Named Entity Recognition 2.1 Task of the IREX Workshop The task of named entity recognition of the IREX workshop is to recognize eight named entity types in Table 1 (IREX Committee, 1999). The organizer of the IREX workshop provided 1,174 newspaper articles which include 18,677 named entities as the training data. In the formal run (general domain) of the workshop, the participating systems were requested to recognize 1,510 named entities included in the heldout 71 newspaper articles. 2.2 Segmentatio"
C00-2102,utsuro-sassano-2000-minimally,1,0.866232,"Missing"
C00-2102,P94-1013,0,0.55291,"nsidering the cases of named entities of the length up to three morphemes and only implicitly considering those longer than three morphemes. We also restrict it to considering two morphemes in both left and right contexts of the named entity. Left ) ( Context  (Named Entity) Right ) ( Context M L2 M L1 M1NE    MiNE    MmNE M1R M2R (3) &quot; (Current Position)  (2) 4 Supervised Learning for Japanese Named Entity Recognition This section describes how to apply the decision list learning method to chunking/tagging named entities. 4.1 Decision List Learning A decision list (Rivest, 1987; Yarowsky, 1994) is a sorted list of decision rules, each of which decides the value of a decision D given some evidence E . Each decision rule in a decision list is sorted in descending order with respect to some preference value, and rules with higher preference values are applied rst when applying the decision list to some new test data. First, the random variable D representing a decision varies over several possible values, and the random variable E representing some evidence varies over `1' and `0' (where `1' denotes the presence of the corresponding piece of evidence, `0' its absence). Then, given some"
C04-1149,C02-1011,0,0.0136866,"rrespondence estimation from comparable corpora, it is diﬃcult to estimate bilingual term correspondences against every possible pair of terms due to its computational complexity. Previous works on bilingual term correspondence estimation from comparable corpora controlled experimental evaluation in various ways in order to reduce this computational complexity. For example, Rapp (1999) ﬁltered out bilingual term pairs with low monolingual frequencies (those below 100 times), while Fung and Yee (1998) restricted candidate bilingual term pairs to be pairs of the most frequent 118 unknown words. Cao and Li (2002) restricted candidate bilingual compound term pairs by consulting a seed bilingual lexicon and requiring their constituent words to be translation of each other across languages. On the other hand, in the framework of bilingual term correspondences estimation of this paper, the computational complexity of enumerating translation candidates can be easily avoided with the help of cross-language retrieval of relevant news texts. Furthermore, unlike Cao and Li (2002), bilingual term correspondences for compound terms are not restricted to compositional translation. 6 Conclusion In the framework of"
C04-1149,P98-1069,0,0.299193,"using much larger monolingual Web documents sets that are easily accessible through search engines. First, English pages which contain the target English term are collected through an English search engine. In the similar way, for each Japanese term in the Japanese translation candidates, Japanese pages which contain the Japanese term are collected through a Japanese search engine. Then, texts contained in those English and Japanese pages are extracted and are regarded as comparable corpora. Here, a standard technique of estimating bilingual term correspondences from comparable corpora (e.g., Fung and Yee (1998) and Rapp (1999)) is employed. Contextual similarity between the target English term and the Japanese translation candidate is measured across languages, and all the Japanese translation candidates are re-ranked according to the contextual similarities. 3.2 Filtering by Hits of Search Engines Before re-estimating bilingual term correspondences using monolingual Web documents, we assume there exists certain correlation between hits of the English term tE and the Japanese term tJ returned by search engines. Depending on the hits h(tE ) of tE , we restrict the hits h(tJ ) of tJ to be within the r"
C04-1149,P99-1067,0,0.148101,"ngual Web documents sets that are easily accessible through search engines. First, English pages which contain the target English term are collected through an English search engine. In the similar way, for each Japanese term in the Japanese translation candidates, Japanese pages which contain the Japanese term are collected through a Japanese search engine. Then, texts contained in those English and Japanese pages are extracted and are regarded as comparable corpora. Here, a standard technique of estimating bilingual term correspondences from comparable corpora (e.g., Fung and Yee (1998) and Rapp (1999)) is employed. Contextual similarity between the target English term and the Japanese translation candidate is measured across languages, and all the Japanese translation candidates are re-ranked according to the contextual similarities. 3.2 Filtering by Hits of Search Engines Before re-estimating bilingual term correspondences using monolingual Web documents, we assume there exists certain correlation between hits of the English term tE and the Japanese term tJ returned by search engines. Depending on the hits h(tE ) of tE , we restrict the hits h(tJ ) of tJ to be within the range of a lower"
C04-1149,E03-1023,1,0.833465,"pproach is that the techniques of translation knowledge acquisition heavily rely on availability of parallel/comparative corpora. However, the sizes as well as the domain of existing parallel/comparative corpora are limited, while it is very expensive to manually collect parallel/comparative corpora. Therefore, it is quite important to overcome this resource scarcity bottleneck in corpus-based translation knowledge acquisition research. In order to solve this problem, we proposed an approach of taking bilingual news articles on Web news sites as a source for translation knowledge acquisition (Utsuro et al., 2003). In the case of Web news sites in Japan, Japanese as well as English news articles are updated everyday. Although most of those bilingual news articles are not parallel even if they are from the same site, certain portion of those bilingual news articles share their contents or at least report quite relevant topics. This characteristic is quite important for the purpose of translation knowledge acquisition. Utsuro et al. (2003) showed that it is possible to acquire translation knowledge of domain speciﬁc named entities, event expressions, and collocational expressions from the collection of b"
C04-1149,C98-1066,0,\N,Missing
C92-2088,P91-1027,0,0.0420531,"Missing"
C92-2088,P91-1017,0,0.087783,"and word mf~anings (such as English and Japanese), and to c(nnt~are analyzed results from each language, h| many (:asc~, the two languagcs }Lave different types of syntactic ambiguities, anti comparison of syntactic structures of both bmguagcs helps to resolve the ambiguities. Also, a pair of bilingually equivalent snrface words helps to a~&apos;4ociate tile words with conceptual l&apos;~oc. OF COL]NG-92. NANTES.AUG.23-28, 1992 words helps to associate the words with conceptual items, because the intersection of conceptual items that each surface word has could be considered as one conceptual item[ll] [2]. [&quot;or example, in tire case of the translation example given in Example 1, both syntactic and semantic ambiguities are resolved. Example 1 E: J: I hung my coat on the hook. ~:L(I) ;~ (topic) ~2~ (coat) ~ (ca.se-m~trker) ~&apos;5&quot; (hook) lZ (case-marker) zi&apos;$~&apos;f: (hung)o 1. S y n t a c t i c d i s u m b i g u a t i o n The English sentence in Example 1 is syntactically ambiguous because the prepositional phrase &quot;on the hook&quot; can modify both the verb &quot;hung&quot; aad tim noun phrase &quot;my coat&quot; using grammatical knowledge only. On the other band, in the Japanese sentence, the phrase &quot;7)~~&apos;, Is_&quot; can modify"
C92-2088,P90-1034,0,0.0411537,"ion. One ~nch approach is to extract hierarclfical relations or it thesanrtm of conceptual items froln hunLall dictionaries in an automatic way. q)surrnnaru et el. studied to construct a t}LeSaLLrlIsof nominal concepts from noun detinitions[t3], q b m i a r a et al. also extracted snperordinatc-subordmatc relation between verbs from the defining sentences in IPAL[12]. l i e sidcs these rcseasches, there are other several research activitics tbr lexical knowledge acquisition, which syntactically anMyze the sentences m large corpora and attcmpt to extract lcxical knowledge from statistical data [3] [1]. Most of the works undertake shallow analysis of texts and they extract only superticial lexical information. For the development of tile techniques of knowledge acquisition from natural language texts, it is very important to improve the httter approach of cornpiling semantic dictionaries by comimter l)rograuL~. Ilowever, there are at least two basic difficulties in this at)preach 1. Tire i~robh~m (ff s y n t a c t i c a m b i g u i t i e s When analyzing a sentence., syntactic ambiguities often remain. So i~ is not easy to obtain correct parsed results automatically. 2. The, probh~rrr o"
C92-2088,C90-3044,1,0.839076,"COLING-92, NANTES,AUG. 23-28, 1992 cable to sew:ral otller problenrs as well. One of t h e m is to acquire features of nominal concepts. We are at the m o m e n t looking at some specitie nominal expression &quot;A q) B&quot; in Japanese, corresponding literally to &quot;I1 of A&quot; in English. T h a t expression specifies a variety of relationships of noun phrases, which are often stated in different expressions in English. T h e y will help to acquire typical attributes of nominal concepts fl&apos;om bilingual corpora. Our ntethod is also useful to collect parsed traamlation examples tbr example-based translation [9] attd to acquire translation p a t t e r n s between two languages. &apos;Fable 3: Acquired Case Frames for &quot;~-[ &lt; (wr;le)&quot; (7~Lse Frame 15 (on) l~t . :6¢ (sub3) ~ ) J3.. ~ ( [subj,passive]) &quot;~&quot; (with) -e I PRO IIUM REL, QUA, LIN (i,,) Ca.~e Frlmm 2 V- (to) HUM ~;t • fie (subj) HUM l;~ &quot; ~ (obj) t:]: • fit ( LIN [subj,p,,ssive]) ~ (with) -e (i,,) the e x t r a c t e d cm~e slots, ttle systenr ~sks the h u m a n instructor a b o u t the pcx~sibi[ities of tile co-occurrence of the case slots that do not cc.occur in the trans lation examples by composing saml)le phr,&apos;~ses. T h e questions and answers"
C92-2088,H91-1067,0,\N,Missing
C92-2088,P86-1038,0,\N,Missing
C94-2169,1993.iwpt-1.11,1,0.734317,"roposes a novel example retrieval method for avoiding ftfll retrieval of examples. The proposed method has the following three features, 1) it generates retrieval queries from similarities, 2) efficient example retrieval through the tree structure of a thesaurus, 3) binary search along subsumption ordering of retrieval queries. Example retrieval time drastically decreases with the method. 1 2 Introduction Since a nmdel of machine translation (MT) called Translation by Analogy was first proposed in Nagao (1984), nmch work has been undertaken in exampleba~sed NLP (e.g. Sato and Nagao (1990) and Kurohashi and Nagao (1993)). The basic idea of examplebased approach to NLP is to accomplish some task in NLP by imitating a similar previous example, instead of using rules written by h u m a n writers. Major processing steps of example-based approach are: 1) collect examples and the results of performing the task in a database, 2) given an input, retrieve similar examples from the database, 3) adapt the results of tile similar examples to the current input and obtain the output. Compared with the traditional rule-based approach, example-based approach has advantages like: 1) it is easier to m a i n t a i n the implem"
C94-2169,C90-3044,1,0.740067,"the database. This paper proposes a novel example retrieval method for avoiding ftfll retrieval of examples. The proposed method has the following three features, 1) it generates retrieval queries from similarities, 2) efficient example retrieval through the tree structure of a thesaurus, 3) binary search along subsumption ordering of retrieval queries. Example retrieval time drastically decreases with the method. 1 2 Introduction Since a nmdel of machine translation (MT) called Translation by Analogy was first proposed in Nagao (1984), nmch work has been undertaken in exampleba~sed NLP (e.g. Sato and Nagao (1990) and Kurohashi and Nagao (1993)). The basic idea of examplebased approach to NLP is to accomplish some task in NLP by imitating a similar previous example, instead of using rules written by h u m a n writers. Major processing steps of example-based approach are: 1) collect examples and the results of performing the task in a database, 2) given an input, retrieve similar examples from the database, 3) adapt the results of tile similar examples to the current input and obtain the output. Compared with the traditional rule-based approach, example-based approach has advantages like: 1) it is easie"
C94-2169,1988.tmi-1.13,0,0.0817155,"Missing"
C94-2175,J90-2002,0,0.292042,"Missing"
C94-2175,J93-2003,0,0.0512019,"Missing"
C94-2175,J93-1004,0,0.225334,"echniques are apt plied to estimate word correspondences not included in bilingual dictionaries. Estimated word correspondences are useful for improving both sentence alignment and structural matching. Introduction Bilingnal (or parallel) texts are useful as resources of linguistic knowledge as well as in applications such as machine translation. One of the major approaches to analyzing bilingual texts is the statistical approach. The statistical approach involves the following: alignment of bilingual texts at the sentence level nsing statistical techniques (e.g. Brown, Lai and Mercer (1991), Gale and Church (1993), Chen (1993), and Kay and RSscheisen (1993)), statistical machine translation models (e.g. Brown, Cooke, Pietra, Pietra et al. (1990)), finding character-level / word-level / phrase-level correspondences from bilingual texts (e.g. Gale and Church (1991), Church (1993), and Kupiec (1993)), and word sense disambiguation for MT (e.g. Dagan, Itai and Schwall (1991)). In general, the statistical approach does not use existing hand-written bilingual dictionaries, and depends solely upon statistics. For example, sentence alignment of bilingual texts are performed just by measuring sentence lengths i"
C94-2175,C90-3101,0,0.017792,"91; Gale and Church, 1993), or by statistically estimating word level correspondences (Chen, 1993; Kay and RSscheisen, 1993). The statistical approach analyzes unstructured sentences in bilingual texts, and it is claimed that the results are useful enough in real applications such as machine translation and word sense disambiguation. However, structured bilingual sentences are undoubtedly more informative and important for future natural language researches. Structured bilingual or multilingual corpora serve as richer sonrces for extracting linguistic knowledge (Klavans and Tzonkermann, 1990; Sadler and Vendelmans, 1990; Kaji, Kida attd Morimoto, 1992; Utsuro, Matsnmoto and Nagao, 1992; Matsumoto, l.shimoto and Utsuro, 1993; Ut1076 Makoto Nagao ~ tGraduate School of Information Science Abstract 1 Yuji Matsumoto t suro, Matsumoto and Nagao, 1993). Compared with the statistical approach, those works are quite different in that they use word correspondence information available in hand-written bilingual dictionaries and try to extract structured linguistic knowledge such as structured translation patterns and case frames of verbs. For example, in Matsunloto et al. (1993), we proposed a method for finding struct"
C94-2175,C92-2088,1,0.843099,"proach, those works are quite different in that they use word correspondence information available in hand-written bilingual dictionaries and try to extract structured linguistic knowledge such as structured translation patterns and case frames of verbs. For example, in Matsunloto et al. (1993), we proposed a method for finding structural matching of parallel sentences, making use of word level similarities calculated from a bilingual dictionary and a thesaurus. Then, those structurally matched parallel sentences are used as a source for acquiring lexical knowledge snch as verbal case frames (Utsuro et al., 1992; Utsuro et al., 1993). With the aim of acquiring those structnred linguistic knowledge, this paper describes a unilied framework for bilingual text matching by combining existing hand-written bilingual dictionaries and statistical techniques. The process of bilingual text matchin 9 consists of two major steps: sentence alignment and structural matching of bilingual sentences. In those two steps, we use word correspondence information, which is available in hand-written bilingual dictionaries, or not included in bilingual dictionaries but estimated with statistical techniques. The reasons why"
C94-2175,C92-2101,0,0.0750694,"Missing"
C94-2175,C90-3031,0,0.0660578,"Missing"
C94-2175,P93-1003,0,0.0605224,"Missing"
C94-2175,P93-1001,0,\N,Missing
C94-2175,P91-1022,0,\N,Missing
C94-2175,P93-1004,1,\N,Missing
C94-2175,P91-1017,0,\N,Missing
C94-2175,J93-1006,0,\N,Missing
C94-2175,H91-1026,0,\N,Missing
C94-2175,P93-1002,0,\N,Missing
C96-2163,J90-1003,0,0.0190957,"Only surface forms of English verbs and case labels are used and sense distribution of English verbs is not used. Also, the threshold of deciding a distinction in the sense distribution of Japanese case element nouns is predetermined on a fixed level in a Japanese thesaurus. As a result, the human instructor is frequently asked to judge the correctness of the clue. In the field of statistical analysis of natural language data, it is common to use measures of lexical association, such as the informationtheoretic measure of mutual information, to extract useful relationships between words (e.g. Church and Hanks (1990)). Lexical association has its limits, however, since often either the data is insufficient to provide reliable word/word correspondences, or the task requires more abstraction than word/word correspondences permit. Thus, Resnik (1992) proposed a useful mea~ sure of word/class association by generalizing information-theoretic measure of word/word association. The proposed measure addresses the limitations of lexical association by facilitating sta~ tistical discovery of facts involving word classes rather than individual words. We find the measure of word/class association of Resnik (1992) is"
C96-2163,P91-1017,0,0.0328299,"Missing"
C96-2163,P93-1004,1,0.89173,"Missing"
C98-2209,J96-1002,0,0.0117999,"mited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and reported that dependencies were discovered only at the slotlevel and not at the class-level. Compared with these previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb and argum e n t / a d j u n c t nouns (section 2) and then view the model as a probability model (section 3). As a model learning method, we adopt the maximum entropy model learning method (Della Pietra et al., 1997; Berger et al., 1996). Case dependencies and noun class generalization are represented as features in the maximum entropy approach. Features are allowed to have overlap and this is quite advantageous when we consider case dependcncies and noun class generalization in parameter estimation. An optimal model is selected by searching for an optimal set of features, i.e, optimal case dependencies and optimal noun class generMization levels. As the feature selection process, this paper proposes a new feature selection algorithm which starts from the most general model and gradually examines more specific models (section"
C98-2209,P96-1025,0,0.0255014,"ximum entropy modeling method. We also propose a new model selection algorithm which starts from the most general model and gradually examines more specific models. In the experimental evaluation, it is shown that both of the case dependencies and specific sense restriction selected by the proposed method contribute to improving the performance in subcategorization preference resolution. 1 Introduction In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis. For example, Magerman (1995), Collins (1996), and Charniak (1997) proposed statistical parsing models which incorporated lexical/semantic information. In their models, syntactic and lexical/semantic features are dependent on each other and are combined together. This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis. However, unlike the models of Magerman (1995), Collins (1996), and Charniak (1997), we assume that syntactic and lexical/semantic features are independent. Then, we focus on extracting lcxical/semantic collocational knowledge of verbs"
C98-2209,C96-1004,0,0.0176758,", 1998. An extended version of this paper is available from the above URL. 1314 dependent of other cases. When considering 2), we have to decide which superordinate class generates each observed leaf class in the verb-noun collocation. So far, there exist several works which worked on these two issues in learning collocational knowledge of verbs and also evaluated the results in terms of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argument noun in a tree-structured thesaurus. Their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and reported that dependencies were discovered only at the slotlevel and not at the class-level. Compared with these previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb and argum e n t / a d j u n c t nouns (section 2) and then view the model as a probability model (section 3). As a model learning method, we adopt the maximum entropy model learning method (Della Pietra et al., 1997; Berger et al., 1996). Case dependencies and n"
C98-2209,P95-1037,0,0.013454,"employing the maximum entropy modeling method. We also propose a new model selection algorithm which starts from the most general model and gradually examines more specific models. In the experimental evaluation, it is shown that both of the case dependencies and specific sense restriction selected by the proposed method contribute to improving the performance in subcategorization preference resolution. 1 Introduction In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis. For example, Magerman (1995), Collins (1996), and Charniak (1997) proposed statistical parsing models which incorporated lexical/semantic information. In their models, syntactic and lexical/semantic features are dependent on each other and are combined together. This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis. However, unlike the models of Magerman (1995), Collins (1996), and Charniak (1997), we assume that syntactic and lexical/semantic features are independent. Then, we focus on extracting lcxical/semantic collocational kn"
C98-2209,H93-1054,0,0.0333564,"re optional and in* This research was partially supported by the Ministry of Education, Science, Sports and Culture, Japan, Grantin-Aid for Encouragement of Young Scientists, 09780338, 1998. An extended version of this paper is available from the above URL. 1314 dependent of other cases. When considering 2), we have to decide which superordinate class generates each observed leaf class in the verb-noun collocation. So far, there exist several works which worked on these two issues in learning collocational knowledge of verbs and also evaluated the results in terms of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argument noun in a tree-structured thesaurus. Their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and reported that dependencies were discovered only at the slotlevel and not at the class-level. Compared with these previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb and argum e n t / a d j u n c t nouns (section 2) and then view the model a"
C98-2209,A97-1053,1,0.575665,"Missing"
C98-2209,J98-2002,0,\N,Missing
D19-5622,K18-1010,0,0.0387704,"Missing"
D19-5622,P19-2030,1,0.769292,"prove the self-attention in a systematic and multifaceted perspective, rather than just paying attention to one specific characteristic. 6 Compared to a conventional NMT model with only a single head, multi-head is assumed to have a stronger ability to extract different features in different subspaces. However, there are no explicit mechanism that make them distinct (Voita et al., 2019; Michel et al., 2019). Li et al. (2018) had shown that using a disagreement regularization to encourage different attention heads to have different behaviors can improve the performance of multi-head attention. Iida et al. (2019) proposed a multi-hop attention where the second-hop serves as a head gate function to normalize the attentional context of each head. Not only limited in the field of neural machine translation, Strubell et al. (2018) combined multi-head self-attention with multi-task learning, this led to a promising result for semantic role labeling. Similar to the above studies, we also attempt to model diversity for multi-head attention. In this work, we apply difRelated Work In the field of neural machine translation, the two most used attention mechanisms are additive attention (Bahdanau et al., 2015) a"
D19-5622,W18-2709,0,0.0240383,"our mixed multihead self-attention. For a fair comparison, we apply each attention function twice in base model. By doing this, our Transformer MMA have the same number of parameters as the original Transformer. For evaluation, we use a beam size of 5 for beam search, translation quality is reported via BLEU (Papineni et al., 2002) and statistical significance test is conducted by paired bootstrap resampling method (Koehn, 2004). 5.1 Effectiveness of MMA Neural machine translation must consider the correlated ordering of words, where order has a lot of influence on the meaning of a sentence (Khayrallah and Koehn, 2018). In vanilla Transformer, the position embedding is a deterministic function of position and it allows the model to be aware of the order of the sequence (Yang et al., 2019). As shown in Table 3, Transformer without position embedding fails on translation task, resulting in a decrease of 17.91 BLEU score. With the help of proposed MMA, the performance is only reduced by 0.75 BLEU score without position embedding, and 18.11 points higher than the Transformer baseline. The same result holds true for a distant language pair Japanese-English where word oder is completely different. When removing p"
D19-5622,W04-3250,0,0.140022,"20 epochs, the small model are trained for 45 epochs. The number of heads are 8 for base model and 4 for small model. We replace multi-head selfattention in the encoder layers by our mixed multihead self-attention. For a fair comparison, we apply each attention function twice in base model. By doing this, our Transformer MMA have the same number of parameters as the original Transformer. For evaluation, we use a beam size of 5 for beam search, translation quality is reported via BLEU (Papineni et al., 2002) and statistical significance test is conducted by paired bootstrap resampling method (Koehn, 2004). 5.1 Effectiveness of MMA Neural machine translation must consider the correlated ordering of words, where order has a lot of influence on the meaning of a sentence (Khayrallah and Koehn, 2018). In vanilla Transformer, the position embedding is a deterministic function of position and it allows the model to be aware of the order of the sequence (Yang et al., 2019). As shown in Table 3, Transformer without position embedding fails on translation task, resulting in a decrease of 17.91 BLEU score. With the help of proposed MMA, the performance is only reduced by 0.75 BLEU score without position"
D19-5622,D18-1317,0,0.0717605,"cy of the Transformer with only one head and eight has occurred in multiple heads. In this paheads (Vaswani et al., 2017; Chen et al., 2018). per, we argue that using the same global atHowever, all encoder self-attention heads fully tention in multiple heads limits multi-head self-attention’s capacity for learning distinct take global information into account, there is features. In order to improve the expresno explicit mechanism to ensure that differsiveness of multi-head self-attention, we proent attention heads indeed capture different feapose a novel Mixed Multi-Head Self-Attention tures (Li et al., 2018). Concerning the results pre(MMA) which models not only global and losented by some latest researches, the majority cal attention but also forward and backward atof the encoder self-attention heads, can even be tention in different attention heads. This enpruned away without substantially hurting model’s ables the model to learn distinct representations explicitly among multiple heads. In our performance (Voita et al., 2019; Michel et al., experiments on both WAT17 English-Japanese 2019). Moreover, the ability of multi-head selfas well as IWSLT14 German-English transattention, in which lacking"
D19-5622,D15-1166,0,0.833569,"e latest researches, the majority cal attention but also forward and backward atof the encoder self-attention heads, can even be tention in different attention heads. This enpruned away without substantially hurting model’s ables the model to learn distinct representations explicitly among multiple heads. In our performance (Voita et al., 2019; Michel et al., experiments on both WAT17 English-Japanese 2019). Moreover, the ability of multi-head selfas well as IWSLT14 German-English transattention, in which lacking capacity to capture lolation task, we show that, without increascal information (Luong et al., 2015; Yang et al., ing the number of parameters, our models 2018; Wu et al., 2019) and sequential informayield consistent and significant improvements tion (Shaw et al., 2018; Dehghani et al., 2019), (0.9 BLEU scores on average) over the strong 1 has recently come into question (Tang et al., Transformer baseline. 2018). Motivated by above findings, we attribute the 1 Introduction redundancy arising in encoder self-attention heads Neural machine translation (NMT) has made to the using of same global self-attention among promising progress in recent years with differall attention heads. Additionally"
D19-5622,P18-1008,0,0.0242936,"llow the model of its high-performance is the multi-head selfto independently attend to information from attention which allows the model to jointly attend different representation subspaces. However, to information from different representation subthere is no explicit mechanism to ensure that spaces at different positions. There is a huge gap different attention heads indeed capture dif(around 1 BLEU score) between the performance ferent features, and in practice, redundancy of the Transformer with only one head and eight has occurred in multiple heads. In this paheads (Vaswani et al., 2017; Chen et al., 2018). per, we argue that using the same global atHowever, all encoder self-attention heads fully tention in multiple heads limits multi-head self-attention’s capacity for learning distinct take global information into account, there is features. In order to improve the expresno explicit mechanism to ensure that differsiveness of multi-head self-attention, we proent attention heads indeed capture different feapose a novel Mixed Multi-Head Self-Attention tures (Li et al., 2018). Concerning the results pre(MMA) which models not only global and losented by some latest researches, the majority cal atte"
D19-5622,N19-4009,0,0.0214542,"K, 1.8K sentence pairs respectively. We adopt the official 16K vocabularies preprocessed by sentencepiece.2 IWSLT14 German-English: We use the TED data from the IWSLT14 German-English shared translation task (Cettolo et al., 2014) which contains 160K training sentences and 7K validation sentences randomly sampled from the training data. We test on the concatenation of tst2010, tst2011, tst2012, tst2013 and dev2010. For this benchmark, data is lowercased and tokenized with byte pair encoding (BPE) (Sennrich et al., 2016). 4.2 Setup Our implementation is built upon open-source toolkit fairseq3 (Ott et al., 2019). For WAT17 dataset and IWSLT14 dataset, we use the configurations of the Transformer base and small model respectively. Both of them consist of a 6-layer encoder and 6-layer decoder, the size of hidden state and word embedding are set to 512. The dimensionality of inner feed-forward layer is 2048 for base and 1024 for small model. The dropout probability is 0.1 and 0.3 for base and small model. Models are optimized with Adam (Kingma and Ba, 2014). We use the same warmup and decay strategy for learning rate as Vaswani et al. (2017) with 4000 warmup steps. Experiments 4.1 Datasets To test the p"
D19-5622,P02-1040,0,0.104861,"trained on a single NVIDIA RTX2080Ti with a batch size of around 4096 tokens. The base model are trained for 20 epochs, the small model are trained for 45 epochs. The number of heads are 8 for base model and 4 for small model. We replace multi-head selfattention in the encoder layers by our mixed multihead self-attention. For a fair comparison, we apply each attention function twice in base model. By doing this, our Transformer MMA have the same number of parameters as the original Transformer. For evaluation, we use a beam size of 5 for beam search, translation quality is reported via BLEU (Papineni et al., 2002) and statistical significance test is conducted by paired bootstrap resampling method (Koehn, 2004). 5.1 Effectiveness of MMA Neural machine translation must consider the correlated ordering of words, where order has a lot of influence on the meaning of a sentence (Khayrallah and Koehn, 2018). In vanilla Transformer, the position embedding is a deterministic function of position and it allows the model to be aware of the order of the sequence (Yang et al., 2019). As shown in Table 3, Transformer without position embedding fails on translation task, resulting in a decrease of 17.91 BLEU score."
D19-5622,W18-5431,0,0.0369679,"MA achieves the best result. One possible reason is that, in the case where there are already global features captured by global attention, the smaller the attention scope, the more local features can be learned by local attention. 5.4 Attention Visualization To further explore the behavior of our Transformer MMA, we observe the distribution of encoder attention weights in our models and show an example of Japanese sentence as plotted in Figure 3. The first discovery is that we find the word overlooks itself on the first layer in the global attention head. This contrasts with the results from Raganato and Tiedemann (2018). They find that, on the first layer of original Transformer, more en5.3 Ablation Study For ablation study, the primary question is whether the Transformer benefits from the integration of different attention equally. To do evaluate the impact of various attention functions, we keep global self-attention head unchanged, and next we replace other heads with different attention function. 211 Figure 3: Visualization of the attention weights of Japanese sentence “これらは 腰椎 装具 装用 または 運動 制 限 により 全 症例 軽快した 。” (meaning “These persons were improved in all cases by wearing lumbar braces or limiting exerci"
D19-5622,D18-1475,0,0.107174,"us on the word itself. This change is in line with our assumption that, due to the existence of other attention heads, global attention head can focus more on capturing global information. The second discovery is that, on the upper layers, forward and backward attention heads move the attention more on distant words. This suggests forward and backward attention is able to serve as a complement to capturing long-range dependency. with a global receptive field, the ability of selfattention recently came into question (Tang et al., 2018). And modeling localness, either restricting context sizes (Yang et al., 2018; Wu et al., 2019; Child et al., 2019) or balancing the contribution of local and global information (Xu et al., 2019), has been shown to be able to improve the expressiveness of self-attention. In contrast to these studies, we aim to improve the self-attention in a systematic and multifaceted perspective, rather than just paying attention to one specific characteristic. 6 Compared to a conventional NMT model with only a single head, multi-head is assumed to have a stronger ability to extract different features in different subspaces. However, there are no explicit mechanism that make them dis"
D19-5622,P19-1354,0,0.0126744,"s as the original Transformer. For evaluation, we use a beam size of 5 for beam search, translation quality is reported via BLEU (Papineni et al., 2002) and statistical significance test is conducted by paired bootstrap resampling method (Koehn, 2004). 5.1 Effectiveness of MMA Neural machine translation must consider the correlated ordering of words, where order has a lot of influence on the meaning of a sentence (Khayrallah and Koehn, 2018). In vanilla Transformer, the position embedding is a deterministic function of position and it allows the model to be aware of the order of the sequence (Yang et al., 2019). As shown in Table 3, Transformer without position embedding fails on translation task, resulting in a decrease of 17.91 BLEU score. With the help of proposed MMA, the performance is only reduced by 0.75 BLEU score without position embedding, and 18.11 points higher than the Transformer baseline. The same result holds true for a distant language pair Japanese-English where word oder is completely different. When removing position embedding, the Transformer baseline drops to 12.83 BLEU score. However, our model still achieves 23.80 in terms of BLEU score, with 10.97 points improvement over the"
D19-5622,P16-1162,0,0.0826212,"nd does not affect the training efficiency. 4 Training, validation and test sets comprise 2M, 1.8K, 1.8K sentence pairs respectively. We adopt the official 16K vocabularies preprocessed by sentencepiece.2 IWSLT14 German-English: We use the TED data from the IWSLT14 German-English shared translation task (Cettolo et al., 2014) which contains 160K training sentences and 7K validation sentences randomly sampled from the training data. We test on the concatenation of tst2010, tst2011, tst2012, tst2013 and dev2010. For this benchmark, data is lowercased and tokenized with byte pair encoding (BPE) (Sennrich et al., 2016). 4.2 Setup Our implementation is built upon open-source toolkit fairseq3 (Ott et al., 2019). For WAT17 dataset and IWSLT14 dataset, we use the configurations of the Transformer base and small model respectively. Both of them consist of a 6-layer encoder and 6-layer decoder, the size of hidden state and word embedding are set to 512. The dimensionality of inner feed-forward layer is 2048 for base and 1024 for small model. The dropout probability is 0.1 and 0.3 for base and small model. Models are optimized with Adam (Kingma and Ba, 2014). We use the same warmup and decay strategy for learning"
D19-5622,P19-1021,0,0.051077,"Missing"
D19-5622,N18-2074,0,0.24625,"enpruned away without substantially hurting model’s ables the model to learn distinct representations explicitly among multiple heads. In our performance (Voita et al., 2019; Michel et al., experiments on both WAT17 English-Japanese 2019). Moreover, the ability of multi-head selfas well as IWSLT14 German-English transattention, in which lacking capacity to capture lolation task, we show that, without increascal information (Luong et al., 2015; Yang et al., ing the number of parameters, our models 2018; Wu et al., 2019) and sequential informayield consistent and significant improvements tion (Shaw et al., 2018; Dehghani et al., 2019), (0.9 BLEU scores on average) over the strong 1 has recently come into question (Tang et al., Transformer baseline. 2018). Motivated by above findings, we attribute the 1 Introduction redundancy arising in encoder self-attention heads Neural machine translation (NMT) has made to the using of same global self-attention among promising progress in recent years with differall attention heads. Additionally, it is because of ent architectures, ranging from recurrent neuthe redundancy, multi-head self-attention is unral networks (Sutskever et al., 2014; Cho et al., able to l"
D19-5622,D18-1548,0,0.0377067,"assumed to have a stronger ability to extract different features in different subspaces. However, there are no explicit mechanism that make them distinct (Voita et al., 2019; Michel et al., 2019). Li et al. (2018) had shown that using a disagreement regularization to encourage different attention heads to have different behaviors can improve the performance of multi-head attention. Iida et al. (2019) proposed a multi-hop attention where the second-hop serves as a head gate function to normalize the attentional context of each head. Not only limited in the field of neural machine translation, Strubell et al. (2018) combined multi-head self-attention with multi-task learning, this led to a promising result for semantic role labeling. Similar to the above studies, we also attempt to model diversity for multi-head attention. In this work, we apply difRelated Work In the field of neural machine translation, the two most used attention mechanisms are additive attention (Bahdanau et al., 2015) and dot attention (Luong et al., 2015). Based on the latter, Vaswani et al. (2017) proposed a multi-head selfattention, that is not only highly parallelizable but also with better performance. However, self-attention, w"
D19-5622,D18-1458,0,0.164173,"Missing"
D19-5622,P19-1580,0,0.310539,"echanism to ensure that differsiveness of multi-head self-attention, we proent attention heads indeed capture different feapose a novel Mixed Multi-Head Self-Attention tures (Li et al., 2018). Concerning the results pre(MMA) which models not only global and losented by some latest researches, the majority cal attention but also forward and backward atof the encoder self-attention heads, can even be tention in different attention heads. This enpruned away without substantially hurting model’s ables the model to learn distinct representations explicitly among multiple heads. In our performance (Voita et al., 2019; Michel et al., experiments on both WAT17 English-Japanese 2019). Moreover, the ability of multi-head selfas well as IWSLT14 German-English transattention, in which lacking capacity to capture lolation task, we show that, without increascal information (Luong et al., 2015; Yang et al., ing the number of parameters, our models 2018; Wu et al., 2019) and sequential informayield consistent and significant improvements tion (Shaw et al., 2018; Dehghani et al., 2019), (0.9 BLEU scores on average) over the strong 1 has recently come into question (Tang et al., Transformer baseline. 2018). Motivated"
D19-5622,P19-1295,0,0.593715,"ly describe the Transformer architecture (Vaswani et al., 2017) which includes 207 ATT(·) is computed by: ei = Qi K ⊤ √ d ATT(Q, K, V ) = Softmax(ei )V receptive field which is used to connect with arbitrary words directly. Under our framework, we define the hard mask for global attention as follows: (5) G Mi,j =0 But global attention may be less powerful and can potentially render it impractical for longer sequences (Luong et al., 2015). On the other hand, self-attention can be enhanced by local attention which focuses more on restricted scope rather than the entire context (Wu et al., 2019; Xu et al., 2019). Based on the above findings, we also define a local attention which simply employs a hard mask to restrict the attention scope by: { 0, i−w ≤j ≤i+w L Mi,j = (9) −∞, otherwise (6) where ei is the i-th energy and d is the dimension of hidden state. The decoder is also composed of N identical layers and it contains a third sublayer, which performs attention over the output of the encoder between the self-attention sublayer and feed-forward network sublayer. 3 Proposed Architecture Our proposed approach is mainly motivated by the fact that redundancy has occurred in multiheads (Voita et al., 201"
E03-1023,P98-1041,0,0.330025,"Missing"
E03-1023,P98-1069,0,0.399756,"lingual term correspondence corrEj(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English term t E in CCE and each Japanese term tj in CCj, occurrences of surrounding wor"
E03-1023,W95-0114,0,0.0228852,"nally, for every pair of an English term t E and a Japanese term t J , bilingual term correspondence corrEj(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English"
E03-1023,C96-1006,0,0.107453,"an English term t E and a Japanese term t J , bilingual term correspondence corrEj(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English term t E in CCE and each Japanese"
E03-1023,P95-1050,0,0.0567641,"very pair of an English term t E and a Japanese term t J , bilingual term correspondence corrEj(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English term t E in"
E03-1023,P99-1067,0,0.713591,"ondence corrEj(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English term t E in CCE and each Japanese term tj in CCj, occurrences of surrounding words are recor"
E03-1023,C96-2098,0,0.0286341,"d a Japanese term t J , bilingual term correspondence corrEj(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English term t E in CCE and each Japanese term tj in CCj, occurrence"
E03-1023,C02-1065,0,0.0494882,"Ej(tE,Q) is estimated in terms of a certain similarity measure sim(cv (tE, CCE ), cv (tj, CCJ)) between contextual vectors cv(tE, CCE) and cv(tj, CCJ): 2 Acquisition of Bilingual Term Correspondences from Comparable Corpora 3 Acquisition of Bilingual Term Correspondences from CrossLingually Relevant Texts Previously studied techniques of estimating bilingual term correspondences from comparable corpora are mostly based on the idea that semantically similar words appear in similar contexts (Fung, 1995; Rapp, 1995; Kaji and Aizono, 1996; Tanaka and Iwasaki, 1996; Fung and Yee, 1998; Rapp, 1999; Tanaka, 2002). In those techniques, frequency information of contextual words cooccurring in the monolingual text is stored and their similarity is measured across languages. The following gives a rough formalization of the previous approaches to acquiring bilingual term correspondences from comparable corpora. Suppose that CCE and CCj denote an English corpus and a Japanese corpus, respectively, and that they can be considered as comparable corpora. Then, in the previous approaches, for each English term t E in CCE and each Japanese term tj in CCj, occurrences of surrounding words are recorded in the form"
E03-1023,utsuro-etal-2002-semi,1,0.891247,"Missing"
E03-1023,C98-1066,0,\N,Missing
E03-1023,C98-1041,0,\N,Missing
E06-1029,W04-0404,0,0.219756,"ated as follows: H (s ∨ x ) = H (s ) + H ( x ) − H (s ∧ x ) Candidates that have a high enough coefficient are considered related terms of the seed. 3 Term Alignment Once we have collected related terms in both French and Japanese, we must link the terms in the source language to the terms in the target language. Our alignment procedure is twofold. First, we first generate Japanese translation candidates for each collected French term. Second, we select the most likely translation(s) from the set of candidates. This is similar to the generation and selection procedures used in the literature (Baldwin and Tanaka (2004), Cao and Li, Langkilde and Knight (1998)). 3.1 Translation Candidates Generation Translation candidates are generated using a compositional method, which can be divided in three steps. First, we decompose the French MWTs into combinations of shorter MWU elements. Second, we look up the elements in bilingual dictionaries. Third, we recompose translation candidates by generating different combinations of translated elements. Decomposition In accordance with Daille et al., we define the length of a MWU as the number of content words it contains. Let n be the length of the MWT to decompose. We pr"
E06-1029,C02-1011,0,0.0853173,"Missing"
E06-1029,C02-2020,0,0.57505,"Missing"
E06-1029,C94-1084,0,0.228628,"Missing"
E06-1029,I05-1062,0,0.18161,"Missing"
E06-1029,P95-1032,0,0.0967771,"Missing"
E06-1029,P98-1116,0,0.016069,"H ( x ) − H (s ∧ x ) Candidates that have a high enough coefficient are considered related terms of the seed. 3 Term Alignment Once we have collected related terms in both French and Japanese, we must link the terms in the source language to the terms in the target language. Our alignment procedure is twofold. First, we first generate Japanese translation candidates for each collected French term. Second, we select the most likely translation(s) from the set of candidates. This is similar to the generation and selection procedures used in the literature (Baldwin and Tanaka (2004), Cao and Li, Langkilde and Knight (1998)). 3.1 Translation Candidates Generation Translation candidates are generated using a compositional method, which can be divided in three steps. First, we decompose the French MWTs into combinations of shorter MWU elements. Second, we look up the elements in bilingual dictionaries. Third, we recompose translation candidates by generating different combinations of translated elements. Decomposition In accordance with Daille et al., we define the length of a MWU as the number of content words it contains. Let n be the length of the MWT to decompose. We produce all the combinations of MWU element"
E06-1029,P99-1067,0,0.691258,"Missing"
E06-1029,P03-2020,1,0.867567,"Missing"
E06-1029,W03-1803,0,0.101723,"Missing"
E06-1029,C02-1166,0,\N,Missing
E06-1029,C98-1112,0,\N,Missing
fujii-etal-2008-producing,P02-1040,0,\N,Missing
fujii-etal-2008-producing,P03-1010,1,\N,Missing
fujii-etal-2008-producing,fujii-etal-2006-test,1,\N,Missing
I05-2020,C02-1011,0,0.0674735,"ting bilingual lexicon in the same way as our proposed method. One of the major differences of the technique of (Fujii and Ishikawa, 2001) and the one proposed in this paper is that in (Fujii and Ishikawa, 2001), instead of the domain/topic specific corpus, they use a corpus of the collection of the technical papers, each of which is published by one of the 65 Japanese associations for various technical domains. Another important difference is that in (Fujii and Ishikawa, 2001), they evaluate only the performance of cross-language information retrieval but not that of translation estimation. (Cao and Li, 2002) proposed a method of com119 This paper proposed a method of compositional translation estimation for technical terms using the domain/topic specific corpus, and through the experimental evaluation, showed that the domain/topic specific corpus contributes to improving the performance of compositional translation estimation. Future works include the followings: first, in order to improve the proposed method with respect to its coverage, for example, it is desirable to extend the bilingual constituents lexicons and to introduce constituent reordering rules with prepositions into the process of c"
I05-2020,P98-1069,0,0.0614404,"nguage pair (S,T ) (language (languageSS)) translation candidates U M compiled bilingual lexicon XST , XST ,YST web web (language (languageTT)) collecting corpus (language T ) domain/topic specific corpus (language T ) Figure 1: Compilation of a Domain/Topic Specific Bilingual Lexicon 1 Introduction This paper studies issues on compiling a bilingual lexicon for technical terms. So far, several techniques of estimating bilingual term correspondences from a parallel/comparable corpus have been studied (Matsumoto and Utsuro, 2000). For example, in the case of estimation from comparable corpora, (Fung and Yee, 1998; Rapp, 1999) proposed standard techniques of estimating bilingual term correspondences from comparable corpora. In their techniques, contextual similarity between a source language term and its translation candidate is measured across the languages, and all the translation candidates are re-ranked according to the contextual similarities. However, 114 there are limited number of parallel/comparable corpora that are available for the purpose of estimating bilingual term correspondences. Therefore, even if one wants to apply those existing techniques to the task of estimating bilingual term cor"
I05-2020,P99-1067,0,0.0357271,"language (languageSS)) translation candidates U M compiled bilingual lexicon XST , XST ,YST web web (language (languageTT)) collecting corpus (language T ) domain/topic specific corpus (language T ) Figure 1: Compilation of a Domain/Topic Specific Bilingual Lexicon 1 Introduction This paper studies issues on compiling a bilingual lexicon for technical terms. So far, several techniques of estimating bilingual term correspondences from a parallel/comparable corpus have been studied (Matsumoto and Utsuro, 2000). For example, in the case of estimation from comparable corpora, (Fung and Yee, 1998; Rapp, 1999) proposed standard techniques of estimating bilingual term correspondences from comparable corpora. In their techniques, contextual similarity between a source language term and its translation candidate is measured across the languages, and all the translation candidates are re-ranked according to the contextual similarities. However, 114 there are limited number of parallel/comparable corpora that are available for the purpose of estimating bilingual term correspondences. Therefore, even if one wants to apply those existing techniques to the task of estimating bilingual term correspondences"
I05-2020,P03-2020,1,0.78364,"translation of those technical terms. Among those two issues, this paper focuses on the second issue of translation estimation of technical terms, and proposes a method for translation estimation for technical terms using a domain/topic specific corpus collected from the Web. More specifically, the overall framework of compiling a bilingual lexicon from the Web can be illustrated as in Figure 1. Suppose that we have sample terms of a specific domain/topic, technical terms to be listed as the headwords of a bilingual lexicon are collected from the Web by the related term collection method of (Sato and Sasaki, 2003). Those collected technical terms can be divided into three subsets according to the number of translation candidates they have in an existing bilingual lexicon, i.e., the subset XSU of terms for which the number of translations in the existing bilingual lexicon is one, the subset XSM of terms for which the number of translations is more than one, and the subset YS of terms which are not found in the existing bilingual lexicon. (Henceforth, the union XSU ∪ XSM is denoted as XS .) The translation estimation task here is to estimate translations for the terms of XSM and YS . For the terms of XSM"
I05-2020,C98-1066,0,\N,Missing
I13-1118,P12-1056,0,0.0635385,"Missing"
L16-1303,D11-1145,0,0.0423646,"e 3 and Figure 4, we also show optimal correlation coefficient between the actual market share statistics and the rates of concerns of those who search for Web pages, as well as between the actual page view statistics and the rates of concerns of those who search for Web pages, by simply selecting K and θ lbd which maximize those correlation coefficients. Those results show that the predicted statistics have comparatively high correlation against the actual statistics of market share and page view. 9. Related Work Related work include a technique of detecting influenza epidemics from Twitter (Aramaki et al., 2011) ，that of predicting stock market from sentiment analysis of Twitter (Bollen et al., 2011) ，that of predicting movie ranking based on Twitter analysis before the release of the movie (Asur and Huberman, 2010) ，and that of predicting stock market based on Wikipedia page view statistics (Moat et al., 2013). Those previous related methods predict changes in real world based on statistics available through Internet such as that of Twitter and Wikipedia page view. In the method proposed in this paper, on the other hand, it is shown that real world statistics such as market share within certain prod"
nagasaka-etal-2010-utilizing,W07-1109,1,\N,Missing
nagasaka-etal-2010-utilizing,P07-2045,0,\N,Missing
nagasaka-etal-2010-utilizing,Y09-2044,1,\N,Missing
nagasaka-etal-2010-utilizing,J03-1002,0,\N,Missing
nagasaka-etal-2010-utilizing,W06-2404,1,\N,Missing
nagasaka-etal-2010-utilizing,I08-2094,1,\N,Missing
narita-etal-2002-web,C94-1042,0,\N,Missing
narita-etal-2002-web,narita-2000-constructing,1,\N,Missing
P06-2046,W02-2016,0,0.0218485,"ku totally tat-anai stand-NEG Morphology & Dependency Analysis yaku / ni part DAT ··· Idiom Recognizer ··· tatu stand Dependency Matching Output yaku / ni / wa part DAT TOP yaku / ni / wa part DAT TOP mattaku totally mattaku totally tatu / nai stand NEG tatu / nai stand NEG Figure 4: Internal Working of the Idiom Recognizer Idiom Dictionary Idiom Recognizer Input Dependency Pattern Generator Morphology Analysis Dependency Analysis ChaSen CaboCha Pattern DB Dependency Matching TGrep2 Output Figure 5: Organization of the System As in Figure 5, we use ChaSen as a morphology analyzer and CaboCha (Kudo and Matsumoto, 2002) as a dependency analyzer. Dependency matching is performed by TGrep2 (Rohde, 2005), which finds syntactic patterns in a sentence or treebank. The dependency pattern is usually getting complicated since it is tailored to the specification of TGrep2. Thus, we developed the Dependency Pattern Generator that compiles the pattern database from a human-readable idiom dictionary. Only the difference in treatments of Class B and C lies in their dependency patterns. The dependency pattern of Class B consists of only its dependency knowledge, while that of Class C consists of not only its dependency kn"
P06-2046,W04-0405,0,0.0671537,"e) “get on track,” has a constituent, kidou, which is incorporated into a compound noun kaihuku-kidou “recovery track.” This is unexpected and cannot be handled by the current machinery. 5 Related Work There has been a growing awareness of Japanese MWE problems (Baldwin and Bond, 2002). However, few attempts have been made to recognize idioms in a sentence with their ambiguity and transformations taken into account. In fact, most of them only create catalogs of Japanese idiom: collecting idioms as many as possible and classifying them based on some general linguistic properties (Tanaka, 1997; Shudo et al., 2004). A notable exception is Oku (1990); his idiom recognizer takes the ambiguity and transformations into account. However, he only uses the Genitive Phrase Prohibition, the Detachment Constraint, and the Selectional Restriction, which would be too few to disambiguate idioms.17 As well, his classification does not take the recognition difficulty into account. This makes his idiom dictionary get bloated, since disambiguation knowledge is given to unambiguous idioms, too. Uchiyama et al. (2005) deals with disambiguating some Japanese verbal compounds. Though verbal compounds are not counted as idio"
P19-2030,N18-1118,0,0.032865,"p and 7-layer stacked vanilla Transformer ei Layers 4 4 5 5 6 6 7 7 (4) (5) First, MLP attention between the output of the (h) first hop, ai , and the query, Q, is calculated. Attention is considered as the calculation of a relationship between the query and the key/value. Therefore, in the second hop, attention is calculated again by using the output of the first hop, rather than the key/value. Equations 4 and 5 are head gate in Figure 1. The head gate normalizes the attention score of (h) each head to βi , using the softmax function, where h ranges over all heads. In hierarchical attention (Bawden et al., 2018), the softmax function is used to select a single source from multiple sources. Here, the proposed head gate uses the softmax function to select a head from multi3.2 Experimental Setup In our experiments, the baseline was the Transformer (Vaswani et al., 2017) model. We used 1 https://sites.google.com/site/ iwsltevaluation2017/ 2 http://www.statmt.org/wmt17/ translation-task.html 219 (a) All learning curve view (b) Enlarged view (loss 3.9 to 4.4) Figure 2: Validation loss by each epoch for IWSLT2017 de-en - second hop in layer n to 6 fairseq (Gehring et al., 2017) 3 toolkit and the source code"
P19-2030,P17-1055,0,0.0493162,"Missing"
P19-2030,N19-1423,0,0.0350455,"is well known that the Transformer is difficult to train (Popel and Bojar, 2018). As it has a large number of parameters, it takes time to converge and sometimes it does not do so at all without appropriate hyper parameter tuning. Considering the experimental results of our multi-hop attention experiments, and that of the Weight Transformer, an appropriate design of the network to combine multi-head attention could result in faster and more stable convergence of the Transformer. As the Transformer is used as a building block for the recently proposed pre-trained language models such as BERT (Devlin et al., 2019) which takes about a month for training, we think it is worthwhile to pursue this line of research including the proposed multi-hop attention. Universal Transformer (Dehghani et al., 2019) can be thought of variable-depth recurrent attention. It obtained Turing-complete expressive power in exchange for a vast increase in the number of parameters and training time. As shown in Table 4, we have proposed an efficient method to increase the depth of recurrence in terms of the number of parameters and training time. Recently, Voita et al. (2019) and Michel et al. (2019) independently reported that"
P19-2030,P17-2031,0,0.0810122,"Missing"
P19-2030,P16-1162,0,0.0856626,"tention and head gate, as shown in Figure 1 and the following equations. (h) 3 Experiment 3.1 Data (h) (h) = vbT tanh(Wb Q(h) + Ub ai ) (3) We used German-English parallel data obtained from the IWSLT2017 1 and the WMT17 2 shared tasks. The IWSLT2017 training, validation, and test sets contain approximately 160K, 7.3K, and 6.7K sentence pairs, respectively. There are approximately 5.9M sentence pairs in the WMT17 training dataset. For the WMT17 corpus, we used newstest2013 as the validation set and newstest2014 and newstest2017 as the test sets. For tokenization, we used the subword-nmt tool (Sennrich et al., 2016) to set a vocabulary size of 32,000 for both German and English. (h) (h) βi ′(h) ai = = exp(ei ) ∑N (h) n=1 exp(ei ) (h) (h) βi Uc(h) ai IWSLT2017 de→en en→de 40,747K 41,882K 40,763K 41,898K 48,103K 49,238K 48,120K 49,254K 55,459K 56,594K 55,492K 56.627K 62,816K 63,951K 62,833K 63,967K Table 4: Model Parameters Table 3: Difference between 6-layer Transformer with multi-hop and 7-layer stacked vanilla Transformer ei Layers 4 4 5 5 6 6 7 7 (4) (5) First, MLP attention between the output of the (h) first hop, ai , and the query, Q, is calculated. Attention is considered as the calculation of a re"
P93-1004,J90-2002,0,0.0344871,"Missing"
P93-1004,P91-1023,0,0.0926974,"Missing"
P93-1004,P87-1033,0,0.0198529,"Missing"
P93-1004,J93-1004,0,\N,Missing
P93-1004,C92-2088,1,\N,Missing
P93-1004,C90-3031,0,\N,Missing
P93-1004,C92-2101,0,\N,Missing
P93-1004,P91-1022,0,\N,Missing
P93-1004,P91-1017,0,\N,Missing
P93-1004,H91-1026,0,\N,Missing
P98-2214,J96-1002,0,0.0117505,"mited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and reported that dependencies were discovered only at the slotlevel and not at the class-level. Compared with these previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb and argum e n t / a d j u n c t nouns (section 2) and then view the model as a probability model (section 3). As a model learning method, we adopt the maximum entropy model learning method (Della Pietra et al., 1997; Berger et al., 1996). Case dependencies and noun class generalization are represented as features in the maximum entropy approach. Features are allowed to have overlap and this is quite advantageous when we consider case dependencies and noun class generalization in parameter estimation. An optimal model is selected by searching for an optimal set of features, i.e, optimal case dependencies and optimal noun class generalization levels. As the feature selection process, this paper proposes a new feature selection algorithm which starts from the most general model and gradually examines more specific models (sectio"
P98-2214,P96-1025,0,0.0273121,"ximum entropy modeling method. We also propose a new model selection algorithm which starts from the most general model and gradually examines more specific models. In the experimental evaluation, it is shown that both of the case dependencies and specific sense restriction selected by the proposed method contribute to improving the performance in subcategorization preference resolution. 1 Introduction In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis. For example, Magerman (1995), Collins (1996), and Charniak (1997) proposed statistical parsing models which incorporated lexical/semantic information. In their models, syntactic and lexical/semantic features are dependent on each other and are combined together. This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis. However, unlike the models of Magerman (1995), Collins (1996), and Charniak (1997), we assume that syntactic and lexical/semantic features are independent. Then, we focus on extracting lexical/semantic collocational knowledge of verbs"
P98-2214,C96-1004,0,0.018434,", 1998. An extended version of this paper is available from the above URL. 1314 dependent of other cases. When considering 2), we have to decide which superordinate class generates each observed leaf class in the verb-noun collocation. So far, there exist several works which worked on these two issues in learning collocational knowledge of verbs and also evaluated the results in terms of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argument noun in a tree-structured thesaurus. Their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and reported that dependencies were discovered only at the slotlevel and not at the class-level. Compared with these previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb and argum e n t / a d j u n c t nouns (section 2) and then view the model as a probability model (section 3). As a model learning method, we adopt the maximum entropy model learning method (Della Pietra et al., 1997; Berger et al., 1996). Case dependencies and n"
P98-2214,P95-1037,0,0.0117733,"employing the maximum entropy modeling method. We also propose a new model selection algorithm which starts from the most general model and gradually examines more specific models. In the experimental evaluation, it is shown that both of the case dependencies and specific sense restriction selected by the proposed method contribute to improving the performance in subcategorization preference resolution. 1 Introduction In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis. For example, Magerman (1995), Collins (1996), and Charniak (1997) proposed statistical parsing models which incorporated lexical/semantic information. In their models, syntactic and lexical/semantic features are dependent on each other and are combined together. This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis. However, unlike the models of Magerman (1995), Collins (1996), and Charniak (1997), we assume that syntactic and lexical/semantic features are independent. Then, we focus on extracting lexical/semantic collocational kn"
P98-2214,H93-1054,0,0.0333755,"re optional and in* This research was partially supported by the Ministry of Education, Science, Sports and Culture, Japan, Grantin-Aid for Encouragement of Young Scientists, 09780338, 1998. An extended version of this paper is available from the above URL. 1314 dependent of other cases. When considering 2), we have to decide which superordinate class generates each observed leaf class in the verb-noun collocation. So far, there exist several works which worked on these two issues in learning collocational knowledge of verbs and also evaluated the results in terms of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argument noun in a tree-structured thesaurus. Their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and reported that dependencies were discovered only at the slotlevel and not at the class-level. Compared with these previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb and argum e n t / a d j u n c t nouns (section 2) and then view the model a"
P98-2214,A97-1053,1,0.561477,"Missing"
P98-2214,J98-2002,0,\N,Missing
suzuki-etal-2012-detecting,W07-1109,1,\N,Missing
suzuki-etal-2012-detecting,Y09-2044,1,\N,Missing
suzuki-etal-2012-detecting,2011.mtsummit-wpt.10,1,\N,Missing
suzuki-etal-2012-detecting,nagasaka-etal-2010-utilizing,1,\N,Missing
utsuro-2000-learning,A00-2015,1,\N,Missing
utsuro-2000-learning,P98-1083,0,\N,Missing
utsuro-2000-learning,C98-1080,0,\N,Missing
utsuro-2000-learning,P96-1025,0,\N,Missing
utsuro-2000-learning,P94-1013,0,\N,Missing
utsuro-2000-learning,W98-1511,0,\N,Missing
utsuro-etal-2002-semi,C00-2159,0,\N,Missing
utsuro-etal-2002-semi,P98-1069,0,\N,Missing
utsuro-etal-2002-semi,C98-1066,0,\N,Missing
utsuro-etal-2002-semi,W01-1413,0,\N,Missing
utsuro-etal-2002-semi,C96-1089,0,\N,Missing
utsuro-sassano-2000-minimally,W98-1120,0,\N,Missing
utsuro-sassano-2000-minimally,W99-0621,0,\N,Missing
utsuro-sassano-2000-minimally,W98-1118,0,\N,Missing
utsuro-sassano-2000-minimally,C00-2102,1,\N,Missing
utsuro-sassano-2000-minimally,X96-1050,0,\N,Missing
utsuro-sassano-2000-minimally,P95-1026,0,\N,Missing
utsuro-sassano-2000-minimally,P94-1013,0,\N,Missing
utsuro-sassano-2000-minimally,W99-0612,0,\N,Missing
W02-1036,W98-1118,0,0.0604978,"Missing"
W02-1036,P98-1029,0,0.137114,"Missing"
W02-1036,W99-0623,0,0.0380812,"Missing"
W02-1036,A00-2005,0,0.0321499,"Missing"
W02-1036,C00-2102,1,0.899727,"Missing"
W02-1036,W98-1120,0,0.0805802,"Missing"
W02-1036,A00-2007,0,0.0360044,"Missing"
W02-1036,P00-1042,1,0.906528,"Missing"
W02-1036,P98-1081,0,0.0733585,"Missing"
W02-1036,P94-1013,0,0.124199,"Missing"
W02-1036,C98-1078,0,\N,Missing
W02-1036,C98-1029,0,\N,Missing
W04-2012,P02-1054,0,0.0551789,"Missing"
W04-2012,P03-2020,1,0.830248,"a conjunct query consisting of a keyword “Pyramid” and a choice, the choice with the maximum hits, i.e., “Canada” is not the correct answer “Egypt”. Why could not this question be solved? Let us consider the hits of the choices alone. The hits of the atomic query “Canada” is about seven times larger than the hits of the atomic query “Egypt”. With this observation, we can hypothesize that the hits of a conjunct query “Pyramid” and a choice are affected by the hits of the choice alone. Therefore some normalization might be required. Based on the analysis above, we employ the metrics proposed by Sato and Sasaki (2003). Sato and Sasaki (2003) has proposed two metrics for evaluating the strength of the relation of two terms. Suppose that X be the set of Summary • How many questions can be solved by this strategy based on keyword association. 3 Keyword Selection This section describes two methods for selecting appropriate keywords from a question sentence: one is based on the features of each word, the other based on hits of a search engine. First, all the nouns are extracted from the question sentence using a Japanese morphological analyzer JUMAN(Kurohashi and Nagao, 1999) and a Japanese parser KNP(Kurohashi"
W06-1407,N03-1013,0,0.0475382,"Missing"
W06-1407,J87-3006,0,0.168148,"Missing"
W06-1407,2003.mtsummit-systems.9,0,\N,Missing
W06-1703,I05-2012,0,0.0648574,"Missing"
W06-1703,P99-1067,0,0.0188498,"components in the scoring functions of compositional translation estimation. Through experimental evaluation, we show that the domain/topic-specific corpus contributes toward improving the performance of the compositional translation estimation. 1 Introduction This paper studies issues related to the compilation of a bilingual lexicon for technical terms. Thus far, several techniques of estimating bilingual term correspondences from a parallel/comparable corpus have been studied (Matsumoto and Utsuro, 2000). For example, in the case of estimation from comparable corpora, (Fung and Yee, 1998; Rapp, 1999) proposed standard techniques of estimating bilingual term correspondences from comparable corpora. In their techniques, contextual similarity between a source language term and its translation candidate is measured across the languages, and all the translation candidates are re-ranked according to their contextual similarities. However, there 11 process existing bilingual lexicon data sample terms of specific domain/topic (language S ) collecting terms of specific domain/topic (language S ) web web (language (languageSS)) term set (language S ) looking up bilingual lexicon XSU (# of translati"
W06-1703,P03-2020,1,0.810753,"exicon. The set of translations of the terms of the subset XSU is denoted as XTU . Then, in the second approach, the domain/topicspecific corpus is collected from the Web using the terms of the set XTU . 3 Compositional Translation Estimation for Technical Terms 2 Overall framework The overall framework of compiling a bilingual lexicon from the Web is illustrated as in Figure 1. Suppose that we have sample terms of a specific domain/topic, then the technical terms that are to be listed as the headwords of a bilingual lexicon are collected from the Web by the related term collection method of (Sato and Sasaki, 2003). These collected technical terms can be divided into three 3.1 Overview An example of compositional translation estimation for the Japanese technical term “応用行動分 析” is illustrated in Figure 2. First, the Japanese technical term “応用行動分析” is decomposed into its constituents by consulting an existing bilingual lexicon and retrieving Japanese head12  䋱䋮Decompose source term into constituents a ᔕ↪ • application(1) • practical(0.3) • applied(1.6) b ᔕ↪ • application(1) • practical(0.3) • applied(1.6) Generated translation candidates ⴕേ applied applied applied process 䋲䋮Translate constituents into t"
W06-1703,2003.mtsummit-papers.50,0,0.0310948,"Missing"
W06-1703,I05-2020,1,0.593725,"U (lang. T ) XSM (# of translations is more than one) YS (# of translations is zero) translation set (language T ) estimating bilingual term correspondences language pair (S,T ) compiled bilingual lexicon XSTU , XSTM ,YST validating translation candidates web web (language (languageTT)) collecting corpus (language T ) domain/topic specific corpus (language T ) web web (language (languageTT)) Figure 1: Compilation of a Domain/TopicSpecific Bilingual Lexicon using the Web before translation estimation, then generated translation candidates are validated against the domain/topic-specific corpus (Tonoike et al., 2005). The first approach is preferable in terms of coverage, while the second is preferable in terms of computational efficiency. This paper mainly focuses on quantitatively comparing the two approaches in terms of coverage and precision of compositional translation estimation. More specifically, in compositional translation estimation, we decompose the scoring function of a translation candidate into two components: bilingual lexicon score and corpus score. In this paper, we examine variants for those components and define 9 types of scoring functions in total. Regarding the above mentioned two a"
W06-1703,C02-1011,0,0.0703861,"ain/topic-specific corpus is collected from the Web in advance and then generated translation candidates are validated against this corpus. ‘On-line’ indicates that translation candidates are directly validated through the search engine. Roughly speaking, the scoring function ‘A’ corresponds to a variant of the model proposed by (Fujii and Ishikawa, 2001). The scoring function ‘D’ is a variant of the model proposed by (Tonoike et al., 2005) and ‘E’ corresponds to the bilingual lexicon score of the scoring function ‘D’. The scoring function ‘I’ is intended to evaluate the approach proposed in (Cao and Li, 2002). Corpus Score Qcorpus(yt ) = P (t1 ) · prune corpus on-line (search engine) Variation of the total scoring functions 10 fB (s, t) 3.3.3 (11) • Occurrence: whether a translation candidate occurs in a target language corpus or not ⎧ ⎪ ⎨1 Qcorpus (yt ) = 0 ⎪ ⎩ prune o o o o prune/final (s, t in Eijiro) (s, t in B) (9) Note that the frequency of a translation pair in Eijiro is regarded as 106 and fB (s, t) denotes the frequency of the translation pair s, t in the bilingual constituent lexicon B. fprob (s, t) = off-line prune/final fprob (s, t) denotes the frequency of the translatio"
W06-1703,P98-1069,0,0.372909,"ng variations of the components in the scoring functions of compositional translation estimation. Through experimental evaluation, we show that the domain/topic-specific corpus contributes toward improving the performance of the compositional translation estimation. 1 Introduction This paper studies issues related to the compilation of a bilingual lexicon for technical terms. Thus far, several techniques of estimating bilingual term correspondences from a parallel/comparable corpus have been studied (Matsumoto and Utsuro, 2000). For example, in the case of estimation from comparable corpora, (Fung and Yee, 1998; Rapp, 1999) proposed standard techniques of estimating bilingual term correspondences from comparable corpora. In their techniques, contextual similarity between a source language term and its translation candidate is measured across the languages, and all the translation candidates are re-ranked according to their contextual similarities. However, there 11 process existing bilingual lexicon data sample terms of specific domain/topic (language S ) collecting terms of specific domain/topic (language S ) web web (language (languageSS)) term set (language S ) looking up bilingual lexicon XSU (#"
W06-1703,H05-1061,0,0.108985,"Missing"
W06-1703,C98-1066,0,\N,Missing
W06-1703,W01-1413,0,\N,Missing
W06-1703,J98-4003,0,\N,Missing
W06-2404,N01-1025,0,0.0932704,"Missing"
W06-2404,W03-0429,0,0.0467726,"Missing"
W06-2404,W99-0502,0,0.0173432,"Missing"
W06-2404,W04-0405,0,0.196948,"Missing"
W06-2404,E99-1023,0,0.0382977,"Missing"
W06-2404,J96-2004,0,\N,Missing
W07-1109,N01-1025,0,0.0456221,"g to their grammatical functions, those 337 expressions in total are roughly classified into post-positional particle type, and auxiliary verb type. Functional expressions of post-positional particle type are further classified into three subtypes: i) conjunctive particle types, which are used for constructing subordinate clauses, ii) case-marking particle types, iii) adnominal particle types, which are used for constructing adnominal This section describes summaries of formalizing the chunking task using SVMs (Tsuchiya et al., 2006). In this paper, we use an SVMs-based chunking tool YamCha8 (Kudo and Matsumoto, 2001). In the SVMs-based chunking framework, SVMs are used as classifiers for assigning labels for representing chunks to each token. In our task of chunking Japanese compound functional expressions, each 7 Compound functional expressions of auxiliary verb types can be regarded as syntactically-flexible expressions. 8 http://chasen.org/˜taku/software/ yamcha/ 68 3 Identifying Compound Functional Expressions by Chunking with SVMs sentence is represented as a sequence of morphemes, where a morpheme is regarded as a token. formation on the candidate compound functional expression at i-th position. 3.1"
W07-1109,W02-2016,0,0.35662,"dependency relations. We formalize the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem (Tsuchiya et al., 2006). We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking. Next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (Kudo and Matsumoto, 2002), which is simple and efficient because it parses a sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its immediate right hand side. As we showed in Figure 1, identifying compound functional expressions before analyzing dependencies in a sentence does actually help deciding dependency relations of compound functional expressions. In the experimental evaluation, we focus on 59 expressions having balanced distribution of their usages in the newspaper text corpus and are among the most difficult ones in terms of their identification in a text. We fi"
W07-1109,W04-0405,0,0.226963,"Missing"
W07-1109,W06-2404,1,0.90456,"ency analysis bunsetsu segment compound functional expression dependency relation Figure 2: Overall Flow of Processing Compound Functional Expressions in a Japanese Sentence lustrated in Figure 2. First of all, we assume a sequence of morphemes obtained by a variant of ChaSen with all the compound functional expressions removed from its outputs, as an input to our procedure of identifying compound functional expressions and analyzing their dependency relations. We formalize the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem (Tsuchiya et al., 2006). We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking. Next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (Kudo and Matsumoto, 2002), which is simple and efficient because it parses a sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its"
W15-3408,Y11-1021,1,0.467246,"Missing"
W15-3408,P13-1040,0,0.0576258,"Missing"
W15-3408,P98-1069,0,0.296067,"Missing"
W15-3408,Y09-2038,0,0.0379834,"Missing"
W15-3408,H05-1061,0,0.104242,"Missing"
W15-3408,P07-2045,0,0.00380345,"Missing"
W15-3408,2008.amta-papers.14,1,0.803484,"Missing"
W15-3408,E14-4022,0,0.030874,"Missing"
W15-3408,W14-1016,0,0.0433181,"Missing"
W15-3408,W06-1703,1,0.855102,"Missing"
W15-3408,I05-3027,0,0.0395262,"Missing"
W15-3408,I08-1060,0,0.0291023,"Missing"
W15-3408,2007.mtsummit-papers.63,0,0.125477,"Missing"
W15-3408,C98-1066,0,\N,Missing
W16-4602,D14-1179,0,0.0424234,"Missing"
W16-4602,P16-2058,0,0.0454148,"Missing"
W16-4602,D10-1092,0,0.0704799,"Missing"
W16-4602,D13-1176,0,0.250377,"Missing"
W16-4602,P07-2045,0,0.00912197,"Missing"
W16-4602,P16-1100,0,0.047721,"Missing"
W16-4602,D15-1166,0,0.118126,"Missing"
W16-4602,P15-1002,0,0.13181,"Missing"
W16-4602,W15-5001,0,0.169769,"Missing"
W16-4602,P02-1040,0,0.0939337,"Missing"
W16-4602,P16-1162,0,0.183067,"Missing"
W16-4602,I05-3027,0,0.132577,"Missing"
W16-4602,2007.mtsummit-papers.63,0,0.16184,"Missing"
W17-5709,P16-1100,0,0.0126767,"rge vocabulary in an NMT system. Luong et al. (2015b) proposed annotating the occurrences of the out-of-vocabulary token in the target sentence with positional information to track its alignments, after which they replace the tokens with their translations using simple word dictionary lookup or identity copy. Li et al. (2016) proposed replacing out-of-vocabulary words with similar in-vocabulary words based on a similarity model learnt from monolingual data. Sennrich et al. (2016) introduced an effective approach based on encoding rare and out-of-vocabulary words as sequences of subword units. Luong and Manning (2016) provided a character-level and word-level hybrid NMT model to achieve an open vocabulary, and Costa-juss`a and Fonollosa (2016) proposed an NMT system that uses character-based embeddings. 110 Proceedings of the 4th Workshop on Asian Translation, pages 110–118, c Taipei, Taiwan, November 27, 2017. 2017 AFNLP Figure 1: Example of translation errors when translating patent sentences with technical terms using NMT However, these previous approaches have limitations when translating patent sentences. This is because their methods only focus on addressing the problem of out-of-vocabulary words eve"
W17-5709,D15-1166,0,0.481855,"-English patent datasets. Evaluation on Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching entropy, where the NMT model of Long et al. (2017) achieves a substantial improvement over a baseline NMT model without the technique proposed by Long et al. (2017). 1 Introduction Neural machine translation (NMT), a new approach to solving machine translation, has achieved promising results (Bahdanau et al., 2015; Cho et al., 2014; Jean et al., 2014; Kalchbrenner and Blunsom, 2013; Luong et al., 2015a,b; Sutskever et al., 2014). An NMT system builds a simple large neural network that reads Mikio Yamamoto Grad. Sc. Sys. & Inf. Eng., University of Tsukuba, Tsukuba, 305-8573, Japan the entire input source sentence and generates an output translation. The entire neural network is jointly trained to maximize the conditional probability of the correct translation of a source sentence with a bilingual corpus. Although NMT offers many advantages over traditional phrase-based approaches, such as a small memory footprint and simple decoder implementation, conventional NMT is limited when it comes t"
W17-5709,P15-1002,0,0.237435,"-English patent datasets. Evaluation on Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching entropy, where the NMT model of Long et al. (2017) achieves a substantial improvement over a baseline NMT model without the technique proposed by Long et al. (2017). 1 Introduction Neural machine translation (NMT), a new approach to solving machine translation, has achieved promising results (Bahdanau et al., 2015; Cho et al., 2014; Jean et al., 2014; Kalchbrenner and Blunsom, 2013; Luong et al., 2015a,b; Sutskever et al., 2014). An NMT system builds a simple large neural network that reads Mikio Yamamoto Grad. Sc. Sys. & Inf. Eng., University of Tsukuba, Tsukuba, 305-8573, Japan the entire input source sentence and generates an output translation. The entire neural network is jointly trained to maximize the conditional probability of the correct translation of a source sentence with a bilingual corpus. Although NMT offers many advantages over traditional phrase-based approaches, such as a small memory footprint and simple decoder implementation, conventional NMT is limited when it comes t"
W17-5709,D14-1179,0,0.0303844,"Missing"
W17-5709,W17-5701,0,0.0623668,"Missing"
W17-5709,P16-2058,0,0.0286737,"Missing"
W17-5709,W15-5001,0,0.375396,"2 compares the NMT model with the PosUnk model, which is the best model proposed by Luong et al. (2015b) The NMT model of Long et al. (2017) achieves performance gains of 0.9 BLEU points when translating Japanese into Chinese, and performance gains of 0.6 BLEU points when translating Chinese into Japanese. The NMT model of Long et al. (2017) achieves performance gains of 0.4 BLEU points when translating Japanese into English, and performance gains of 0.5 BLEU points when translating English into Japanese In this study, we also conducted two types of human evaluations according to the work of Nakazawa et al. (2015): pairwise evaluation and JPO adequacy evaluation. In the pairwise evaluation, we compared each translation produced by the baseline NMT with that produced by the NMT model of Long et al. (2017) as well as the NMT model with PosUnk model, and judged which translation is better or whether they have Table 4: Human evaluation results of JPO adequacy evaluation System ja → ch ch → ja ja → en Baseline SMT (Koehn et al., 2007) 3.1 3.2 2.9 Baseline NMT 3.6 3.6 3.7 NMT with PosUnk model (Luong et al., 2015b) 3.8 3.9 3.9 NMT with phrase translation by SMT 4.1 4.1 4.2 (Long et al., 2017) Evaluation Auto"
W17-5709,W17-3206,0,0.0305224,"Missing"
W17-5709,P02-1040,0,0.099136,"et al., 2015b) 34.5 41.0 NMT with phrase translation by SMT 35.6 41.6 (Long et al., 2017) ja → en 28.0 43.1 43.5 en → ja 29.4 41.8 42.0 43.9 42.5 Table 3: Human evaluation results of pairwise evaluation System ja → ch ch → ja ja → en NMT with PosUnk model (Luong et al., 2015b) 13 12.5 9.5 NMT with phrase translation by SMT 23.5 22.5 15.5 (Long et al., 2017) machine. We compute the branching entropy using the frequency statistics from the training set. 5.3 Evaluation Results In this work, we calculated automatic evaluation scores for the translation results using a popular metrics called BLEU (Papineni et al., 2002). As shown in Table 2, we report the evaluation scores, using the translations by Moses (Koehn et al., 2007) as the baseline SMT and the scores using the translations produced by the baseline NMT system without the approach proposed by Long et al. (2017) as the baseline NMT. As shown in Table 2, the BLEU score obtained by the NMT model of Long et al. (2017) is clearly higher than those of the baselines. Here, as described in Section 3, the lower bounds of branching entropy for phrase pair selection are tuned as 5 throughout the evaluation of language pair of JapaneseChinese, and tuned as 8 thr"
W17-5709,P16-1162,0,0.252181,"abulary limitation of NMT systems. Jean et al. (2014) provided an efficient approximation to the softmax function to accommodate a very large vocabulary in an NMT system. Luong et al. (2015b) proposed annotating the occurrences of the out-of-vocabulary token in the target sentence with positional information to track its alignments, after which they replace the tokens with their translations using simple word dictionary lookup or identity copy. Li et al. (2016) proposed replacing out-of-vocabulary words with similar in-vocabulary words based on a similarity model learnt from monolingual data. Sennrich et al. (2016) introduced an effective approach based on encoding rare and out-of-vocabulary words as sequences of subword units. Luong and Manning (2016) provided a character-level and word-level hybrid NMT model to achieve an open vocabulary, and Costa-juss`a and Fonollosa (2016) proposed an NMT system that uses character-based embeddings. 110 Proceedings of the 4th Workshop on Asian Translation, pages 110–118, c Taipei, Taiwan, November 27, 2017. 2017 AFNLP Figure 1: Example of translation errors when translating patent sentences with technical terms using NMT However, these previous approaches have limi"
W17-5709,P06-2056,0,0.0319852,"the problem of the under-translation. (from xN to x1 ) , resulting in a sequence of backward hidden states. The decoder then predicts target words using not only a recurrent hidden state and the previously predicted word but also a context vector as followings: p(yz |y<z , x) = g(yz−1 , sz−1 , cz ) 3.2 where sz−1 is an LSTM hidden state of decoder, and cz is a context vector computed from both of the forward hidden states and backward hidden states, for 1 ≤ z ≤ M . 3 Phrase Pair Selection using Branching Entropy Branching entropy has been applied to the procedure of text segmentation (e.g., (Jin and Tanaka-Ishii, 2006)) and key phrases extraction (e.g., (Chen et al., 2010)). In this work, we use the left/right branching entropy to detect the boundaries of phrases, and thus select phrase pairs automatically. 3.1 Branching Entropy The left branching entropy and right branching entropy of a phrase w are respectively defined as  Hl (w) = − pl (v) log 2 pl (v) w v∈Vl  Hr (w) = − pr (v) log2 pr (v) v∈Vrw where w is the phrase of interest (e.g., “ / ” in the Japanese sentence shown in Figure 1, which means “bridge interface”), Vlw is a set of words that are adjacent to the left of w (e.g., “ ” in Figure 1, which"
W17-5709,D13-1176,0,0.0575336,"17 Japanese-Chinese and Japanese-English patent datasets. Evaluation on Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching entropy, where the NMT model of Long et al. (2017) achieves a substantial improvement over a baseline NMT model without the technique proposed by Long et al. (2017). 1 Introduction Neural machine translation (NMT), a new approach to solving machine translation, has achieved promising results (Bahdanau et al., 2015; Cho et al., 2014; Jean et al., 2014; Kalchbrenner and Blunsom, 2013; Luong et al., 2015a,b; Sutskever et al., 2014). An NMT system builds a simple large neural network that reads Mikio Yamamoto Grad. Sc. Sys. & Inf. Eng., University of Tsukuba, Tsukuba, 305-8573, Japan the entire input source sentence and generates an output translation. The entire neural network is jointly trained to maximize the conditional probability of the correct translation of a source sentence with a bilingual corpus. Although NMT offers many advantages over traditional phrase-based approaches, such as a small memory footprint and simple decoder implementation, conventional NMT is lim"
W17-5709,P16-1008,0,0.0312643,"Missing"
W17-5709,P07-2045,0,0.0574417,"airs, which are 35,544 types of phrase pairs with unique 34,569 types of Japanese phrases and 35,087 unique types of English phrases. Within the total 2,000 Japanese patent sentences in the Japanese-English test set, 249 occurrences of Japanese phrases were extracted, which correspond to 221 types. With the total 2,000 English patent sentences in the 114 Japanese-English test set, 246 occurrences of English phrases were extracted, which correspond to 230 types. 5.2 Training Details For the training of the SMT model, including the word alignment and the phrase translation table, we used Moses (Koehn et al., 2007), a toolkit for phrase-based SMT models. We trained the SMT model on the training set and tuned it with the validation set. For the training of the NMT model, our training procedure and hyperparameter choices were similar to those of Bahdanau et al. (2015). The encoder consists of forward and backward deep LSTM neural networks each consisting of three layers, with 512 cells in each layer. The decoder is a three-layer deep LSTM with 512 cells in each layer. Both the source vocabulary and the target vocabulary are limited to the 40K most-frequently used morphemes / words in the training set. The"
W17-5709,W16-4602,1,0.438577,"have limitations when translating patent sentences. This is because their methods only focus on addressing the problem of out-of-vocabulary words even though the words are parts of technical terms. It is obvious that a technical term should be considered as one word that comprises components that always have different meanings and translations when they are used alone. An example is shown in Figure 1, where the Japanese word “ ”(bridge) should be translated to Chinese word “ ” when included in technical term “bridge interface”; however, it is always translated as “ ”. To address this problem, Long et al. (2016) proposed extracting compound nouns as technical terms and replacing them with tokens. Long et al. (2017) proposed to select phrase pairs using the statistical approach of branching entropy; this allows the proposed technique to be applied to the translation task on any language pair without needing specific language knowledge to formulate the rules for technical term identification. In this paper, we apply the method proposed by Long et al. (2017) to the WAT 2017 Japanese-Chinese and Japanese-English patent datasets. On the WAT 2017 Japanese-Chinese JPO patent dataset, the NMT model of Long e"
W18-3721,W17-5050,0,0.0477122,"Missing"
W19-6616,W17-3206,0,0.0216436,"1 , x0 ), . . . , y022 (x±5 , x0 ), we select the translation that yields the highest 3 In the evaluation discussed in Section 7.1, forced backtranslation using the 1-to-1 model achieved merely the same BLEU scores as that of the 2-to-1 model. Dublin, Aug. 19-23, 2019 |p. 166 forced back-translation probability B when backtranslating into the source sentence x0 as below:   (i = 0)  B x0 , y011 (x0 )  argmax  0) B x0 , yi22 (xi , x0 ), (i =  i=0,±1,...,±5 y022 (xi , x0 ) Employing the forced back-translation probability differs from existing approaches (Rapp, 2009; Li and Jurafsky, 2016; Goto and Tanaka, 2017; Kimura et al., 2017) that incorporate backtranslation from the translated target sentence to the source sentence. Rapp (2009) employed the BLEU score between the source sentence and source language sentence back-translated from the target translated sentence in an automatic MT evaluation context. Li and Jurafsky (Li and Jurafsky, 2016) proposed to re-rank decoded translations based on mutual information between source and target sentences x and y i.e., the probabilities p(y |x) and p(x |y). Goto and Tanaka (2017) and Kimura et al. (2017) also employed the ratio of forced back-translation pro"
W19-6616,P17-4012,0,0.0260002,"ion 5 when back-translating y022 (xi , x0 ) (i = 0, i.e., translated from x0 with a context sentence by the 2-to-2 model ). 6 In training and development, the encoder rejects input sentences (source sentence concatenated with the context sentence for the 2-to-2 models) with greater than 50 tokens. Average token length of the 10,000 pairs for oracle statistics and evaluation is 7.9 (English) and 6.9 (Japanese). 7 Experimental setup is as follows: Tokenizers are Moses tokenizer (Koehn et al., 2007) for English and MeCab ( http://taku910.github.io/mecab/ ) for Japanese tokenization. OpenNMT-py (Klein et al., 2017) is used for training and testing NMT models. 50,000 vocabulary sizes are employed for both English and Japanese. Embedding sizes are 512. Encoder and decoder are with six layers with batch size as 4,096 and dropout rate as 0.3 and 100,000 steps for training. Adam optimizer (Kingma and Ba, 2015) is used. One NVIDIA Tesla P100 16GB GPU is used. MTEval Toolkit ( https://github.com/odashi/mteval ) is used to measure BLEU, and Moses decoder’s sentence-bleu.cpp is used to measure sentence-BLEU. Dublin, Aug. 19-23, 2019 |p. 167 with the maximum sentence-BLEU score among the candidate translations af"
W19-6616,P07-2045,0,0.00664312,"(x0 ) (i = 0), while we used the 2-to-1 Transformer model (denoted as back-tran21 ) with the setup described in section 5 when back-translating y022 (xi , x0 ) (i = 0, i.e., translated from x0 with a context sentence by the 2-to-2 model ). 6 In training and development, the encoder rejects input sentences (source sentence concatenated with the context sentence for the 2-to-2 models) with greater than 50 tokens. Average token length of the 10,000 pairs for oracle statistics and evaluation is 7.9 (English) and 6.9 (Japanese). 7 Experimental setup is as follows: Tokenizers are Moses tokenizer (Koehn et al., 2007) for English and MeCab ( http://taku910.github.io/mecab/ ) for Japanese tokenization. OpenNMT-py (Klein et al., 2017) is used for training and testing NMT models. 50,000 vocabulary sizes are employed for both English and Japanese. Embedding sizes are 512. Encoder and decoder are with six layers with batch size as 4,096 and dropout rate as 0.3 and 100,000 steps for training. Adam optimizer (Kingma and Ba, 2015) is used. One NVIDIA Tesla P100 16GB GPU is used. MTEval Toolkit ( https://github.com/odashi/mteval ) is used to measure BLEU, and Moses decoder’s sentence-bleu.cpp is used to measure sen"
W19-6616,P09-2034,0,0.0401943,"e translations y011 (x0 ), y022 (x±1 , x0 ), . . . , y022 (x±5 , x0 ), we select the translation that yields the highest 3 In the evaluation discussed in Section 7.1, forced backtranslation using the 1-to-1 model achieved merely the same BLEU scores as that of the 2-to-1 model. Dublin, Aug. 19-23, 2019 |p. 166 forced back-translation probability B when backtranslating into the source sentence x0 as below:   (i = 0)  B x0 , y011 (x0 )  argmax  0) B x0 , yi22 (xi , x0 ), (i =  i=0,±1,...,±5 y022 (xi , x0 ) Employing the forced back-translation probability differs from existing approaches (Rapp, 2009; Li and Jurafsky, 2016; Goto and Tanaka, 2017; Kimura et al., 2017) that incorporate backtranslation from the translated target sentence to the source sentence. Rapp (2009) employed the BLEU score between the source sentence and source language sentence back-translated from the target translated sentence in an automatic MT evaluation context. Li and Jurafsky (Li and Jurafsky, 2016) proposed to re-rank decoded translations based on mutual information between source and target sentences x and y i.e., the probabilities p(y |x) and p(x |y). Goto and Tanaka (2017) and Kimura et al. (2017) also emp"
W19-6616,P15-4020,0,0.0524053,"Missing"
W19-6616,W17-4811,0,0.511817,"ral machine translation (NMT) models (Sutskever et al., 2014; Luong et al., 2015; c 2019 The authors. This article is licensed under a Creative  Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 Vaswani et al., 2017) have made remarkable progress. Most NMT models are designed to translate a single sentence and do not accept input greater than one sentence, i.e., input sentences that include additional context information. However, recently, several approaches that attempt to translate inputs with more than one sentence have been proposed (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Maruf and Haffari, 2018; Miculicich et al., 2018; Bawden et al., 2018; Voita et al., 2018; Tu et al., 2018). These approaches to context-based NMT models can be roughly categorized according to the width of the context considered in those models. A typical approach is to consider the sentence immediately preceding the source sentence to be translated as the context (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Bawden et al., 2018; Voita et al., 2018). Context-based NMT models can be further categorized according to whether the source and context sente"
W19-6616,Q18-1029,0,0.287154,"mons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 Vaswani et al., 2017) have made remarkable progress. Most NMT models are designed to translate a single sentence and do not accept input greater than one sentence, i.e., input sentences that include additional context information. However, recently, several approaches that attempt to translate inputs with more than one sentence have been proposed (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Maruf and Haffari, 2018; Miculicich et al., 2018; Bawden et al., 2018; Voita et al., 2018; Tu et al., 2018). These approaches to context-based NMT models can be roughly categorized according to the width of the context considered in those models. A typical approach is to consider the sentence immediately preceding the source sentence to be translated as the context (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Bawden et al., 2018; Voita et al., 2018). Context-based NMT models can be further categorized according to whether the source and context sentences are encoded using a single (Tiedemann and Scherrer, 2017) or multiple encoders (Libovick´y and Helcl, 2017; Bawden et al., 2018; Voi"
W19-6616,P18-1117,0,0.0656541,"der a Creative  Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 Vaswani et al., 2017) have made remarkable progress. Most NMT models are designed to translate a single sentence and do not accept input greater than one sentence, i.e., input sentences that include additional context information. However, recently, several approaches that attempt to translate inputs with more than one sentence have been proposed (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Maruf and Haffari, 2018; Miculicich et al., 2018; Bawden et al., 2018; Voita et al., 2018; Tu et al., 2018). These approaches to context-based NMT models can be roughly categorized according to the width of the context considered in those models. A typical approach is to consider the sentence immediately preceding the source sentence to be translated as the context (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Bawden et al., 2018; Voita et al., 2018). Context-based NMT models can be further categorized according to whether the source and context sentences are encoded using a single (Tiedemann and Scherrer, 2017) or multiple encoders (Libovick´y and Helcl, 2017; Bawden"
W19-6616,D17-1018,0,0.0227174,"Missing"
W19-6616,P17-2031,0,0.0699766,"Missing"
W19-6616,L18-1275,0,0.0875507,"Missing"
W19-6616,D15-1166,0,0.121673,"d. Experimental results with Japanese and English parallel sentences from the OpenSubtitles2018 corpus demonstrate that, when the context length of ﬁve preceding and ﬁve subsequent sentences are examined, the proposed approach achieved signiﬁcant improvements of 0.74 (Japanese to English) and 1.14 (English to Japanese) BLEU scores compared to the baseline 2-to-2 model, where the oracle translation achieved upper bounds improvements of 5.88 (Japanese to English) and 9.10 (English to Japanese) BLEU scores. 1 Introduction Recently, neural machine translation (NMT) models (Sutskever et al., 2014; Luong et al., 2015; c 2019 The authors. This article is licensed under a Creative  Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 Vaswani et al., 2017) have made remarkable progress. Most NMT models are designed to translate a single sentence and do not accept input greater than one sentence, i.e., input sentences that include additional context information. However, recently, several approaches that attempt to translate inputs with more than one sentence have been proposed (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Maruf and Haffari, 201"
W19-6616,P18-1118,0,0.287562,"14; Luong et al., 2015; c 2019 The authors. This article is licensed under a Creative  Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 Vaswani et al., 2017) have made remarkable progress. Most NMT models are designed to translate a single sentence and do not accept input greater than one sentence, i.e., input sentences that include additional context information. However, recently, several approaches that attempt to translate inputs with more than one sentence have been proposed (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Maruf and Haffari, 2018; Miculicich et al., 2018; Bawden et al., 2018; Voita et al., 2018; Tu et al., 2018). These approaches to context-based NMT models can be roughly categorized according to the width of the context considered in those models. A typical approach is to consider the sentence immediately preceding the source sentence to be translated as the context (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Bawden et al., 2018; Voita et al., 2018). Context-based NMT models can be further categorized according to whether the source and context sentences are encoded using a single (Tiedemann and Scherr"
W19-6616,D18-1325,0,0.155944,"2019 The authors. This article is licensed under a Creative  Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 Vaswani et al., 2017) have made remarkable progress. Most NMT models are designed to translate a single sentence and do not accept input greater than one sentence, i.e., input sentences that include additional context information. However, recently, several approaches that attempt to translate inputs with more than one sentence have been proposed (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Maruf and Haffari, 2018; Miculicich et al., 2018; Bawden et al., 2018; Voita et al., 2018; Tu et al., 2018). These approaches to context-based NMT models can be roughly categorized according to the width of the context considered in those models. A typical approach is to consider the sentence immediately preceding the source sentence to be translated as the context (Tiedemann and Scherrer, 2017; Libovick´y and Helcl, 2017; Bawden et al., 2018; Voita et al., 2018). Context-based NMT models can be further categorized according to whether the source and context sentences are encoded using a single (Tiedemann and Scherrer, 2017) or multiple enc"
W19-7203,N18-1118,0,0.0171848,"n the proposed multi-hop attention mechanism. In evaluation, we compared the performance of the proposed method with Transformer and RNN encoder-decoder using OpenSubtitles 2018 (Lison et al., 2018) and Asian Scientific Paper Excerpt Corpus (ASPEC) (Nakazawa et al., 2016). To test the power of translating long sentences, we also Dublin, Aug. 20, 2019 |p. 24 (a) Baseline RNN-based model (b) Multi-head RNN model (c) Hierarchical attention model (d) Proposed method: Multi-hop attention model Figure 1: Baseline attention and proposed attention made a context-aware translation model, called 2to-2 (Bawden et al., 2018; Tiedemann and Scherrer, 2017) for OpenSubtitles 2018. In the Japaneseto-English translation of the ASPEC corpus, the proposed method achieved a significantly better score than the Transformer for long sentences with more than 120 tokens. In the following sections, we first show previous works on baseline RNN and multi-head RNN encoder-decoders in Section 2. We then describe the proposed multi-hop method in Section 3. We then show the performance for Japanese-toEnglish and English-to-Japanese translation tasks, focusing on long sentences in Section 4. 2 Neural Machine Translation 2.1 RNN base"
W19-7203,P18-1008,0,0.0315345,"ni et al., 2017) is used to calcu(k) late the context vector ci between k-th head of a (k) decoder state si and encoder states H. When the model has two heads (N = 2), the equation (1) and the equation (2) becomes as follows. si (1) = Wa(1) di (3) (2) si = Wa(2) di (4) (1) (1) = sof tmax(si H T )H (5) (2) ci (2) sof tmax(si H T )H (6) ci = Dublin, Aug. 20, 2019 |p. 25 Figure 2: Proposed method detail As shown in the equation (5) and the equation (6), by using multiple parallel attention via the param(k) eters Wa , we expect that each head will attend to a different part of the encoder states. Chen et al. (2018) attempted to incorporate the various mechanisms of the Transformer into RNN encoder-decoder. They used multi-head attention as shown in Figure 1(b) in source-target attention. Our method becomes the same as their method when we use single-hop attention. 3 Multi-Hop Attention RNN 3.1 Multi-Hop Dependent Attention To the best of our knowledge, multi-hop attention is first used in end-to-end memory network (Sukhbaatar et al., 2015) to extend the expressive power of RNN. To introduce multi-hop attention into translation, we refer to hierarchical attention (Libovick´y and Helcl, 2017) in multimoda"
W19-7203,N19-1423,0,0.0143468,"i-hop independent attention) Proposed Method (multi-hop dependent attention) Transformer 5 head 1 2 3 hop 1 1 1 Parameter 68,460,544 70,557,696 72,654,848 2 2 72,654,848 2 2 3 3 4 2 3 2 3 1 75,800,576 81,043,456 79,994,880 87,334,912 81,604,608 Related Works Dehghani et al. (2019) proposed Universal Transformer for solving the problems of Transformer including the weakness for long distance dependency. Although it has a mechanism to repeat updating the states for each word with parameters shared, it requires a larger number of parameters than Transformer. There could be an approach like BERT (Devlin et al., 2019) where the number of parameters is increased significantly to make a more powerful Transformer model. Our approach, on the other hand, improves the strength of RNN with a little increase of parameters as shown in Table 5. Moreover, Iida et al. (2019) also applied the multi-hop attention mechanism to the Transformer and reported that the Transformer augmented with the multi-hop attention mechanism significantly outperformed the Transformer. Among other existing approaches to neural machine translation, it is known that ConvS2S (Gehring et al., 2017) is equipped with multiple decoder layers wher"
W19-7203,W18-6412,0,0.0192606,"the N context vectors ci with the RNN decoder state di to obtain the prediction of the output word distribution p(yi |yi−1 , X) where Wo is a learnable parameter. ′(1) ′(k) ]) (16) p(yi |yi−1 , X) = sof tmax(oi ) (17) oi = tanh(Wo [di ; ci ; ...; ci When the number of heads N is 2, equation (16) becomes the following: ′(1) ′(2) oi = tanh(Wo [di ; ci ; ci ]) (18) 3.2 Multi-Hop Independent Attention In the multi-hop dependent attention described in the previous subsection, we use the information of other heads and share parameters of MLP attention (Wb and vb ) over all heads (equation (7)) to 1 Haddow et al. (2018) evaluated a similar multi-head and multi-hop attention mechanism, although Haddow et al. (2018) employed the vector concatenation over the multiple heads in stead of normalization. Haddow et al. (2018) also reported that the multi-head and multi-hop attention mechanism outperformed the baseline RNN model in the evaluation of the language pairs of CS-EN, EN-CS, ET-EN, EN-ET, FIEN, and EN-FI, where the length of the training sentences is limited to 50 words or less. In this paper, on the other hand, in the evaluation of the language pairs of JA-EN and EN-JA, the proposed multi-head and multi-ho"
W19-7203,P19-2030,1,0.830527,"Works Dehghani et al. (2019) proposed Universal Transformer for solving the problems of Transformer including the weakness for long distance dependency. Although it has a mechanism to repeat updating the states for each word with parameters shared, it requires a larger number of parameters than Transformer. There could be an approach like BERT (Devlin et al., 2019) where the number of parameters is increased significantly to make a more powerful Transformer model. Our approach, on the other hand, improves the strength of RNN with a little increase of parameters as shown in Table 5. Moreover, Iida et al. (2019) also applied the multi-hop attention mechanism to the Transformer and reported that the Transformer augmented with the multi-hop attention mechanism significantly outperformed the Transformer. Among other existing approaches to neural machine translation, it is known that ConvS2S (Gehring et al., 2017) is equipped with multiple decoder layers where each decoder layer has a separate attention module. The attention of each of those multiple layers is computed and is then fed to another layer, which then takes the fed information into account when computing its own attention etc. The way those m"
W19-7203,P07-2045,0,0.0122451,"ed so as to keep the total number of word tokens within each subset as 20,000. We do not set any upper bound of sentence length in training/development/test. This is for the purpose of evaluating the capability of the proposed method against long sentences. For tokenization, we used the SentencePiece tool (Kudo and Richardson, 2018) to set the vocabulary size of 32,000 each for both Japanese and English in order to avoid unknown words. Before splitting into subword units by SentencePiece, tokenization is performed by the morphological analysis tool MeCab2 for Japanese, and by Moses Tokenizer (Koehn et al., 2007) for English3 . 2 3 http://taku910.github.io/mecab/ By performing tokenization before splitting into subword Dublin, Aug. 20, 2019 |p. 28 Table 3: BLEU per sentence length (ASPEC ja→en) sentence length number of sentences RNN baseline multi-hop dependent (head2, hop2) Transformer 0-9 1594 5.94 10-19 1248 18.47 20-29 810 27.10 30-39 579 27.16 40-49 457 25.44 50-59 372 22.97 60-69 315 23.71 70-79 272 21.70 80-89 238 21.34 90-99 214 20.96 100-109 192 23.14 110-119 176 21.18 120-129 162 19.78 130-139 151 18.73 6.40‡ 19.43‡ 27.62 27.78 26.49† 24.08‡ 25.02‡ 22.42 22.74‡ 22.72‡ 23.11 20.62 20.56†† 20"
W19-7203,D18-2012,0,0.0421826,"Missing"
W19-7203,P17-2031,0,0.031579,"Missing"
W19-7203,L18-1275,0,0.0251852,"chanism, those increased number of parameters are well-tuned so that the overall translation accuracy improves, in particular, for long sentences. The proposed multi-hop attention mechanism is based on the hierarchical attention (Libovick´y and Helcl, 2017) for multi-source encoders, although, in the hierarchical attention (Libovick´y and Helcl, 2017), the number of parameters for one input does not increase, unlike in the proposed multi-hop attention mechanism. In evaluation, we compared the performance of the proposed method with Transformer and RNN encoder-decoder using OpenSubtitles 2018 (Lison et al., 2018) and Asian Scientific Paper Excerpt Corpus (ASPEC) (Nakazawa et al., 2016). To test the power of translating long sentences, we also Dublin, Aug. 20, 2019 |p. 24 (a) Baseline RNN-based model (b) Multi-head RNN model (c) Hierarchical attention model (d) Proposed method: Multi-hop attention model Figure 1: Baseline attention and proposed attention made a context-aware translation model, called 2to-2 (Bawden et al., 2018; Tiedemann and Scherrer, 2017) for OpenSubtitles 2018. In the Japaneseto-English translation of the ASPEC corpus, the proposed method achieved a significantly better score than t"
W19-7203,D15-1166,0,0.524119,"op attention model has two heads, where for each head, a context vector is calculated based on the states of the encoder and the decoder. Then, in the second turn of the context vector calculation, those context vectors are updated depending not only on one’s own context vector but also on the context vector of the other head. Experimental results show that the proposed model significantly outperforms the baseline in BLEU score in Japanese-to-English/English-toJapanese machine translation tasks with and without extended context. 1 Introduction RNN encoder-decoder model (Bahdanau et al., 2015; Luong et al., 2015; Sutskever et al., © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of The 8th Workshop on Patent and Scientific Literature Translation 2014) was the state-of-the-art in machine translation. However, it is outperformed by nonrecursive encoder-decoder models such as Transformer (Vaswani et al., 2017) and Convolutional Sequence-to-Sequence (Gehring et al., 2017) in recent years. However, RNN is not considered to be inferior to Transformer in all respects. For example, according to Tran et al. (2018), it is"
W19-7203,L16-1350,0,0.174966,"e overall translation accuracy improves, in particular, for long sentences. The proposed multi-hop attention mechanism is based on the hierarchical attention (Libovick´y and Helcl, 2017) for multi-source encoders, although, in the hierarchical attention (Libovick´y and Helcl, 2017), the number of parameters for one input does not increase, unlike in the proposed multi-hop attention mechanism. In evaluation, we compared the performance of the proposed method with Transformer and RNN encoder-decoder using OpenSubtitles 2018 (Lison et al., 2018) and Asian Scientific Paper Excerpt Corpus (ASPEC) (Nakazawa et al., 2016). To test the power of translating long sentences, we also Dublin, Aug. 20, 2019 |p. 24 (a) Baseline RNN-based model (b) Multi-head RNN model (c) Hierarchical attention model (d) Proposed method: Multi-hop attention model Figure 1: Baseline attention and proposed attention made a context-aware translation model, called 2to-2 (Bawden et al., 2018; Tiedemann and Scherrer, 2017) for OpenSubtitles 2018. In the Japaneseto-English translation of the ASPEC corpus, the proposed method achieved a significantly better score than the Transformer for long sentences with more than 120 tokens. In the follow"
W19-7203,P02-1040,0,0.104028,"Missing"
W19-7203,W17-4811,0,0.0183823,"hop attention mechanism. In evaluation, we compared the performance of the proposed method with Transformer and RNN encoder-decoder using OpenSubtitles 2018 (Lison et al., 2018) and Asian Scientific Paper Excerpt Corpus (ASPEC) (Nakazawa et al., 2016). To test the power of translating long sentences, we also Dublin, Aug. 20, 2019 |p. 24 (a) Baseline RNN-based model (b) Multi-head RNN model (c) Hierarchical attention model (d) Proposed method: Multi-hop attention model Figure 1: Baseline attention and proposed attention made a context-aware translation model, called 2to-2 (Bawden et al., 2018; Tiedemann and Scherrer, 2017) for OpenSubtitles 2018. In the Japaneseto-English translation of the ASPEC corpus, the proposed method achieved a significantly better score than the Transformer for long sentences with more than 120 tokens. In the following sections, we first show previous works on baseline RNN and multi-head RNN encoder-decoders in Section 2. We then describe the proposed multi-hop method in Section 3. We then show the performance for Japanese-toEnglish and English-to-Japanese translation tasks, focusing on long sentences in Section 4. 2 Neural Machine Translation 2.1 RNN based sequence to sequence NMT Ther"
W19-7203,D18-1503,0,0.0255545,", 2015; Luong et al., 2015; Sutskever et al., © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of The 8th Workshop on Patent and Scientific Literature Translation 2014) was the state-of-the-art in machine translation. However, it is outperformed by nonrecursive encoder-decoder models such as Transformer (Vaswani et al., 2017) and Convolutional Sequence-to-Sequence (Gehring et al., 2017) in recent years. However, RNN is not considered to be inferior to Transformer in all respects. For example, according to Tran et al. (2018), it is reported that Transformer is not good at decoding sentences whose length is not included in the training data and it is weak to long distance dependency. In other words, it is weak against long sentence translation. It seems that Transformer became more powerful than RNN by increasing the number of parameters, but it became weak to long sentences for the same reason. We propose an RNN based source-to-target attention mechanism where the number of parameters increases by repeating the calculation of multihead attention for a single-source encoder like multi-hop attention in end-to-end m"
W97-0123,P96-1025,0,0.100362,"in recent years. In those research, extracted lexical/semantic collocation is especially useful in terms of ranking parses in syntactic analysis as well as automatic construction of lexicon for NLP. For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decision-tree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees. As lexical/semantic information, Black (1993) used about 50 semantic categories, while Magerman (1995) used lexical forms of words. Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree. In those works, lexical/semantic collocation are used for ranking parses in syntactic analysis. They put an assumption that syntactic and lexical/semantic features are dependent on each other. In their models, syntactic and lexical/semantic features are combined together, and this causes each parameter to depend on both syntactic and lexical/semantic features. On the other hand, in the context of automatic lexicon construction, the emphasis is mainly on the extraction of lexical"
W97-0123,C96-1004,0,0.0169545,"have to decide which superordinate class generates each observed leaf class in the verb.noun collocation. So far, there exist several researches which worked on these two issues in learning eollocational knowledge of verbs and also evaluated the results in terms of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argnment noun in a tree-structured thesaurus. Although they evaluated the obtained abstraction level of the argument noun by its performance in syntactic disambiguation, their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and evaluated the discovered dependencies in the syntactic disambiguation task. They first obtained optimal abstraction levels of the argument nouns by the method in Li and Abe (1995), and then tried to discover dependencies between the class-based case slots. They reported that dependencies were discovered only at the slot-level and not at the class-level. Compared with those previous works, this paper proposes to consider the above two issues in a uniform way. First, we introduce a model of generating a collocation of a verb"
W97-0123,P95-1037,0,0.0461045,"Missing"
W97-0123,H93-1054,0,0.0322544,"ational knowledge of verbs from corpus, it is necessary to consider the following two issues: 1) 2) Case dependencies Noun class generalization When considering 1), we have to decide which cases are dependent on each other and which cases are optional and independent of other cases. When considering 2), we have to decide which superordinate class generates each observed leaf class in the verb.noun collocation. So far, there exist several researches which worked on these two issues in learning eollocational knowledge of verbs and also evaluated the results in terms of syntactic disambiguation. Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argnment noun in a tree-structured thesaurus. Although they evaluated the obtained abstraction level of the argument noun by its performance in syntactic disambiguation, their works are limited to only one argument. Li and Abe (1996) also studied a method for learning dependencies between case slots and evaluated the discovered dependencies in the syntactic disambiguation task. They first obtained optimal abstraction levels of the argument nouns by the method in Li and Abe (1995), and then tried to discover dependenc"
W97-0123,A97-1053,1,0.404543,"Missing"
W97-0123,J98-2002,0,\N,Missing
W97-0123,J96-1002,0,\N,Missing
Y09-2044,P07-2045,0,0.00901957,"Missing"
Y09-2044,I08-2094,1,0.599389,"nal expressions with nine abstraction levels, the lexicon compiled by Matsuyoshi et al. (2006) also has a hierarchy of semantic equivalence classes introduced from the viewpoint of paraphrasability. This semantic hierarchy has three abstraction levels, where 435 entries in L2 (headwords with a unique sense) of the hierarchy of surface forms are organized into the top 45 semantic equivalence classes, the middle 128 classes, and the 199 bottom classes. Figure 1 shows examples of the bottom 199 classes, where each of “k11”, “D21”, “t32”, and “t22” represents a label of the bottom 199 classes. In Matsuyoshi and Sato (2008), the bottom 199 semantic equivalence classes of Japanese functional expressions are designed so that functional expressions within a class are paraphrasable in most contexts of Japanese texts. 2 http://kotoba.nuee.nagoya-u.ac.jp/tsutsuji/ 804 Figure 1: Translation of Japanese Functional Expressions through Semantic Equivalence Classes 4 Ambiguities of Functional/Content Usages One of the most important assumption of applying the translation rules invented in this paper is that each functional expression to which those translation rules are applied must be monosemous. Unless each functional ex"
Y09-2044,1993.tmi-1.20,0,0.0507842,"tive expressions. In this paper, we apply this architecture to the task of translating Japanese functional expressions into English, where we introduce a recently compiled large scale hierarchical lexicon of Japanese functional expressions (Matsuyoshi et al., 2006). We employ the semantic equivalence classes of the lexicon and examine each class whether it is monosemous or not. We then study whether functional expressions within a class can be translated into a single 1 Copyright 2009 by Akiko Sakamoto, Taiji Nagasaka, Takehito Utsuro, and Suguru Matsuyoshi A similar idea was proposed also in Shirai et al. (1993). 23rd Pacific Asia Conference on Language, Information and Computation, pages 803–810 803 canonical English expression. Next, we introduce two types of ambiguities of functional expressions and identify monosemous functional expressions. In the evaluation of our translation rules for Japanese functional expressions, we directly apply those rules to monosemous functional expressions, and show that the proposed framework outperforms commercial machine translation software products. We further study how to extract rules for translating functional expressions in Japanese patent documents into Eng"
Y09-2044,W06-2404,1,0.522651,"e verb “ie”, and has a content word meaning “can not say”. Compared to Table 1 (b), Table 1 (a) shows an example of a functional expression without ambiguity of functional/content usages. In this case, the compound expression “koto ga dekiru” consists of a formal noun “koto”, a post-positional particle “ga”, and an auxiliary verb “dekiru”. In almost all the occurrences in a newspaper corpus, the surface form of this compound expression functions as an auxiliary verb and has a non-compositional functional meaning “can”. This type of ambiguity has been well studied in Tsuchiya et al. (2005) and Tsuchiya et al. (2006). Tsuchiya et al. (2005) reported that, out of about 180 compound expressions which are frequently observed in the newspaper text, one third (about 60 expressions) have this type of 805 ambiguity. Next, Tsuchiya et al. (2006) formalized the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem. The proposed technique performed reasonably well, while its major drawback is in its scale. So far, the proposed technique has not yet been applied to the whole list of over 10,000 Japanese functional expressions. Considering this situation,"
Y09-2044,C02-1163,0,0.865728,"m can be partially recognized by the fact that the Japanese language has a large number of variants of functional expressions, where their total number is recently counted as over 10,000 in Matsuyoshi et al. (2006). Based on those recent development in studies on lexicon for processing Japanese functional expressions (Matsuyoshi et al., 2006), this paper studies issues on MT of Japanese functional expressions into English. More specifically, in order to solve the problem of a large number of variants of Japanese functional expressions, in this paper, we employ the “Sandglass” MT architecture (Yamamoto, 2002) 1 . In the “Sandglass” MT architecture, variant expressions in the source language are first paraphrased into representative expressions, and then, a small number of translation rules are applied to the representative expressions. In this paper, we apply this architecture to the task of translating Japanese functional expressions into English, where we introduce a recently compiled large scale hierarchical lexicon of Japanese functional expressions (Matsuyoshi et al., 2006). We employ the semantic equivalence classes of the lexicon and examine each class whether it is monosemous or not. We th"
Y11-1021,2008.amta-papers.8,1,0.78641,"Missing"
Y11-1021,P98-1069,0,0.792826,"Missing"
Y11-1021,H05-1061,0,0.452018,"Missing"
Y11-1021,2007.mtsummit-papers.36,0,0.171791,"Missing"
Y11-1021,P07-2045,0,0.00595837,"ber of these documents is smaller than that of the JPO documents. From these document sets, patent families are automatically extracted and the fields of “Background of the Invention” and “Detailed Description of the Preferred Embodiments” are selected. This is because the text of those fields is usually translated on a sentence-by-sentence basis. Then, the method of Utiyama and Isahara (2007) is applied to the text of those fields, and Japanese and English sentences are aligned. 3 Phrase Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, first, word alignment of parallel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase table and a phrase translation probability is assigned to each pair. More specifically, we construct a phrase table in the direction of Japanese to English translation, and another one in the opposite direction of English to Japanese translation. In the direction of Japanese to"
Y11-1021,Y11-1021,1,0.0529408,"we manually divide the set CBP (sJ ) of candidates of bilingual synonymous technical term pairs into SBP (sJE ), those of which are synonymous with sJE , and the remaining N SBP (sJE ). As in Table 1, the number of bilingual technical terms included in SBP (sJE ) in total for all of the 134 seed bilingual technical term pairs is 1,680, which amounts to 12.5 per seed on average. 5 Automatic Identification of Bilingual Synonymous Technical Terms by Machine Learning In this section, we apply the SVMs to the task of identifying bilingual synonymous technical terms, which we originally proposed in Liang et al. (2011). 5.1 The Procedure First, let CBP be the union of the sets CBP (sJ ) of candidates of bilingual synonymous technical term pairs for all of the 134 seed bilingual technical term pairs. In the training and testing of the classifier for identifying bilingual synonymous technical terms, we first divide the set of 134 seed bilingual technical term pairs into 10 subsets. Here, for each i-th subset (i = 1, . . . , 10), we construct the union CBPi of the sets CBP (sJ ) of candidates of bilingual synonymous technical term pairs, where CBP1 , . . . , CBP10 are 10 disjoint subsets3 of CBP . As a tool fo"
Y11-1021,2008.amta-papers.14,1,0.299692,"Missing"
Y11-1021,J03-1002,0,0.00530945,"ackground of the Invention” and “Detailed Description of the Preferred Embodiments” are selected. This is because the text of those fields is usually translated on a sentence-by-sentence basis. Then, the method of Utiyama and Isahara (2007) is applied to the text of those fields, and Japanese and English sentences are aligned. 3 Phrase Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, first, word alignment of parallel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase table and a phrase translation probability is assigned to each pair. More specifically, we construct a phrase table in the direction of Japanese to English translation, and another one in the opposite direction of English to Japanese translation. In the direction of Japanese to English translation, we finally obtain 76M translation pairs with 33M unique Japanese phrases, i.e., 2.29 English translations per Japanese phrase on aver"
Y11-1021,W06-1703,1,0.776908,"is the most important key resource. Since manual compilation of bilingual lexicon requires plenty of time and huge manual labor, in the research area of knowledge acquisition from natural language text, automatic bilingual lexicon compilation have been studied. Techniques invented so far include translation term pair acquisition based on statistical co-occurrence measure from parallel sentences (Matsumoto and Utsuro, 2000), translation term pair acquisition from comparable corpora (Fung and Yee, 1998), compositional translation generation based on an existing bilingual lexicon for human use (Tonoike et al., 2006), and translation term pair acquisition by collecting partially bilingual texts through the search engine (Huang et al., 2005). Among those efforts of acquiring bilingual lexicon from text, Morishita et al. (2008) studied to acquire technical term translation lexicon from phrase tables, which are trained by a phrasebased statistical machine translation model with parallel sentences automatically extracted from parallel patent documents. Recently, we further studied to require the acquired technical term translation equivalents to be consistent with word alignment in parallel sentences and achi"
Y11-1021,I08-1060,0,0.161057,"Missing"
Y11-1021,2007.mtsummit-papers.63,0,0.362248,"e U.S. Patent & Trademark Office (USPTO) in 1993-2000. The numbers of documents are approximately 3,500,000 for Japanese and 1,300,000 for English. Because the USPTO documents consist of only patent that have been granted, the number of these documents is smaller than that of the JPO documents. From these document sets, patent families are automatically extracted and the fields of “Background of the Invention” and “Detailed Description of the Preferred Embodiments” are selected. This is because the text of those fields is usually translated on a sentence-by-sentence basis. Then, the method of Utiyama and Isahara (2007) is applied to the text of those fields, and Japanese and English sentences are aligned. 3 Phrase Table of an SMT Model As a toolkit of a phrase-based statistical machine translation model, we use Moses (Koehn et al., 2007) and apply it to the whole 1.8M parallel patent sentences. In Moses, first, word alignment of parallel sentences are obtained by GIZA++ (Och and Ney, 2003) in both translation directions and then the two alignments are symmetrised. Next, any phrase pair that is consistent with word alignment is collected into the phrase table and a phrase translation probability is assigned"
Y11-1021,C98-1066,0,\N,Missing
Y12-1054,P10-1115,0,0.0309413,"elated Works Wang et al. (2007) studied how to detect correlated bursty topic patterns across multiple text streams such as multilingual news streams, where their method concentrated on detecting correlated bursty topic patterns based on the similarity of temporal distribution of tokens. Unlike the method of Wang et al. (2007), in this paper, we do not utilize burst detection techniques, but employ a time series topic model and cross-lingually align time series topics utilizing translation knowledge automatically extracted from Wikipedia. Boyd-Graber and Blei (2009), De Smet and Moens (2009), Zhang et al. (2010), and Jagarlamudi and Daum´e III (2010) concentrated on applying variants of topic models which have certain functions of bridging cross-lingual gaps by exploiting clues such as translation knowledge from bilingual lexicon or distribution of named entities. Compared with those previous works, the approach we take in this paper is different in that we focus on a time series topic model and align time series topics across two languages. It is one of our future works to introduce those other models and compare them with 506 our proposed framework in terms of effectiveness of aligning time series"
