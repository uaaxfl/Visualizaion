levin-etal-2014-resources,Resources for the Detection of Conventionalized Metaphors in Four Languages,2014,11,6,7,0,17380,lori levin,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes a suite of tools for extracting conventionalized metaphors in English, Spanish, Farsi, and Russian. The method depends on three significant resources for each language: a corpus of conventionalized metaphors, a table of conventionalized conceptual metaphors (CCM table), and a set of extraction rules. Conventionalized metaphors are things like {``}escape from poverty{''} and {``}burden of taxation{''}. For each metaphor, the CCM table contains the metaphorical source domain word (such as {``}escape{''}) the target domain word (such as {``}poverty{''}) and the grammatical construction in which they can be found. The extraction rules operate on the output of a dependency parser and identify the grammatical configurations (such as a verb with a prepositional phrase complement) that are likely to contain conventional metaphors. We present results on detection rates for conventional metaphors and analysis of the similarity and differences of source domains for conventional metaphors in the four languages."
feely-etal-2014-cmu,The {CMU} {METAL} {F}arsi {NLP} Approach,2014,6,4,3,0,14102,weston feely,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"While many high-quality tools are available for analyzing major languages such as English, equivalent freely-available tools for important but lower-resourced languages such as Farsi are more difficult to acquire and integrate into a useful NLP front end. We report here on an accurate and efficient Farsi analysis front end that we have assembled, which may be useful to others who wish to work with written Farsi. The pre-existing components and resources that we incorporated include the Carnegie Mellon TurboParser and TurboTagger (Martins et al., 2010) trained on the Dadegan Treebank (Rasooli et al., 2013), the Uppsala Farsi text normalizer PrePer (Seraji, 2013), the Uppsala Farsi tokenizer (Seraji et al., 2012a), and Jon DehdariÂs PerStem (Jadidinejad et al., 2010). This set of tools (combined with additional normalization and tokenization modules that we have developed and made available) achieves a dependency parsing labeled attachment score of 89.49{\%}, unlabeled attachment score of 92.19{\%}, and label accuracy score of 91.38{\%} on a held-out parsing test data set. All of the components and resources used are freely available. In addition to describing the components and resources, we also explain the rationale for our choices."
marujo-etal-2012-supervised,"Supervised Topical Key Phrase Extraction of News Stories using Crowdsourcing, Light Filtering and Co-reference Normalization",2012,9,25,4,0,26032,luis marujo,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Fast and effective automated indexing is critical for search and personalized services. Key phrases that consist of one or more words and represent the main concepts of the document are often used for the purpose of indexing. In this paper, we investigate the use of additional semantic features and pre-processing steps to improve automatic key phrase extraction. These features include the use of signal words and freebase categories. Some of these features lead to significant improvements in the accuracy of the results. We also experimented with 2 forms of document pre-processing that we call light filtering and co-reference normalization. Light filtering removes sentences from the document, which are judged peripheral to its main content. Co-reference normalization unifies several written forms of the same named entity into a unique form. We also needed a ÂGold StandardÂ â a set of labeled documents for training and evaluation. While the subjective nature of key phrase selection precludes a true ÂGold StandardÂ, we used Amazon's Mechanical Turk service to obtain a useful approximation. Our data indicates that the biggest improvements in performance were due to shallow semantic features, news categories, and rhetorical signals (nDCG 78.47{\%} vs. 68.93{\%}). The inclusion of deeper semantic features such as Freebase sub-categories was not beneficial by itself, but in combination with pre-processing, did cause slight improvements in the nDCG scores."
W10-2420,{CONE}: Metrics for Automatic Evaluation of Named Entity Co-Reference Resolution,2010,21,2,3,0,45327,bo lin,Proceedings of the 2010 Named Entities Workshop,0,"Human annotation for Co-reference Resolution (CRR) is labor intensive and costly, and only a handful of annotated corpora are currently available. However, corpora with Named Entity (NE) annotations are widely available. Also, unlike current CRR systems, state-of-the-art NER systems have very high accuracy and can generate NE labels that are very close to the gold standard for unlabeled corpora. We propose a new set of metrics collectively called CONE for Named Entity Co-reference Resolution (NE-CRR) that use a subset of gold standard annotations, with the advantage that this subset can be easily approximated using NE labels when gold standard CRR annotations are absent. We define CONE B3 and CONE CEAF metrics based on the traditional B3 and CEAF metrics and show that CONE B3 and CONE CEAF scores of any CRR system on any dataset are highly correlated with its B3 and CEAF scores respectively. We obtain correlation factors greater than 0.6 for all CRR systems across all datasets, and a best-case correlation factor of 0.8. We also present a baseline method to estimate the gold standard required by CONE metrics, and show that CONE B3 and CONE CEAF scores using this estimated gold standard are also correlated with B3 and CEAF scores respectively. We thus demonstrate the suitability of CONE B3 and CONE CEAF for automatic evaluation of NE-CRR."
W08-1509,Speech Translation for Triage of Emergency Phonecalls in Minority Languages,2008,9,0,4,0,14460,udhyakumar nallasamy,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,"We describe Ayudame, a system designed to recognize and translate Spanish emergency calls for better dispatching. We analyze the research challenges in adapting speech translation technology to 9-1-1 domain. We report our initial research in 9-1-1 translation system design, ASR experiments, and utterance classification for translation."
W08-0410,Inductive Detection of Language Features via Clustering Minimal Pairs: Toward Feature-Rich Grammars in Machine Translation,2008,14,1,2,0,3375,jonathan clark,Proceedings of the {ACL}-08: {HLT} Second Workshop on Syntax and Structure in Statistical Translation ({SSST}-2),0,"Syntax-based Machine Translation systems have recently become a focus of research with much hope that they will outperform traditional Phrase-Based Statistical Machine Translation (PBSMT). Toward this goal, we present a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included in the LDC's upcoming LCTL language packs. The presented method discovers a mapping between morphemes and linguistically relevant features. By providing this tool that can augment structure-based MT models with these rich features, we believe the discriminative power of current models can be improved. We conclude by outlining how the resulting output can then be used in inducing a morphosyntactically feature-rich grammar for AVENUE, a modern syntax-based MT system."
clark-etal-2008-toward,Toward Active Learning in Data Selection: Automatic Discovery of Language Features During Elicitation,2008,12,4,2,0,3375,jonathan clark,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Data Selection has emerged as a common issue in language technologies. We define Data Selection as the choosing of a subset of training data that is most effective for a given task. This paper describes deductive feature detection, one component of a data selection system for machine translation. Feature detection determines whether features such as tense, number, and person are expressed in a language. The database of the The World Atlas of Language Structures provides a gold standard against which to evaluate feature detection. The discovered features can be used as input to a Navigator, which uses active learning to determine which piece of language data is the most important to acquire next."
nallasamy-etal-2008-nineoneone,{N}ine{O}ne{O}ne: Recognizing and Classifying Speech for Handling Minority Language Emergency Calls,2008,11,3,4,0,14460,udhyakumar nallasamy,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, we describe NineOneOne (9-1-1), a system designed to recognize and translate Spanish emergency calls for better dispatching. We analyze the research challenges in adapting speech translation technology to 9-1-1 domain. We report our initial research towards building the system and the results of our initial experiments."
monson-etal-2008-linguistic,Linguistic Structure and Bilingual Informants Help Induce Machine Translation of Lesser-Resourced Languages,2008,14,10,9,0,44751,christian monson,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Producing machine translation (MT) for the many minority languages in the world is a serious challenge. Minority languages typically have few resources for building MT systems. For many minor languages there is little machine readable text, few knowledgeable linguists, and little money available for MT development. For these reasons, our research programs on minority language MT have focused on leveraging to the maximum extent two resources that are available for minority languages: linguistic structure and bilingual informants. All natural languages contain linguistic structure. And although the details of that linguistic structure vary from language to language, language universals such as context-free syntactic structure and the paradigmatic structure of inflectional morphology, allow us to learn the specific details of a minority language. Similarly, most minority languages possess speakers who are bilingual with the major language of the area. This paper discusses our efforts to utilize linguistic structure and the translation information that bilingual informants can provide in three sub-areas of our rapid development MT program: morphology induction, syntactic transfer rule learning, and refinement of imperfect learned rules."
2007.tmi-papers.1,An assessment of language elicitation without the supervision of a linguist,2007,-1,-1,3,1,48478,alison alvarez,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
N06-2002,The {MILE} Corpus for Less Commonly Taught Languages,2006,4,7,3,1,48478,alison alvarez,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"This paper describes a small, structured English corpus that is designed for translation into Less Commonly Taught Languages (LCTLs), and a set of re-usable tools for creation of similar corpora. The corpus systematically explores meanings that are known to affect morphology or syntax in the world's languages. Each sentence is associated with a feature structure showing the elements of meaning that are represented in the sentence. The corpus is highly structured so that it can support machine learning with only a small amount of data. As part of the REFLEX program, the corpus will be translated into multiple LCTLs, resulting in parallel corpora can be used for training of MT and other language technologies. Only the untranslated English corpus is described in this paper."
2005.mtsummit-posters.10,Semi-Automated Elicitation Corpus Generation,2005,10,4,3,1,48478,alison alvarez,Proceedings of Machine Translation Summit X: Posters,0,"In this document we will describe a semi-automated process for creating elicitation corpora. An elicitation corpus is translated by a bilingual consultant in order to produce high quality word aligned sentence pairs. The corpus sentences are automatically generated from detailed feature structures using the GenKit generation program. Feature structures themselves are automatically generated from information that is provided by a linguist using our corpus specification software. This helps us to build small, flexible corpora for testing and development of machine translation systems."
N03-4010,"{JAVELIN}: A Flexible, Planner-Based Architecture for Question Answering",2003,5,4,2,0,9610,eric nyberg,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Demonstrations,0,"The JAVELIN system integrates a flexible, planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text. The demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session."
N03-4015,{S}peechalator: Two-Way Speech-to-Speech Translation in Your Hand,2003,2,20,4,0,5073,alex waibel,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Demonstrations,0,"This demonstration involves two-way automatic speech-to-speech translation on a consumer off-the-shelf PDA. This work was done as part of the DARPA-funded Babylon project, investigating better speech-to-speech translation systems for communication in the field. The development of the Speechalator software-based translation system required addressing a number of hard issues, including a new language for the team (Egyptian Arabic), close integration on a small device, computational efficiency on a limited platform, and scalable coverage for the domain."
2003.mtsummit-tttt.4,Teaching machine translation in a graduate language technologies program,2003,-1,-1,3,0,7705,teruko mitamura,Workshop on Teaching Translation Technologies and Tools,0,"This paper describes a graduate-level machine translation (MT) course taught at the Language Technologies Institute at Carnegie Mellon University. Most of the students in the course have a background in computer science. We discuss what we teach (the course syllabus), and how we teach it (lectures, homeworks, and projects). The course has evolved steadily over the past several years to incorporate refinements in the set of course topics, how they are taught, and how students {``}learn by doing{''}. The course syllabus has also evolved in response to changes in the field of MT and the role that MT plays in various social contexts."
W02-0711,Speech Translation on a Tight Budget without Enough Data,2002,11,3,1,1,39652,robert frederking,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"The Tongues speech-to-speech translation system was developed for the US Army chaplains, with fairly stringent constraints on time, budget, and available data. The resulting prototype was required to undergo a quite realistic field test. We describe the development and architecture of the system, the field test, and our analysis of its results. The system performed quite well, especially given its development constraints."
W02-0106,Design and Evolution of a Language Technologies Curriculum,2002,0,1,1,1,39652,robert frederking,Proceedings of the {ACL}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,0,The Language Technologies Institute (LTI) of the School of Computer Science at Carnegie Mellon University is one of the largest programs of its kind. We present here the initial design and subsequent evolution of our MS and PhD programs in Language Technologies. The motivations for the design and evolution are also presented.
frederking-etal-2002-field,Field Testing the Tongues Speech-to-Speech Machine Translation System,2002,5,12,1,1,39652,robert frederking,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The Tongues portable, rapid-development, speech-to-speech machine translation system was developed specifically to allow a realistic field-test of a deployable prototype. In this paper we will describe the system, its field-testing using regular US Army officers and naive Croatians, and the evaluation of these tests. The evaluation includes analysis of answers to a questionnaire, analysis of system transcript logs, and the authorsxe2x80x99 qualitative observations. The overall result of the test was that while the system did successfully aid translation, it requires further development before it would be ready for regular field use. 1. The Tongues System The Tongues system was funded by the US Army to support the mission of the US Army chaplains, who are increasingly called upon to deal with local populations, usually without the benefit of human translators. It is thus intended to be used by a trained US Army chaplain with a completely naive and untrained non-English speaker. The architecture and user interface of the Tongues system were based in large measure on the Diplomat system (Frederking et al., 2000). The speech recognition system used was the open-source Sphinx II (Huang et al., 1992); the translation system was a EBMT/MEMT (ExampleBased MT/Multi-Engine MT) system (Brown, 1996; Frederking and Nirenburg, 1994; Brown and Frederking, 1995) very similar to that in Diplomat; and the synthesis system was the open-source Festival (Black et al., 1998). While the initial system was specifically to demonstrate translation in both directions between English and Croatian, the design was also required to allow rapid development for new languages. To ensure rapid development, the entire project was only allowed to take one calendar year, including contractual arrangements, hiring language experts, etc. The total development effort was similarly restricted: six senior research personnel (the authors of this paper) provided an estimated total of about two (2) fulltime person-years of effort. In addition to the senior staff, there were also part-time Croatian informants, chaplains, and some student programmers. We should note that some of the translation data used to train the system was collected for the Diplomat project (Frederking et al., 2000). In addition to rapid development, the system was not permitted to be restricted to a narrowly-limited domain, but had to be wide-coverage. (Both of these properties were important for the chaplainsxe2x80x99 envisioned activities.) Since we were to build a broad-coverage system in a short period of time on a small budget, data-driven approaches were the only reasonable choice. In order to provide in-domain conversational data, we arranged at the start of the project to record a number of chaplains in role-playing conversations of the type they expected the device to encounter. Fortunately, the chaplains were familiar with role-playing exercises, and all had relevant field experiences to re-enact. Both sides of the conversations were spoken in English. These were digitally recorded with head-mounted microphones at 16KHz in stereo (one speaker on each channel), as this was closest to the intended audio channel characteristics of the eventual system. In all, we recorded 46 conversations, ranging from a few minutes to 20 minutes length. This provided a total of 4.25 hours of actual speech. The recorded conversations were hand-transcribed at the word level, and translated into Croatian by native Croatian speakers. The English recordings were used for training the English speech recognition models. The transcripts and their translations were added to the EBMT systemxe2x80x99s example base of parallel sentences. A subset of the Croatian translations were read by native Croatian speakers to create data for the Croatian speech recognizer, as described elsewhere (Black et al., 2002). This simple approach appears to be surprisingly adequate. Simply stringing together a recognizer, translator, and synthesizer does not make a very useful speech-to-speech translation system. A good interface is necessary to make the parts work together in such a way that a user can actually derive benefit from it. Using our experience from the earlier Diplomat system, we designed the Tongues interface to be asymmetric, with the Croatian side being as simple as possible, and any necessary complexity handled on the English side, since the chaplain would be trained and practiced in using the system. Even the English side was not terribly complex (see Figure 1). We included a back-translation capability, to allow a user with no knowledge of the target language to better assess the quality of the translation. (We could not use the approach of generating paraphrases from meaning representations, since the system does not use any meaning representations.) We also included several user-requested features, such as built-in pre-recorded instructions and explanations for the Croatian (since the Croatian speaker is completely naive regarding the device and the chaplainxe2x80x99s intentions), emergency key phrases (such as xe2x80x9cDonxe2x80x99t move!xe2x80x9d), and enhancements such as being able to modify the translation lexicon in the field, so that the system could be tuned to more specific tasks. The final system ran on a Windows-based Toshiba Libretto, running at 200MHz with 192MB of memory. At the time of the project (2000) this was the best combination of speed and size that was readily available. The system was equipped with a custom touchscreen, so that the Croatian-speaker would not need to type or use a mouse at all. Aware that the system might be used in situations where the non-English participant would be unfamiliar with computer technology, we included a microphone/speaker handset that looks like a conventional telephone handset. This has the advantage of provided a close-talking microphone, thus making speech recognition easier, while coming in a form factor that will be familiar to most people. We have provided a more detailed description of the development of the Tongues system elsewhere (Black et al., 2002). Our design provides abundant opportunities for user error correction, in an effort to enable cooperative users to communicate well enough to accomplish significant tasks that they could not accomplish without the system (or a bilingual human interpreter), despite the error-prone nature of current speech recognition, broad-coverage rapiddevelopment machine translation, and speech synthesis. Determining whether we have met such a goal requires task-based evaluation; while error rates of components are useful information, the real system-level issue is whether communication is achieved, and at what level of effort. Figure 1: Tongues User Interface."
lavie-etal-2002-nespole,The {NESPOLE}! speech-to-speech translation system,2002,9,19,3,0,13539,alon lavie,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: System Descriptions,0,"NESPOLE! is a speech-to-speech machine translation research system designed to provide fully functional speech-to-speech capabilities within real-world settings of common users involved in e-commerce applications. The project is funded jointly by the European Commission and the US NSF. The NESPOLE! system uses a client-server architecture to allow a common user, who is browsing web-pages on the internet, to connect seamlessly in real-time to an agent of the service provider, using a video-conferencing channel and with speech-to-speech translation services mediating the conversation. Shared web pages and annotated images supported via a Whiteboard application are available to enhance the communication."
H01-1002,Adapting an Example-Based Translation System to {C}hinese,2001,4,12,3,0,7842,ying zhang,Proceedings of the First International Conference on Human Language Technology Research,0,We describe an Example-Based Machine Translation (EBMT) system and the adaptations and enhancements made to create a Chinese-English translation system from the Hong Kong legal code and various other bilingual resources available from the Linguistic Data Consortium (LDC).
2001.mtsummit-papers.69,Pre-processing of bilingual corpora for {M}andarin-{E}nglish {EBMT},2001,5,3,3,0,7842,ying zhang,Proceedings of Machine Translation Summit VIII,0,"Pre-processing of bilingual corpora plays an important role in Example-Based Machine Translation (EBMT) and Statistical-Based Machine Translation (SBMT). For our Mandarin-English EBMT system, pre-processing includes segmentation for Mandarin, bracketing for English and building a statistical dictionary from the corpora. We used the Mandarin segmenter from the Linguistic Data Consortium (LDC). It uses dynamic programming with a frequency dictionary to segment the text. Although the frequency dictionary is large, it does not completely cover the corpora. In this paper, we describe the work we have done to improve the segmentation for Mandarin and the bracketing process for English to increase the length of English phrases. A statistical dictionary is built from the aligned bilingual corpus. It is used as feedback to segmentation and bracketing to re-segment / re-bracket the corpus. The process iterates several times to achieve better results. The final results of the corpus pre-processing are a segmented/bracketed aligned bilingual corpus and a statistical dictionary. We achieved positive results by increasing the average length of Chinese terms about 60{\%} and 10{\%} for English. The statistical dictionary gained about a 30{\%} increase in coverage."
C00-2154,{W}eb{DIPLOMAT}: A Web-Based Interactive Machine Translation System,2000,11,6,2,1,54657,christopher hogan,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"We have implemented an interactive, Web-based, chat-style machine translation system, supporting speech recognition and synthesis, local- or third-party correction of speech recognition and machine translation output, and online learning. The underlying client-server architecture, implemented in JavaTM, provides remote, distributed computation for the translation and speech subsystems. We further describe our Web-based user interfaces, which can easily produce different useful configurations."
1999.mtsummit-1.82,A new approach to the translating telephone,1999,15,1,1,1,39652,robert frederking,Proceedings of Machine Translation Summit VII,0,"The Translating Telephone has been a major goal of speech translation for many years. Previous approaches have attempted to work from limited-domain, fully-automatic translation towards broad-coverage, fully-automatic translation. We are approaching the problem from a different direction: starting with a broad-coverage but not fully-automatic system, and working towards full automation. We believe that working in this direction will provide us with better feedback, by observing users and collecting language data under realistic conditions, and thus may allow more rapid progress towards the same ultimate goal. Our initial approach relies on the wide-spread availability of Internet connections and web browsers to provide a user interface. We describe our initial work, which is an extension of the Diplomat wearable speech translator."
hogan-frederking-1998-evaluation,An evaluation of the multi-engine {MT} architecture,1998,23,26,2,1,54657,christopher hogan,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"The Multi-Engine MT (MEMT) architecture combines the outputs of multiple MT engines using a statistical language model of the target language. It has been used successfully in a number of MT research systems, for both text and speech translation. Despite its perceived benefits, there has never been a rigorous, published, double-blind evaluation of the claim that the combined output of a MEMT system is in fact better than that of any one of the component MT engines. We report here the results of such an evaluation. The combined MEMT output is shown to indeed be better overall than the output of the component engines in a Croatian â English MT system. This result is consistent in both translation directions, and between different raters."
W97-0409,Interactive Speech Translation in the {DIPLOMAT} Project,1997,-1,-1,1,1,39652,robert frederking,Spoken Language Translation,0,None
1997.mtsummit-systems.9,The {DIPLOMAT} Rapid Development Speech {MT} System,1997,-1,-1,1,1,39652,robert frederking,Proceedings of Machine Translation Summit VI: Systems,0,None
1996.amta-1.35,The {P}angloss-{L}ite machine translation system,1996,-1,-1,1,1,39652,robert frederking,Conference of the Association for Machine Translation in the Americas,0,None
1995.tmi-1.17,Applying Statistical {E}nglish Language Modelling to Symbolic Machine Translation,1995,-1,-1,2,0.263158,40110,ralf brown,Proceedings of the Sixth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
H94-1026,Toward Multi-Engine Machine Translation,1994,4,17,2,0,32552,sergei nirenburg,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"Current MT systems, whatever translation method they at present employ, do not reach an optimum output on free text. Our hypothesis for the experiment reported in this paper is that if an MT environment can use the best results from a variety of MT systems working simultaneously on the same text, the overall quality will improve. Using this novel approach to MT in the latest version of the Pangloss MT project, we submit an input text to a battery of machine translation systems (engines), collect their (possibly, incomplete) results in a joint chart-like data structure and select the overall best translation using a set of simple heuristics. This paper describes the simple mechanism we use for combining the findings of the various translation engines."
C94-1019,Two Types of Adaptive {MT} Environments,1994,7,7,2,0,32552,sergei nirenburg,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"A number of proposal have come up in recent years for hybridization of MT. Current MT projects --- both pure and hybrid, both predominantly technology-oriented and scientific (including those currently funded by NSF) are single-engine projects, capable of one particular type of source text analysis, one particular method of finding target language correspondences for source language elements and one prescribed method of generating the target language text. While such projects can be quite useful, we believe that it is time to make the next step in the design of machine translation systems and to move toward adaptive, multiple-engine systems. We describe the architecture of an adaptive multi-engine MT system which uses each of the engines under the circumstances which are most favorable for its success."
A94-1016,Three Heads are Better than One,1994,4,128,1,1,39652,robert frederking,Fourth Conference on Applied Natural Language Processing,0,"Machine translation (MT) systems do not currently achieve optimal quality translation on free text, whatever translation method they employ. Our hypothesis is that the quality of MT will improve if an MT environment uses output from a variety of MT systems working on the same text. In the latest version of the Pangloss MT project, we collect the results of three translation engines---typically, subsentential chunks---in a chart data structure. Since the individual MT systems operate completely independently, their results may be incomplete, conflicting, or redundant. We use simple scoring heuristics to estimate the quality of each chunk, and find the highest-score sequence of chunks (the best cover). This paper describes in detail the combining method, presenting the algorithm and illustrations of its progress on one of many actual translations it has produced. It uses dynamic programming to efficiently compare weighted averages of sets of adjacent scored component translations. The current system operates primarily in a human-aided MT mode. The translation delivery system and its associated post-editing aide are briefly described, as is an initial evaluation of the usefulness of this method. Individual MT engines will be reported separately and are not, therefore, described in detail here."
1994.amta-1.10,Integrating Translations from Multiple Sources within the {PANGLOSS} Mark {III} Machine Translation System,1994,-1,-1,1,1,39652,robert frederking,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
1994.amta-1.41,{PANGLOSS},1994,0,0,3,0,10837,jaime carbonell,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
H93-1038,An {MAT} Tool and Its Effectiveness,1993,2,19,1,1,39652,robert frederking,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"Although automatic machine translation (MT) of unconstrained text is beyond the state of the art today, the need for increased translator productivity is urgent. The PANGLOSS system addresses this dilemma by integrating MT with machine-aided translation (MAT). The main measure of progress in the development of the PANGLOSS system is a gradual increase in the level of automation. The current PANGLOSS MT system typically generates sub-sentence-length units of the target text. Any remaining gaps are treated by lexicon lookup. A mixture of these two kinds of components is presented to the user using the CMAT (Component Machine-Aided Translation) editor, which was designed to facilitate the transformation of this output into a high-quality text. An experiment evaluating the utility of the CMAT editor demonstrated its usefulness in this task, and provides useful guidance for further development."
E93-1062,The {PANGLOSS MARK I} {MAT} system,1993,2,4,1,1,39652,robert frederking,Sixth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The goal of the PANGLOSS projecd is to develop a system which will, from the very beginning, produce highquality translations of unconstrained text. This can only be attained currently by keeping the human in the translation loop, in our case via a software module called the A U O ~ R . The main measure of progress in the development of the Pangloss system will therefore be the gradual decrease in need for user assistance, as the level of automation increases. The analyzer used in the first version of PANGLOSS, PANGLOSS MARK I, is a version of the ULTRA Spanish analyzer from NMSU [Farwell 1990], while generation is carried out by the PENMAN generator from ISI [Mann 1983]. The Translator's Workstation (TWS) provides the user interface and the integration platform [Nirenburg 1992]. This paper focuses on this use of TWS as a substrate for PANGLOSS. PANOLOSS operates in the following mode: a) a fullyautomated translation of each full sentence is attempted; if it fails, then b) a fully-automated translation of smaller chunks of text is attempted (in the first PANGLOSS configuration, PANGLOSS MARK I, these were noun phrases); c) the material that does not get covered by noun phrases is treated in word-for-word mode, whereby translation suggestions for each word (or phrase) are sought in the system's MT lexicons, a machine-readable dictionary, and a set of user glossaries; d) The resulting list of translated noun phrases and translation suggestions for words and phrases is displayed in a special editor window of TWS, where the human user finalizes the translation. At stages a) and b) there is an option of the user being presented by the system with disambiguation questions via the AUGMENTOR. We provide an intelligent environment, the CMAT (Constituent Machine-Aided Translation) editor, for postediting. It allows the user to select, move, and delete words and phrases (constituents) quickly and easily, using dynamically-changing menus. As can be seen in Figure 1, each constituent in the target window is surrounded by  > characters. If the user clicks with the mouse anywhere within a constituent (between the  > symbols), a CMAT menu for that constituent appears. It contains the word or phrase in the source text if available, the functions Move and Delete, and alternative translations of the word or phrase from the source text if any. Using these popup menus, the user moves, replaces, or deletes a constituent with a single mouse action, rapidly turning the list of translated words"
P81-1018,A Rule-based Conversation Participant,1981,9,9,1,1,39652,robert frederking,19th Annual Meeting of the Association for Computational Linguistics,1,"The problem of modeling human understanding and generation of a coherent dialog is investigated by simulating a conversation participant. The rule-based system currently under development attempts to capture the intuitive concept of topic using data structures consisting of declarative representations of the subjects under discussion linked to the utterances and rules that generated them. Scripts, goal trees, and a semantic network are brought to bear by general, domain-independent conversational rules to understand and generate coherent topic transitions and specific output utterances."
