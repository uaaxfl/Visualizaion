2021.naacl-main.131,Bridging Resolution: Making Sense of the State of the Art,2021,-1,-1,2,1,3640,hideo kobayashi,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"While Yu and Poesio (2020) have recently demonstrated the superiority of their neural multi-task learning (MTL) model to rule-based approaches for bridging anaphora resolution, there is little understanding of (1) how it is better than the rule-based approaches (e.g., are the two approaches making similar or complementary mistakes?) and (2) what should be improved. To shed light on these issues, we (1) propose a hybrid rule-based and MTL approach that would enable a better understanding of their comparative strengths and weaknesses; and (2) perform a manual analysis of the errors made by the MTL model."
2021.naacl-main.356,Constrained Multi-Task Learning for Event Coreference Resolution,2021,-1,-1,2,1,4313,jing lu,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We propose a neural event coreference model in which event coreference is jointly trained with five tasks: trigger detection, entity coreference, anaphoricity determination, realis detection, and argument extraction. To guide the learning of this complex model, we incorporate cross-task consistency constraints into the learning process as soft constraints via designing penalty functions. In addition, we propose the novel idea of viewing entity coreference and event coreference as a single coreference task, which we believe is a step towards a unified model of coreference resolution. The resulting model achieves state-of-the-art results on the KBP 2017 event coreference dataset."
2021.findings-emnlp.129,Don{'}t Miss the Potential Customers! Retrieving Similar Ads to Improve User Targeting,2021,-1,-1,4,0,6746,yi feng,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"User targeting is an essential task in the modern advertising industry: given a package of ads for a particular category of products (e.g., green tea), identify the online users to whom the ad package should be targeted. A (ad package specific) user targeting model is typically trained using historical clickthrough data: positive instances correspond to users who have clicked on an ad in the package before, whereas negative instances correspond to users who have not clicked on any ads in the package that were displayed to them. Collecting a sufficient amount of positive training data for training an accurate user targeting model, however, is by no means trivial. This paper focuses on the development of a method for automatic augmentation of the set of positive training instances. Experimental results on two datasets, including a real-world company dataset, demonstrate the effectiveness of our proposed method."
2021.emnlp-main.103,Conundrums in Event Coreference Resolution: Making Sense of the State of the Art,2021,-1,-1,2,1,4313,jing lu,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Despite recent promising results on the application of span-based models for event reference interpretation, there is a lack of understanding of what has been improved. We present an empirical analysis of a state-of-the-art span-based event reference systems with the goal of providing the general NLP audience with a better understanding of the state of the art and reference researchers with directions for future research."
2021.codi-sharedtask.1,"The {CODI}-{CRAC} 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue",2021,-1,-1,4,0,2579,sopan khosla,"Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue",0,"In this paper, we provide an overview of the CODI-CRAC 2021 Shared-Task: Anaphora Resolution in Dialogue. The shared task focuses on detecting anaphoric relations in different genres of conversations. Using five conversational datasets, four of which have been newly annotated with a wide range of anaphoric relations: identity, bridging references and discourse deixis, we defined multiple subtasks focusing individually on these key relations. We discuss the evaluation scripts used to assess the system performance on these subtasks, and provide a brief summary of the participating systems and the results obtained across ?? runs from 5 teams, with most submissions achieving significantly better results than our baseline methods."
2021.codi-sharedtask.2,Neural Anaphora Resolution in Dialogue,2021,-1,-1,3,1,3640,hideo kobayashi,"Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue",0,"We describe the systems that we developed for the three tracks of the CODI-CRAC 2021 shared task, namely entity coreference resolution, bridging resolution, and discourse deixis resolution. Our team ranked second for entity coreference resolution, first for bridging resolution, and first for discourse deixis resolution."
2021.codi-sharedtask.8,"The {CODI}-{CRAC} 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis Resolution in Dialogue: A Cross-Team Analysis",2021,-1,-1,3,0,11449,shengjie li,"Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue",0,"The CODI-CRAC 2021 shared task is the first shared task that focuses exclusively on anaphora resolution in dialogue and provides three tracks, namely entity coreference resolution, bridging resolution, and discourse deixis resolution. We perform a cross-task analysis of the systems that participated in the shared task in each of these tracks."
2020.lrec-1.839,Unsupervised Argumentation Mining in Student Essays,2020,-1,-1,2,1,18284,isaac persing,Proceedings of the 12th Language Resources and Evaluation Conference,0,"State-of-the-art systems for argumentation mining are supervised, thus relying on training data containing manually annotated argument components and the relationships between them. To eliminate the reliance on annotated data, we present a novel approach to unsupervised argument mining. The key idea is to bootstrap from a small set of argument components automatically identified using simple heuristics in combination with reliable contextual cues. Results on a Stab and Gurevych{'}s corpus of 402 essays show that our unsupervised approach rivals two supervised baselines in performance and achieves 73.5-83.7{\%} of the performance of a state-of-the-art neural approach."
2020.lrec-1.840,Aspect-Based Sentiment Analysis as Fine-Grained Opinion Mining,2020,-1,-1,3,0,18285,gerardo diaz,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We show how the general fine-grained opinion mining concepts of opinion target and opinion expression are related to aspect-based sentiment analysis (ABSA) and discuss their benefits for resource creation over popular ABSA annotation schemes. Specifically, we first discuss why opinions modeled solely in terms of (entity, aspect) pairs inadequately captures the meaning of the sentiment originally expressed by authors and how opinion expressions and opinion targets can be used to avoid the loss of information. We then design a meaning-preserving annotation scheme and apply it to two popular ABSA datasets, the 2016 SemEval ABSA Restaurant and Laptop datasets. Finally, we discuss the importance of opinion expressions and opinion targets for next-generation ABSA systems. We make our datasets publicly available for download."
2020.emnlp-main.536,Conundrums in Entity Coreference Resolution: Making Sense of the State of the Art,2020,-1,-1,2,1,4313,jing lu,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Despite the significant progress on entity coreference resolution observed in recent years, there is a general lack of understanding of what has been improved. We present an empirical analysis of state-of-the-art resolvers with the goal of providing the general NLP audience with a better understanding of the state of the art and coreference researchers with directions for future research."
2020.emnlp-main.571,Identifying Exaggerated Language,2020,-1,-1,5,0,20573,li kong,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"While hyperbole is one of the most prevalent rhetorical devices, it is arguably one of the least studied devices in the figurative language processing community. We contribute to the study of hyperbole by (1) creating a corpus focusing on sentence-level hyperbole detection, (2) performing a statistical and manual analysis of our corpus, and (3) addressing the automatic hyperbole detection task."
2020.coling-main.331,Bridging Resolution: A Survey of the State of the Art,2020,254,0,2,1,3640,hideo kobayashi,Proceedings of the 28th International Conference on Computational Linguistics,0,"Bridging reference resolution is an anaphora resolution task that is arguably more challenging and less studied than entity coreference resolution. Given that significant progress has been made on coreference resolution in recent years, we believe that bridging resolution will receive increasing attention in the NLP community. Nevertheless, progress on bridging resolution is currently hampered in part by the scarcity of large annotated corpora for model training as well as the lack of standardized evaluation protocols. This paper presents a survey of the current state of research on bridging reference resolution and discusses future research directions."
2020.aacl-main.66,Event Coreference Resolution with Non-Local Information,2020,-1,-1,2,1,4313,jing lu,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"We present two extensions to a state-of-theart joint model for event coreference resolution, which involve incorporating (1) a supervised topic model for improving trigger detection by providing global context, and (2) a preprocessing module that seeks to improve event coreference by discarding unlikely candidate antecedents of an event mention using discourse contexts computed based on salient entities. The resulting model yields the best results reported to date on the KBP 2017 English and Chinese datasets."
P19-1390,Give Me More Feedback {II}: Annotating Thesis Strength and Related Attributes in Student Essays,2019,0,0,4,0.666667,4367,zixuan ke,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"While the vast majority of existing work on automated essay scoring has focused on holistic scoring, researchers have recently begun work on scoring specific dimensions of essay quality. Nevertheless, progress on dimension-specific essay scoring is limited in part by the lack of annotated corpora. To facilitate advances in this area, we design a scoring rubric for scoring a core, yet unexplored dimension of persuasive essay quality, thesis strength, and annotate a corpus of essays with thesis strength scores. We additionally identify the attributes that could impact thesis strength and annotate the essays with the values of these attributes, which, when predicted by computational models, could provide further feedback to students on why her essay receives a particular thesis strength score."
N19-1085,Improving Event Coreference Resolution by Learning Argument Compatibility from Unlabeled Data,2019,0,0,4,0,10901,yin huang,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Argument compatibility is a linguistic condition that is frequently incorporated into modern event coreference resolution systems. If two event mentions have incompatible arguments in any of the argument roles, they cannot be coreferent. On the other hand, if these mentions have compatible arguments, then this may be used as information towards deciding their coreferent status. One of the key challenges in leveraging argument compatibility lies in the paucity of labeled data. In this work, we propose a transfer learning framework for event coreference resolution that utilizes a large amount of unlabeled data to learn argument compatibility of event mentions. In addition, we adopt an interactive inference network based model to better capture the compatible and incompatible relations between the context words of event mentions. Our experiments on the KBP 2017 English dataset confirm the effectiveness of our model in learning argument compatibility, which in turn improves the performance of the overall event coreference model."
P18-1058,Give Me More Feedback: Annotating Argument Persuasiveness and Related Attributes in Student Essays,2018,0,4,4,0,29115,winston carlile,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"While argument persuasiveness is one of the most important dimensions of argumentative essay quality, it is relatively little studied in automated essay scoring research. Progress on scoring argument persuasiveness is hindered in part by the scarcity of annotated corpora. We present the first corpus of essays that are simultaneously annotated with argument components, argument persuasiveness scores, and attributes of argument components that impact an argument{'}s persuasiveness. This corpus could trigger the development of novel computational models concerning argument persuasiveness that provide useful feedback to students on why their arguments are (un)persuasive in addition to how persuasive they are."
P18-1065,Modeling and Prediction of Online Product Review Helpfulness: A Survey,2018,0,9,2,0,18285,gerardo diaz,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"As the amount of free-form user-generated reviews in e-commerce websites continues to increase, there is an increasing need for automatic mechanisms that sift through the vast amounts of user reviews and identify quality content. Review helpfulness modeling is a task which studies the mechanisms that affect review helpfulness and attempts to accurately predict it. This paper provides an overview of the most relevant work in helpfulness prediction and understanding in the past decade, discusses the insights gained from said work, and provides guidelines for future research."
L18-1585,Modeling Trolling in Social Media Conversations,2018,0,4,2,1,25031,luis vega,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1588,Improving Unsupervised Keyphrase Extraction using Background Knowledge,2018,0,0,2,0,7098,yang yu,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
P17-1009,Joint Learning for Event Coreference Resolution,2017,22,8,2,1,4313,jing lu,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"While joint models have been developed for many NLP tasks, the vast majority of event coreference resolvers, including the top-performing resolvers competing in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, are pipeline-based, where the propagation of errors from the trigger detection component to the event coreference component is a major performance limiting factor. To address this problem, we propose a model for jointly learning event coreference, trigger detection, and event anaphoricity. Our joint model is novel in its choice of tasks and its features for capturing cross-task interactions. To our knowledge, this is the first attempt to train a mention-ranking model and employ event anaphoricity for event coreference. Our model achieves the best results to date on the KBP 2016 English and Chinese datasets."
I17-1060,Lightly-Supervised Modeling of Argument Persuasiveness,2017,22,0,2,1,18284,isaac persing,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"We propose the first lightly-supervised approach to scoring an argument{'}s persuasiveness. Key to our approach is the novel hypothesis that lightly-supervised persuasiveness scoring is possible by explicitly modeling the major errors that negatively impact persuasiveness. In an evaluation on a new annotated corpus of online debate arguments, our approach rivals its fully-supervised counterparts in performance by four scoring metrics when using only 10{\%} of the available training instances."
P16-1074,{C}hinese Zero Pronoun Resolution with Deep Neural Networks,2016,0,13,2,1,4438,chen chen,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
P16-1205,Modeling Stance in Student Essays,2016,19,7,2,1,18284,isaac persing,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
N16-1164,End-to-End Argumentation Mining in Student Essays,2016,20,22,2,1,18284,isaac persing,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
L16-1610,Syllable based {DNN}-{HMM} {C}antonese Speech to Text System,2016,18,0,9,0,35324,timothy wong,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper reports our work on building up a Cantonese Speech-to-Text (STT) system with a syllable based acoustic model. This is a part of an effort in building a STT system to aid dyslexic students who have cognitive deficiency in writing skills but have no problem expressing their ideas through speech. For Cantonese speech recognition, the basic unit of acoustic models can either be the conventional Initial-Final (IF) syllables, or the Onset-Nucleus-Coda (ONC) syllables where finals are further split into nucleus and coda to reflect the intra-syllable variations in Cantonese. By using the Kaldi toolkit, our system is trained using the stochastic gradient descent optimization model with the aid of GPUs for the hybrid Deep Neural Network and Hidden Markov Model (DNN-HMM) with and without I-vector based speaker adaptive training technique. The input features of the same Gaussian Mixture Model with speaker adaptive training (GMM-SAT) to DNN are used in all cases. Experiments show that the ONC-based syllable acoustic modeling with I-vector based DNN-HMM achieves the best performance with the word error rate (WER) of 9.66{\%} and the real time factor (RTF) of 1.38812."
L16-1631,Event Coreference Resolution with Multi-Pass Sieves,2016,20,1,2,1,4313,jing lu,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Multi-pass sieve approaches have been successfully applied to entity coreference resolution and many other tasks in natural language processing (NLP), owing in part to the ease of designing high-precision rules for these tasks. However, the same is not true for event coreference resolution: typically lying towards the end of the standard information extraction pipeline, an event coreference resolver assumes as input the noisy outputs of its upstream components such as the trigger identification component and the entity coreference resolution component. The difficulty in designing high-precision rules makes it challenging to successfully apply a multi-pass sieve approach to event coreference resolution. In this paper, we investigate this challenge, proposing the first multi-pass sieve approach to event coreference resolution. When evaluated on the version of the KBP 2015 corpus available to the participants of EN Task 2 (Event Nugget Detection and Coreference), our approach achieves an Avg F-score of 40.32{\%}, outperforming the best participating system by 0.67{\%} in Avg F-score."
L16-1695,{M}arkov {L}ogic {N}etworks for Text Mining: A Qualitative and Empirical Comparison with Integer Linear Programming,2016,15,2,2,1,25031,luis vega,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Joint inference approaches such as Integer Linear Programming (ILP) and Markov Logic Networks (MLNs) have recently been successfully applied to many natural language processing (NLP) tasks, often outperforming their pipeline counterparts. However, MLNs are arguably much less popular among NLP researchers than ILP. While NLP researchers who desire to employ these joint inference frameworks do not necessarily have to understand their theoretical underpinnings, it is imperative that they understand which of them should be applied under what circumstances. With the goal of helping NLP researchers better understand the relative strengths and weaknesses of MLNs and ILP; we will compare them along different dimensions of interest, such as expressiveness, ease of use, scalability, and performance. To our knowledge, this is the first systematic comparison of ILP and MLNs on an NLP task."
D16-2002,Advanced {M}arkov {L}ogic Techniques for Scalable Joint Inference in {NLP},2016,-1,-1,3,1,35502,deepak venugopal,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,0,"In the early days of the statistical NLP era, many language processing tasks were tackled using the so-called pipeline architecture: the given task is broken into a series of sub-tasks such that the output of one sub-task is an input to the next sub-task in the sequence. The pipeline architecture is appealing for various reasons, including modularity, modeling convenience, and manageable computational complexity. However, it suffers from the error propagation problem: errors made in one sub-task are propagated to the next sub-task in the sequence, leading to poor accuracy on that sub-task, which in turn leads to more errors downstream. Another disadvantage associated with it is lack of feedback: errors made in a sub-task are often not corrected using knowledge uncovered while solving another sub-task down the pipeline.Realizing these weaknesses, researchers have turned to joint inference approaches in recent years. One such approach involves the use of Markov logic, which is defined as a set of weighted first-order logic formulas and, at a high level, unifies first-order logic with probabilistic graphical models. It is an ideal modeling language (knowledge representation) for compactly representing relational and uncertain knowledge in NLP. In a typical use case of MLNs in NLP, the application designer describes the background knowledge using a few first-order logic sentences and then uses software packages such as Alchemy, Tuffy, and Markov the beast to perform learning and inference (prediction) over the MLN. However, despite its obvious advantages, over the years, researchers and practitioners have found it difficult to use MLNs effectively in many NLP applications. The main reason for this is that it is hard to scale inference and learning algorithms for MLNs to large datasets and complex models, that are typical in NLP.In this tutorial, we will introduce the audience to recent advances in scaling up inference and learning in MLNs as well as new approaches to make MLNs a ``black-box'' for NLP applications (with only minor tuning required on the part of the user). Specifically, we will introduce attendees to a key idea that has emerged in the MLN research community over the last few years, lifted inference , which refers to inference techniques that take advantage of symmetries (e.g., synonyms), both exact and approximate, in the MLN . We will describe how these next-generation inference techniques can be used to perform effective joint inference. We will also present our new software package for inference and learning in MLNs, Alchemy 2.0, which is based on lifted inference, focusing primarily on how it can be used to scale up inference and learning in large models and datasets for applications such as semantic similarity determination, information extraction and question answering."
C16-1308,Joint Inference for Event Coreference Resolution,2016,31,7,4,1,4313,jing lu,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Event coreference resolution is a challenging problem since it relies on several components of the information extraction pipeline that typically yield noisy outputs. We hypothesize that exploiting the inter-dependencies between these components can significantly improve the performance of an event coreference resolver, and subsequently propose a novel joint inference based event coreference resolver using Markov Logic Networks (MLNs). However, the rich features that are important for this task are typically very hard to explicitly encode as MLN formulas since they significantly increase the size of the MLN, thereby making joint inference and learning infeasible. To address this problem, we propose a novel solution where we implicitly encode rich features into our model by augmenting the MLN distribution with low dimensional unit clauses. Our approach achieves state-of-the-art results on two standard evaluation corpora."
S15-2146,{UTD}: Ensemble-Based Spatial Relation Extraction,2015,16,1,2,1,1752,jennifer dsouza,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"SpaceEval (SemEval 2015 Task 8), which concerns spatial information extraction, builds on the spatial role identification tasks introduced in SemEval 2012 and used in SemEval 2013. Among the host of subtasks presented in SpaceEval, we participated in subtask 3a, which focuses solely on spatial relation extraction. To address the complexity of a MOVELINK, we decompose it into smaller relations so that the roles involved in each relation can be extracted in a joint fashion without losing computational tractability. Our system was ranked first in the official evaluation, achieving an overall spatial relation extraction F-score of 84.5%."
P15-2049,Sieve-Based Entity Linking for the Biomedical Domain,2015,9,18,2,1,1752,jennifer dsouza,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We examine a key task in biomedical text processing, normalization of disorder mentions. We present a multi-pass sieve approach to this task, which has the advantage of simplicity and modularity. Our approach is evaluated on two datasets, one comprising clinical reports and the other comprising biomedical abstracts, achieving state-of-the-art results."
P15-2053,{C}hinese Zero Pronoun Resolution: A Joint Unsupervised Discourse-Aware Model Rivaling State-of-the-Art Resolvers,2015,24,13,2,1,4438,chen chen,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We propose an unsupervised probabilistic model for zero pronoun resolution. To our knowledge, this is the first such model that (1) is trained on zero pronouns in an unsupervised manner; (2) jointly identifies and resolves anaphoric zero pronouns; and (3) exploits discourse information provided by a salience model. Experiments demonstrate that our unsupervised model significantly outperforms its state-of-the-art unsupervised counterpart when resolving the Chinese zero pronouns in the OntoNotes corpus."
P15-1053,Modeling Argument Strength in Student Essays,2015,18,43,2,1,18284,isaac persing,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"While recent years have seen a surge of interest in automated essay grading, including work on grading essays with respect to particular dimensions such as prompt adherence, coherence, and technical quality, there has been relatively little work on grading the essay dimension of argument strength, which is arguably the most important aspect of argumentative essays. We introduce a new corpus of argumentative student essays annotated with argument strength scores and propose a supervised, feature-rich approach to automatically scoring the essays along this dimension. Our approach significantly outperforms a baseline that relies solely on heuristically applied sentence argument function labels by up to 16.1%."
N15-1116,{C}hinese Event Coreference Resolution: An Unsupervised Probabilistic Model Rivaling Supervised Resolvers,2015,30,3,2,1,4438,chen chen,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Recent work has successfully leveraged the semantic information extracted from lexical knowledge bases such as WordNet and FrameNet to improve English event coreference resolvers. The lack of comparable resources in other languages, however, has made the design of high-performance non-English event coreference resolvers, particularly those employing unsupervised models, very difficult. We propose a generative model for the under-studied task of Chinese event coreference resolution that rivals its supervised counterparts in performance when evaluated on the ACE 2005 corpus."
K15-1024,Recovering Traceability Links in Requirements Documents,2015,15,1,4,0,37723,zeheng li,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"Software system development is guided by the evolution of requirements. In this paper, we address the task of requirements traceability, which is concerned with providing bi-directional traceability between various requirements, enabling users to find the origin of each requirement and track every change made to it. We propose a knowledge-rich approach to the task, where we extend a supervised baseline system with (1) additional training instances derived from human-provided annotator rationales; and (2) additional features derived from a hand-built ontology. Experiments demonstrate that our approach yields a relative error reduction of 11.1xe2x80x9019.7%."
D15-1087,Sieve-Based Spatial Relation Extraction with Expanding Parse Trees,2015,23,2,2,1,1752,jennifer dsouza,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"A key challenge introduced by the recent SpaceEval shared task on spatial relation extraction is the identification of MOVELINKs, a type of spatial relation in which up to eight spatial elements can participate. To handle the complexity of extracting MOVELINKs, we combine two ideas that have been successfully applied to information extraction tasks, namely tree kernels and multi-pass sieves, proposing the use of an expanding parse tree as a novel structured feature for training MOVELINK classifiers. Our approach yields state-of-the-art results on two key tasks in SpaceEval."
P14-2006,Scoring Coreference Partitions of Predicted Mentions: A Reference Implementation,2014,19,67,5,0,11322,sameer pradhan,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,": The definitions of two coreference scoring metrics- B3 and CEAF-are underspecified with respect to predicted, as opposed to key (or gold) mentions. Several variations have been proposed that manipulate either, or both, the key and predicted mentions in order to get a one-to-one mapping. On the other hand, the metric BLANC was, until recently, limited to scoring partitions of key mentions. In this paper, we (i) argue that mention manipulation for scoring predicted mentions is unnecessary, and potentially harmful as it could produce unintuitive results; (ii) illustrate the application of all these measures to scoring predicted mentions; (iii) make available an open-source, thoroughly-tested reference implementation of the main coreference evaluation measures; and (iv) rescore the results of the CoNLL-2011/2012 shared task systems with this implementation. This will help the community accurately measure and compare new end-to-end coreference resolution algorithms."
P14-1119,Automatic Keyphrase Extraction: A Survey of the State of the Art,2014,64,207,2,1,21775,kazi hasan,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"While automatic keyphrase extraction has been examined extensively, state-of-theart performance on this task is still much lower than that on many core natural language processing tasks. We present a survey of the state of the art in automatic keyphrase extraction, examining the major sources of errors made by existing systems and discussing the challenges ahead."
P14-1144,Modeling Prompt Adherence in Student Essays,2014,19,21,2,1,18284,isaac persing,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Recently, researchers have begun exploring methods of scoring student essays with respect to particular dimensions of quality such as coherence, technical errors, and prompt adherence. The work on modeling prompt adherence, however, has been focused mainly on whether individual sentences adhere to the prompt. We present a new annotated corpus of essaylevel prompt adherence scores and propose a feature-rich approach to scoring essays along the prompt adherence dimension. Our approach significantly outperforms a knowledge-lean baseline prompt adherence scoring system yielding improvements of up to 16.6%."
chen-ng-2014-sinocoreferencer,{S}ino{C}oreferencer: An End-to-End {C}hinese Event Coreference Resolver,2014,17,8,2,1,4438,chen chen,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Compared to entity coreference resolution, there is a relatively small amount of work on event coreference resolution. Much work on event coreference was done for English. In fact, to our knowledge, there are no publicly available results on Chinese event coreference resolution. This paper describes the design, implementation, and evaluation of SinoCoreferencer, an end-to-end state-of-the-art ACE-style Chinese event coreference system. We have made SinoCoreferencer publicly available, in hope to facilitate the development of high-level Chinese natural language applications that can potentially benefit from event coreference information."
dsouza-ng-2014-annotating,Annotating Inter-Sentence Temporal Relations in Clinical Notes,2014,8,0,2,1,1752,jennifer dsouza,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Owing in part to the surge of interest in temporal relation extraction, a number of datasets manually annotated with temporal relations between event-event pairs and event-time pairs have been produced recently. However, it is not uncommon to find missing annotations in these manually annotated datasets. Many researchers attributed this problem to {``}annotator fatigue{''}. While some of these missing relations can be recovered automatically, many of them cannot. Our goals in this paper are to (1) manually annotate certain types of missing links that cannot be automatically recovered in the i2b2 Clinical Temporal Relations Challenge Corpus, one of the recently released evaluation corpora for temporal relation extraction; and (2) empirically determine the usefulness of these additional annotations. We will make our annotations publicly available, in hopes of enabling a more accurate evaluation of temporal relation extraction systems."
D14-1083,Why are You Taking this Stance? Identifying and Classifying Reasons in Ideological Debates,2014,33,83,2,1,21775,kazi hasan,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Recent years have seen a surge of interest in stance classification in online debates. Oftentimes, however, it is important to determine not only the stance expressed by an author in her debate posts, but also the reasons behind her supporting or opposing the issue under debate. We therefore examine the new task of reason classification in this paper. Given the close interplay between stance classification and reason classification, we design computational models for examining how automatically computed stance information can be profitably exploited for reason classification. Experiments on our reason-annotated corpus of ideological debate posts from four domains demonstrate that sophisticated models of stances and reasons can indeed yield more accurate reason and stance classification results than their simpler counterparts."
D14-1084,{C}hinese Zero Pronoun Resolution: An Unsupervised Probabilistic Model Rivaling Supervised Resolvers,2014,26,6,2,1,4438,chen chen,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"State-of-the-art Chinese zero pronoun resolution systems are supervised, thus relying on training data containing manually resolved zero pronouns. To eliminate the reliance on annotated data, we present a generative model for unsupervised Chinese zero pronoun resolution. At the core of our model is a novel hypothesis: a probabilistic pronoun resolver trained on overt pronouns in an unsupervised manner can be used to resolve zero pronouns. Experiments demonstrate that our unsupervised model rivals its state-ofthe-art supervised counterparts in performance when resolving the Chinese zero pronouns in the OntoNotes corpus."
D14-1090,Relieving the Computational Bottleneck: Joint Inference for Event Extraction with High-Dimensional Features,2014,60,16,4,1,35502,deepak venugopal,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Several state-of-the-art event extraction systems employ models based on Support Vector Machines (SVMs) in a pipeline architecture, which fails to exploit the joint dependencies that typically exist among events and arguments. While there have been attempts to overcome this limitation using Markov Logic Networks (MLNs), it remains challenging to perform joint inference in MLNs when the model encodes many high-dimensional sophisticated features such as those essential for event extraction. In this paper, we propose a new model for event extraction that combines the power of MLNs and SVMs, dwarfing their limitations. The key idea is to reliably learn and process high-dimensional features using SVMs; encode the output of SVMs as low-dimensional, soft formulas in MLNs; and use the superior joint inferencing power of MLNs to enforce joint consistency constraints over the soft formulas. We evaluate our approach for the task of extracting biomedical events on the BioNLP 2013, 2011 and 2009 Genia shared task datasets. Our approach yields the best F1 score to date on the BioNLPxe2x80x9913 (53.61) and BioNLPxe2x80x9911 (58.07) datasets and the second-best F1 score to date on the BioNLPxe2x80x9909 dataset (58.16)."
D14-1119,Vote Prediction on Comments in Social Polls,2014,23,7,2,1,18284,isaac persing,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"A poll consists of a question and a set of predefined answers from which voters can select. We present the new problem of vote prediction on comments, which involves determining which of these answers a voter selected given a comment she wrote after voting. To address this task, we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints. In an evaluation involving nearly one million comments collected from the popular SodaHead social polling website, we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information."
C14-1159,Ensemble-Based Medical Relation Classification,2014,32,4,2,1,1752,jennifer dsouza,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Despite the successes of distant supervision approaches to relation extraction in the news domain, the lack of a comprehensive ontology of medical relations makes it difficult to apply such approaches to relation classification in the medical domain. In light of this difficulty, we propose an ensemble approach to this task where we exploit human-supplied knowledge to guide the design of members of the ensemble. Results on the 2010 i2b2/VA Challenge corpus show that our ensemble approach yields a 19.8% relative error reduction over a state-of-the-art baseline."
W13-3514,Frame Semantics for Stance Classification,2013,18,13,2,1,21775,kazi hasan,Proceedings of the Seventeenth Conference on Computational Natural Language Learning,0,Determining the stance expressed by an author from a post written for a two-sided debate in an online debate forum is a relatively new problem in opinion mining. We extend a state-of-the-art learningbased approach to debate stance classification by (1) inducing lexico-syntactic patterns based on syntactic dependencies and semantic frames that aim to capture the meaning of a sentence and provide a generalized representation of it; and (2) improving the classification of a test post via a novel way of exploiting the information in other test posts with the same stance. Empirical results on four datasets demonstrate the effectiveness of our extensions.
W13-1720,Simple Yet Powerful Native Language Identification on {TOEFL}11,2013,8,2,4,0,41049,chingyi wu,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"Native language identification (NLI) is the task to determine the native language of the author based on an essay written in a second language. NLI is often treated as a classification problem. In this paper, we use the TOEFL11 data set which consists of more data, in terms of the amount of essays and languages, and less biased across prompts, i.e., topics, of essays. We demonstrate that even using word level n-grams as features, and support vector machine (SVM) as a classifier can yield nearly 80% accuracy. We observe that the accuracy of a binary-based word level ngram representation (~80%) is much better than the performance of a frequency-based word level n-gram representation (~20%). Notably, comparable results can be achieved without removing punctuation marks, suggesting a very simple baseline system for NLI."
P13-2142,Extra-Linguistic Constraints on Stance Recognition in Ideological Debates,2013,21,23,2,1,21775,kazi hasan,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Determining the stance expressed by an author from a post written for a twosided debate in an online debate forum is a relatively new problem. We seek to improve Anand et al.xe2x80x99s (2011) approach to debate stance classification by modeling two types of soft extra-linguistic constraints on the stance labels of debate posts, user-interaction constraints and ideology constraints. Experimental results on four datasets demonstrate the effectiveness of these inter-post constraints in improving debate stance classification."
P13-1026,Modeling Thesis Clarity in Student Essays,2013,18,14,2,1,18284,isaac persing,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Recently, researchers have begun exploring methods of scoring student essays with respect to particular dimensions of quality such as coherence, technical errors, and relevance to prompt, but there is relatively little work on modeling thesis clarity. We present a new annotated corpus and propose a learning-based approach to scoring essays along the thesis clarity dimension. Additionally, in order to provide more valuable feedback on why an essay is scored as it is, we propose a second learning-based approach to identifying what kinds of errors an essay has that may lower its thesis clarity score."
N13-1112,Classifying Temporal Relations with Rich Linguistic Knowledge,2013,18,25,2,1,1752,jennifer dsouza,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We examine the task of temporal relation classification. Unlike existing approaches to this task, we (1) classify an event-event or eventtime pair as one of the 14 temporal relations defined in the TimeBank corpus, rather than as one of the six relations collapsed from the original 14; (2) employ sophisticated linguistic knowledge derived from a variety of semantic and discourse relations, rather than focusing on morpho-syntactic knowledge; and (3) leverage a novel combination of rule-based and learning-based approaches, rather than relying solely on one or the other. Experiments with the TimeBank corpus demonstrate that our knowledge-rich, hybrid approach yields a 15xe2x80x9016% relative reduction in error over a state-of-the-art learning-based baseline system."
I13-1100,{C}hinese Event Coreference Resolution: Understanding the State of the Art,2013,16,2,2,1,4438,chen chen,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Given the relatively small amount of work on event coreference resolution, our understanding of the task is arguably fairly limited. This makes it difficult to determine how to improve an event coreference resolver. We seek to gain a better understanding of the state of the art in event coreference resolution by performing the first publicly available analysis of a Chinese event coreference resolver."
I13-1191,"Stance Classification of Ideological Debates: Data, Models, Features, and Constraints",2013,19,77,2,1,21775,kazi hasan,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Determining the stance expressed in a post written for a two-sided debate in an online debate forum is a relatively new and challenging problem in opinion mining. We seek to gain a better understanding of how to improve machine learning approaches to stance classification of ideological debates, specifically by examining how the performance of a learning-based stance classification system varies with the amount and quality of the training data, the complexity of the underlying model, the richness of the feature set, as well as the application of extra-linguistic constraints."
I13-1193,Linguistically Aware Coreference Evaluation Metrics,2013,7,5,2,1,4438,chen chen,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Virtually all the commonly-used evaluation metrics for entity coreference resolution are linguistically agnostic, treating the mentions to be clustered as generic rather than linguistic objects. We argue that the performance of an entity coreference resolver cannot be accurately reflected when it is evaluated using linguistically agnostic metrics. Consequently, we propose a framework for incorporating linguistic awareness into commonly-used coreference evaluation metrics."
D13-1135,{C}hinese Zero Pronoun Resolution: Some Recent Advances,2013,10,25,2,1,4438,chen chen,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"We extend Zhao and Ng's (2007) Chinese anaphoric zero pronoun resolver by (1) using a richer set of features and (2) exploiting the coreference links between zero pronouns during resolution. Results on OntoNotes show that our approach significantly outperforms two state-of-the-art anaphoric zero pronoun resolvers. To our knowledge, this is the first work to report results obtained by an end-toend Chinese zero pronoun resolver."
W12-4504,Combining the Best of Two Worlds: A Hybrid Approach to Multilingual Coreference Resolution,2012,9,36,2,1,4438,chen chen,Joint Conference on {EMNLP} and {C}o{NLL} - Shared Task,0,"We describe our system for the CoNLL-2012 shared task, which seeks to model coreference in OntoNotes for English, Chinese, and Arabic. We adopt a hybrid approach to coreference resolution, which combines the strengths of rule-based methods and learning-based methods. Our official combined score over all three languages is 56.35. In particular, our score on the Chinese test set is the best among the participating teams."
N12-1090,Translation-Based Projection for Multilingual Coreference Resolution,2012,35,14,2,1,42833,altaf rahman,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"To build a coreference resolver for a new language, the typical approach is to first coreference-annotate documents from this target language and then train a resolver on these annotated documents using supervised learning techniques. However, the high cost associated with manually coreference-annotating documents needed by a supervised approach makes it difficult to deploy coreference technologies across a large number of natural languages. To alleviate this corpus annotation bottleneck, we examine a translation-based projection approach to multilingual coreference resolution. Experimental results on two target languages demonstrate the promise of our approach."
E12-1081,Learning the Fine-Grained Information Status of Discourse Entities,2012,18,6,2,1,42833,altaf rahman,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"While information status (IS) plays a crucial role in discourse processing, there have only been a handful of attempts to automatically determine the IS of discourse entities. We examine a related but more challenging task, fine-grained IS determination, which involves classifying a discourse entity as one of 16 IS subtypes. We investigate the use of rich knowledge sources for this task in combination with a rule-based approach and a learning-based approach. In experiments with a set of Switchboard dialogues, the learning-based approach achieves an accuracy of 78.7%, outperforming the rule-based approach by 21.3%."
D12-1071,Resolving Complex Cases of Definite Pronouns: The {W}inograd Schema Challenge,2012,43,53,2,1,42833,altaf rahman,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"We examine the task of resolving complex cases of definite pronouns, specifically those for which traditional linguistic constraints on coreference (e.g., Binding Constraints, gender and number agreement) as well as commonly-used resolution heuristics (e.g., string-matching facilities, syntactic salience) are not useful. Being able to solve this task has broader implications in artificial intelligence: a restricted version of it, sometimes referred to as the Winograd Schema Challenge, has been suggested as a conceptually and practically appealing alternative to the Turing Test. We employ a knowledge-rich approach to this task, which yields a pronoun resolver that outperforms state-of-the-art resolvers by nearly 18 points in accuracy on our dataset."
C12-2019,{C}hinese Noun Phrase Coreference Resolution: Insights into the State of the Art,2012,10,2,2,1,4438,chen chen,Proceedings of {COLING} 2012: Posters,0,"Compared to the amount of research on English coreference resolution, relatively little work has been done on Chinese coreference resolution. Worse still, it has been difficult to determine the state of the art in Chinese coreference resolution, owing in part to the lack of a standard evaluation dataset. The organizers of the CoNLL-2012 shared task, Modeling Unrestricted Multilingual Coreference in OntoNotes, have recently addressed this issue by providing standard training and test sets for developing and evaluating Chinese coreference resolvers. We aim to gain insights into the state of the art via extensive experimentation with our Chinese resolver, which is ranked first in the shared task on the Chinese test data. Title and Abstract in Chinese"
C12-2045,Predicting Stance in Ideological Debate with Rich Linguistic Knowledge,2012,5,11,2,1,21775,kazi hasan,Proceedings of {COLING} 2012: Posters,0,"Debate stance classification, the task of classifying an author's stance in a two-sided debate, is a relatively new and challenging problem in opinion mining. One of its challenges stems from the fact that it is not uncommon to find words and phrases in a debate post that are indicative of the opposing stance, owing to the frequent need for an author to re-state other people's opinions so that she can refer to and contrast with them when establishing her own arguments. We propose a machine learning approach to debate stance classification that leverages two types of rich linguistic knowledge, one exploiting contextual information and the other involving the determination of the author's stances on topics. Experimental results on debate posts involving two popular debate domains demonstrate the effectiveness of our two types of linguistic knowledge when they are combined in an integer linear programming framework. Title and Abstract in Bengali xe0xa6x89 xe0xa6xa4 xe0xa6xadxe0xa6xbexe0xa6xb7xe0xa6xbexe0xa6xbfxe0xa6xacxe0xa6xa6 xe0xa6xbexe0xa6xb0 xe0xa6xb8xe0xa6xbexe0xa6xb9xe0xa6xbexe0xa7x87xe0xa6xaf xe0xa6xadxe0xa6xbexe0xa6xacxe0xa6xbexe0xa6xa6xe0xa6xbfxe0xa6xb6xe0xa6x95 xe0xa6xbfxe0xa6xacxe0xa6xa4xe0xa7x87xe0xa6x95xe0xa6xb0 xe0xa6xaa xe0xa6xbfxe0xa6xa8xe0xa6xa3xe0xa6xaf xe0xa6xbfxe0xa6xacxe0xa6xa4xe0xa7x87xe0xa6x95xe0xa6xb0 xe0xa6xaa xe0xa6xbfxe0xa6xa8xe0xa6xa3xe0xa6xaf xe0xa6xa4xe0xa6xa5xe0xa6xbe xe0xa6x8fxe0xa6x95xe0xa6xbfxe0xa6x9f xe0xa6xbf xe0xa6xaaxe0xa6xbexe0xa6xbf xe0xa6x95 xe0xa6xbfxe0xa6xacxe0xa6xa4xe0xa7x87xe0xa6x95 xe0xa6x8fxe0xa6x95xe0xa6x9cxe0xa6xa8 xe0xa6xa4xe0xa6xbexe0xa6xbfxe0xa6x95xe0xa6x95 xe0xa6x95xe0xa6xbexe0xa6xa8 xe0xa6xaa xe0xa6xbfxe0xa6xa8xe0xa7x87 xe0xa6xa8 xe0xa6xb8xe0xa6xbfxe0xa6x9f xe0xa6xbfxe0xa6xa8xe0xa6xa7xe0xa6xbexe0xa6xb0xe0xa6xa3 xe0xa6x95xe0xa6xb0xe0xa6xbe xe0xa6x93xe0xa6xbfxe0xa6xaaxe0xa6xbfxe0xa6xa8xe0xa6xafxe0xa6xa8 xe0xa6xaexe0xa6xbexe0xa6x87xe0xa6xbfxe0xa6xa8xe0xa6x82-xe0xa6x8f xe0xa6x8fxe0xa6x95xe0xa6xbfxe0xa6x9f xe0xa6x85xe0xa7x87xe0xa6xaa xe0xa6xbexe0xa6x95xe0xa6xa4 xe0xa6xa8xe0xa6xa4xe0xa6xa8 xe0xa6x8fxe0xa6xacxe0xa6x82 xe0xa6x9cxe0xa6xbfxe0xa6x9fxe0xa6xb2 xe0xa6xb8xe0xa6xae xe0xa6xbexe0xa5xa4 xe0xa6x8fxe0xa7x87 xe0xa7x87 xe0xa6x8fxe0xa6x95xe0xa6xbfxe0xa6x9f xe0xa6x85 xe0xa6xa4xe0xa6xae xe0xa6xbfxe0xa6xa4xe0xa6xac xe0xa6x95 xe0xa6xb9xe0xa7x87xe0xa6xb2xe0xa6xbe xe0xa6x8fxe0xa6x95xe0xa6x9cxe0xa6xa8 xe0xa6xa4xe0xa6xbexe0xa6xbfxe0xa6x95xe0xa7x87xe0xa6x95xe0xa6xb0 xe0xa6xb2xe0xa6x96xe0xa6xbexe0xa6xaf xe0xa6xbexe0xa6xafxe0xa6x87 xe0xa6xbfxe0xa6xacxe0xa6xaaxe0xa7x87 xe0xa6xb0 xe0xa6xac xe0xa6xac xe0xa6xa4 xe0xa6xb6 xe0xa6x8fxe0xa6xacxe0xa6x82 xe0xa6xacxe0xa6xbexe0xa6x95 xe0xa6xbexe0xa6x82xe0xa6xb6 xe0xa6xaaxe0xa6xbexe0xa6x93xe0xa6xafxe0xa6xbe xe0xa6xafxe0xa6xbexe0xa6xaf xe0xa6xafxe0xa6xbe xe0xa6x90 xe0xa6xa4xe0xa6xbexe0xa6xbfxe0xa6x95xe0xa6x95 xe0xa6x85 xe0xa6xaaxe0xa7x87 xe0xa6xb0 xe0xa6xafxe0xa6xbf xe0xa6xaaxe0xa6xa8 xe0xa7x87 xe0xa6x96 xe0xa6x8fxe0xa6xacxe0xa6x82 xe0xa6x96 xe0xa6xa1xe0xa7x87xe0xa6xa8xe0xa6xb0 xe0xa6xaexe0xa6xbexe0xa6xa7 xe0xa7x87xe0xa6xae xe0xa6xbfxe0xa6xa8xe0xa6x9c xe0xa6xafxe0xa6xbf xe0xa6x89xe0xa6xaa xe0xa6xbexe0xa6xaaxe0xa7x87xe0xa6xa8xe0xa6xb0 xe0xa6x9c xe0xa6xac xe0xa6xacxe0xa6xb9xe0xa6xbexe0xa6xb0 xe0xa6x95xe0xa7x87xe0xa6xb0xe0xa6xa8xe0xa5xa4 xe0xa6xbfxe0xa6xacxe0xa6xa4xe0xa7x87xe0xa6x95xe0xa6xb0 xe0xa6xaa xe0xa6xbfxe0xa6xa8xe0xa6xa3xe0xa7x87xe0xa6xafxe0xa6xb0 xe0xa6x9c xe0xa6x86xe0xa6xaexe0xa6xb0xe0xa6xbe xe0xa6x8fxe0xa6x95xe0xa6xbfxe0xa6x9f xe0xa6xaexe0xa6xbfxe0xa6xb6xe0xa6xa8 xe0xa6xb2xe0xa6xbexe0xa6xbfxe0xa6xa8xe0xa6x82 xe0xa6xaa xe0xa6xbfxe0xa6xa4 xe0xa6xbexe0xa6xac xe0xa6x95xe0xa6xb0xe0xa6xbfxe0xa6x9b xe0xa6xafxe0xa6xbexe0xa7x87xe0xa6xa4 xe0xa6x87 xe0xa6xa7xe0xa6xb0xe0xa7x87xe0xa6xa3xe0xa6xb0 xe0xa6x89 xe0xa6xa4 xe0xa6xadxe0xa6xbexe0xa6xb7xe0xa6xbexe0xa6xbfxe0xa6xacxe0xa6xa6 xe0xa6xbe xe0xa7x87xe0xa6xafxe0xa6xbexe0xa6x97 xe0xa6x95xe0xa6xb0xe0xa6xbe xe0xa6xb9xe0xa7x87xe0xa6xafxe0xa7x87xe0xa6x9b, xe0xa6xa5xe0xa6xaexe0xa6xbfxe0xa6x9f xe0xa6xbexe0xa6xb8xe0xa6x82xe0xa6xbfxe0xa6x97xe0xa6x95 xe0xa6xa4xe0xa6xa5 xe0xa6x8fxe0xa6xacxe0xa6x82 xe0xa6x85 xe0xa6xbfxe0xa6x9f xe0xa6xbfxe0xa6xacxe0xa6xbfxe0xa6xad xe0xa6x86xe0xa7x87xe0xa6xb2xe0xa6xbexe0xa6x9a xe0xa6xbfxe0xa6xacxe0xa6xb7xe0xa7x87xe0xa6xafxe0xa6xb0 xe0xa7x87 xe0xa6xa4xe0xa6xbexe0xa6xbfxe0xa6x95xe0xa7x87xe0xa6x95xe0xa6xb0 xe0xa6x85xe0xa6xbfxe0xa6xadxe0xa6xaexe0xa7x87xe0xa6xa4xe0xa6xb0 xe0xa6x89xe0xa6xaaxe0xa6xb0 xe0xa6xbfxe0xa6xadxe0xa6xbf xe0xa6x95xe0xa7x87xe0xa6xb0 xe0xa6xbfxe0xa6xa4xe0xa6xbf xe0xa6xa4xe0xa5xa4 xe0xa6xbfxe0xa6x9f xe0xa6xac xe0xa6xb2 xe0xa6x86xe0xa7x87xe0xa6xb2xe0xa6xbexe0xa6xbfxe0xa6x9axe0xa6xa4 xe0xa6xbfxe0xa6xacxe0xa6xb7xe0xa7x87xe0xa6xafxe0xa6xb0 xe0xa6xaaxe0xa7x87 -xe0xa6xbfxe0xa6xacxe0xa6xaaxe0xa7x87 xe0xa6xb2xe0xa6x96xe0xa6xbe xe0xa6xb0xe0xa6x9axe0xa6xa8xe0xa6xbexe0xa6xb0 xe0xa6x89xe0xa6xaaxe0xa6xb0 xe0xa6x9axe0xa6xbexe0xa6xb2xe0xa6xbexe0xa7x87xe0xa6xa8xe0xa6xbe xe0xa6xaaxe0xa6xb0xe0xa7x80 xe0xa6xbexe0xa6xb0 xe0xa6xabxe0xa6xb2xe0xa6xbexe0xa6xabxe0xa6xb2 xe0xa6x87xe0xa6xbf xe0xa6x9fxe0xa6x9cxe0xa6xbexe0xa6xb0 xe0xa6xbfxe0xa6xb2xe0xa6xbfxe0xa6xa8xe0xa6xafxe0xa6xbexe0xa6xb0 xe0xa6xbe xe0xa6xbexe0xa6xbfxe0xa6xaexe0xa6x82-xe0xa6x8fxe0xa6xb0 xe0xa6xb8xe0xa6xbexe0xa7x87xe0xa6xa5 xe0xa6xaf xe0xa6xbexe0xa6xac xe0xa6xbe xe0xa6x8fxe0xa6x87 xe0xa6x87 xe0xa6xa7xe0xa6xb0xe0xa7x87xe0xa6xa3xe0xa6xb0 xe0xa6x89 xe0xa6xa4 xe0xa6xadxe0xa6xbexe0xa6xb7xe0xa6xbexe0xa6xbfxe0xa6xacxe0xa6xa6 xe0xa6xbexe0xa6xb0 xe0xa6x95xe0xa6xbexe0xa6xafxe0xa6x95xe0xa6xbexe0xa6xbfxe0xa6xb0xe0xa6xa4xe0xa6xbe xe0xa6xaexe0xa6xbexe0xa6xa3 xe0xa6x95xe0xa7x87xe0xa6xb0xe0xa5xa4"
C12-1033,Joint Modeling for {C}hinese Event Extraction with Rich Linguistic Features,2012,23,34,2,1,4438,chen chen,Proceedings of {COLING} 2012,0,"Compared to the amount of research that has been done on English event extraction, there exists relatively little work on Chinese event extraction. We seek to push the frontiers of supervised Chinese event extraction research by proposing two extension to Li et al.'s (2012) state-of-the-art event extraction system. First, we employ a joint modeling approach to event extraction, aiming to address the error propagation problem inherent in Li et al.'s pipeline system architecture. Second, we investigate a variety of rich knowledge sources for Chinese event extraction that encode knowledge ranging from the character level to the discourse level. Experimental results on the ACE 2005 dataset show that our joint-modeling, knowledge-rich approach significantly outperforms Li et al.'s approach. Title and Abstract in Chinese xe8xbfx90xe7x94xa8xe4xb8xb0xe5xafx8cxe8xafxadxe8xa8x80xe5xadxa6xe7x89xb9xe5xbex81xe7x9ax84xe4xb8xadxe6x96x87xe4xbax8bxe4xbbxb6xe6x8axbdxe5x8fx96xe8x81x94xe5x90x88xe6xa8xa1xe5x9ex8b xe6x96x87xe7x9ax84xe4xbax8bxe4xbbxb6xe6x8axbdxe5x8fx96 xe4xb8xadxe6x96x87xe7x9ax84xe4xbax8bxe4xbbxb6xe6x8axbdxe5x8fx96 Li et al.(2012)xe7x9ax84 xe5xadxa6 xe7x9ax84xe4xbax8bxe4xbbxb6xe6x8axbdxe5x8fx96 xe4xb8xadxe6x96x87xe4xbax8bxe4xbbxb6xe6x8axbdxe5x8fx96xe7x9ax84 xe7x94xa8 xe8x81x94xe5x90x88xe6xa8xa1xe5x9ex8b Li et al. xe4xb8xadxe7x9ax84 xe4xb8xadxe6x96x87 xe6x8axbdxe5x8fx96 xe6x96x87 xe7x9ax84xe7x89xb9xe5xbex81 ACE2005 xe7x9ax84 xe8xbfx90xe7x94xa8xe4xb8xb0xe5xafx8cxe8xafxadxe8xa8x80xe5xadxa6xe7x89xb9xe5xbex81xe7x9ax84xe8x81x94xe5x90x88xe6xa8xa1xe5x9ex8b Li et al.xe7x9ax84"
P11-1082,Coreference Resolution with World Knowledge,2011,29,85,2,1,42833,altaf rahman,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"While world knowledge has been shown to improve learning-based coreference resolvers, the improvements were typically obtained by incorporating world knowledge into a fairly weak baseline resolver. Hence, it is not clear whether these benefits can carry over to a stronger baseline. Moreover, since there has been no attempt to apply different sources of world knowledge in combination to coreference resolution, it is not clear whether they offer complementary benefits to a resolver. We systematically compare commonly-used and under-investigated sources of world knowledge for coreference resolution by applying them to two learning-based coreference models and evaluating them on documents annotated with two different annotation schemes."
I11-1052,Syntactic Parsing for Ranking-Based Coreference Resolution,2011,26,4,2,1,42833,altaf rahman,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Recent research efforts have led to the development of a state-of-the-art supervised coreference model, the cluster-ranking model. However, it is not clear whether the features that have been shown to be useful when employed in traditional coreference models will fare similarly when used in combination with this new model. Rather than merely re-evaluate them using the cluster-ranking model, we examine two interesting types of features derived from syntactic parses, tree-based features and path-based features, and discuss the challenges involved in employing them in the cluster-ranking model. Results on a set of Switchboard dialogues show their effectiveness in improving the cluster-ranking model: using them to augment a baseline coreference feature set yields a 8.6xe2x80x9011.7% reduction in relative error."
D11-1099,Learning the Information Status of Noun Phrases in Spoken Dialogues,2011,37,8,2,1,42833,altaf rahman,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"An entity in a dialogue may be old, new, or mediated/inferrable with respect to the hearer's beliefs. Knowing the information status of the entities participating in a dialogue can therefore facilitate its interpretation. We address the under-investigated problem of automatically determining the information status of discourse entities. Specifically, we extend Nissim's (2006) machine learning approach to information-status determination with lexical and structured features, and exploit learned knowledge of the information status of each discourse entity for coreference resolution. Experimental results on a set of Switchboard dialogues reveal that (1) incorporating our proposed features into Nissim's feature set enables our system to achieve state-of-the-art performance on information-status classification, and (2) the resulting information can be used to improve the performance of learning-based coreference resolvers."
P10-1142,Supervised Noun Phrase Coreference Research: The First Fifteen Years,2010,141,157,1,1,3641,vincent ng,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,The research focus of computational coreference resolution has exhibited a shift from heuristic approaches to machine learning approaches in the past decade. This paper surveys the major milestones in supervised coreference research since its inception fifteen years ago.
D10-1023,Modeling Organization in Student Essays,2010,23,22,3,1,18284,isaac persing,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"Automated essay scoring is one of the most important educational applications of natural language processing. Recently, researchers have begun exploring methods of scoring essays with respect to particular dimensions of quality such as coherence, technical errors, and relevance to prompt, but there is relatively little work on modeling organization. We present a new annotated corpus and propose heuristic-based and learning-based approaches to scoring essays along the organization dimension, utilizing techniques that involve sequence alignment, alignment kernels, and string kernels."
C10-2042,Conundrums in Unsupervised Keyphrase Extraction: Making Sense of the State-of-the-Art,2010,19,103,2,1,21775,kazi hasan,Coling 2010: Posters,0,"State-of-the-art approaches for unsupervised keyphrase extraction are typically evaluated on a single dataset with a single parameter setting. Consequently, it is unclear how effective these approaches are on a new dataset from a different domain, and how sensitive they are to changes in parameter settings. To gain a better understanding of state-of-the-art unsupervised keyphrase extraction algorithms, we conduct a systematic evaluation and analysis of these algorithms on a variety of standard evaluation datasets."
C10-1105,Inducing Fine-Grained Semantic Classes via Hierarchical and Collective Classification,2010,15,25,2,1,42833,altaf rahman,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Research in named entity recognition and mention detection has typically involved a fairly small number of semantic classes, which may not be adequate if semantic class information is intended to support natural language applications. Motivated by this observation, we examine the under-studied problem of semantic subtype induction, where the goal is to automatically determine which of a set of 92 fine-grained semantic classes a noun phrase belongs to. We seek to improve the standard supervised approach to this problem using two techniques: hierarchical classification and collective classification. Experimental results demonstrate the effectiveness of these techniques, whether or not they are applied in isolation or in combination with the standard approach."
W09-2211,Discriminative Models for Semi-Supervised Natural Language Learning,2009,17,1,2,1,37433,sajib dasgupta,Proceedings of the {NAACL} {HLT} 2009 Workshop on Semi-supervised Learning for Natural Language Processing,0,"An interesting question surrounding semi-supervised learning for NLP is: should we use discriminative models or generative models? Despite the fact that generative models have been frequently employed in a semi-supervised setting since the early days of the statistical revolution in NLP, we advocate the use of discriminative models. The ability of discriminative models to handle complex, high-dimensional feature spaces and their strong theoretical guarantees have made them a very appealing alternative to their generative counterparts. Perhaps more importantly, discriminative models have been shown to offer competitive performance on a variety of sequential and structured learning tasks in NLP that are traditionally tackled via generative models, such as letter-to-phoneme conversion (Jiampojamarn et al., 2008), semantic role labeling (Toutanova et al., 2005), syntactic parsing (Taskar et al., 2004), language modeling (Roark et al., 2004), and machine translation (Liang et al., 2006). While generative models allow the seamless integration of prior knowledge, discriminative models seem to outperform generative models in a no prior, agnostic learning setting. See Ng and Jordan (2002) and Toutanova (2006) for insightful comparisons of generative and discriminative models."
P09-1079,"Mine the Easy, Classify the Hard: A Semi-Supervised Approach to Automatic Sentiment Classification",2009,20,111,2,1,37433,sajib dasgupta,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Supervised polarity classification systems are typically domain-specific. Building these systems involves the expensive process of annotating a large amount of data for each domain. A potential solution to this corpus annotation bottleneck is to build unsupervised polarity classification systems. However, unsupervised learning of polarity is difficult, owing in part to the prevalence of sentimentally ambiguous reviews, where reviewers discuss both the positive and negative aspects of a product. To address this problem, we propose a semi-supervised approach to sentiment classification where we first mine the unambiguous reviews using spectral techniques and then exploit them to classify the ambiguous reviews via a novel combination of active learning, transductive learning, and ensemble learning."
P09-1095,Semi-Supervised Cause Identification from Aviation Safety Reports,2009,13,18,2,1,18284,isaac persing,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"We introduce cause identification, a new problem involving classification of incident reports in the aviation domain. Specifically, given a set of pre-defined causes, a cause identification system seeks to identify all and only those causes that can explain why the aviation incident described in a given report occurred. The difficulty of cause identification stems in part from the fact that it is a multi-class, multilabel categorization task, and in part from the skewness of the class distributions and the scarcity of annotated reports. To improve the performance of a cause identification system for the minority classes, we present a bootstrapping algorithm that automatically augments a training set by learning from a small amount of labeled data and a large amount of unlabeled data. Experimental results show that our algorithm yields a relative error reduction of 6.3% in F-measure for the minority classes in comparison to a baseline that learns solely from the labeled data."
N09-1065,Graph-Cut-Based Anaphoricity Determination for Coreference Resolution,2009,29,29,1,1,3641,vincent ng,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Recent work has shown that explicitly identifying and filtering non-anaphoric mentions prior to coreference resolution can improve the performance of a coreference system. We present a novel approach to this task of anaphoricity determination based on graph cuts, and demonstrate its superiority to competing approaches by comparing their effectiveness in improving a learning-based coreference system on the ACE data sets."
E09-1041,"Learning-Based Named Entity Recognition for Morphologically-Rich, Resource-Scarce Languages",2009,24,14,3,1,21775,kazi hasan,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Named entity recognition for morphologically rich, case-insensitive languages, including the majority of semitic languages, Iranian languages, and Indian languages, is inherently more difficult than its English counterpart. Worse still, progress on machine learning approaches to named entity recognition for many of these languages is currently hampered by the scarcity of annotated data and the lack of an accurate part-of-speech tagger. While it is possible to rely on manually-constructed gazetteers to combat data scarcity, this gazetteer-centric approach has the potential weakness of creating irreproducible results, since these name lists are not publicly available in general. Motivated in part by this concern, we present a learning-based named entity recognizer that does not rely on manually-constructed gazetteers, using Bengali as our representative resource-scarce, morphologically-rich language. Our recognizer achieves a relative improvement of 7.5% in F-measure over a baseline recognizer. Improvements arise from (1) using induced affixes, (2) extracting information from online lexical databases, and (3) jointly modeling part-of-speech tagging and named entity recognition."
E09-1042,"Weakly Supervised Part-of-Speech Tagging for Morphologically-Rich, Resource-Scarce Languages",2009,21,12,2,1,21775,kazi hasan,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"This paper examines unsupervised approaches to part-of-speech (POS) tagging for morphologically-rich, resource-scarce languages, with an emphasis on Goldwater and Griffiths's (2007) fully-Bayesian approach originally developed for English POS tagging. We argue that existing unsupervised POS taggers unrealistically assume as input a perfect POS lexicon, and consequently, we propose a weakly supervised fully-Bayesian approach to POS tagging, which relaxes the unrealistic assumption by automatically acquiring the lexicon from a small amount of POS-tagged data. Since such relaxation comes at the expense of a drop in tagging accuracy, we propose two extensions to the Bayesian framework and demonstrate that they are effective in improving a fully-Bayesian POS tagger for Bengali, our representative morphologically-rich, resource-scarce language."
D09-1061,"Topic-wise, Sentiment-wise, or Otherwise? {I}dentifying the Hidden Dimension for Unsupervised Text Classification",2009,24,44,2,1,37433,sajib dasgupta,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"While traditional work on text clustering has largely focused on grouping documents by topic, it is conceivable that a user may want to cluster documents along other dimensions, such as the author's mood, gender, age, or sentiment. Without knowing the user's intention, a clustering algorithm will only group documents along the most prominent dimension, which may not be the one the user desires. To address this problem, we propose a novel way of incorporating user feedback into a clustering algorithm, which allows a user to easily specify the dimension along which she wants the data points to be clustered via inspecting only a small number of words. This distinguishes our method from existing ones, which typically require a large amount of effort on the part of humans in the form of document annotation or interactive construction of the feature space. We demonstrate the viability of our method on several challenging sentiment datasets."
D09-1101,Supervised Models for Coreference Resolution,2009,-1,-1,2,1,42833,altaf rahman,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,None
J08-3006,Book Reviews: Semisupervised Learning for Computational Linguistics by Steven Abney,2008,-1,-1,1,1,3641,vincent ng,Computational Linguistics,0,None
D08-1067,Unsupervised Models for Coreference Resolution,2008,52,179,1,1,3641,vincent ng,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Traditional learning-based coreference resolvers operate by training a mention-pair classifier for determining whether two mentions are coreferent or not. Two independent lines of recent research have attempted to improve these mention-pair classifiers, one by learning a mention-ranking model to rank preceding mentions for a given anaphor, and the other by training an entity-mention classifier to determine whether a preceding cluster is coreferent with a given mention. We propose a cluster-ranking approach to coreference resolution that combines the strengths of mention rankers and entity-mention models. We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution. Experimental results on the ACE data sets demonstrate its superior performance to competing approaches."
P07-1068,Semantic Class Induction and Coreference Resolution,2007,26,46,1,1,3641,vincent ng,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"This paper examines whether a learningbased coreference resolver can be improved using semantic class knowledge that is automatically acquired from a version of the Penn Treebank in which the noun phrases are labeled with their semantic classes. Experiments on the ACE test data show that a resolver that employs such induced semantic class knowledge yields a statistically significant improvement of 2% in F-measure over one that exploits heuristically computed semantic class knowledge. In addition, the induced knowledge improves the accuracy of common noun resolution by 2-6%."
N07-1020,"High-Performance, Language-Independent Morphological Segmentation",2007,8,53,2,1,37433,sajib dasgupta,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"This paper introduces an unsupervised morphological segmentation algorithm that shows robust performance for four languages with different levels of morphological complexity. In particular, our algorithm outperforms Goldsmithis Linguistica and Creutz and Lagusis Morphessor for English and Bengali, and achieves performance that is comparable to the best results for all three PASCAL evaluation datasets. Improvements arise from (1) the use of relative corpus frequency and suffix level similarity for detecting incorrect morpheme attachments and (2) the induction of orthographic rules and allomorphs for segmenting words where roots exhibit spelling changes during morpheme attachments."
D07-1023,Unsupervised Part-of-Speech Acquisition for Resource-Scarce Languages,2007,21,22,2,1,37433,sajib dasgupta,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"This paper proposes a new bootstrapping approach to unsupervised part-of-speech induction. In comparison to previous bootstrapping algorithms developed for this problem, our approach aims to improve the quality of the seed clusters by employing seed words that are both distributionally and morphologically reliable. In particular, we present a novel method for combining morphological and distributional information for seed selection. Experimental results demonstrate that our approach works well for English and Bengali, thus providing suggestive evidence that it is applicable to both morphologically impoverished languages and highly inflectional languages."
P06-2079,Examining the Role of Linguistic Knowledge Sources in the Automatic Identification and Classification of Reviews,2006,26,185,1,1,3641,vincent ng,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"This paper examines two problems in document-level sentiment analysis: (1) determining whether a given document is a review or not, and (2) classifying the polarity of a review as positive or negative. We first demonstrate that review identification can be performed with high accuracy using only unigrams as features. We then examine the role of four types of simple linguistic knowledge sources in a polarity classification system."
P05-1020,Machine Learning for Coreference Resolution: From Local Classification to Global Ranking,2005,26,73,1,1,3641,vincent ng,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems. We propose a set of partition-based features to learn a ranking model for distinguishing good and bad partitions. Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets."
P04-1020,Learning Noun Phrase Anaphoricity to Improve Conference Resolution: Issues in Representation and Optimization,2004,19,59,1,1,3641,vincent ng,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"Knowledge of the anaphoricity of a noun phrase might be profitably exploited by a coreference system to bypass the resolution of non-anaphoric noun phrases. Perhaps surprisingly, recent attempts to incorporate automatically acquired anaphoricity information into coreference systems, however, have led to the degradation in resolution performance. This paper examines several key issues in computing and using anaphoricity information to improve learning-based coreference systems. In particular, we present a new corpus-based approach to anaphoricity determination. Experiments on three standard coreference data sets demonstrate the effectiveness of our approach."
W03-1015,Bootstrapping Coreference Classifiers with Multiple Machine Learning Algorithms,2003,18,39,1,1,3641,vincent ng,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,0,"Successful application of multi-view co-training algorithms relies on the ability to factor the available features into views that are compatible and uncorrelated. This can potentially preclude their use on problems such as coreference resolution that lack an obvious feature split. To bootstrap coreference classifiers, we propose and evaluate a single-view weakly supervised algorithm that relies on two different learning algorithms in lieu of the two different views required by co-training. In addition, we investigate a method for ranking unlabeled instances to be fed back into the bootstrapping loop as labeled data, aiming to alleviate the problem of performance deterioration that is commonly observed in the course of bootstrapping."
N03-1023,Weakly Supervised Natural Language Learning Without Redundant Views,2003,23,95,1,1,3641,vincent ng,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We investigate single-view algorithms as an alternative to multi-view algorithms for weakly supervised learning for natural language processing tasks without a natural feature split. In particular, we apply co-training, self-training, and EM to one such task and find that both self-training and FS-EM, a new variation of EM that incorporates feature selection, outperform co-training and are comparatively less sensitive to parameter changes."
W02-1008,Combining Sample Selection and Error-Driven Pruning for Machine Learning of Coreference Rules,2002,16,44,1,1,3641,vincent ng,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"Most machine learning solutions to noun phrase coreference resolution recast the problem as a classification task. We examine three potential problems with this reformulation, namely, skewed class distributions, the inclusion of hard training instances, and the loss of transitivity inherent in the original coreference relation. We show how these problems can be handled via intelligent sample selection and error-driven pruning of classification rule-sets. The resulting system achieves an F-measure of 69.5 and 63.4 on the MUC-6 and MUC-7 coreference resolution data sets, respectively, surpassing the performance of the best MUC-6 and MUC-7 coreference systems. In particular, the system outperforms the best-performing learning-based coreference system to date."
P02-1014,Improving Machine Learning Approaches to Coreference Resolution,2002,13,559,1,1,3641,vincent ng,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC-6 and MUC-7 coreference resolution data sets --- F-measures of 70.4 and 63.4, respectively. Improvements arise from two sources: extra-linguistic changes to the learning framework and a large-scale expansion of the feature set to include more sophisticated linguistic knowledge."
C02-1139,Identifying Anaphoric and Non-Anaphoric Noun Phrases to Improve Coreference Resolution,2002,19,127,1,1,3641,vincent ng,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We present a supervised learning approach to identification of anaphoric and non-anaphoric noun phrases and show how such information can be incorporated into a coreference resolution system. The resulting system outperforms the best MUC-6 and MUC-7 coreference resolution systems on the corresponding MUC coreference data sets, obtaining F-measures of 66.2 and 64.0, respectively."
H01-1054,Multidocument Summarization via Information Extraction,2001,12,90,4,0,1437,michael white,Proceedings of the First International Conference on Human Language Technology Research,0,"We present and evaluate the initial version of RIPTIDES, a system that combines information extraction, extraction-based summarization, and natural language generation to support user-directed multidocument summarization."
A00-1025,Examining the Role of Statistical and Linguistic Knowledge Sources in a General-Knowledge Question-Answering System,2000,25,66,2,0,3442,claire cardie,Sixth Applied Natural Language Processing Conference,0,"We describe and evaluate an implemented system for general-knowledge question answering. The system combines techniques for standard ad-hoc information retrieval (IR), query-dependent text summarization, and shallow syntactic and semantic sentence analysis. In a series of experiments we examine the role of each statistical and linguistic knowledge source in the question-answering system. In contrast to previous results, we find first that statistical knowledge of word co-occurrences as computed by IR vector space methods can be used to quickly and accurately locate the relevant documents for each question. The use of query-dependent text summarization techniques, however, provides only small increases in performance and severely limits recall levels when inaccurate. Nevertheless, it is the text summarization component that allows subsequent linguistic filters to focus on relevant passages. We find that even very weak linguistic knowledge can offer substantial improvements over purely IRbased techniques for question answering, especially when smoothly integrated with statistical preferences computed by the IR subsystems."
