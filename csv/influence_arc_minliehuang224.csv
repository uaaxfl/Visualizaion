2020.aacl-main.16,C14-1001,0,0.0121497,"Model World Model World Model Learning DDQ Human Conversational Data Supervised Learning Acting Direct RL User Real Experience User Estimator OPPA Imitation Learning ?? ( ?$? ?? # Policy Model Direct RL Acting User Real Experience Figure 1: A comparison of dialogue policy learning a) with real/simulated user, b) with real user via DDQ and c) with real user guided by active user estimation. more efficient but also improve the target agent’s performance. In agreement with the findings from cognitive science, humans often maintain models of other people they interact with to capture their goals (Harper, 2014; Premack and Woodruff, 1978). And humans manage to use their mental process to simulate others’ behavior (Gordon, 1986; Gallese and Goldman, 1998). Therefore, to carefully treat and model the behaviors of other agents would be full of potential. For example, in competitive tasks such as chess, the player often sees a number of moves ahead by considering the possible reaction of the other player. In goal-oriented dialogues for a hotel booking task, the agent can reduce interaction numbers and improve user experience by modeling users as business travellers with strict time limit or backpackers"
2020.aacl-main.16,2020.sigdial-1.36,0,0.0249627,"selines. 1 Introduction In goal-oriented dialogue systems, dialogue policy plays a crucial role by deciding the next action to take conditioned on the dialogue state. This problem is often formulated using reinforcement learning (RL) in which the user serves as the environment (Levin et al., 1997; Rieser and Lemon, 2011; Lemon and Pietquin, 2012; Young et al., 2013; Fatemi et al., 2016; Zhao and Eskenazi, 2016; Dhingra et al., 2016; Su et al., 2016; Li et al., 2017; Williams et al., 2017; Liu and Lane, 2017; Lipton et al., 2018; Liu et al., 2018; Gao et al., 2019; Takanobu et al., 2019, 2020; Jhunjhunwala et al., 2020). However, different from symbolic-based and simulation-based RL tasks, such as chess (Silver et al., 2016) and video games (Mnih et al., ∗ Corresponding author. § {liuzitao,galehuang}@100tal.com 2015), which can get vast amounts of training interactions in low cost, dialogue systems require to learn directly from real users, which is too expensive. Therefore, there are some efforts using simulation methods to provide an affordable training environment. One principle direction for mitigating this problem is to leverage human conversation data to build a user simulator, and then to learn the di"
2020.aacl-main.16,W18-5007,0,0.0131494,"et al., 2016) is a widely applied rule-based method, which starts with a randomly generated user goal that is unknown to the system. During a dialogue session, it remains a stack data structure known as user agenda, which holds some pending user intentions to achieve. In the stack update process, machine learning or expert-defined methods can be applied. There are also some model-based methods that learn a simulator from real conversation data. The seq2seq framework has recently been introduced by encoding dialogue history and generates the next response or dialogue action (Asri et al., 2016; Kreyssig et al., 2018). By incorporating a variational step to the seq2seq network, it can introduce meaningful diversity into the simulator (G¨ur et al., 2018). Our work tackles the problem from a different point of view. We let the target agent approximate an opposite agent model to save user simulation efforts. 3 Model In this section, we introduce our proposed OPPA model. There are two agents in our framework, one is the system agent we want to optimize, and the other is the user agent. We refer to these two agents as target and opposite agents in the following sections. Note that the proposed model works at di"
2020.aacl-main.16,D17-1259,0,0.377378,"goal-oriented dialogue dataset, which contains 7 domains, 13 intents and 25 slot types. There are 10,483 sessions and 71,544 turns, which is at least one order of magnitude larger than previous annotated task-oriented dialogue dataset. Among all the dialogue sessions, we used 1,000 each for validation and test. Specifically, in the data collection stage, the user follows a specific goal to converse with the agent but is encouraged to change his/her goal dynamically during the session, which makes the dataset more challenging. For the competitive task, we used a bilateral negotiation dataset (Lewis et al., 2017), where there are 5,808 dialogues from 2,236 scenarios. In each session, there are two people negotiating to divide some items, such as books, hats and balls. Each kind of item is of different value to each person, thus they can give priority to valuable items in the negotiation. For example, a hat may worth 5 for person A and 3 for person B, so B can give up some hat in order to get other valuable items. To conduct our experiment, we further labeled the dataset with system dialogue actions. 126 4.2 We implemented the model using PyTorch (Paszke et al., 2017). The hyper-parameters were decided"
2020.aacl-main.16,P17-1045,0,0.0298629,"Missing"
2020.aacl-main.16,I17-1074,0,0.0698595,"Missing"
2020.aacl-main.16,W16-3613,0,0.0349863,"Missing"
2020.aacl-main.16,N18-1187,0,0.0128112,"ogue tasks, showing superior performance over state-of-the-art baselines. 1 Introduction In goal-oriented dialogue systems, dialogue policy plays a crucial role by deciding the next action to take conditioned on the dialogue state. This problem is often formulated using reinforcement learning (RL) in which the user serves as the environment (Levin et al., 1997; Rieser and Lemon, 2011; Lemon and Pietquin, 2012; Young et al., 2013; Fatemi et al., 2016; Zhao and Eskenazi, 2016; Dhingra et al., 2016; Su et al., 2016; Li et al., 2017; Williams et al., 2017; Liu and Lane, 2017; Lipton et al., 2018; Liu et al., 2018; Gao et al., 2019; Takanobu et al., 2019, 2020; Jhunjhunwala et al., 2020). However, different from symbolic-based and simulation-based RL tasks, such as chess (Silver et al., 2016) and video games (Mnih et al., ∗ Corresponding author. § {liuzitao,galehuang}@100tal.com 2015), which can get vast amounts of training interactions in low cost, dialogue systems require to learn directly from real users, which is too expensive. Therefore, there are some efforts using simulation methods to provide an affordable training environment. One principle direction for mitigating this problem is to leverage"
2020.aacl-main.16,P18-1203,0,0.390173,"this problem is to leverage human conversation data to build a user simulator, and then to learn the dialogue policy by making simulated interactions with the simulator (Schatzmann et al., 2006; Li et al., 2016; G¨ur et al., 2018). However, there always exist discrepancies between simulated users and real users due to the inductive biases of the simulation model, which can lead to a sub-optimal dialogue policy (Dhingra et al., 2016). Another direction is to learn the dynamics of dialogue environment during interacting with real user, and concurrently use the learned dynamics for RL planning (Peng et al., 2018; Su et al., 2018; Wu et al., 2018; Zhang et al., 2019b). Most of these works are based on Deep Dyna-Q (DDQ) framework (Sutton, 1990), where a world model is introduced to learn the dynamics (which is much like a simulated user) from real experiences. The target agent’s policy is trained using both real experiences via direct RL and simulated experiences via a world-model. In the above methods, both the simulated user and world model facilitate target policy learning by providing more simulated experiences and remain a black box for the target agent. That is, the target agent’s knowledge about"
2020.aacl-main.16,D17-1237,0,0.0139645,"ied in dialogue policy learning, including DQN (Mnih et al., 2015) and Policy Gradient (Sutton et al., 2000) methods, which mitigate the problem of domain adaptation through function approximation and representation learning (Zhao and Eskenazi, 2016). Recently, there are some efforts focused on multi-domain dialogue policy. An intuitive way is to learn independent policies for each specific domain and aggregate them (Wang et al., 2014; Gaˇsi´c 123 et al., 2015; Cuay´ahuitl et al., 2016). There are also some works using hierarchical RL, which decomposes the complex task into several sub-tasks (Peng et al., 2017; Casanueva et al., 2018) according to pre-defined domain structure and cross-domain constraints. Nevertheless, most of the above works regard the opposite agent as part of the environment without explicitly modeling its behavior. Planning based RL methods are also introduced to make a trade-off between reducing human interaction cost and learning a more realistic simulator. Peng et al. (2018) proposed to use Deep Dynamic Q-network, in which a world model is co-trained with the target policy model. By training the world model with the real system-human interaction data, it consistently approac"
2020.aacl-main.16,D18-1416,0,0.335433,"leverage human conversation data to build a user simulator, and then to learn the dialogue policy by making simulated interactions with the simulator (Schatzmann et al., 2006; Li et al., 2016; G¨ur et al., 2018). However, there always exist discrepancies between simulated users and real users due to the inductive biases of the simulation model, which can lead to a sub-optimal dialogue policy (Dhingra et al., 2016). Another direction is to learn the dynamics of dialogue environment during interacting with real user, and concurrently use the learned dynamics for RL planning (Peng et al., 2018; Su et al., 2018; Wu et al., 2018; Zhang et al., 2019b). Most of these works are based on Deep Dyna-Q (DDQ) framework (Sutton, 1990), where a world model is introduced to learn the dynamics (which is much like a simulated user) from real experiences. The target agent’s policy is trained using both real experiences via direct RL and simulated experiences via a world-model. In the above methods, both the simulated user and world model facilitate target policy learning by providing more simulated experiences and remain a black box for the target agent. That is, the target agent’s knowledge about the simulated ag"
2020.aacl-main.16,2020.acl-main.59,1,0.806324,"Missing"
2020.aacl-main.16,D19-1010,1,0.81731,"ance over state-of-the-art baselines. 1 Introduction In goal-oriented dialogue systems, dialogue policy plays a crucial role by deciding the next action to take conditioned on the dialogue state. This problem is often formulated using reinforcement learning (RL) in which the user serves as the environment (Levin et al., 1997; Rieser and Lemon, 2011; Lemon and Pietquin, 2012; Young et al., 2013; Fatemi et al., 2016; Zhao and Eskenazi, 2016; Dhingra et al., 2016; Su et al., 2016; Li et al., 2017; Williams et al., 2017; Liu and Lane, 2017; Lipton et al., 2018; Liu et al., 2018; Gao et al., 2019; Takanobu et al., 2019, 2020; Jhunjhunwala et al., 2020). However, different from symbolic-based and simulation-based RL tasks, such as chess (Silver et al., 2016) and video games (Mnih et al., ∗ Corresponding author. § {liuzitao,galehuang}@100tal.com 2015), which can get vast amounts of training interactions in low cost, dialogue systems require to learn directly from real users, which is too expensive. Therefore, there are some efforts using simulation methods to provide an affordable training environment. One principle direction for mitigating this problem is to leverage human conversation data to build a user s"
2020.aacl-main.16,D14-1007,0,0.0261301,"2007). However, these methods require manual work to define features and state representation, which leads to poor domain adaptation. More recently, deep learning methods are applied in dialogue policy learning, including DQN (Mnih et al., 2015) and Policy Gradient (Sutton et al., 2000) methods, which mitigate the problem of domain adaptation through function approximation and representation learning (Zhao and Eskenazi, 2016). Recently, there are some efforts focused on multi-domain dialogue policy. An intuitive way is to learn independent policies for each specific domain and aggregate them (Wang et al., 2014; Gaˇsi´c 123 et al., 2015; Cuay´ahuitl et al., 2016). There are also some works using hierarchical RL, which decomposes the complex task into several sub-tasks (Peng et al., 2017; Casanueva et al., 2018) according to pre-defined domain structure and cross-domain constraints. Nevertheless, most of the above works regard the opposite agent as part of the environment without explicitly modeling its behavior. Planning based RL methods are also introduced to make a trade-off between reducing human interaction cost and learning a more realistic simulator. Peng et al. (2018) proposed to use Deep Dyn"
2020.aacl-main.16,N07-2038,0,0.345898,"interaction data, it consistently approaches the performance of real users, which provides better simulated experience for planning. Adversarial methods are applied to dynamically control the proportion of simulated and real experience during different stages of training (Su et al., 2018; Wu et al., 2018). Still, these methods work from the opposite agents’ angle. 2.2 Dialogue User Simulation In RL-based dialogue policy learning methods, a user simulator is often required to provide affordable training environments due to the high cost of collecting real human corpus. Agenda-based simulation (Schatzmann et al., 2007; Li et al., 2016) is a widely applied rule-based method, which starts with a randomly generated user goal that is unknown to the system. During a dialogue session, it remains a stack data structure known as user agenda, which holds some pending user intentions to achieve. In the stack update process, machine learning or expert-defined methods can be applied. There are also some model-based methods that learn a simulator from real conversation data. The seq2seq framework has recently been introduced by encoding dialogue history and generates the next response or dialogue action (Asri et al., 2"
2020.aacl-main.16,P17-1062,0,0.0173839,". We evaluate our model on both cooperative and competitive dialogue tasks, showing superior performance over state-of-the-art baselines. 1 Introduction In goal-oriented dialogue systems, dialogue policy plays a crucial role by deciding the next action to take conditioned on the dialogue state. This problem is often formulated using reinforcement learning (RL) in which the user serves as the environment (Levin et al., 1997; Rieser and Lemon, 2011; Lemon and Pietquin, 2012; Young et al., 2013; Fatemi et al., 2016; Zhao and Eskenazi, 2016; Dhingra et al., 2016; Su et al., 2016; Li et al., 2017; Williams et al., 2017; Liu and Lane, 2017; Lipton et al., 2018; Liu et al., 2018; Gao et al., 2019; Takanobu et al., 2019, 2020; Jhunjhunwala et al., 2020). However, different from symbolic-based and simulation-based RL tasks, such as chess (Silver et al., 2016) and video games (Mnih et al., ∗ Corresponding author. § {liuzitao,galehuang}@100tal.com 2015), which can get vast amounts of training interactions in low cost, dialogue systems require to learn directly from real users, which is too expensive. Therefore, there are some efforts using simulation methods to provide an affordable training environment. One prin"
2020.aacl-main.16,P19-1426,0,0.0435272,"Missing"
2020.aacl-main.16,P19-1364,0,0.112982,"to build a user simulator, and then to learn the dialogue policy by making simulated interactions with the simulator (Schatzmann et al., 2006; Li et al., 2016; G¨ur et al., 2018). However, there always exist discrepancies between simulated users and real users due to the inductive biases of the simulation model, which can lead to a sub-optimal dialogue policy (Dhingra et al., 2016). Another direction is to learn the dynamics of dialogue environment during interacting with real user, and concurrently use the learned dynamics for RL planning (Peng et al., 2018; Su et al., 2018; Wu et al., 2018; Zhang et al., 2019b). Most of these works are based on Deep Dyna-Q (DDQ) framework (Sutton, 1990), where a world model is introduced to learn the dynamics (which is much like a simulated user) from real experiences. The target agent’s policy is trained using both real experiences via direct RL and simulated experiences via a world-model. In the above methods, both the simulated user and world model facilitate target policy learning by providing more simulated experiences and remain a black box for the target agent. That is, the target agent’s knowledge about the simulated agents is still passively obtained thro"
2020.aacl-main.16,W16-3601,0,0.162786,"timation to improve the target agent by regarding it as part of the target policy. We evaluate our model on both cooperative and competitive dialogue tasks, showing superior performance over state-of-the-art baselines. 1 Introduction In goal-oriented dialogue systems, dialogue policy plays a crucial role by deciding the next action to take conditioned on the dialogue state. This problem is often formulated using reinforcement learning (RL) in which the user serves as the environment (Levin et al., 1997; Rieser and Lemon, 2011; Lemon and Pietquin, 2012; Young et al., 2013; Fatemi et al., 2016; Zhao and Eskenazi, 2016; Dhingra et al., 2016; Su et al., 2016; Li et al., 2017; Williams et al., 2017; Liu and Lane, 2017; Lipton et al., 2018; Liu et al., 2018; Gao et al., 2019; Takanobu et al., 2019, 2020; Jhunjhunwala et al., 2020). However, different from symbolic-based and simulation-based RL tasks, such as chess (Silver et al., 2016) and video games (Mnih et al., ∗ Corresponding author. § {liuzitao,galehuang}@100tal.com 2015), which can get vast amounts of training interactions in low cost, dialogue systems require to learn directly from real users, which is too expensive. Therefore, there are some efforts u"
2020.aacl-main.16,D18-1547,0,\N,Missing
2020.aacl-main.28,D18-1454,0,0.0229478,"tations. Experimental results show that our framework outperforms knowledge-aware text generation baselines and GPT-2 (Radford et al., 2019) in both automatic and human evaluation. Particularly, our model generates explanations with more informative content and provides reasoning paths on the knowledge graph for concept extraction. To summarize, our contributions are two-fold: knowledge base completion (Bosselut et al., 2019). While the ultimate goals of these tasks are different from ours, we argue that performing explicit commonsense reasoning is also critical to generation. A line of work (Bauer et al., 2018; Lin et al., 2019a) resorts to structured commonsense knowledge and builds graph-aware representations along with the contextualized word embeddings to tackle the commonsense question answering problem. In our work, we focus on reasoning over structured knowledge to explicitly infer discrete bridge concepts that are further used for text generation. Another line of work (Rajani et al., 2019; Khot et al., 2019) identifies the knowledge gap critical for the complete reasoning chain and fills the gap by writing general explanation or acquiring fine-grained annotations with human effort. While sh"
2020.aacl-main.28,P19-1470,0,0.0422763,"Missing"
2020.aacl-main.28,2020.tacl-1.7,1,0.829718,"Text Generation Existing work that utilizes structured knowledge graphs to generate texts mainly lies in conversation generation (Zhou et al., 2018; Tuan et al., 2019; Moon et al., 2019), story generation (Guan et al., 2019) and language modeling (Ahn et al., 2016; Logan et al., 2019; Hayashi et al., 2019). Zhou et al. (2018) and Guan et al. (2019) propose to use graph attention that incorporates the information of neighbouring concepts into context representations to help generate the target sentence. Yang et al. (2019) resort to a dynamic concept memory that updates during essay generation. Guan et al. (2020) conduct post-training on knowledge triples to enhance the GPT-2 with commonsense knowledge. Since one-hop graphs of concepts in the statement have low coverage to the concepts in the explanation, merely leveraging information of individual concepts or triples is not suitable for this task. Another direction that utilizes more complex graph is to model multi-hop reasoning by performing random walk (Moon et al., 2019) on the knowledge graph or simulating a Markov process on the pre-extracted knowledge paths (Tuan et al., 2019). While in our task, we don’t have access to a parallel grounded know"
2020.aacl-main.28,D19-1281,0,0.0245197,"t et al., 2019). While the ultimate goals of these tasks are different from ours, we argue that performing explicit commonsense reasoning is also critical to generation. A line of work (Bauer et al., 2018; Lin et al., 2019a) resorts to structured commonsense knowledge and builds graph-aware representations along with the contextualized word embeddings to tackle the commonsense question answering problem. In our work, we focus on reasoning over structured knowledge to explicitly infer discrete bridge concepts that are further used for text generation. Another line of work (Rajani et al., 2019; Khot et al., 2019) identifies the knowledge gap critical for the complete reasoning chain and fills the gap by writing general explanation or acquiring fine-grained annotations with human effort. While sharing a similar motivation, our method differs from theirs in the sense that we acquire distant supervisions for the bridge concepts to extract reasoning paths and generate plausible explanations without the need of additional human annotation. • We analyze the under-explored commonsense explanation generation task and investigate the challenges in incorporating external knowledge graph to aid the generation pr"
2020.aacl-main.28,D19-1282,0,0.203309,"ng neural language generation models tend to generate trivial and uninformative explanations. For example, one of the existing neural models generates an explanation “The school wasn’t open for summer” to the statement in Figure 1. Although it is sometimes reasonable, simple modification of the statement to the negation form with no additional information cannot explain the reasons why the statement conflicts with commonsense. 2) Noisy commonsense knowledge grounding. It’s still challenging for most existing language generation models to generate explanations that are faithful to commonsense (Lin et al., 2019b). Thus, explicitly incorporating external knowledge sources is necessary for this task. Since the nature of the explanation generation task involves using underlying commonsense knowledge to explain, locating useful commonsense knowledge from large-scale knowledge graph is not trivial and generally requires multi-hop reasoning. 248 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 248–257 c December 4 - 7, 2020. 2020 Association for Computational Ling"
2020.aacl-main.28,W05-0909,0,0.0727217,"English version ConceptNet as our external commonsense knowledge graph. It contains triples in the form of (h, r, t) where h and t represent head and tail concepts and r is the relation type. We follow Lin et al. (2019a) to merge the original 42 relation types into 17 types. We additionally define 17 reverse types corresponding to the original 17 relation types to distinguish the direction of the triples on the graph. 4.2 Automatic Evaluation Metrics To automatically evaluate the performance of the generation models, we use the BLEU-3/4 (Papineni et al., 2001), ROUGE-2/L (Lin, 2004), METEOR (Banerjee and Lavie, 2005) as our main metrics. We also propose Concept F1 to evaluate the accuracy of the unique concepts in the generated explanation that do not occur in the statement. ˆ Specifically, given the generated explanation y and the reference explanation y, we extract a set of concepts Cyˆ and Cy from the generated explanation and the reference explanation respectively using the method in §3.3. We denote the sets of unique concepts in the explanation as Uy = Cy − Cx and Uyˆ = Cyˆ − Cx . Then we can compute the Concept F1 as the harmonic mean of recall and precision. Dataset and Experimental Setup Commonsen"
2020.aacl-main.28,W04-1013,0,0.039496,"dge Graph We use the English version ConceptNet as our external commonsense knowledge graph. It contains triples in the form of (h, r, t) where h and t represent head and tail concepts and r is the relation type. We follow Lin et al. (2019a) to merge the original 42 relation types into 17 types. We additionally define 17 reverse types corresponding to the original 17 relation types to distinguish the direction of the triples on the graph. 4.2 Automatic Evaluation Metrics To automatically evaluate the performance of the generation models, we use the BLEU-3/4 (Papineni et al., 2001), ROUGE-2/L (Lin, 2004), METEOR (Banerjee and Lavie, 2005) as our main metrics. We also propose Concept F1 to evaluate the accuracy of the unique concepts in the generated explanation that do not occur in the statement. ˆ Specifically, given the generated explanation y and the reference explanation y, we extract a set of concepts Cyˆ and Cy from the generated explanation and the reference explanation respectively using the method in §3.3. We denote the sets of unique concepts in the explanation as Uy = Cy − Cx and Uyˆ = Cyˆ − Cx . Then we can compute the Concept F1 as the harmonic mean of recall and precision. Datas"
2020.aacl-main.28,P19-1598,0,0.0288822,"e commonsense explanation generation task in both automatic and human evaluation. 2 2.1 Related Work Machine Commonsense Reasoning Previous work on machine commonsense reasoning mainly focuses on the tasks of inference (Levesque et al., 2011), question answering (Talmor et al., 2018; Sap et al., 2019) and 249 2.2 Knowledge-Grounded Text Generation Existing work that utilizes structured knowledge graphs to generate texts mainly lies in conversation generation (Zhou et al., 2018; Tuan et al., 2019; Moon et al., 2019), story generation (Guan et al., 2019) and language modeling (Ahn et al., 2016; Logan et al., 2019; Hayashi et al., 2019). Zhou et al. (2018) and Guan et al. (2019) propose to use graph attention that incorporates the information of neighbouring concepts into context representations to help generate the target sentence. Yang et al. (2019) resort to a dynamic concept memory that updates during essay generation. Guan et al. (2020) conduct post-training on knowledge triples to enhance the GPT-2 with commonsense knowledge. Since one-hop graphs of concepts in the statement have low coverage to the concepts in the explanation, merely leveraging information of individual concepts or triples is no"
2020.aacl-main.28,P19-1081,0,0.028584,"es the explanation based on these concepts. Our model outperforms state-of-the-art baselines on the commonsense explanation generation task in both automatic and human evaluation. 2 2.1 Related Work Machine Commonsense Reasoning Previous work on machine commonsense reasoning mainly focuses on the tasks of inference (Levesque et al., 2011), question answering (Talmor et al., 2018; Sap et al., 2019) and 249 2.2 Knowledge-Grounded Text Generation Existing work that utilizes structured knowledge graphs to generate texts mainly lies in conversation generation (Zhou et al., 2018; Tuan et al., 2019; Moon et al., 2019), story generation (Guan et al., 2019) and language modeling (Ahn et al., 2016; Logan et al., 2019; Hayashi et al., 2019). Zhou et al. (2018) and Guan et al. (2019) propose to use graph attention that incorporates the information of neighbouring concepts into context representations to help generate the target sentence. Yang et al. (2019) resort to a dynamic concept memory that updates during essay generation. Guan et al. (2020) conduct post-training on knowledge triples to enhance the GPT-2 with commonsense knowledge. Since one-hop graphs of concepts in the statement have low coverage to the"
2020.aacl-main.28,2001.mtsummit-papers.68,0,0.0371618,"4.1 4.1.1 4.1.2 Commonsense Knowledge Graph We use the English version ConceptNet as our external commonsense knowledge graph. It contains triples in the form of (h, r, t) where h and t represent head and tail concepts and r is the relation type. We follow Lin et al. (2019a) to merge the original 42 relation types into 17 types. We additionally define 17 reverse types corresponding to the original 17 relation types to distinguish the direction of the triples on the graph. 4.2 Automatic Evaluation Metrics To automatically evaluate the performance of the generation models, we use the BLEU-3/4 (Papineni et al., 2001), ROUGE-2/L (Lin, 2004), METEOR (Banerjee and Lavie, 2005) as our main metrics. We also propose Concept F1 to evaluate the accuracy of the unique concepts in the generated explanation that do not occur in the statement. ˆ Specifically, given the generated explanation y and the reference explanation y, we extract a set of concepts Cyˆ and Cy from the generated explanation and the reference explanation respectively using the method in §3.3. We denote the sets of unique concepts in the explanation as Uy = Cy − Cx and Uyˆ = Cyˆ − Cx . Then we can compute the Concept F1 as the harmonic mean of reca"
2020.aacl-main.28,P19-1487,0,0.0401311,"e completion (Bosselut et al., 2019). While the ultimate goals of these tasks are different from ours, we argue that performing explicit commonsense reasoning is also critical to generation. A line of work (Bauer et al., 2018; Lin et al., 2019a) resorts to structured commonsense knowledge and builds graph-aware representations along with the contextualized word embeddings to tackle the commonsense question answering problem. In our work, we focus on reasoning over structured knowledge to explicitly infer discrete bridge concepts that are further used for text generation. Another line of work (Rajani et al., 2019; Khot et al., 2019) identifies the knowledge gap critical for the complete reasoning chain and fills the gap by writing general explanation or acquiring fine-grained annotations with human effort. While sharing a similar motivation, our method differs from theirs in the sense that we acquire distant supervisions for the bridge concepts to extract reasoning paths and generate plausible explanations without the need of additional human annotation. • We analyze the under-explored commonsense explanation generation task and investigate the challenges in incorporating external knowledge graph to a"
2020.aacl-main.28,D19-1454,0,0.126624,"Missing"
2020.aacl-main.28,D19-1194,0,0.0127204,"hs and then generates the explanation based on these concepts. Our model outperforms state-of-the-art baselines on the commonsense explanation generation task in both automatic and human evaluation. 2 2.1 Related Work Machine Commonsense Reasoning Previous work on machine commonsense reasoning mainly focuses on the tasks of inference (Levesque et al., 2011), question answering (Talmor et al., 2018; Sap et al., 2019) and 249 2.2 Knowledge-Grounded Text Generation Existing work that utilizes structured knowledge graphs to generate texts mainly lies in conversation generation (Zhou et al., 2018; Tuan et al., 2019; Moon et al., 2019), story generation (Guan et al., 2019) and language modeling (Ahn et al., 2016; Logan et al., 2019; Hayashi et al., 2019). Zhou et al. (2018) and Guan et al. (2019) propose to use graph attention that incorporates the information of neighbouring concepts into context representations to help generate the target sentence. Yang et al. (2019) resort to a dynamic concept memory that updates during essay generation. Guan et al. (2020) conduct post-training on knowledge triples to enhance the GPT-2 with commonsense knowledge. Since one-hop graphs of concepts in the statement have"
2020.aacl-main.28,P19-1393,0,0.0263181,"e concepts like vacation by identifying the relation to the source concepts, i.e. school and summer in the statement. Introduction Machine commonsense reasoning has been widely acknowledged as a crucial component of artificial intelligence and a considerable amount of work has been dedicated to evaluate this ability from various aspects in natural language processing (Levesque et al., 2011; Talmor et al., 2018; Sap et al., 2019). A large proportion of existing tasks frame commonsense reasoning as multi-choice reading comprehension problems, which lack direct assessment to machine commonsense (Wang et al., 2019) and impede its practicability to realistic scenarios (Lin ∗ Corresponding author The source code is available at https://github. com/cdjhz/CommExpGen. 1 et al., 2019b). Recently, Wang et al. (2019) proposed a commonsense explanation generation challenge that directly tests machine’s sense-making capability via commonsense reasoning. In this paper, we focus on the challenging explanation generation task where the goal is to generate a sentence to explain the reasons why the input statement is against commonsense, as shown in Figure 1. Generating a reasonable explanation for a statement faces t"
2020.aacl-main.28,P19-1193,0,0.0211606,", question answering (Talmor et al., 2018; Sap et al., 2019) and 249 2.2 Knowledge-Grounded Text Generation Existing work that utilizes structured knowledge graphs to generate texts mainly lies in conversation generation (Zhou et al., 2018; Tuan et al., 2019; Moon et al., 2019), story generation (Guan et al., 2019) and language modeling (Ahn et al., 2016; Logan et al., 2019; Hayashi et al., 2019). Zhou et al. (2018) and Guan et al. (2019) propose to use graph attention that incorporates the information of neighbouring concepts into context representations to help generate the target sentence. Yang et al. (2019) resort to a dynamic concept memory that updates during essay generation. Guan et al. (2020) conduct post-training on knowledge triples to enhance the GPT-2 with commonsense knowledge. Since one-hop graphs of concepts in the statement have low coverage to the concepts in the explanation, merely leveraging information of individual concepts or triples is not suitable for this task. Another direction that utilizes more complex graph is to model multi-hop reasoning by performing random walk (Moon et al., 2019) on the knowledge graph or simulating a Markov process on the pre-extracted knowledge pa"
2020.aacl-main.77,N19-1423,0,0.00777534,"ying graph based ranking is SEAL (Wang and Cohen, 2007) • SEISA. SEISA (He and Xin, 2011) is an entity set expansion system developed by Microsoft after SEAL and outperforms traditional graph-based methods by an original unsupervised similarity metric. We implement its Dynamic Thresholding algorithm to sort expanded concepts. • EMB. Embedding based method mainly utilizes context information to examine the similarity between expanded concepts and seeds according to (Mamou et al., 2018). For each expanded concept e, we calculate the sum of its cosine similarities with course concepts M in BERT (Devlin et al., 2019) and use the average as golden standard to rank the expanded concept list. • PUL. PU learning is a semi-supervised learning model regarding set expansion as a binary classification task. We employ the same setting as (Wang et al., 2017) to classify and sort concepts. • PIP. It is a pipeline method for course concept expansion (Yu et al., 2019a), which first uses an online clustering method during candidate generation and then classify them to obtain final expansion results. We follow the workflow of this work to sort expanded concepts. 4.1.4 Evaluation Metrics Our objective is to generate a ra"
2020.aacl-main.77,I17-1088,1,0.731139,"ed as N t the likelihood can be formalized as P (ct0 ∈ N t ⊂ Lt |K t , t0 ). The expansion set is refreshed as Ect+1 = Ect ∪ N t until its size reaches the preset upper limit τ or cannot find new candidates (He and Xin, 2011). 2.3 Preliminaries 2.1 base KB as an external source, the task is to return a ranked list of expanded concepts Ec . In this formulation, a course corpus is defined as D = {C j }|n| , which is composed of n courses’ j=1 video subtitles in the same subject area. Course concepts are the subjects taught in the course (such |M| as LSTM in Figure 1), denoted as M = {ci }i=1 . (Pan et al., 2017). Knowledge base KB = (E, R) is consist of concepts E and relations R, which is utilized as an external source to obtain expansion candidates. Though other source (such as Web tables) can also take on this role, we still employ a KB to search for expansion candidates like the prior work, i.e., Ec ⊂ E. Interactive MOOC Environment The workflow above has been experimentally proven to be effective in many concept expansion tasks (Shen et al., 2018; Rastogi et al., 2019). However, such methods only consider the course concepts’ semantic information, which makes their expansion results hard to matc"
2020.aacl-main.77,C10-1112,0,0.0130339,"(The overlap rises from 0.005 to 0.091), which indicates that our model can provide more high-quality concepts. 5 Related Work Our work follows the task of concept expansion in MOOCs (Yu et al., 2019a), a particular type of set expansion problem, which takes several seeds as input and expands the entity set. Set expansion was born to serve knowledge acquisition applications on the Internet. Google Sets was a pioneer which leaded a series of early research, e.g. Bayesian Sets (Ghahramani and Heller, 2006), SEAL (Wang and Cohen, 2007), SEISA (He and Xin, 2011) and others (Sarmento et al., 2007; Shi et al., 2010; Wang et al., 2015). These efforts utilize web tables as a resource and mainly serves for search engines. Recently, more related research has turned its attention to other application fields, such as news mining (Redondo-Garc´ıa et al., 2014), knowledge graphs (Zhang et al., 2017), education assistance (Yu et al., 2019a), etc. Meanwhile, corpus-based expansion methods snowball, and iterative bootstrapping became a common solution (Shen et al., 2017; Yu et al., 2019b; Yan et al., 2019), which expands the set in round and select high-quality results to extract feature iteratively. ExpanRL is in"
2020.aacl-main.77,D18-2004,0,0.062772,"24 user behaviors from a real MOOC website. 2 Problem Formulation Following (Yu et al., 2019a), Course Concept Expansion is formally defined as: given the course corpus D, course concepts M, and a knowledge 2 A course from the University of London in Coursera. 2.2 Basic Model for Concept Expansion The general idea of concept expansion is first to characterize the concept set according to its representative elements, then find new candidates and rank them to expand the set. Seed Selection Stage. A group of representative concepts are called seeds and formalized to K ⊂ Ec (Wang and Cohen, 2007; Mamou et al., 2018). While the expansion process is often carried out iteratively, we also formalize the expansion set of round t to Ect . Seed selection is to calculate the possibility that each concept in Ect becomes a seed, i.e., P (ci ∈ K t ⊂ Ect |t), where K t contains the seeds of t-th round. Based on these seeds, we can extract features of the current set and search for candidate concepts for expansion from external sources. Expansion Stage. After finding a new list of candi t dates L = c1 , ..., ct0 , ..., c|Lt |, expansion stage aims to calculate the likelihood of ct0 to be a expanded concept. The top"
2020.aacl-main.77,D17-1059,0,0.0276969,"larity metric. We implement its Dynamic Thresholding algorithm to sort expanded concepts. • EMB. Embedding based method mainly utilizes context information to examine the similarity between expanded concepts and seeds according to (Mamou et al., 2018). For each expanded concept e, we calculate the sum of its cosine similarities with course concepts M in BERT (Devlin et al., 2019) and use the average as golden standard to rank the expanded concept list. • PUL. PU learning is a semi-supervised learning model regarding set expansion as a binary classification task. We employ the same setting as (Wang et al., 2017) to classify and sort concepts. • PIP. It is a pipeline method for course concept expansion (Yu et al., 2019a), which first uses an online clustering method during candidate generation and then classify them to obtain final expansion results. We follow the workflow of this work to sort expanded concepts. 4.1.4 Evaluation Metrics Our objective is to generate a ranked list of expanded concepts. Thus, we use the Mean Average Precision(MAP) as our evaluation metric, which is the preferred metric in information retrieval for evaluating ranked lists. 4.2 Overall Evaluation Table 2 summarizes the com"
2020.aacl-main.77,D19-1028,0,0.0601988,"Missing"
2020.aacl-main.77,P19-1421,1,0.5905,"lassrooms, these concepts are often considerately introduced by teachers. ∗ 1 Corresponding author. https://www.coursera.org However, in the era of Massive Open Online Courses (MOOCs), thousands of courses are prerecorded for with millions of students with various backgrounds (Shah, 2019), which makes it infeasible to pick out these essential concepts manually. Therefore, there is a clear need to automatically discover course-related concepts so that they can easily acquire additional knowledge and achieve better educational outcomes. This task is formally defined as Course Concept Expansion (Yu et al., 2019a), a special type of Concept Expansion or Set Expansion (Wang and Cohen, 2007), which refers to the task of expanding a small set of seed concepts into a complete set of concepts that belong to the same course or subject from external resources. Despite abundant efforts in related topics (He and Xin, 2011; Shen et al., 2017; Yan et al., 2019), existing methods still face three challenges when applied to MOOCs. First, distinct from the task of enriching a certain concept set, the purpose of course concept expansion is to benefit students’ learning, making the context information insufficient t"
2020.acl-demos.19,D18-1547,0,0.234895,"Missing"
2020.acl-demos.19,P19-1360,0,0.06182,"b-2 provides a template-based method and SC-LSTM (Wen et al., 2015). 2.3.1 CamRest676 CamRest676 (Wen et al., 2017) is a Wizard-of-Oz dataset, consisting of 676 dialogues in a restaurant domain. ConvLab-2 offers an agenda-based user simulator and a complete set of models for building a traditional pipeline dialogue system on the CamRest676 dataset. 2.2.6 Word-level Policy Word-level policy directly generates a natural language response (rather than dialogue acts) according to the dialogue history and the belief state. ConvLab-2 integrates three models: MDRG (Budzianowski et al., 2018a), HDSA (Chen et al., 2019), and LaRL (Zhao et al., 2019). MDRG is the baseline model proposed by Budzianowski et al. (2018b) on MultiWOZ, while HDSA and LaRL achieve much stronger performance on this dataset. 2.2.7 User Policy User policy is the core of a user simulator. It takes a pre-set user goal and system dialogue acts as input and outputs user dialogue acts. ConvLab-2 provides an agenda-based (Schatzmann et al., 2007) model and neural network-based models including HUS and its variational variants (G¨ur et al., 2018). To perform end-to-end simulation, researchers can equip the user policy with NLU and NLG compone"
2020.acl-demos.19,N19-1423,0,0.0163653,"ntegrated models in ConvLab-2 are marked in bold. Researchers can easily add their models by implementing the interface of the corresponding component. We will keep adding state-of-the-art models to reflect the latest progress in task-oriented dialogue. 2.2.1 Natural Language Understanding The natural language understanding (NLU) component, which is used to parse the other agent’s intent, takes an utterance as input and outputs the corresponding dialogue acts. ConvLab-2 provides three models: Semantic Tuple Classifier (STC) (Mairesse et al., 2009), MILU (Lee et al., 2019b), and BERTNLU. BERT (Devlin et al., 2019) has shown strong performance in many NLP tasks. Thus, ConvLab-2 proposes a new BERTNLU model. BERTNLU adds two MLPs on top of BERT for intent classification and slot tagging, respectively, and fine-tunes all parameters on the specified tasks. BERTNLU achieves the best performance on MultiWOZ in comparison with other models. 2.2.2 Dialogue State Tracking The dialogue state tracking (DST) component updates the belief state, which contains the constraints and requirements of the other agent (such as a user). ConvLab-2 provides a rule-based tracker that takes dialogue acts parsed by the NLU as in"
2020.acl-demos.19,W14-4337,0,0.245946,"Missing"
2020.acl-demos.19,P19-1546,0,0.189107,"l Intelligence, † State Key Lab of Intelligent Technology and Systems, † Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China ‡ Microsoft Research, Redmond, USA † ‡ {zhu-q18,z-zhang15,fangy17,gxly19}@mails.tsinghua.edu.cn {jincli,bapeng,jfgao}@microsoft.com † {zxy-dcs,aihuang}@tsinghua.edu.cn Abstract We present ConvLab-2, an open-source toolkit that enables researchers to build task-oriented dialogue systems with state-of-the-art models, perform an end-to-end evaluation, and diagnose the weakness of systems. As the successor of ConvLab (Lee et al., 2019b), ConvLab2 inherits ConvLab’s framework but integrates more powerful dialogue models and supports more datasets. Besides, we have developed an analysis tool and an interactive tool to assist researchers in diagnosing dialogue systems. The analysis tool presents rich statistics and summarizes common mistakes from simulated dialogues, which facilitates error analysis and system improvement. The interactive tool provides a user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component. 1 Figure 1: F"
2020.acl-demos.19,P19-3011,1,0.903958,"Missing"
2020.acl-demos.19,P18-1133,0,0.311994,"improvement. The interactive tool provides a user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component. 1 Figure 1: Framework of ConvLab-2. The top block shows different approaches to build a dialogue system. Introduction Task-oriented dialogue systems are gaining increasing attention in recent years, resulting in a number of datasets (Henderson et al., 2014; Wen et al., 2017; Budzianowski et al., 2018b; Rastogi et al., 2019) and a wide variety of models (Wen et al., 2015; Peng et al., 2017; Lei et al., 2018; Wu et al., 2019; Gao et al., 2019). However, very few opensource toolkits provide full support to assembling an end-to-end dialogue system with state-of-the-art models, evaluating the performance in an end-toend fashion, and analyzing the bottleneck both qualitatively and quantitatively. To fill the gap, we have developed ConvLab-2 based on our previous dialogue system platform ConvLab (Lee et al., 2019b). ConvLab-2 inherits its predecessor’s framework and extend it by integrating many recently proposed state-of-the-art dialogue models. In addition, ∗ Corresponding author. two powerful tools"
2020.acl-demos.19,D17-1259,0,0.47465,"20. 2020 Association for Computational Linguistics have state-of-the-art models integrated. ConvLab (Lee et al., 2019b) is the first toolkit that provides various powerful models for all dialogue components and allows researchers to quickly assemble a complete dialogue system (using a set of recipes). ConvLab-2 inherits the flexible framework of ConvLab and imports recently proposed models that achieve state-of-the-art performance. In addition, ConvLab-2 supports several large-scale dialogue datasets including CamRest676 (Wen et al., 2017), MultiWOZ (Budzianowski et al., 2018b), DealOrNoDeal (Lewis et al., 2017), and CrossWOZ (Zhu et al., 2020). To support end-to-end evaluation, ConvLab-2 provides user simulators for automatic evaluation and integrates Amazon Mechanical Turk for human evaluation, similar to ConvLab. Moreover, it provides an analysis tool and a human-machine interactive tool for diagnosing a dialogue system. Researchers can perform quantitative analysis using the analysis tool. It presents useful statistics extracted from the conversations between the user simulator and the dialogue system. This information helps reveal the weakness of the system and signifies the direction for furthe"
2020.acl-demos.19,D17-2014,0,0.0314309,"rating many recently proposed state-of-the-art dialogue models. In addition, ∗ Corresponding author. two powerful tools, namely the analysis tool and the interactive tool, are provided for in-depth error analysis. ConvLab-2 will be the development platform for Multi-domain Task-oriented Dialog Challenge II track in the 9th Dialog System Technology Challenge (DSTC9)1 . As shown in Figure 1, there are many approaches to building a task-oriented dialogue system, ranging from pipeline methods with multiple components to fully end-to-end models. Previous toolkits focus on either end-to-end models (Miller et al., 2017) or one specific component such as dialogue policy (POL) (Ultes et al., 2017), while the others toolkits that are designed for developers (Bocklisch et al., 2017; Papangelis et al., 2020) do not 1 https://sites.google.com/dstc. community/dstc9/home 142 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 142–149 c July 5 - July 10, 2020. 2020 Association for Computational Linguistics have state-of-the-art models integrated. ConvLab (Lee et al., 2019b) is the first toolkit that provides various powerful models for all dialogue components and allows rese"
2020.acl-demos.19,D17-1237,1,0.845901,"analysis and system improvement. The interactive tool provides a user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component. 1 Figure 1: Framework of ConvLab-2. The top block shows different approaches to build a dialogue system. Introduction Task-oriented dialogue systems are gaining increasing attention in recent years, resulting in a number of datasets (Henderson et al., 2014; Wen et al., 2017; Budzianowski et al., 2018b; Rastogi et al., 2019) and a wide variety of models (Wen et al., 2015; Peng et al., 2017; Lei et al., 2018; Wu et al., 2019; Gao et al., 2019). However, very few opensource toolkits provide full support to assembling an end-to-end dialogue system with state-of-the-art models, evaluating the performance in an end-toend fashion, and analyzing the bottleneck both qualitatively and quantitatively. To fill the gap, we have developed ConvLab-2 based on our previous dialogue system platform ConvLab (Lee et al., 2019b). ConvLab-2 inherits its predecessor’s framework and extend it by integrating many recently proposed state-of-the-art dialogue models. In addition, ∗ Corresponding author."
2020.acl-demos.19,P18-2069,0,0.077924,"Missing"
2020.acl-demos.19,N07-2038,0,0.404849,"rectly generates a natural language response (rather than dialogue acts) according to the dialogue history and the belief state. ConvLab-2 integrates three models: MDRG (Budzianowski et al., 2018a), HDSA (Chen et al., 2019), and LaRL (Zhao et al., 2019). MDRG is the baseline model proposed by Budzianowski et al. (2018b) on MultiWOZ, while HDSA and LaRL achieve much stronger performance on this dataset. 2.2.7 User Policy User policy is the core of a user simulator. It takes a pre-set user goal and system dialogue acts as input and outputs user dialogue acts. ConvLab-2 provides an agenda-based (Schatzmann et al., 2007) model and neural network-based models including HUS and its variational variants (G¨ur et al., 2018). To perform end-to-end simulation, researchers can equip the user policy with NLU and NLG components to assemble a complete user simulator. 2.2.8 End-to-end Model A fully end-to-end dialogue model receives the dialogue history and generates a response in natural language directly. ConvLab-2 extends Sequicity (Lei et al., 2018) to multi-domain scenarios: when the model senses that the current domain has switched, it resets the belief span, which records information of the current domain. ConvLa"
2020.acl-demos.19,D19-1010,1,0.86197,", 2019a), and TRADE (Wu et al., 2019). TRADE generates the belief state 143 from utterances using a copy mechanism and achieves state-of-the-art performance on MultiWOZ. the DealOrNoDeal dataset, we provide the ROLLOUTS RL policy proposed by Lewis et al. (2017). 2.2.4 Dialogue Policy Dialogue policy receives the belief state and outputs system dialogue acts. ConvLab-2 provides a rule-based policy, a simple neural policy that learns directly from the corpus using imitation learning, and reinforcement learning policies including REINFORCE (Williams, 1992), PPO (Schulman et al., 2017), and GDPL (Takanobu et al., 2019). GDPL achieves state-of-the-art performance on MultiWOZ. Compared with ConvLab, ConvLab-2 can integrate a new dataset more conveniently. For each dataset, ConvLab-2 provides a unified data loader that can be used by all the models, thus separating data processing from the model definition. Currently, ConvLab-2 supports four task-oriented dialogue datasets, including CamRest676 (Wen et al., 2017), MultiWOZ (Eric et al., 2019), DealOrNoDeal (Lewis et al., 2017), and CrossWOZ (Zhu et al., 2020). 2.2.5 Natural Language Generation The natural language generation (NLG) component transforms dialogue"
2020.acl-demos.19,P17-4013,0,0.0308827,"Corresponding author. two powerful tools, namely the analysis tool and the interactive tool, are provided for in-depth error analysis. ConvLab-2 will be the development platform for Multi-domain Task-oriented Dialog Challenge II track in the 9th Dialog System Technology Challenge (DSTC9)1 . As shown in Figure 1, there are many approaches to building a task-oriented dialogue system, ranging from pipeline methods with multiple components to fully end-to-end models. Previous toolkits focus on either end-to-end models (Miller et al., 2017) or one specific component such as dialogue policy (POL) (Ultes et al., 2017), while the others toolkits that are designed for developers (Bocklisch et al., 2017; Papangelis et al., 2020) do not 1 https://sites.google.com/dstc. community/dstc9/home 142 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 142–149 c July 5 - July 10, 2020. 2020 Association for Computational Linguistics have state-of-the-art models integrated. ConvLab (Lee et al., 2019b) is the first toolkit that provides various powerful models for all dialogue components and allows researchers to quickly assemble a complete dialogue system (using a set of recipe"
2020.acl-demos.19,D15-1199,0,0.102409,"Missing"
2020.acl-demos.19,E17-1042,0,0.288565,"Missing"
2020.acl-demos.19,P19-1078,0,0.112045,"interactive tool provides a user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component. 1 Figure 1: Framework of ConvLab-2. The top block shows different approaches to build a dialogue system. Introduction Task-oriented dialogue systems are gaining increasing attention in recent years, resulting in a number of datasets (Henderson et al., 2014; Wen et al., 2017; Budzianowski et al., 2018b; Rastogi et al., 2019) and a wide variety of models (Wen et al., 2015; Peng et al., 2017; Lei et al., 2018; Wu et al., 2019; Gao et al., 2019). However, very few opensource toolkits provide full support to assembling an end-to-end dialogue system with state-of-the-art models, evaluating the performance in an end-toend fashion, and analyzing the bottleneck both qualitatively and quantitatively. To fill the gap, we have developed ConvLab-2 based on our previous dialogue system platform ConvLab (Lee et al., 2019b). ConvLab-2 inherits its predecessor’s framework and extend it by integrating many recently proposed state-of-the-art dialogue models. In addition, ∗ Corresponding author. two powerful tools, namely the anal"
2020.acl-demos.19,N19-1123,0,0.131839,"method and SC-LSTM (Wen et al., 2015). 2.3.1 CamRest676 CamRest676 (Wen et al., 2017) is a Wizard-of-Oz dataset, consisting of 676 dialogues in a restaurant domain. ConvLab-2 offers an agenda-based user simulator and a complete set of models for building a traditional pipeline dialogue system on the CamRest676 dataset. 2.2.6 Word-level Policy Word-level policy directly generates a natural language response (rather than dialogue acts) according to the dialogue history and the belief state. ConvLab-2 integrates three models: MDRG (Budzianowski et al., 2018a), HDSA (Chen et al., 2019), and LaRL (Zhao et al., 2019). MDRG is the baseline model proposed by Budzianowski et al. (2018b) on MultiWOZ, while HDSA and LaRL achieve much stronger performance on this dataset. 2.2.7 User Policy User policy is the core of a user simulator. It takes a pre-set user goal and system dialogue acts as input and outputs user dialogue acts. ConvLab-2 provides an agenda-based (Schatzmann et al., 2007) model and neural network-based models including HUS and its variational variants (G¨ur et al., 2018). To perform end-to-end simulation, researchers can equip the user policy with NLU and NLG components to assemble a complete use"
2020.acl-demos.19,2020.tacl-1.19,1,0.84554,"nal Linguistics have state-of-the-art models integrated. ConvLab (Lee et al., 2019b) is the first toolkit that provides various powerful models for all dialogue components and allows researchers to quickly assemble a complete dialogue system (using a set of recipes). ConvLab-2 inherits the flexible framework of ConvLab and imports recently proposed models that achieve state-of-the-art performance. In addition, ConvLab-2 supports several large-scale dialogue datasets including CamRest676 (Wen et al., 2017), MultiWOZ (Budzianowski et al., 2018b), DealOrNoDeal (Lewis et al., 2017), and CrossWOZ (Zhu et al., 2020). To support end-to-end evaluation, ConvLab-2 provides user simulators for automatic evaluation and integrates Amazon Mechanical Turk for human evaluation, similar to ConvLab. Moreover, it provides an analysis tool and a human-machine interactive tool for diagnosing a dialogue system. Researchers can perform quantitative analysis using the analysis tool. It presents useful statistics extracted from the conversations between the user simulator and the dialogue system. This information helps reveal the weakness of the system and signifies the direction for further improvement. With the interacti"
2020.acl-main.361,D15-1220,0,0.0174979,"21.1 17.9 22.0† 27.2 DREAM Dev Test Acc Acc 57.3 57.7 63.9 63.2 64.2 62.8 63.1 63.4 62.5 63.0 65.3‡ 65.8† N/A N/A Table 3: Results on three multiple-choice reading comprehension datasets. (F1a : F1 score on all answer-options; F1m : macro-average F1 score of all questions; EM0 : exact match.) Note that there is no golden evidence label on RACE and DREAM. The results for DPL (deep programming logic) are copied from (Wang et al., 2019). Significance tests were conducted between BERT-HA+STM and the best baseline of each column (t-test). ‡ means p-value &lt; 0.01, and † means p-value &lt; 0.05. (ILP) (Boudin et al., 2015), and inverse term frequency (ITF) (Wang et al., 2019), among which ITF performed best in most cases. For simplicity, we merely provided experimental results with the rule of ITF. (4) Based on BERT-HA, BERTHA+RL trains the evidence extractor via reinforcement learning, similar to (Choi et al., 2017). And (5) another deep programming logic (DPL) method, GPT+DPL (Wang et al., 2019), is complicated, and the source code is not provided. Thus we directly used the results from the original paper and did not evaluate it on BERT. ODQA: (1) For each question, DSQA (Lin et al., 2018) aggregates multiple"
2020.acl-main.361,P17-1152,0,0.0208731,"evidential and relevant information for downstream processes in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; Huang et al., 2019). Second, supervised methods train evidence extraction with golden evidence labels, which sometimes can be generated automatically in extractive MRC settings (Lin et al., 2018; Yin and Roth, 2018; Hanselowski et al., 2018). Third, weakly supervised methods rely on noisy evidence labels, where the l"
2020.acl-main.361,P18-1063,0,0.0260948,"arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; Huang et al., 2019). Second, supervised methods train evidence extraction with golden evidence labels, which sometimes can be generated automatically in extractive MRC settings (Lin et al., 2018; Yin and Roth, 2018; Hanselowski et al., 2018). Third, weakly supervised methods rely on noisy evidence labels, where the labels can be obtained by heuristic rules (Min et al., 2018). Moreover, some data p"
2020.acl-main.361,P17-1020,0,0.501132,"16) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to the lack of evidence labels for supervision. Neural models have achieved great success on machine reading comprehension (MRC), many of which typically consist of two components: an evidence extractor and an answer predictor. The former seeks the most relevant information from a reference text, while the latter is to locate or generate answers from"
2020.acl-main.361,N19-1300,0,0.0965903,"ining method works in MRC. Introduction Machine reading comprehension (MRC) has received increasing attention recently, which can be roughly divided into two categories: extractive and non-extractive MRC. Extractive MRC requires a model to extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to"
2020.acl-main.361,N19-1423,0,0.0229519,"ncoder layer, an evidence extractor, and an answer predictor. The encoders will obtain hQ for the question, and hD i for each sentence in a document. The summary vector hD will be used to predict the answer. The encoder layer takes document D and question Q as input to obtain contextual representation for each word. Denote hD i,j as the representation of the j-th word in Si , and hQ i as the representation of the i-th word in question Q. Our framework is agnostic to the architecture of the encoder, and we 3918 show improvements on two widely used encoding models, i.e., Transformer (with BERT, Devlin et al., 2019) and LSTM (with DSQA, Lin et al., 2018) in the experiments. The evidence extractor employs hierarchical attention, including token- and sentence-level attention, to obtain the document representation hD . Token-level attention obtains a sentence vector by self-attention (Vaswani et al., 2017) within the words in a sentence, as follows: hD i = |Si | X S Q D αi,j hD i,j , αi,j ∝ exp(F (h , hi,j )), j |Si | sD i = X D βi,j hD i,j , βi,j ∝ exp(ws hi,j + bs ), j where hQ is the sentence representation of the question. αi,j refers to the importance of word j in sentence i, and so on for βi,j . ws an"
2020.acl-main.361,P17-1168,0,0.136438,"ly divided into two categories: extractive and non-extractive MRC. Extractive MRC requires a model to extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to the lack of evidence labels for supervision. Neural models have achieved great success on machine reading comprehension (MRC), many of whic"
2020.acl-main.361,P19-1259,0,0.0959178,"o extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to the lack of evidence labels for supervision. Neural models have achieved great success on machine reading comprehension (MRC), many of which typically consist of two components: an evidence extractor and an answer predictor. The former"
2020.acl-main.361,W18-5516,0,0.0485147,"(Lin et al., 2018). Experimental results demonstrate that our proposed method improves base models in three MRC tasks remarkably. 2 Related Work Early MRC studies focus on modeling semantic matching between a question and a reference document (Seo et al., 2017; Huang et al., 2018; Zhu Evidence extraction aims at finding evidential and relevant information for downstream processes in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; H"
2020.acl-main.361,N18-1023,0,0.0233337,"rehension (MRC) has received increasing attention recently, which can be roughly divided into two categories: extractive and non-extractive MRC. Extractive MRC requires a model to extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to the lack of evidence labels for supervision. Neural models hav"
2020.acl-main.361,P18-1161,0,0.217937,"dictor. The former seeks the most relevant information from a reference text, while the latter is to locate or generate answers from the extracted evidence. Despite the importance of evidence labels for training the evidence extractor, they are not cheaply accessible, particularly in many non-extractive MRC tasks such as YES/NO question answering and multi-choice MRC. 1 zmt.keke@gmail.com Manually annotating the golden evidence is expensive. Therefore, some recent efforts have been dedicated to improving MRC by leveraging noisy evidence labels when training the evidence extractor. Some works (Lin et al., 2018; Min et al., 2018) generate distant labels using hand-crafted rules and external resources. Some studies (Wang et al., 2018; Choi et al., 2017) adopt reinforcement learning (RL) to decide the labels of evidence. However, such RL methods suffer from unstable training. More distant supervision techniques are also used to refine noisy labels, such as deep probability logic (Wang et al., 2019), but they are hard to transfer to other tasks. Nevertheless, improving the evidence extractor remains challenging when golden evidence labels are not available. In this paper, we present a general and effec"
2020.acl-main.361,2021.ccl-1.108,0,0.178591,"Missing"
2020.acl-main.361,P19-1244,0,0.0965347,"imental results demonstrate that our proposed method improves base models in three MRC tasks remarkably. 2 Related Work Early MRC studies focus on modeling semantic matching between a question and a reference document (Seo et al., 2017; Huang et al., 2018; Zhu Evidence extraction aims at finding evidential and relevant information for downstream processes in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; Huang et al., 2019)"
2020.acl-main.361,P18-1076,0,0.0263728,"his paper, we present a general and effective method based on Self-Training (Scudder, 1965) to improve MRC with soft evidence extraction when golden evidence labels are not available. Following the Self-Training paradigm, a base MRC model is iteratively trained. At each iteration, the base model is trained with golden answers, as well as noisy evidence labels obtained at the preceding it3916 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3916–3927 c July 5 - 10, 2020. 2020 Association for Computational Linguistics Q: D: A: Q: D: A: et al., 2018; Mihaylov and Frank, 2018). In order to mimic the reading mode of human, hierarchical coarse-to-fine methods are proposed (Choi et al., 2017; Li et al., 2018). Such models first read the full text to select relevant text spans, and then infer answers from these relevant spans. Extracting such spans in MRC is drawing more and more attention, though still quite challenging (Wang et al., 2019). Did a little boy write the note? ...This note is from a little girl. She wants to be your friend. If you want to be her friend, ... No Is she carrying something? ...On the step, I find the elderly Chinese lady, small and slight, ho"
2020.acl-main.361,P18-1160,0,0.166834,"span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to the lack of evidence labels for supervision. Neural models have achieved great success on machine reading comprehension (MRC), many of which typically consist of two components: an evidence extractor and an answer predictor. The former seeks the most rele"
2020.acl-main.361,C18-1193,0,0.0220957,"ocesses in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; Huang et al., 2019). Second, supervised methods train evidence extraction with golden evidence labels, which sometimes can be generated automatically in extractive MRC settings (Lin et al., 2018; Yin and Roth, 2018; Hanselowski et al., 2018). Third, weakly supervised methods rely on noisy evidence labels, where the labels can be obtained by heuristic rules (Min et al., 2018"
2020.acl-main.361,P19-1225,0,0.0784954,"document (Seo et al., 2017; Huang et al., 2018; Zhu Evidence extraction aims at finding evidential and relevant information for downstream processes in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; Huang et al., 2019). Second, supervised methods train evidence extraction with golden evidence labels, which sometimes can be generated automatically in extractive MRC settings (Lin et al., 2018; Yin and Roth, 2018; Hanselowski et"
2020.acl-main.361,Q19-1016,0,0.154961,"vidence labels as extra supervision in the next iteration. We evaluate STM on seven datasets over three MRC tasks. Experimental results demonstrate the improvement on existing MRC models, and we also analyze how and why such a self-training method works in MRC. Introduction Machine reading comprehension (MRC) has received increasing attention recently, which can be roughly divided into two categories: extractive and non-extractive MRC. Extractive MRC requires a model to extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 201"
2020.acl-main.361,Q19-1014,0,0.0703699,"eived increasing attention recently, which can be roughly divided into two categories: extractive and non-extractive MRC. Extractive MRC requires a model to extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019). In contrast, non-extractive MRC infers answers based on some evidence in reference ∗ † Equal contribution Corresponding author: Minlie Huang. aihuang@tsinghua.edu.cn documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b). As shown in Table 1, evidence plays a vital role in MRC (Zhou et al., 2019; Ding et al., 2019; Min et al., 2018), and the coarse-tofine paradigm has been widely adopted in multiple models (Choi et al., 2017; Li et al., 2018; Wang et al., 2018) where an evidence extractor first seeks the evidence from given documents and then an answer predictor infers the answer based on the evidence. However, it is challenging to learn a good evidence extractor due to the lack of evidence labels for supervision. Neural models have achieved great su"
2020.acl-main.361,K19-1065,0,0.444343,"Manually annotating the golden evidence is expensive. Therefore, some recent efforts have been dedicated to improving MRC by leveraging noisy evidence labels when training the evidence extractor. Some works (Lin et al., 2018; Min et al., 2018) generate distant labels using hand-crafted rules and external resources. Some studies (Wang et al., 2018; Choi et al., 2017) adopt reinforcement learning (RL) to decide the labels of evidence. However, such RL methods suffer from unstable training. More distant supervision techniques are also used to refine noisy labels, such as deep probability logic (Wang et al., 2019), but they are hard to transfer to other tasks. Nevertheless, improving the evidence extractor remains challenging when golden evidence labels are not available. In this paper, we present a general and effective method based on Self-Training (Scudder, 1965) to improve MRC with soft evidence extraction when golden evidence labels are not available. Following the Self-Training paradigm, a base MRC model is iteratively trained. At each iteration, the base model is trained with golden answers, as well as noisy evidence labels obtained at the preceding it3916 Proceedings of the 58th Annual Meeting"
2020.acl-main.361,N18-1113,0,0.0788661,"ng, a widely used semi-supervised method. Most related studies follow the framework of traditional SelfTraining (Scudder, 1965) and Co-Training (Blum and Mitchell, 1998), and focus on designing better policies for selecting confident samples. CoTrade (Zhang and Zhou, 2011) evaluates the confidence of whether a sample has been correctly labeled via a statistic-based data editing technique (Zighed et al., 2002). Self-paced CoTraining (Ma et al., 2017) adjusts labeled data dynamically according to the consistency between the two models trained on different views. A reinforcement learning method (Wu et al., 2018) designs an additional Q-agent as a sample selector. 3 3.1 Methods model makes evidence predictions on unlabeled instances (the labeling arrow), and then Selector chooses the most confident instances from U to provide noisy evidence labels. In particular, the instances with newly generated evidence labels are moved from U to L (the moving arrow), which are used to supervise evidence extraction in the next iteration. This process will iterate several times. Selector ?    labeling Base Model training moving ?  Figure 1: Overview of Self-Training MRC (STM). The base model is trained on both L"
2020.acl-main.361,D18-1010,0,0.0272886,"luding BERT and DSQA (Lin et al., 2018). Experimental results demonstrate that our proposed method improves base models in three MRC tasks remarkably. 2 Related Work Early MRC studies focus on modeling semantic matching between a question and a reference document (Seo et al., 2017; Huang et al., 2018; Zhu Evidence extraction aims at finding evidential and relevant information for downstream processes in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extra"
2020.acl-main.361,P19-1217,0,0.0191047,"tasks remarkably. 2 Related Work Early MRC studies focus on modeling semantic matching between a question and a reference document (Seo et al., 2017; Huang et al., 2018; Zhu Evidence extraction aims at finding evidential and relevant information for downstream processes in a task, which arguably improves the overall performance of the task. Not surprisingly, evidence extraction is useful and becomes an important component in fact verification (Zhou et al., 2019; Yin and Roth, 2018; Hanselowski et al., 2018; Ma et al., 2019), multiple-choice reading comprehension (Wang et al., 2019; Bax, 2013; Yu et al., 2019), open-domain question answering (Lin et al., 2018; Wang et al., 2018), multi-hop reading comprehension (Nishida et al., 2019; Ding et al., 2019), natural language inference (Wang et al., 2017; Chen et al., 2017), and a wide range of other tasks (Nguyen and Nguyen, 2018; Chen and Bansal, 2018). In general, evidence extraction in MRC can be classified into four types according to the training method. First, unsupervised methods provide no guidance for evidence extraction (Seo et al., 2017; Huang et al., 2019). Second, supervised methods train evidence extraction with golden evidence labels, whi"
2020.acl-main.361,D17-1082,0,\N,Missing
2020.acl-main.59,D17-1259,0,0.045169,". Figure 1: The user has his/her own goal to be accomplished and the system is provided with an interface to access an external database. Both agents can only obtain information from the other side via communication. in a cooperative setting. As shown in Fig. 1, only the user agent knows the user goal, while only the system agent can access the backend database. The user agent should express the requirements completely in an organized way, and the system should respond with useful information accurately and immediately. So it is inappropriate to apply simple self-play RL (Silver et al., 2017; Lewis et al., 2017) that views two agents as the same agent in this task. To address this issue, the system and the user are viewed as two asymmetric agents in MADPL. We introduce Hybrid Value Network (HVN) for roleaware reward decomposition. It decomposes the reward into two parts: one is the role-specific reward that focuses on its local target, and the other is the global reward that represents the shared goal. To evaluate the proposed approach, we conduct our experiments on a multi-domain, multiintent task-oriented dialog corpus, MultiWOZ (Budzianowski et al., 2018). The corpus involves high dimensional stat"
2020.acl-main.59,W19-5912,0,0.34023,"behaviors. In this paper, we propose Multi-Agent Dialog Policy Learning (MADPL), where the user is regarded as another dialog agent rather than a user simulator. The conversation between the user and the system is modeled as a cooperative interactive process where the system agent and the user agent are trained simultaneously. Two dialog agents interact with each other and collaborate to achieve the goal so that they require no explicit domain expertise, which helps develop a dialog system without the need of a well-built user simulator. Different from existing methods (Georgila et al., 2014; Papangelis et al., 2019), our approach is based on actor-critic framework (Barto et al., 1983) in order to facilitate pretraining and bootstrap the RL training. Following the paradigm of centralized training with decentralized execution (CTDE) (Bernstein et al., 2002) in multi-agent RL (MARL), the actor selects its action conditioned only on its local stateaction history, while the critic is trained with the actions of all agents. It should be noted that the roles of two agents are different though they interact with each other 625 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistic"
2020.acl-main.59,D17-1237,0,0.1925,"Value Network for the role-aware reward decomposition to integrate role-specific domain knowledge of each agent in task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction. 1 Introduction Dialog policy, which decides the next action that the dialog agent should take, plays a vital role in a task-oriented dialog system. More recently, dialog policy learning has been widely formulated as a Reinforcement Learning (RL) problem (Su et al., 2016; Peng et al., 2017; He et al., 2018; Zhao et al., 2019; Zhang et al., 2019; Takanobu et al., 2019), which models users as the interactive environment. Since RL requires much interaction for training, it is too time-consuming and costly to interact with real users directly. The most common way is first ∗ Corresponding author to develop a dialog agent with a user simulator that mimics human behaviors in an offline scenario. Designing a reliable user simulator, however, is not trivial and often challenging as it is equivalent to building a good dialog agent. With the growing needs for the dialog system to handle m"
2020.acl-main.59,N07-2038,0,0.306034,"sk-oriented dialog. • We apply actor-critic based multi-agent reinforcement learning to learn the task-oriented dialog policy to facilitate pretraining and 626 2.2 User Modeling in Task-Oriented Dialog User modeling is essential for training RL-based dialog models, because a large amount of dialog samples are required for RL policy learning, making it impractical to learn with real users directly from the beginning. There are three main approaches for user modeling. The first approach is to build a rule-based user simulator. Among these methods, the most popular one is agenda-based simulator (Schatzmann et al., 2007; Shah et al., 2018), which is built on hand-crafted rules with a stack-like agenda based on the user goal. The second approach is to build a user simulator from the dialog data (Keizer et al., 2010; El Asri et al., 2016; Kreyssig et al., 2018). Recently, G¨ur et al. (2018) uses a variational hierarchical seq2seq framework to encode user goal and system turns, and then generate the user response. Shi et al. (2019) uses two decoders with a copy and attention mechanism to predict a belief span first and then decode user utterance. The third approach is to use model-based policy optimization that"
2020.acl-main.59,N18-3006,0,0.0624637,"Missing"
2020.acl-main.59,D19-1206,0,0.188697,"th real users directly. The most common way is first ∗ Corresponding author to develop a dialog agent with a user simulator that mimics human behaviors in an offline scenario. Designing a reliable user simulator, however, is not trivial and often challenging as it is equivalent to building a good dialog agent. With the growing needs for the dialog system to handle more complex tasks, it will be much challenging and laborious to build a fully rule-based user simulator, which requires heavy domain expertise. Datadriven user simulators have been proposed in recent studies (Kreyssig et al., 2018; Shi et al., 2019), but they require a considerable quantity of manually labeled data, most of which regard the simulator as a stationary environment. Furthermore, there is no standard automatic metric for evaluating these user simulators, as it is unclear to define how closely the simulator resembles real user behaviors. In this paper, we propose Multi-Agent Dialog Policy Learning (MADPL), where the user is regarded as another dialog agent rather than a user simulator. The conversation between the user and the system is modeled as a cooperative interactive process where the system agent and the user agent are"
2020.acl-main.59,J00-3003,0,0.698849,"Missing"
2020.acl-main.59,P16-1230,0,0.0402203,"Missing"
2020.acl-main.59,D18-1416,0,0.127471,"ch is to build a user simulator from the dialog data (Keizer et al., 2010; El Asri et al., 2016; Kreyssig et al., 2018). Recently, G¨ur et al. (2018) uses a variational hierarchical seq2seq framework to encode user goal and system turns, and then generate the user response. Shi et al. (2019) uses two decoders with a copy and attention mechanism to predict a belief span first and then decode user utterance. The third approach is to use model-based policy optimization that incorporates a differentiable model of the world dynamics and assumptions about the interactions between users and systems (Su et al., 2018; Zhang et al., 2019), but this approach still requires real users or a user simulator for world model learning. Instead of employing a user simulator, a few methods jointly learn two agents directly from the corpus. Liu and Lane (2017) models the system and the user by iteratively training two policies. Papangelis et al. (2019) make the first attempt to apply MARL into the task-oriented dialog policy, whose algorithm is based on Q-learning for mixed policies. However, it is not well scalable to complex tasks such as multi-domain dialog. Therefore, MADPL uses the actor-critic framework instead"
2020.acl-main.59,D19-1010,1,0.91139,"ecific domain knowledge of each agent in task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction. 1 Introduction Dialog policy, which decides the next action that the dialog agent should take, plays a vital role in a task-oriented dialog system. More recently, dialog policy learning has been widely formulated as a Reinforcement Learning (RL) problem (Su et al., 2016; Peng et al., 2017; He et al., 2018; Zhao et al., 2019; Zhang et al., 2019; Takanobu et al., 2019), which models users as the interactive environment. Since RL requires much interaction for training, it is too time-consuming and costly to interact with real users directly. The most common way is first ∗ Corresponding author to develop a dialog agent with a user simulator that mimics human behaviors in an offline scenario. Designing a reliable user simulator, however, is not trivial and often challenging as it is equivalent to building a good dialog agent. With the growing needs for the dialog system to handle more complex tasks, it will be much challenging and laborious to build a fully ru"
2020.acl-main.59,P19-1364,0,0.114993,"to integrate role-specific domain knowledge of each agent in task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction. 1 Introduction Dialog policy, which decides the next action that the dialog agent should take, plays a vital role in a task-oriented dialog system. More recently, dialog policy learning has been widely formulated as a Reinforcement Learning (RL) problem (Su et al., 2016; Peng et al., 2017; He et al., 2018; Zhao et al., 2019; Zhang et al., 2019; Takanobu et al., 2019), which models users as the interactive environment. Since RL requires much interaction for training, it is too time-consuming and costly to interact with real users directly. The most common way is first ∗ Corresponding author to develop a dialog agent with a user simulator that mimics human behaviors in an offline scenario. Designing a reliable user simulator, however, is not trivial and often challenging as it is equivalent to building a good dialog agent. With the growing needs for the dialog system to handle more complex tasks, it will be much challenging and labor"
2020.acl-main.59,N19-1123,0,0.0304627,"ward decomposition to integrate role-specific domain knowledge of each agent in task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction. 1 Introduction Dialog policy, which decides the next action that the dialog agent should take, plays a vital role in a task-oriented dialog system. More recently, dialog policy learning has been widely formulated as a Reinforcement Learning (RL) problem (Su et al., 2016; Peng et al., 2017; He et al., 2018; Zhao et al., 2019; Zhang et al., 2019; Takanobu et al., 2019), which models users as the interactive environment. Since RL requires much interaction for training, it is too time-consuming and costly to interact with real users directly. The most common way is first ∗ Corresponding author to develop a dialog agent with a user simulator that mimics human behaviors in an offline scenario. Designing a reliable user simulator, however, is not trivial and often challenging as it is equivalent to building a good dialog agent. With the growing needs for the dialog system to handle more complex tasks, it will be much c"
2020.acl-main.59,P14-1047,0,\N,Missing
2020.acl-main.59,D18-1547,0,\N,Missing
2020.acl-main.59,W18-5007,0,\N,Missing
2020.acl-main.635,D14-1179,0,0.0186658,"Missing"
2020.acl-main.635,N19-1423,0,0.0203577,"current encoder-decoder model that has a specific context RNN to incorporate historical conversational utterances into a context state, which is used as the initial hidden state of the decoder. The adapted model generates the k-th utterance based on the past k − 1 utterances, where k was also set to 8, for fair comparison with Seq2Seq. All the generative models were trained by optimizing the cross-entropy loss: (g) L0 = − T 1X log P(ˆ xt = xt ), T t=1 where x ˆt denotes the predicted token at the time step t, while xt is the t-th token of the target sentence. 4.1.2 Retrieval-based Model BERT (Devlin et al., 2019): We adapted this deep bidirectional transformers (Vaswani et al., 2017) as a retrieval-based model. For each utterance (except the first one in a dialog), we extracted keywords in the same way as Wu et al. (2017) and retrieved 10 response candidates, including the golden truth based on the BM25 algorithm (Robertson et al., 1995). The training task is to predict whether a candidate is the correct next utterance given the context, where a sigmoid function was used to output the probability score yˆ = P(y = 1) and the cross-entropy loss was optimized: 7103 (r) L0 = −y log yˆ − (1 − y) log(1 − yˆ"
2020.acl-main.635,N16-1014,0,0.64384,"ntroducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available1 . 1 Introduction It has been a long-term goal of artificial intelligence to deliver human-like conversations, where background knowledge plays a crucial role in the success of conversational systems (Shang et al., 2015; Li et al., 2016a; Shao et al., 2017). In taskoriented dialog systems, background knowledge is defined as slot-value pairs, which provides key information for question answering or recommendation, and has been well defined and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al."
2020.acl-main.635,P18-1138,0,0.275527,"tudied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations of topics. OpenDialKG (Moon et al., 2019) and DuConv (W"
2020.acl-main.635,W15-4640,0,0.0739565,"nt but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations of topics. OpenDialKG (Moon et al., 2019) and DuConv (Wu et al., 2019) use knowledge graphs as knowledge resources. Nevertheless, the number of topics is limited to one (Moon et al., 2019) or two (Wu et al., 2019), which is not sufficient for diversif"
2020.acl-main.635,D16-1147,0,0.0245084,"rds in the same way as Wu et al. (2017) and retrieved 10 response candidates, including the golden truth based on the BM25 algorithm (Robertson et al., 1995). The training task is to predict whether a candidate is the correct next utterance given the context, where a sigmoid function was used to output the probability score yˆ = P(y = 1) and the cross-entropy loss was optimized: 7103 (r) L0 = −y log yˆ − (1 − y) log(1 − yˆ), where y ∈ {0, 1} is the true label. For the test, we selected the candidate response with the largest probability. 4.1.3 Knowledge-aware Models A key-value memory module (Miller et al., 2016) is introduced to the aforementioned models to utilize the knowledge information. We treated all knowledge triples mentioned in a dialogue as the knowledge information in the memory module. For a triple that is indexed by i, we represented the key memory and the value memory respectively as a key vector ki and a value vector vi , where ki is the average word embeddings of the head entity and the relation, and vi is those of the tail entity. We used a query vector q to attend to the key vectors ki (i = 1, 2, ...): αi = softmaxi (q T ki ), then the weighted P sum of the value vectors vi (i = 1,"
2020.acl-main.635,D18-1255,0,0.335864,"commendation, and has been well defined and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations o"
2020.acl-main.635,P19-1081,0,0.169542,"s been well defined and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations of topics. OpenDialK"
2020.acl-main.635,D18-1398,0,0.0179714,"nce/character respectively). collect multi-turn conversations from scratch based on such large-scale knowledge. KdConv is proposed as one small step to achieve this goal, where we narrowed down the scale of background knowledge to several domains (film, music, and travel) and collected conversations based on the domainspecific knowledge. KdConv contains similar domains (film and music) and dissimilar domains (film and travel) so that it offers the possibility to investigate the generalization and transferability of knowledge-driven conversational models with transfer learning or meta learning(Gu et al., 2018; Mi et al., 2019). In the following subsections, we will describe the two steps in data collection: (1) Constructing the domain-specific knowledge graph; (2) Collecting conversation utterances and knowledge interactions by crowdsourcing. 3.1 Knowledge Graph Construction As the sparsity and the large scale of the knowledge were difficult to handle, we reduced the range of the domain-specific knowledge by crawling the most popular films and film stars, music and singers, and attractions as start entities, from several related websites for the film4 /music5 /travel6 domain. The knowledge of thes"
2020.acl-main.635,P02-1040,0,0.106856,"DAM (Kingma and Ba, 2014) was used to optimize all the models with the initial learning rate of 5 × 10−5 for BERT and 10−3 for others. The mini-batch sizes are set to 2 dialogues for LM and 32 pairs of post and response for Seq2Seq and HRED. 4.3 4.3.1 Metrics We measured the performance of all the retrievalbased models using Hits@1 and Hits@3, same as Zhang et al. (2018) and Wu et al. (2019). 8 We adopted several widely-used metrics to measure the quality of the generated response. We calculated Perplexity (PPL) to evaluate whether the generation result is grammatical and fluent. BLEU1/2/3/4 (Papineni et al., 2002) is a popular metric to compute the k-gram overlap between a generated sentence and a reference (Sordoni et al., 2015; Li et al., 2016b). Distinct-1/2/3/4 (Li et al., 2016b) is also provided to evaluates the diversity of generated responses. 4.3.2 Results The results are shown in Table 5. We analyze the results from the following perspectives: The influence of knowledge: after introducing the knowledge, all the models were improved in terms of all the metrics except PPL in all the domains. First, all the models obtain higher Hits@1 scores (in the music domain, BERT obtains an improvement of 0."
2020.acl-main.635,P19-1539,0,0.25324,", 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations of topics. OpenDialKG (Moon et al., 2019) and DuConv (Wu et al., 2019) use knowledge graphs a"
2020.acl-main.635,N10-1020,0,0.0602713,"n adaptation or transfer learning between similar domains (e.g., from film to music) or dissimilar domains (e.g., from music to travel). • We provide benchmark models on this corpus to facilitate further research, and conduct extensive experiments. Results show that the models can be enhanced by introducing background knowledge, but there is still much room for further research. The corpus and the models are publicly available3 . 2 Related Work Recently, open-domain conversation generation has been largely advanced due to the increase of publicly available dialogue data (Godfrey et al., 1992; Ritter et al., 2010; Shang et al., 2015; Lowe et al., 2015). However, the lack of annotation of background information or related knowledge results in significantly degenerated conversations, where the text is bland and strangely repetitive (Holtzman et al., 2019). These models produce conversations that are substantially different from those humans make, which largely rely on background knowledge. To facilitate the development of conversational models that mimic human conversations, there have been several knowledge-grounded corpora proposed. Some datasets (Zhou et al., 2018b; Ghazvininejad et al., 2018; Liu et"
2020.acl-main.635,P15-1152,0,0.143131,"can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available1 . 1 Introduction It has been a long-term goal of artificial intelligence to deliver human-like conversations, where background knowledge plays a crucial role in the success of conversational systems (Shang et al., 2015; Li et al., 2016a; Shao et al., 2017). In taskoriented dialog systems, background knowledge is defined as slot-value pairs, which provides key information for question answering or recommendation, and has been well defined and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Gha"
2020.acl-main.635,N18-2028,0,0.0254902,"ighted sum of L0 and Latt : (l) (l) Ltot = L0 + λLatt , l ∈ {g, r}. Note that the knowledge-enhanced BERT was initialized from the fine-tuned BERT discussed in Section 4.1.2, and the parameters of the transformers were frozen during training the knowledge related modules. The purpose was to exclude the impact of the deep transformers but only examine the potential effects introduced by the background knowledge. 4.2 Implementation Details 2017) and CoTK (Huang et al., 2020). The Jieba Chinese word segmenter7 was employed for tokenization. The 200-dimensional word embeddings were initialized by Song et al. (2018), while the unmatched ones were randomly sampled from a standard normal distribution N (0, 1). The type of RNN network units was all GRU (Cho et al., 2014) and the number of hidden units of GRU cells were all set to 200. ADAM (Kingma and Ba, 2014) was used to optimize all the models with the initial learning rate of 5 × 10−5 for BERT and 10−3 for others. The mini-batch sizes are set to 2 dialogues for LM and 32 pairs of post and response for Seq2Seq and HRED. 4.3 4.3.1 Metrics We measured the performance of all the retrievalbased models using Hits@1 and Hits@3, same as Zhang et al. (2018) and"
2020.acl-main.635,N15-1020,0,0.091094,"Missing"
2020.acl-main.635,D15-1199,0,0.0119797,"ing that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available1 . 1 Introduction It has been a long-term goal of artificial intelligence to deliver human-like conversations, where background knowledge plays a crucial role in the success of conversational systems (Shang et al., 2015; Li et al., 2016a; Shao et al., 2017). In taskoriented dialog systems, background knowledge is defined as slot-value pairs, which provides key information for question answering or recommendation, and has been well defined and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan e"
2020.acl-main.635,P19-1369,0,0.310226,"and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations of topics. OpenDialKG (Moon et al., 2"
2020.acl-main.635,P17-1046,0,0.01859,"ates the k-th utterance based on the past k − 1 utterances, where k was also set to 8, for fair comparison with Seq2Seq. All the generative models were trained by optimizing the cross-entropy loss: (g) L0 = − T 1X log P(ˆ xt = xt ), T t=1 where x ˆt denotes the predicted token at the time step t, while xt is the t-th token of the target sentence. 4.1.2 Retrieval-based Model BERT (Devlin et al., 2019): We adapted this deep bidirectional transformers (Vaswani et al., 2017) as a retrieval-based model. For each utterance (except the first one in a dialog), we extracted keywords in the same way as Wu et al. (2017) and retrieved 10 response candidates, including the golden truth based on the BM25 algorithm (Robertson et al., 1995). The training task is to predict whether a candidate is the correct next utterance given the context, where a sigmoid function was used to output the probability score yˆ = P(y = 1) and the cross-entropy loss was optimized: 7103 (r) L0 = −y log yˆ − (1 − y) log(1 − yˆ), where y ∈ {0, 1} is the true label. For the test, we selected the candidate response with the largest probability. 4.1.3 Knowledge-aware Models A key-value memory module (Miller et al., 2016) is introduced to t"
2020.acl-main.635,P18-1205,0,0.0565722,"ed by Song et al. (2018), while the unmatched ones were randomly sampled from a standard normal distribution N (0, 1). The type of RNN network units was all GRU (Cho et al., 2014) and the number of hidden units of GRU cells were all set to 200. ADAM (Kingma and Ba, 2014) was used to optimize all the models with the initial learning rate of 5 × 10−5 for BERT and 10−3 for others. The mini-batch sizes are set to 2 dialogues for LM and 32 pairs of post and response for Seq2Seq and HRED. 4.3 4.3.1 Metrics We measured the performance of all the retrievalbased models using Hits@1 and Hits@3, same as Zhang et al. (2018) and Wu et al. (2019). 8 We adopted several widely-used metrics to measure the quality of the generated response. We calculated Perplexity (PPL) to evaluate whether the generation result is grammatical and fluent. BLEU1/2/3/4 (Papineni et al., 2002) is a popular metric to compute the k-gram overlap between a generated sentence and a reference (Sordoni et al., 2015; Li et al., 2016b). Distinct-1/2/3/4 (Li et al., 2016b) is also provided to evaluates the diversity of generated responses. 4.3.2 Results The results are shown in Table 5. We analyze the results from the following perspectives: The i"
2020.acl-main.635,C16-1191,1,0.906669,"Missing"
2020.acl-main.635,D18-1076,0,0.305676,"of conversational systems (Shang et al., 2015; Li et al., 2016a; Shao et al., 2017). In taskoriented dialog systems, background knowledge is defined as slot-value pairs, which provides key information for question answering or recommendation, and has been well defined and thoroughly studied (Wen et al., 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrat"
2020.acl-main.635,D19-1194,0,0.129115,", 2015; Zhou et al., 2016). In ∗ Equal contribution Corresponding author: Minlie Huang. 1 https://github.com/thu-coai/KdConv † open-domain conversational systems, it is important but challenging to leverage background knowledge, which is represented as either knowledge graphs (Zhu et al., 2017; Zhou et al., 2018a) or unstructured texts (Ghazvininejad et al., 2018), for making effective interactions. Recently, a variety of knowledge-grounded conversation corpora have been proposed (Zhou et al., 2018b; Dinan et al., 2018; Moghe et al., 2018; Moon et al., 2019; Wu et al., 2019; Liu et al., 2018; Tuan et al., 2019; Qin et al., 2019) to fill the gap where previous datasets do not provide knowledge grounding of the conversations (Godfrey et al., 1992; Shang et al., 2015; Lowe et al., 2015). CMU DoG (Zhou et al., 2018b), India DoG (Moghe et al., 2018), and Wizard of Wikipedia (Dinan et al., 2018) demonstrate attempts for generating informative responses with topic-related Wikipedia articles. However, these datasets are not suitable for modeling topic transition or knowledge planning through multi-turn dialogs based on the relations of topics. OpenDialKG (Moon et al., 2019) and DuConv (Wu et al., 2019) use"
2020.emnlp-demos.12,N19-4015,0,0.0234476,"f the system is available at https://youtu.be/DFeNpHk0pm4. 1 Introduction Lyrics Generation has been a prevalent task in Natural Language Generation (NLG), due to the easy availability of training data and the value of the application. However, despite the popularity of lyrics generation, there still lacks a comprehensive lyrics creation assistant system for music creators. Previous researches (Castro and Attarian, 2018; Saeed et al., 2019; Lu et al., 2019; Manjavacas et al., 2019; Watanabe et al., 2018; Potash et al., 2018; Fan et al., 2019; Li et al., 2020) and systems (Potash et al., 2015; Lee et al., 2019; Shen et al., 2019), are mostly model-oriented, utilizing ∗ † Equal contribution Corresponding Author 85 Proceedings of the 2020 EMNLP (Systems Demonstrations), pages 85–91 c November 16-20, 2020. 2020 Association for Computational Linguistics Content controlling attributes Style: 流行(Pop) Emotion: 积极 (Positive) Theme: 校园 (Campus) Expected Keywords: 青春 (Youth) Format controlling attributes Acrostic: 多想再见到你 (I want to meet you again) Rhyme: 言前辙 (YanQian) Line count: 6 Word count: 8, 9, 9, 7, 7, 7 User Input Full-text generation Interactive generation 多年前的那个夏天(ian) (That summer many years ago )"
2020.emnlp-demos.12,N18-1015,0,0.033872,"Missing"
2020.emnlp-demos.12,2020.acl-main.68,0,0.0242127,"nt and format of generated lyrics. The demo video of the system is available at https://youtu.be/DFeNpHk0pm4. 1 Introduction Lyrics Generation has been a prevalent task in Natural Language Generation (NLG), due to the easy availability of training data and the value of the application. However, despite the popularity of lyrics generation, there still lacks a comprehensive lyrics creation assistant system for music creators. Previous researches (Castro and Attarian, 2018; Saeed et al., 2019; Lu et al., 2019; Manjavacas et al., 2019; Watanabe et al., 2018; Potash et al., 2018; Fan et al., 2019; Li et al., 2020) and systems (Potash et al., 2015; Lee et al., 2019; Shen et al., 2019), are mostly model-oriented, utilizing ∗ † Equal contribution Corresponding Author 85 Proceedings of the 2020 EMNLP (Systems Demonstrations), pages 85–91 c November 16-20, 2020. 2020 Association for Computational Linguistics Content controlling attributes Style: 流行(Pop) Emotion: 积极 (Positive) Theme: 校园 (Campus) Expected Keywords: 青春 (Youth) Format controlling attributes Acrostic: 多想再见到你 (I want to meet you again) Rhyme: 言前辙 (YanQian) Line count: 6 Word count: 8, 9, 9, 7, 7, 7 User Input Full-text generation Interactive gene"
2020.emnlp-demos.12,W19-8638,0,0.016413,"edly. Besides, Youling allows users to use multifaceted attributes to control the content and format of generated lyrics. The demo video of the system is available at https://youtu.be/DFeNpHk0pm4. 1 Introduction Lyrics Generation has been a prevalent task in Natural Language Generation (NLG), due to the easy availability of training data and the value of the application. However, despite the popularity of lyrics generation, there still lacks a comprehensive lyrics creation assistant system for music creators. Previous researches (Castro and Attarian, 2018; Saeed et al., 2019; Lu et al., 2019; Manjavacas et al., 2019; Watanabe et al., 2018; Potash et al., 2018; Fan et al., 2019; Li et al., 2020) and systems (Potash et al., 2015; Lee et al., 2019; Shen et al., 2019), are mostly model-oriented, utilizing ∗ † Equal contribution Corresponding Author 85 Proceedings of the 2020 EMNLP (Systems Demonstrations), pages 85–91 c November 16-20, 2020. 2020 Association for Computational Linguistics Content controlling attributes Style: 流行(Pop) Emotion: 积极 (Positive) Theme: 校园 (Campus) Expected Keywords: 青春 (Youth) Format controlling attributes Acrostic: 多想再见到你 (I want to meet you again) Rhyme: 言前辙 (YanQian) Line count:"
2020.emnlp-demos.12,D15-1221,0,0.0125287,"ics. The demo video of the system is available at https://youtu.be/DFeNpHk0pm4. 1 Introduction Lyrics Generation has been a prevalent task in Natural Language Generation (NLG), due to the easy availability of training data and the value of the application. However, despite the popularity of lyrics generation, there still lacks a comprehensive lyrics creation assistant system for music creators. Previous researches (Castro and Attarian, 2018; Saeed et al., 2019; Lu et al., 2019; Manjavacas et al., 2019; Watanabe et al., 2018; Potash et al., 2018; Fan et al., 2019; Li et al., 2020) and systems (Potash et al., 2015; Lee et al., 2019; Shen et al., 2019), are mostly model-oriented, utilizing ∗ † Equal contribution Corresponding Author 85 Proceedings of the 2020 EMNLP (Systems Demonstrations), pages 85–91 c November 16-20, 2020. 2020 Association for Computational Linguistics Content controlling attributes Style: 流行(Pop) Emotion: 积极 (Positive) Theme: 校园 (Campus) Expected Keywords: 青春 (Youth) Format controlling attributes Acrostic: 多想再见到你 (I want to meet you again) Rhyme: 言前辙 (YanQian) Line count: 6 Word count: 8, 9, 9, 7, 7, 7 User Input Full-text generation Interactive generation 多年前的那个夏天(ian) (That summer"
2020.emnlp-demos.12,W18-1604,0,0.0301916,"faceted attributes to control the content and format of generated lyrics. The demo video of the system is available at https://youtu.be/DFeNpHk0pm4. 1 Introduction Lyrics Generation has been a prevalent task in Natural Language Generation (NLG), due to the easy availability of training data and the value of the application. However, despite the popularity of lyrics generation, there still lacks a comprehensive lyrics creation assistant system for music creators. Previous researches (Castro and Attarian, 2018; Saeed et al., 2019; Lu et al., 2019; Manjavacas et al., 2019; Watanabe et al., 2018; Potash et al., 2018; Fan et al., 2019; Li et al., 2020) and systems (Potash et al., 2015; Lee et al., 2019; Shen et al., 2019), are mostly model-oriented, utilizing ∗ † Equal contribution Corresponding Author 85 Proceedings of the 2020 EMNLP (Systems Demonstrations), pages 85–91 c November 16-20, 2020. 2020 Association for Computational Linguistics Content controlling attributes Style: 流行(Pop) Emotion: 积极 (Positive) Theme: 校园 (Campus) Expected Keywords: 青春 (Youth) Format controlling attributes Acrostic: 多想再见到你 (I want to meet you again) Rhyme: 言前辙 (YanQian) Line count: 6 Word count: 8, 9, 9, 7, 7, 7 User Input F"
2020.emnlp-demos.12,D19-3008,0,0.0528386,"Missing"
2020.emnlp-main.277,P19-1608,0,0.0871381,"ored in various NLP tasks, such as text classification (Wei and Zou, 2019; Zheng et al., 2020a), machine reading comprehension (Yu et al., 2018) and machine translation (Sennrich et al., 2016). Although proved to be effective, this technique is rarely investigated in open-domain dialogue models. Few existing approaches are restricted to only take the dialogue pairs as their inputs (Li et al., 2019; Zhao et al., 2017; Cai et al., 2020), whereas unpaired texts, i.e., sentences without replies, are not utilized. Note that the pre-training based methods (Devlin et al., 2019; Radford et al., 2019; Golovanov et al., 2019; Zheng et al., 2020b) share a similar motivation with our study, i.e., to boost the performance of neural NLP models utilizing unlabeled (i.e., unpaired) texts. Nevertheless, the data augmentation method proposed in our study can be regarded as a supplement to these pre-training approaches. Experiments demonstrate that our method can be used to improve the performance of dialogue models even if these models are initialized with strong pretrained models. Our study is also related to the knowledge distillation method (Hinton et al., 2015), which also employs a teacher model and tries to minimiz"
2020.emnlp-main.277,2020.findings-emnlp.196,0,0.0772925,"Missing"
2020.emnlp-main.277,N19-1124,0,0.0186519,"to rank these candidate pairs. the KL divergence between the teacher distribution and the model distribution. The most related work in this branch compared to ours was done by Kim and Rush (2016). However, their methods do not utilize unpaired data, and the augmented data are decoded from a probability model using beam search. Whereas our method tries to utilize the unpaired data, and the augmented data are generated by aligning human produced sentences. There are also works that try to utilize retrieved non-conversational texts to improve the diversity of the dialogue model (Wu et al., 2019; Cai et al., 2019; Zhu et al., 2019; Su et al., 2020). However, most of these studies focus on extracting templates from these non-conversational texts rather than generating augmented pairs, and they typically use specifically designed model structures. Nevertheless, the data augmentation method proposed in our study can be used in combination with any dialogue models to improve the performance. 3 Data-level Distillation The data-level distillation in our method aims at constructing a set of new post-response pairs Da by matching non-parallel sentences retrieved from 3.1 Constructing Candidate Pairs We first"
2020.emnlp-main.277,2020.acl-main.564,0,0.0193239,"categories all focus on DNN-based data-driven methods (Huang et al., 2020). Data augmentation is an effective approach to boost the performance of neural models. It has been explored in various NLP tasks, such as text classification (Wei and Zou, 2019; Zheng et al., 2020a), machine reading comprehension (Yu et al., 2018) and machine translation (Sennrich et al., 2016). Although proved to be effective, this technique is rarely investigated in open-domain dialogue models. Few existing approaches are restricted to only take the dialogue pairs as their inputs (Li et al., 2019; Zhao et al., 2017; Cai et al., 2020), whereas unpaired texts, i.e., sentences without replies, are not utilized. Note that the pre-training based methods (Devlin et al., 2019; Radford et al., 2019; Golovanov et al., 2019; Zheng et al., 2020b) share a similar motivation with our study, i.e., to boost the performance of neural NLP models utilizing unlabeled (i.e., unpaired) texts. Nevertheless, the data augmentation method proposed in our study can be regarded as a supplement to these pre-training approaches. Experiments demonstrate that our method can be used to improve the performance of dialogue models even if these models are"
2020.emnlp-main.277,N19-1423,0,0.557887,"formance of neural models. It has been explored in various NLP tasks, such as text classification (Wei and Zou, 2019; Zheng et al., 2020a), machine reading comprehension (Yu et al., 2018) and machine translation (Sennrich et al., 2016). Although proved to be effective, this technique is rarely investigated in open-domain dialogue models. Few existing approaches are restricted to only take the dialogue pairs as their inputs (Li et al., 2019; Zhao et al., 2017; Cai et al., 2020), whereas unpaired texts, i.e., sentences without replies, are not utilized. Note that the pre-training based methods (Devlin et al., 2019; Radford et al., 2019; Golovanov et al., 2019; Zheng et al., 2020b) share a similar motivation with our study, i.e., to boost the performance of neural NLP models utilizing unlabeled (i.e., unpaired) texts. Nevertheless, the data augmentation method proposed in our study can be regarded as a supplement to these pre-training approaches. Experiments demonstrate that our method can be used to improve the performance of dialogue models even if these models are initialized with strong pretrained models. Our study is also related to the knowledge distillation method (Hinton et al., 2015), which als"
2020.emnlp-main.277,W18-5708,0,0.026605,"arge amount of high-quality paired data, e.g., post-response pairs, which are usually labor-intensive and time consuming to collect. A feasible solution to this data dilemma is to use data augmentation techniques, which are popular in various research areas such as computer vision (Cubuk et al., 2019) or machine translation (Sennrich et al., 2016). Nevertheless, this technique is rarely investigated in the study of opendomain dialogues, and few existing approaches are specifically designed for either the generationbased dialogue models (Li et al., 2019) or the retrieval-based dialogue models (Du and Black, 2018). Moreover, existing data augmentation approaches only take a set of paired data as input without considering to utilize unpaired data. As a matter of fact, high-quality unpaired data, i.e., non-conversational texts, are generally easier to collect compared to high-quality dialogue pairs. Specifically, these unpaired data provide us a rich 3449 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 3449–3460, c November 16–20, 2020. 2020 Association for Computational Linguistics bank of alternative expressions for different contents. It is thus feasible t"
2020.emnlp-main.277,D16-1139,0,0.326117,"is randomly selected in the unpaired data Du . (2) A set of posts X1 , . . . , Xn that are similar to S are retrieved from the paired data Dp . (3) Each corresponding response Yi is then used to retrieve m sentences Si1 , . . . , Sim that are similar to Yi from Du . (4) Then n × m candidate pairs can be formed by grouping S with each sentence: hS, Sij i, (i = 1, . . . , n, j = 1, . . . , m). (5) A ranking module is used to rank these candidate pairs. the KL divergence between the teacher distribution and the model distribution. The most related work in this branch compared to ours was done by Kim and Rush (2016). However, their methods do not utilize unpaired data, and the augmented data are decoded from a probability model using beam search. Whereas our method tries to utilize the unpaired data, and the augmented data are generated by aligning human produced sentences. There are also works that try to utilize retrieved non-conversational texts to improve the diversity of the dialogue model (Wu et al., 2019; Cai et al., 2019; Zhu et al., 2019; Su et al., 2020). However, most of these studies focus on extracting templates from these non-conversational texts rather than generating augmented pairs, and"
2020.emnlp-main.277,W04-3250,0,0.0631273,"Missing"
2020.emnlp-main.277,N16-1014,0,0.0405767,"unpaired data Du using X and Y as the query, respectively. An augmented pair is constructed by pairing the retrieved post and response sentence without the ranking process. Note that there are two major differences between the baseline SP and our data-level distillation process: 1) the baseline SP starts with a dialogue pair hX, Y i sampled from Dp rather than a candidate post sampled from Du ; 2) The ranking process is not used in the baseline SP to further filter the candidate pairs. 5.3.2 Metrics The automatic evaluation of augmented dialogue pairs uses the following metrics: 1) Distinct (Li et al., 2016) is used to measure the proportion of unique n-grams in the augmented dialogue pairs (n=1,2,3,4); 2) Novelty (Wang and Wan, 2018) is used to measure the proportion of new n-grams in the augmented dialogue pairs (n=1,2,3,4), i.e., ngrams that are covered by the augmented dialogue pairs but are not shown in the paired dataset Dp . A higher novelty score means the augmented dialogue pairs contain more “novel” contents. Manual evaluation is also used to evaluate the quality of augmented dialogue pairs. Three annotators are employed to rate these pairs from two aspects: 1) Fluency (Flu.): whether t"
2020.emnlp-main.277,P16-1009,0,0.274287,"al., 2018b, 2020). ∗ 2 Equal contribution. Order determined by swapping the one in Zheng et al. (2020b) † Work performed while at Fuxi AI Lab, NetEase Inc. ‡ Corresponding Author: aihuang@tsinghua.edu.cn In general, training neural open-domain dialogue models requires a large amount of high-quality paired data, e.g., post-response pairs, which are usually labor-intensive and time consuming to collect. A feasible solution to this data dilemma is to use data augmentation techniques, which are popular in various research areas such as computer vision (Cubuk et al., 2019) or machine translation (Sennrich et al., 2016). Nevertheless, this technique is rarely investigated in the study of opendomain dialogues, and few existing approaches are specifically designed for either the generationbased dialogue models (Li et al., 2019) or the retrieval-based dialogue models (Du and Black, 2018). Moreover, existing data augmentation approaches only take a set of paired data as input without considering to utilize unpaired data. As a matter of fact, high-quality unpaired data, i.e., non-conversational texts, are generally easier to collect compared to high-quality dialogue pairs. Specifically, these unpaired data provid"
2020.emnlp-main.277,2020.acl-main.634,0,0.0136016,"L divergence between the teacher distribution and the model distribution. The most related work in this branch compared to ours was done by Kim and Rush (2016). However, their methods do not utilize unpaired data, and the augmented data are decoded from a probability model using beam search. Whereas our method tries to utilize the unpaired data, and the augmented data are generated by aligning human produced sentences. There are also works that try to utilize retrieved non-conversational texts to improve the diversity of the dialogue model (Wu et al., 2019; Cai et al., 2019; Zhu et al., 2019; Su et al., 2020). However, most of these studies focus on extracting templates from these non-conversational texts rather than generating augmented pairs, and they typically use specifically designed model structures. Nevertheless, the data augmentation method proposed in our study can be used in combination with any dialogue models to improve the performance. 3 Data-level Distillation The data-level distillation in our method aims at constructing a set of new post-response pairs Da by matching non-parallel sentences retrieved from 3.1 Constructing Candidate Pairs We first construct candidate dialogue pairs w"
2020.emnlp-main.277,D19-1670,0,0.0201036,"models. 2 Related Work There are two major categories of open-domain dialogue models: 1) retrieval-based models, which retrieve the best matching response from the precollected dialogues (Lu and Li, 2013); and 2) generation-based models, which decode responses from a learned distribution (Sutskever et al., 2014; Vinyals and Le, 2015). Recent advances in these two categories all focus on DNN-based data-driven methods (Huang et al., 2020). Data augmentation is an effective approach to boost the performance of neural models. It has been explored in various NLP tasks, such as text classification (Wei and Zou, 2019; Zheng et al., 2020a), machine reading comprehension (Yu et al., 2018) and machine translation (Sennrich et al., 2016). Although proved to be effective, this technique is rarely investigated in open-domain dialogue models. Few existing approaches are restricted to only take the dialogue pairs as their inputs (Li et al., 2019; Zhao et al., 2017; Cai et al., 2020), whereas unpaired texts, i.e., sentences without replies, are not utilized. Note that the pre-training based methods (Devlin et al., 2019; Radford et al., 2019; Golovanov et al., 2019; Zheng et al., 2020b) share a similar motivation w"
2020.emnlp-main.277,P18-1205,0,0.0424892,"d postresponse pairs. The sentence in blue rectangle is used to match the anchor pair and the corresponding response is then used to retrieve similar sentences in unpaired data. Each augmented pair contains two sentences both from unpaired data. Introduction Open-domain dialogue systems have attracted much research attention (Shum et al., 2018; Huang et al., 2020), thanks to the success of neural generation models trained with large-scale data. Existing research has been endeavored to address various aspects in dialogue systems, such as modeling persona (Qian et al., 2018; Zheng et al., 2019; Zhang et al., 2018), expressing emotion (Zhou et al., 2018a), or generating knowledge-grounded dialogues (Ghazvininejad et al., 2018; Zhou et al., 2018b, 2020). ∗ 2 Equal contribution. Order determined by swapping the one in Zheng et al. (2020b) † Work performed while at Fuxi AI Lab, NetEase Inc. ‡ Corresponding Author: aihuang@tsinghua.edu.cn In general, training neural open-domain dialogue models requires a large amount of high-quality paired data, e.g., post-response pairs, which are usually labor-intensive and time consuming to collect. A feasible solution to this data dilemma is to use data augmentation tec"
2020.emnlp-main.277,W17-5505,0,0.0262214,"vances in these two categories all focus on DNN-based data-driven methods (Huang et al., 2020). Data augmentation is an effective approach to boost the performance of neural models. It has been explored in various NLP tasks, such as text classification (Wei and Zou, 2019; Zheng et al., 2020a), machine reading comprehension (Yu et al., 2018) and machine translation (Sennrich et al., 2016). Although proved to be effective, this technique is rarely investigated in open-domain dialogue models. Few existing approaches are restricted to only take the dialogue pairs as their inputs (Li et al., 2019; Zhao et al., 2017; Cai et al., 2020), whereas unpaired texts, i.e., sentences without replies, are not utilized. Note that the pre-training based methods (Devlin et al., 2019; Radford et al., 2019; Golovanov et al., 2019; Zheng et al., 2020b) share a similar motivation with our study, i.e., to boost the performance of neural NLP models utilizing unlabeled (i.e., unpaired) texts. Nevertheless, the data augmentation method proposed in our study can be regarded as a supplement to these pre-training approaches. Experiments demonstrate that our method can be used to improve the performance of dialogue models even i"
2020.emnlp-main.277,2020.acl-main.635,1,0.865181,"Missing"
2020.emnlp-main.277,P19-1366,0,0.0235861,"idate pairs. the KL divergence between the teacher distribution and the model distribution. The most related work in this branch compared to ours was done by Kim and Rush (2016). However, their methods do not utilize unpaired data, and the augmented data are decoded from a probability model using beam search. Whereas our method tries to utilize the unpaired data, and the augmented data are generated by aligning human produced sentences. There are also works that try to utilize retrieved non-conversational texts to improve the diversity of the dialogue model (Wu et al., 2019; Cai et al., 2019; Zhu et al., 2019; Su et al., 2020). However, most of these studies focus on extracting templates from these non-conversational texts rather than generating augmented pairs, and they typically use specifically designed model structures. Nevertheless, the data augmentation method proposed in our study can be used in combination with any dialogue models to improve the performance. 3 Data-level Distillation The data-level distillation in our method aims at constructing a set of new post-response pairs Da by matching non-parallel sentences retrieved from 3.1 Constructing Candidate Pairs We first construct candidat"
2020.emnlp-main.54,W05-0909,0,0.397637,"Missing"
2020.emnlp-main.54,D18-1454,0,0.0573109,"Missing"
2020.emnlp-main.54,P19-1470,0,0.0376001,"rporate one-hop knowledge graph for concepts in the story context. In topic-to-essay generation, Yang et al. (2019) augmented the generator with a concept memory that updated dynamically with gate mechanism. Recently, some work also attempted to integrate external commonsense knowledge into generative pretrained language models such as GPT-2 (Radford et al., 2019). Guan et al. (2020) conducted posttraining on sythetic data constructed from commonsense knowledge bases by translating triplets into natural language texts using templates. Bhagavatula et al. (2020) transferred embeddings of COMeT (Bosselut et al., 2019), a GPT-2 model fine-tuned to generate the tail entity of a triple in commonsense knowledge graph, into another GPT-2 model for text generation. In comparison, our model utilizes both structural and semantic information of the commonsense knowledge graph during generation and does not suffers from the catastrophic forgetting problem (Kirkpatrick et al., 2016) caused by implicit knowledge transferring. Our contributions can be summarized as follows: 1) We propose GRF, a novel generation model that utilizes external structural commonsense knowledge to facilitate explicit commonsense reasoning in"
2020.emnlp-main.54,N19-1240,0,0.295331,"e commonsense-aware text generation tasks and show that our model outperforms various selective baselines. We also visualize reasoning paths inferred by the model to demonstrate the effectiveness of the multi-hop reasoning module. 2 2.1 Related Work Commonsense-Aware Neural Text Generation Incorporating commonsense knowledge is essential for text generation to augment the limited textual information. In dialogue generation, Zhou et al. (2018) enriched the context representations of the post with neighbouring concepts on ConceptNet using graph attention. In story ending generation, Guan et al. (2019) proposed incremental encoding with multi-source attention to incorporate one-hop knowledge graph for concepts in the story context. In topic-to-essay generation, Yang et al. (2019) augmented the generator with a concept memory that updated dynamically with gate mechanism. Recently, some work also attempted to integrate external commonsense knowledge into generative pretrained language models such as GPT-2 (Radford et al., 2019). Guan et al. (2020) conducted posttraining on sythetic data constructed from commonsense knowledge bases by translating triplets into natural language texts using temp"
2020.emnlp-main.54,N18-1165,0,0.0287248,"sed by implicit knowledge transferring. Our contributions can be summarized as follows: 1) We propose GRF, a novel generation model that utilizes external structural commonsense knowledge to facilitate explicit commonsense reasoning in text generation. 2) We propose the dynamic multi-hop reasoning module that aggregates evidence along relational paths for grounded gener726 2.2 Multi-Hop Reasoning on Graph Structure Performing explicit multi-hop reasoning on graph structure has been demonstrated to be an effective approach for query answering over incomplete knowledge graphs (Das et al., 2018; Chen et al., 2018; Lin et al., 2018), multi-hop question answering (Bauer et al., 2018; Cao et al., 2019; Qiu et al., 2019) and dialogue generation (Tuan et al., Decoder hidden state Layer Norm Feed Forward LD x Layer Norm Concept distribution H-hops Vocab distribution Masked Self-Attention Word embedding (x1 x2 ... xN [bos] y1 y2 ... yt-1) Graph representations Reasoning module (a) (b) (c) (d) Figure 2: Model architecture. (a) Context modeling with pre-trained transformer (§3.2.2). (b) The model encodes the multi-relational graph with non-parametric operation φ(·) to combine relations and concepts (§3.2.1). ("
2020.emnlp-main.54,P16-1154,0,0.191063,"v)), (11) where ct is the concept of the selected node at the t-th time step. Intuitively, the reasoning module learns to dynamically distribute along the paths by considering the triple evidence according to the current decoder state. 3.2.4 Generation Distribution with Gate Control The final generation distribution combines the distribution over the concepts (Eq. 11) and the distribution over the standard vocabulary (Eq. 7). We use a soft gate probability gt which denotes whether to copy a concept in the generation to control the weight of the two distributions similar to the copy mechanism (Gu et al., 2016; See et al., 2017).   D . (12) gt = σ Wgate hL t 728 The final output distribution is the linear combination of the two distributions weighted by gt and 1 − gt respectively. P (yt |y<t , x, G) = gt+N · P (ct+N |s<t+N , G) + (1 − gt+N ) · P (st+N |s<t+N ), (13) where N is the length of the input text sequence. 3.3 Training and Inference To train the proposed model, we minimize the negative log-likelihood of generating the ground truth target sequence y gold = (y1 , y2 · · · , yM , [eos]). Lgen = M +1 X gold − log P (yt gold |y<t , x, G). Explanation Generation (EG) is to generate an explanat"
2020.emnlp-main.54,2020.tacl-1.7,1,0.939847,"ch as (volcano, MadeOf, lava) besides the story context. Although pre-trained models have been demonstrated to possess commonsense reasoning ability (Trinh and Le, 2018) by implicitly learning some relational patterns from large-scale corpora, they do not fully utilize the commonsense knowledge bases that provide more explicit knowledge grounding. To address this defect, incorporating external commonsense knowledge to enhance models’ reasoning ability has been widely explored (Lin et al., 2019; Ye et al., 2019; Lv et al., 2019). In language generation, previous work (Bhagavatula et al., 2020; Guan et al., 2020) transfers commonsense knowledge into pre-trained language models by utilizing triple information in commonsense knowledge bases such as ConceptNet (Speer and Havasi, 2012) and ATOMIC (Sap et al., 2019). However, this approach has two drawbacks. 725 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 725–736, c November 16–20, 2020. 2020 Association for Computational Linguistics First, recovering knowledge triples at the posttraining stage (Guan et al., 2020) hardly enables the model to utilize the encoded knowledge in fine-tuning generation tasks whic"
2020.emnlp-main.54,N16-1014,0,0.11829,"Missing"
2020.emnlp-main.54,D19-1282,0,0.198087,"y the model that provide rationale to the generation.1 “lava” in the story ending by providing background knowledge such as (volcano, MadeOf, lava) besides the story context. Although pre-trained models have been demonstrated to possess commonsense reasoning ability (Trinh and Le, 2018) by implicitly learning some relational patterns from large-scale corpora, they do not fully utilize the commonsense knowledge bases that provide more explicit knowledge grounding. To address this defect, incorporating external commonsense knowledge to enhance models’ reasoning ability has been widely explored (Lin et al., 2019; Ye et al., 2019; Lv et al., 2019). In language generation, previous work (Bhagavatula et al., 2020; Guan et al., 2020) transfers commonsense knowledge into pre-trained language models by utilizing triple information in commonsense knowledge bases such as ConceptNet (Speer and Havasi, 2012) and ATOMIC (Sap et al., 2019). However, this approach has two drawbacks. 725 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 725–736, c November 16–20, 2020. 2020 Association for Computational Linguistics First, recovering knowledge triples at the posttraining"
2020.emnlp-main.54,W04-1013,0,0.0182468,"Missing"
2020.emnlp-main.54,D18-1362,0,0.12802,"wledge transferring. Our contributions can be summarized as follows: 1) We propose GRF, a novel generation model that utilizes external structural commonsense knowledge to facilitate explicit commonsense reasoning in text generation. 2) We propose the dynamic multi-hop reasoning module that aggregates evidence along relational paths for grounded gener726 2.2 Multi-Hop Reasoning on Graph Structure Performing explicit multi-hop reasoning on graph structure has been demonstrated to be an effective approach for query answering over incomplete knowledge graphs (Das et al., 2018; Chen et al., 2018; Lin et al., 2018), multi-hop question answering (Bauer et al., 2018; Cao et al., 2019; Qiu et al., 2019) and dialogue generation (Tuan et al., Decoder hidden state Layer Norm Feed Forward LD x Layer Norm Concept distribution H-hops Vocab distribution Masked Self-Attention Word embedding (x1 x2 ... xN [bos] y1 y2 ... yt-1) Graph representations Reasoning module (a) (b) (c) (d) Figure 2: Model architecture. (a) Context modeling with pre-trained transformer (§3.2.2). (b) The model encodes the multi-relational graph with non-parametric operation φ(·) to combine relations and concepts (§3.2.1). (c) The multi-hop re"
2020.emnlp-main.54,D19-1187,0,0.0130561,"Masked Self-Attention Word embedding (x1 x2 ... xN [bos] y1 y2 ... yt-1) Graph representations Reasoning module (a) (b) (c) (d) Figure 2: Model architecture. (a) Context modeling with pre-trained transformer (§3.2.2). (b) The model encodes the multi-relational graph with non-parametric operation φ(·) to combine relations and concepts (§3.2.1). (c) The multi-hop reasoning module aggregates evidence from source concepts Cx along structural paths to all nodes where shade indicates the node score (§3.2.3). (d) The final generation distribution with gate control (§3.2.4). 2019; Moon et al., 2019; Liu et al., 2019). Particularly, reasoning on knowledge graphs to answer relational query typically adopts REINFORCE to learn concrete policies to search for entities or relations. In multi-hop question answering tasks, the reasoning process is augmented with entity graph (Cao et al., 2019; Qiu et al., 2019) or concept paths (Bauer et al., 2018) to enhance semantic connections among document segments. In dialogue generation, Tuan et al. (2019) modeled multiple hops on relationship graphs with a Markov transition matrix. Liu et al. (2019) proposed a twostage architecture that selected information from a knowled"
2020.emnlp-main.54,D17-1159,0,0.0309066,"graph extraction process in §4.2 and describe our proposed model in the next section. 3.2 Static Multi-Relational Graph Encoding Graph Neural Network (GNN) frameworks, such as graph convolution network (GCN) (Kipf and Welling, 2017) and graph attention network (GAT) (Velickovic et al., 2018), have been shown effective at encoding graph-structured data by aggregating node information from local neighbours. To model the relational information in the knowledge graph, R-GCN (Schlichtkrull et al., 2018) generalizes GCN with relationspecific weight matrices but is reported to be over-parameterized (Marcheggiani and Titov, 2017; Schlichtkrull et al., 2018). We follow Vashishth et al. (2020) and use a non-parametric compositional operation φ(·) to combine the node embedding and the relation embedding. Specifically, 727 3.2.1 Generation with Multi-Hop Reasoning Flow given the input graph G = (V, E) and a GCN with LG layer, for each node v ∈ V we update the node embedding at the l + 1-th layer by aggregating information from its local neighbours N (v) which consist of pairs of node u and the connected relation r. X 1 l WN φ(hlu , hlr ), (2) olv = |N (v)| (u,r)∈N (v)   l l l (3) hl+1 = ReLU o + W h v v S v , where h0v"
2020.emnlp-main.54,P02-1040,0,0.106054,"Missing"
2020.emnlp-main.54,P19-1617,0,0.0334703,"a novel generation model that utilizes external structural commonsense knowledge to facilitate explicit commonsense reasoning in text generation. 2) We propose the dynamic multi-hop reasoning module that aggregates evidence along relational paths for grounded gener726 2.2 Multi-Hop Reasoning on Graph Structure Performing explicit multi-hop reasoning on graph structure has been demonstrated to be an effective approach for query answering over incomplete knowledge graphs (Das et al., 2018; Chen et al., 2018; Lin et al., 2018), multi-hop question answering (Bauer et al., 2018; Cao et al., 2019; Qiu et al., 2019) and dialogue generation (Tuan et al., Decoder hidden state Layer Norm Feed Forward LD x Layer Norm Concept distribution H-hops Vocab distribution Masked Self-Attention Word embedding (x1 x2 ... xN [bos] y1 y2 ... yt-1) Graph representations Reasoning module (a) (b) (c) (d) Figure 2: Model architecture. (a) Context modeling with pre-trained transformer (§3.2.2). (b) The model encodes the multi-relational graph with non-parametric operation φ(·) to combine relations and concepts (§3.2.1). (c) The multi-hop reasoning module aggregates evidence from source concepts Cx along structural paths to al"
2020.emnlp-main.54,P19-1081,0,0.0288194,"Vocab distribution Masked Self-Attention Word embedding (x1 x2 ... xN [bos] y1 y2 ... yt-1) Graph representations Reasoning module (a) (b) (c) (d) Figure 2: Model architecture. (a) Context modeling with pre-trained transformer (§3.2.2). (b) The model encodes the multi-relational graph with non-parametric operation φ(·) to combine relations and concepts (§3.2.1). (c) The multi-hop reasoning module aggregates evidence from source concepts Cx along structural paths to all nodes where shade indicates the node score (§3.2.3). (d) The final generation distribution with gate control (§3.2.4). 2019; Moon et al., 2019; Liu et al., 2019). Particularly, reasoning on knowledge graphs to answer relational query typically adopts REINFORCE to learn concrete policies to search for entities or relations. In multi-hop question answering tasks, the reasoning process is augmented with entity graph (Cao et al., 2019; Qiu et al., 2019) or concept paths (Bauer et al., 2018) to enhance semantic connections among document segments. In dialogue generation, Tuan et al. (2019) modeled multiple hops on relationship graphs with a Markov transition matrix. Liu et al. (2019) proposed a twostage architecture that selected informa"
2020.emnlp-main.54,P17-1099,0,0.0148382,"t is the concept of the selected node at the t-th time step. Intuitively, the reasoning module learns to dynamically distribute along the paths by considering the triple evidence according to the current decoder state. 3.2.4 Generation Distribution with Gate Control The final generation distribution combines the distribution over the concepts (Eq. 11) and the distribution over the standard vocabulary (Eq. 7). We use a soft gate probability gt which denotes whether to copy a concept in the generation to control the weight of the two distributions similar to the copy mechanism (Gu et al., 2016; See et al., 2017).   D . (12) gt = σ Wgate hL t 728 The final output distribution is the linear combination of the two distributions weighted by gt and 1 − gt respectively. P (yt |y<t , x, G) = gt+N · P (ct+N |s<t+N , G) + (1 − gt+N ) · P (st+N |s<t+N ), (13) where N is the length of the input text sequence. 3.3 Training and Inference To train the proposed model, we minimize the negative log-likelihood of generating the ground truth target sequence y gold = (y1 , y2 · · · , yM , [eos]). Lgen = M +1 X gold − log P (yt gold |y<t , x, G). Explanation Generation (EG) is to generate an explanation given a counter"
2020.emnlp-main.54,N16-1098,0,0.053806,"resentations for the concepts and the relations (§3.2.1). Then, the multi-hop reasoning module performs dynamic reasoning via aggregating triple evidence along multiple relational paths to generate the salient concept under the context (§3.2.3). Finally, the generation distribution combines the probability of copying concepts from the knowledge graph and that of choosing a word from the standard vocabulary with a gate control (§3.2.4). The overall model architecture is shown in Figure 2. We conduct experiments on three commonsense-aware text generation tasks including story ending generation (Mostafazadeh et al., 2016), abductive natural language generation (Bhagavatula et al., 2020), and explanation generation for sense making (Wang et al., 2019). Results show that our model outperforms strong baselines on these tasks, thereby demonstrating the benefit of multi-hop commonsense reasoning in language generation. ation of some critical concepts. 3) We conduct extensive experiments including automatic and human evaluation on three commonsense-aware text generation tasks and show that our model outperforms various selective baselines. We also visualize reasoning paths inferred by the model to demonstrate the ef"
2020.emnlp-main.54,D19-1194,0,0.0123326,"ng structural paths to all nodes where shade indicates the node score (§3.2.3). (d) The final generation distribution with gate control (§3.2.4). 2019; Moon et al., 2019; Liu et al., 2019). Particularly, reasoning on knowledge graphs to answer relational query typically adopts REINFORCE to learn concrete policies to search for entities or relations. In multi-hop question answering tasks, the reasoning process is augmented with entity graph (Cao et al., 2019; Qiu et al., 2019) or concept paths (Bauer et al., 2018) to enhance semantic connections among document segments. In dialogue generation, Tuan et al. (2019) modeled multiple hops on relationship graphs with a Markov transition matrix. Liu et al. (2019) proposed a twostage architecture that selected information from a knowledge graph for further generating the response. Compared with these generation models that operate on knowledge graphs within a specific domain, our focus is to utilize general commonsense knowledge to supply evidence for text generation. 3 3.1 Methodology Problem Formulation In this paper, we focus on text generation tasks where reasoning over external commonsense knowledge is required. Without loss of generality, the input sou"
2020.emnlp-main.54,P19-1393,0,0.0236239,"riple evidence along multiple relational paths to generate the salient concept under the context (§3.2.3). Finally, the generation distribution combines the probability of copying concepts from the knowledge graph and that of choosing a word from the standard vocabulary with a gate control (§3.2.4). The overall model architecture is shown in Figure 2. We conduct experiments on three commonsense-aware text generation tasks including story ending generation (Mostafazadeh et al., 2016), abductive natural language generation (Bhagavatula et al., 2020), and explanation generation for sense making (Wang et al., 2019). Results show that our model outperforms strong baselines on these tasks, thereby demonstrating the benefit of multi-hop commonsense reasoning in language generation. ation of some critical concepts. 3) We conduct extensive experiments including automatic and human evaluation on three commonsense-aware text generation tasks and show that our model outperforms various selective baselines. We also visualize reasoning paths inferred by the model to demonstrate the effectiveness of the multi-hop reasoning module. 2 2.1 Related Work Commonsense-Aware Neural Text Generation Incorporating commonsens"
2020.emnlp-main.54,P19-1193,0,0.0310046,"onstrate the effectiveness of the multi-hop reasoning module. 2 2.1 Related Work Commonsense-Aware Neural Text Generation Incorporating commonsense knowledge is essential for text generation to augment the limited textual information. In dialogue generation, Zhou et al. (2018) enriched the context representations of the post with neighbouring concepts on ConceptNet using graph attention. In story ending generation, Guan et al. (2019) proposed incremental encoding with multi-source attention to incorporate one-hop knowledge graph for concepts in the story context. In topic-to-essay generation, Yang et al. (2019) augmented the generator with a concept memory that updated dynamically with gate mechanism. Recently, some work also attempted to integrate external commonsense knowledge into generative pretrained language models such as GPT-2 (Radford et al., 2019). Guan et al. (2020) conducted posttraining on sythetic data constructed from commonsense knowledge bases by translating triplets into natural language texts using templates. Bhagavatula et al. (2020) transferred embeddings of COMeT (Bosselut et al., 2019), a GPT-2 model fine-tuned to generate the tail entity of a triple in commonsense knowledge g"
2020.emnlp-main.567,C14-1151,0,0.0157364,"olarity polari from SentiWordNet for each pair (xi , posi ). In SentiWordNet, we can find m different senses for the pair (xi , posi ), each of which contains a sense number, a positive / negative score, (j) (j) (j) (j) and a gloss (SNi , P scorei , N scorei , Gi ), 1 ≤ j ≤ m, where SN indicates the rank of different senses, P score/N score is the positive / negative score assigned by SentiWordNet, and G denotes the definition of each sense. Inspired by the existing work on inferring word-level prior polarity from SentiWordNet (Guerini et al., 2013) and unsupervised word sense disambiguation (Basile et al., 2014), we propose a context-aware attention mechanism which simultaneously considers the sense rank and the context-gloss similarity to determine the attention weight of each sense: (j) αi where = sof tmax( 1 (j) SNi 1 (j) SNi (j) · sim(X, Gi )) approximates the impact of sense frequency because a smaller sense rank indicates more frequent use of this sense in natural lan(j) guage (Guerini et al., 2013), and sim(X, Gi ) denotes the textual similarity between the context and the gloss of each sense, which is commonly used as an important feature in unsupervised word sense disambiguation (Basile et a"
2020.emnlp-main.567,D19-1005,0,0.0217718,"Mo (Peters et al., 2018), GPT (Radford et al., 2018, 2019), and BERT (Devlin et al., 2019) become prevalent. These models use LSTM (Hochreiter and Schmidhuber, 1997) or Transformer (Vaswani et al., 2017) as the encoder to acquire contextual language representation, and explore various pre-training tasks including masked language model and next sentence prediction (Devlin et al., 2019). Thanks to the great success of BERT on various NLP tasks, many variants of BERT have been proposed, which mainly fall into four aspects: 1) Knowledge enhancement: ERNIE-Tsinghua (Zhang et al., 2019) / KnowBERT (Peters et al., 2019) explicitly introduces knowledge graph / knowledge base to BERT, while ERNIE-Baidu (Sun et al., 2019b) designs entity-specific masking strategies during pre-training. 2) Transferability: TransBERT (Li et al., 2019) conducts supervised post-training on the pre-trained BERT with transfer tasks to get a better initialization for target tasks. 3) Hyper-parameters: RoBERTa (Liu et al., 2019) measures the impact of key hyper-parameters to improve the under-trained BERT. 4) Pre-training tasks: SpanBERT (Joshi et al., 2020) masks consecutive spans randomly instead of individual tokens, while XLNet (Ya"
2020.emnlp-main.567,D13-1170,0,0.0522466,"ared with the existing work on pre-trained models for sentiment analysis, our work integrates sentiment-related linguistic knowledge from SentiWordNet (Baccianella et al., 2010) into pre-trained models to construct knowledge-aware language representation, which can benefit a wide range of downstream tasks in sentiment analysis. Linguistic Knowledge for Sentiment Analysis Linguistic knowledge such as part of speech and word-level sentiment polarity is commonly used as external features in sentiment analysis. Part of speech is shown to facilitate the parsing of the syntactic structure of texts (Socher et al., 2013). It 6976 Linguistic Knowledge Acquisition from SentiWordNet Pre-training Task: Label-aware Masked Language Model ࣦ ௪ௗ ሺሻ  ࣦ ைௌ ሺሻ  ࣦ  ሺሻ 濈濦濕濢濧濚濣濦濡濙濦 Context-aware Sentiment Attention Term ሺଵሻ ߙௗ POS good ሺଶሻ ߙௗ ڮ a SN 1 good a 2 … … … ሺሻ ߙௗ Pscore / Nscore 0.75/0 Having amount the normally … ൌ ݔܽݐݏሺ BERT Embedding ܧሾୌሿ Having desirable or positive qualities especially those suitable for a thing specified 0/0 ͳ 濮濖濟濦濰 Gloss (G) POS Embedding Word-level Polarity Embedding Sentence-level Sentiment Embedding expected … ሺሻ  ܵܰௗ ݏ ڄሺݒ  ܽ"
2020.emnlp-main.567,D19-1569,0,0.116784,"ent. These models use LSTM (Hochreiter and Schmidhuber, 1997) or Transformer (Vaswani et al., 2017) as the encoder to acquire contextual language representation, and explore various pre-training tasks including masked language model and next sentence prediction (Devlin et al., 2019). Thanks to the great success of BERT on various NLP tasks, many variants of BERT have been proposed, which mainly fall into four aspects: 1) Knowledge enhancement: ERNIE-Tsinghua (Zhang et al., 2019) / KnowBERT (Peters et al., 2019) explicitly introduces knowledge graph / knowledge base to BERT, while ERNIE-Baidu (Sun et al., 2019b) designs entity-specific masking strategies during pre-training. 2) Transferability: TransBERT (Li et al., 2019) conducts supervised post-training on the pre-trained BERT with transfer tasks to get a better initialization for target tasks. 3) Hyper-parameters: RoBERTa (Liu et al., 2019) measures the impact of key hyper-parameters to improve the under-trained BERT. 4) Pre-training tasks: SpanBERT (Joshi et al., 2020) masks consecutive spans randomly instead of individual tokens, while XLNet (Yang et al., 2019) designs a training objective combining both reconstruction and autoregressive langu"
2020.emnlp-main.567,S14-2004,0,0.0365378,"s that for sentiment analysis tasks, linguistic knowledge can be used to enhance the state-of-the-art pre-trained model via the well-designed pre-training task. 4.5 Table 2: Statistics of sentence-level sentiment classification (SSC) datasets. We first evaluated our model on sentenceAspect-level Sentiment Analysis Aspect-level sentiment analysis includes aspect term extraction, aspect term sentiment classification, aspect category detection, and aspect category sentiment classification. For aspect term based tasks, we chose SemEval2014 Task 4 for laptop (Lap14) and restaurant (Res14) domains (Pontiki et al., 2014) as the benchmarks, while for aspect category based tasks, we used SemEval2014 Task 6980 Dataset Lap14 Res14 Res16 # sentences # terms # categories # sentiment Amount of ATE Amount of ATSC Amount of ACD Amount of ACSC (Train/Test) (Train/Test) (Train/Test) classes (Train/Valid/Test) (Train/Valid/Test) (Train/Valid/Test) (Train/Valid/Test) 3,045 / 800 2,358 / 654 3 1,338 / 150 / 422 2,163 / 150 / 638 3,041 / 800 3,693 / 1,134 3,711 / 1,025 3 1,871 / 150 / 606 3,452 / 150 / 1,120 2,891 / 150 / 800 3,366 / 150 / 973 2,000 / 676 2,507 / 859 3 1,850 / 150 / 676 2,150 / 150 / 751 Table 4: Statistics"
2020.emnlp-main.567,P17-1154,1,0.934047,"19a). Despite the great success of pre-trained models, existing pre-training tasks like masked language model and next sentence prediction (Devlin et al., ∗ Equal contribution Corresponding author 1 The data, codes, and model parameters are available at https://github.com/thu-coai/SentiLARE. † 2019) neglect to consider the linguistic knowledge. Such knowledge is important for some NLP tasks, particularly for sentiment analysis. For instance, existing work has shown that linguistic knowledge including part-of-speech tag (Qian et al., 2015; Huang et al., 2017) and word-level sentiment polarity (Qian et al., 2017) is closely related to the sentiment of longer texts. We argue that pre-trained models enriched with the linguistic knowledge of words will facilitate the understanding of the sentiment of the whole texts, thereby resulting in better performance on sentiment analysis. There are two major challenges to construct knowledge-aware pre-trained language representation models which can promote the downstream tasks in sentiment analysis: 1) Knowledge acquisition across different contexts. Most of the existing work has adopted static sentiment lexicons as linguistic resource (Qian et al., 2017; Chen et"
2020.emnlp-main.567,P15-1132,1,0.930297,"state-of-the-art performance on various downstream tasks (Wang et al., 2019a). Despite the great success of pre-trained models, existing pre-training tasks like masked language model and next sentence prediction (Devlin et al., ∗ Equal contribution Corresponding author 1 The data, codes, and model parameters are available at https://github.com/thu-coai/SentiLARE. † 2019) neglect to consider the linguistic knowledge. Such knowledge is important for some NLP tasks, particularly for sentiment analysis. For instance, existing work has shown that linguistic knowledge including part-of-speech tag (Qian et al., 2015; Huang et al., 2017) and word-level sentiment polarity (Qian et al., 2017) is closely related to the sentiment of longer texts. We argue that pre-trained models enriched with the linguistic knowledge of words will facilitate the understanding of the sentiment of the whole texts, thereby resulting in better performance on sentiment analysis. There are two major challenges to construct knowledge-aware pre-trained language representation models which can promote the downstream tasks in sentiment analysis: 1) Knowledge acquisition across different contexts. Most of the existing work has adopted s"
2020.emnlp-main.567,P18-1215,0,0.0131144,"sks. Task-specific Pre-trained Models: We used BERT-PT (Xu et al., 2019), TransBERT (Li et al., 2019), and SentiBERT (Yin et al., 2020) as taskspecific pre-trained baselines. Since TransBERT is not originally designed to deal with sentiment analysis tasks, we chose review-level sentiment classification on Yelp Dataset Challenge 2019 as the transfer task, and the downstream tasks in sentiment analysis as the target tasks. Task-specific Models without Pre-training: We also chose some task-specific baselines without pre-training for corresponding tasks, including SCSNN (Chen et al., 2019), DRNN (Wang, 2018), ML (Sachan et al., 2019) for sentence-level sentiment classification, DE-CNN (Xu et al., 2018) for aspect term extraction, CDT (Sun et al., 2019a) for aspect term sentiment classification, TAN (Movahedi et al., 2019) for aspect category detection, and ASCapsules (Wang et al., 2019b) for aspect category sentiment classification. We evaluated all the pre-trained baselines based on the codes and the model parameters provided by the original papers. For a fair comparison, all the pre-trained models were set to the base version, which possess a similar number of parameters (about 110M). The exper"
2020.emnlp-main.567,H05-1044,0,0.0524276,"tained by weighting the matched senses with context-aware sentiment attention. During pre-training, the model is trained based on label-aware masked language model including early fusion and late supervision. Red dotted boxes denote that the linguistic knowledge is used in input embedding or pre-training loss function. can also be incorporated into all layers of RNN as tag embeddings (Qian et al., 2015). Huang et al. (2017) shows that part of speech can help to learn sentiment-favorable representations. Word-level sentiment polarity is mostly derived from sentiment lexicons (Hu and Liu, 2004; Wilson et al., 2005). Guerini et al. (2013) obtains the prior sentiment polarity by weighting the sentiment scores over all the senses of a word in SentiWordNet (Esuli and Sebastiani, 2006; Baccianella et al., 2010). Teng et al. (2016) proposes a context-aware lexicon-based weighted sum model, which weights the prior sentiment scores of sentiment words to derive the sentiment label of the whole sentence. Qian et al. (2017) models the linguistic role of sentiment, negation and intensity words via linguistic regularizers in the training objective of LSTM. 3 3.1 Model Task Definition and Model Overview Our task is d"
2020.emnlp-main.567,P18-2094,0,0.0192082,"al., 2019), and SentiBERT (Yin et al., 2020) as taskspecific pre-trained baselines. Since TransBERT is not originally designed to deal with sentiment analysis tasks, we chose review-level sentiment classification on Yelp Dataset Challenge 2019 as the transfer task, and the downstream tasks in sentiment analysis as the target tasks. Task-specific Models without Pre-training: We also chose some task-specific baselines without pre-training for corresponding tasks, including SCSNN (Chen et al., 2019), DRNN (Wang, 2018), ML (Sachan et al., 2019) for sentence-level sentiment classification, DE-CNN (Xu et al., 2018) for aspect term extraction, CDT (Sun et al., 2019a) for aspect term sentiment classification, TAN (Movahedi et al., 2019) for aspect category detection, and ASCapsules (Wang et al., 2019b) for aspect category sentiment classification. We evaluated all the pre-trained baselines based on the codes and the model parameters provided by the original papers. For a fair comparison, all the pre-trained models were set to the base version, which possess a similar number of parameters (about 110M). The experimental results were presented with mean values over 5 runs. As for the task-specific baselines"
2020.emnlp-main.736,W19-2310,0,0.0473293,"uality based on the samplelevel pair-wise comparison. However, it is unlikely to evaluate a single sample without access to its references. Hybrid metrics combine referenced and unreferenced metrics. For open-domain dialog system evaluation, Lowe et al. (2017) proposed a learnable metric Adem to learn from the human-annotated score of a response given its post and ground truth. However, such a metric shows very poor generalization and is not robust to easy attacks such as simple word substitution or random word shuffle (Sai et al., 2019). Furthermore, RUBER and its variants (Tao et al., 2018; Ghazarian et al., 2019) evaluate a response by directly averaging a nonlearnable referenced embedding similarity score and a learnable unreferenced post-response relatedness score that is learned by applying negative sampling without human annotations. However, merely measuring input-output relatedness is not sufficient for evaluating long text generation, as the intrinsic coherence and consistency within the generated text is a critical factor. Additionally, some metrics which learn from human preference achieve substantial results in conditional language generation, e.g., RUSE (Shimanaka et al., 2018) and BLEURT ("
2020.emnlp-main.736,2020.tacl-1.7,1,0.765946,"rScore (M=0.35 in Sample 3). In contrast, U NION is more reliable for evaluating story generation. tive evaluation metrics, particularly for open-ended text generation tasks such as story generation. Introduction Significant advances have been witnessed with neural encoder-decoder paradigm (Sutskever et al., 2014), transformer-based architecture (Vaswani et al., 2017) and large-scale pretraining models (Devlin et al., 2019; Radford et al., 2019) in a wide array of natural language generation (NLG) tasks including machine translation (Bahdanau et al., 2015), story generation (Fan et al., 2018; Guan et al., 2020), and many more. However, the research is increasingly hindered by the lack of effec∗ Corresponding author Since human evaluation is time-consuming, expensive, and difficult to reproduce, the community commonly uses automatic metrics for evaluation. Previous studies in conditional language generation tasks (e.g., machine translation) have developed several successful referenced metrics, which roughly quantify the lexical overlap (e.g., BLEU (Papineni et al., 2002)) or semantic entailment (e.g., MoverScore (Zhao et al., 2019)) between a generated sample and the reference. However, such referenc"
2020.emnlp-main.736,N19-1169,0,0.0154288,"2016) and story generation, where the input contains only limited information for generation, and there are many plausible outputs for the same input, which can vary substantially in literal or semantics. Unreferenced metrics measure the quality of a sample without any reference. The most classic unreferenced metric is perplexity, which measures how likely a sample is generated by a given language model trained on human-written texts. However, recent work has shown that natural language is rarely the most probable text (Holtzman et al., 2020), and perplexity is inadequate to measure quality (Hashimoto et al., 2019). Therefore, perplexity may not indicate the actual text quality well. Discriminator-based metric (Kannan and Vinyals, 2017) measures how easily a discriminator distinguishes the generated samples from human-written texts. However, training such a discriminator can be easily over-fitted to a specific dataset, thereby leading to poor generalization and low correlation with human judgments (Garbacea et al., 2019). In addition to the above point-wise metrics which score an individual sample, Semeniuta et al. (2019) proposed the Fréchet InferSent Distance (FID) to evaluate the model-level quality"
2020.emnlp-main.736,W04-1013,0,0.0927481,"ge generation tasks. We roughly divide existing metrics into referenced, unreferenced, and hybrid metrics, according to whether they rely on human-written references when calculating the metric score. Referenced metrics usually measure how similar a generated text is to the reference text. Therefore, they are developed mainly for conditional language generation tasks such as machine translation and text summarization, where plausible outputs are largely limited within the semantics of input. Commonly used referenced metrics include wordoverlap based (e.g., BLEU (Papineni et al., 2002), ROUGE (Lin, 2004)) and embedding based metrics (e.g., BertScore (Zhang* et al., 2020), MoverScore (Zhao et al., 2019)). However, referenced metrics are reported to correlate poorly with human judgments in open-ended generation tasks including open-domain dialog generation (Liu et al., 2016) and story generation, where the input contains only limited information for generation, and there are many plausible outputs for the same input, which can vary substantially in literal or semantics. Unreferenced metrics measure the quality of a sample without any reference. The most classic unreferenced metric is perplexity"
2020.emnlp-main.736,N18-1204,0,0.0652069,"Missing"
2020.emnlp-main.736,N19-1423,0,0.32832,"Zhao et al., 2019), and U for U NION. A story can be reasonable even if it is dissimilar to the reference with a low BLEU score (B=0.14 in Sample 2), or unreasonable even if it has a large MoverScore (M=0.35 in Sample 3). In contrast, U NION is more reliable for evaluating story generation. tive evaluation metrics, particularly for open-ended text generation tasks such as story generation. Introduction Significant advances have been witnessed with neural encoder-decoder paradigm (Sutskever et al., 2014), transformer-based architecture (Vaswani et al., 2017) and large-scale pretraining models (Devlin et al., 2019; Radford et al., 2019) in a wide array of natural language generation (NLG) tasks including machine translation (Bahdanau et al., 2015), story generation (Fan et al., 2018; Guan et al., 2020), and many more. However, the research is increasingly hindered by the lack of effec∗ Corresponding author Since human evaluation is time-consuming, expensive, and difficult to reproduce, the community commonly uses automatic metrics for evaluation. Previous studies in conditional language generation tasks (e.g., machine translation) have developed several successful referenced metrics, which roughly quan"
2020.emnlp-main.736,P18-1082,0,0.492047,"t has a large MoverScore (M=0.35 in Sample 3). In contrast, U NION is more reliable for evaluating story generation. tive evaluation metrics, particularly for open-ended text generation tasks such as story generation. Introduction Significant advances have been witnessed with neural encoder-decoder paradigm (Sutskever et al., 2014), transformer-based architecture (Vaswani et al., 2017) and large-scale pretraining models (Devlin et al., 2019; Radford et al., 2019) in a wide array of natural language generation (NLG) tasks including machine translation (Bahdanau et al., 2015), story generation (Fan et al., 2018; Guan et al., 2020), and many more. However, the research is increasingly hindered by the lack of effec∗ Corresponding author Since human evaluation is time-consuming, expensive, and difficult to reproduce, the community commonly uses automatic metrics for evaluation. Previous studies in conditional language generation tasks (e.g., machine translation) have developed several successful referenced metrics, which roughly quantify the lexical overlap (e.g., BLEU (Papineni et al., 2002)) or semantic entailment (e.g., MoverScore (Zhao et al., 2019)) between a generated sample and the reference. Ho"
2020.emnlp-main.736,D19-1409,0,0.0614685,"can be reasonable if it is coherent to the given input, and self-consistent within its own context but not necessarily being similar to the reference in literal or semantics, as shown in Sample 2 and 3. To address the one-to-many issue, unreferenced metrics are proposed to measure the quality of a generated sample without any reference. Kannan and Vinyals (2017) presented a learnable, unreferenced metric which measures the text quality by learning to distinguish human-written texts from generated samples. However, the discriminatorbased metric can easily lead to over-fitting to specific data (Garbacea et al., 2019) or model bias since the quality of generated texts varies substantially across different NLG models. As a matter of fact, the generalization or robustness issue is critical for any learnable metrics. Therefore, we propose U NION, a learnable UNreferenced metrIc for evaluating Open-eNded story generation. U NION learns to distinguish human-written stories from negative samples autoconstructed by generating perturbations of humanwritten stories. It is trained without dependence on specific NLG models or any human annotation, making it more generalizable to distribution drift (Sellam et al., 202"
2020.emnlp-main.736,D16-1230,0,0.186304,"itional language generation tasks (e.g., machine translation) have developed several successful referenced metrics, which roughly quantify the lexical overlap (e.g., BLEU (Papineni et al., 2002)) or semantic entailment (e.g., MoverScore (Zhao et al., 2019)) between a generated sample and the reference. However, such referenced metrics correlate poorly with 9157 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 9157–9166, c November 16–20, 2020. 2020 Association for Computational Linguistics human judgments when evaluating open-ended text generation (Liu et al., 2016) due to the one-tomany nature (Zhao et al., 2017), as illustrated in Table 1. Specifically, a generated sample can be reasonable if it is coherent to the given input, and self-consistent within its own context but not necessarily being similar to the reference in literal or semantics, as shown in Sample 2 and 3. To address the one-to-many issue, unreferenced metrics are proposed to measure the quality of a generated sample without any reference. Kannan and Vinyals (2017) presented a learnable, unreferenced metric which measures the text quality by learning to distinguish human-written texts fr"
2020.emnlp-main.736,P17-1103,0,0.132282,"a matter of fact, the generalization or robustness issue is critical for any learnable metrics. Therefore, we propose U NION, a learnable UNreferenced metrIc for evaluating Open-eNded story generation. U NION learns to distinguish human-written stories from negative samples autoconstructed by generating perturbations of humanwritten stories. It is trained without dependence on specific NLG models or any human annotation, making it more generalizable to distribution drift (Sellam et al., 2020) than the discriminator-based metric and those metrics which learn from human preference (e.g., Adem (Lowe et al., 2017)). To capture commonly observed issues in generated stories, such as repeated plots, conflicting logic, and inter-sentence incoherence, we adopt four negative sampling techniques to construct negative samples, including repetition, substitution, reordering, and negation alteration. In addition, we design an auxiliary reconstruction objective for U NION, which recovers the perturbation from a negative sample. This objective is shown to further improve the performance of U NION. Our contributions are summarized as follows: I. We propose a learnable unreferenced metric U NION for evaluating open-"
2020.emnlp-main.736,N16-1098,0,0.637443,"ed it. Eventually he gave it to the bartender. They put it into their lost and found box. Sample 2 (Reasonable, B=0.14, M=0.27, U=1.00) He had a drinking problem. He kept having more beers. After a while he passed out. When he waked up, he was surprised to find that he lost over a hundred dollars. Sample 3 (Unreasonable, B=0.20, M=0.35, U=0.00) He was going to get drunk and get drunk. The bartender told him it was already time to leave. Jack started drinking. Jack wound up returning but cops came on the way home. Table 1: Generated story samples given the same leading context from ROCStories (Mostafazadeh et al., 2016). B stands for BLEU (Papineni et al., 2002), M for MoverScore (Zhao et al., 2019), and U for U NION. A story can be reasonable even if it is dissimilar to the reference with a low BLEU score (B=0.14 in Sample 2), or unreasonable even if it has a large MoverScore (M=0.35 in Sample 3). In contrast, U NION is more reliable for evaluating story generation. tive evaluation metrics, particularly for open-ended text generation tasks such as story generation. Introduction Significant advances have been witnessed with neural encoder-decoder paradigm (Sutskever et al., 2014), transformer-based architect"
2020.emnlp-main.736,P02-1040,0,0.124544,"They put it into their lost and found box. Sample 2 (Reasonable, B=0.14, M=0.27, U=1.00) He had a drinking problem. He kept having more beers. After a while he passed out. When he waked up, he was surprised to find that he lost over a hundred dollars. Sample 3 (Unreasonable, B=0.20, M=0.35, U=0.00) He was going to get drunk and get drunk. The bartender told him it was already time to leave. Jack started drinking. Jack wound up returning but cops came on the way home. Table 1: Generated story samples given the same leading context from ROCStories (Mostafazadeh et al., 2016). B stands for BLEU (Papineni et al., 2002), M for MoverScore (Zhao et al., 2019), and U for U NION. A story can be reasonable even if it is dissimilar to the reference with a low BLEU score (B=0.14 in Sample 2), or unreasonable even if it has a large MoverScore (M=0.35 in Sample 3). In contrast, U NION is more reliable for evaluating story generation. tive evaluation metrics, particularly for open-ended text generation tasks such as story generation. Introduction Significant advances have been witnessed with neural encoder-decoder paradigm (Sutskever et al., 2014), transformer-based architecture (Vaswani et al., 2017) and large-scale"
2020.emnlp-main.736,2020.acl-main.704,0,0.304525,"acea et al., 2019) or model bias since the quality of generated texts varies substantially across different NLG models. As a matter of fact, the generalization or robustness issue is critical for any learnable metrics. Therefore, we propose U NION, a learnable UNreferenced metrIc for evaluating Open-eNded story generation. U NION learns to distinguish human-written stories from negative samples autoconstructed by generating perturbations of humanwritten stories. It is trained without dependence on specific NLG models or any human annotation, making it more generalizable to distribution drift (Sellam et al., 2020) than the discriminator-based metric and those metrics which learn from human preference (e.g., Adem (Lowe et al., 2017)). To capture commonly observed issues in generated stories, such as repeated plots, conflicting logic, and inter-sentence incoherence, we adopt four negative sampling techniques to construct negative samples, including repetition, substitution, reordering, and negation alteration. In addition, we design an auxiliary reconstruction objective for U NION, which recovers the perturbation from a negative sample. This objective is shown to further improve the performance of U NION"
2020.emnlp-main.736,D19-1053,0,0.330976,"Sample 2 (Reasonable, B=0.14, M=0.27, U=1.00) He had a drinking problem. He kept having more beers. After a while he passed out. When he waked up, he was surprised to find that he lost over a hundred dollars. Sample 3 (Unreasonable, B=0.20, M=0.35, U=0.00) He was going to get drunk and get drunk. The bartender told him it was already time to leave. Jack started drinking. Jack wound up returning but cops came on the way home. Table 1: Generated story samples given the same leading context from ROCStories (Mostafazadeh et al., 2016). B stands for BLEU (Papineni et al., 2002), M for MoverScore (Zhao et al., 2019), and U for U NION. A story can be reasonable even if it is dissimilar to the reference with a low BLEU score (B=0.14 in Sample 2), or unreasonable even if it has a large MoverScore (M=0.35 in Sample 3). In contrast, U NION is more reliable for evaluating story generation. tive evaluation metrics, particularly for open-ended text generation tasks such as story generation. Introduction Significant advances have been witnessed with neural encoder-decoder paradigm (Sutskever et al., 2014), transformer-based architecture (Vaswani et al., 2017) and large-scale pretraining models (Devlin et al., 201"
2020.emnlp-main.736,W18-6456,0,0.0159566,"t al., 2018; Ghazarian et al., 2019) evaluate a response by directly averaging a nonlearnable referenced embedding similarity score and a learnable unreferenced post-response relatedness score that is learned by applying negative sampling without human annotations. However, merely measuring input-output relatedness is not sufficient for evaluating long text generation, as the intrinsic coherence and consistency within the generated text is a critical factor. Additionally, some metrics which learn from human preference achieve substantial results in conditional language generation, e.g., RUSE (Shimanaka et al., 2018) and BLEURT (Sellam et al., 2020). RUSE trained a regression model to score a reference-candidate pair using their sentence embeddings. And BLEURT used multiple automatic metrics (e.g., BLEU) as supervision signals for pretraining on synthetic data, and was fine-tuned on human judgments. However, BLEURT heavily relies on the quality of automatic metrics, but there are yet no such reliable metrics for open-ended text generation. 3 Methodology U NION is expected to measure the overall quality of a generated story. In this section, we begin with common issues that can be observed in the output of"
2020.emnlp-main.736,speer-havasi-2012-representing,0,0.185743,"Missing"
2020.emnlp-main.736,P17-1061,0,0.0498534,"Missing"
2020.findings-emnlp.11,P04-3031,0,0.210715,"rved that DiffKSFus performs a bit better on WoW while DiffKSDis on Holl-E. We conjecture that it is because in Holl-E, the golden selected knowledge among different turns usually has high contextual dependency (for example, they may be continuous sentences in the document), which makes it feasible to predict the next selected knowledge simply conditioned on the differential information. 4.5 tively, and adopted the same copy mechanism in SLKS as in our models. 4.3 Implementation Details All the models were implemented with PyTorch (Paszke et al., 2017). The sentences were tokenized with NLTK (Bird and Loper, 2004). We set the vocabulary size to 20K for WoW and 16K for HollE and used the 300-dimensional word embeddings initialized by GloVe (Pennington et al., 2014) or from a standard normal distribution N (0, 1). We applied a dropout rate of 0.5 on word embeddings. The hidden sizes were set to 200 for the encoders (totally 400 for two directions) and to 400 for the decoder. We adopted the ADAM (Kingma and Ba, 2015) optimizer with the initial learning rate set to 0.0005. The batch size was set to 8 dialogues. All the models share the same hyperparameter setting Automatic Evaluation Human Observational Ev"
2020.findings-emnlp.11,D14-1179,0,0.0106621,"Missing"
2020.findings-emnlp.11,N19-1423,0,0.00952322,"the context and the posterior one on both the context and the golden response, and their KL divergence is minimized during training. The knowledge selection of PostKS is supervised by a BOW loss. We also evaluated two variants, where one uses LKS instead of the BOW loss to supervise knowledge selection (PostKS+), and the other is further equipped with copy mechanism (PostKS++). SLKS (Kim et al., 2020) improves PostKS by using two separate GRUs to update the states of dialog history and previously selected knowledge sentences respectively. For fair comparison, we replaced the pretrained BERT (Devlin et al., 2019) encoder and the Transformer (Vaswani et al., 2017) decoder in SLKS with BiGRU and GRU respec119 Models ACC BLEU-2/4 and were trained for 20 epochs on one NVIDIA Titan Xp GPU. The checkpoints of our reported results were selected according to BLEU-4 on the Dev sets. ROUGE-2 WoW Seen MemNet +LKS PostKS +LKS +Copy SLKS 13.2** 18.4** 13.8** 22.5** 21.9** 23.4** 6.6** 7.2** 6.9** 7.5** 9.9** 11.3 1.8** 1.9** 1.8** 2.3** 4.5** 5.5 3.2** 3.3** 3.2** 3.7** 5.6** 6.5 DiffKSFus DiffKSDis 25.5 24.7 11.6 11.3 5.7 5.7 6.8 6.8 4.4 WoW Uneen MemNet +LKS PostKS +LKS +Copy SLKS 12.8** 15.9** 13.6** 15.8** 14."
2020.findings-emnlp.11,W04-1013,0,0.0139932,"5** 4.5** 4.3** 3.9** 8.2** 22.4** 24.5** 8.9** 9.0** 8.6** 13.1** 23.1** 24.9* DiffKSFus DiffKSDis 33.0 33.5 29.5 29.9 25.5 25.9 25.9 26.4 Table 1: Automatic evaluation results. The best results are in bold. Significance tests were conducted between the best results and other competitors, with sign test for ACC, bootstrap resampling (Koehn, 2004) for BLEU, and Student’s t-test for ROUGE. */** indicate p-value &lt; 0.05/0.005 respectively. We used several automatic metrics: ACC, the accuracy of knowledge selection on the whole test set, corpus-level BLEU-2/4 (Papineni et al., 2002), and ROUGE-2 (Lin, 2004). As shown in Table 13 , our method outperforms significantly all the baselines in all the metrics on three test sets (except BLEU and ROUGE on WoW Seen compared with SLKS), which indicates its superiority in selecting proper knowledge and generating informative responses. Compared to the baseline models, our models also demonstrate a stronger ability of generalization from in-domain (WoW Seen) to out-of-domain data (WoW Unseen). It is worth noting that on WoW Unseen, our DiffKSFus obtains a higher accuracy (19.7) of knowledge selection even than the BERT-enhanced SLKS in their original paper"
2020.findings-emnlp.11,P16-1154,0,0.0437195,"l Selector simply looks for st = GRUD (st−1 , [e (yt−1 ) ; hk ]) , s0 = WD [hc ; hk ] + bD , (13) (14) where WD and bD are trainable parameters, and e (yt−1 ) denotes the embedding of the word yt−1 generated in the last time step. Then, the decoder 118 2 The model is trained with teacher forcing, where the golden selected knowledge hτk,iτ ∗ is used during training. outputs the generation probability over the vocabulary (without normalization): φG (yt = w) = wT (WG st + bG ) , (15) where WG and bG are trainable parameters, and w is the one-hot vector of the word w. Meanwhile, a copy mechanism (Gu et al., 2016) is adopted to output additional copy probability of the words in the selected knowledge sentence kbi (without normalization):   X φC (yt = w) = (st )T H hk,bi,j , (16) j:kbi,j =w where H is a fully connected layer activated with tanh. The final probability distribution is computed as follows: P (yt = w) = 1  φG (yt =w) φC (yt =w)  e +e , (17) Z where Z is the normalization term. Then we select the word from vocabulary with the highest probability, saying: yt = arg maxw P(yt = w). 3.5 WoW (Dinan et al., 2019) contains multi-turn knowledge-grounded conversations, collected by wizard-apprent"
2020.findings-emnlp.11,W04-3250,0,0.269559,"6.6** 7.9** 8.7** 1.2** 1.3** 1.2** 1.5** 3.2** 3.7** 2.3** 2.3** 2.1** 2.6** 3.9** 4.6** DiffKSFus DiffKSDis 19.7 18.3* 10.0 9.6 4.7 4.5 5.6 5.3 Holl-E MemNet +LKS PostKS +LKS +Copy SLKS 5.1** 25.1** 6.1** 29.5** 28.0** 28.6** 8.0** 7.7** 6.9** 15.9** 26.5** 28.5** 4.5** 4.3** 3.9** 8.2** 22.4** 24.5** 8.9** 9.0** 8.6** 13.1** 23.1** 24.9* DiffKSFus DiffKSDis 33.0 33.5 29.5 29.9 25.5 25.9 25.9 26.4 Table 1: Automatic evaluation results. The best results are in bold. Significance tests were conducted between the best results and other competitors, with sign test for ACC, bootstrap resampling (Koehn, 2004) for BLEU, and Student’s t-test for ROUGE. */** indicate p-value &lt; 0.05/0.005 respectively. We used several automatic metrics: ACC, the accuracy of knowledge selection on the whole test set, corpus-level BLEU-2/4 (Papineni et al., 2002), and ROUGE-2 (Lin, 2004). As shown in Table 13 , our method outperforms significantly all the baselines in all the metrics on three test sets (except BLEU and ROUGE on WoW Seen compared with SLKS), which indicates its superiority in selecting proper knowledge and generating informative responses. Compared to the baseline models, our models also demonstrate a st"
2020.findings-emnlp.11,P19-1002,0,0.0526079,"that our method significantly outperforms strong baselines in terms of knowledge selection and can generate more informative responses. 2 2.1 existing studies have been mainly devoted to addressing two research problems: (1) knowledge selection: selecting appropriate knowledge given the dialog context and previously selected knowledge (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020; Kim et al., 2020); and (2) knowledge-aware generation: injecting the required knowledge to generate meaningful and informative responses (Ghazvininejad et al., 2018; Zhou et al., 2018a; Li et al., 2019; Qin et al., 2019; Yavuz et al., 2019; Zhao et al., 2020). Since selecting the appropriate knowledge is a precursor to the success of knowledge grounded dialog systems, we focus on the knowledge selection problem in this paper. 2.2 The non-sequential selection models capture the relationship between the current context and background knowledge (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020). For instance, PostKS (Lian et al., 2019) estimates a posterior distribution over candidate knowledge sentences, which is based on both the context and the golden response, and"
2020.findings-emnlp.11,P18-1138,0,0.0858333,"long to non-sequential selection models. Different from our work and Lian et al. (2019); Kim et al. (2020) that select knowledge from candidate knowledge sentences, their methods are devised for selecting important text spans or fragments from the background knowledge document that will be used in generation. Therefore these works have a different task setting from ours. 2.3 Related Work Knowledge-grounded Dialog Generation Recently, a variety of neural models have been proposed to facilitate knowledge-grounded conversation generation (Zhu et al., 2017; Young et al., 2018; Zhou et al., 2018a; Liu et al., 2018). The research topic is also greatly advanced by many corpora (Zhou et al., 2018b; Moghe et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Moon et al., 2019; Tuan et al., 2019; Wu et al., 2019; Zhou et al., 2020). As surveyed in Huang et al. (2020), Non-sequential Knowledge Selection Sequential Knowledge Selection The sequential selection models additionally make use of previously selected knowledge to facilitate knowledge selection (Kim et al., 2020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states"
2020.findings-emnlp.11,D17-2014,0,0.046796,"Missing"
2020.findings-emnlp.11,D18-1255,0,0.467457,"(2020) that select knowledge from candidate knowledge sentences, their methods are devised for selecting important text spans or fragments from the background knowledge document that will be used in generation. Therefore these works have a different task setting from ours. 2.3 Related Work Knowledge-grounded Dialog Generation Recently, a variety of neural models have been proposed to facilitate knowledge-grounded conversation generation (Zhu et al., 2017; Young et al., 2018; Zhou et al., 2018a; Liu et al., 2018). The research topic is also greatly advanced by many corpora (Zhou et al., 2018b; Moghe et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Moon et al., 2019; Tuan et al., 2019; Wu et al., 2019; Zhou et al., 2020). As surveyed in Huang et al. (2020), Non-sequential Knowledge Selection Sequential Knowledge Selection The sequential selection models additionally make use of previously selected knowledge to facilitate knowledge selection (Kim et al., 2020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states of dialog history and previously selected knowledge sentences. Our method is parallel to SLKS because"
2020.findings-emnlp.11,P19-1081,0,0.0191341,"r methods are devised for selecting important text spans or fragments from the background knowledge document that will be used in generation. Therefore these works have a different task setting from ours. 2.3 Related Work Knowledge-grounded Dialog Generation Recently, a variety of neural models have been proposed to facilitate knowledge-grounded conversation generation (Zhu et al., 2017; Young et al., 2018; Zhou et al., 2018a; Liu et al., 2018). The research topic is also greatly advanced by many corpora (Zhou et al., 2018b; Moghe et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Moon et al., 2019; Tuan et al., 2019; Wu et al., 2019; Zhou et al., 2020). As surveyed in Huang et al. (2020), Non-sequential Knowledge Selection Sequential Knowledge Selection The sequential selection models additionally make use of previously selected knowledge to facilitate knowledge selection (Kim et al., 2020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states of dialog history and previously selected knowledge sentences. Our method is parallel to SLKS because we also utilize the previously selected knowledge. However, we expl"
2020.findings-emnlp.11,P02-1040,0,0.106956,"* 8.0** 7.7** 6.9** 15.9** 26.5** 28.5** 4.5** 4.3** 3.9** 8.2** 22.4** 24.5** 8.9** 9.0** 8.6** 13.1** 23.1** 24.9* DiffKSFus DiffKSDis 33.0 33.5 29.5 29.9 25.5 25.9 25.9 26.4 Table 1: Automatic evaluation results. The best results are in bold. Significance tests were conducted between the best results and other competitors, with sign test for ACC, bootstrap resampling (Koehn, 2004) for BLEU, and Student’s t-test for ROUGE. */** indicate p-value &lt; 0.05/0.005 respectively. We used several automatic metrics: ACC, the accuracy of knowledge selection on the whole test set, corpus-level BLEU-2/4 (Papineni et al., 2002), and ROUGE-2 (Lin, 2004). As shown in Table 13 , our method outperforms significantly all the baselines in all the metrics on three test sets (except BLEU and ROUGE on WoW Seen compared with SLKS), which indicates its superiority in selecting proper knowledge and generating informative responses. Compared to the baseline models, our models also demonstrate a stronger ability of generalization from in-domain (WoW Seen) to out-of-domain data (WoW Unseen). It is worth noting that on WoW Unseen, our DiffKSFus obtains a higher accuracy (19.7) of knowledge selection even than the BERT-enhanced SLKS"
2020.findings-emnlp.11,D14-1162,0,0.0833471,"among different turns usually has high contextual dependency (for example, they may be continuous sentences in the document), which makes it feasible to predict the next selected knowledge simply conditioned on the differential information. 4.5 tively, and adopted the same copy mechanism in SLKS as in our models. 4.3 Implementation Details All the models were implemented with PyTorch (Paszke et al., 2017). The sentences were tokenized with NLTK (Bird and Loper, 2004). We set the vocabulary size to 20K for WoW and 16K for HollE and used the 300-dimensional word embeddings initialized by GloVe (Pennington et al., 2014) or from a standard normal distribution N (0, 1). We applied a dropout rate of 0.5 on word embeddings. The hidden sizes were set to 200 for the encoders (totally 400 for two directions) and to 400 for the decoder. We adopted the ADAM (Kingma and Ba, 2015) optimizer with the initial learning rate set to 0.0005. The batch size was set to 8 dialogues. All the models share the same hyperparameter setting Automatic Evaluation Human Observational Evaluation We conducted human observational evaluation with pair-wise comparison, where our two models were compared with PostKS++ and SLKS. 100 dialogues"
2020.findings-emnlp.11,P19-1539,0,0.0386284,"ignificantly outperforms strong baselines in terms of knowledge selection and can generate more informative responses. 2 2.1 existing studies have been mainly devoted to addressing two research problems: (1) knowledge selection: selecting appropriate knowledge given the dialog context and previously selected knowledge (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020; Kim et al., 2020); and (2) knowledge-aware generation: injecting the required knowledge to generate meaningful and informative responses (Ghazvininejad et al., 2018; Zhou et al., 2018a; Li et al., 2019; Qin et al., 2019; Yavuz et al., 2019; Zhao et al., 2020). Since selecting the appropriate knowledge is a precursor to the success of knowledge grounded dialog systems, we focus on the knowledge selection problem in this paper. 2.2 The non-sequential selection models capture the relationship between the current context and background knowledge (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020). For instance, PostKS (Lian et al., 2019) estimates a posterior distribution over candidate knowledge sentences, which is based on both the context and the golden response, and only uses the con"
2020.findings-emnlp.11,D19-1194,0,0.0137048,"ed for selecting important text spans or fragments from the background knowledge document that will be used in generation. Therefore these works have a different task setting from ours. 2.3 Related Work Knowledge-grounded Dialog Generation Recently, a variety of neural models have been proposed to facilitate knowledge-grounded conversation generation (Zhu et al., 2017; Young et al., 2018; Zhou et al., 2018a; Liu et al., 2018). The research topic is also greatly advanced by many corpora (Zhou et al., 2018b; Moghe et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Moon et al., 2019; Tuan et al., 2019; Wu et al., 2019; Zhou et al., 2020). As surveyed in Huang et al. (2020), Non-sequential Knowledge Selection Sequential Knowledge Selection The sequential selection models additionally make use of previously selected knowledge to facilitate knowledge selection (Kim et al., 2020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states of dialog history and previously selected knowledge sentences. Our method is parallel to SLKS because we also utilize the previously selected knowledge. However, we explicitly compute the"
2020.findings-emnlp.11,P18-2118,0,0.0646039,"Missing"
2020.findings-emnlp.11,P19-1369,0,0.102069,"portant text spans or fragments from the background knowledge document that will be used in generation. Therefore these works have a different task setting from ours. 2.3 Related Work Knowledge-grounded Dialog Generation Recently, a variety of neural models have been proposed to facilitate knowledge-grounded conversation generation (Zhu et al., 2017; Young et al., 2018; Zhou et al., 2018a; Liu et al., 2018). The research topic is also greatly advanced by many corpora (Zhou et al., 2018b; Moghe et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Moon et al., 2019; Tuan et al., 2019; Wu et al., 2019; Zhou et al., 2020). As surveyed in Huang et al. (2020), Non-sequential Knowledge Selection Sequential Knowledge Selection The sequential selection models additionally make use of previously selected knowledge to facilitate knowledge selection (Kim et al., 2020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states of dialog history and previously selected knowledge sentences. Our method is parallel to SLKS because we also utilize the previously selected knowledge. However, we explicitly compute the difference betwee"
2020.findings-emnlp.11,2020.acl-main.166,0,0.0136441,"020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states of dialog history and previously selected knowledge sentences. Our method is parallel to SLKS because we also utilize the previously selected knowledge. However, we explicitly compute the difference between knowledge selected at different turns, while SLKS only encodes the already selected knowledge in an implicit way. 116 k&quot;! In addition, recently there emerge a number of works that propose RL-based models to select a path in structured knowledge graph (KG) (Xu et al., 2020a,b), which also select knowledge in a sequential way. While our method is designed to ground the conversation to unstructured knowledge text, we will leave as future work the application of our method to such KG-grounded dialog generation tasks (Wu et al., 2019; Moon et al., 2019; Zhou et al., 2020). 3 3.1 Knowledge Encoder Context Encoder 3.3 Task Formulation ?&quot;# Response Decoder Copy Difference-aware Knowledge Selection In order to select proper knowledge, our model gets aware of the difference between the current candidate knowledge sentences and the previously selected knowledge. To make"
2020.findings-emnlp.11,W19-5917,0,0.1384,"rforms strong baselines in terms of knowledge selection and can generate more informative responses. 2 2.1 existing studies have been mainly devoted to addressing two research problems: (1) knowledge selection: selecting appropriate knowledge given the dialog context and previously selected knowledge (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020; Kim et al., 2020); and (2) knowledge-aware generation: injecting the required knowledge to generate meaningful and informative responses (Ghazvininejad et al., 2018; Zhou et al., 2018a; Li et al., 2019; Qin et al., 2019; Yavuz et al., 2019; Zhao et al., 2020). Since selecting the appropriate knowledge is a precursor to the success of knowledge grounded dialog systems, we focus on the knowledge selection problem in this paper. 2.2 The non-sequential selection models capture the relationship between the current context and background knowledge (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020). For instance, PostKS (Lian et al., 2019) estimates a posterior distribution over candidate knowledge sentences, which is based on both the context and the golden response, and only uses the context to estimate a p"
2020.findings-emnlp.11,2020.acl-main.635,1,0.830287,"s or fragments from the background knowledge document that will be used in generation. Therefore these works have a different task setting from ours. 2.3 Related Work Knowledge-grounded Dialog Generation Recently, a variety of neural models have been proposed to facilitate knowledge-grounded conversation generation (Zhu et al., 2017; Young et al., 2018; Zhou et al., 2018a; Liu et al., 2018). The research topic is also greatly advanced by many corpora (Zhou et al., 2018b; Moghe et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Moon et al., 2019; Tuan et al., 2019; Wu et al., 2019; Zhou et al., 2020). As surveyed in Huang et al. (2020), Non-sequential Knowledge Selection Sequential Knowledge Selection The sequential selection models additionally make use of previously selected knowledge to facilitate knowledge selection (Kim et al., 2020). For instance, Kim et al. (2020) propose a Sequential Latent Knowledge Selection (SLKS) model. It keeps track of the hidden states of dialog history and previously selected knowledge sentences. Our method is parallel to SLKS because we also utilize the previously selected knowledge. However, we explicitly compute the difference between knowledge selected"
2020.findings-emnlp.11,D18-1076,0,0.406741,"rd they are fantasy novels written by Brandon Sanderson. Figure 1: An example of difference-aware knowledge selection. The blue 4 denotes that the corresponding knowledge has little difference from or is identical to the previously selected one, and selecting it may lead to repetitive responses. The red × denotes that the difference is too large, and selecting it could make the response incoherent with the context. Introduction Knowledge-grounded conversation generation aims at generating informative responses based on both discourse context and external knowledge (Ghazvininejad et al., 2018; Zhou et al., 2018a), where selecting appropriate knowledge is critical to the success of the task. Existing knowledge selection models generally fall into two types. One type is solely based on the context (Lian et al., 2019; Zhang et al., 2019; Meng et al., 2020; Ren et al., 2020), which we call non-sequential selection because knowledge selection at different turns is independent. The other type sequentially selects knowledge additionally conditioned on previously selected knowledge (Kim et al., 2020), which we ∗ * Corresponding author. call sequential selection. As shown in Kim et al. (2020), such a sequent"
2020.findings-emnlp.16,I05-5002,0,0.19826,"Missing"
2020.findings-emnlp.16,2020.emnlp-main.500,0,0.0145451,"identifying replaceable position pairs that are linked with red lines. In the negative example, POS tags of non-stopwords are also shown. 166 adopts DenseNet (Huang et al., 2017) to extract interaction features. BERT (Devlin et al., 2018) is a pre-trained encoder fine-tuned on this task with a classifier applied on encoded representations. These models are representative in terms of backbone neural architectures: BiMPM is based on recurrent neural networks, DIIN on convolutional neural networks, and BERT on Transformers. similarity constraints of the new sentence. Moreover, some recent works (Li et al., 2020; Garg and Ramakrishnan, 2020) that appeared later than our preprint have shown that using a masked language model for substituting words can outperform stateof-the-art methods in generating adversarial examples on text classification and natural language inference tasks. 3.3 Finding Modification Solutions 4.2 We then use beam search with beam size B to find a modification solution in multiple steps. At step t, we have two stages to determine the replaced positions and the substitution words respectively, based on a two-stage framework (Yang et al., 2018). First, for replaced positions, we enu"
2020.findings-emnlp.16,2020.emnlp-main.498,0,0.0296731,"Missing"
2020.findings-emnlp.16,K18-1007,0,0.0239969,"ra achieved even better results (Devlin et al., 2018). 2.2 Robustness of NLP Models On the robustness of NLP models, many previous works constructed semantic-preserving perturbations to input sentences (Alzantot et al., 2018; Iyyer et al., 2018; Ribeiro et al., 2018; Hsieh et al., 2019; Jin et al., 2019; Ren et al., 2019). However, NLP models for some tasks have robustness issues not only when facing semantic-preserving perturbations. In reading comprehension, Jia and Liang (2017) studied the robustness issue when a distractor sentence is added to the paragraph. In natural language inference, Minervini and Riedel (2018) considered logical rules of sentence relations, and Glockner et al. (2018) used single word replacement with lexical knowledge. Thus methods for general NLP tasks alone are insufficient for studying the robustness of specific tasks. In particular, for paraphrase identification, the only prior work • We study the robustness of paraphrase identification models via modification with shared 165 Replaceable Position Pairs For a sentence pair under modification, we impose heuristic rules on replaceable position pairs. First, we do not replace stopwords. Besides, for a positive example, we require e"
2020.findings-emnlp.16,P18-2103,0,0.0200743,"els On the robustness of NLP models, many previous works constructed semantic-preserving perturbations to input sentences (Alzantot et al., 2018; Iyyer et al., 2018; Ribeiro et al., 2018; Hsieh et al., 2019; Jin et al., 2019; Ren et al., 2019). However, NLP models for some tasks have robustness issues not only when facing semantic-preserving perturbations. In reading comprehension, Jia and Liang (2017) studied the robustness issue when a distractor sentence is added to the paragraph. In natural language inference, Minervini and Riedel (2018) considered logical rules of sentence relations, and Glockner et al. (2018) used single word replacement with lexical knowledge. Thus methods for general NLP tasks alone are insufficient for studying the robustness of specific tasks. In particular, for paraphrase identification, the only prior work • We study the robustness of paraphrase identification models via modification with shared 165 Replaceable Position Pairs For a sentence pair under modification, we impose heuristic rules on replaceable position pairs. First, we do not replace stopwords. Besides, for a positive example, we require each replaceable word pair to be shared words, while for a negative example,"
2020.findings-emnlp.16,P19-1103,0,0.029024,"ns between the two sentences by jointly encoding and matching them (Wang et al., 2017; Duan et al., 2018; Kim et al., 2018) or hierarchically extracting features from their interaction space (Hu et al., 2014; Pang et al., 2016; Gong et al., 2017). Notably, BERT pre-trained on large-scale corpora achieved even better results (Devlin et al., 2018). 2.2 Robustness of NLP Models On the robustness of NLP models, many previous works constructed semantic-preserving perturbations to input sentences (Alzantot et al., 2018; Iyyer et al., 2018; Ribeiro et al., 2018; Hsieh et al., 2019; Jin et al., 2019; Ren et al., 2019). However, NLP models for some tasks have robustness issues not only when facing semantic-preserving perturbations. In reading comprehension, Jia and Liang (2017) studied the robustness issue when a distractor sentence is added to the paragraph. In natural language inference, Minervini and Riedel (2018) considered logical rules of sentence relations, and Glockner et al. (2018) used single word replacement with lexical knowledge. Thus methods for general NLP tasks alone are insufficient for studying the robustness of specific tasks. In particular, for paraphrase identification, the only prior w"
2020.findings-emnlp.16,D15-1237,0,0.0443454,"Missing"
2020.findings-emnlp.16,D19-1382,0,0.0138238,"ed, and the two modified sentences are likely to talk about another same thing, e.g. changing from “purpose of life” to “measure of value”, and thereby the new example tends to remain positive. As for the second example (negative), nouns “Gmail”, “account”, “school”, “management” and “software” can be replaced. Consequently, the modified sentences are based on templates “How can I get · · · back ? ” and “What is the best · · · ?”, and the pair tends to remain negative even if the template is filled by shared words. In this way, the labels can usually be preserved. is PAWS (Zhang et al., 2019; Yang et al., 2019) which used word swapping, but this method is for negative examples only and each constructed pair of sentences have exactly the same words. 3 3.1 Methodology Algorithm Framework Paraphrase identification can be formulated as follows: given two sentences P = p1 p2 · · · pn and Q = q1 q2 · · · qm , the goal is to predict whether P and Q are paraphrases. The model outputs a score [Z(P, Q)]yˆ for each class yˆ ∈ Y = {positive, negative}, where positive means P and Q are paraphrases and vice versa. We first sample an original example from the dataset and then conduct modification. We take multiple"
2020.findings-emnlp.16,N19-1131,0,0.0457567,"Missing"
2020.findings-emnlp.16,D15-1075,0,\N,Missing
2020.findings-emnlp.16,P18-1079,0,\N,Missing
2020.findings-emnlp.16,P18-2006,0,\N,Missing
2020.findings-emnlp.16,P19-1559,0,\N,Missing
2020.findings-emnlp.16,P19-1147,0,\N,Missing
2020.findings-emnlp.310,U19-1011,0,0.0284988,"ose exemplars that best approximate the mean feature vector of a class, and it is widely used in Castro et al. (2018); Wu et al. (2019); Hou et al. (2019); Zhao et al. (2019); Mi et al. (2020a,b). Ramalho and Garnelo (2019) proposed to store samples that the model is least confident. Chaudhry et al. (2019) demonstrated the effectiveness of exemplars for various continual learning tasks in computer vision. Catastrophic Forgetting in NLP. The catastrophic forgetting issue in NLP tasks has raised increasing attention recently (Mou et al., 2016; Chronopoulou et al., 2019). Yogatama et al. (2019); Arora et al. (2019) identified the detrimental catastrophic forgetting issue while fine-tuning ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019). To deal with this issue, He et al. (2019) proposed to replay pre-train data during fine-tuning heavily, and Chen et al. (2020) proposed an improved Adam optimizer to recall knowledge captured during pretraining. The catastrophic forgetting issue is also noticed in domain adaptation setups for neural machine translation (Saunders et al., 2019; Thompson et al., 2019; Varis and Bojar, 2019) and the reading comprehension task (Xu et al., 2019). Lee (2017) firstly s"
2020.findings-emnlp.310,D18-1547,0,0.120105,"pose to adaptively adjust the regularization weight to consider the difference between new and old data to flexibly deal with different new data distributions. To summarize our contribution, (1) to the best of our knowledge, this is the first attempt to study the practical continual learning configuration for NLG in task-oriented dialog systems; (2) we propose a method called Adaptively Regularized Prioritized Exemplar Replay (ARPER) for this task, and benchmark it with a wide range of state-of-the-art continual learning techniques; (3) extensive experiments are conducted on the MultiWoZ-2.0 (Budzianowski et al., 2018) dataset to continually learn new tasks, including domains and intents using two base NLG models. Empirical results demonstrate the superior performance of ARPER and its ability to mitigate catastrophic forgetting. Our code is available at https://github.com/MiFei/ Continual-Learning-for-NLG 2 Related Work Continual Learning. The major challenge for continual learning is catastrophic forgetting (McCloskey and Cohen, 1989; French, 1999), where optimization over new data leads to performance degradation on data learned before. Methods designed to mitigate catastrophic forgetting fall into three"
2020.findings-emnlp.310,P19-2017,0,0.0248231,"cently (Mou et al., 2016; Chronopoulou et al., 2019). Yogatama et al. (2019); Arora et al. (2019) identified the detrimental catastrophic forgetting issue while fine-tuning ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019). To deal with this issue, He et al. (2019) proposed to replay pre-train data during fine-tuning heavily, and Chen et al. (2020) proposed an improved Adam optimizer to recall knowledge captured during pretraining. The catastrophic forgetting issue is also noticed in domain adaptation setups for neural machine translation (Saunders et al., 2019; Thompson et al., 2019; Varis and Bojar, 2019) and the reading comprehension task (Xu et al., 2019). Lee (2017) firstly studied the continual learning setting for dialog state tracking in task-oriented dialog systems. However, their setting is still a onetime adaptation process, and the adopted dataset is small. Shen et al. (2019) recently applied progressive network (Rusu et al., 2016) for the semantic slot filling task from a continual learning perspective similar to ours. However, their method is based on a dynamic architecture that is beyond the scope of this paper. Liu et al. (2019) proposed a Boolean operation of “conceptor” matrice"
2020.findings-emnlp.310,W15-4639,0,0.0713975,"Missing"
2020.findings-emnlp.310,D15-1199,0,0.0563492,"Missing"
2020.sigdial-1.37,P19-1080,0,0.0137241,"inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dia"
2020.sigdial-1.37,W19-5932,0,0.0447506,"Missing"
2020.sigdial-1.37,N18-2118,0,0.0666864,"dialog systems, which are designed to mimic human conversations rather than complete speciﬁc tasks and are often implemented as end-to-end systems, a goal-oriented dialog system has access to an external database on which to inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint mod"
2020.sigdial-1.37,D19-5602,0,0.0328958,"Missing"
2020.sigdial-1.37,D18-1547,0,0.142513,"Kim et al., 2019; Li et al., 2020). Although end-to-end systems are evaluated in a system-wise manner, none of such systems is compared with its pipeline counterpart. Furthermore, unlike the component-wise assessment, system-wise evaluation requires simulated users or human users to interact with the system to be evaluated via multi-turn conversations to complete tasks. To this end, we conduct both simulated and human evaluations on dialog systems with a wide variety of conﬁgurations and settings using a standardized dialog system platform, Convlab (Lee et al., 2019b), on the MultiWOZ corpus (Budzianowski et al., 2018). Our work attempts to shed light on evaluating and comparing goal-oriented dialog systems by conducting a system-wise evaluation and a detailed empirical analysis. Speciﬁcally, we strive to answer the following research questions: (RQ1) Which conﬁgurations lead to better goaloriented dialog systems? (§3.1); (RQ2) Whether the component-wise, single-turn metrics are consistent with system-wise, multi-turn metrics for evaluation? (§3.2); (RQ3) How does the performance vary when a system is evaluated using tasks of different complexities, e.g., from single-domain to multi-domain tasks? (§3.3); (R"
2020.sigdial-1.37,P19-1360,0,0.188546,"s the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging to properly evaluate and compare the overall performance of goaloriented dialog systems due to the wide variety of system conﬁgurations and evaluation settings. Nu297 Proceedings of the SIGdial 2020 Conference, pages 297–310 c 1st virtual meeting, 01-03 July 2020. 2020 Association for Computational Linguistics merous approaches have been proposed to tackle different components in pipeline systems, whereas these modules are merely evaluated separately. Most studies only compare the proposed models with baselines"
2020.sigdial-1.37,N19-1423,0,0.0233249,"in MultiWOZ, and replicate the performance reported in the original papers or on the leaderboard. 299 NLU A natural language understanding module identiﬁes user intents and extracts associated information from users’ raw utterances. We consider 1 All state-of-the-art models mentioned in this paper are based on the open-source code that is available and executable as of February 29, 2020. two approaches that can handle multi-intents as reference: a RNN-based model MILU which extends (Hakkani-T¨ur et al., 2016) and is ﬁne-tuned on multiple domains, intents and slots; and a ﬁne-tuned BERT model (Devlin et al., 2019). Following the joint tagging scheme (Zheng et al., 2017), the labels of intent detection and slot ﬁlling are annotated for domain classiﬁcation during training. Both models use dialog history up to the last dialog turn as context. Note that there can be multiple intents or slots in one sentence, we calculate two F1 scores for intents and slots, respectively. DST A dialog state tracker encodes the extracted information as a compact set of dialog state that contains a set of informable slots and their corresponding values (user constraints), and a set of requested slots2 . We have implemented a"
2020.sigdial-1.37,W14-4337,0,0.0315072,"eturn evaluation, BLEU, inform rate and success rate are provided. 3 3.1 Empirical Analysis Performance under Different Settings (RQ1) We compare the performance of three types of systems, pipeline, joint-model and end-to-end. Results in Table 1 show that pipeline systems often achieve better overall performance than the joint models and end-to-end systems because using ﬁne-grained labels at the component level can help pipeline systems improve the task success rate. 2 Dialog state can include everything a system must know in order to make a decision about what to do next, e.g., DSTC2 corpus (Henderson et al., 2014) contains search method representing user intents in the dialog state, but only aforementioned items are taken into account as our experiments are conducted on MultiWOZ in this paper. 300 NLU with DST or joint DST It is essential to predict dialog states to determine what a user has expressed and wants to inquire. The dialog state is used to query the database, predict the system dialog act, and generate a dialog response. Although many studies have focused on the wordlevel DST that directly predicts the state using the ID 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Conﬁguration NLU DST Policy NLG"
2020.sigdial-1.37,P17-1045,1,0.88059,"hree classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is partic"
2020.sigdial-1.37,P19-1546,0,0.197239,"rall performance of different combinations (Kim et al., 2019; Li et al., 2020). Although end-to-end systems are evaluated in a system-wise manner, none of such systems is compared with its pipeline counterpart. Furthermore, unlike the component-wise assessment, system-wise evaluation requires simulated users or human users to interact with the system to be evaluated via multi-turn conversations to complete tasks. To this end, we conduct both simulated and human evaluations on dialog systems with a wide variety of conﬁgurations and settings using a standardized dialog system platform, Convlab (Lee et al., 2019b), on the MultiWOZ corpus (Budzianowski et al., 2018). Our work attempts to shed light on evaluating and comparing goal-oriented dialog systems by conducting a system-wise evaluation and a detailed empirical analysis. Speciﬁcally, we strive to answer the following research questions: (RQ1) Which conﬁgurations lead to better goaloriented dialog systems? (§3.1); (RQ2) Whether the component-wise, single-turn metrics are consistent with system-wise, multi-turn metrics for evaluation? (§3.2); (RQ3) How does the performance vary when a system is evaluated using tasks of different complexities, e.g."
2020.sigdial-1.37,W16-3602,0,0.106933,"eciﬁc tasks and are often implemented as end-to-end systems, a goal-oriented dialog system has access to an external database on which to inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint word"
2020.sigdial-1.37,P19-3011,1,0.912839,"Missing"
2020.sigdial-1.37,P18-1133,0,0.104061,"s, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging to properly evalu"
2020.sigdial-1.37,N18-1187,0,0.0173212,"their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging"
2020.sigdial-1.37,D17-1237,1,0.937191,"as end-to-end systems, a goal-oriented dialog system has access to an external database on which to inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and D"
2020.sigdial-1.37,P19-1079,0,0.0194091,"hich are designed to mimic human conversations rather than complete speciﬁc tasks and are often implemented as end-to-end systems, a goal-oriented dialog system has access to an external database on which to inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (b"
2020.sigdial-1.37,D19-1013,0,0.0219569,"in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging to properly evaluate and compare th"
2020.sigdial-1.37,P18-2069,0,0.0258295,"ng. Both models use dialog history up to the last dialog turn as context. Note that there can be multiple intents or slots in one sentence, we calculate two F1 scores for intents and slots, respectively. DST A dialog state tracker encodes the extracted information as a compact set of dialog state that contains a set of informable slots and their corresponding values (user constraints), and a set of requested slots2 . We have implemented a rule-based DST to update the slot values in the dialog state based on the output of NLU. We then compare four word-level DST: a multi-domain classiﬁer MDBT (Ramadan et al., 2018) which enumerates all possible candidate slots and values, SUMBT (Lee et al., 2019a) that uses a BERT encoder and a slotutterance matching architecture for classiﬁcation, TRADE (Wu et al., 2019) that shares knowledge among domains to directly generate slot values, and COMER (Ren et al., 2019) which applies a hierarchical encoder-decoder model for state generation. We use two metrics for evaluation. The joint goal accuracy compares the predicted dialog states to the ground truth at each dialog turn, and the output is considered correct if and only if all the predicted values exactly match the g"
2020.sigdial-1.37,D19-1196,0,0.0302745,"Missing"
2020.sigdial-1.37,P18-1136,0,0.0485947,"Missing"
2020.sigdial-1.37,N07-2038,0,0.142779,"goals, the numbers of goals involving 1/2/3 domains are 328/549/123, respectively. 2.3 Evaluation Metrics 2.5 Platform and Simulator We use the open-source end-to-end dialog system platform, ConvLab (Lee et al., 2019b), as our experimental platform. ConvLab enables researchers to develop a dialog system using preferred architectures and supports system-wise simulated evaluation. It also provides an integration of crowdsourcing platforms such as Amazon Mechanical Turk for human evaluation. To automatically evaluate a multi-turn dialog system, Convlab implements an agenda-based user simulator (Schatzmann et al., 2007). Given a user goal, the simulator’s policy uses a stack-like structure with complex hand-crafted heuristics to inform its goal and mimics complex user behaviors during a conversation. Since the system interacts with the simulator in natural language, the user simulator directly takes system utterances as input and outputs a user response. The overall architecture of user simulator is presented in Fig. 3. It consists of three modules: NLU, policy, and NLG. We use the default conﬁguration of the simulator in Convlab: a RNN-based model MILU (Multi-Intent Language Understanding, extended (Hakkani"
2020.sigdial-1.37,W19-5921,0,0.0736932,"onding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging to properly evaluate and compare the overall performance"
2020.sigdial-1.37,W01-1614,0,0.195413,"k of ro304 bustness in dealing with real human conversations. 4 Related Work Developers have been facing many problems when evaluating a goal-oriented dialog system. A range of well-deﬁned automatic metrics have been designed for different components in the system, e.g., joint goal accuracy in DST and task success rate in policy optimization introduced in Table 2b and 2c. A broadly accepted evaluation scheme for the goaloriented dialog was ﬁrst proposed by PARADISE (Walker et al., 1997). It estimates the user satisfaction by measuring two types of aspects, namely dialog cost and task success. Paek (2001) suggests that a useful dialog metric should provide an estimate of how well the goal is met and allow for a comparative judgement of different systems. Though a model can be optimized against these metrics via supervised learning, each component is trained or evaluated separately, thus difﬁcult to reﬂect real user satisfaction. As human evaluation by asking crowd-sourcing workers to interact with a dialog system is much expensive (Ultes et al., 2013; Su et al., 2016) and prone to be affected by subjective factors (Higashinaka et al., 2010; Schmitt and Ultes, 2015), researchers have tried to r"
2020.sigdial-1.37,J00-3003,0,0.470465,"Missing"
2020.sigdial-1.37,P02-1040,0,0.107816,"log policies: a hand-crafted policy, and a reinforcement learning policy GDPL (Takanobu et al., 2019) that jointly learns a reward function. We also include in our comparison three joint models, known as word-level policies, which combine the policy and the NLG module to produce natural language responses from dialog states. They are MDRG (Wen et al., 2017) where an attention mechanism is conditioned on the dialog states, HDSA (Chen et al., 2019) that decodes response from predicted hierarchical dialog acts, and LaRL (Zhao et al., 2019) which uses a latent action framework. We use BLEU score (Papineni et al., 2002), inform rate and task success rate as metrics for evaluation. Note that the inform rate and task success for evaluating policies are computed at the turn level, while the ones used in system-wise evaluation are computed at the dialog level. NLG A natural language generation module generates a natural language response from a dialog act representation. We experiment with two models: a retrieval-based model that samples a sentence randomly from the corpus using dialog acts, and a generation-based model SCLSTM (Wen et al., 2015) which appends a sentence planning cell in RNN. To evaluate the perf"
2020.sigdial-1.37,P16-1230,0,0.0656448,"Missing"
2020.sigdial-1.37,2020.acl-main.59,1,0.883409,"Missing"
2020.sigdial-1.37,D19-1010,1,0.945403,"ems, a goal-oriented dialog system has access to an external database on which to inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018;"
2020.sigdial-1.37,P17-4013,0,0.0248449,"Missing"
2020.sigdial-1.37,P19-1078,0,0.0308496,"Missing"
2020.sigdial-1.37,W15-4641,0,0.0212453,"r than complete speciﬁc tasks and are often implemented as end-to-end systems, a goal-oriented dialog system has access to an external database on which to inquire about information to accomplish tasks for users. Goal-oriented dialog systems can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For"
2020.sigdial-1.37,N13-1064,0,0.0307734,"t proposed by PARADISE (Walker et al., 1997). It estimates the user satisfaction by measuring two types of aspects, namely dialog cost and task success. Paek (2001) suggests that a useful dialog metric should provide an estimate of how well the goal is met and allow for a comparative judgement of different systems. Though a model can be optimized against these metrics via supervised learning, each component is trained or evaluated separately, thus difﬁcult to reﬂect real user satisfaction. As human evaluation by asking crowd-sourcing workers to interact with a dialog system is much expensive (Ultes et al., 2013; Su et al., 2016) and prone to be affected by subjective factors (Higashinaka et al., 2010; Schmitt and Ultes, 2015), researchers have tried to realize automatic evaluation of dialog systems. Simulated evaluation (Araki and Doshita, 1996; Eckert et al., 1997) is widely used in recent works (Williams et al., 2017; Peng et al., 2017; Takanobu et al., 2019, 2020) and platforms (Ultes et al., 2017; Lee et al., 2019b; Papangelis et al., 2020; Zhu et al., 2020), where the system interacts with a user simulator which mimics human behaviors. Such evaluation can be conducted at the dialog act or natur"
2020.sigdial-1.37,N19-1123,0,0.091931,"r unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging to properly evaluate and compare the overall performance of goaloriented dialog systems due to the wide variety of system conﬁgurations and evaluation settings. Nu297 Proceedings of the SIGdial 2020 Conference, pages 297–310 c 1st virtual meeting, 01-03 July 2020. 2020 Association for Computational Linguistics merous approaches have been proposed to tackle different components in pipeline systems, whereas these modules are merely evaluated separately. Most studies only compare the proposed models with baselines of the same module"
2020.sigdial-1.37,P97-1035,0,0.908929,"are vulnerable to the variation of human language (e.g., the sentence highlighted in brown in Table 7), which demonstrates a lack of ro304 bustness in dealing with real human conversations. 4 Related Work Developers have been facing many problems when evaluating a goal-oriented dialog system. A range of well-deﬁned automatic metrics have been designed for different components in the system, e.g., joint goal accuracy in DST and task success rate in policy optimization introduced in Table 2b and 2c. A broadly accepted evaluation scheme for the goaloriented dialog was ﬁrst proposed by PARADISE (Walker et al., 1997). It estimates the user satisfaction by measuring two types of aspects, namely dialog cost and task success. Paek (2001) suggests that a useful dialog metric should provide an estimate of how well the goal is met and allow for a comparative judgement of different systems. Though a model can be optimized against these metrics via supervised learning, each component is trained or evaluated separately, thus difﬁcult to reﬂect real user satisfaction. As human evaluation by asking crowd-sourcing workers to interact with a dialog system is much expensive (Ultes et al., 2013; Su et al., 2016) and pro"
2020.sigdial-1.37,P17-1113,0,0.0280956,"original papers or on the leaderboard. 299 NLU A natural language understanding module identiﬁes user intents and extracts associated information from users’ raw utterances. We consider 1 All state-of-the-art models mentioned in this paper are based on the open-source code that is available and executable as of February 29, 2020. two approaches that can handle multi-intents as reference: a RNN-based model MILU which extends (Hakkani-T¨ur et al., 2016) and is ﬁne-tuned on multiple domains, intents and slots; and a ﬁne-tuned BERT model (Devlin et al., 2019). Following the joint tagging scheme (Zheng et al., 2017), the labels of intent detection and slot ﬁlling are annotated for domain classiﬁcation during training. Both models use dialog history up to the last dialog turn as context. Note that there can be multiple intents or slots in one sentence, we calculate two F1 scores for intents and slots, respectively. DST A dialog state tracker encodes the extracted information as a compact set of dialog state that contains a set of informable slots and their corresponding values (user constraints), and a set of requested slots2 . We have implemented a rule-based DST to update the slot values in the dialog s"
2020.sigdial-1.37,D15-1199,0,0.0926213,"Missing"
2020.sigdial-1.37,P18-1135,0,0.0250954,"kanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´c, 2019). It is particularly challenging to properly evaluate and compare the overall performance of goaloriented dialog systems due to the wide variety of system conﬁgurations and evaluation settings. Nu297 Proceedings of the SIGdial 2020 Conference, pages 297–310 c 1st virtual meeting, 01-03 July 2020. 2020 Association for Computational Linguistics merous approaches have been proposed to tackle different components in pipeline"
2020.sigdial-1.37,E17-1042,0,0.133925,"Missing"
2020.sigdial-1.37,2020.acl-demos.19,1,0.793267,"to reﬂect real user satisfaction. As human evaluation by asking crowd-sourcing workers to interact with a dialog system is much expensive (Ultes et al., 2013; Su et al., 2016) and prone to be affected by subjective factors (Higashinaka et al., 2010; Schmitt and Ultes, 2015), researchers have tried to realize automatic evaluation of dialog systems. Simulated evaluation (Araki and Doshita, 1996; Eckert et al., 1997) is widely used in recent works (Williams et al., 2017; Peng et al., 2017; Takanobu et al., 2019, 2020) and platforms (Ultes et al., 2017; Lee et al., 2019b; Papangelis et al., 2020; Zhu et al., 2020), where the system interacts with a user simulator which mimics human behaviors. Such evaluation can be conducted at the dialog act or natural language level. The advantages of using simulated evaluation are that it can support multi-turn language interaction in a full end-to-end fashion and generate dialogs unseen in the original corpus. 5 Conclusion and Discussion In this paper, we have presented the system-wise evaluation result and empirical analysis to estimate the practicality of goal-oriented dialog systems with a number of conﬁgurations and approaches. Though our experiments are only c"
2020.sigdial-1.37,P17-1062,0,0.12801,"s can be grouped into three classes based on their architectures, as illustrated in Fig. 1. Corresponding author DST State Introduction ∗ Semantic Info The ﬁrst class is the pipeline (or modular) systems which typically consist of the four components: Natural Language Understanding (NLU) (Goo et al., 2018; Pentyala et al., 2019), Dialog State Tracker (DST) (Xie et al., 2015; Lee and Stent, 2016), Dialog Policy (Peng et al., 2017; Takanobu et al., 2019), and Natural Language Generation (NLG) (Wen et al., 2015; Balakrishnan et al., 2019). The second class is the end-to-end (or unitary) systems (Williams et al., 2017; Dhingra et al., 2017; Liu et al., 2018; Lei et al., 2018; Qin et al., 2019; Mehri et al., 2019), which use a machine-learned neural model to generate a system response directly from a dialog history. The third one lies in between the above two types, where some systems use joint models that combine some (but not all) of the four dialog components. For example, a joint wordlevel DST model combines NLU and DST (Zhong et al., 2018; Wu et al., 2019; Gao et al., 2019b), and a joint word-level policy model combines dialog policy and NLG (Chen et al., 2019; Zhao et al., 2019; Budzianowski and Vuli´"
2020.sigdial-1.37,W01-0902,0,\N,Missing
2020.tacl-1.19,W17-5526,0,0.0936601,"Missing"
2020.tacl-1.19,W17-5506,0,0.163439,"er simulation, etc. 1 Introduction Recently, there have been a variety of task-oriented dialogue models thanks to the prosperity of neural architectures (Yao et al., 2013; Wen et al., 2015; Mrkˇsi´c et al., 2017; Peng et al., 2017; Lei et al., 2018; G¨ur et al., 2018). However, research is still largely limited by the lack of large-scale highquality dialogue data. Many corpora have advanced the research of task-oriented dialogue systems, most of which are single domain conversations, including ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017), KVRET (Eric et al., 2017), WOZ 2.0 (Wen et al., 2017), and M2M (Shah et al., 2018). 1. The dependency between domains is more challenging because the choice in one domain will affect the choices in related domains ∗ Corresponding author. 281 Transactions of the Association for Computational Linguistics, vol. 8, pp. 281–295, 2020. https://doi.org/10.1162/tacl a 00314 Action Editor: Bonnie Webber. Submission batch: 10/2019; Revision batch: 1/2020; Published 6/2020. c 2020 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. in CrossWOZ. As shown in Figure 1 and Table 2, the hotel must be nea"
2020.tacl-1.19,H90-1021,0,0.827971,"f tasks in cross-domain dialogue modeling, such as dialogue state tracking, policy learning, user simulation, etc. 1 Introduction Recently, there have been a variety of task-oriented dialogue models thanks to the prosperity of neural architectures (Yao et al., 2013; Wen et al., 2015; Mrkˇsi´c et al., 2017; Peng et al., 2017; Lei et al., 2018; G¨ur et al., 2018). However, research is still largely limited by the lack of large-scale highquality dialogue data. Many corpora have advanced the research of task-oriented dialogue systems, most of which are single domain conversations, including ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017), KVRET (Eric et al., 2017), WOZ 2.0 (Wen et al., 2017), and M2M (Shah et al., 2018). 1. The dependency between domains is more challenging because the choice in one domain will affect the choices in related domains ∗ Corresponding author. 281 Transactions of the Association for Computational Linguistics, vol. 8, pp. 281–295, 2020. https://doi.org/10.1162/tacl a 00314 Action Editor: Bonnie Webber. Submission batch: 10/2019; Revision batch: 1/2020; Published 6/2020. c 2020 Association for Computational Linguistics. Distributed unde"
2020.tacl-1.19,D18-1547,0,0.119842,"Missing"
2020.tacl-1.19,W14-4337,0,0.146229,"modeling, such as dialogue state tracking, policy learning, user simulation, etc. 1 Introduction Recently, there have been a variety of task-oriented dialogue models thanks to the prosperity of neural architectures (Yao et al., 2013; Wen et al., 2015; Mrkˇsi´c et al., 2017; Peng et al., 2017; Lei et al., 2018; G¨ur et al., 2018). However, research is still largely limited by the lack of large-scale highquality dialogue data. Many corpora have advanced the research of task-oriented dialogue systems, most of which are single domain conversations, including ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017), KVRET (Eric et al., 2017), WOZ 2.0 (Wen et al., 2017), and M2M (Shah et al., 2018). 1. The dependency between domains is more challenging because the choice in one domain will affect the choices in related domains ∗ Corresponding author. 281 Transactions of the Association for Computational Linguistics, vol. 8, pp. 281–295, 2020. https://doi.org/10.1162/tacl a 00314 Action Editor: Bonnie Webber. Submission batch: 10/2019; Revision batch: 1/2020; Published 6/2020. c 2020 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. in CrossWO"
2020.tacl-1.19,N19-1423,0,0.0180028,"in transition is a key factor for a cross-domain dialogue system, natural language understanding models need to utilize context information more effectively. 6.1 Natural Language Understanding Task: The natural language understanding component in a task-oriented dialogue system takes an utterance as input and outputs the corresponding semantic representation, namely, a dialogue act. The task can be divided into two sub-tasks: intent classification that decides the intent type of an utterance, and slot tagging which identifies the value of a slot. Model: We adapted BERTNLU from ConvLab2. BERT (Devlin et al., 2019) has shown strong performance in many NLP tasks. We use Chinese pre-trained BERT1 (Cui et al., 2019) for initial6.2 Dialogue State Tracking Task: Dialogue state tracking is responsible for recognizing user goals from the dialogue context and then encoding the goals into the pre-defined 1 BERT-wwm-ext model in https://github.com/ ymcui/Chinese-BERT-wwm. 289 S M M+T CM CM+T Overall BERTNLU – context Dialogue act F1 96.69 96.01 96.15 94.99 95.38 94.55 93.05 93.70 90.66 90.82 95.53 91.85 RuleDST TRADE Joint state accuracy (single turn) 84.17 78.17 81.93 63.38 67.86 Joint state accuracy 71.67 45.29"
2020.tacl-1.19,P18-1133,0,0.134956,"vide a user simulator and several benchmark models for pipelined taskoriented dialogue systems, which will facilitate researchers to compare and evaluate their models on this corpus. The large size and rich annotation of CrossWOZ make it suitable to investigate a variety of tasks in cross-domain dialogue modeling, such as dialogue state tracking, policy learning, user simulation, etc. 1 Introduction Recently, there have been a variety of task-oriented dialogue models thanks to the prosperity of neural architectures (Yao et al., 2013; Wen et al., 2015; Mrkˇsi´c et al., 2017; Peng et al., 2017; Lei et al., 2018; G¨ur et al., 2018). However, research is still largely limited by the lack of large-scale highquality dialogue data. Many corpora have advanced the research of task-oriented dialogue systems, most of which are single domain conversations, including ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017), KVRET (Eric et al., 2017), WOZ 2.0 (Wen et al., 2017), and M2M (Shah et al., 2018). 1. The dependency between domains is more challenging because the choice in one domain will affect the choices in related domains ∗ Corresponding author. 281 Transactions"
2020.tacl-1.19,D17-1259,0,0.0440343,"user simulator, which will facilitate the development and evaluation of dialogue models on this corpus. The corpus and the benchmark models are publicly available at https://github.com/ thu-coai/CrossWOZ. 2 Related Work According to whether the dialogue agent is human or machine, we can group the collection methods of existing task-oriented dialogue datasets into three categories. The first one is human-to-human dialogues. One of the earliest and well-known is the ATIS dataset (Hemphill et al., 1990) used this setting, followed by El Asri et al. (2017), Eric et al. (2017), Wen et al. (2017), Lewis et al. (2017), Wei et al. (2018), and Budzianowski et al. (2018b). Though this setting requires many human efforts, it can collect natural and diverse dialogues. The second one is human-to-machine dialogues, which need a ready dialogue system to converse with humans. The famous Dialogue State Tracking Challenges provided a set of human-to-machine dialogue data (Williams et al., 2013; Henderson Figure 1: A dialogue example. The user state is initialized by the user goal: Finding an attraction and one of its nearby hotels, then booking a taxi to commute between these two places. In addition to expressing pre"
2020.tacl-1.19,P17-1163,0,0.123031,"Missing"
2020.tacl-1.19,D17-1237,0,0.201526,"sation. We also provide a user simulator and several benchmark models for pipelined taskoriented dialogue systems, which will facilitate researchers to compare and evaluate their models on this corpus. The large size and rich annotation of CrossWOZ make it suitable to investigate a variety of tasks in cross-domain dialogue modeling, such as dialogue state tracking, policy learning, user simulation, etc. 1 Introduction Recently, there have been a variety of task-oriented dialogue models thanks to the prosperity of neural architectures (Yao et al., 2013; Wen et al., 2015; Mrkˇsi´c et al., 2017; Peng et al., 2017; Lei et al., 2018; G¨ur et al., 2018). However, research is still largely limited by the lack of large-scale highquality dialogue data. Many corpora have advanced the research of task-oriented dialogue systems, most of which are single domain conversations, including ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017), KVRET (Eric et al., 2017), WOZ 2.0 (Wen et al., 2017), and M2M (Shah et al., 2018). 1. The dependency between domains is more challenging because the choice in one domain will affect the choices in related domains ∗ Corresponding author."
2020.tacl-1.19,D15-1199,0,0.110348,"Missing"
2020.tacl-1.19,N07-2038,0,0.287802,"Missing"
2020.tacl-1.19,D19-1010,1,0.862571,"are underlined. Some turns are omitted to save space. Names of hotels are replaced by A,B,C for simplicity. Cross-domain constraints are pre-specified in MultiWOZ and Schema, while determined dynamically in CrossWOZ. In CrossWOZ, the choice in one domain will greatly affect related domains. much attention recently, due to its large size and multi-domain characteristics. It is at least one order of magnitude larger than previous datasets, amounting to 8,438 dialogues and 115K turns in the training set. It greatly promotes the research on multi-domain dialogue modeling, such as policy learning (Takanobu et al., 2019), state tracking (Wu et al., 2019), and context-to-text generation (Budzianowski et al., 2018a). Recently the Schema dataset has been collected in a machine-to-machine fashion, resulting in 16,142 dialogues and 330K turns for 16 domains in the training set. However, the multi-domain dependency in these two datasets is only embodied in imposing the same pre-specified constraints on system simulators to generate dialogue outlines, then use templates (Peng et al., 2017) to generate dialogues or further use people to paraphrase the dialogues to make them more natural (Shah et al., 2018; Rastogi et"
2020.tacl-1.19,W13-4065,0,0.0807343,"ee categories. The first one is human-to-human dialogues. One of the earliest and well-known is the ATIS dataset (Hemphill et al., 1990) used this setting, followed by El Asri et al. (2017), Eric et al. (2017), Wen et al. (2017), Lewis et al. (2017), Wei et al. (2018), and Budzianowski et al. (2018b). Though this setting requires many human efforts, it can collect natural and diverse dialogues. The second one is human-to-machine dialogues, which need a ready dialogue system to converse with humans. The famous Dialogue State Tracking Challenges provided a set of human-to-machine dialogue data (Williams et al., 2013; Henderson Figure 1: A dialogue example. The user state is initialized by the user goal: Finding an attraction and one of its nearby hotels, then booking a taxi to commute between these two places. In addition to expressing prespecified informable slots and filling in requestable slots, users need to consider and modify cross-domain informable slots (bold) that vary through conversation. We only show a few turns (turn number on the left), each with either user or system state of the current domain, which are shown above each utterance. et al., 2014). The performance of the dialogue system wil"
2020.tacl-1.19,P19-1078,0,0.27026,"o save space. Names of hotels are replaced by A,B,C for simplicity. Cross-domain constraints are pre-specified in MultiWOZ and Schema, while determined dynamically in CrossWOZ. In CrossWOZ, the choice in one domain will greatly affect related domains. much attention recently, due to its large size and multi-domain characteristics. It is at least one order of magnitude larger than previous datasets, amounting to 8,438 dialogues and 115K turns in the training set. It greatly promotes the research on multi-domain dialogue modeling, such as policy learning (Takanobu et al., 2019), state tracking (Wu et al., 2019), and context-to-text generation (Budzianowski et al., 2018a). Recently the Schema dataset has been collected in a machine-to-machine fashion, resulting in 16,142 dialogues and 330K turns for 16 domains in the training set. However, the multi-domain dependency in these two datasets is only embodied in imposing the same pre-specified constraints on system simulators to generate dialogue outlines, then use templates (Peng et al., 2017) to generate dialogues or further use people to paraphrase the dialogues to make them more natural (Shah et al., 2018; Rastogi et al., 2019). It needs much less hu"
2020.tacl-1.19,2020.acl-demos.19,1,\N,Missing
2020.tacl-1.7,P19-1470,0,0.0616403,"et al., 2019), and essay generation from given topics (Yang et al., 2019b). And recently, some work also attempted to integrate external commonsense knowledge into pretrained models such as BERT (Devlin et al., 2018) to enhance language representation for reading comprehension (Yang et al., 2019a) and other knowledge-driven NLP tasks like entity typing and relation classification (Zhang et al., 2019). Besides, Sun et al. (2019) improved BERT on Chinese NLP tasks by multi-stage knowledge masking strategy to integrate phrase and entity level knowledge into the language representation. Moreover, Bosselut et al. (2019) transferred the implicit knowledge from GPT-2 by fine-tuning the model to generate an object given the subject and a relation as input in commonsense knowledge graphs, that is, automatic knowledge base construction. However, the low novelty of the generated objects showed that it could still be difficult for GPT-2 to generate commonsense texts solely based on its implicit knowledge. Therefore, we target integrating external knowledge into GPT-2 for generating more reasonable commonsense stories. 2.2 Pretraining Recently, large-scale pretraining models have been widely developed in various NLP"
2020.tacl-1.7,D15-1075,0,0.0379736,"e dependencies between sentences (Ji et al., 2017; Clark et al., 2018). Another line is to decompose story generation into separate steps (Martin et al., 2018; Fan et al., 2018; Wang et al., 2016; Xu et al., 2018; Yao et al., 2019; Fan et al., 2019). These models usually focused on first planning story sketches and then generating sentences from the sketches. However, improving pretrained models to generate commonsense stories is yet to be well investigated. 2.3 Commonsense Knowledge Incorporating commonsense knowledge is necessary and beneficial for language inference (LoBue and Yates, 2011; Bowman et al., 2015; Rashkin et al., 2018b), reading comprehension (Mihaylov and Frank, 2018; Rashkin et al., 2018a), and particularly for open-ended language generation, which usually requires external knowledge to enrich the limited source information. Commonsense knowledge has been demonstrated to significantly improve dialogue generation (Zhou et al., 2018), story ending generation (Guan et al., 2019), and essay generation from given topics (Yang et al., 2019b). And recently, some work also attempted to integrate external commonsense knowledge into pretrained models such as BERT (Devlin et al., 2018) to enha"
2020.tacl-1.7,N18-1204,0,0.0395001,"github.com/thu-coai/CommonsenseStoryGen, and demo is available at http://coai.cs.tsinghua. edu.cn/static/CommonsenseStoryGen. 94 et al., 2014), we build our model based on GPT-2 because of its simplicity and broad applicability. short text descriptions (Jain et al., 2017). Different from these studies, we consider the setting of open-ended story generation from only a limited leading context in this paper. For this task, prior studies have attempted to build specific sentence representations by modeling story entities and events to simplify the dependencies between sentences (Ji et al., 2017; Clark et al., 2018). Another line is to decompose story generation into separate steps (Martin et al., 2018; Fan et al., 2018; Wang et al., 2016; Xu et al., 2018; Yao et al., 2019; Fan et al., 2019). These models usually focused on first planning story sketches and then generating sentences from the sketches. However, improving pretrained models to generate commonsense stories is yet to be well investigated. 2.3 Commonsense Knowledge Incorporating commonsense knowledge is necessary and beneficial for language inference (LoBue and Yates, 2011; Bowman et al., 2015; Rashkin et al., 2018b), reading comprehension (Mi"
2020.tacl-1.7,N19-1423,0,0.0269491,"Missing"
2020.tacl-1.7,P18-1082,0,0.410495,"the sentences in a reasonable story, we use multi-task learning, which combines a discriminative objective to distinguish true and fake stories during fine-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence. 1 Introduction Story generation is a strong indicator of machine understanding of natural language. It is often approached as selecting a sequence of events to form a story with a reasonable logic or plot. Although existing generative models (Roemmele, 2016; Fan et al., 2018; Fan et al., 2019) can generate stories with good local coherence, they ∗ Corresponding author: Minlie Huang. 93 Transactions of the Association for Computational Linguistics, vol. 8, pp. 93–108, 2020. https://doi.org/10.1162/tacl a 00302 Action Editor: Noah Smith. Submission batch: 10/2019; Revision batch: 11/2019; Published 2020. c 2020 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. these knowledge bases, which can provide additional crucial information for story generation. Empirical experiments demonstrate that training with millions of such examples hel"
2020.tacl-1.7,P19-1254,0,0.347048,"a reasonable story, we use multi-task learning, which combines a discriminative objective to distinguish true and fake stories during fine-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence. 1 Introduction Story generation is a strong indicator of machine understanding of natural language. It is often approached as selecting a sequence of events to form a story with a reasonable logic or plot. Although existing generative models (Roemmele, 2016; Fan et al., 2018; Fan et al., 2019) can generate stories with good local coherence, they ∗ Corresponding author: Minlie Huang. 93 Transactions of the Association for Computational Linguistics, vol. 8, pp. 93–108, 2020. https://doi.org/10.1162/tacl a 00302 Action Editor: Noah Smith. Submission batch: 10/2019; Revision batch: 11/2019; Published 2020. c 2020 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. these knowledge bases, which can provide additional crucial information for story generation. Empirical experiments demonstrate that training with millions of such examples helps improve the cohe"
2020.tacl-1.7,P19-1134,0,0.0494618,"Missing"
2020.tacl-1.7,K17-1034,0,0.0131358,"is difficult to match the events extracted from the training data with those stored in KB. (2) Learning and utilizing multi-hop triples in knowledge graphs is costly in time because of the large-scale size. (3) Most of KB triples do not appear in the task-specific training data, so that those absent triples are not fully utilized in existing models. Fortunately, our model is trained on the knowledge bases directly, which can effectively ease these limitations. We transform the commonsense triples in ConceptNet and ATOMIC into readable natural language sentences using a template-based method (Levy et al., 2017), as illustrated in Table 2. We do not use roughly concatenated triples in order to avoid introducing additional special tokens (e.g., UsedFor in ConceptNet and oEffect in ATOMIC), or break the syntactic features contained in the pretrained language model (Alt et al., 2019), which are essential for following story generation. And then the language model is post-trained on the transformed sentences to learn commonsense knowledge between entities and events by minimizing the negative likelihood of predicting the next token: LKG = − |r | X logP (rt |r<t ), Figure 2: An example of fake story const"
2020.tacl-1.7,N16-1014,0,0.158784,"n and fully connected layers. Radford et al. (2019) used a 12-layer decoder-only transformer (GPT-2) (i.e., a left-to-right language model) with masked self-attention heads which are constrained in that every token can only attend to its left context. Formally, the objective in this stage is to minimize the following negative likelihood: LGP T = − |u| X logP (ut |u<t ), (1) P (ut |u<t ) = softmax(HL t W + b), (2) notable work for dialog generation (Zhou et al., 2018). To leverage commonsense knowledge in pretrained language models, we resort to existing large-scale knowledge bases ConceptNet (Li et al., 2016b) and ATOMIC (Sap et al., 2019). The ConceptNet dataset2 consists of triples obtained from the Open Mind Common Sense entries in ConceptNet 5 (Speer and Havasi, 2012). It contains 34 relations in total and represents each knowledge triple by R = (h, r, t), meaning that head concept h has the relation r with tail concept t for example, (cross street, Causes, accident). And the ATOMIC dataset3 is an atlas of everyday commonsense reasoning containing a mass of textual description of inferential knowledge organized as typed if-then triples. For example, a typical if-then triple is (PersonX pays P"
2020.tacl-1.7,P16-1137,0,0.15463,"n and fully connected layers. Radford et al. (2019) used a 12-layer decoder-only transformer (GPT-2) (i.e., a left-to-right language model) with masked self-attention heads which are constrained in that every token can only attend to its left context. Formally, the objective in this stage is to minimize the following negative likelihood: LGP T = − |u| X logP (ut |u<t ), (1) P (ut |u<t ) = softmax(HL t W + b), (2) notable work for dialog generation (Zhou et al., 2018). To leverage commonsense knowledge in pretrained language models, we resort to existing large-scale knowledge bases ConceptNet (Li et al., 2016b) and ATOMIC (Sap et al., 2019). The ConceptNet dataset2 consists of triples obtained from the Open Mind Common Sense entries in ConceptNet 5 (Speer and Havasi, 2012). It contains 34 relations in total and represents each knowledge triple by R = (h, r, t), meaning that head concept h has the relation r with tail concept t for example, (cross street, Causes, accident). And the ATOMIC dataset3 is an atlas of everyday commonsense reasoning containing a mass of textual description of inferential knowledge organized as typed if-then triples. For example, a typical if-then triple is (PersonX pays P"
2020.tacl-1.7,P11-2057,0,0.017414,"d events to simplify the dependencies between sentences (Ji et al., 2017; Clark et al., 2018). Another line is to decompose story generation into separate steps (Martin et al., 2018; Fan et al., 2018; Wang et al., 2016; Xu et al., 2018; Yao et al., 2019; Fan et al., 2019). These models usually focused on first planning story sketches and then generating sentences from the sketches. However, improving pretrained models to generate commonsense stories is yet to be well investigated. 2.3 Commonsense Knowledge Incorporating commonsense knowledge is necessary and beneficial for language inference (LoBue and Yates, 2011; Bowman et al., 2015; Rashkin et al., 2018b), reading comprehension (Mihaylov and Frank, 2018; Rashkin et al., 2018a), and particularly for open-ended language generation, which usually requires external knowledge to enrich the limited source information. Commonsense knowledge has been demonstrated to significantly improve dialogue generation (Zhou et al., 2018), story ending generation (Guan et al., 2019), and essay generation from given topics (Yang et al., 2019b). And recently, some work also attempted to integrate external commonsense knowledge into pretrained models such as BERT (Devlin"
2020.tacl-1.7,P19-1373,0,0.0670514,"e pretraining models have been widely developed in various NLP tasks. Some work leveraged pretraining to provide better language representations at the word level (Mikolov et al., 2013; Pennington et al., 2014; Peters et al., 2018) or sentence level (Le and Mikolov, 2014; Kiros et al., 2015) for various downstream task-specific architectures. However, Radford et al. (2018) and Devlin et al. (2018) suggest that these complex task-specific architectures are no longer necessary, and it is sufficient to merely fine-tune pretrained task-independent transformer language models for downstream tasks. Mehri et al. (2019) explored different pretraining methods based on language models for dialogue context representation learning. Furthermore, Radford et al. (2019) demonstrate pretrained language models (i.e., GPT-2) can perform downstream tasks better than state-of-the-art models even in a zero-shot setting (i.e., without any finetuning on task-specific data). Wolf et al. (2019) fine-tuned GPT-2 for personalized conversation generation, which obtains very competitive results in the challenge. However, as previous studies (See et al., 2019; Holtzman et al., 2019) observed, transferring GPT-2 directly to open-en"
2020.tacl-1.7,D17-1195,0,0.0376794,"able at https:// github.com/thu-coai/CommonsenseStoryGen, and demo is available at http://coai.cs.tsinghua. edu.cn/static/CommonsenseStoryGen. 94 et al., 2014), we build our model based on GPT-2 because of its simplicity and broad applicability. short text descriptions (Jain et al., 2017). Different from these studies, we consider the setting of open-ended story generation from only a limited leading context in this paper. For this task, prior studies have attempted to build specific sentence representations by modeling story entities and events to simplify the dependencies between sentences (Ji et al., 2017; Clark et al., 2018). Another line is to decompose story generation into separate steps (Martin et al., 2018; Fan et al., 2018; Wang et al., 2016; Xu et al., 2018; Yao et al., 2019; Fan et al., 2019). These models usually focused on first planning story sketches and then generating sentences from the sketches. However, improving pretrained models to generate commonsense stories is yet to be well investigated. 2.3 Commonsense Knowledge Incorporating commonsense knowledge is necessary and beneficial for language inference (LoBue and Yates, 2011; Bowman et al., 2015; Rashkin et al., 2018b), read"
2020.tacl-1.7,N16-1098,0,0.503158,"as trying to get home but the other passengers would not let her go. He thought she was going to die because of her weight. She was trying to get home but the other passengers would not let her go. The bus driver would not let her go. Fine-tuned GPT-2: I was on my way to a party. I was on my way to a party and I ’d gotten out of my seat, and started driving. I got a flat tire, so I stopped driving. I drove to the party and had a great time. Table 1: Story examples generated by human and GPT-2 models. The stories written by the pretrained GPT-2 and fine-tuned GPT-2 (post-trained on ROCStories [Mostafazadeh et al., 2016b]) suffer from repetition (in italic), bad inter-sentence coherence to the context (e.g., ignoring key entities such as accident in bold), as well as conflicting logic (underlined, e.g., first stopped driving and then drove to the party), in spite of their good fluency and intra-sentence coherence. • We propose a knowledge-enhanced pretraining model for commonsense story generation by extending GPT-2 with external commonsense knowledge. The model is post-trained on the knowledge examples constructed from ConceptNet and ATOMIC, thereby improving long-range coherence of generated stories. • To"
2020.tacl-1.7,W16-2505,0,0.0960944,"as trying to get home but the other passengers would not let her go. He thought she was going to die because of her weight. She was trying to get home but the other passengers would not let her go. The bus driver would not let her go. Fine-tuned GPT-2: I was on my way to a party. I was on my way to a party and I ’d gotten out of my seat, and started driving. I got a flat tire, so I stopped driving. I drove to the party and had a great time. Table 1: Story examples generated by human and GPT-2 models. The stories written by the pretrained GPT-2 and fine-tuned GPT-2 (post-trained on ROCStories [Mostafazadeh et al., 2016b]) suffer from repetition (in italic), bad inter-sentence coherence to the context (e.g., ignoring key entities such as accident in bold), as well as conflicting logic (underlined, e.g., first stopped driving and then drove to the party), in spite of their good fluency and intra-sentence coherence. • We propose a knowledge-enhanced pretraining model for commonsense story generation by extending GPT-2 with external commonsense knowledge. The model is post-trained on the knowledge examples constructed from ConceptNet and ATOMIC, thereby improving long-range coherence of generated stories. • To"
2020.tacl-1.7,P02-1040,0,0.107429,"ch sentence with RAKE algorithm (Rose et al., 2010). Skeleton-based Model with Reinforcement Learning (SKRL): The model first generates a compressed story including the most critical phrases, called skeleton, and then generates a story conditioned upon the skeleton. The skeleton is automatically learned by reinforcement learning (Xu et al., 2018). 4.4 Automatic Evaluation Evaluation Metrics We adopted the following automatic metrics to evaluate the generation performance in the entire test set. (1) Perplexity (PPL). Smaller perplexity scores indicate better fluency in general. (2) BLEU. BLEU (Papineni et al., 2002) evaluates n-gram overlap between a generated story and a human-written story. However, BLEU is usually inappropriate for openended text generation (Fan et al., 2018) because there are multiple plausible stories for the same input but only one story is given in the dataset. And BLEU scores will become extremely low for large n. We thus experimented with n = 1,2. (3) Coverage. To access the effect of incorporating commonsense knowledge, we calculated the coverage score as the average number of commonsense triples matched in each generated story, which requires both head and tail entities/events"
2020.tacl-1.7,D14-1162,0,0.0837457,"on as input in commonsense knowledge graphs, that is, automatic knowledge base construction. However, the low novelty of the generated objects showed that it could still be difficult for GPT-2 to generate commonsense texts solely based on its implicit knowledge. Therefore, we target integrating external knowledge into GPT-2 for generating more reasonable commonsense stories. 2.2 Pretraining Recently, large-scale pretraining models have been widely developed in various NLP tasks. Some work leveraged pretraining to provide better language representations at the word level (Mikolov et al., 2013; Pennington et al., 2014; Peters et al., 2018) or sentence level (Le and Mikolov, 2014; Kiros et al., 2015) for various downstream task-specific architectures. However, Radford et al. (2018) and Devlin et al. (2018) suggest that these complex task-specific architectures are no longer necessary, and it is sufficient to merely fine-tune pretrained task-independent transformer language models for downstream tasks. Mehri et al. (2019) explored different pretraining methods based on language models for dialogue context representation learning. Furthermore, Radford et al. (2019) demonstrate pretrained language models (i.e."
2020.tacl-1.7,N18-1202,0,0.015855,"e knowledge graphs, that is, automatic knowledge base construction. However, the low novelty of the generated objects showed that it could still be difficult for GPT-2 to generate commonsense texts solely based on its implicit knowledge. Therefore, we target integrating external knowledge into GPT-2 for generating more reasonable commonsense stories. 2.2 Pretraining Recently, large-scale pretraining models have been widely developed in various NLP tasks. Some work leveraged pretraining to provide better language representations at the word level (Mikolov et al., 2013; Pennington et al., 2014; Peters et al., 2018) or sentence level (Le and Mikolov, 2014; Kiros et al., 2015) for various downstream task-specific architectures. However, Radford et al. (2018) and Devlin et al. (2018) suggest that these complex task-specific architectures are no longer necessary, and it is sufficient to merely fine-tune pretrained task-independent transformer language models for downstream tasks. Mehri et al. (2019) explored different pretraining methods based on language models for dialogue context representation learning. Furthermore, Radford et al. (2019) demonstrate pretrained language models (i.e., GPT-2) can perform d"
2020.tacl-1.7,K19-1079,0,0.320773,"a University, Beijing 100084, China 2 School of Software, Beihang University, Beijing, China 1 Institute for Artificial Intelligence, State Key Lab of Intelligent Technology and Systems 1 Beijing National Research Center for Information Science and Technology j-guan19@mails.tsinghua.edu.cn,f-huang18@mails.tsinghua.edu.cn, extsuioku@gmail.com, zxy-dcs@tsinghua.edu.cn, aihuang@tsinghua.edu.cn Abstract are still struggling to plan a coherent plot and maintain a reasonable event sequence throughout the story, or they are often biased towards generating a limited set of stories with generic plots (See et al., 2019) (e.g., I have a great time), even when using the powerful generative model OpenAI’s GPT-2 (Radford et al., 2019), as shown in Table 1. Pretrained GPT-2 has been shown to capture useful semantic and syntactic features (Alt et al., 2019), as demonstrated by state-of-theart performance on some generation tasks such as machine translation and text summarization (Radford et al., 2019). However, compared with such tasks whose source inputs have contained sufficient information to generate desired target texts, story generation is a typical openended generation task, where only very limited informat"
2020.tacl-1.7,D19-1321,1,0.78663,"re are multiple plausible stories for the same input but only one story is given in the dataset. And BLEU scores will become extremely low for large n. We thus experimented with n = 1,2. (3) Coverage. To access the effect of incorporating commonsense knowledge, we calculated the coverage score as the average number of commonsense triples matched in each generated story, which requires both head and tail entities/events appears in the same story. (4) Repetition. We measured the redundancy of stories by computing repetition-4, the percentage of generated stories that repeat at least one 4-gram (Shao et al., 2019). (5) Distinct. To measure the generation diversity, we adopted distinct-4 (Li et al., 2016a), the ratio of distinct 4-grams to all the generated 4-grams. Decomposed Model with Semantic Role Labeling (DSRL): It first generates a predicateargument structure conditioned upon the beginning and then generates a story by surface realization on top of the structure. The structures are identified by semantic role labelling (Fan et al., 2019). We also made comparisons with GPT-2 in different settings as follows: GPT-2 (Scratch): The network architecture is the same as GPT-2, but the model is only trai"
2020.tacl-1.7,speer-havasi-2012-representing,0,0.235598,"e knowledge for expanding a reasonable story, handling the causal relationships, as well as deciding the temporal orders between entities and events in context. Explicitly introducing external commonsense knowledge has been shown helpful to improve language understanding and long-range coherence of generated texts (Zhou et al., 2018; Guan et al., 2019; Yang et al., 2019b). For example, for the entities in the given context of Table 1, many potentially related concepts (e.g., run over, cross street) can be inferred and predicted based on external commonsense knowledge bases such as ConceptNet (Speer and Havasi, 2012) and ATOMIC (Sap et al., 2019). These knowledge bases contain abundant semantic knowledge of concepts and inferential knowledge for commonsense reasoning. We enhance GPT-2 with such knowledge by post-training the model on the knowledge examples constructed from • We conduct extensive experiments with automatic and manual evaluation. Results show that our model can generate more reasonable stories than strong baselines, particularly in terms of logicality and global coherence.1 2 Related Work 2.1 Neural Story Generation Many existing neural story generation models generated stories by condition"
2020.tacl-1.7,P18-1213,0,0.0457733,"Missing"
2020.tacl-1.7,P18-1043,0,0.0289463,"n sentences (Ji et al., 2017; Clark et al., 2018). Another line is to decompose story generation into separate steps (Martin et al., 2018; Fan et al., 2018; Wang et al., 2016; Xu et al., 2018; Yao et al., 2019; Fan et al., 2019). These models usually focused on first planning story sketches and then generating sentences from the sketches. However, improving pretrained models to generate commonsense stories is yet to be well investigated. 2.3 Commonsense Knowledge Incorporating commonsense knowledge is necessary and beneficial for language inference (LoBue and Yates, 2011; Bowman et al., 2015; Rashkin et al., 2018b), reading comprehension (Mihaylov and Frank, 2018; Rashkin et al., 2018a), and particularly for open-ended language generation, which usually requires external knowledge to enrich the limited source information. Commonsense knowledge has been demonstrated to significantly improve dialogue generation (Zhou et al., 2018), story ending generation (Guan et al., 2019), and essay generation from given topics (Yang et al., 2019b). And recently, some work also attempted to integrate external commonsense knowledge into pretrained models such as BERT (Devlin et al., 2018) to enhance language represent"
2020.tacl-1.7,C16-1100,0,0.0422215,"Missing"
2020.tacl-1.7,D18-1462,0,0.0892502,"build our model based on GPT-2 because of its simplicity and broad applicability. short text descriptions (Jain et al., 2017). Different from these studies, we consider the setting of open-ended story generation from only a limited leading context in this paper. For this task, prior studies have attempted to build specific sentence representations by modeling story entities and events to simplify the dependencies between sentences (Ji et al., 2017; Clark et al., 2018). Another line is to decompose story generation into separate steps (Martin et al., 2018; Fan et al., 2018; Wang et al., 2016; Xu et al., 2018; Yao et al., 2019; Fan et al., 2019). These models usually focused on first planning story sketches and then generating sentences from the sketches. However, improving pretrained models to generate commonsense stories is yet to be well investigated. 2.3 Commonsense Knowledge Incorporating commonsense knowledge is necessary and beneficial for language inference (LoBue and Yates, 2011; Bowman et al., 2015; Rashkin et al., 2018b), reading comprehension (Mihaylov and Frank, 2018; Rashkin et al., 2018a), and particularly for open-ended language generation, which usually requires external knowledge"
2020.tacl-1.7,D16-1023,0,0.0130188,"previous studies (See et al., 2019; Holtzman et al., 2019) observed, transferring GPT-2 directly to open-ended text generation still suffers from several issues such as repetition or lack of knowledge and inter-sentence coherence with different decoding algorithms. Besides, although Song et al. (2019) and Dong et al. (2019) extended the language model to support an encoder-decoder framework (Sutskever 2.4 Multi-Task Learning Incorporating other auxiliary task objectives to complement the primary goal has been shown to improve the performance in many NLP tasks such as sentiment classification (Yu and Jiang, 2016) and conversation generation (Zhao et al., 2017). Recently, multi-task learning was also used to pretrain language models to capture dependencies in context (Devlin et al., 2018; Mehri et al., 2019) and further improve pretrained models’ representation power during fine-tuning (Wolf et al., 2019). 95 3 Methodology The task in this work can be defined as follows: Given a one-sentence story beginning X as the leading context, the model should continue to complete a K -sentence story Y with a reasonable plot. The sentences in a generated story should have reasonable logical connections, causal re"
2020.tacl-1.7,P19-1139,0,0.0511831,"Missing"
2020.tacl-1.7,P19-1226,0,0.376298,"istinguish true stories from auto-constructed fake stories. The auxiliary task makes the model implicitly capture the causal, temporal dependencies between sentences and inter-sentence coherence, and lead to less repetition. dependent commonsense knowledge for expanding a reasonable story, handling the causal relationships, as well as deciding the temporal orders between entities and events in context. Explicitly introducing external commonsense knowledge has been shown helpful to improve language understanding and long-range coherence of generated texts (Zhou et al., 2018; Guan et al., 2019; Yang et al., 2019b). For example, for the entities in the given context of Table 1, many potentially related concepts (e.g., run over, cross street) can be inferred and predicted based on external commonsense knowledge bases such as ConceptNet (Speer and Havasi, 2012) and ATOMIC (Sap et al., 2019). These knowledge bases contain abundant semantic knowledge of concepts and inferential knowledge for commonsense reasoning. We enhance GPT-2 with such knowledge by post-training the model on the knowledge examples constructed from • We conduct extensive experiments with automatic and manual evaluation. Results show t"
2020.tacl-1.7,P17-1061,0,0.0273739,"l., 2019) observed, transferring GPT-2 directly to open-ended text generation still suffers from several issues such as repetition or lack of knowledge and inter-sentence coherence with different decoding algorithms. Besides, although Song et al. (2019) and Dong et al. (2019) extended the language model to support an encoder-decoder framework (Sutskever 2.4 Multi-Task Learning Incorporating other auxiliary task objectives to complement the primary goal has been shown to improve the performance in many NLP tasks such as sentiment classification (Yu and Jiang, 2016) and conversation generation (Zhao et al., 2017). Recently, multi-task learning was also used to pretrain language models to capture dependencies in context (Devlin et al., 2018; Mehri et al., 2019) and further improve pretrained models’ representation power during fine-tuning (Wolf et al., 2019). 95 3 Methodology The task in this work can be defined as follows: Given a one-sentence story beginning X as the leading context, the model should continue to complete a K -sentence story Y with a reasonable plot. The sentences in a generated story should have reasonable logical connections, causal relationships, and temporal dependencies with each"
2020.tacl-1.7,P19-1193,0,0.423439,"istinguish true stories from auto-constructed fake stories. The auxiliary task makes the model implicitly capture the causal, temporal dependencies between sentences and inter-sentence coherence, and lead to less repetition. dependent commonsense knowledge for expanding a reasonable story, handling the causal relationships, as well as deciding the temporal orders between entities and events in context. Explicitly introducing external commonsense knowledge has been shown helpful to improve language understanding and long-range coherence of generated texts (Zhou et al., 2018; Guan et al., 2019; Yang et al., 2019b). For example, for the entities in the given context of Table 1, many potentially related concepts (e.g., run over, cross street) can be inferred and predicted based on external commonsense knowledge bases such as ConceptNet (Speer and Havasi, 2012) and ATOMIC (Sap et al., 2019). These knowledge bases contain abundant semantic knowledge of concepts and inferential knowledge for commonsense reasoning. We enhance GPT-2 with such knowledge by post-training the model on the knowledge examples constructed from • We conduct extensive experiments with automatic and manual evaluation. Results show t"
2021.acl-demo.21,D15-1075,0,0.0408833,"rs, 1024 hidden size, 16 self-attention heads and 317 million parameters. We used fairseq5 for training of the models. 2.2 Input Processor The input text of a player will firstly be checked by a toxicity detection service6 to avoid potential risks. It is then processed by a semantic similarity detection model to determine if it is too semantically close to the plot goal. This is to avoid making it too easy for players to reach the plot goal. The semantic similarity detection model is based on Sentence-Bert(Reimers and Gurevych, 2019), trained on the combination of several Chinese NLI datasets(Bowman et al., 2015; Williams et al., 2018; Hu et al., 2020). The virtual adversarial training(Zhu et al., 2020) is also adopted. This approach improves the generalization of the model by adding small perturbations to the input embeddings. For every plot goal, at least three textual descriptions of that goal should be prepared. The input text will be compared with all the textual descriptions of current plot goal. If any of the similarity scores is above a certain threshold, the player will receive a message telling the player to input again. After the input text has passed the toxicity detection and semantic si"
2021.acl-demo.21,N19-1423,0,0.0183771,") Determining whether a story contains a specified plot is a typical textual entailment problem. However. because players can create story scripts and submit them to the game community, it is intractable to create a dataset dealing with numerous possible plot goals. So we had to approach the problem from a different angle. We argue that it is easier to solve this problem by transforming it into a problem similar to Next Sentence Prediction (NSP), i.e., determining whether a plot goal can be coherently connected to a generated story. It is well known that the original NSP task proposed in BERT(Devlin et al., 2019) is too easy, many latest pre-trained language models have abandoned it(Liu et al., 2019; Lan et al., 2019). We argue that discriminating the randomly sampled negative examples is relatively easy so we adopt a novel strategy to enhance the difficulty of NSP. When generating the training dataset, in addition to the randomly sampled sentences, we also take the next sentence of next sentence as a negative sample with a certain probability. We finetuned the pre-trained Roberta-large based model as described in Section 2.1 on this generated dataset. The finetuned model is then used as a discriminat"
2021.acl-demo.21,P84-1044,0,0.482682,"Missing"
2021.acl-demo.21,2020.findings-emnlp.314,0,0.099869,"Missing"
2021.acl-demo.21,2021.ccl-1.108,0,0.049528,"Missing"
2021.acl-demo.21,D19-1410,0,0.0115118,"idirectional transformer model(Vaswani et al., 2017) on the same dataset. It has 24 layers, 1024 hidden size, 16 self-attention heads and 317 million parameters. We used fairseq5 for training of the models. 2.2 Input Processor The input text of a player will firstly be checked by a toxicity detection service6 to avoid potential risks. It is then processed by a semantic similarity detection model to determine if it is too semantically close to the plot goal. This is to avoid making it too easy for players to reach the plot goal. The semantic similarity detection model is based on Sentence-Bert(Reimers and Gurevych, 2019), trained on the combination of several Chinese NLI datasets(Bowman et al., 2015; Williams et al., 2018; Hu et al., 2020). The virtual adversarial training(Zhu et al., 2020) is also adopted. This approach improves the generalization of the model by adding small perturbations to the input embeddings. For every plot goal, at least three textual descriptions of that goal should be prepared. The input text will be compared with all the textual descriptions of current plot goal. If any of the similarity scores is above a certain threshold, the player will receive a message telling the player to inp"
2021.acl-demo.21,K19-1079,0,0.0443016,"Missing"
2021.acl-demo.21,N18-1101,0,0.0170239,"16 self-attention heads and 317 million parameters. We used fairseq5 for training of the models. 2.2 Input Processor The input text of a player will firstly be checked by a toxicity detection service6 to avoid potential risks. It is then processed by a semantic similarity detection model to determine if it is too semantically close to the plot goal. This is to avoid making it too easy for players to reach the plot goal. The semantic similarity detection model is based on Sentence-Bert(Reimers and Gurevych, 2019), trained on the combination of several Chinese NLI datasets(Bowman et al., 2015; Williams et al., 2018; Hu et al., 2020). The virtual adversarial training(Zhu et al., 2020) is also adopted. This approach improves the generalization of the model by adding small perturbations to the input embeddings. For every plot goal, at least three textual descriptions of that goal should be prepared. The input text will be compared with all the textual descriptions of current plot goal. If any of the similarity scores is above a certain threshold, the player will receive a message telling the player to input again. After the input text has passed the toxicity detection and semantic similarity detection, it"
2021.acl-demo.21,2020.emnlp-demos.12,1,0.823771,"Missing"
2021.acl-long.192,D18-1316,0,0.0188701,"rovide an automatic way to test the LU robustness in task-oriented dialog. Various textual adversarial attacks (Zhang et al., 2020a) have been proposed and received increasing attentions these years to measure the robustness of a victim model. Most attack methods perform whitebox attacks (Papernot et al., 2016; Li et al., 2019; Ebrahimi et al., 2018) based on the model’s internal structure or gradient signals. Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018). However, all these methods address random perturbation but do not consider linguistic phenomena to evaluate the real-life generalization of LU models. While data augmentation can be an efficient method to address data sparsity, it can improve the generalization abilities and measure the model robustness as well (Eshghi et al., 2017). Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018). Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou"
2021.acl-long.192,D17-1236,0,0.0281074,"et al., 2018) based on the model’s internal structure or gradient signals. Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018). However, all these methods address random perturbation but do not consider linguistic phenomena to evaluate the real-life generalization of LU models. While data augmentation can be an efficient method to address data sparsity, it can improve the generalization abilities and measure the model robustness as well (Eshghi et al., 2017). Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018). Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou, 2019) including replacement, insertion, and deletion were also proposed to increase language variety. Other studies (Shah et al., 2019; Xu and Sarikaya, 2014) worked on the out-of-vocabulary problem when facing unseen user expression. Some other research 9 See appendix for case study. focused on building robust spoken language under"
2021.acl-long.192,2020.findings-emnlp.358,0,0.209696,"noisy data, therefore can be used for future research to test the LU robustness in task-oriented dialog1 . 2 Robustness Type We summarize several common interleaved challenges in language understanding from three aspects, as shown in Fig. 1b: Language Variety A modern dialog system in a text form has to interact with a large variety of real users. The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020). Speech Characteristics The dialog system can take voice input or typed text, but these two differ in many ways. For example, written language 1 The data, toolkit, and codes are available at https: //github.com/thu-coai/LAUG, and will be merged into https://github.com/thu-coai/ConvLab-2 (Zhu et al., 2020). I want to go to Leicester. Write Worker Text Data (a) Dataset construction User Crowd I’m planning a trip to Leicester. A ticket to Leicester, please Diverse Input I want to um go to Lester. Speech Real User ASR I wamt to go to Leicester. Noisy Input Random Noise (b) Real-world application"
2021.acl-long.192,D18-1547,0,0.150862,"n in this paper to approximate the natural perturbations to existing data. LAUG is a black-box testing toolkit on LU robustness composed of four data augmentation methods, including word perturbation, text paraphrasing, speech recognition, and speech disfluency. We instantiate LAUG on two dialog corpora 2467 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2467–2480 August 1–6, 2021. ©2021 Association for Computational Linguistics Frames (El Asri et al., 2017) and MultiWOZ (Budzianowski et al., 2018) to demonstrate the toolkit’s effectiveness. Quality evaluation by annotators indicates that the utterances augmented by LAUG are reasonable and appropriate with regards to each augmentation approach’s target. A number of LU models with different categories and training paradigms are tested as base models with in-depth analysis. Experiments indicate a sharp performance decline in most baselines in terms of each robustness aspect. Real user evaluation further verifies that LAUG well reflects real-world robustness issues. Since our toolkit is model-agnostic and does not require model parameters"
2021.acl-long.192,N18-2118,0,0.09076,"veals critical robustness issues in state-of-the-art models. The augmented dataset through LAUG can be used to facilitate future research on the robustness testing of language understanding in task-oriented dialog. 1 Introduction Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems. While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use. ∗ † Equal contribution. Corresponding author. Real dialogs between human participants involve language phenomena that do not contribute so much to the intent of communication. As shown in Fig. 1, user expressions can be of high lexical and syntactic diversity when a system is deployed to users; typed texts may differ significantly from those recognized from voice speech; interaction environments may be full of chaos and even users themselves may"
2021.acl-long.192,N19-1423,0,0.0613054,"Missing"
2021.acl-long.192,P16-1154,0,0.0498796,"Missing"
2021.acl-long.192,D19-1461,0,0.0151897,"ness issues. 2474 8 See appendix for details on real data collection. This again demonstrates that real user evaluation is more challenging than the original test set9 . 6 Related Work Robustness in LU has always been a challenge in task-oriented dialog. Several studies have investigated the model’s sensitivity to the collected data distribution, in order to prevent models from overfitting to the training data and improve robustness in the real world. Kang et al. (2018) collected dialogs with templates and paraphrased with crowdsourcing to achieve high coverage and diversity in training data. Dinan et al. (2019) proposed a training schema that involves human in the loop in dialog systems to enhance the model’s defense against human attack in an iterative way. Ganhotra et al. (2020) injected natural perturbation into the dialog history manually to refine over-controlled data generated through crowd-sourcing. All these methods require laborious human intervention. This paper aims to provide an automatic way to test the LU robustness in task-oriented dialog. Various textual adversarial attacks (Zhang et al., 2020a) have been proposed and received increasing attentions these years to measure the robustne"
2021.acl-long.192,P18-2006,0,0.0215624,"against human attack in an iterative way. Ganhotra et al. (2020) injected natural perturbation into the dialog history manually to refine over-controlled data generated through crowd-sourcing. All these methods require laborious human intervention. This paper aims to provide an automatic way to test the LU robustness in task-oriented dialog. Various textual adversarial attacks (Zhang et al., 2020a) have been proposed and received increasing attentions these years to measure the robustness of a victim model. Most attack methods perform whitebox attacks (Papernot et al., 2016; Li et al., 2019; Ebrahimi et al., 2018) based on the model’s internal structure or gradient signals. Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018). However, all these methods address random perturbation but do not consider linguistic phenomena to evaluate the real-life generalization of LU models. While data augmentation can be an efficient method to address data sparsity, it can improve the generalization abilities and measure the model robustness as well (Eshghi et al.,"
2021.acl-long.192,W17-5526,0,0.0644527,"Missing"
2021.acl-long.192,2020.acl-main.58,0,0.106511,"hemselves may introduce irrelevant noises such that the system can hardly get clean user input. Unfortunately, neural LU models are vulnerable to these natural perturbations that are legitimate inputs but not observed in training data. For example, Bickmore et al. (2018) found that popular conversational assistants frequently failed to understand real health-related scenarios and were unable to deliver adequate responses on time. Although many studies have discussed the LU robustness (Ray et al., 2018; Zhu et al., 2018; Iyyer et al., 2018; Yoo et al., 2019; Ren et al., 2019; Jin et al., 2020; He et al., 2020), there is a lack of systematic studies for real-life robustness issues and corresponding benchmarks for evaluating task-oriented dialog systems. In order to study the real-world robustness issues, we define the LU robustness from three aspects: language variety, speech characteristics and noise perturbation. While collecting dialogs from deployed systems could obtain realistic data distribution, it is quite costly and not scalable since a large number of conversational interactions with real users are required. Therefore, we propose an automatic method LAUG for Language understanding AUGmenta"
2021.acl-long.192,N18-1170,0,0.164044,"ice speech; interaction environments may be full of chaos and even users themselves may introduce irrelevant noises such that the system can hardly get clean user input. Unfortunately, neural LU models are vulnerable to these natural perturbations that are legitimate inputs but not observed in training data. For example, Bickmore et al. (2018) found that popular conversational assistants frequently failed to understand real health-related scenarios and were unable to deliver adequate responses on time. Although many studies have discussed the LU robustness (Ray et al., 2018; Zhu et al., 2018; Iyyer et al., 2018; Yoo et al., 2019; Ren et al., 2019; Jin et al., 2020; He et al., 2020), there is a lack of systematic studies for real-life robustness issues and corresponding benchmarks for evaluating task-oriented dialog systems. In order to study the real-world robustness issues, we define the LU robustness from three aspects: language variety, speech characteristics and noise perturbation. While collecting dialogs from deployed systems could obtain realistic data distribution, it is quite costly and not scalable since a large number of conversational interactions with real users are required. Therefore,"
2021.acl-long.192,N18-3005,0,0.0607249,"Missing"
2021.acl-long.192,P11-2047,0,0.0171678,"et al., 2020; Ren et al., 2019; Alzantot et al., 2018). However, all these methods address random perturbation but do not consider linguistic phenomena to evaluate the real-life generalization of LU models. While data augmentation can be an efficient method to address data sparsity, it can improve the generalization abilities and measure the model robustness as well (Eshghi et al., 2017). Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018). Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou, 2019) including replacement, insertion, and deletion were also proposed to increase language variety. Other studies (Shah et al., 2019; Xu and Sarikaya, 2014) worked on the out-of-vocabulary problem when facing unseen user expression. Some other research 9 See appendix for case study. focused on building robust spoken language understanding (Zhu et al., 2018; Henderson et al., 2012; Huang and Chen, 2019) from audio signals beyond text transcripts. Simulating ASR errors (Schatzmann et al., 2007; Park et al., 2019; Wang et al., 2020a) and speaker disfluency (Wang"
2021.acl-long.192,D19-1097,0,0.0142288,"ustness issues in state-of-the-art models. The augmented dataset through LAUG can be used to facilitate future research on the robustness testing of language understanding in task-oriented dialog. 1 Introduction Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems. While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use. ∗ † Equal contribution. Corresponding author. Real dialogs between human participants involve language phenomena that do not contribute so much to the intent of communication. As shown in Fig. 1, user expressions can be of high lexical and syntactic diversity when a system is deployed to users; typed texts may differ significantly from those recognized from voice speech; interaction environments may be full of chaos and even users themselves may introduce irrelev"
2021.acl-long.192,2020.findings-emnlp.17,0,0.0217133,"o to Cambridge . I to want go to Cambridge . I want to go to Cambridge . I want to go to Liverpool . attraction { inform (dest = Liverpool) } Table 2 shows an example of SC-EDA. Original EDA randomly performs one of the four operations, including synonym replacement, random insertion, random swap and random deletion2 . Noting that, to keep the label unchanged, words related to slot See the EDA paper for details of each operation. Text Paraphrasing The target of text paraphrasing is to generate a new utterance x0 6= x while maintaining its dialog act unchanged, i.e. y 0 = y. We applied SC-GPT (Peng et al., 2020), a finetuned language model conditioned on the dialog acts, to paraphrase the sentences as data augmentation. Specifically, it characterizes the conditional Q probability pθ (x|y) = K p (x |x k=1 θ k &lt;k , y), where x&lt;k denotes all the tokens before the k-th position. The model parameters θ are trained by maximizing the log-likelihood of pθ . DA train * { inform ( dest = Cambridge ; arrive = 20:45 ) } Text Hi, I’m looking for a train that is going to Cambridge and arriving there by 20:45, is there anything like that? DA train { inform ( dest = Cambridge ; arrive = 20:45 ) } Text Yes, to Cambri"
2021.acl-long.192,P19-1103,0,0.336295,"ay be full of chaos and even users themselves may introduce irrelevant noises such that the system can hardly get clean user input. Unfortunately, neural LU models are vulnerable to these natural perturbations that are legitimate inputs but not observed in training data. For example, Bickmore et al. (2018) found that popular conversational assistants frequently failed to understand real health-related scenarios and were unable to deliver adequate responses on time. Although many studies have discussed the LU robustness (Ray et al., 2018; Zhu et al., 2018; Iyyer et al., 2018; Yoo et al., 2019; Ren et al., 2019; Jin et al., 2020; He et al., 2020), there is a lack of systematic studies for real-life robustness issues and corresponding benchmarks for evaluating task-oriented dialog systems. In order to study the real-world robustness issues, we define the LU robustness from three aspects: language variety, speech characteristics and noise perturbation. While collecting dialogs from deployed systems could obtain realistic data distribution, it is quite costly and not scalable since a large number of conversational interactions with real users are required. Therefore, we propose an automatic method LAUG"
2021.acl-long.192,2020.acl-main.442,0,0.0491244,"me randomly picked slot values are replaced by unseen values with the same slot name in the database or crawled from web sources. For example in Table 2, “Cambridge” is replaced by “Liverpool”, where both belong to the same slot name “dest” (destination). Synonym replacement and slot value replacement aim at increasing the language variety, while random word insertion/deletion/swap test the robustness of noise perturbation. From another perspective, four operations from EDA perform an Invariance test, while slot value replacement conducts a Directional Expectation test according to CheckList (Ribeiro et al., 2020). We observe that co-reference and ellipsis frequently occurs in user utterances. Therefore, we propose different encoding strategies during paraphrasing to further evaluate each model’s capacity for context resolution. In particular, if the user mentions a certain domain for the first time in a dialog, we will insert a “*” mark into the sequential dialog act y 0 to indicate that the user tends to express without co-references or ellipsis, as shown in Table 3. Then SC-GPT is finetuned on the processed data so that it can be aware of dialog context when generating paraphrases. As a result, we f"
2021.acl-long.192,P19-1547,0,0.150644,"state-of-the-art models. The augmented dataset through LAUG can be used to facilitate future research on the robustness testing of language understanding in task-oriented dialog. 1 Introduction Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems. While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use. ∗ † Equal contribution. Corresponding author. Real dialogs between human participants involve language phenomena that do not contribute so much to the intent of communication. As shown in Fig. 1, user expressions can be of high lexical and syntactic diversity when a system is deployed to users; typed texts may differ significantly from those recognized from voice speech; interaction environments may be full of chaos and even users themselves may introduce irrelevant noises such that"
2021.acl-long.192,2020.sigdial-1.37,1,0.844353,"f language understanding models. Dialog history is first encoded as conditions (not depicted here). semantic labels of user utterances are annotated. In particular, MultiWOZ is one of the most challenging datasets due to its multi-domain setting and complex ontology, and we conduct our experiments on the latest annotation-enhanced version MultiWOZ 2.3 (Han et al., 2020), which provides cleaned annotations of user dialog acts (i.e. semantic labels). The dialog act consists of four parts: domain, intent, slot names, and slot values. The statistics of two datasets are shown in Table 6. Following Takanobu et al. (2020), we calculate overall F1 scores as evaluation metrics due to the multiintent setting in LU. Datasets # Training Dialogs # Validation / Test Dialogs # Domains / # Intents Avg. # Turns per Dialog Avg. # Tokens per Turn Avg. # DAs per Turn Frames 1,095 137 / 137 2 / 12 7.60 11.67 1.87 MultiWOZ 8,438 1,000 / 1,000 7/5 6.85 13.55 1.66 Table 6: Statistics of Frames and MultiWOZ 2.3. Only user turns U are counted here. The data are augmented with the inclusion of its copies, leading to a composite of all 4 augmentation types with equal proportion. Other setups are described in each experiment7 . Met"
2021.acl-long.192,2020.nlp4convai-1.8,0,0.0856838,"Missing"
2021.acl-long.192,N18-2050,0,0.0149794,"aspects are assembled in LAUG, which reveals critical robustness issues in state-of-the-art models. The augmented dataset through LAUG can be used to facilitate future research on the robustness testing of language understanding in task-oriented dialog. 1 Introduction Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems. While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use. ∗ † Equal contribution. Corresponding author. Real dialogs between human participants involve language phenomena that do not contribute so much to the intent of communication. As shown in Fig. 1, user expressions can be of high lexical and syntactic diversity when a system is deployed to users; typed texts may differ significantly from those recognized from voice speech; interaction environments may be full"
2021.acl-long.192,D19-1670,0,0.123751,"x2t } at dialog turn t, where each x is an utterance and m is the size of sliding window that controls the length of utilizing dialog history, the model should recognize yt , the dialog act (DA) of x2t . Empirically, we set m = 2 in the experiment. Let U, S denote the set of user/system utterances, respectively. Then, we have x2t−2i ∈ U and x2t−2i−1 ∈ S. The task of this paper is to examine different LU models whether they can predict yt correctly given a ˜ t . The perturbation is only perperturbed input X formed on user utterances. Word Perturbation Inspired by EDA (Easy Data Augmentation) (Wei and Zou, 2019), we propose its semantically conditioned version, SC-EDA, which considers task-specific augmentation operations in LU. SC-EDA injects word-level perturbation into each utterance x0 and updates its corresponding semantic label y 0 . Original DA Syno. Insert Swap Delete SVR DA I want to go to Cambridge . attraction { inform (dest = Cambridge) } I wishing to go to Cambridge . I need want to go to Cambridge . I to want go to Cambridge . I want to go to Cambridge . I want to go to Liverpool . attraction { inform (dest = Liverpool) } Table 2 shows an example of SC-EDA. Original EDA randomly perform"
2021.acl-long.192,P18-2068,0,0.0274418,"led in LAUG, which reveals critical robustness issues in state-of-the-art models. The augmented dataset through LAUG can be used to facilitate future research on the robustness testing of language understanding in task-oriented dialog. 1 Introduction Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems. While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use. ∗ † Equal contribution. Corresponding author. Real dialogs between human participants involve language phenomena that do not contribute so much to the intent of communication. As shown in Fig. 1, user expressions can be of high lexical and syntactic diversity when a system is deployed to users; typed texts may differ significantly from those recognized from voice speech; interaction environments may be full of chaos and even us"
2021.acl-long.192,D19-1375,0,0.103417,"tive of real-world noisy data, therefore can be used for future research to test the LU robustness in task-oriented dialog1 . 2 Robustness Type We summarize several common interleaved challenges in language understanding from three aspects, as shown in Fig. 1b: Language Variety A modern dialog system in a text form has to interact with a large variety of real users. The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020). Speech Characteristics The dialog system can take voice input or typed text, but these two differ in many ways. For example, written language 1 The data, toolkit, and codes are available at https: //github.com/thu-coai/LAUG, and will be merged into https://github.com/thu-coai/ConvLab-2 (Zhu et al., 2020). I want to go to Leicester. Write Worker Text Data (a) Dataset construction User Crowd I’m planning a trip to Leicester. A ticket to Leicester, please Diverse Input I want to um go to Lester. Speech Real User ASR I wamt to go to Leicester. Noisy Input Random Noise (b)"
2021.acl-long.192,2020.acl-demos.19,1,0.775832,"t with a large variety of real users. The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020). Speech Characteristics The dialog system can take voice input or typed text, but these two differ in many ways. For example, written language 1 The data, toolkit, and codes are available at https: //github.com/thu-coai/LAUG, and will be merged into https://github.com/thu-coai/ConvLab-2 (Zhu et al., 2020). I want to go to Leicester. Write Worker Text Data (a) Dataset construction User Crowd I’m planning a trip to Leicester. A ticket to Leicester, please Diverse Input I want to um go to Lester. Speech Real User ASR I wamt to go to Leicester. Noisy Input Random Noise (b) Real-world application Figure 1: Difference between dialogs collected for training and those for real-world applications. tends to be more complex and intricate with longer sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al"
2021.acl-long.192,2020.emnlp-main.66,0,0.0399352,"Missing"
2021.acl-long.237,D19-1243,0,0.0558251,"Missing"
2021.acl-long.237,2020.acl-main.679,0,0.124454,"tion (Trinh and Le, 2018; Shwartz et al., 2020; Bosselut and Choi, 2019; Tamborrino et al., 2020). Table 1 lists several typical score functions. However, these scores can be easily influenced by word frequencies, sentence structures, and other 3037 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3037–3049 August 1–6, 2021. ©2021 Association for Computational Linguistics factors, which can mislead the models and make existing methods oversensitive to lexical perturbations (Abdou et al., 2020; Tamborrino et al., 2020). Figure 1 shows two examples. The correct choices are paraphrased via synonym replacement or structure transformation. In these examples, the baseline (Pro-A) produces much lower scores for the paraphrased choices and chooses the wrong choices. Since existing methods can be easily distracted by irrelevant factors such as lexical perturbations, we argue that a commonsense question answering method should focus on the answers’ semantics and assign similar scores to synonymous choices. To this end, we introduce a novel SEmantic-based Question Answering model, SEQA, whic"
2021.acl-long.237,2020.emnlp-main.11,0,0.0152985,"ch has no restriction on the query types. Thus, Self-Talk can be applied to a wide range of domains. Despite the introduction of auxiliary information, these methods are essentially dependent on language model scores, so they are still sensitive to lexical perturbations. Besides directly using pre-trained LMs, some recent efforts have been dedicated to automatically constructing task-specific data to train commonsense reasoners in zero-shot settings. Wang et al. (2019) and Kocijan et al. (2019) provide some rules to construct labeled training data from large corpus for pronoun disambiguation. Banerjee and Baral (2020), Moghimifar et al. (2020) and Ma et al. (2020) collect training data based on knowledge bases, such as Atomic (Sap et al., 2019a). Though effective, they are limited by the specific task settings or highly dependent on the task-related knowledge bases, which makes them difficult to transfer to other commonsense reasoning tasks. 3 And it then takes the statement as a prompt to calculate the generative probability of each choice. Note that the templates for rewriting is not the focus of this paper, and hence we directly use the templates of previous work (Shwartz et al., 2020; Tamborrino et al."
2021.acl-long.237,2020.coling-main.467,0,0.0294948,"e query types. Thus, Self-Talk can be applied to a wide range of domains. Despite the introduction of auxiliary information, these methods are essentially dependent on language model scores, so they are still sensitive to lexical perturbations. Besides directly using pre-trained LMs, some recent efforts have been dedicated to automatically constructing task-specific data to train commonsense reasoners in zero-shot settings. Wang et al. (2019) and Kocijan et al. (2019) provide some rules to construct labeled training data from large corpus for pronoun disambiguation. Banerjee and Baral (2020), Moghimifar et al. (2020) and Ma et al. (2020) collect training data based on knowledge bases, such as Atomic (Sap et al., 2019a). Though effective, they are limited by the specific task settings or highly dependent on the task-related knowledge bases, which makes them difficult to transfer to other commonsense reasoning tasks. 3 And it then takes the statement as a prompt to calculate the generative probability of each choice. Note that the templates for rewriting is not the focus of this paper, and hence we directly use the templates of previous work (Shwartz et al., 2020; Tamborrino et al., 2020) for our method and"
2021.acl-long.237,N16-1098,0,0.0192474,"Evaluation results, including the original selection accuracy before attack, the accuracy after attack, the attack success rate, the percentage of perturbed words with respect to the original sentence length in successful attacks, and the semantic similarity between the original and paraphrased choices. GPT-2, RoBERTa and SRoBERTa refer to GPT-2-xlarge, RoBERTa-large (Liu et al., 2019) and SentenceRoBERTa-large, respectively. 4 4.1 Experiments 4.3 Datasets We conducted experiments on four multiplechoice commonsense question answering tasks, COPA (Roemmele et al., 2011), StoryClozeTest (SCT) (Mostafazadeh et al., 2016), SocialIQA (Sap et al., 2019b) and CosmosQA (Huang et al., 2019). For each instance, only one choice is correct. See Appendix for more description about datasets. For COPA, we reported the results on its test set. As the test sets of another three datasets are hidden, for convenience of analysis, we reported the experiment results on their development sets. 4.2 Baselines We employed five strong baselines. Table 1 shows three of them, Pro-A, Pro-Q and MI-QA. There is no explicit auxiliary information used in these three methods, while another two baselines rely on explicit information suppleme"
2021.acl-long.237,2020.findings-emnlp.369,0,0.020767,"fore, it is vital to study unsupervised commonsense question answering without relying on any labeled downstream task data. In this paper, we investigate multiple-choice commonsense question answering tasks in an unsupervised setting: given a question and a set of answer choices, a model is required to predict the most reasonable answer choice for the question, but without access to any labeled task data. Introduction Pre-trained language models have been widely used for commonsense question answering. Finetuning pre-trained models on task-specific data produces many state-of-the-art results (Wang et al., 2020; * Equal † contribution Corresponding author: Minlie Huang. Many existing unsupervised methods tackle these tasks by scoring each answer choice using a language model, e.g., estimating the generative probability of the answer choice conditioned on the question (Trinh and Le, 2018; Shwartz et al., 2020; Bosselut and Choi, 2019; Tamborrino et al., 2020). Table 1 lists several typical score functions. However, these scores can be easily influenced by word frequencies, sentence structures, and other 3037 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and t"
2021.acl-long.237,D14-1162,0,0.0871353,"Missing"
2021.acl-long.237,N19-1094,0,0.021734,"generalize to different domains. Self-Talk (Shwartz et al., 2020) breaks the limit by extracting knowledge from GPT-2 (Radford et al., 2019), which has no restriction on the query types. Thus, Self-Talk can be applied to a wide range of domains. Despite the introduction of auxiliary information, these methods are essentially dependent on language model scores, so they are still sensitive to lexical perturbations. Besides directly using pre-trained LMs, some recent efforts have been dedicated to automatically constructing task-specific data to train commonsense reasoners in zero-shot settings. Wang et al. (2019) and Kocijan et al. (2019) provide some rules to construct labeled training data from large corpus for pronoun disambiguation. Banerjee and Baral (2020), Moghimifar et al. (2020) and Ma et al. (2020) collect training data based on knowledge bases, such as Atomic (Sap et al., 2019a). Though effective, they are limited by the specific task settings or highly dependent on the task-related knowledge bases, which makes them difficult to transfer to other commonsense reasoning tasks. 3 And it then takes the statement as a prompt to calculate the generative probability of each choice. Note that the t"
2021.acl-long.237,D19-1250,0,0.0572008,"Missing"
2021.acl-long.237,P19-1487,0,0.013742,"2018; Tamborrino et al., 2020) , which is denoted as Probability-Q (Pro-Q) in Table 1. Some recent work claims that external knowledge can benefit commonsense reasoning. Besides static knowledge bases (KBs), such as ConceptNet (Speer et al., 2017) and Atomic (Sap et al., 2019a), there are also numerous studies treating LMs as dynamic KBs. Petroni et al. (2019) shows that LMs can be used for KB completion. And Davison et al. (2019) shows that BERT can distinguish true and fake ConceptNet triplets. Further, the extracted knowledge can work as complementary information for answering a question. Rajani et al. (2019) proposes a model for Com3038 1 PBERT (Q|A) , Q|Q| i PBERT (Qi |Q/i , A). monSenseQA (Talmor et al., 2019) that generates explanations for questions, which are then used as additional inputs. The shortcoming of this approach is that it requires collecting human explanations for each new dataset to fine-tune LMs. Some following researches explore unsupervised explanation/knowledge generator. CGA (Bosselut and Choi, 2019) employs COMET (Bosselut et al., 2019) to generate intermediate inferences which are then used to score the choice. However, COMET is limited by a small set of question types so"
2021.acl-long.237,D19-1410,0,0.0762639,"probability of observing the choice’s semantics. A choice’s semantic score can be obtained by summing the generative probabilities of sentences that have the same semantic meanings with the choice, where the sentences are called the choice’s supporters. However, it is hard to obtain the supporters which have exactly the same semantic meanings with the choice, so we reformulate the semantic score into a soft version as explained in Section 3.2. Each supporter is weighed by the semantic similarity to the answer choice, which can be computed with some off-the-shelf models, such as SentenceBERT (Reimers and Gurevych, 2019). Since the supporters and their weights depend on the semantics rather than the surface form of the answer choice, by this means, the effects of the distracting factors can be largely suppressed. Moreover, synonymous choices are likely to share the same set of supporters, so their scores are expected to be stably close. Our contributions in this paper are summarized as follows: • We propose a semantic-based question answering model (SEQA) for robust commonsense question answering in an unsupervised setting. Instead of directly scoring the answer choices, our method first generates some plausi"
2021.acl-long.237,D19-1454,0,0.0543383,"Missing"
2021.acl-long.237,2020.emnlp-main.373,0,0.0376012,"Missing"
2021.acl-long.237,N19-1421,0,0.0193007,"laims that external knowledge can benefit commonsense reasoning. Besides static knowledge bases (KBs), such as ConceptNet (Speer et al., 2017) and Atomic (Sap et al., 2019a), there are also numerous studies treating LMs as dynamic KBs. Petroni et al. (2019) shows that LMs can be used for KB completion. And Davison et al. (2019) shows that BERT can distinguish true and fake ConceptNet triplets. Further, the extracted knowledge can work as complementary information for answering a question. Rajani et al. (2019) proposes a model for Com3038 1 PBERT (Q|A) , Q|Q| i PBERT (Qi |Q/i , A). monSenseQA (Talmor et al., 2019) that generates explanations for questions, which are then used as additional inputs. The shortcoming of this approach is that it requires collecting human explanations for each new dataset to fine-tune LMs. Some following researches explore unsupervised explanation/knowledge generator. CGA (Bosselut and Choi, 2019) employs COMET (Bosselut et al., 2019) to generate intermediate inferences which are then used to score the choice. However, COMET is limited by a small set of question types so that CGA is difficult to generalize to different domains. Self-Talk (Shwartz et al., 2020) breaks the lim"
2021.acl-long.237,2020.acl-main.357,0,0.0465758,"Missing"
2021.acl-long.260,P17-1147,0,0.0212785,"tions. From the results listed in Table 4, we observe that ERICA outperforms baselines in both settings, indicating that ERICA can better understand entities and their relations in the documents and extract the true answer according to queries. The significant improvements in the masked setting also indicate that ERICA can better perform multi-hop reasoning to synthesize and analyze information from contexts, instead of relying on entity mention “shortcuts” (Jiang and Bansal, 2019). Extractive QA For extractive QA, we adopt three widely-used datasets: SQuAD (Rajpurkar et al., 2016), TriviaQA (Joshi et al., 2017) and NaturalQA (Kwiatkowski et al., 2019) in MRQA (Fisch et al., 2019) to evaluate ERICA in various domains. Since MRQA does not provide the test set for each dataset, we randomly split the original dev set into two halves and obtain the new dev/test set. We follow the QA setting of BERT (Devlin et al., 2018): we concatenate the given question and passage into one long sequence, encode the sequence by PLMs and adopt two classifiers to predict the start and end index of the answer. We choose BERT, RoBERTa, MTB and CP as baselines. From the results listed in Table 5, we observe that ERICA outper"
2021.acl-long.260,Q19-1026,0,0.0120968,"able 4, we observe that ERICA outperforms baselines in both settings, indicating that ERICA can better understand entities and their relations in the documents and extract the true answer according to queries. The significant improvements in the masked setting also indicate that ERICA can better perform multi-hop reasoning to synthesize and analyze information from contexts, instead of relying on entity mention “shortcuts” (Jiang and Bansal, 2019). Extractive QA For extractive QA, we adopt three widely-used datasets: SQuAD (Rajpurkar et al., 2016), TriviaQA (Joshi et al., 2017) and NaturalQA (Kwiatkowski et al., 2019) in MRQA (Fisch et al., 2019) to evaluate ERICA in various domains. Since MRQA does not provide the test set for each dataset, we randomly split the original dev set into two halves and obtain the new dev/test set. We follow the QA setting of BERT (Devlin et al., 2018): we concatenate the given question and passage into one long sequence, encode the sequence by PLMs and adopt two classifiers to predict the start and end index of the answer. We choose BERT, RoBERTa, MTB and CP as baselines. From the results listed in Table 5, we observe that ERICA outperforms all baselines, indicating that thro"
2021.acl-long.260,2021.ccl-1.108,0,0.049509,"Missing"
2021.acl-long.260,2020.emnlp-main.298,1,0.863483,"Missing"
2021.acl-long.260,D19-1005,0,0.0318608,"heir relations, which are crucial for understanding the whole text. To improve the entity and relation understanding of PLMs, a typical line of work is knowledgeguided PLM, which incorporates external knowledge such as Knowledge Graphs (KGs) into PLMs to enhance the entity and relation understanding. Some enforce PLMs to memorize information about real-world entities and propose novel pretraining objectives (Xiong et al., 2019; Wang et al., 2019; Sun et al., 2020; Yamada et al., 2020). Others modify the internal structures of PLMs to fuse both textual and KG’s information (Zhang et al., 2019; Peters et al., 2019; Wang et al., 2020; He et al., 2020). Although knowledge-guided PLMs introduce extra factual knowledge in KGs, these methods ignore the intrinsic relational facts in text, making it hard to understand out-of-KG entities or knowledge in downstream tasks, let alone the errors and incompleteness of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts. Another line of work is to directly model entities or relations in text in pre-training stage to break the limitations of individual token representations. Some focus on obtaining better span representation"
2021.acl-long.260,D16-1264,0,0.0361457,"hich are introduced in previous sections. From the results listed in Table 4, we observe that ERICA outperforms baselines in both settings, indicating that ERICA can better understand entities and their relations in the documents and extract the true answer according to queries. The significant improvements in the masked setting also indicate that ERICA can better perform multi-hop reasoning to synthesize and analyze information from contexts, instead of relying on entity mention “shortcuts” (Jiang and Bansal, 2019). Extractive QA For extractive QA, we adopt three widely-used datasets: SQuAD (Rajpurkar et al., 2016), TriviaQA (Joshi et al., 2017) and NaturalQA (Kwiatkowski et al., 2019) in MRQA (Fisch et al., 2019) to evaluate ERICA in various domains. Since MRQA does not provide the test set for each dataset, we randomly split the original dev set into two halves and obtain the new dev/test set. We follow the QA setting of BERT (Devlin et al., 2018): we concatenate the given question and passage into one long sequence, encode the sequence by PLMs and adopt two classifiers to predict the start and end index of the answer. We choose BERT, RoBERTa, MTB and CP as baselines. From the results listed in Table"
2021.acl-long.260,W04-2401,0,0.417814,"Missing"
2021.acl-long.260,W03-0419,0,0.619684,"Missing"
2021.acl-long.260,P19-1279,0,0.23953,"s of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts. Another line of work is to directly model entities or relations in text in pre-training stage to break the limitations of individual token representations. Some focus on obtaining better span representations, including entity mentions, via span-based pre-training (Sun et al., 2019; Joshi et al., 2020; Kong et al., 2020; Ye et al., 2020). Others learn to extract relation-aware semantics from text by comparing the sentences that share the same entity pair or distantly supervised relation in KGs (Soares et al., 2019; Peng et al., 2020). However, these methods only consider either individual entities or within-sentence relations, which limits the performance in dealing with multiple entities and relations at document level. In contrast, our ERICA considers the interactions among multiple entities 3351 {h1 , h2 , ..., h|di |}, then we apply mean pooling operation over the consecutive tokens that mention eij to obtain local entity representations. Note eij may appear multiple times in di , the k-th occurrence of eij , which contains the tokens from index nkstart to nkend , is represented as: mkeij = MeanPoo"
2021.acl-long.260,2020.coling-main.327,0,0.0338092,"y. Although achieving great success, these PLMs usually regard words as basic units in textual understanding, ignoring the informative entities and their relations, which are crucial for understanding the whole text. To improve the entity and relation understanding of PLMs, a typical line of work is knowledgeguided PLM, which incorporates external knowledge such as Knowledge Graphs (KGs) into PLMs to enhance the entity and relation understanding. Some enforce PLMs to memorize information about real-world entities and propose novel pretraining objectives (Xiong et al., 2019; Wang et al., 2019; Sun et al., 2020; Yamada et al., 2020). Others modify the internal structures of PLMs to fuse both textual and KG’s information (Zhang et al., 2019; Peters et al., 2019; Wang et al., 2020; He et al., 2020). Although knowledge-guided PLMs introduce extra factual knowledge in KGs, these methods ignore the intrinsic relational facts in text, making it hard to understand out-of-KG entities or knowledge in downstream tasks, let alone the errors and incompleteness of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts. Another line of work is to directly model entities or"
2021.acl-long.260,P19-1485,0,0.020828,"elf is considerably smaller, measuring only. [6] Culiacán is a rail junction and is located on the Panamerican Highway that runs south to Guadalajara and Mexico City. [7] Culiacán is connected to the north with Los Mochis, and to the south with Mazatlán, Tepic. 1 Q: where is Guadalajara? Mexico Pre-trained Language Models (PLMs) (Devlin et al., 2018; Yang et al., 2019; Liu et al., 2019) have shown superior performance on various Natural Language Processing (NLP) tasks such as text classification (Wang et al., 2018), named entity recognition (Sang and De Meulder, 2003), and question answering (Talmor and Berant, 2019). Benefiting from designing various effective self-supervised learning objectives, such as masked language modeling (Devlin et al., 2018), PLMs can effectively capture the syntax and semantics in text to generate informative language representations for downstream NLP tasks. Corresponding author. Our code and data are publicly available at https:// github.com/thunlp/ERICA. 1 A: Mexico. o Panamerican Highway Los Mochis Sinaloa Mexico City Guadalajara Figure 1: An example for a document “Culiacán”, in which all entities are underlined. We show entities and their relations as a relational graph,"
2021.acl-long.260,W18-5446,0,0.0555444,"Missing"
2021.acl-long.260,K17-1028,0,0.0151597,"reading multiple documents and conducting multi-hop reasoning. It has both standard and masked settings, where the latter setting masks all entities with random IDs to avoid information leakage. We first concatenate the question and documents into a long sequence, then we find all the occurrences of an entity in the documents, encode them into hidden representations and obtain the global entity representation by applying mean pooling on these hidden representations. Finally, we use a classifier on top of the entity representation for prediction. We choose the following baselines: (1) FastQA (Weissenborn et al., 2017) and BiDAF (Seo et al., 2016), which are widely used question answering systems; (2) BERT, RoBERTa, CorefBERT, SpanBERT, MTB and CP, which are introduced in previous sections. From the results listed in Table 4, we observe that ERICA outperforms baselines in both settings, indicating that ERICA can better understand entities and their relations in the documents and extract the true answer according to queries. The significant improvements in the masked setting also indicate that ERICA can better perform multi-hop reasoning to synthesize and analyze information from contexts, instead of relying"
2021.acl-long.260,Q18-1021,0,0.0536187,"Missing"
2021.acl-long.260,C14-1220,0,0.139289,"Missing"
2021.acl-long.260,D17-1004,0,0.026425,"easoning patterns in the pre-training; (2) both MTB and CP achieve worse results than BERT, which means sentence-level pre-training, lacking consideration for complex reasoning patterns, hurts PLM’s performance on document-level RE tasks to some extent; (3) ERICA outperforms baselines by a larger margin on smaller training sets, which means ERICA has gained pretty good document-level relation reasoning ability in contrastive learning, and thus obtains improvements more extensively under low-resource settings. Sentence-level RE For sentence-level RE, we choose two widely used datasets: TACRED (Zhang et al., 2017) and SemEval-2010 Task 8 (Hendrickx et al., 2019). We insert extra marker tokens to indicate the head and tail entities in each sentence. For baselines, we compare ERICA with BERT, RoBERTa, MTB and CP. From the results shown in Table 2, we observe that ERICA achieves almost comparable results on sentence-level RE tasks with CP, which means document-level pre-training in 10 In practice, documents are split into sentences and we only keep within-sentence entity pairs. 11 https://github.com/thunlp/ RE-Context-or-Names - 27.2 49.7 53.7 54.4 56.4 51.7 50.4 57.8 69.5 68.8 70.7 68.4 67.4 69.7 37.9 39"
2021.acl-long.260,P19-1139,1,0.80299,"ative entities and their relations, which are crucial for understanding the whole text. To improve the entity and relation understanding of PLMs, a typical line of work is knowledgeguided PLM, which incorporates external knowledge such as Knowledge Graphs (KGs) into PLMs to enhance the entity and relation understanding. Some enforce PLMs to memorize information about real-world entities and propose novel pretraining objectives (Xiong et al., 2019; Wang et al., 2019; Sun et al., 2020; Yamada et al., 2020). Others modify the internal structures of PLMs to fuse both textual and KG’s information (Zhang et al., 2019; Peters et al., 2019; Wang et al., 2020; He et al., 2020). Although knowledge-guided PLMs introduce extra factual knowledge in KGs, these methods ignore the intrinsic relational facts in text, making it hard to understand out-of-KG entities or knowledge in downstream tasks, let alone the errors and incompleteness of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts. Another line of work is to directly model entities or relations in text in pre-training stage to break the limitations of individual token representations. Some focus on obtaining bette"
2021.acl-long.260,2020.emnlp-main.523,0,0.162157,"ing great success, these PLMs usually regard words as basic units in textual understanding, ignoring the informative entities and their relations, which are crucial for understanding the whole text. To improve the entity and relation understanding of PLMs, a typical line of work is knowledgeguided PLM, which incorporates external knowledge such as Knowledge Graphs (KGs) into PLMs to enhance the entity and relation understanding. Some enforce PLMs to memorize information about real-world entities and propose novel pretraining objectives (Xiong et al., 2019; Wang et al., 2019; Sun et al., 2020; Yamada et al., 2020). Others modify the internal structures of PLMs to fuse both textual and KG’s information (Zhang et al., 2019; Peters et al., 2019; Wang et al., 2020; He et al., 2020). Although knowledge-guided PLMs introduce extra factual knowledge in KGs, these methods ignore the intrinsic relational facts in text, making it hard to understand out-of-KG entities or knowledge in downstream tasks, let alone the errors and incompleteness of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts. Another line of work is to directly model entities or relations in text in p"
2021.acl-long.260,P19-1074,1,0.884737,"Missing"
2021.acl-long.260,2020.emnlp-main.582,1,0.844179,"e methods ignore the intrinsic relational facts in text, making it hard to understand out-of-KG entities or knowledge in downstream tasks, let alone the errors and incompleteness of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts. Another line of work is to directly model entities or relations in text in pre-training stage to break the limitations of individual token representations. Some focus on obtaining better span representations, including entity mentions, via span-based pre-training (Sun et al., 2019; Joshi et al., 2020; Kong et al., 2020; Ye et al., 2020). Others learn to extract relation-aware semantics from text by comparing the sentences that share the same entity pair or distantly supervised relation in KGs (Soares et al., 2019; Peng et al., 2020). However, these methods only consider either individual entities or within-sentence relations, which limits the performance in dealing with multiple entities and relations at document level. In contrast, our ERICA considers the interactions among multiple entities 3351 {h1 , h2 , ..., h|di |}, then we apply mean pooling operation over the consecutive tokens that mention eij to obtain local entity"
2021.acl-long.269,I17-1099,0,0.0176651,"s shows the Joint model can mimic human supporters’ behaviors in strategy utilization. We believe our work will facilitate research on more data-driven approaches to build dialog systems capable of providing effective emotional support. 2 2.1 Related Work Emotional & Empathetic Conversation Figure 2 intuitively shows the relationships among In this paper, we define the task of Emotional ESC, emotional conversation, and empathetic conSupport Conversation (ESC), aiming to provide versation. Emotion has been shown to be impor3470 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020). As a notable work of emotional conversation, Zhou et al. (2018) propose Emotional Chatting Machine (ECM) to generate emotional responses given a pre-specified emotion. This task is required to accurately express (designated or not) emotions in generated responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely"
2021.acl-long.269,W04-1013,0,0.0229567,"Missing"
2021.acl-long.269,2020.acl-demos.30,0,0.167107,"en used to provide effective ES (Hill, 2009). Figure 2 illustrates the relationship between the three tasks and we provide further discussion in Section 2.1. Second, people are not naturally good at being supportive, so guidelines have been developed to train humans how to be more supportive. Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations. As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES. Empathetic Responding Emotional Chatting Accurately express emotions in responses Understand users&apos; feelings and reply accordingly Emotional Support Conversation Reduce users&apos; emotional distress and help them work through the challenges Figure 2: Emotional support conversations (our work) can include elements of emotional chatting (Zhou et al., 2018) and empathetic responding(Rashkin et al., 2019). support through social interactions (like the interactions betwee"
2021.acl-long.269,2021.findings-acl.72,1,0.739112,"responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely a basic quality of dialog systems, while ES is a more high-level and complex ability that dialog systems are expected to be equipped with. Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accordingly. For instance, Rashkin et al. (2019) argued that dialog models can generate more empathetic responses by recognizing the interlocutor’s feelings. Effective ES naturally requires expressing empathy according to the help-seeker’s experiences and feelings, as shown in our proposed Emotional Support Framework (Section 3.2, Figure 3). Hence, empathetic responding is only one of the necessary components of emotional support. In addition to empathetic responding, an emotional support conversation needs to explore the users’ p"
2021.acl-long.269,2020.emnlp-main.531,0,0.274036,"pathetic responding (Rashkin et al., 2019) return messages that are examples of emotion or empathy and are thus limited in functionality, as they are not capable of many other skills that are often used to provide effective ES (Hill, 2009). Figure 2 illustrates the relationship between the three tasks and we provide further discussion in Section 2.1. Second, people are not naturally good at being supportive, so guidelines have been developed to train humans how to be more supportive. Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations. As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES. Empathetic Responding Emotional Chatting Accurately express emotions in responses Understand users&apos; feelings and reply accordingly Emotional Support Conversation Reduce users&apos; emotional distress and help them work through the challenges Figure 2: Emotional support convers"
2021.acl-long.269,2020.cl-1.2,0,0.051659,"Missing"
2021.acl-long.269,P18-1104,0,0.0205011,"model can mimic human supporters’ behaviors in strategy utilization. We believe our work will facilitate research on more data-driven approaches to build dialog systems capable of providing effective emotional support. 2 2.1 Related Work Emotional & Empathetic Conversation Figure 2 intuitively shows the relationships among In this paper, we define the task of Emotional ESC, emotional conversation, and empathetic conSupport Conversation (ESC), aiming to provide versation. Emotion has been shown to be impor3470 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020). As a notable work of emotional conversation, Zhou et al. (2018) propose Emotional Chatting Machine (ECM) to generate emotional responses given a pre-specified emotion. This task is required to accurately express (designated or not) emotions in generated responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely a basic quality of d"
2021.acl-long.272,N19-1125,0,0.0367524,"Missing"
2021.acl-long.272,2020.findings-emnlp.352,0,0.0437804,"Missing"
2021.acl-long.272,2020.acl-main.185,0,0.0563013,"Missing"
2021.acl-long.272,D16-1139,0,0.0622703,"Missing"
2021.acl-long.272,P17-4012,0,0.081538,"Missing"
2021.acl-long.272,W19-8609,0,0.0396998,"Missing"
2021.acl-long.272,N16-1014,0,0.0681581,"Missing"
2021.acl-long.272,2020.acl-main.428,0,0.0704239,"Missing"
2021.acl-long.272,I17-1099,0,0.039754,"Missing"
2021.acl-long.272,2020.findings-emnlp.22,0,0.0755207,"Missing"
2021.acl-long.272,P17-1061,0,0.0321126,"Missing"
2021.acl-long.318,D13-1160,0,0.0567264,"ed stabilizing training by reducing the variance of rewards and setting a small λ. 4.2 Multi-Mention Reading Comprehension Multi-mention reading comprehension is a natural feature of many QA tasks. Given a document d and a question q, a task-specific model is required to locate the answer text a which is usually mentioned many times in the document(s). A solution is defined as a document span. The solution set Z is computed by finding exact match of a: Z = {z = (s, e)d |[ds , ..., de ] = a} We experimented on two open domain QA datasets, i.e., Quasar-T (Dhingra et al., 2017) and WebQuestions (Berant et al., 2013). For Quasar-T, we retrieved 50 reference sentences from ClueWeb09 for each question; for WebQuestions, we used the 2016-12-21 dump of Wikipedia as the knowledge source and retrieved 50 reference paragraphs for each question using a Lucene index system. We used the same BERTbase (Devlin et al., 2019) reading comprehension model and data preprocessing from (Min et al., 2019). Quasar-T Dev Test EM F1 EM F1 First Only 36.0 43.9 35.6 42.8 MML 40.1 47.4 39.1 46.5 HardEM 41.5 49.1 40.7 47.7 HardEM-thres 42.8 50.2 41.9 49.4 Ours 44.7‡ 52.6‡ 44.0‡ 51.5‡ WebQuestions Test EM F1 16.7 22.6 18.4 25.0 18.0"
2021.acl-long.318,P19-1007,0,0.0187808,"use model confidence to filter out spurious solutions in a soft or hard way. They do not explicitly exploit the semantic correlations between a question and its solution. Most relevantly, Cheng and Lapata (2018) focused on text2SQL tasks; they modeled SQL queries as the latent variables for question generation, and maximized the evidence lower bound of log likelihood of questions. A few works treated solution prediction and question generation as dual tasks and introduced dual learning losses to regularize learning under the fully-supervised or the semi-supervised setting (Tang et al., 2017; Cao et al., 2019; Ye et al., 2019). In dual learning, a model generates intermediate outputs (e.g., the task-specific model predicts solutions from a question) while the dual model gives feedback signals (e.g., the question reconstructor computes the likelihood of the question conditioned on predicted solutions). This method is featured in three aspects. First, both models need training on fully-annotated data so that they can produce reasonable intermediate outputs. Second, the intermediate outputs can 4112 introduce noise during learning as they are sampled from models but not restricted to solutions with c"
2021.acl-long.318,K18-1035,0,0.140759,"Talmor and Berant, 2019), training on all possible solutions with MML (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019; Wang et al., 2019), reinforcement learning (Liang et al., 2017, 2018), and hard EM (Min et al., 2019; Chen et al., 2020). All these approaches either use heuristics to select possibly reasonable solutions, rely on model architectures to bias towards correct solutions, or use model confidence to filter out spurious solutions in a soft or hard way. They do not explicitly exploit the semantic correlations between a question and its solution. Most relevantly, Cheng and Lapata (2018) focused on text2SQL tasks; they modeled SQL queries as the latent variables for question generation, and maximized the evidence lower bound of log likelihood of questions. A few works treated solution prediction and question generation as dual tasks and introduced dual learning losses to regularize learning under the fully-supervised or the semi-supervised setting (Tang et al., 2017; Cao et al., 2019; Ye et al., 2019). In dual learning, a model generates intermediate outputs (e.g., the task-specific model predicts solutions from a question) while the dual model gives feedback signals (e.g., t"
2021.acl-long.318,P18-1078,0,0.129234,"mprehension, many mentions of an answer in the document(s) are irrelevant to the question; for discrete reasoning tasks or text2SQL tasks, an answer can be produced by the equations or SQL queries that do not correctly match the question in logic. Some previous works heuristically selected one possible solution per question for training, e.g., the first answer span in the document (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019); some treated all possible solutions equally and maximized the sum of their likelihood (maximum marginal likelihood, or MML) (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019); many others selected solutions according to model confidence (Liang et al., 2018; Min et al., 2019), 4111 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4111–4124 August 1–6, 2021. ©2021 Association for Computational Linguistics i.e., the likelihood of the solutions being derived by the model. A drawback of these methods is that they do not explicitly consider the mutual semantic correlations between a question and its solution when selecting solutions"
2021.acl-long.318,N19-1423,0,0.0115289,"h is usually mentioned many times in the document(s). A solution is defined as a document span. The solution set Z is computed by finding exact match of a: Z = {z = (s, e)d |[ds , ..., de ] = a} We experimented on two open domain QA datasets, i.e., Quasar-T (Dhingra et al., 2017) and WebQuestions (Berant et al., 2013). For Quasar-T, we retrieved 50 reference sentences from ClueWeb09 for each question; for WebQuestions, we used the 2016-12-21 dump of Wikipedia as the knowledge source and retrieved 50 reference paragraphs for each question using a Lucene index system. We used the same BERTbase (Devlin et al., 2019) reading comprehension model and data preprocessing from (Min et al., 2019). Quasar-T Dev Test EM F1 EM F1 First Only 36.0 43.9 35.6 42.8 MML 40.1 47.4 39.1 46.5 HardEM 41.5 49.1 40.7 47.7 HardEM-thres 42.8 50.2 41.9 49.4 Ours 44.7‡ 52.6‡ 44.0‡ 51.5‡ WebQuestions Test EM F1 16.7 22.6 18.4 25.0 18.0 24.2 19.0 25.3 20.4‡ 27.2‡ Table 2: Evaluation on multi-mention reading comprehension datasets. Numbers marked with ‡ are significantly better than the others (t-test, p-value < 0.05). Results: Our method outperforms all baselines on both datasets (Table 2). The improvements can be attributed to the"
2021.acl-long.318,N19-1246,0,0.0274635,"Missing"
2021.acl-long.318,P17-1147,0,0.431756,"h spurious solutions can hurt model performance (e.g., misleading the model to produce unreasonable solutions or wrong answers). As shown in Fig 1, ∗ *Corresponding author: Minlie Huang. for multi-mention reading comprehension, many mentions of an answer in the document(s) are irrelevant to the question; for discrete reasoning tasks or text2SQL tasks, an answer can be produced by the equations or SQL queries that do not correctly match the question in logic. Some previous works heuristically selected one possible solution per question for training, e.g., the first answer span in the document (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019); some treated all possible solutions equally and maximized the sum of their likelihood (maximum marginal likelihood, or MML) (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019); many others selected solutions according to model confidence (Liang et al., 2018; Min et al., 2019), 4111 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4111–4124 August 1–6, 2021. ©2021 Association for Computational Linguistics i.e., t"
2021.acl-long.318,Q18-1023,0,0.0547158,"Missing"
2021.acl-long.318,P19-1612,0,0.0959051,"s of an answer in the document(s) are irrelevant to the question; for discrete reasoning tasks or text2SQL tasks, an answer can be produced by the equations or SQL queries that do not correctly match the question in logic. Some previous works heuristically selected one possible solution per question for training, e.g., the first answer span in the document (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019); some treated all possible solutions equally and maximized the sum of their likelihood (maximum marginal likelihood, or MML) (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019); many others selected solutions according to model confidence (Liang et al., 2018; Min et al., 2019), 4111 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4111–4124 August 1–6, 2021. ©2021 Association for Computational Linguistics i.e., the likelihood of the solutions being derived by the model. A drawback of these methods is that they do not explicitly consider the mutual semantic correlations between a question and its solution when selecting solutions for training. Intu"
2021.acl-long.318,2020.acl-main.703,0,0.0233164,"Missing"
2021.acl-long.318,P17-1003,0,0.11412,"an answer) are not provided. This setting is worth exploration as it simplifies annotation and makes it easier to collect large-scale corpora. However, this setting introduces the spurious solution problem, and thus complicates model learning. Most existing approaches for this learning challenge include heuristically selecting one possible solution per question for training (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019), training on all possible solutions with MML (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019; Wang et al., 2019), reinforcement learning (Liang et al., 2017, 2018), and hard EM (Min et al., 2019; Chen et al., 2020). All these approaches either use heuristics to select possibly reasonable solutions, rely on model architectures to bias towards correct solutions, or use model confidence to filter out spurious solutions in a soft or hard way. They do not explicitly exploit the semantic correlations between a question and its solution. Most relevantly, Cheng and Lapata (2018) focused on text2SQL tasks; they modeled SQL queries as the latent variables for question generation, and maximized the evidence lower bound of log likelihood of questions. A few"
2021.acl-long.318,D17-1090,0,0.0608387,"Missing"
2021.acl-long.318,D19-1284,0,0.225883,"t2SQL tasks, an answer can be produced by the equations or SQL queries that do not correctly match the question in logic. Some previous works heuristically selected one possible solution per question for training, e.g., the first answer span in the document (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019); some treated all possible solutions equally and maximized the sum of their likelihood (maximum marginal likelihood, or MML) (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019); many others selected solutions according to model confidence (Liang et al., 2018; Min et al., 2019), 4111 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4111–4124 August 1–6, 2021. ©2021 Association for Computational Linguistics i.e., the likelihood of the solutions being derived by the model. A drawback of these methods is that they do not explicitly consider the mutual semantic correlations between a question and its solution when selecting solutions for training. Intuitively speaking, a question often contains vital clues about how to derive the answer, and a wrong s"
2021.acl-long.318,P15-1142,0,0.0142296,"task performance and is more effective in training models to produce correct solutions. 2 Related Work Question answering has raised prevalent attention and has achieved great progress these years. A lot of challenging datasets have been constructed to advance models’ reasoning abilities, such as (1) reading comprehension datasets with extractive answer spans (Joshi et al., 2017; Dhingra et al., 2017), with free-form answers (Kocisk´y et al., 2018), for multi-hop reasoning (Yang et al., 2018), or for discrete reasoning over paragraphs (Dua et al., 2019), and (2) datasets for semantic parsing (Pasupat and Liang, 2015; Zhong et al., 2017; Yu et al., 2018). Under the weakly supervised setting, the specific solutions to derive the final answers (e.g., the correct location of an answer text, or the correct logic executing an answer) are not provided. This setting is worth exploration as it simplifies annotation and makes it easier to collect large-scale corpora. However, this setting introduces the spurious solution problem, and thus complicates model learning. Most existing approaches for this learning challenge include heuristically selecting one possible solution per question for training (Joshi et al., 20"
2021.acl-long.318,D19-1391,0,0.294103,"answer text, or the correct logic executing an answer) are not provided. This setting is worth exploration as it simplifies annotation and makes it easier to collect large-scale corpora. However, this setting introduces the spurious solution problem, and thus complicates model learning. Most existing approaches for this learning challenge include heuristically selecting one possible solution per question for training (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019), training on all possible solutions with MML (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019; Wang et al., 2019), reinforcement learning (Liang et al., 2017, 2018), and hard EM (Min et al., 2019; Chen et al., 2020). All these approaches either use heuristics to select possibly reasonable solutions, rely on model architectures to bias towards correct solutions, or use model confidence to filter out spurious solutions in a soft or hard way. They do not explicitly exploit the semantic correlations between a question and its solution. Most relevantly, Cheng and Lapata (2018) focused on text2SQL tasks; they modeled SQL queries as the latent variables for question generation, and maximized the evidence lower"
2021.acl-long.318,D18-1259,0,0.0250719,"conducted extensive experiments on four QA datasets. Our approach significantly outperforms strong baselines in terms of task performance and is more effective in training models to produce correct solutions. 2 Related Work Question answering has raised prevalent attention and has achieved great progress these years. A lot of challenging datasets have been constructed to advance models’ reasoning abilities, such as (1) reading comprehension datasets with extractive answer spans (Joshi et al., 2017; Dhingra et al., 2017), with free-form answers (Kocisk´y et al., 2018), for multi-hop reasoning (Yang et al., 2018), or for discrete reasoning over paragraphs (Dua et al., 2019), and (2) datasets for semantic parsing (Pasupat and Liang, 2015; Zhong et al., 2017; Yu et al., 2018). Under the weakly supervised setting, the specific solutions to derive the final answers (e.g., the correct location of an answer text, or the correct logic executing an answer) are not provided. This setting is worth exploration as it simplifies annotation and makes it easier to collect large-scale corpora. However, this setting introduces the spurious solution problem, and thus complicates model learning. Most existing approaches"
2021.acl-long.318,P19-1201,0,0.0236122,"nce to filter out spurious solutions in a soft or hard way. They do not explicitly exploit the semantic correlations between a question and its solution. Most relevantly, Cheng and Lapata (2018) focused on text2SQL tasks; they modeled SQL queries as the latent variables for question generation, and maximized the evidence lower bound of log likelihood of questions. A few works treated solution prediction and question generation as dual tasks and introduced dual learning losses to regularize learning under the fully-supervised or the semi-supervised setting (Tang et al., 2017; Cao et al., 2019; Ye et al., 2019). In dual learning, a model generates intermediate outputs (e.g., the task-specific model predicts solutions from a question) while the dual model gives feedback signals (e.g., the question reconstructor computes the likelihood of the question conditioned on predicted solutions). This method is featured in three aspects. First, both models need training on fully-annotated data so that they can produce reasonable intermediate outputs. Second, the intermediate outputs can 4112 introduce noise during learning as they are sampled from models but not restricted to solutions with correct answer or v"
2021.acl-long.318,P19-1485,0,0.0535664,"rformance (e.g., misleading the model to produce unreasonable solutions or wrong answers). As shown in Fig 1, ∗ *Corresponding author: Minlie Huang. for multi-mention reading comprehension, many mentions of an answer in the document(s) are irrelevant to the question; for discrete reasoning tasks or text2SQL tasks, an answer can be produced by the equations or SQL queries that do not correctly match the question in logic. Some previous works heuristically selected one possible solution per question for training, e.g., the first answer span in the document (Joshi et al., 2017; Tay et al., 2018; Talmor and Berant, 2019); some treated all possible solutions equally and maximized the sum of their likelihood (maximum marginal likelihood, or MML) (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019); many others selected solutions according to model confidence (Liang et al., 2018; Min et al., 2019), 4111 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4111–4124 August 1–6, 2021. ©2021 Association for Computational Linguistics i.e., the likelihood of the solutions being derived"
2021.acl-long.318,D18-1425,0,0.0180048,", 2019), training on all possible solutions with MML (Swayamdipta et al., 2018; Clark and Gardner, 2018; Lee et al., 2019; Wang et al., 2019), reinforcement learning (Liang et al., 2017, 2018), and hard EM (Min et al., 2019; Chen et al., 2020). All these approaches either use heuristics to select possibly reasonable solutions, rely on model architectures to bias towards correct solutions, or use model confidence to filter out spurious solutions in a soft or hard way. They do not explicitly exploit the semantic correlations between a question and its solution. Most relevantly, Cheng and Lapata (2018) focused on text2SQL tasks; they modeled SQL queries as the latent variables for question generation, and maximized the evidence lower bound of log likelihood of questions. A few works treated solution prediction and question generation as dual tasks and introduced dual learning losses to regularize learning under the fully-supervised or the semi-supervised setting (Tang et al., 2017; Cao et al., 2019; Ye et al., 2019). In dual learning, a model generates intermediate outputs (e.g., the task-specific model predicts solutions from a question) while the dual model gives feedback signals (e.g., t"
2021.acl-long.499,2020.emnlp-main.351,0,0.478273,"ollowing perspectives. Li et al. (2015) adopted a hierarchical RNN-based decoder to learn the sentence representation but without any external supervision. Shao et al. (2017) proposed a self-attention mechanism to attend on the prefix by appending it to the RNN-based encoder, which is a similar idea with the vanilla Transformer (Vaswani et al., 2017). However, the token-level self-attention mechanism still struggles to model high-level dependency in the context. Recent works proposed several multi-step generation models (Fan et al., 2018; Yao et al., 2019; Shao et al., 2019; Tan et al., 2020; Goldfarb-Tarrant et al., 2020), which first plan high-level sketches and then generate texts from the sketches. However, the lack of exposure to degenerate sketches may impair the generation performance since the models are only trained on sketches constructed from golden truth texts (Tan et al., 2020). Another line is to incorporate external knowledge into generation especially for commonsense story generation (Guan et al., 2020; Xu et al., 2020). However, the methods may not be always effective for other types of generation tasks. Guan et al. (2020) also required the decoder to distinguish true texts from negative sample"
2021.acl-long.499,2020.tacl-1.7,1,0.822534,"odel (Lewis et al., 2020) and a human writer given the same leading context from ROCStories (Mostafazadeh et al., 2016). The generated story by BART suffers from severe incoherence issue in spite of some related concepts (in bold). In comparison, the human writer can write a coherent story because they fully consider the context semantics and discourse relations (e.g., the temporal order) among the sentences. provide sufficient source information in the input for generating desired texts, while open-ended generation tasks require expanding reasonable plots from very limited input information (Guan et al., 2020). As exemplified in Figure 1, we observe severe issues of incoherence when applying BART for story generation. Although BART performs reasonably well at generating some concepts related to the context (e.g., “basketball”, “player”), they are used incoherently in the generated texts, which is manifested in repetitive plots (e.g., the sentences B and C), unrelated events (e.g., “played baseball 6379 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6379–6393 August 1–6, 2021. ©"
2021.acl-long.499,2020.emnlp-main.736,1,0.906623,"ayer”), they are used incoherently in the generated texts, which is manifested in repetitive plots (e.g., the sentences B and C), unrelated events (e.g., “played baseball 6379 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6379–6393 August 1–6, 2021. ©2021 Association for Computational Linguistics better”) and conflicting logic (e.g., “not good at basketball” but “in the basketball team”). These issues are also commonly observed in other NLG models (Holtzman et al., 2020; Guan and Huang, 2020). We argue that existing models are rarely trained beyond the token-level co-occurrence, and therefore they can easily generate related concepts but do not arrange them reasonably. In contrast, human writers always first fully understand the semantics (e.g., some key events such as “try out”, “not make the cut”) and the discourse relations (e.g., temporal orders) among the already written sentences before deciding the following content. In this way, the writers can write coherent stories even with few related concepts, as shown in Figure 1. Therefore, it is important for subsequent generation"
2021.acl-long.499,2020.acl-main.439,0,0.0216649,"and distinguish between normal and shuffled sentence orders with the discourse-level representations (Task 3) based on the human-written texts and autoconstructed negative samples. hierarchical LSTM-based encoder to learn the contextualized sentence representation by downstream classification. HIBERT (Zhang et al., 2019) incorporated the hierarchical architecture to BERT (Devlin et al., 2019) and learned sentence representation by recovering masked sentences. SentenceBERT (Reimers and Gurevych, 2019) derived sentence representation by fine-tuning BERT for natural language inference. C ONPONO (Iter et al., 2020) and SLM (Lee et al., 2020) further trained BERT to understand relations among sentences at discourse level by distance prediction and sentence unshuffling, respectively. However, all these models focused on enhancing the representation of encoders for language understanding, while improving decoders by high-level representation for long text generation is yet to be well investigated. 3 3.1 Methodology Task Definition and Model Overview Our task can be defined as follows: given an input X = (x1 , x2 , · · · , xm ) (e.g., a beginning or a prompt), the model should generate a multisentence text"
2021.acl-long.499,N16-1098,0,0.0798254,"Missing"
2021.acl-long.499,P02-1040,0,0.109117,"evel representations for each sentence. And during evaluation, we remove the special tokens in the generated texts. We apply these settings to all the baselines. 4.4 Automatic Evaluation Evaluation Metrics We adopt the following automatic metrics to evaluate the performance on the test sets: (1) Perplexity (PPL): Smaller perplexity scores indicate better fluency in general. We do not count the probability values at the positions where the sentence or discourse token is the golden truth. (2) BLEU (B-n): We use n = 1, 2 to evaluate n-gram overlap between generated texts and human-written texts (Papineni et al., 2002). (3) Lexical Repetition (LR-n): The metric computes the percentage of those texts which repeat a 4-gram at least n times in all the generated texts (Shao et al., 2019). We set n = 2 for ROC and n = 5 for WP. (4) Semantic Repetition (SR-n): The metric first computes the average top-n SentenceBERT similarity between any two sentences in each generated text, and then averages the results as the final score. We set n = 1 for ROC and n = 10 for WP. (5) Distinct-4 (D-4) (Li et al., 2016): We adopt distinct-4, the ratio of distinct 4-grams to all the generated 4-grams, to measure the generation dive"
2021.acl-long.499,N18-1202,0,0.0234838,"t guidance for generation at each step. Therefore, the coherence of language generation is still an open problem. I. We propose a generation model named H INT for long text generation. H INT derives high-level representations for each decoded sentence to model the long-range coherence. We adopt two pretraining objectives called similarity prediction and order discrimination to learn the representations at sentence level and discourse level, respectively. High-Level Language Representation Significant advances have been witnessed in many NLP tasks with pretrained contextualized representation (Peters et al., 2018; Devlin et al., 2019). However, most models were limited on token-level representation learning, which is not enough for capturing the hierarchical structure of natural language texts (Ribeiro et al., 2020). Several works have tried to learn high-level representation. SkipThought vectors (Kiros et al., 2015) learned to encode a sentence by reconstructing its neighboring sentences. HLSTM (Yang et al., 2016) considered a II. We conduct extensive experiments on commonsense story and fiction generation tasks. Results 1 The codes are available at https://github.com/ thu-coai/HINT 6380 Task 1: Lang"
2021.acl-long.499,D19-1410,0,0.251615,"by next word prediction based on the attention to all the prefix words. In order to encourage the model to capture high-level features, we extend the decoder to represent the prefix information at sentence level and discourse level, respectively, with special tokens which are inserted at the end of each sentence. To effectively learn the representations, we propose two pretraining objectives including: (a) semantic similarity prediction, which requires predicting the inter-sentence similarity using the sentencelevel representation, with the powerful sentence understanding model SentenceBERT (Reimers and Gurevych, 2019) as the teacher model; and (b) sentence order discrimination, which requires distinguishing between the normal and shuffled sentence orders using the discourse-level representation. The objectives are designed to help the decoder capture the semantics and discourse structure of the prefix, which can benefit modeling the longrange coherence when generating long texts. We summarize our contributions in two folds: show that H INT can learn meaningful high-level representations and generate more coherent long texts than baselines.1 2 Related Works Long Text Generation Recent studies tackle the inc"
2021.acl-long.499,2020.acl-main.442,0,0.0130933,"evel representations for each decoded sentence to model the long-range coherence. We adopt two pretraining objectives called similarity prediction and order discrimination to learn the representations at sentence level and discourse level, respectively. High-Level Language Representation Significant advances have been witnessed in many NLP tasks with pretrained contextualized representation (Peters et al., 2018; Devlin et al., 2019). However, most models were limited on token-level representation learning, which is not enough for capturing the hierarchical structure of natural language texts (Ribeiro et al., 2020). Several works have tried to learn high-level representation. SkipThought vectors (Kiros et al., 2015) learned to encode a sentence by reconstructing its neighboring sentences. HLSTM (Yang et al., 2016) considered a II. We conduct extensive experiments on commonsense story and fiction generation tasks. Results 1 The codes are available at https://github.com/ thu-coai/HINT 6380 Task 1: Language Modeling HumanWritten Texts B Perturbation sen ... Task 2: Similarity Prediction Task 3: Order Discrimination eos Feed Forward Negative Samples ??? ... All Hidden Representations ??? ??? ??? ??? ??? ???"
2021.acl-long.499,D17-1235,0,0.0192109,"ed to help the decoder capture the semantics and discourse structure of the prefix, which can benefit modeling the longrange coherence when generating long texts. We summarize our contributions in two folds: show that H INT can learn meaningful high-level representations and generate more coherent long texts than baselines.1 2 Related Works Long Text Generation Recent studies tackle the incoherence problem in long text generation from the following perspectives. Li et al. (2015) adopted a hierarchical RNN-based decoder to learn the sentence representation but without any external supervision. Shao et al. (2017) proposed a self-attention mechanism to attend on the prefix by appending it to the RNN-based encoder, which is a similar idea with the vanilla Transformer (Vaswani et al., 2017). However, the token-level self-attention mechanism still struggles to model high-level dependency in the context. Recent works proposed several multi-step generation models (Fan et al., 2018; Yao et al., 2019; Shao et al., 2019; Tan et al., 2020; Goldfarb-Tarrant et al., 2020), which first plan high-level sketches and then generate texts from the sketches. However, the lack of exposure to degenerate sketches may impai"
2021.acl-long.499,Q19-1040,0,0.0525163,"Missing"
2021.acl-long.499,2020.emnlp-main.226,0,0.538813,"evel dependency in the context. Recent works proposed several multi-step generation models (Fan et al., 2018; Yao et al., 2019; Shao et al., 2019; Tan et al., 2020; Goldfarb-Tarrant et al., 2020), which first plan high-level sketches and then generate texts from the sketches. However, the lack of exposure to degenerate sketches may impair the generation performance since the models are only trained on sketches constructed from golden truth texts (Tan et al., 2020). Another line is to incorporate external knowledge into generation especially for commonsense story generation (Guan et al., 2020; Xu et al., 2020). However, the methods may not be always effective for other types of generation tasks. Guan et al. (2020) also required the decoder to distinguish true texts from negative samples to alleviate potential issues such as repetition. But the classification objective does not provide explicit guidance for generation at each step. Therefore, the coherence of language generation is still an open problem. I. We propose a generation model named H INT for long text generation. H INT derives high-level representations for each decoded sentence to model the long-range coherence. We adopt two pretraining"
2021.acl-long.499,N16-1174,0,0.0498344,"ntence level and discourse level, respectively. High-Level Language Representation Significant advances have been witnessed in many NLP tasks with pretrained contextualized representation (Peters et al., 2018; Devlin et al., 2019). However, most models were limited on token-level representation learning, which is not enough for capturing the hierarchical structure of natural language texts (Ribeiro et al., 2020). Several works have tried to learn high-level representation. SkipThought vectors (Kiros et al., 2015) learned to encode a sentence by reconstructing its neighboring sentences. HLSTM (Yang et al., 2016) considered a II. We conduct extensive experiments on commonsense story and fiction generation tasks. Results 1 The codes are available at https://github.com/ thu-coai/HINT 6380 Task 1: Language Modeling HumanWritten Texts B Perturbation sen ... Task 2: Similarity Prediction Task 3: Order Discrimination eos Feed Forward Negative Samples ??? ... All Hidden Representations ??? ??? ??? ??? ??? ??? ??? Discourse-Level Representations Sentence-Level Representations HINT Encoder ??? ??? ??? ??? F sen HINT Decoder A B sen C dis Sentence 1 D sen E dis Sentence 2 dis Sentence 3 Figure 2: Model overview"
2021.acl-long.500,N16-1098,0,0.122014,"to evaluate NLG metrics, such as measuring the robustness to adversarial examples (Zhang* et al., 2020), and the generalization to quality-biased data (Sellam et al., 2020). However, these approaches only focus on an individual capability or a single task, thereby failing to fully reveal the strengths and weaknesses of a NLG metric. Therefore, we propose OpenMEVA, a benchmark for Open-ended story generation Metrics Evaluation. We first collect a MANually annotated Story dataset (MANS). The stories are generated by various generation models trained on two widely used story corpora, ROCStories (Mostafazadeh et al., 2016) and WritingPrompts (Fan et al., 2018). Therefore, MANS supports to evaluate metrics in terms of not only the correlation with human judgments, but also the generalization w.r.t model drift (generations from different models) and dataset drift (examples from different datasets). In addition, OpenMEVA also includes an AUTOconstructed Story dataset (AUTOS) to test the robustness and the ability to judge story coherence, namely, the semantic relations and discourse structures in the context. We construct AUTOS by per6394 Proceedings of the 59th Annual Meeting of the Association for Computational"
2021.acl-long.500,2020.emnlp-main.742,0,0.0419636,"rd embedding (e.g., BERTScore (Zhang* et al., 2020), MoverScore (Zhao et al., 2019)). However, referenced metrics were reported to correlate poorly with human judgments in open-ended generation tasks (Liu et al., 2016) due to the one-to-many issue (Zhao et al., 2017). To address the issue, un1 All the tools, data, and evaluation scripts are available at https://github.com/thu-coai/OpenMEVA referenced metrics were proposed to measure the quality of a sample without any reference, such as perplexity, discriminator-based metric (Kannan and Vinyals, 2017), U NION (Guan and Huang, 2020) and GRADE (Huang et al., 2020). Besides, hybrid metrics combine referenced and unreferenced metrics (e.g., RUBER and its variant (Tao et al., 2018; Ghazarian et al., 2019)) or learn from the human-annotated score (e.g., ADEM (Lowe et al., 2017), BLEURT (Sellam et al., 2020)). Recently, there have been many criticisms for existing metrics. Garbacea et al. (2019) showed the poor generalization of discriminator-based metrics. Sai et al. (2019) demonstrated ADEM is not robust to simple attacks such as simple word substitution or random word shuffle. However, these criticisms only focus on individual metrics or capabilities. No"
2021.acl-long.500,speer-havasi-2012-representing,0,0.102439,"Missing"
2021.ecnlp-1.4,N18-1163,0,0.0154278,"h topic over the past decades. Most of the existing work focused on the session-level user satisfaction estimation (Jiang et al., 2015; Hashemi et al., 2018; Park et al., 2020). Walker et al. (1997) first proposed PARADISE framework, which can estimate the user satisfaction in spoken dialogue systems through a task success measure and dialogue-based cost measures. Yang et al. (2010) extended the PARADISE framework by an item-based collaborative filtering model. Some works on user satisfaction estimation focused on extracting useful features from usersystem interaction (Kiseleva et al., 2016a; Sandbank et al., 2018). Others modeled a dialogue as a sequence of dialogue actions (Jiang et al., 2015) or utterances (Hashemi et al., 2018; Choi et al., 2019). However, these methods can predict user satisfaction only after the dialog is completed, which can not be adopted in an E-commerce customer service scenario where timely satisfaction estimation is preferred. Figure 2: The overview of the proposed method. 3.1 Dialogue Encoder Following (Choi et al., 2019), we extract features from each turn and model a dialogue as a sequence of features, such as turn index and input channel2 . Suppose there are m features a"
2021.ecnlp-1.4,P97-1035,0,0.810433,"Missing"
2021.emnlp-main.139,N19-1423,0,0.0404242,"e items to be recommended, even if some of them have no connection with other entities on the graph. In addition, we maintain the status of each entity whether the entity is mentioned or not in the context, to facilitate reasoning during interaction. 3.3 Dialog and Knowledge Representation In this subsection, we describe how to represent dialog context, external knowledge and user interests in CR-Walker. Utterance Embedding We formulate the dialog history D = {x1 , y1 , . . . , xt−1 , yt−1 , xt }, where xt and yt is user/system utterance respectively. At each dialog turn t, we first use BERT (Devlin et al., 2019) to encode last system utterance yt−1 and current user utterance xt successively. The embedding of “[CLS]” token of xt is applied as the turn’s representation, denoted as BERT([yt−1 ; xt ]). Then the utterance embedding ut is obtained simply through a LSTM over BERT([yt−1 ; xt ]) to capture the sentence-level dependencies. Formally, ut = LSTM(ut−1 , BERT([yt−1 ; xt ])). (1) Entity Embedding To introduce external structured knowledge in CR-Walker, we extract KG from DBpedia (Auer et al., 2007) and add generic classes (see Sec. 3.1). We encode the graph using R-GCN (Schlichtkrull et al., 2018),"
2021.emnlp-main.139,N16-1014,0,0.0391513,"as additional feature (+ConceptNet in Table 2), and even outperforms KGSF on Recall@1 and Recall@10, but this is not the focus of this paper. Regarding recommendation diversity, CR-Walker outperformed all baselines including KGSF. The tree structured reasoning enables multiple items to be recommended at the second hop, each with its certain attributes related to earlier conversation. This results in a higher coverage of candidate items compared with 1-hop reasoning that directly arrives at recommendation. easily, even without user utterances. Response Generation We apply BLEU and Distinct-n (Li et al., 2016) to measure the generated response on word-level matches and diversity. Noting that different from Chen et al. (2019) that calculate sentence-level Distinct, we use corpus-level Distinct to give a more comprehensive assessment. Following Wu et al. (2019), we also adopt knowledge F1-score to measure knowledge exploitation. Unlike metrics in item recommendation, the knowledge score is calculated by corresponding generic classes rather than the exact match. For example, it only evaluates whether the system mentioned the genre to promote movie recommendation but does not care about the exact genre"
2021.emnlp-main.139,2020.acl-main.98,0,0.0123259,"ed annotations that follow single-path reasoning scheme. However, multiple entities can be selected at each reasoning hop (e.g. recommend several items within one turn, each item with different reasons). Therefore, we propose tree-structured reasoning in this work to enable CRS to select multiple entities through multi-path reasoning for accurate recommendation. Xu et al. (2020) introduces a dynamic user memory graph to address the reasoning of user knowledge in CRS, which is beyond the scope of this paper. The other is dialog-biased CRS (Li et al., 2018; Kang et al., 2019; Liao et al., 2019; Liu et al., 2020) that makes recommendations using free text, which have much flexibility to influence how the dialog continues. As these systems suffer from existing limitations in NLP (e.g. understand preference implicitly from user expression), most methods incorporate external information such as KG and user logs to enhance the dialog semantics (Yu et al., 2019; Zhou et al., 2020a) or update the user representation (Zhang et al., 2019; Chen et al., 2 2019). However, these methods do not capture The codes are released at https://github.com/ truthless11/CR-Walker higher-level strategic behaviors in recommend"
2021.emnlp-main.139,P19-1081,0,0.158423,"Computational Linguistics interests in “Comedy” movies. It then recommends “Thor” based on several distinct paths of reasoning over user preference (“comedy” & “action”). Another challenge lies in fully utilizing the selected entities in response generation. Since different dialog actions can be applied in conversational recommendation, selected entities needs to be properly expressed with the guide of dialog acts, an abstract representation of dialog semantics and intentions, in order to form natural, informative, and engaging utterances to interact with users. However, most previous works (Moon et al., 2019; Lei et al., 2020a) stopped at inferring entities without modeling response generation. In Fig. 1 again, the agent first asks the user’s preferred genres and actors, and then talks about the star and the movie to engage the user in the conversation, and last recommends a movie based on the user interests. In addition, the agent provides explanations at the third turn to make recommendation more interpretable and persuasive. To address these issues, we propose Conversational Recommendation Walker (CR-Walker) in this paper. It first selects a system intent to decide whether the system asks for"
2021.emnlp-main.139,2020.acl-main.59,1,0.892942,"Missing"
2021.emnlp-main.139,D19-1010,1,0.822488,"tes topic threads to enforce transitions actively towards final recommendation, but it models CRS as an open-ended chit-chat task, which does not fully utilize relations between items and their attributes in response. In contrast, CRS can be regarded as a variation of task-oriented dialog system that supports its users in achieving recommendation-related goals through multi-turn conversations (Tran et al., 2020). Inspired by the use of dialog acts (Traum, 1999), we choose a set of system dialog acts in CRS to facilitate information filtering and decision making as task-oriented dialog policy (Takanobu et al., 2019, 2020) does. 3 CR-Walker: Conversational Recommendation Walker In this section, we start from defining the key concepts of knowledge graph and dialog acts used in CR-Walker. As illustrated in Fig. 2, CR-Walker works as follows: First of all, dialog history is represented in two views: one is utterance embedding in the content view, and the other is user portrait in the user interest view. Then, CR-Walker makes reasoning on a KG to obtain a reasoning tree, which is treated as a dialog act. Afterwards, the treestructured dialog act is linearized to a sequence, on which CR-Walker finally generat"
2021.emnlp-main.139,2020.emnlp-demos.6,0,0.0290032,"Missing"
2021.emnlp-main.139,P19-1369,0,0.0240938,"asoning enables multiple items to be recommended at the second hop, each with its certain attributes related to earlier conversation. This results in a higher coverage of candidate items compared with 1-hop reasoning that directly arrives at recommendation. easily, even without user utterances. Response Generation We apply BLEU and Distinct-n (Li et al., 2016) to measure the generated response on word-level matches and diversity. Noting that different from Chen et al. (2019) that calculate sentence-level Distinct, we use corpus-level Distinct to give a more comprehensive assessment. Following Wu et al. (2019), we also adopt knowledge F1-score to measure knowledge exploitation. Unlike metrics in item recommendation, the knowledge score is calculated by corresponding generic classes rather than the exact match. For example, it only evaluates whether the system mentioned the genre to promote movie recommendation but does not care about the exact genre. Results show that CR-Walker outperforms all baselines on corpus-level language diversity by a large margin (dist-2,3 in Table 3). Noticeably, while CR-Walker achieves the highest BLEU in GoRecDial, BLEU in ReDial drops a little when incorporating tree-"
2021.emnlp-main.139,2020.coling-main.463,0,0.0365443,"(Christakopoulou et al., 2016, 2018), thus leading to unsatisfactory user experience. Recently, Moon et al. (2019) improves knowledge selection by assuming a single chain of reasoning throughout the conversation. It relies on finegrained annotations that follow single-path reasoning scheme. However, multiple entities can be selected at each reasoning hop (e.g. recommend several items within one turn, each item with different reasons). Therefore, we propose tree-structured reasoning in this work to enable CRS to select multiple entities through multi-path reasoning for accurate recommendation. Xu et al. (2020) introduces a dynamic user memory graph to address the reasoning of user knowledge in CRS, which is beyond the scope of this paper. The other is dialog-biased CRS (Li et al., 2018; Kang et al., 2019; Liao et al., 2019; Liu et al., 2020) that makes recommendations using free text, which have much flexibility to influence how the dialog continues. As these systems suffer from existing limitations in NLP (e.g. understand preference implicitly from user expression), most methods incorporate external information such as KG and user logs to enhance the dialog semantics (Yu et al., 2019; Zhou et al.,"
2021.emnlp-main.142,N19-1003,0,0.0179489,"this way, GradAug prevents replacing tokens that are critical for a downstream task. 2.2 Self-training The first focus of self-training is designing better policies to label unlabeled samples. Zhang and Zhou (2011) evaluated the confidence via a The main contribution of this paper is three-fold: statistic-based data editing technique. Lee (2013) • This is the first attempt to study the effect of designed an annealing function that gradually inself-training on top of existing strong pre-trained creases the loss of labeled samples during training. models for ToD in few-shot learning scenarios. Amiri (2019) utilized a Leitner queue (Dempster, 1989) to gradually put confident samples in the • We propose a self-training method to gradually front. Niu et al. (2020) selected the most confident train a stronger Student by iteratively labeling samples with prediction loss below some threshthe most confident unlabeled data and a new text old. Kumar et al. (2010); Ma et al. (2017); Li et al. augmentation technique (GradAug). (2019); Mukherjee and Awadallah (2020) proposed to learn sampling weights for unlabeled data to con• We conduct extensive experiments on four downtrol the selection process. Reinfor"
2021.emnlp-main.142,D19-5602,0,0.0205129,"elector. Nevertheless, methods using strate that self-training consistently improves learnable weights or RL provide marginal benefits state-of-the-art pre-trained models (BERT, ToDcompared to the elevated optimization cost. As BERT Wu et al. (2020)). designing new sample selection schemes is not our primary focus, we will go for a simple and effective pipeline described in Section 4.1. Specialized ex2 Related Work plorations on this topic are orthogonal to the focus of this paper and will be left as future work. 2.1 Pre-training for ToD Systems The second focus of self-training is to improve Budzianowski and Vulic (2019) first applied GPT- the robustness of the Student model trained from 2 to train a response generation model by taking potentially noisy pseudo-labeled samples. Data the system belief state, database entries, and last augmentation techniques are widely used. In comdialog turn as input. Henderson et al. (2019) pre- puter vision, recent works demonstrated the bentrained a response selection model for ToD by first efit of different stochastic augmentation tricks, pre-training on general-domain conversational cor- including input transformations (Laine and Aila, pora (Reddit). Ham et al. (2020); Ho"
2021.emnlp-main.142,D18-1547,0,0.050169,"Missing"
2021.emnlp-main.142,D18-1045,0,0.0210574,"rbations to word embeddings. Wei and Zou firmed these findings for ToD. For the task of gener- (2019) proposed EDA using basic synonym replaceating responses conditioned on a semantic represen- ment, random insertion, swap, and deletion. Kutation, GPT-2 was leveraged by Peng et al. (2020b) mar et al. (2019) proposed to maximize a monotone to improve few-shot learning. Peng et al. (2020a) sub-modular function to obtain diverse paraphrases. utilized GPT-2 for few-shot end-to-end response Xie et al. (2019) proposed UDA applying backgeneration from dialog contexts. T5 (Raffel et al., translation (Edunov et al., 2018) and word replace2020) is also recently applied to few-shot ToD by ment using a Tf-Idf metric. He et al. (2020) studied Lin et al. (2021) for dialog state tracking and by the effect of dropout compared to back-translation Kale and Rastogi (2020) for natural language gen- during self-training for the neural sequence genereration. Wu et al. (2020) improve a BERT model ation task. Chen et al. (2020) proposed MixText for few-shot learning on four downstream tasks. that utilizes Manifold Mixup (Verma et al., 2019) 1888 to interpolate hidden layers corresponding to semantic representations of BERT."
2021.emnlp-main.142,P18-1082,0,0.0289057,"i . The probability pi of masking the M ˜ (Xi ) as: i-th token is inversely correlated to M Input: Labeled data: L, Teacher: F T , Number of augmentations per input: q Output: Augmented labeled data LAug 1: Initialize LAug ← L 2: for {x, y} ∈ L do 3: Compute masking probability p using F T 4: for j ∈ 1 . . . q do 5: x0 ← Mask tokens of x based on p 6: x ˆ ← Predict masked tokens by MLM 7: LAug .append({ˆ x, y}) 8: end for 9: end for Reconstruction using MLM. To reconstruct the masked tokens in x0 , we utilize a pre-trained MLM to predict the [MASK] tokens. For stochastic purposes suggested by Fan et al. (2018), we reconstruct each [MASK] by sampling 1 token from 10 most likely tokens according to their predicted probabilities. Afterwards, we get a paraphrased x ˆ of the original x as an augmentation. As our gradient-based masking scheme avoids replacing tokens crucial to the meaning of x, the label of x ˆ is preserved the same as x. An illustrative example of GradAug is given in Figure 2, and the detailed procedure applying GradAug on L is described in Algorithm 2. 5 5.1 Experiments Dataset Description We evaluate four different datasets for four downstream tasks as in Wu et al. (2020). OOS (Larson"
2021.emnlp-main.142,2020.acl-main.54,0,0.0284896,"wski and Vulic (2019) first applied GPT- the robustness of the Student model trained from 2 to train a response generation model by taking potentially noisy pseudo-labeled samples. Data the system belief state, database entries, and last augmentation techniques are widely used. In comdialog turn as input. Henderson et al. (2019) pre- puter vision, recent works demonstrated the bentrained a response selection model for ToD by first efit of different stochastic augmentation tricks, pre-training on general-domain conversational cor- including input transformations (Laine and Aila, pora (Reddit). Ham et al. (2020); Hosseini-Asl 2017; Xie et al., 2020; Zoph et al., 2020), dropout et al. (2020); Peng et al. (2020a) proposed to train (Laine and Aila, 2017; Xie et al., 2020; Zoph et al., GPT-2 on different sub-tasks (dialog state tracking, 2020), adversarial samples (Miyato et al., 2019), dialog act prediction, and response generation) as and Mixup (Berthelot et al., 2019, 2020). Text a sequence prediction problem. augmentation is more challenging because of the Recent studies have shown that large-scale pre- complex syntactic and semantic structures. Miyato trained language models are good few-shot learne"
2021.emnlp-main.142,W14-4337,0,0.0751468,"Missing"
2021.emnlp-main.142,2020.emnlp-main.527,0,0.0984357,"tion, GPT-2 was leveraged by Peng et al. (2020b) mar et al. (2019) proposed to maximize a monotone to improve few-shot learning. Peng et al. (2020a) sub-modular function to obtain diverse paraphrases. utilized GPT-2 for few-shot end-to-end response Xie et al. (2019) proposed UDA applying backgeneration from dialog contexts. T5 (Raffel et al., translation (Edunov et al., 2018) and word replace2020) is also recently applied to few-shot ToD by ment using a Tf-Idf metric. He et al. (2020) studied Lin et al. (2021) for dialog state tracking and by the effect of dropout compared to back-translation Kale and Rastogi (2020) for natural language gen- during self-training for the neural sequence genereration. Wu et al. (2020) improve a BERT model ation task. Chen et al. (2020) proposed MixText for few-shot learning on four downstream tasks. that utilizes Manifold Mixup (Verma et al., 2019) 1888 to interpolate hidden layers corresponding to semantic representations of BERT. Ng et al. (2020) proposed SSMBA utilizing the masked language model of BERT to replace words. In experiments, we compare the proposed GradAug technique with state-of-the-art text augmentation methods. 3 Background of Using Pre-trained Models for"
2021.emnlp-main.142,N19-1363,0,0.0605087,"Missing"
2021.emnlp-main.142,D19-1131,0,0.0248084,"Missing"
2021.emnlp-main.142,2021.ccl-1.108,0,0.0837416,"Missing"
2021.emnlp-main.142,2020.emnlp-main.97,0,0.524657,"a better Student. To train a more rocost is very high such that the size of well-labeled bust Student during self-training, we propose a data data is often small. Therefore, few-shot learning augmentation technique called GradAug. GradAug in ToD is important and valuable in many practical first “masks” a fraction of tokens of a dialog input. applications. Many attempts (Peng et al., 2020b,a; Then, it reconstructs the corrupted text with a preWu et al., 2020) have been proposed to leverage trained masked language model of BERT. Different large-scale pre-trained language models to improve from Ng et al. (2020), the probability of masking 1887 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1887–1898 c November 7–11, 2021. 2021 Association for Computational Linguistics a token is conditioned on the gradient of the corresponding token embedding w.r.t. the downstream task. In this way, GradAug prevents replacing tokens that are critical for a downstream task. 2.2 Self-training The first focus of self-training is designing better policies to label unlabeled samples. Zhang and Zhou (2011) evaluated the confidence via a The main contribution of this paper is"
2021.emnlp-main.142,2020.acl-main.361,1,0.836795,"ter policies to label unlabeled samples. Zhang and Zhou (2011) evaluated the confidence via a The main contribution of this paper is three-fold: statistic-based data editing technique. Lee (2013) • This is the first attempt to study the effect of designed an annealing function that gradually inself-training on top of existing strong pre-trained creases the loss of labeled samples during training. models for ToD in few-shot learning scenarios. Amiri (2019) utilized a Leitner queue (Dempster, 1989) to gradually put confident samples in the • We propose a self-training method to gradually front. Niu et al. (2020) selected the most confident train a stronger Student by iteratively labeling samples with prediction loss below some threshthe most confident unlabeled data and a new text old. Kumar et al. (2010); Ma et al. (2017); Li et al. augmentation technique (GradAug). (2019); Mukherjee and Awadallah (2020) proposed to learn sampling weights for unlabeled data to con• We conduct extensive experiments on four downtrol the selection process. Reinforcement learning stream tasks in ToD, including intent classifica(RL) methods (Chen et al., 2018; Wu et al., 2018; tion, dialog state tracking, dialog act pred"
2021.emnlp-main.142,2020.findings-emnlp.17,0,0.0840229,"ostic ples. The Teacher then iteratively generates pseudolanguage knowledge learned via pre-training tasks. labels for the most confident subset of unlabeled In task-oriented dialog (ToD) systems, the labeling samples to train a better Student. To train a more rocost is very high such that the size of well-labeled bust Student during self-training, we propose a data data is often small. Therefore, few-shot learning augmentation technique called GradAug. GradAug in ToD is important and valuable in many practical first “masks” a fraction of tokens of a dialog input. applications. Many attempts (Peng et al., 2020b,a; Then, it reconstructs the corrupted text with a preWu et al., 2020) have been proposed to leverage trained masked language model of BERT. Different large-scale pre-trained language models to improve from Ng et al. (2020), the probability of masking 1887 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1887–1898 c November 7–11, 2021. 2021 Association for Computational Linguistics a token is conditioned on the gradient of the corresponding token embedding w.r.t. the downstream task. In this way, GradAug prevents replacing tokens that are critica"
2021.emnlp-main.142,N18-3006,0,0.0586786,"Missing"
2021.emnlp-main.142,P95-1026,0,0.316347,"acto has many unlabeled ules with the least amount of labeled data. Redialog data. Therefore, utilizing unlabeled data to cently, large-scale pre-trained language modimprove a ToD system is practically important. In els, have shown promising results for few-shot learning in ToD. In this paper, we devise a selfthis paper, we take a semi-supervised self-training training approach to utilize the abundant unla(ST) perspective to iteratively train a better Stubeled dialog data to further improve state-ofdent model using unlabeled data (Scudder, 1965; the-art pre-trained models in few-shot learning Yarowsky, 1995). ST has been successfully applied scenarios for ToD systems. Specifically, we to a variety of tasks, including image classification propose a self-training approach that iteratively (Yalniz et al., 2019; Xie et al., 2020; Zoph et al., labels the most confident unlabeled data to train 2020), automatic speech classification (Synnaeve a stronger Student model. Moreover, a new et al., 2019; Kahn et al., 2020; Park et al., 2020; text augmentation technique (GradAug) is proposed to better train the Student by replacing Likhomanenko et al., 2020), sequence generation non-crucial tokens using a maske"
2021.emnlp-main.142,2020.acl-main.272,0,0.0390509,"d the most confident train a stronger Student by iteratively labeling samples with prediction loss below some threshthe most confident unlabeled data and a new text old. Kumar et al. (2010); Ma et al. (2017); Li et al. augmentation technique (GradAug). (2019); Mukherjee and Awadallah (2020) proposed to learn sampling weights for unlabeled data to con• We conduct extensive experiments on four downtrol the selection process. Reinforcement learning stream tasks in ToD, including intent classifica(RL) methods (Chen et al., 2018; Wu et al., 2018; tion, dialog state tracking, dialog act prediction, Ye et al., 2020) designed an additional Q-agent as and response selection. Empirical results demonthe sample selector. Nevertheless, methods using strate that self-training consistently improves learnable weights or RL provide marginal benefits state-of-the-art pre-trained models (BERT, ToDcompared to the elevated optimization cost. As BERT Wu et al. (2020)). designing new sample selection schemes is not our primary focus, we will go for a simple and effective pipeline described in Section 4.1. Specialized ex2 Related Work plorations on this topic are orthogonal to the focus of this paper and will be left as"
2021.emnlp-main.142,D19-1670,0,0.0555885,"Missing"
2021.emnlp-main.142,2020.emnlp-main.66,0,0.40837,"ge learned via pre-training tasks. labels for the most confident subset of unlabeled In task-oriented dialog (ToD) systems, the labeling samples to train a better Student. To train a more rocost is very high such that the size of well-labeled bust Student during self-training, we propose a data data is often small. Therefore, few-shot learning augmentation technique called GradAug. GradAug in ToD is important and valuable in many practical first “masks” a fraction of tokens of a dialog input. applications. Many attempts (Peng et al., 2020b,a; Then, it reconstructs the corrupted text with a preWu et al., 2020) have been proposed to leverage trained masked language model of BERT. Different large-scale pre-trained language models to improve from Ng et al. (2020), the probability of masking 1887 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1887–1898 c November 7–11, 2021. 2021 Association for Computational Linguistics a token is conditioned on the gradient of the corresponding token embedding w.r.t. the downstream task. In this way, GradAug prevents replacing tokens that are critical for a downstream task. 2.2 Self-training The first focus of self-train"
2021.emnlp-main.142,P19-1078,0,0.0492367,"Missing"
2021.emnlp-main.142,N18-1113,0,0.0226662,"a self-training method to gradually front. Niu et al. (2020) selected the most confident train a stronger Student by iteratively labeling samples with prediction loss below some threshthe most confident unlabeled data and a new text old. Kumar et al. (2010); Ma et al. (2017); Li et al. augmentation technique (GradAug). (2019); Mukherjee and Awadallah (2020) proposed to learn sampling weights for unlabeled data to con• We conduct extensive experiments on four downtrol the selection process. Reinforcement learning stream tasks in ToD, including intent classifica(RL) methods (Chen et al., 2018; Wu et al., 2018; tion, dialog state tracking, dialog act prediction, Ye et al., 2020) designed an additional Q-agent as and response selection. Empirical results demonthe sample selector. Nevertheless, methods using strate that self-training consistently improves learnable weights or RL provide marginal benefits state-of-the-art pre-trained models (BERT, ToDcompared to the elevated optimization cost. As BERT Wu et al. (2020)). designing new sample selection schemes is not our primary focus, we will go for a simple and effective pipeline described in Section 4.1. Specialized ex2 Related Work plorations on thi"
2021.emnlp-main.183,P19-1602,0,0.0606506,"ERSONA M IN E DIT Data Collection We present a new dataset P ERSONA M IN E DIT to evaluate persona-grounded minimal editing. Validation and test data are collected in two steps: Editing persona selection We first construct inference samples (c, ro , pe ), where the dialogue history c and original response ro are from P ER SONAC HAT , and we select the editing persona pe based on two criteria: 1) editing difficulty and 2) conversation consistency. We bias our data to the hard cases that require correction of persona contradictions. Specifically, we use the heuristics provided by Welleck et al. (2019) to select personas that are contradictory to the original response. To ensure conversation consistency, we filter out personas that are contradictory to the speaker’s responses in the dialogue history. Finally, we also ensure that the persona sentences within each persona are not contradictory to each other. Response editing For each constructed triple (c, ro , pe ), we collect references for the edited responses re on Amazon Mechanical Turk. Specifically, re should satisfy three requirements: 1) consistency with the editing persona pe , 2) minimal editing, and 3) coherence with the dialogue"
2021.emnlp-main.183,P06-4018,0,0.0498321,"Missing"
2021.emnlp-main.183,N19-1124,0,0.0897464,"thetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et al., 2020), and retrieval-augmented dialogue modeling (Weston et al., 2018; Pandey et al., 2018; Wu et al., 2019b; Gu et al., 2019; Cai et al., 2019). This paper is essentially different from these works from two perspectives. 1) Regarding the formulation, we emphasize minimal editing, while previous works do not. As analyzed in Section 1, minimal editing is an important component to address the transferability challenges; 2) Regarding the training algorithm, previous works derive templates from self-generated or retrieved texts, while our model derives templates from the observed responses. Our work is also related to controlled text editing • We propose a framework named grounded without parallel data, e.g., unsupervised text style minim"
2021.emnlp-main.183,D19-1201,0,0.01552,"M IN E DIT dataset. GME is also transferable to edit other models’ outputs and improve the persona consistency while preserving their use of knowledge and empathy. 2 Related Work Recent work leveraged grounded information in dialogue agents to chat engagingly, e.g., using knowledge (Zhou et al., 2018b), emotions (Zhou et al., 2018a), personas (Zhang et al., 2018), and images (Shuster et al., 2020). For persona grounding (Li et al., 2016; Zhang et al., 2018), transfer learning methods (Zhang et al., 2019; Wolf et al., 2019; Golovanov et al., 2019) and latent variable models (Song et al., 2019; Chan et al., 2019) have shown promising results. Further, the persona consistency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et"
2021.emnlp-main.183,2020.emnlp-main.65,0,0.0259074,"e persona consistency while preserving their use of knowledge and empathy. 2 Related Work Recent work leveraged grounded information in dialogue agents to chat engagingly, e.g., using knowledge (Zhou et al., 2018b), emotions (Zhou et al., 2018a), personas (Zhang et al., 2018), and images (Shuster et al., 2020). For persona grounding (Li et al., 2016; Zhang et al., 2018), transfer learning methods (Zhang et al., 2019; Wolf et al., 2019; Golovanov et al., 2019) and latent variable models (Song et al., 2019; Chan et al., 2019) have shown promising results. Further, the persona consistency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et al., 2020), and retrieval-augmented dialogue modeling (Weston et al., 2018; Pandey et"
2021.emnlp-main.183,P16-1094,0,0.0315869,"E DIT dataset to evaluate GME’s effectiveness for personagrounded minimal editing. • Experimental results show that GME largely outperforms strong baselines on the P ERSON A M IN E DIT dataset. GME is also transferable to edit other models’ outputs and improve the persona consistency while preserving their use of knowledge and empathy. 2 Related Work Recent work leveraged grounded information in dialogue agents to chat engagingly, e.g., using knowledge (Zhou et al., 2018b), emotions (Zhou et al., 2018a), personas (Zhang et al., 2018), and images (Shuster et al., 2020). For persona grounding (Li et al., 2016; Zhang et al., 2018), transfer learning methods (Zhang et al., 2019; Wolf et al., 2019; Golovanov et al., 2019) and latent variable models (Song et al., 2019; Chan et al., 2019) have shown promising results. Further, the persona consistency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grou"
2021.emnlp-main.183,N18-1169,0,0.0612335,"Missing"
2021.emnlp-main.183,P19-1542,0,0.0374087,"Missing"
2021.emnlp-main.183,2020.emnlp-main.699,0,0.0418376,"e edited responses are longer than the original ones, which can be explained by the observation that human sometimes add persona information into the response when no persona contradiction exists. 6 Experiment on P ERSONA M IN E DIT We use P ERSONA M IN E DIT to evaluate personagrounded minimal editing (Q1 in Section 1). 6.1 Baselines We modify state-of-the-art models for unsupervised text style transfer and counterfactual story generation as the baselines for grounded minimal editing. No edit This baseline does not make any edits to the original response. UNMT Lample et al. (2019); He et al. (2020) adopted the unsupervised neural machine translation (UNMT) model (Lample et al., 2018) for unsupervised text style transfer. For our task, we replace the style condition with persona condition, and use a word dropout rate pwd ∈ {0.1, 0.5}. CycleGAN Luo et al. (2019); Dai et al. (2019) adopted CycleGAN (Zhu et al., 2017) for unsupervised text style transfer. For our task, we replace the style classifier with a response-to-persona model. We use Gumbel-softmax straight through gradient 5.2 Data Statistics estimator (Jang et al., 2017) for optimization. After removing training samples whose perso"
2021.emnlp-main.183,D17-2014,0,0.0221883,"a persona-agnostic Blender-90M (Roller et al., 2020), which is trained on B LENDED S KILLTALK in which the persona sentences are removed. • Responses generated by the original personagrounded Blender-90M. We compare the above two Blender-90M variants and GME-edited resposnes with TransferTransfo (Wolf et al., 2019), a pretrained dialogue model finetuned on P ERSONAC HAT. Note that GME is not finetuned on B LENDED S KILLTALK. Also, conversations in P ERSONAC HAT, on which GME and TransferTransfo are trained, barely display knowledge and empathy. 7.2 Automatic Evaluation We report BLEU and F1 (Miller et al., 2017) computed with the human references. For persona consistency, we report the P-Score defined in Section 6.2. To evaluate fluency, we report the wordlevel NLL evaluated by GPT-2 (Radford et al., 7 Transferability Experiment 2018). The automatic evaluation uses the full 5482 We evaluate the transferability of GME to mini- test samples of B LENDED S KILLTALK. mally edit existing responses on the test split of Table 6 shows that P-Scores are largely improved B LENDED S KILLTALK (Smith et al., 2020). We after GME editing (from 9.2 to 33.0, and from 0.8 also evaluate whether grounded minimal editing"
2021.emnlp-main.183,P18-1123,0,0.0236646,"al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et al., 2020), and retrieval-augmented dialogue modeling (Weston et al., 2018; Pandey et al., 2018; Wu et al., 2019b; Gu et al., 2019; Cai et al., 2019). This paper is essentially different from these works from two perspectives. 1) Regarding the formulation, we emphasize minimal editing, while previous works do not. As analyzed in Section 1, minimal editing is an important component to address the transferability challenges; 2) Regarding the training algorithm, previous works derive templates from self-generated or retrieved texts, while our model derives templates from the observed responses. Our work is also related to controlled text editing • We propose a framework named grounded with"
2021.emnlp-main.183,P02-1040,0,0.10929,"nsupervised text style transfer. For our task, we replace the style classifier with a response-to-persona model. We use Gumbel-softmax straight through gradient 5.2 Data Statistics estimator (Jang et al., 2017) for optimization. After removing training samples whose persona DeLorean-FT DeLorean (Qin et al., 2020) iteraappears in the editing personas in the validation and tively modifying GPT-2’s logits via gradients from 2372 6.2 Automatic Evaluation For automatic evaluation, we run each experiment with five random seeds. More details are presented in Appendix C. BLEU We compute BLEU-4 score (Papineni et al., 2002) based on the collected multiple human references, using the Moses script multi-bleu.perl. From Table 2 and Table 5, we observe that higher BLEU indicates the less editing. P-Score We define P-Score to evaluate the persona consistency. Specifically, we finetune a BERT model on the DNLI dataset (Welleck et al., 2019) to predict the relation C(r, pj ) (entailment, neutral, or contradiction) of a response r and a persona sentence pj .2 We then map entailment, neutral, and contradiction to +0.5, 0, and −0.5 and define the P-Score of a sample as X P-Score = map[C(re , pej )] (4) j where re is the e"
2021.emnlp-main.183,2020.emnlp-main.58,0,0.033052,"Missing"
2021.emnlp-main.183,N18-1012,0,0.0608416,"Missing"
2021.emnlp-main.183,2020.acl-main.219,0,0.121009,"rnal information natural conversations. As a result, models trained is important for building engaging conversational with Eq. (1) may generate unnatural responses and AI systems (Huang et al., 2020). Along this track, are vulnerable to the distributional shift of the diavarious datasets and models have been proposed to logue history. On the other hand, at inference time, ground dialogues on personas (Zhang et al., 2018), models trained with Eq. (1) cannot be grounded on knowledge (Dinan et al., 2019), emotions (Zhou unseen types of concept g 0 other than g. An examet al., 2018a), and images (Shuster et al., 2020). ple for such grounding gap is that a model trained Generally, grounded dialogue modeling trains on P ERSONAC HAT (Zhang et al., 2018) with Eq. (1) a dialogue model on a dataset D that consists of cannot be grounded on world knowledge. triples (c, r, g), where c is the dialogue history, r To address the above transferability challenges, is the response, and g is the grounded concept. we propose a grounded minimal editing framework The model is generally optimized using maximum for grounded dialogue modeling. Instead of learnlikelihood estimate (MLE), i.e., ing a grounded response generator as"
2021.emnlp-main.183,2020.acl-main.183,0,0.0132055,"nference. Two research questions are investigated in this paper: Q1) Is the proposed GME model effective for grounded minimal editing? Q2) Does our framework address the transferability challenges (more specifically, the distributional gap and the grounding gap)? For Q1, we build P ERSONA M IN E DIT, a new dataset derived from P ERSONAC HAT with multiple human references for the edited response. Automatic and human evaluations show that GME outperforms competitive baselines and has the most similar behavior to humans references. For Q2, we evaluate GME on the test set of B LENDED S KIL LTALK (Smith et al., 2020), whose data distribution and grounded concepts are different from P ER SONAC HAT , which requires GME to be transferable. We observe that GME improves the persona consistency of responses generated by pretrained Blender-90M models (Roller et al., 2020), while preserving the use of knowledge and empathy. Results also show that GME-edited responses largely outperforms TransferTransfo (Wolf et al., 2019), which is trained in the canonical way as in Eq. (1). Our contributions include: challenges of grounded dialogue modeling. • We propose Grounded Minimal Editor (GME) and present the P ERSONA M I"
2021.emnlp-main.183,2020.acl-main.516,0,0.0136987,", 2019) have shown promising results. Further, the persona consistency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et al., 2020), and retrieval-augmented dialogue modeling (Weston et al., 2018; Pandey et al., 2018; Wu et al., 2019b; Gu et al., 2019; Cai et al., 2019). This paper is essentially different from these works from two perspectives. 1) Regarding the formulation, we emphasize minimal editing, while previous works do not. As analyzed in Section 1, minimal editing is an important component to address the transferability challenges; 2) Regarding the training algorithm, previous works derive templates from self-generated or retrieved texts, while our model derives templates from the observed responses. Our work is"
2021.emnlp-main.183,D19-1509,0,0.0834321,"ERSONA M IN E DIT Data Collection We present a new dataset P ERSONA M IN E DIT to evaluate persona-grounded minimal editing. Validation and test data are collected in two steps: Editing persona selection We first construct inference samples (c, ro , pe ), where the dialogue history c and original response ro are from P ER SONAC HAT , and we select the editing persona pe based on two criteria: 1) editing difficulty and 2) conversation consistency. We bias our data to the hard cases that require correction of persona contradictions. Specifically, we use the heuristics provided by Welleck et al. (2019) to select personas that are contradictory to the original response. To ensure conversation consistency, we filter out personas that are contradictory to the speaker’s responses in the dialogue history. Finally, we also ensure that the persona sentences within each persona are not contradictory to each other. Response editing For each constructed triple (c, ro , pe ), we collect references for the edited responses re on Amazon Mechanical Turk. Specifically, re should satisfy three requirements: 1) consistency with the editing persona pe , 2) minimal editing, and 3) coherence with the dialogue"
2021.emnlp-main.183,P19-1363,0,0.0954048,"uation Data: P ERSONA M IN E DIT Data Collection We present a new dataset P ERSONA M IN E DIT to evaluate persona-grounded minimal editing. Validation and test data are collected in two steps: Editing persona selection We first construct inference samples (c, ro , pe ), where the dialogue history c and original response ro are from P ER SONAC HAT , and we select the editing persona pe based on two criteria: 1) editing difficulty and 2) conversation consistency. We bias our data to the hard cases that require correction of persona contradictions. Specifically, we use the heuristics provided by Welleck et al. (2019) to select personas that are contradictory to the original response. To ensure conversation consistency, we filter out personas that are contradictory to the speaker’s responses in the dialogue history. Finally, we also ensure that the persona sentences within each persona are not contradictory to each other. Response editing For each constructed triple (c, ro , pe ), we collect references for the edited responses re on Amazon Mechanical Turk. Specifically, re should satisfy three requirements: 1) consistency with the editing persona pe , 2) minimal editing, and 3) coherence with the dialogue"
2021.emnlp-main.183,W18-5713,0,0.0765915,"istency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et al., 2020), and retrieval-augmented dialogue modeling (Weston et al., 2018; Pandey et al., 2018; Wu et al., 2019b; Gu et al., 2019; Cai et al., 2019). This paper is essentially different from these works from two perspectives. 1) Regarding the formulation, we emphasize minimal editing, while previous works do not. As analyzed in Section 1, minimal editing is an important component to address the transferability challenges; 2) Regarding the training algorithm, previous works derive templates from self-generated or retrieved texts, while our model derives templates from the observed responses. Our work is also related to controlled text editing • We propose a framewor"
2021.emnlp-main.183,2020.emnlp-demos.6,0,0.0173202,"e edited responses are longer than the original ones, which can be explained by the observation that human sometimes add persona information into the response when no persona contradiction exists. 6 Experiment on P ERSONA M IN E DIT We use P ERSONA M IN E DIT to evaluate personagrounded minimal editing (Q1 in Section 1). 6.1 Baselines We modify state-of-the-art models for unsupervised text style transfer and counterfactual story generation as the baselines for grounded minimal editing. No edit This baseline does not make any edits to the original response. UNMT Lample et al. (2019); He et al. (2020) adopted the unsupervised neural machine translation (UNMT) model (Lample et al., 2018) for unsupervised text style transfer. For our task, we replace the style condition with persona condition, and use a word dropout rate pwd ∈ {0.1, 0.5}. CycleGAN Luo et al. (2019); Dai et al. (2019) adopted CycleGAN (Zhu et al., 2017) for unsupervised text style transfer. For our task, we replace the style classifier with a response-to-persona model. We use Gumbel-softmax straight through gradient 5.2 Data Statistics estimator (Jang et al., 2017) for optimization. After removing training samples whose perso"
2021.emnlp-main.183,P18-1205,0,0.0255136,"eling. • We propose Grounded Minimal Editor (GME) and present the P ERSONA M IN E DIT dataset to evaluate GME’s effectiveness for personagrounded minimal editing. • Experimental results show that GME largely outperforms strong baselines on the P ERSON A M IN E DIT dataset. GME is also transferable to edit other models’ outputs and improve the persona consistency while preserving their use of knowledge and empathy. 2 Related Work Recent work leveraged grounded information in dialogue agents to chat engagingly, e.g., using knowledge (Zhou et al., 2018b), emotions (Zhou et al., 2018a), personas (Zhang et al., 2018), and images (Shuster et al., 2020). For persona grounding (Li et al., 2016; Zhang et al., 2018), transfer learning methods (Zhang et al., 2019; Wolf et al., 2019; Golovanov et al., 2019) and latent variable models (Song et al., 2019; Chan et al., 2019) have shown promising results. Further, the persona consistency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distrib"
2021.emnlp-main.183,2020.emnlp-main.531,0,0.020594,"Related Work Recent work leveraged grounded information in dialogue agents to chat engagingly, e.g., using knowledge (Zhou et al., 2018b), emotions (Zhou et al., 2018a), personas (Zhang et al., 2018), and images (Shuster et al., 2020). For persona grounding (Li et al., 2016; Zhang et al., 2018), transfer learning methods (Zhang et al., 2019; Wolf et al., 2019; Golovanov et al., 2019) and latent variable models (Song et al., 2019; Chan et al., 2019) have shown promising results. Further, the persona consistency issue (Kim et al., 2020; Nie et al., 2020) and persona-augmented empathetic agents (Zhong et al., 2020) have also been explored. As discussed in Section 1, existing methods generally adopt the MLE objective in Eq. (1) and suffer from two transferability challenges, i.e., the distributional gap and the grounding gap, which are addressed by the proposed grounded minimal editing framework. The idea of editing existing responses has been explored, e.g., the deliberation network (Xia et al., 2017), two-pass response generation (Song et al., 2020), and retrieval-augmented dialogue modeling (Weston et al., 2018; Pandey et al., 2018; Wu et al., 2019b; Gu et al., 2019; Cai et al., 2019). This paper is e"
2021.emnlp-main.183,2020.acl-main.639,0,0.0181434,"e edited responses are longer than the original ones, which can be explained by the observation that human sometimes add persona information into the response when no persona contradiction exists. 6 Experiment on P ERSONA M IN E DIT We use P ERSONA M IN E DIT to evaluate personagrounded minimal editing (Q1 in Section 1). 6.1 Baselines We modify state-of-the-art models for unsupervised text style transfer and counterfactual story generation as the baselines for grounded minimal editing. No edit This baseline does not make any edits to the original response. UNMT Lample et al. (2019); He et al. (2020) adopted the unsupervised neural machine translation (UNMT) model (Lample et al., 2018) for unsupervised text style transfer. For our task, we replace the style condition with persona condition, and use a word dropout rate pwd ∈ {0.1, 0.5}. CycleGAN Luo et al. (2019); Dai et al. (2019) adopted CycleGAN (Zhu et al., 2017) for unsupervised text style transfer. For our task, we replace the style classifier with a response-to-persona model. We use Gumbel-softmax straight through gradient 5.2 Data Statistics estimator (Jang et al., 2017) for optimization. After removing training samples whose perso"
2021.emnlp-main.184,P19-1081,0,0.0234423,"dels EARL can generate informative responses with both seen knowledge graphs and unseen Some prior works introduce high-quality structured knowledge graphs in two benchmark datasets. knowledge graph for conversation generation. Zhu Ablation studies demonstrate the influence of et al. (2017) presented an end-to-end knowledge different mechanisms and conversation frame- grounded conversation model using a copy networks. work (Gu et al., 2016). A large-scale commonsense 2384 knowledge graph is introduced to open-domain conversation generation by graph attention mechanisms in (Zhou et al., 2018). Moon et al. (2019) proposed a knowledge graph walker to select relevant entities of the knowledge graph to improve the performance of retrieval-based conversation models. The adjacency matrix (Tuan et al., 2019) is introduced to modeling the dynamic knowledge graph in conversation generation. However, these studies adopt pre-trained knowledge graph embeddings (Zhou et al., 2018), word embeddings (Wu et al., 2019), or the adjacency matrix (Tuan et al., 2019) to represent knowledge triples, making them not applicable for large-scale and unseen knowledge graphs. By contrast, our model addresses this issue by repre"
2021.emnlp-main.184,Y14-1039,0,0.0305778,"ion and the structure informaEARL consists of three modules: an encoder to tion of the knowledge graph. Entity-agnostic repreconvert the context to the hidden representations, sentations are defined as category representations a knowledge interpreter to represent each subject for entities sharing the same context and structure and object entity based on the context and structure information, including two major circumstances. information, and a decoder to generate a token or One is caused by the one-to-many mapping propselect an entity from the knowledge graph deter- erty of knowledge graphs (Fan et al., 2014; Xiao mined by a knowledge selector. The overview of et al., 2016), where a subject has multiple objects EARL is presented in Figure 3. with the same relation. As shown in the left knowlInstead of parameterizing specific representa- edge graph in Figure 1, (Chuck Palahniuk, Write, tions for entities of knowledge graphs as used in Pygmy) and (Chuck Palahniuk, Write, Tell-All) have prior studies (Zhou et al., 2018; Wu et al., 2019; the one-to-many mapping property, and EARL Tuan et al., 2019), EARL learns entity-agnostic rep- learns the same category representation for Pygmy resentations condit"
2021.emnlp-main.184,C16-1316,0,0.0150829,"2 2.1 Related Work Open-domain Conversation Models Recently, Sequence-to-Sequence (Seq2Seq) models (Sutskever et al., 2014; Bahdanau et al., 2014) have been applied to large-scale open-domain conversation generation, including neural responding machine (Shang et al., 2015), hierarchical recurrent models (Serban et al., 2015), and many others (Sordoni et al., 2015; Li et al., 2016; Shao et al., 2017). Some models are proposed to improve the content quality of generated responses by copy mechanisms, diversified beam search algorithms, and various techniques (Shao et al., 2017; Li et al., 2016; Mou et al., 2016; Gu et al., 2016). However, the lack of background information or related knowledge results in significantly degenerated conversations, where the text is bland and strangely repetitive (Holtzman et al., 2020). Other studies, aiming to generate informative responses, incorporate external knowledge into conversation generation, including unstructured texts (Ghazvininejad et al., 2018; Long et al., 2017), and structured knowledge graphs (Han et al., 2015; Xu et al., 2017; Zhou et al., 2018). 2.2 Knowledge Graph Enhanced • Automatic and manual evaluations show that Conversation Models EARL can ge"
2021.emnlp-main.184,P16-1154,0,0.0249314,"k Open-domain Conversation Models Recently, Sequence-to-Sequence (Seq2Seq) models (Sutskever et al., 2014; Bahdanau et al., 2014) have been applied to large-scale open-domain conversation generation, including neural responding machine (Shang et al., 2015), hierarchical recurrent models (Serban et al., 2015), and many others (Sordoni et al., 2015; Li et al., 2016; Shao et al., 2017). Some models are proposed to improve the content quality of generated responses by copy mechanisms, diversified beam search algorithms, and various techniques (Shao et al., 2017; Li et al., 2016; Mou et al., 2016; Gu et al., 2016). However, the lack of background information or related knowledge results in significantly degenerated conversations, where the text is bland and strangely repetitive (Holtzman et al., 2020). Other studies, aiming to generate informative responses, incorporate external knowledge into conversation generation, including unstructured texts (Ghazvininejad et al., 2018; Long et al., 2017), and structured knowledge graphs (Han et al., 2015; Xu et al., 2017; Zhou et al., 2018). 2.2 Knowledge Graph Enhanced • Automatic and manual evaluations show that Conversation Models EARL can generate informative"
2021.emnlp-main.184,W15-4616,0,0.0158617,"lity of generated responses by copy mechanisms, diversified beam search algorithms, and various techniques (Shao et al., 2017; Li et al., 2016; Mou et al., 2016; Gu et al., 2016). However, the lack of background information or related knowledge results in significantly degenerated conversations, where the text is bland and strangely repetitive (Holtzman et al., 2020). Other studies, aiming to generate informative responses, incorporate external knowledge into conversation generation, including unstructured texts (Ghazvininejad et al., 2018; Long et al., 2017), and structured knowledge graphs (Han et al., 2015; Xu et al., 2017; Zhou et al., 2018). 2.2 Knowledge Graph Enhanced • Automatic and manual evaluations show that Conversation Models EARL can generate informative responses with both seen knowledge graphs and unseen Some prior works introduce high-quality structured knowledge graphs in two benchmark datasets. knowledge graph for conversation generation. Zhu Ablation studies demonstrate the influence of et al. (2017) presented an end-to-end knowledge different mechanisms and conversation frame- grounded conversation model using a copy networks. work (Gu et al., 2016). A large-scale commonsense"
2021.emnlp-main.184,D16-1230,0,0.0290225,"p performances in automatic evaluation. For each response pair, three judges were hired to give a preference between the two responses in terms of the following two metrics. The tie was allowed. Notice that system identifiers were masked during annotation. Metrics: We adopted two widely used metrics, Appropriateness and Informativeness as proposed in (Zhou et al., 2018). Appropriateness measures the quality of the generated response at the 4 BLEU (Papineni et al., 2002) is not adopted due to its low content level (whether the response is appropricorrelation with human judgment, as proposed by Liu et al. (2016). ate in relevance, coherence, and adequacy). In2389 Dataset Model Entity Precision Recall F1 Distinct-3 Distinct-4 PPL DuConv Seen Test Set Seq2Seq DIALOGPT MemNet PostKS CopyNet CCM EARL 0.068 0.141 0.195 0.131 0.650 0.655 1.269 0.020 0.054 0.084 0.051 0.399 0.376 0.435 0.013 0.036 0.062 0.036 0.396 0.392 0.478 0.015 0.041 0.068 0.040 0.379 0.365 0.422 0.128 0.078 0.179 0.135 0.255 0.239 0.379 0.201 0.125 0.278 0.232 0.378 0.350 0.519 20.54 9.94 19.88 25.30 15.63 20.71 17.00 DuConv Unseen Test Set Seq2Seq DIALOGPT MemNet PostKS CopyNet CCM EARL 0.062 0.133 0.195 0.110 0.684 0.686 1.310 0.020"
2021.emnlp-main.184,P02-1040,0,0.114287,"e generated by EARL and the one by a baseline for the same context. In total, there are 1,200 pairs since we chose three baselines, which achieve top performances in automatic evaluation. For each response pair, three judges were hired to give a preference between the two responses in terms of the following two metrics. The tie was allowed. Notice that system identifiers were masked during annotation. Metrics: We adopted two widely used metrics, Appropriateness and Informativeness as proposed in (Zhou et al., 2018). Appropriateness measures the quality of the generated response at the 4 BLEU (Papineni et al., 2002) is not adopted due to its low content level (whether the response is appropricorrelation with human judgment, as proposed by Liu et al. (2016). ate in relevance, coherence, and adequacy). In2389 Dataset Model Entity Precision Recall F1 Distinct-3 Distinct-4 PPL DuConv Seen Test Set Seq2Seq DIALOGPT MemNet PostKS CopyNet CCM EARL 0.068 0.141 0.195 0.131 0.650 0.655 1.269 0.020 0.054 0.084 0.051 0.399 0.376 0.435 0.013 0.036 0.062 0.036 0.396 0.392 0.478 0.015 0.041 0.068 0.040 0.379 0.365 0.422 0.128 0.078 0.179 0.135 0.255 0.239 0.379 0.201 0.125 0.278 0.232 0.378 0.350 0.519 20.54 9.94 19.88"
2021.emnlp-main.184,P15-1152,0,0.0217111,"te The Selfish Gene. Figure 1: Conversation samples generated with welltrained knowledge graphs (left) and unseen knowledge graphs (right). Grey nodes are well-trained entities, and white nodes are unseen nodes in the training data. Entities in the blue rectangle share the same entity-agnostic representation (see Section 3.2 for more details). 2 2.1 Related Work Open-domain Conversation Models Recently, Sequence-to-Sequence (Seq2Seq) models (Sutskever et al., 2014; Bahdanau et al., 2014) have been applied to large-scale open-domain conversation generation, including neural responding machine (Shang et al., 2015), hierarchical recurrent models (Serban et al., 2015), and many others (Sordoni et al., 2015; Li et al., 2016; Shao et al., 2017). Some models are proposed to improve the content quality of generated responses by copy mechanisms, diversified beam search algorithms, and various techniques (Shao et al., 2017; Li et al., 2016; Mou et al., 2016; Gu et al., 2016). However, the lack of background information or related knowledge results in significantly degenerated conversations, where the text is bland and strangely repetitive (Holtzman et al., 2020). Other studies, aiming to generate informative r"
2021.emnlp-main.184,N15-1020,0,0.0775017,"Missing"
2021.emnlp-main.184,P16-1008,0,0.0217122,"object entity, respectively. Although aforementioned methods is able to represent the relevant entities related to the context, it cannot represent entities, which are not mentioned in the context or not connected to the subject entity in the context with any path in the knowledge graph. In this case, we resort to represent the entity i with Nri relations connected to it by graph attention based on the hidden state hX of the context, which is formulated as follows: Nri X is designed to allow the decoder to select object entities from knowledge graphs or words from the vocabulary. Inspired by Tu et al., 2016, we also introduce a coverage mechanism to facilitate the decoder to avoid generating repetitive entities. The decoding process is formulated as follows: (11) where gt ∈ [0, 1] is a scalar to balance the choice between an entity obj i and a generic word wg , Pg /Pe is the distribution over generic words / entities respectively, and P (yt ) is the final word decoding distribution. 3.6 Loss Function The loss function is the cross entropy between the predicted token distribution P (yt ) and the groundtruth distribution pt in the training corpus. Additionally, we apply supervised signals on the k"
2021.emnlp-main.184,D19-1194,0,0.200814,"incorporating unseen entities in knowledge graphs into conversation generation. Automatic and manual evaluations demonstrate that our model can generate more informative, coherent, and natural responses than baseline models. KG Freebase Wikidata ConceptNet # Entities # Triples # Relations 40M 18M 8M 637M 66M 21M 35,000 1,632 36 Table 1: Statistics of some widely used knowledge graphs (KG, Knowledge Graph; M, million). Prior studies adopt either pre-trained knowledge graph embeddings (Zhou et al., 2018), e.g. TransE (Bordes et al., 2013), word embeddings (Wu et al., 2019), or adjacency matrix (Tuan et al., 2019) to model entities and relations in knowledge graphs and incorporate them to conversation generation. These models face two major challenges when applied to introduce large-scale knowledge graphs. First, there is a significant gap in representations between knowledge and text (Buitelaar and Cimiano, 2008; Zhou et al., 2018), which requires model training to apply knowledge in conversation generation based on different knowledge representations. However, the training corpus of knowledgegrounded conversations only contains a small subset of entities for applying knowledge, while the 1 Introducti"
2021.emnlp-main.184,P19-1369,0,0.356449,"for entities, which is generalized to incorporating unseen entities in knowledge graphs into conversation generation. Automatic and manual evaluations demonstrate that our model can generate more informative, coherent, and natural responses than baseline models. KG Freebase Wikidata ConceptNet # Entities # Triples # Relations 40M 18M 8M 637M 66M 21M 35,000 1,632 36 Table 1: Statistics of some widely used knowledge graphs (KG, Knowledge Graph; M, million). Prior studies adopt either pre-trained knowledge graph embeddings (Zhou et al., 2018), e.g. TransE (Bordes et al., 2013), word embeddings (Wu et al., 2019), or adjacency matrix (Tuan et al., 2019) to model entities and relations in knowledge graphs and incorporate them to conversation generation. These models face two major challenges when applied to introduce large-scale knowledge graphs. First, there is a significant gap in representations between knowledge and text (Buitelaar and Cimiano, 2008; Zhou et al., 2018), which requires model training to apply knowledge in conversation generation based on different knowledge representations. However, the training corpus of knowledgegrounded conversations only contains a small subset of entities for a"
2021.emnlp-main.184,P16-1219,1,0.873385,"Missing"
2021.emnlp-main.184,2020.acl-demos.30,0,0.202847,"ns some noisy data, e.g. empty utterances in the dialogue. After filtering the noisy data, we randomly split the corpus in the same way as DuConv. The statistics is presented in Table 2. Conversations Training 14,845 Validation 1,800 Seen 900 Test Unseen 900 Training 10,583 Validation 1,200 Seen 600 Test Unseen 600 Knowledge Graphs Entity 12,909 Relation 39 Triple 113,959 Entity Relation 100,717 1,380 Triple 1,172,552 Table 2: Statistics of datasets and knowledge graphs. (Mikolov et al., 2010), which is widely used in open-domain conversation systems. • DIALOGPT: a pre-trained dialogue model (Zhang et al., 2020; Wang et al., 2020) based on transformers, which is widely adopted in dialogue generation. • MemNet: a knowledge-grounded model adapted from (Ghazvininejad et al., 2018), of which the memory units store word embeddings of knowledge triples. • PostKS: a knowledge-grounded model selecting knowledge by prior and posterior distributions proposed by Wu et al. (2019), where we adopt word embeddings, instead of the RNN knowledge encoder, to represent knowledge triples. • CopyNet: a copy network model (Zhu et al., 2017), which represents knowledge triples by word embeddings, and can copy words from k"
2021.emnlp-main.347,P18-1082,0,0.132446,"ed the correspondence between the latent codes and categorical features, e.g., dialogue acts (Zhao et al., 2018) and POS tags (Bao et al., 2021). Recently, van den Oord et al. (2017) proposed a vector-quantized variational autoencoder (VQ-VAE) which circumvents the posterior col2 Related Work lapse problem by learning quantized one-hot pos2.1 Long Text Generation terior that can be adapted with powerful autorePrior works endeavored to solve the incoherence gressive decoders. In image and speech generation, issue in long text generation can be mainly cate- Razavi et al. (2019); Dieleman et al. (2018) exgorized into model structure modifications, gener- tended VQ-VAE with hierarchical latent variables ation mechanism modifications, and prior knowl- to capture different input data resolutions and gen4209 Discrete Bottleneck ... ... &lt;/s&gt; 0.0 Generator ... EDU1 ... ... Gumbel-Softmax ... ... 0.0 + EDU2 Embedding Embedding &lt;s&gt; -1.0 Transposed 1D CNN 1D CNN Posterior Network 1.0 Discourse Relation Modeling &lt;s&gt; ... (a) (b) Figure 2: Overview of D ISCO DVT. (a) Learning discrete latent codes via encoding and reconstructing the target text with discourse relation modeling where the latent represen"
2021.emnlp-main.347,P19-1254,0,0.0741814,") We further acquire the discourse relation information and introduce an auxiliary objective for the discrete latent codes to abstract the discourse structure of the text. (3) We conduct extensive experiments on two open story generation datasets with automatic and human evaluation. Results demonstrate that our model outperforms baselines in generating coherent long texts with interpretable latent codes. edge injection. To model the hierarchical nature of human texts, Li et al. (2015) proposed a hierarchical RNN decoder to learn sentence-level representations within the paragraph. Shen et al. (2019) augmented the hierarchical model with multi-level latent variables, and Shao et al. (2019) further incorporates a planning mechanism to pre-arrange the order and the group of the input keywords. Another line of works proposed to decompose long text generation into multiple stages (Fan et al., 2018; Yao et al., 2019; Fan et al., 2019; Tan et al., 2020) where the model first generates a rough sketch, such as key phrases or summaries, and then expands it into the complete long text with fine detail. However, the multi-step generation method is known to have the stage-level exposure bias (Tan et"
2021.emnlp-main.347,2020.emnlp-main.351,0,0.0689276,"Missing"
2021.emnlp-main.347,2020.tacl-1.7,1,0.825864,"18; Yao et al., 2019; Fan et al., 2019; Tan et al., 2020) where the model first generates a rough sketch, such as key phrases or summaries, and then expands it into the complete long text with fine detail. However, the multi-step generation method is known to have the stage-level exposure bias (Tan et al., 2020), i.e., the discrepancy of middle-stage outputs during training and inference, which can accumulate error through stages and impair the final generation quality. The final direction is to inject prior external knowledge into pre-trained language models for commonsense story generation (Guan et al., 2020; Xu et al., 2020). However, these methods may not be generalizable to different data genres such as fictional stories and do not provide long-range guidance during text generation. 2.2 Discrete Latent Variable Models In text generation, continuous Gaussian VAEs have been explored to model response diversity (Zhao et al., 2017; Serban et al., 2017) and high-level structures, such as template and order (Wiseman et al., 2018; Shen et al., 2019; Shao et al., 2019). Aside from Gaussian latent variables in the continuous space (Kingma and Welling, 2014), recent works also explored VAEs in the discr"
2021.emnlp-main.347,J00-4006,0,0.101206,"locally stead of the commonly used continuous latent varicoherent texts which are relatively short, it is still challenging for pre-trained models to generate glob- ables, we resort to learn discrete latent codes that naturally correspond to interpretable categories in ally coherent passages spanning over dozens of natural languages (Zhao et al., 2018). For the latent sentences. codes to capture the explicit discourse structure of Global coherence in human texts is represented the texts as shown in Figure 1, we further design by the topic-maintenance and natural transition between viewpoints (Jurafsky and Martin, 2000). an auxiliary objective on the latent representations to model the discourse relations. As illustrated in Figure 1, discourse relations such We name the proposed model as D ISCO DVT, ∗ Corresponding author 1 Discourse-aware Discrete Variational The source code is available at https://github. i.e., com/cdjhz/DiscoDVT. Transformer. The main idea is to learn a discrete 4208 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 4208–4224 c November 7–11, 2021. 2021 Association for Computational Linguistics latent variable sequence that summarizes the long t"
2021.emnlp-main.347,2020.inlg-1.8,0,0.0327862,"a discrete latent variable sequence abstracts the discourse structure of the text. Inter-sentence and intra-sentence discourse relations are indicated by the bolded discourse markers. as causal, temporal succession between contiguous text segments are commonly indicated by the highlighted discourse markers which bind collocated text segments into a global structure (Hobbs, 1985). Although pre-trained language models are inspected to perform reasonably well in associating topic-related concepts, they can hardly arrange contents with well-structured discourses (See et al., 1 Introduction 2019; Ko and Li, 2020). In this work, we urge the revival of variational Generating passages that maintain long-range coautoencoder (VAE) with its global representation herence is a long-standing problem in natural language generation (NLG). Despite the recent ad- ability to tackle the incoherence issue in long text generation in the era of pre-trained language modvances of large pre-trained language generation models (Radford et al., 2019; Lewis et al., 2020) els. To represent texts with high-level structures, we propose to learn a latent variable sequence with in various NLG tasks such as summarization and each l"
2021.emnlp-main.347,2020.acl-main.703,0,0.2376,"erform reasonably well in associating topic-related concepts, they can hardly arrange contents with well-structured discourses (See et al., 1 Introduction 2019; Ko and Li, 2020). In this work, we urge the revival of variational Generating passages that maintain long-range coautoencoder (VAE) with its global representation herence is a long-standing problem in natural language generation (NLG). Despite the recent ad- ability to tackle the incoherence issue in long text generation in the era of pre-trained language modvances of large pre-trained language generation models (Radford et al., 2019; Lewis et al., 2020) els. To represent texts with high-level structures, we propose to learn a latent variable sequence with in various NLG tasks such as summarization and each latent code abstracting a local text span. Indialogue generation that target generating locally stead of the commonly used continuous latent varicoherent texts which are relatively short, it is still challenging for pre-trained models to generate glob- ables, we resort to learn discrete latent codes that naturally correspond to interpretable categories in ally coherent passages spanning over dozens of natural languages (Zhao et al., 2018)."
2021.emnlp-main.347,2020.emnlp-main.378,0,0.0248958,"for the same number of steps as ours and the baselines in generating texts with higher nthen fine-tuning on the downstream datasets. This gram overlaps and n-gram distribution similarity baseline is proposed to investigate the side effect to the reference texts indicated by a higher BLEU of the language modeling objective on the decoder and MSJ score, respectively. in the warm-start stage. BART-CVAE is inspired by recent literature that In terms of diversity, D ISCO DVT outperforms incorporates continuous latent variables to large BART and BART-LM by large margins in terms pre-trained models (Li et al., 2020), which serves of Distinct while slightly underperforms BARTas a counterpart to our discrete variable model. We CVAE. However, when evaluating diversity jointly implement a CVAE with modules initialized by with quality, D ISCO DVT surpasses BART-CVAE the pre-trained parameters of BART. The sampled with higher reverse-BLEU score. We further examlatent variable is added to the embedding layer ine the generated examples of BART-CVAE and of the generator’s decoder as our model (same at found that its diversity mainly comes from generatevery position). We adopt the KL thresholding ing more spurious"
2021.emnlp-main.347,K19-1079,0,0.0542542,"Missing"
2021.emnlp-main.347,D19-1321,1,0.785551,"ary objective for the discrete latent codes to abstract the discourse structure of the text. (3) We conduct extensive experiments on two open story generation datasets with automatic and human evaluation. Results demonstrate that our model outperforms baselines in generating coherent long texts with interpretable latent codes. edge injection. To model the hierarchical nature of human texts, Li et al. (2015) proposed a hierarchical RNN decoder to learn sentence-level representations within the paragraph. Shen et al. (2019) augmented the hierarchical model with multi-level latent variables, and Shao et al. (2019) further incorporates a planning mechanism to pre-arrange the order and the group of the input keywords. Another line of works proposed to decompose long text generation into multiple stages (Fan et al., 2018; Yao et al., 2019; Fan et al., 2019; Tan et al., 2020) where the model first generates a rough sketch, such as key phrases or summaries, and then expands it into the complete long text with fine detail. However, the multi-step generation method is known to have the stage-level exposure bias (Tan et al., 2020), i.e., the discrepancy of middle-stage outputs during training and inference, wh"
2021.emnlp-main.347,P19-1200,0,0.0700183,"oherence. (2) We further acquire the discourse relation information and introduce an auxiliary objective for the discrete latent codes to abstract the discourse structure of the text. (3) We conduct extensive experiments on two open story generation datasets with automatic and human evaluation. Results demonstrate that our model outperforms baselines in generating coherent long texts with interpretable latent codes. edge injection. To model the hierarchical nature of human texts, Li et al. (2015) proposed a hierarchical RNN decoder to learn sentence-level representations within the paragraph. Shen et al. (2019) augmented the hierarchical model with multi-level latent variables, and Shao et al. (2019) further incorporates a planning mechanism to pre-arrange the order and the group of the input keywords. Another line of works proposed to decompose long text generation into multiple stages (Fan et al., 2018; Yao et al., 2019; Fan et al., 2019; Tan et al., 2020) where the model first generates a rough sketch, such as key phrases or summaries, and then expands it into the complete long text with fine detail. However, the multi-step generation method is known to have the stage-level exposure bias (Tan et"
2021.emnlp-main.347,D18-1356,0,0.0658782,"Missing"
2021.findings-acl.138,2021.ccl-1.108,0,0.0263718,"Missing"
2021.findings-acl.138,W17-4902,0,0.0258789,"(b) An example of word alignments between the source and target sentences. Arrows connect aligned words (identical or relevant), and blue words are not aligned. (c) NAST’s generation process. Step 1: generate the index of aligned words. [Mask] is a placeholder for unaligned words. Step 2: generate the transferred sentence non-autoregressively. Text style transfer aims at changing the text style while preserving the style-irrelevant contents, which has a wide range of applications, e.g., sentiment transfer (Shen et al., 2017), text formalization (Rao and Tetreault, 2018), and author imitation (Jhamtani et al., 2017). Due to the lack of parallel training data, most works focus on unsupervised text style transfer using non-parallel stylistic data. The cycle consistency loss (Zhu et al., 2017), a.k.a. the back-translation loss (Lample et al., 2018, author: Minlie Huang. Not great, but good atmosphere and great service (b) Observation of Word Alignment Source: Not terrible , but Introduction * Corresponding Not terrible, but not very good 2019), has been widely adopted by unsupervised text style transfer models (Dai et al., 2019; He et al., 2020; Yi et al., 2020). Specifically, the cycle loss minimizes the r"
2021.findings-acl.138,P19-1041,0,0.370615,"based models. To the best of our knowledge, we are the first to introduce a non-autoregressive generator to an unsupervised generation task. • Experiments show that incorporating NAST in cycle-loss-based models significantly improves the overall performance and the speed of training and inference. In further analysis, we find that NAST provides better optimization of the cycle loss and learns explainable word alignments. 2 Related Work Unsupervised Text Style Transfer We categorize style transfer models into three types. The first type (Shen et al., 2017; Zhao et al., 2018; Yang et al., 2018; John et al., 2019) disentangles the style and content representations, and then combines the content representations with the target style to generate the transferred sentence. However, the disentangled representations are limited in capacity and thus hardly scalable for long sentences (Dai et al., 2019). The second type is the editing-based method (Li et al., 2018; Wu et al., 2019a,b), which edits the source sentence with several discrete operations. The operations are usually trained separately and then constitute a pipeline. These methods are highly explainable, but they usually need to locate and replace th"
2021.findings-acl.138,2020.acl-main.639,0,0.0266396,"ation seems similar to a pipeline, NAST is trained in an end-to-end fashion with the cycle loss. All transferred words in NAST are generated, not copied, which is essentially different from these methods. The third type is based on the cycle loss. Zhang et al. (2018); Lample et al. (2019) introduce the back translation method into style transfer, where the model is directly trained with the cycle loss after a proper initialization. The following works (Dai et al., 2019; Luo et al., 2019; He et al., 2020; Yi et al., 2020) further adopt a style loss to improve the style control. A recent study (Zhou et al., 2020) explores the word-level information for style transfer, which is related to our motivation. However, they focus on word-level style relevance in designing novel objectives, while we focus on modeling word alignments and the non-autoregressive architecture. Non-Autoregressive Generation Non-AutoRegressive (NAR) generation is first introduced in machine translation for parallel decoding with low latency (Gu et al., 2018). The NAR generator assumes that each token is generated independently of each other conditioned on the input sentence, which sacrifices the generation quality in exchange for t"
2021.findings-acl.139,P17-1120,0,0.0210758,"ialog turns (Williams et al., 2013; Henderson et al., 2014). The states are converted into a representation of constraints based on different schemes to query the databases (El Asri et al., 2017; Budzianowski et al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the system with chatting capability to address both task and non-task content in TODs. Other studies apply knowledge graph (Liao et al., 2019; Yang et al., 2020) or tables via SQL (Yu et al., 2019) to enrich the knowledge of TOD systems. However, all these studies are still limited in dialog modeling grounded on structured knowledge. There are a couple of studies to integrate unstructured knowledge into TOD modeling recently. Kim et al. (2020) introduce knowledge snippets to answer follow-up questions out of the coverage of databases. Feng et al. (2020) formulate document-grounded dialo"
2021.findings-acl.139,W05-0909,0,0.188612,"LABES-S2S TRADE + BDA UniConv + BDA LABES-S2S + BDA HyKnow (Single) - w/o Joint Optim HyKnow (Multiple) - w/o Joint Optim TripPy SimpleTOD TripPy + BDA SimpleTOD + BDA Model Inform Success BLEU Combined UniConv 84.2 71.8 19.0 97.3 LABES-S2S 83.6 74.2 18.3 97.2 UniConv + BDA 85.8 73.9 19.3 99.4 LABES-S2S + BDA 85.0 75.3 18.9 99.1 HyKnow 87.2 76.5 19.5 101.4 SimpleTOD 87.5 76.4 16.3 98.3 SimpleTOD + BDA 89.0 77.2 17.0 100.1 Table 2: Context-to-response generation results on modified MultiWOZ 2.1. All symbols and markings have the same meaning as in Table 1. BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and ROUGE-L (Lin, 2004). Moreover, we use Combined score computed by (Inf orm + Success) × 0.5 + BLEU for overall evaluation, as suggested by Eric et al. (2020). We find that HyKnow has better task completion rate than the light-weight E2E TOD models, which is comparable with SimpleTOD who uses large-scale pretrained GPT-2. It also generates responses with better language quality compared to all the E2E models. This is because our extended belief state can distinguish whether a dialog turn is grounded on structured or unstructured knowledge, which avoids the confusion between handling the two"
2021.findings-acl.139,D18-1547,0,0.24845,"jointly optimize dialog modeling grounded on the two kinds of knowledge. • Experimental results show that HyKnow has strong performance in dialog modeling grounded on hybrid knowledge.1 2 Related Work TOD systems usually use belief tracking, i.e. dialog state tracking (DST) to trace the user goals, i.e. be1 The code is available at https://github.com/ truthless11/HyKnow lief states, through multiple dialog turns (Williams et al., 2013; Henderson et al., 2014). The states are converted into a representation of constraints based on different schemes to query the databases (El Asri et al., 2017; Budzianowski et al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the system with chatting capability to address both task and non-task content in TODs. Other studies apply knowledge graph (Liao et al., 2019; Yang et al., 2020) or tables via SQL (Yu et al.,"
2021.findings-acl.139,N19-1423,0,0.00482968,"d from GPT-2 (Radford et al., 2019). All three E2E models only manage structured knowledge (database) in their TOD modeling. In addition to E2E TOD models, we also compare HyKnow with existing DST models in the belief tracking evaluation. Specifically, we use TRADE (Wu et al., 2019) and TripPy (Heck et al., 2020) as two DST baselines, which are representative BERT-free and BERT-based DST models, respectively. Unstructured Knowledge Management Models. We first compare our system with Beyond Domain APIs (BDA) (Kim et al., 2020). This baseline model uses two classification modules based on BERT (Devlin et al., 2019) to detect unstructured knowledge-grounded dialog turns and retrieve relevant documents, respectively. Moreover, we use standard information retrieval (IR) systems TFIDF (Manning et al., 2008) and BM25 (Robertson and Zaragoza, 2009) as the other two baseline models. Combinations. We combine the unstructured knowledge management model BDA with every DST or E2E TOD model. Specifically, BDA detects dialog turns that are grounded on unstructured knowledge, and uses a fine-tuned GPT-2 to generate responses in these turns, based on the dialog context and retrieved documents. While the DST or E2E TOD"
2021.findings-acl.139,W17-5526,0,0.0534814,"Missing"
2021.findings-acl.139,2020.emnlp-main.652,0,0.0592158,"Missing"
2021.findings-acl.139,P16-1154,0,0.01249,"e the belief state enet and coder and the document encoder to encode B et B Dt Dt into hidden states henc and henc , respectively. Based on the hidden states of all the encoders and (3) Dt t Rt = Seq2Seq(r) (Ct |hB enc , henc , mt ), e where Encoder(b) and Encoder(d) denote the belief state encoder and the document encoder. Following previous TOD systems with Seq2Seq architectures (Lei et al., 2018; Liang et al., 2020; Zhang et al., 2020a,b), we use one-layer, bidirectional GRU as encoders and standard GRU as decoders. We also apply global attention (Bahdanau et al., 2015) and copy mechanism (Gu et al., 2016) in all the Seq2Seq processes, to improve the et and Rt . context-awareness of decoding B 4.4 (2) 4.2 4.3 the vector mt , we use the response decoder to generate the system response Rt , formulated as: Model Training HyKnow is optimized through supervised training. Specifically, each dialog turn in the training data is initially labeled with the original belief state and the relevant document. We extend the belief state label based on the domain, entity and extracted topic of the relevant document. Then the extended belief state label and the reference response are used to calculate the cross-"
2021.findings-acl.139,2020.emnlp-main.146,0,0.0442862,"erformance compared to existing TOD systems. It also outperforms the pipeline knowledge management schemes, with higher unstructured knowledge retrieval accuracy. 1 Figure 1: Illustration of task-oriented dialog modeling with hybrid knowledge management. Words in red and blue illustrate the new domain-slot-value triple and the topic of user utterance that we introduce into the belief state, respectively. Words in yellow illustrate the topics of documents that we extract through preprocessing. Introduction Recently, Task-Oriented Dialog (TOD) systems (Mehri et al., 2019; Zhang et al., 2020a,b; Le et al., 2020; Hosseini-Asl et al., 2020; Peng et al., 2020; Li et al., 2021) have achieved promising performance on accomplishing user goals. Most systems typically query structured knowledge such as tables and databases based on the user goals, and use the query results to guide the generation of system responses, as shown in the first dialog turn in Fig. 1. However, real-world task-oriented conversations often step into dialog turns which are grounded on unstructured knowledge (Feng et al., 2020), such as passages and documents. For example, as the * Equal † contribution. Corresponding author. second di"
2021.findings-acl.139,P18-1133,0,0.140656,"trieve relevant references for generating the response. To address our defined task, we propose a taskoriented dialog system with Hybrid Knowledge management (HyKnow). This model extends the belief state to handle TODs grounded on hybrid knowledge, and further uses the extended belief state to perform both database query and document retrieval, whose outputs are thereby used to generate the final response. We consider two implementations of our system, with different schemes of extended belief state decoding. Both implementations are in an end-to-end multi-stage sequence-tosequence (Seq2Seq) (Lei et al., 2018; Liang et al., 2020; Zhang et al., 2020a,b) framework, where dialog modeling grounded on the two kinds of knowledge can be jointly optimized. We evaluate our system on the modified version of MultiWOZ 2.1 (Kim et al., 2020) dataset, where dialogs are grounded on hybrid knowledge. Experimental results show that HyKnow outperforms existing TOD systems which do not leverage large pretrained language models, no matter whether they add extra unstructured knowledge management or not. It also has a higher accuracy in unstructured knowledge retrieval, compared to the pipeline knowledge management sch"
2021.findings-acl.139,2020.sigdial-1.4,0,0.020553,"Missing"
2021.findings-acl.139,W14-4337,0,0.162364,"ems. • We propose a TOD system HyKnow to address our proposed task. It extends the belief state to manage hybrid knowledge, and is the first end-toend model to jointly optimize dialog modeling grounded on the two kinds of knowledge. • Experimental results show that HyKnow has strong performance in dialog modeling grounded on hybrid knowledge.1 2 Related Work TOD systems usually use belief tracking, i.e. dialog state tracking (DST) to trace the user goals, i.e. be1 The code is available at https://github.com/ truthless11/HyKnow lief states, through multiple dialog turns (Williams et al., 2013; Henderson et al., 2014). The states are converted into a representation of constraints based on different schemes to query the databases (El Asri et al., 2017; Budzianowski et al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the system with chatting capa"
2021.findings-acl.139,W19-5921,0,0.070558,"ts show that HyKnow has strong end-to-end performance compared to existing TOD systems. It also outperforms the pipeline knowledge management schemes, with higher unstructured knowledge retrieval accuracy. 1 Figure 1: Illustration of task-oriented dialog modeling with hybrid knowledge management. Words in red and blue illustrate the new domain-slot-value triple and the topic of user utterance that we introduce into the belief state, respectively. Words in yellow illustrate the topics of documents that we extract through preprocessing. Introduction Recently, Task-Oriented Dialog (TOD) systems (Mehri et al., 2019; Zhang et al., 2020a,b; Le et al., 2020; Hosseini-Asl et al., 2020; Peng et al., 2020; Li et al., 2021) have achieved promising performance on accomplishing user goals. Most systems typically query structured knowledge such as tables and databases based on the user goals, and use the query results to guide the generation of system responses, as shown in the first dialog turn in Fig. 1. However, real-world task-oriented conversations often step into dialog turns which are grounded on unstructured knowledge (Feng et al., 2020), such as passages and documents. For example, as the * Equal † contr"
2021.findings-acl.139,P02-1040,0,0.111671,"etrics 1595 Model TRADE UniConv LABES-S2S TRADE + BDA UniConv + BDA LABES-S2S + BDA HyKnow (Single) - w/o Joint Optim HyKnow (Multiple) - w/o Joint Optim TripPy SimpleTOD TripPy + BDA SimpleTOD + BDA Model Inform Success BLEU Combined UniConv 84.2 71.8 19.0 97.3 LABES-S2S 83.6 74.2 18.3 97.2 UniConv + BDA 85.8 73.9 19.3 99.4 LABES-S2S + BDA 85.0 75.3 18.9 99.1 HyKnow 87.2 76.5 19.5 101.4 SimpleTOD 87.5 76.4 16.3 98.3 SimpleTOD + BDA 89.0 77.2 17.0 100.1 Table 2: Context-to-response generation results on modified MultiWOZ 2.1. All symbols and markings have the same meaning as in Table 1. BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and ROUGE-L (Lin, 2004). Moreover, we use Combined score computed by (Inf orm + Success) × 0.5 + BLEU for overall evaluation, as suggested by Eric et al. (2020). We find that HyKnow has better task completion rate than the light-weight E2E TOD models, which is comparable with SimpleTOD who uses large-scale pretrained GPT-2. It also generates responses with better language quality compared to all the E2E models. This is because our extended belief state can distinguish whether a dialog turn is grounded on structured or unstructured knowledge, which avoids the"
2021.findings-acl.139,2020.sigdial-1.35,0,0.444767,"nded on hybrid knowledge, and further uses the extended belief state to perform both database query and document retrieval, whose outputs are thereby used to generate the final response. We consider two implementations of our system, with different schemes of extended belief state decoding. Both implementations are in an end-to-end multi-stage sequence-tosequence (Seq2Seq) (Lei et al., 2018; Liang et al., 2020; Zhang et al., 2020a,b) framework, where dialog modeling grounded on the two kinds of knowledge can be jointly optimized. We evaluate our system on the modified version of MultiWOZ 2.1 (Kim et al., 2020) dataset, where dialogs are grounded on hybrid knowledge. Experimental results show that HyKnow outperforms existing TOD systems which do not leverage large pretrained language models, no matter whether they add extra unstructured knowledge management or not. It also has a higher accuracy in unstructured knowledge retrieval, compared to the pipeline knowledge management schemes. Our contributions are summarized as below: • We formulate a task of modeling TOD grounded on both structured and unstructured knowledge, to incorporate more domain knowledge into the TOD systems. • We propose a TOD sys"
2021.findings-acl.139,D14-1162,0,0.0843713,"Missing"
2021.findings-acl.139,W17-5505,0,0.0117876,"Know lief states, through multiple dialog turns (Williams et al., 2013; Henderson et al., 2014). The states are converted into a representation of constraints based on different schemes to query the databases (El Asri et al., 2017; Budzianowski et al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the system with chatting capability to address both task and non-task content in TODs. Other studies apply knowledge graph (Liao et al., 2019; Yang et al., 2020) or tables via SQL (Yu et al., 2019) to enrich the knowledge of TOD systems. However, all these studies are still limited in dialog modeling grounded on structured knowledge. There are a couple of studies to integrate unstructured knowledge into TOD modeling recently. Kim et al. (2020) introduce knowledge snippets to answer follow-up questions out of the coverage of databases. Feng et al"
2021.findings-acl.139,2020.tacl-1.19,1,0.797213,"two kinds of knowledge. • Experimental results show that HyKnow has strong performance in dialog modeling grounded on hybrid knowledge.1 2 Related Work TOD systems usually use belief tracking, i.e. dialog state tracking (DST) to trace the user goals, i.e. be1 The code is available at https://github.com/ truthless11/HyKnow lief states, through multiple dialog turns (Williams et al., 2013; Henderson et al., 2014). The states are converted into a representation of constraints based on different schemes to query the databases (El Asri et al., 2017; Budzianowski et al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the system with chatting capability to address both task and non-task content in TODs. Other studies apply knowledge graph (Liao et al., 2019; Yang et al., 2020) or tables via SQL (Yu et al., 2019) to enrich the knowledge of TOD sys"
2021.findings-acl.139,W13-4065,0,0.0186943,"ledge into the TOD systems. • We propose a TOD system HyKnow to address our proposed task. It extends the belief state to manage hybrid knowledge, and is the first end-toend model to jointly optimize dialog modeling grounded on the two kinds of knowledge. • Experimental results show that HyKnow has strong performance in dialog modeling grounded on hybrid knowledge.1 2 Related Work TOD systems usually use belief tracking, i.e. dialog state tracking (DST) to trace the user goals, i.e. be1 The code is available at https://github.com/ truthless11/HyKnow lief states, through multiple dialog turns (Williams et al., 2013; Henderson et al., 2014). The states are converted into a representation of constraints based on different schemes to query the databases (El Asri et al., 2017; Budzianowski et al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the"
2021.findings-acl.139,P19-1078,0,0.0119481,"seline E2E TOD models with different types of structures: UniConv (Le et al., 2020) uses a structured fusion (Mehri et al., 2019) design, LABES-S2S (Zhang et al., 2020a) uses a multistage Seq2Seq (Lei et al., 2018) architecture, and SimpleTOD (Hosseini-Asl et al., 2020) is based on a single auto-regressive language model initialized from GPT-2 (Radford et al., 2019). All three E2E models only manage structured knowledge (database) in their TOD modeling. In addition to E2E TOD models, we also compare HyKnow with existing DST models in the belief tracking evaluation. Specifically, we use TRADE (Wu et al., 2019) and TripPy (Heck et al., 2020) as two DST baselines, which are representative BERT-free and BERT-based DST models, respectively. Unstructured Knowledge Management Models. We first compare our system with Beyond Domain APIs (BDA) (Kim et al., 2020). This baseline model uses two classification modules based on BERT (Devlin et al., 2019) to detect unstructured knowledge-grounded dialog turns and retrieve relevant documents, respectively. Moreover, we use standard information retrieval (IR) systems TFIDF (Manning et al., 2008) and BM25 (Robertson and Zaragoza, 2009) as the other two baseline mode"
2021.findings-acl.139,2020.emnlp-main.147,0,0.0399803,"Missing"
2021.findings-acl.139,D19-1204,0,0.0250975,"al., 2018; Rastogi et al., 2020; Zhu et al., 2020). The entry matching results are then used to generate the system response. With the development of intelligent assistants, the system should have a good command of massive external knowledge to better accomplish complicated user goals and improve user satisfaction. To realize this, some researchers (Zhao et al., 2017; Yu et al., 2017; Akasaki and Kaji, 2017) equip the system with chatting capability to address both task and non-task content in TODs. Other studies apply knowledge graph (Liao et al., 2019; Yang et al., 2020) or tables via SQL (Yu et al., 2019) to enrich the knowledge of TOD systems. However, all these studies are still limited in dialog modeling grounded on structured knowledge. There are a couple of studies to integrate unstructured knowledge into TOD modeling recently. Kim et al. (2020) introduce knowledge snippets to answer follow-up questions out of the coverage of databases. Feng et al. (2020) formulate document-grounded dialog for information seeking tasks. However, they only focus on dialog turns grounded on unstructured knowledge instead. In this paper, we aims to fill the gap of managing domain-specific knowledge with vari"
2021.findings-acl.139,2020.emnlp-main.740,0,0.560606,"has strong end-to-end performance compared to existing TOD systems. It also outperforms the pipeline knowledge management schemes, with higher unstructured knowledge retrieval accuracy. 1 Figure 1: Illustration of task-oriented dialog modeling with hybrid knowledge management. Words in red and blue illustrate the new domain-slot-value triple and the topic of user utterance that we introduce into the belief state, respectively. Words in yellow illustrate the topics of documents that we extract through preprocessing. Introduction Recently, Task-Oriented Dialog (TOD) systems (Mehri et al., 2019; Zhang et al., 2020a,b; Le et al., 2020; Hosseini-Asl et al., 2020; Peng et al., 2020; Li et al., 2021) have achieved promising performance on accomplishing user goals. Most systems typically query structured knowledge such as tables and databases based on the user goals, and use the query results to guide the generation of system responses, as shown in the first dialog turn in Fig. 1. However, real-world task-oriented conversations often step into dialog turns which are grounded on unstructured knowledge (Feng et al., 2020), such as passages and documents. For example, as the * Equal † contribution. Correspondi"
2021.findings-acl.215,2020.acl-main.8,0,0.0274937,"ating the whole story from the sketch. The sketch is usually a series of keywords (Yao et al., 2019), a learnable skeleton (Xu et al., 2018) or an action sequence (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story generation, Huang et al. (2019) and Xu et al. (2020) controlled the story topics and planned keywords, respectively. Besides, for general text generation, the authorship (Tikhonov and Yamshchikov, 2018), sentiment (Hu et al., 2017), and topics (Li et al., 2020) can also be controlled for different purposes. We introduce a new controllable attribute in story generation, i.e., the story style, which has been paid little attention to in prior studies. 1 Link to the code: https://git"
2021.findings-acl.215,2020.emnlp-main.529,0,0.0613897,"Missing"
2021.findings-acl.215,P18-1082,0,0.0268496,"ance of the keywords. Besides, we propose two automatic metrics to evaluate the consistency between the generated story and the specified style. Experiments demonstrates that our model can controllably generate emotion-driven or event-driven stories based on the ROCStories dataset (Mostafazadeh et al., 2016). Our study presents insights for stylized story generation in further research. 1 Story generation is a challenging task in natural language generation (NLG), namely generating a reasonable story given a leading context. Recent work focuses on enhancing the coherence of generated stories (Fan et al., 2018; Yao et al., 2019) or introducing commonsense knowledge (Guan et al., 2020; Xu et al., 2020). However, it has not yet been investigated to generate stories with controllable styles, which is important since different styles serve different writing purposes. As exemplified in Figure 1, emotion-driven stories use emotional words (e.g., “excited”, “enjoyed”) to reveal the inner states of the characters and bring the readers closer to the characters. In comparison, event-driven stories usually contain a sequence of events with a clear temporal order (e.g., “tearing”!“tried”!“found”!“hooked”), whi"
2021.findings-acl.215,P18-1139,1,0.830613,"he sketch is usually a series of keywords (Yao et al., 2019), a learnable skeleton (Xu et al., 2018) or an action sequence (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story generation, Huang et al. (2019) and Xu et al. (2020) controlled the story topics and planned keywords, respectively. Besides, for general text generation, the authorship (Tikhonov and Yamshchikov, 2018), sentiment (Hu et al., 2017), and topics (Li et al., 2020) can also be controlled for different purposes. We introduce a new controllable attribute in story generation, i.e., the story style, which has been paid little attention to in prior studies. 1 Link to the code: https://github.com/thucoai/Stylized-Story-Generat"
2021.findings-acl.215,P19-1254,0,0.0205159,"nce (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story generation, Huang et al. (2019) and Xu et al. (2020) controlled the story topics and planned keywords, respectively. Besides, for general text generation, the authorship (Tikhonov and Yamshchikov, 2018), sentiment (Hu et al., 2017), and topics (Li et al., 2020) can also be controlled for different purposes. We introduce a new controllable attribute in story generation, i.e., the story style, which has been paid little attention to in prior studies. 1 Link to the code: https://github.com/thucoai/Stylized-Story-Generation-withStyle-Guided-Planning.git 3 Proposed Method In this section, we first show the task formulation for s"
2021.findings-acl.215,2020.emnlp-main.351,0,0.041993,"; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story generation, Huang et al. (2019) and Xu et al. (2020) controlled the story topics and planned keywords, respectively. Besides, for general text generation, the authorship (Tikhonov and Yamshchikov, 2018), sentiment (Hu et al., 2017), and topics (Li et al., 2020) can also be controlled for different purposes. We introduce a new controllable attribute in story generation, i.e., the story style, which has been paid little attention to in prior studies. 1 Link to the code: https://github.com/thucoai/Stylized-Story-Generation-withStyle-Guided-Planning.git 3 Proposed Method In this section, we first show the task formulation for stylized story generat"
2021.findings-acl.215,2020.tacl-1.7,1,0.917209,"e the consistency between the generated story and the specified style. Experiments demonstrates that our model can controllably generate emotion-driven or event-driven stories based on the ROCStories dataset (Mostafazadeh et al., 2016). Our study presents insights for stylized story generation in further research. 1 Story generation is a challenging task in natural language generation (NLG), namely generating a reasonable story given a leading context. Recent work focuses on enhancing the coherence of generated stories (Fan et al., 2018; Yao et al., 2019) or introducing commonsense knowledge (Guan et al., 2020; Xu et al., 2020). However, it has not yet been investigated to generate stories with controllable styles, which is important since different styles serve different writing purposes. As exemplified in Figure 1, emotion-driven stories use emotional words (e.g., “excited”, “enjoyed”) to reveal the inner states of the characters and bring the readers closer to the characters. In comparison, event-driven stories usually contain a sequence of events with a clear temporal order (e.g., “tearing”!“tried”!“found”!“hooked”), which aims to narrate the story objectively. † Equal contribution. Correspondi"
2021.findings-acl.215,2020.emnlp-main.736,1,0.790394,"th the reference story for each sample.(3) Distinct (Dn) (Li et al., 2016): The metric measures the generation diversity with the percentage of unique n-grams (n = 1, 2). (4) Numbers of Stylistic Keywords (Number): We use the average n0 (described in §4.2) to evaluate how many consistent stylistic keywords the generated stories have. (5) Lexical Style Consistency (LSC): We calculate the percentage of the stories annotated with the consistent style in all generated stories using the annotation strategy described in §4.2. (6) Semantic Style Consistency (SSC): It is a learnable automatic metric (Guan and Huang, 2020). We finetune BERTBASE on the training set as a classifier to distinguish whether a story is emotion-driven, event-driven, or others with the automatic labels as the golden truth. For each style, we regard the average classification score on the style to measure the style consistency. Table 2 shows the accuracy and F1-Scores of the BERT model on the test set. Emotion-Driven Models PPL # B-1 &quot; B-2 &quot; GPT-2 BART N/A 11.72 32.8 33.2 16.1 16.6 Ours 11.29 33.8 17.1 Table 3: Automatic evaluation results on the entire test set. The Best results are highlighted in bold. #/&quot; indicates the lower/higher,"
2021.findings-acl.215,2020.acl-main.703,0,0.038307,"tic style consistency (SSC), which focus on the number of stylistic keywords and the overall semantics, respectively. Extensive experiments demonstrate that the stories generated by our model not only achieve better fluency and coherence than strong baselines but also have better consistency with the specified styles.1 2 Related Work Story Generation Recently there have been significant advances for story generation with the encoder-decoder paradigm (Sutskever et al., 2014), the transformer-based architecture (Vaswani et al., 2017) and the large-scale pre-trained models (Radford et al., 2019; Lewis et al., 2020). Prior studies usually decomposed the generation into separate steps by first planning a sketch and then generating the whole story from the sketch. The sketch is usually a series of keywords (Yao et al., 2019), a learnable skeleton (Xu et al., 2018) or an action sequence (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable a"
2021.findings-acl.215,N16-1014,0,0.036757,"or the stories in the test set. Instead, we calculate the perplexity of a model for each sample conditioned on two styles (emotion-driven and eventdriven), respectively, and then get the perplexity on the entire test set by averaging the smaller perplexity for each sample.(2) BLEU (B-n) (Papineni et al., 2002): The metric evaluates n-gram overlap (n = 1, 2). For each beginning in the test set, we generate two stories conditioned on two styles, respectively. Then we calculate the BLEU score on the test set by averaging the higher BLEU with the reference story for each sample.(3) Distinct (Dn) (Li et al., 2016): The metric measures the generation diversity with the percentage of unique n-grams (n = 1, 2). (4) Numbers of Stylistic Keywords (Number): We use the average n0 (described in §4.2) to evaluate how many consistent stylistic keywords the generated stories have. (5) Lexical Style Consistency (LSC): We calculate the percentage of the stories annotated with the consistent style in all generated stories using the annotation strategy described in §4.2. (6) Semantic Style Consistency (SSC): It is a learnable automatic metric (Guan and Huang, 2020). We finetune BERTBASE on the training set as a class"
2021.findings-acl.215,N16-1098,0,0.0301581,"ant for controllable text generation. Therefore, we propose a new task, stylized story generation, namely generating stories with specified style given a leading context. To tackle the problem, we propose a novel generation model that first plans the stylized keywords and then generates the whole story with the guidance of the keywords. Besides, we propose two automatic metrics to evaluate the consistency between the generated story and the specified style. Experiments demonstrates that our model can controllably generate emotion-driven or event-driven stories based on the ROCStories dataset (Mostafazadeh et al., 2016). Our study presents insights for stylized story generation in further research. 1 Story generation is a challenging task in natural language generation (NLG), namely generating a reasonable story given a leading context. Recent work focuses on enhancing the coherence of generated stories (Fan et al., 2018; Yao et al., 2019) or introducing commonsense knowledge (Guan et al., 2020; Xu et al., 2020). However, it has not yet been investigated to generate stories with controllable styles, which is important since different styles serve different writing purposes. As exemplified in Figure 1, emotio"
2021.findings-acl.215,2020.acl-tutorials.5,0,0.0398158,". Then she tr ied different adjustments. Eventually, she found out what was wrong. She got the wrong cable hooked up. Figure 1: Example of stylized story generation given the same leading context. The stylized keywords are in bold. Introduction ⇤ Style In this paper, we formalize the task of stylized story generation, which requires generating a coherent story with a specified style given the first sentence as the leading context. Style has multiple interpretations, which can be seen as a unique voice of the author expressed through the use of certain stylistic devices (e.g. choices of words)(Mou and Vechtomova, 2020). In this work we focus on the choices of words and define the story styles based on the pattern of wording. Specifically, we focus on two story styles, including emotion-driven and event-driven stories. Emotion-driven stories contain abundant words with emotional inclination. We identify the emotional words using the off-theshelf toolkit NRCLex (Mohammad, 2020), which supports retrieving the emotional effects of a word from a predefined lexicon. And event-driven stories tend to use serial actions as an event sequence. We use NLTK (Bird et al., 2009) to extract verbs in a story as the actions."
2021.findings-acl.215,Q18-1027,0,0.0209607,"of keywords (Yao et al., 2019), a learnable skeleton (Xu et al., 2018) or an action sequence (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story generation, Huang et al. (2019) and Xu et al. (2020) controlled the story topics and planned keywords, respectively. Besides, for general text generation, the authorship (Tikhonov and Yamshchikov, 2018), sentiment (Hu et al., 2017), and topics (Li et al., 2020) can also be controlled for different purposes. We introduce a new controllable attribute in story generation, i.e., the story style, which has been paid little attention to in prior studies. 1 Link to the code: https://github.com/thucoai/Stylized-Story-Generation-withStyle-Guided-Planning.git 3"
2021.findings-acl.215,P02-1040,0,0.125712,"ap with the human-written stories than baselines. Automatic Evaluation Evaluation Metrics We use the following metrics for automatic evaluation: (1) Perplexity (PPL). Since the automatically annotated style labels may contain innate bias, we do not calculate the perplexity conditioned on the annotated styles for the stories in the test set. Instead, we calculate the perplexity of a model for each sample conditioned on two styles (emotion-driven and eventdriven), respectively, and then get the perplexity on the entire test set by averaging the smaller perplexity for each sample.(2) BLEU (B-n) (Papineni et al., 2002): The metric evaluates n-gram overlap (n = 1, 2). For each beginning in the test set, we generate two stories conditioned on two styles, respectively. Then we calculate the BLEU score on the test set by averaging the higher BLEU with the reference story for each sample.(3) Distinct (Dn) (Li et al., 2016): The metric measures the generation diversity with the percentage of unique n-grams (n = 1, 2). (4) Numbers of Stylistic Keywords (Number): We use the average n0 (described in §4.2) to evaluate how many consistent stylistic keywords the generated stories have. (5) Lexical Style Consistency (LS"
2021.findings-acl.215,P18-1205,0,0.0280011,"ketch and then generating the whole story from the sketch. The sketch is usually a series of keywords (Yao et al., 2019), a learnable skeleton (Xu et al., 2018) or an action sequence (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story generation, Huang et al. (2019) and Xu et al. (2020) controlled the story topics and planned keywords, respectively. Besides, for general text generation, the authorship (Tikhonov and Yamshchikov, 2018), sentiment (Hu et al., 2017), and topics (Li et al., 2020) can also be controlled for different purposes. We introduce a new controllable attribute in story generation, i.e., the story style, which has been paid little attention to in prior studies. 1 Link to t"
2021.findings-acl.215,D18-1462,0,0.0231588,"lines but also have better consistency with the specified styles.1 2 Related Work Story Generation Recently there have been significant advances for story generation with the encoder-decoder paradigm (Sutskever et al., 2014), the transformer-based architecture (Vaswani et al., 2017) and the large-scale pre-trained models (Radford et al., 2019; Lewis et al., 2020). Prior studies usually decomposed the generation into separate steps by first planning a sketch and then generating the whole story from the sketch. The sketch is usually a series of keywords (Yao et al., 2019), a learnable skeleton (Xu et al., 2018) or an action sequence (Fan et al., 2019; Goldfarb-Tarrant et al., 2020). Another line is to incorporate external knowledge into story generation (Guan et al., 2020; Xu et al., 2020). However, generating stories with controllable styles has hardly been investigated. Stylized Generation Stylized generation aims to generate texts with controllable attributes. For example, recent studies in dialogue systems focused on controlling persona (Zhang et al., 2018; Boyd et al., 2020), sentence functions (Ke et al., 2018), politeness (Niu and Bansal, 2018), and topics (Tang et al., 2019). In story genera"
2021.findings-acl.215,2020.emnlp-main.226,0,0.162563,"etween the generated story and the specified style. Experiments demonstrates that our model can controllably generate emotion-driven or event-driven stories based on the ROCStories dataset (Mostafazadeh et al., 2016). Our study presents insights for stylized story generation in further research. 1 Story generation is a challenging task in natural language generation (NLG), namely generating a reasonable story given a leading context. Recent work focuses on enhancing the coherence of generated stories (Fan et al., 2018; Yao et al., 2019) or introducing commonsense knowledge (Guan et al., 2020; Xu et al., 2020). However, it has not yet been investigated to generate stories with controllable styles, which is important since different styles serve different writing purposes. As exemplified in Figure 1, emotion-driven stories use emotional words (e.g., “excited”, “enjoyed”) to reveal the inner states of the characters and bring the readers closer to the characters. In comparison, event-driven stories usually contain a sequence of events with a clear temporal order (e.g., “tearing”!“tried”!“found”!“hooked”), which aims to narrate the story objectively. † Equal contribution. Corresponding author. Stor y"
2021.findings-acl.223,2020.webnlg-1.8,0,0.151112,"on (NLG) task that connects knowledge graphs and texts, this task can further promote the applicability of knowledge graphs in more realistic NLG scenarios, such as knowledge-grounded dialogue generation (Zhou et al., 2018a) and story generation (Guan et al., 2019; Ji et al., 2020). Due to the limited amount of graph-text parallel data, it’s hard for typical neural text generation ∗ Corresponding author The data, codes, and model parameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / relations and target tokens from scratch (Guo et al., 2020; Fu et al., 2020). Recent work resorts to constructing general-purpose pre-trained language models for KG-to-text generation. The most common and simple way is to linearize input graphs into text sequences, and directly fine-tune textto-text Transformer-based pre-trained models like GPT (Radford et al., 2018, 2019), BART (Lewis et al., 2020) or T5 (Raffel et al., 2020) on KG-totext datasets (Ribeiro et al., 2020a; Kale and Rastogi, 2020). Benefiting from self-supervised pretraining on large-scale unlabelled text corpora, pretrained language models can generate high-quality texts via simply fi"
2021.findings-acl.223,2020.emnlp-main.54,1,0.690434,"o-text (KG-to-text) generation aims to generate high-quality texts which are consistent with input graphs (Gardent et al., 2017). This task requires to simultaneously encode the graph structure and the content, and effectively leverage the input graphs in the decoding process (Zhao et al., 2020). As a major natural language generation (NLG) task that connects knowledge graphs and texts, this task can further promote the applicability of knowledge graphs in more realistic NLG scenarios, such as knowledge-grounded dialogue generation (Zhou et al., 2018a) and story generation (Guan et al., 2019; Ji et al., 2020). Due to the limited amount of graph-text parallel data, it’s hard for typical neural text generation ∗ Corresponding author The data, codes, and model parameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / relations and target tokens from scratch (Guo et al., 2020; Fu et al., 2020). Recent work resorts to constructing general-purpose pre-trained language models for KG-to-text generation. The most common and simple way is to linearize input graphs into text sequences, and directly fine-tune textto-text Transformer-based pre-t"
2021.findings-acl.223,2020.coling-main.217,0,0.0283643,"ers with the input of linearized graphs (Gardent et al., 2017; Trisedya et al., 2018; Moryossef et al., 2019), researchers focus on more complex encoder structures for better graph representations, such as graph neural networks (Marcheggiani and Perez-Beltrachini, 2018; Ribeiro et al., 2020b) and graph Transformers (Koncel-Kedziorski et al., 2019; Schmitt et al., 2020a). 2) Unsupervised training: researchers devise unsupervised training objectives to jointly learn the tasks of graph-to-text and textto-graph conversion with non-parallel graph-text data (Schmitt et al., 2020b; Guo et al., 2020; Jin et al., 2020). 3) Building pre-trained models: With the development of pre-trained NLG models such as GPT (Radford et al., 2018, 2019), BART (Lewis et al., 2020) and T5 (Raffel et al., 2020), recent work directly fine-tunes these models on graph-totext datasets and reports impressive performance (Ribeiro et al., 2020a; Kale and Rastogi, 2020; Chen et al., 2020b; Mager et al., 2020). Compared with the existing work on pre-trained models for KG-to-text generation, our model utilizes pre-training methods to explicitly learn graphtext alignments instead of directly fine-tuning textto-text pre-trained models on"
2021.findings-acl.223,2020.inlg-1.14,0,0.196457,"arameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / relations and target tokens from scratch (Guo et al., 2020; Fu et al., 2020). Recent work resorts to constructing general-purpose pre-trained language models for KG-to-text generation. The most common and simple way is to linearize input graphs into text sequences, and directly fine-tune textto-text Transformer-based pre-trained models like GPT (Radford et al., 2018, 2019), BART (Lewis et al., 2020) or T5 (Raffel et al., 2020) on KG-totext datasets (Ribeiro et al., 2020a; Kale and Rastogi, 2020). Benefiting from self-supervised pretraining on large-scale unlabelled text corpora, pretrained language models can generate high-quality texts via simply fine-tuning, and outperform other models with sophisticated structures. Despite the superior performance of fine-tuning pre-trained models on KG-to-text datasets, we argue that building pre-trained models for KG-totext generation still faces two major challenges: 1) Structural information loss during encoding. Most of the existing pre-trained models capture contextual information via bidirectional Transformers (Devlin et al., 2019), which i"
2021.findings-acl.223,N19-1238,0,0.0375841,"Missing"
2021.findings-acl.223,D18-2012,0,0.017748,"Lewis et al., 2020) and T5 (Raffel et al., 2020) as the base model in this paper, which are denoted by JointGT (BART) and JointGT (T5), respectively. The hyper-parameters of the Transformer blocks were the same as BARTbase and T5-base because of the limited computational resources. We initialized our model parameters with the pre-trained checkpoint of BARTbase / T5-base except for the structure-aware semantic aggregation module, which was randomly initialized. We followed BART / T5 to use BytePair Encoding (BPE) vocabulary (Radford et al., 2019) with the size of 50,265 / WordPiece vocabulary (Kudo and Richardson, 2018) with the size of 32,000. The batch size was 42 / 32 for JointGT (BART) / JointGT (T5). The maximum length of linearized input graphs was 600, while the maximum length of text sequences was 64. We adopted Adam (Kingma and Ba, 2015) as the optimizer and set the learning rate to be 3e-5. The warmup ratio was 0.1. JointGT was pre-trained on KGTEXT for 1 epoch with the proposed pre-training tasks. It took 44 / 69 hours for JointGT (BART) / JointGT (T5) on 3 NVIDIA Quadro RTX 6000 GPUs. 4.2 Fine-Tuning Settings We adopted WebNLG, WebQuestions and Path Questions as the benchmark datasets during fine"
2021.findings-acl.223,2020.acl-main.703,0,0.127151,"’s hard for typical neural text generation ∗ Corresponding author The data, codes, and model parameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / relations and target tokens from scratch (Guo et al., 2020; Fu et al., 2020). Recent work resorts to constructing general-purpose pre-trained language models for KG-to-text generation. The most common and simple way is to linearize input graphs into text sequences, and directly fine-tune textto-text Transformer-based pre-trained models like GPT (Radford et al., 2018, 2019), BART (Lewis et al., 2020) or T5 (Raffel et al., 2020) on KG-totext datasets (Ribeiro et al., 2020a; Kale and Rastogi, 2020). Benefiting from self-supervised pretraining on large-scale unlabelled text corpora, pretrained language models can generate high-quality texts via simply fine-tuning, and outperform other models with sophisticated structures. Despite the superior performance of fine-tuning pre-trained models on KG-to-text datasets, we argue that building pre-trained models for KG-totext generation still faces two major challenges: 1) Structural information loss during encoding. Most of the existing pre-trained m"
2021.findings-acl.223,2020.acl-main.167,0,0.0456604,"Missing"
2021.findings-acl.223,W18-6501,0,0.0153687,"of KG-to-text generation including WebNLG, WebQuestions and PathQuestions. Results show that JointGT achieves new state-of-theart performance on KG-to-text generation. 2 Related Work KG-to-Text Generation Recent studies on KG-to-text generation tasks mainly fall into three aspects: 1) Encoder modification: To alleviate the structural information loss of sequence encoders with the input of linearized graphs (Gardent et al., 2017; Trisedya et al., 2018; Moryossef et al., 2019), researchers focus on more complex encoder structures for better graph representations, such as graph neural networks (Marcheggiani and Perez-Beltrachini, 2018; Ribeiro et al., 2020b) and graph Transformers (Koncel-Kedziorski et al., 2019; Schmitt et al., 2020a). 2) Unsupervised training: researchers devise unsupervised training objectives to jointly learn the tasks of graph-to-text and textto-graph conversion with non-parallel graph-text data (Schmitt et al., 2020b; Guo et al., 2020; Jin et al., 2020). 3) Building pre-trained models: With the development of pre-trained NLG models such as GPT (Radford et al., 2018, 2019), BART (Lewis et al., 2020) and T5 (Raffel et al., 2020), recent work directly fine-tunes these models on graph-totext datasets and"
2021.findings-acl.223,N19-1236,0,0.0570043,"Missing"
2021.findings-acl.223,P02-1040,0,0.109804,"each dataset as our baselines, including Seq2Seq with copying or delexicalisation (Shimorina and Gardent, 2018) for WebNLG v2.0, and G2S (Chen et al., 2020d) for WebQuestions and PathQuestions. We directly re-printed the results of baselines if they use the same datasets as ours. Otherwise, we implemented the baselines based on the codes and model parameters released by the original papers. We reported all the results of our implemented models with the mean values over 5 runs. 4.4 Automatic Evaluation We followed the existing work (Shimorina and Gardent, 2018; Chen et al., 2020d) to use BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and ROUGE-L (Lin, 2004) as our automatic metrics. The main results on WebNLG, WebQuestions and PathQuestions are shown in Table 1. We can observe that JointGT based on BART / T5 can outperform vanilla BART / T5 on most of the metrics, respectively, and obtain the state-of-the-art performance on all the datasets. This indicates that our method can promote graph-text alignments and further enhance the performance of the state-of-theart pre-trained models on KG-to-text datasets. 4.5 Human Evaluation To further evaluate the quality of generated results, we condu"
2021.findings-acl.223,D19-1005,0,0.0242072,"re-trained models for KG-to-text generation, our model utilizes pre-training methods to explicitly learn graphtext alignments instead of directly fine-tuning textto-text pre-trained models on KG-to-text datasets. KG-Enhanced Pre-Trained Models Another line of related studies is pre-trained models enhanced by knowledge graphs for natural language understanding (NLU). The motivation of these models is to incorporate knowledge graphs into pre-trained models to facilitate the understanding of entities and relations in natural language. Early work including ERNIE (Zhang et al., 2019) and KnowBERT (Peters et al., 2019) directly uses fixed entity embeddings based on TransE (Bordes et al., 2013) or word vectors (Mikolov et al., 2013) during pre-training. Recent work like KEPLER (Wang et al., 2021) and JAKET (Yu et al., 2020) resorts to jointly pre-training graph-text representations. Specifically, they encode the textual descriptions of entities with pre-trained language models as entity embeddings and jointly optimize the knowledge embedding objective and the masked language modeling objective. In comparison, our model focuses on joint pretraining methods on knowledge graph encoding and sequence decoding in"
2021.findings-acl.223,2020.tacl-1.38,0,0.336959,"ata, codes, and model parameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / relations and target tokens from scratch (Guo et al., 2020; Fu et al., 2020). Recent work resorts to constructing general-purpose pre-trained language models for KG-to-text generation. The most common and simple way is to linearize input graphs into text sequences, and directly fine-tune textto-text Transformer-based pre-trained models like GPT (Radford et al., 2018, 2019), BART (Lewis et al., 2020) or T5 (Raffel et al., 2020) on KG-totext datasets (Ribeiro et al., 2020a; Kale and Rastogi, 2020). Benefiting from self-supervised pretraining on large-scale unlabelled text corpora, pretrained language models can generate high-quality texts via simply fine-tuning, and outperform other models with sophisticated structures. Despite the superior performance of fine-tuning pre-trained models on KG-to-text datasets, we argue that building pre-trained models for KG-totext generation still faces two major challenges: 1) Structural information loss during encoding. Most of the existing pre-trained models capture contextual information via bidirectional Transformers (Dev"
2021.findings-acl.223,2020.emnlp-main.577,0,0.0368561,"Missing"
2021.findings-acl.223,P16-1056,0,0.0453243,"Missing"
2021.findings-acl.223,N18-2074,0,0.183227,"Graph-Text Embedding Alignment ? Figure 3: Overview of our proposed pre-training tasks: (a) Graph enhanced text reconstruction: reconstructing the text sequence given the complete graph. (b) Text enhanced graph reconstruction: predicting the masked entities and relations of the corrupted graph conditioned on the complete text. (c) Graph-text embedding alignment: matching the embedding vectors of the knowledge graph and the text via Optimal Transport. The special token &lt;SEP&gt; is to separate the linearized graph and the text, while &lt;M&gt; denotes the placeholder for masked tokens. attention layer (Shaw et al., 2018): z˜il = |V| X l l βij (zjl W V S + qij W V R) j=1 exp(ulij ) l βij = P|V| l p=1 exp(uip ) ulij = zil W QS  l W KR zjl W KS + qij √ dk (3) 3.3 &gt; i = 1, 2, · · · , |V| where W QS , W KS , W V S , W KR , W V R are the weight matrices in the structure-aware selfattention. This layer integrates the contextual semantic representation of entities and relations based on the graph structure, thereby injecting the structural information into the vanilla Transformer layer. Finally, we use a residual layer to fuse semantic and structural representations of entities, and obtain the hidden states for th"
2021.findings-acl.223,W18-6543,0,0.295351,"OUGE BLEU METEOR ROUGE † † ‡ 36.00 65.00 29.45 30.96‡ 55.45‡ 44.51 70.94 29.61 31.48 55.42 46.04 73.06 28.78 30.55 55.12 76.10** 58.55 75.91 61.01** 72.31 30.02* 73.57** 28.95 45.01 46.32** 32.05** 31.29 55.60 54.47 BLEU 61.48‡ 63.74 58.95 65.89** 60.45 PathQuestions METEOR ROUGE 44.57‡ 77.72‡ 47.23 77.76 44.72 76.58 48.25** 45.38 78.87** 77.59 Table 1: Results on WebNLG, WebQuestions and PathQuestions. SOTA-NPT indicates the state-of-the-art performance from the baselines without pre-training. #Param means the number of model parameters. The results marked with †, ‡ and ] are re-printed from Shimorina and Gardent (2018), Chen et al. (2020d) and Chen et al. (2020b), respectively. - means that the results are not reported in the corresponding references. * indicates that our model significantly outperforms BART and T5 on the corresponding datasets (t-test, p &lt; 0.05), while ** means p &lt; 0.01. Wikipedia hyperlinks of entities in the sentences. The detailed statistics of KGTEXT are shown in Table 2. Dataset KGTEXT WebNLG(U) WebNLG(C) WebQuestions PathQuestions #Ent #Rel 1.8M 3,114 3,129 25,703 7,250 1,210 373 373 672 378 #Instances #Triples Length (Train / Valid / Test) 6.98M / 10K / 10K 27.2 20.2 34,352 / 4,316"
2021.findings-acl.223,2020.acl-main.712,1,0.718322,"our proposed structureaware semantic aggregation module, we fixed the pre-training tasks and compared our encoder with two Transformer-based encoders commonly used in the existing work: SeqEnc: This sequence encoder takes linearized graphs as input and ignores structural information (Ribeiro et al., 2020a; Kale and Rastogi, 2020). RelEnc: This relation-aware encoder regards the entity sequence as input and leverages the relation embedding into the self-attention layer. Both the entity and relation embedding vectors are directly learned as model parameters (Shaw et al., 2018; Zhu et al., 2019; Song et al., 2020). 4.6.2 Pre-Training Task Model JointGT (BART) w/o TextRecon w/o GraphRecon w/o OT w/ BARTPretrain w/ KGPTPretrain BLEU METEOR ROUGE 65.92 47.15 76.10 64.22 46.56 74.96 65.37 47.09 75.97 65.03 47.09 75.83 64.60 46.78 75.74 65.14 46.94 75.72 Table 6: Ablation test of three pre-training tasks on WebNLG(U), including text / graph reconstruction and graph-text alignments via OT. BARTPretrain / KGPTPretrain means using the pre-training tasks of BART / KGPT instead of our tasks on KGTEXT. Model #Param BLEU METEOR ROUGE JointGT (BART) 160M 65.92 47.15 76.10 w/ SeqEnc 140M 64.82 46.87 75.37 160M 65.17"
2021.findings-acl.223,N18-1059,0,0.0186059,"lits: the traditional split (Unconstrained) which guarantees that there is no overlap of input graphs among train / validation / test sets, and a more challenging split (Constrained) where the non-overlap constraint is applied to the triples of input graphs. We denoted these two data splits as WebNLG(U) and WebNLG(C) in our paper. We followed the preprocessing steps of the existing work (Chen et al., 2020b) to replace the underlines in the entities and relations with spaces, and split the entities and relations in a camel case into multiple words. WebQuestions: This dataset (Yih et al., 2016; Talmor and Berant, 2018) is the benchmark for question generation over knowledge bases (KBQG), whose purpose is to generate natural language questions about the corresponding knowledge graphs (Serban et al., 2016). It is constructed from two question answering datasets, i.e., WebQuestionsSP (Yih et al., 2016) and ComplexWebQuestions (Talmor and Berant, 2018). These two datasets contain natural language questions, SPARQL queries and answer entities. We converted the SPARQL query to return a subgraph, and used the same preprocessing steps and data splits as the existing work (Kumar et al., 2019; Chen et al., 2020d). Pa"
2021.findings-acl.223,P18-1151,0,0.0238869,"layer, and utilizes three pre-training tasks to explicitly learn graph-text alignments in the discrete and continuous spaces. • We conduct experiments on the datasets of KG-to-text generation including WebNLG, WebQuestions and PathQuestions. Results show that JointGT achieves new state-of-theart performance on KG-to-text generation. 2 Related Work KG-to-Text Generation Recent studies on KG-to-text generation tasks mainly fall into three aspects: 1) Encoder modification: To alleviate the structural information loss of sequence encoders with the input of linearized graphs (Gardent et al., 2017; Trisedya et al., 2018; Moryossef et al., 2019), researchers focus on more complex encoder structures for better graph representations, such as graph neural networks (Marcheggiani and Perez-Beltrachini, 2018; Ribeiro et al., 2020b) and graph Transformers (Koncel-Kedziorski et al., 2019; Schmitt et al., 2020a). 2) Unsupervised training: researchers devise unsupervised training objectives to jointly learn the tasks of graph-to-text and textto-graph conversion with non-parallel graph-text data (Schmitt et al., 2020b; Guo et al., 2020; Jin et al., 2020). 3) Building pre-trained models: With the development of pre-train"
2021.findings-acl.223,P16-2033,0,0.0165938,"o official data splits: the traditional split (Unconstrained) which guarantees that there is no overlap of input graphs among train / validation / test sets, and a more challenging split (Constrained) where the non-overlap constraint is applied to the triples of input graphs. We denoted these two data splits as WebNLG(U) and WebNLG(C) in our paper. We followed the preprocessing steps of the existing work (Chen et al., 2020b) to replace the underlines in the entities and relations with spaces, and split the entities and relations in a camel case into multiple words. WebQuestions: This dataset (Yih et al., 2016; Talmor and Berant, 2018) is the benchmark for question generation over knowledge bases (KBQG), whose purpose is to generate natural language questions about the corresponding knowledge graphs (Serban et al., 2016). It is constructed from two question answering datasets, i.e., WebQuestionsSP (Yih et al., 2016) and ComplexWebQuestions (Talmor and Berant, 2018). These two datasets contain natural language questions, SPARQL queries and answer entities. We converted the SPARQL query to return a subgraph, and used the same preprocessing steps and data splits as the existing work (Kumar et al., 201"
2021.findings-acl.223,P19-1139,0,0.0260899,"mpared with the existing work on pre-trained models for KG-to-text generation, our model utilizes pre-training methods to explicitly learn graphtext alignments instead of directly fine-tuning textto-text pre-trained models on KG-to-text datasets. KG-Enhanced Pre-Trained Models Another line of related studies is pre-trained models enhanced by knowledge graphs for natural language understanding (NLU). The motivation of these models is to incorporate knowledge graphs into pre-trained models to facilitate the understanding of entities and relations in natural language. Early work including ERNIE (Zhang et al., 2019) and KnowBERT (Peters et al., 2019) directly uses fixed entity embeddings based on TransE (Bordes et al., 2013) or word vectors (Mikolov et al., 2013) during pre-training. Recent work like KEPLER (Wang et al., 2021) and JAKET (Yu et al., 2020) resorts to jointly pre-training graph-text representations. Specifically, they encode the textual descriptions of entities with pre-trained language models as entity embeddings and jointly optimize the knowledge embedding objective and the masked language modeling objective. In comparison, our model focuses on joint pretraining methods on knowledge graph"
2021.findings-acl.223,2020.acl-main.224,0,0.0321197,"re-training tasks to explicitly enhance the graph-text alignment including respective text / graph reconstruction, and graph-text alignment in the embedding space via Optimal Transport. Experiments show that JointGT obtains new stateof-the-art performance on various KG-to-text datasets1 . 1 Introduction Knowledge-graph-to-text (KG-to-text) generation aims to generate high-quality texts which are consistent with input graphs (Gardent et al., 2017). This task requires to simultaneously encode the graph structure and the content, and effectively leverage the input graphs in the decoding process (Zhao et al., 2020). As a major natural language generation (NLG) task that connects knowledge graphs and texts, this task can further promote the applicability of knowledge graphs in more realistic NLG scenarios, such as knowledge-grounded dialogue generation (Zhou et al., 2018a) and story generation (Guan et al., 2019; Ji et al., 2020). Due to the limited amount of graph-text parallel data, it’s hard for typical neural text generation ∗ Corresponding author The data, codes, and model parameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / rela"
2021.findings-acl.223,C18-1171,1,0.845721,"rious KG-to-text datasets1 . 1 Introduction Knowledge-graph-to-text (KG-to-text) generation aims to generate high-quality texts which are consistent with input graphs (Gardent et al., 2017). This task requires to simultaneously encode the graph structure and the content, and effectively leverage the input graphs in the decoding process (Zhao et al., 2020). As a major natural language generation (NLG) task that connects knowledge graphs and texts, this task can further promote the applicability of knowledge graphs in more realistic NLG scenarios, such as knowledge-grounded dialogue generation (Zhou et al., 2018a) and story generation (Guan et al., 2019; Ji et al., 2020). Due to the limited amount of graph-text parallel data, it’s hard for typical neural text generation ∗ Corresponding author The data, codes, and model parameters are available at https://github.com/thu-coai/JointGT. 1 models to learn the alignments between source entities / relations and target tokens from scratch (Guo et al., 2020; Fu et al., 2020). Recent work resorts to constructing general-purpose pre-trained language models for KG-to-text generation. The most common and simple way is to linearize input graphs into text sequences"
2021.findings-acl.223,D19-1548,0,0.0634937,"ated structures. Despite the superior performance of fine-tuning pre-trained models on KG-to-text datasets, we argue that building pre-trained models for KG-totext generation still faces two major challenges: 1) Structural information loss during encoding. Most of the existing pre-trained models capture contextual information via bidirectional Transformers (Devlin et al., 2019), which include full attention connections. This model structure may neglect the structural information when encoding knowledge graphs since the relation between each pair of input entities is not explicitly considered (Zhu et al., 2019). 2) Absence of explicit graph-text alignments. Existing work on pre-trained models for text generation commonly adopts auto-encoding or auto-regressive text reconstruction to learn texttext alignments, which encodes the corrupted text sequence and decodes the original sequence (Lewis et al., 2020; Raffel et al., 2020). Since knowledge graphs may possess more complex structures than text sequences, it’s hard to explicitly learn graphtext alignments by directly using the pre-training tasks based on text reconstruction. Thus, we propose a graph-text joint represen2526 Findings of the Association"
2021.findings-acl.72,2020.acl-main.372,0,0.0231335,"of “no”, “weak”, or “strong”. Due to the unbalanced distribution of three classes, we merged “weak” and “strong” into “yes”. Finally, we differentiated each mechanism as two classes: “no” or “yes”. Dialog Act (DA)4 Welivita and Pu (2020) propose a taxonomy of DA (referred as “intent” in the original paper) for empathetic conversations. They first annotate 15 initial types of DA on the ED corpus (Rashkin et al., 2019), and finally obtain 8 high-frequency types of DA with other types merged as others (8+others), which are shown in Figure 2. Emotion (EM)5 We considered the taxonomy proposed in (Demszky et al., 2020), which contains 27 emotions and a neutral one, because: (1) it has a wide coverage of emotion categories with clear definitions, and (2) the annotated corpus is large-scale and also crawled from Reddit. However, we noted that the original emotion distribution is unbalanced and the too fine-grained taxonomy may lead to the sparsity of partial emotions. Considering the task While no empathetic conversation corpora provide 2 https://github.com/zhongpeixiang/PEC 3 annotations of diverse empathy factors, there are https://github.com/behavioral-data/ abundant publicly available resources that make"
2021.findings-acl.72,W04-1013,0,0.0249377,"are marked with * (Student’s t-test, p-value < 0.05). models. However, when the responses are generated based on the predicted CM / DA / EM, it is not appropriate to compare the generated responses with the reference ones (Liu et al., 2016). Thus, in automatic evaluation we only considered the setting where the models are fed with the ground truth empathy factors. The results where the generated responses are based on the predicted factors will be analyzed in the later experiments. The automatic metrics we adopted include perplexity (PPL), BLEU-2 (B-2) (Papineni et al., 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al., 2016) Greedy matching score. The metrics except PPL were calculated with an NLG evaluation toolkit12 (Sharma et al., 2017), where the generated responses were tokenized with NLTK13 (Loper and Bird, 2002). Results are shown in Table 2. We analyze the results from the following three perspectives: General Performance Our model achieves the best performance on all the metrics on both do12 13 https://github.com/Maluuba/nlg-eval https://www.nltk.org/ mains, and most of the advantages over the competitors are statistically significant. Impact of Empathy Fac"
2021.findings-acl.72,D19-1012,0,0.263581,"both the empirical analysis on a real-life corpus and the extensive experiments. Our codes and used data are available at https://github.com/ chujiezheng/CoMAE. DA CM EM response Abstract EM Figure 1: Our proposed hierarchical framework: CoMAE (right). The directed arrows denote dependencies. We also present the framework (left) of EmpTransfo (Zandie and Mahoor, 2020) for comparison. et al., 2020), which makes the dialog models more empathetic to a certain extent. However, empathy is a multi-dimensional construct (Davis et al., 1980) rather than merely recognizing the interlocutor’s emotion (Lin et al., 2019) or emotional responding (Zhou et al., 2018a). It consists of two broad aspects related to cognition and affection (Omdahl, 2014; Paiva et al., 2017). The cognitive aspect requires understanding and interpreting the situation of the interlocutor (Elliott et al., 2018), which is reflected in the dialog act taken in the conversation (De Vignemont and 1 Introduction Singer, 2006), such as questioning (e.g., What’s Empathy, which refers to the capacity to under- wrong with it?), consoling (e.g., You’ll get through stand or feel what another person is experiencing this), etc. The affective aspect r"
2021.findings-acl.72,D16-1230,0,0.0222641,"Missing"
2021.findings-acl.72,2021.acl-long.269,1,0.820027,"Missing"
2021.findings-acl.72,2021.ccl-1.108,0,0.0787429,"Missing"
2021.findings-acl.72,W02-0109,0,0.0267335,"2016). Thus, in automatic evaluation we only considered the setting where the models are fed with the ground truth empathy factors. The results where the generated responses are based on the predicted factors will be analyzed in the later experiments. The automatic metrics we adopted include perplexity (PPL), BLEU-2 (B-2) (Papineni et al., 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al., 2016) Greedy matching score. The metrics except PPL were calculated with an NLG evaluation toolkit12 (Sharma et al., 2017), where the generated responses were tokenized with NLTK13 (Loper and Bird, 2002). Results are shown in Table 2. We analyze the results from the following three perspectives: General Performance Our model achieves the best performance on all the metrics on both do12 13 https://github.com/Maluuba/nlg-eval https://www.nltk.org/ mains, and most of the advantages over the competitors are statistically significant. Impact of Empathy Factors The model performance vary from different combinations of empathy factors. First, considering more empathy factors always leads to better performance (e.g., CM → DA → EM &gt; CM → EM &gt; +EM &gt; Vanilla). Second, EM brings the most gains to the mod"
2021.findings-acl.72,2020.emnlp-main.721,0,0.0509927,"Missing"
2021.findings-acl.72,P02-1040,0,0.112733,"ignificantly worse than the best scores are marked with * (Student’s t-test, p-value < 0.05). models. However, when the responses are generated based on the predicted CM / DA / EM, it is not appropriate to compare the generated responses with the reference ones (Liu et al., 2016). Thus, in automatic evaluation we only considered the setting where the models are fed with the ground truth empathy factors. The results where the generated responses are based on the predicted factors will be analyzed in the later experiments. The automatic metrics we adopted include perplexity (PPL), BLEU-2 (B-2) (Papineni et al., 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al., 2016) Greedy matching score. The metrics except PPL were calculated with an NLG evaluation toolkit12 (Sharma et al., 2017), where the generated responses were tokenized with NLTK13 (Loper and Bird, 2002). Results are shown in Table 2. We analyze the results from the following three perspectives: General Performance Our model achieves the best performance on all the metrics on both do12 13 https://github.com/Maluuba/nlg-eval https://www.nltk.org/ mains, and most of the advantages over the competitors are statistically signifi"
2021.findings-acl.72,P19-1534,0,0.250848,"at), etc. Very recently, Sharma tion and receive more positive feedback in numer- et al. (2020) further characterizes the text-based ous domains (Klein, 1998; Liu and Picard, 2005; expressed empathy based on the above two aspects Brave et al., 2005; Fitzpatrick et al., 2017; Liu as three communication mechanisms, which is a et al., 2021). Recently, there have also been numer- more higher-level and abstract factor that relates to ous works devoted to improving the dialog models’ empathy expression. ability to understand the feelings of interlocutors In this paper, we propose a novel framework (Rashkin et al., 2019; Lin et al., 2019; Majumder named CoMAE for empathetic response gener∗ Corresponding author. ation (Section 3), which contains the aforemen813 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 813–824 August 1–6, 2021. ©2021 Association for Computational Linguistics tioned three key factors of empathy expression: Communication Mechanism (CM), dialog Act (DA) and Emotion (EM). Specifically, when model these empathy factors simultaneously, we adopt a hierarchical way instead of following previous works that treat multiple factors independently, such like EmpTrans"
2021.findings-acl.72,2021.findings-acl.130,1,0.649499,"Jung, 2016), has been shown to be highly correlated with personality (Leary and Allen, 2011), which in turn influences empathy expression (Richendoller and Weaver III, 1994; Costa et al., 2014). While Zhong et al. (2020) do not explain the explicit connection between persona and empathy expression, they suggest that different speakers may have different “styles” for expressing empathy. 2.2 Empathetic Response Generation In the past years, empathetic response generation has attracted much research interest (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sun et al., 2021). Rashkin et al. (2019) suggest that dialog models can generate more empathetic responses by recognizing the interlocutor’s emotion. Lin et al. (2019) propose to design a dedicated decoder to respond each emotion of the interlocutor, which makes the generation process more interpretable. Majumder et al. (2020) adopt the idea of emotional mimicry (Hess and Fischer, 2014) to make the generated responses more empathetic. Inspired by the advances in generative pre-trained language models (Radford et al., 2018, 2019), EmpTransfo (Zandie and Mahoor, 2020) uses GPT (Radford et al., 2018) to generate"
2021.findings-acl.72,2020.coling-main.429,0,0.04397,"Missing"
2021.findings-acl.72,2020.emnlp-main.531,1,0.437782,"tational Linguistics tioned three key factors of empathy expression: Communication Mechanism (CM), dialog Act (DA) and Emotion (EM). Specifically, when model these empathy factors simultaneously, we adopt a hierarchical way instead of following previous works that treat multiple factors independently, such like EmpTransfo (Zandie and Mahoor, 2020) that considers both DA and EM (see Figure 1 for comparison). Such approaches hold the hypothesis that different factors are independent of each other, which is intuitively unreasonable. In fact, our empirical analysis (Section 4) on a Reddit corpus (Zhong et al., 2020) shows that there are obvious hierarchical relationships between different factors, which confirms the soundness and necessity of hierarchical modeling. We then devise a CoMAE-based model on top of the pre-trained language model GPT-2 (Radford et al., 2019) (Section 5), and compare the model performance with different combinations of empathy factors and hierarchical modeling. Automatic evaluation (Section 6.3) shows that combining all the three factors hierarchically can achieve the best model performance. Manual evaluation (Section 6.4) demonstrates that our model can generate more empathetic"
2021.findings-acl.72,2020.emnlp-main.425,0,0.3853,"mpirically analyze the necessity of hierarchical modeling, and highlight its importance especially in terms of the selection and realization of different empathy factors. 2 2.1 Related Work Factors Related to Empathy Expression Empathy is a complex multi-dimensional construct (Davis et al., 1980) which consists of two broad aspects related to cognition and affection (Omdahl, 2014; Paiva et al., 2017). As shown in Section 1, the two aspects are reflected in the dialog act (DA) taken and the emotion (EM) expressed in the conversation respectively. Based on the theoretical definition of empathy, Sharma et al. (2020) characterize the text-based expressed empathy as 3 communication mechanisms (CM): emotional reaction (ER) (e.g., I feel really sad for you), interpretation (IP) (e.g., This must be terrifying, I also have similar situations), and exploration (EX) (e.g., Are you still feeling alone now?).1 These communication mechanisms are also applied in the recently proposed task of empathetic rewriting (Sharma et al., 2021). Besides, Zhong et al. (2020) propose that persona, which refers to the social face an individual presents to the world (Jung, 2016), has been shown to be highly correlated with persona"
2021.insights-1.9,2020.lrec-1.53,0,0.0227251,"the top of the tokens’ representations to predict BIO format tags. Semantic Parsing (SP) aims at identifying both intents and slots’ values in an utterance. We use TOP dataset (Gupta et al., 2018) that has 45K utterances spanning 25 intents and 36 slots and M ulti WOZ 2.3 dataset (Han et al., 2020) that has 10K dialogs and 143K utterances spanning 7 domains, 13 intents, and 25 slots. We use two linear layers to predict intent and tokens’ tags respectively. Dialog State Tracking (DST) is the task of recognizing user constraints throughout the conversation. We use MultiWOZ dataset version 2.1 (Eric et al., 2020) that has 30 domain-slot pairs to track. We adopt two BERT-based models: TripPy (Heck et al., 2020) and TOD - DST (Wu et al., 2020). Both models use BERT to encode dialog history. Dialog Act Prediction (DAP) is a multi-label sequence classification problem, where models predict the intents of the system response given the dialog history. We use two datasets: MultiWOZ and GSIM (Shah et al., 2018) that contains 6 intents and 3K dialogs. For each intent, we feed the representation of [CLS] token to a linear layer and predict whether the intent is in the response. As for evaluation metrics, we use"
2021.insights-1.9,E17-1042,0,0.0620316,"Missing"
2021.insights-1.9,2020.emnlp-main.66,0,0.26302,"ning MLM Help? An Empirical Study on Task-Oriented Dialog Pre-training Qi Zhu1 , Yuxian Gu1 , Lingxiao Luo1 , Bing Li1 , Cheng Li2 , Wei Peng2 , Xiaoyan Zhu1 , Minlie Huang1∗ 1 CoAI Group, DCST, IAI, BNRIST, Tsinghua University, Beijing, China 2 Artificial Intelligence Application Research Center, Huawei Technologies, Shenzhen, China zhu-q18@mails.tsinghua.edu.cn, aihuang@tsinghua.edu.cn Abstract that DAPT masked LM leads to performance gains under both high- and low-resource settings and TAPT is beneficial with or without DAPT . DAPT has shown effectiveness for task-oriented dialog modeling. Wu et al. (2020) further pretrained BERT on 9 task-oriented dialog corpora and outperformed BERT on four downstream tasks, especially in the few-shot setting. Gu et al. (2020) further pre-trained GPT-2 on 13 dialog corpora ranging from chitchats to task-oriented dialogs, leading to better results on three task-oriented datasets. However, does further pre-training always help? Mehri et al. (2020) performed DAPT on 700M opendomain dialogs and TAPT, but the resulting model only outperforms BERT in 4 out of 7 task-oriented dialog datasets. We also observe that replacing BERT with TOD-BERT-mlm (Wu et al., 2020) th"
2021.insights-1.9,2020.acl-demos.19,1,0.841597,"nt et al. (2020), we encode samples from a test dataset and randomly select the same n = 5000 tokens as stimuli, whose contextual representations at each layer are used to compute an n × n pairwise cosine similarity matrix. The final similarity score between two models’ representations at a certain layer is computed as the Pearson correlation between the flattened upper triangular of the two similarity matrices. Evaluation We conduct comprehensive evaluations on 5 downstream tasks. Models on these tasks are adapted from TOD-BERT (Wu et al., 2020), DialoGLUE (Mehri et al., 2020), or ConvLab-2 (Zhu et al., 2020). See Appendix B for fine-tuning details. Intent Classification (IC) is a sequence classification problem, where models take an utterance as input and predict its intent. We use three datasets: HWU (Liu et al., 2019) that has 64 intents and 26K utterances, BANKING (Casanueva et al., 2020) that has 77 intents and 13K utterances, and OOS (Larson et al., 2019) that has 151 intents and 24K utterances. We pass the representation of [CLS] token to a linear layer for prediction. Slot Filling (SF) requires models to extract slots’ values in an utterance, which is often formulated 3 3.1 Empirical Analy"
2021.insights-1.9,2020.blackboxnlp-1.4,0,0.0220859,"ce respectively, we randomly pick a dialog D and sample a turn t ∈ [1, T ] uniformly, where T is the length of D. Then all the utterances are concatenated into a sequence as the model input: &quot;[CLS] [USR] U1 [SEP] [SYS] S1 [SEP] ... [USR] Ut [SEP]&quot;, where [USR] and [SYS] are two special tokens prepended to user’s and system’s utterances respectively. See Appendix A for the hyper-parameter setting. 2.2 2.3 Representational Similarity Analysis Representational similarity analysis (RSA) is a technique to measure the similarity between models’ representations (Laakso and Cottrell, 2000). Following Merchant et al. (2020), we encode samples from a test dataset and randomly select the same n = 5000 tokens as stimuli, whose contextual representations at each layer are used to compute an n × n pairwise cosine similarity matrix. The final similarity score between two models’ representations at a certain layer is computed as the Pearson correlation between the flattened upper triangular of the two similarity matrices. Evaluation We conduct comprehensive evaluations on 5 downstream tasks. Models on these tasks are adapted from TOD-BERT (Wu et al., 2020), DialoGLUE (Mehri et al., 2020), or ConvLab-2 (Zhu et al., 2020"
2021.insights-1.9,P17-1163,0,0.0623124,"Missing"
C10-1074,J96-1002,0,0.0338033,"Feature Beginning CB Negative Beginning FI Feature Inside CI Negative Inside PB Positive Beginning N Negation Word PI Positive Inside O Other Table 1. Basic Tag Set for Review Mining 3.2 Structure Aware Model In this section, we describe how to encode different linguistic structure into model representation based on our CRFs framework. 3.2.1 Using Linear CRFs. For each sentence in a review, our task is to extract all the object features, positive opinions and negative opinions. This task can be modeled as a classification problem. Traditional classification tools, e.g. Maximum Entropy model (Berger et al, 1996), can be employed, where each word or phrase will be treated as an instance. However, they independently consider each word or phrase, and ignore the dependency relationship among them. Actually, the context information plays an important role for review mining. For example, given two continuous words with same part of speech, if the previous word is a positive opinion, the next word is more likely a positive opinion. Another example is that if the previous word is an adjective, and it is an opinion, the next noun word is more likely an object feature. To this end, we formulate the review mini"
C10-1074,H05-1045,0,0.00632958,"is a generative model, which is hard to integrate rich, overlapping features. It may encounter sparse data problem, especially when simultaneously integrating multiple features. Our framework is based on Conditional Random Fields (CRFs). CRFs is a discriminative model, which can easily integrate various features. These are some studies on opinion mining with Conditional Random Fields. For example, with CRFs, Zhao et al (2008) and McDonald et al. (2007) performed sentiment classification in sentence and document level; Breck et al (2007) identified opinion expressions from newswire documents; Choi et al. (2005) determined opinion holders to opinions also from newswire data. None of previous work focuses on jointly extracting object features, positive opinions and negative opinions simultaneously from review data. More importantly, we also show how to encode the linguistic structure, such as conjunction structure and syntactic tree structure, into model representation in our framework. This is significantly different from most of previous studies, which consider the structure information as heuristic rules (Hu and Liu, 2004) or input features (Wilson et al. 2009). Recently, there are some studies on"
C10-1074,esuli-sebastiani-2006-sentiwordnet,0,0.0325539,"ns in the review sentence, with a collected conjunction set, including “and”, “but”, “or”, “however”, “although” etc. For each conjunction, we extract its connected two text sequences. The nearest two words with same part of speech from the two text sequences are connected with the skip-edge. Here, we just consider the noun, adjective, and adverb. For example, in “good pictures and beautiful music”, there are two skip-edges: one connects two adjective words “good” and “beautiful”; the other connects two nouns “pictures” and “music”. We also employ the general sentiment lexicons, SentiWordNet (Esuli and Sebastiani, 2006), to connect opinions. Two nearest opinion words, detected by sentiment lexicon, from two sequences, will also be connected by skip-edge. If the nearest distance exceeds the threshold, this skip edge will be discarded. Here, we consider the threshold as nine. Skip-chain CRFs improve the performance of review mining, because it naturally encodes the conjunction structure into model representation with skip-edges. 3.2.3 Leveraging Syntactic Tree Structure Besides the conjunction structure, the syntactic tree structure also helps for review mining. The tree denotes the syntactic relationship amon"
C10-1074,P97-1023,0,0.0166859,"tinuous words, as discussed above. It views each word in the sentence as a node, and adjacent nodes are connected by an edge. The graphical representation is shown in Figure 2(a). Linear CRFs can make use of dependency relationship among adjacent words. 3.2.2 Leveraging Conjunction Structure We observe that the conjunctions play important roles on review mining: If the words or phrases are connected by conjunction “and”, they mostly belong to the same opinion polarity. If the words or phrases are connected by conjunction “but”, they mostly belong to different opinion polarity, as reported in (Hatzivassiloglou and McKeown, 1997; Ding and Liu, 2007). For example, “This phone has a very cool and useful feature – the speakerphone”, if we only detect “cool”, it is hard to determine its opinion polarity. But if we see “cool” is connected with “useful” by conjunction “and”, we can easily acquire the polarity of “cool” as positive. This conjunction structure not only helps to determine the opinions, but also helps to recognize object features. For example, “I like the special effects and music in this movie”, with word “music” and conjunction “and”, we can easily detect that “special effects” as an object feature. To model"
C10-1074,H05-1043,0,0.90566,"ject (movie) features, such as “movie”, “actor”, with their corresponding positive opinions and negative opinions, are listed in a structured way. The opinions are ranked by their frequencies. This provides a concise view for reviews. To accomplish this goal, we need to do three tasks: 1), extract all the object features and opinions; 2), determine the sentiment polarities for opinions; 3), for each object feature, determine the relevant opinions, i.e. object feature-opinion pairs. For the first two tasks, most previous studies employ linguistic rules or statistical methods (Hu and Liu, 2004; Popescu and Etzioni 2005). They mainly use unsupervised learning methods, which lack an effective way to address infrequent object features and opinions. They are also hard to incorporate rich overlapping features. 653 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 653–661, Beijing, August 2010 Actually, there are many useful features, which have not been fully exploited for review mining. Meanwhile, most of previous methods extract object features, opinions, and determine the polarities for opinions separately. In fact, the object features, positive opinions and neg"
C10-1074,N07-1038,0,0.0084283,"ious work focuses on jointly extracting object features, positive opinions and negative opinions simultaneously from review data. More importantly, we also show how to encode the linguistic structure, such as conjunction structure and syntactic tree structure, into model representation in our framework. This is significantly different from most of previous studies, which consider the structure information as heuristic rules (Hu and Liu, 2004) or input features (Wilson et al. 2009). Recently, there are some studies on joint sentiment/topic extraction (Mei et al. 2007; Titov and McDonald, 2008; Snyder and Barzilay, 2007). These methods represent reviews as several coarse-grained topics, which can be considered as clusters of object features. They are hard to indentify the low-frequency object features and opinions. While in this paper, we will extract all the present object features and corresponding opinions with their polarities. Besides, the joint sentiment/topic methods are mainly based on review document for topic extraction. In our framework, we focus on sentence-level review extraction. 3 3.1 Structure Aware Review Mining Problem Definition To produce review summaries, we need to first finish two tasks"
C10-1074,P02-1053,0,0.0155192,"Missing"
C10-1074,J09-3003,0,0.168825,"rk can naturally encode the linguistic structure. Besides the neighbor context with linear-chain CRFs, we propose to use Skip-chain CRFs and Tree CRFs to utilize the conjunction structure and syntactic tree structure. We also propose a new unified model, Skip-Tree CRFs to integrate these structures. Here, “structure-aware” refers to the output structure, which model the relationship among output labels. This is significantly different from the previous input structure methods, which consider the linguistic structure as heuristic rules (Ding and Liu, 2007) or input features for classification (Wilson et al. 2009). Our proposed framework has the following advantages: First, it can employ rich features for review mining. We will analyze the effect of features for review mining in this framework. Second, the framework can utilize the relationship among object features, positive opinions and negative opinions. It jointly extracts these three types of expressions in a unified way. Third, the linguistic structure information can be naturally integrated into model representation, which provides more semantic dependency for output labels. Through extensive experiments on movie review and product review, we sh"
C10-1074,P07-1055,0,0.0181301,"and negative opinions, in a unified framework. Recently, Jin and Ho (2009) propose to use Lexicalized HMM for review mining. Lexicalized HMM is a variant of HMM. It is a generative model, which is hard to integrate rich, overlapping features. It may encounter sparse data problem, especially when simultaneously integrating multiple features. Our framework is based on Conditional Random Fields (CRFs). CRFs is a discriminative model, which can easily integrate various features. These are some studies on opinion mining with Conditional Random Fields. For example, with CRFs, Zhao et al (2008) and McDonald et al. (2007) performed sentiment classification in sentence and document level; Breck et al (2007) identified opinion expressions from newswire documents; Choi et al. (2005) determined opinion holders to opinions also from newswire data. None of previous work focuses on jointly extracting object features, positive opinions and negative opinions simultaneously from review data. More importantly, we also show how to encode the linguistic structure, such as conjunction structure and syntactic tree structure, into model representation in our framework. This is significantly different from most of previous stu"
C10-1074,D08-1013,0,\N,Missing
C10-1074,H05-2017,0,\N,Missing
C10-1074,P08-1036,0,\N,Missing
C10-2053,N07-1066,0,0.0282649,"Missing"
C10-2060,W04-3247,0,0.0527343,"experiment, only bigrams are used as concepts. The selection problem requires systems improve diversity or remove redundancy so that more relevant information can be covered by the summary as its length is limited. As our paper focuses on extractive summarization, the selection problem refers to selecting sentences. However, the selection framework presented here is universal for selecting arbitrary textual units, as discussed in Section 4. There have been a variety of studies to approach the ranking problem. These include both unsupervised sentence ranking (Luhn, 1958; Radev and Jing, 2004, Erkan and Radev, 2004), and supervised methods (Ouyang et al., 2007; Shen et al., 2007; Li et al., 2009). Even given a list of ranked sentences, it is not trivial to select a subset of sentences to form a good summary which includes diverse information within a length limit. Three common selection strategies have been studied to address this problem: Maximum Marginal Relevance (MMR) (Carbonell and Goldstein, 1998), Diversity Penalty (DiP) (Wan, 2007), and integer linear programming (ILP) (McDonald, 2007; Gillick and Favre, 2009). As different methods were often evaluated on different datasets, it is of great value"
C10-2060,W04-1017,0,0.0496688,"and TextRank (Mihalcea and Tarau, 2004). There are also a variety of studies on supervised learning methods for sentence ranking and selection. Kupiec et al. (1995) developed a naive Bayes classifier to decide whether a sentence is worthy to extract. Recently, Conditional Random Field (CRF) and Structural SVM have been employed for single document summarization (Shen et al., 2007; Li et al., 2009). Besides ranking sentences directly, there are some approaches that select sentences based on 526 concept ranking. Radev et al. (2004) used centroid words whose tf*idf scores are above a threshold. Filatova and Hatzivassiloglou (2004) used atomic event as concept. Moreover, summarization evaluation metrics such as Basic Element (Hovy et al., 2006), ROUGE (Lin and Hovy, 2003) and Pyramid (Passonneau et al., 2005) are all counting the concept overlap between generated summaries and human-written summaries. Another important issue existing in extractive summarization is to find an optimal sentence subset which can cover diverse information. Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998) and Diversity Penalty (Wan, 2007) are most widely used approaches to reduce redundancy. The two methods are essentially bas"
C10-2060,W09-1802,0,0.476772,"Marginal Relevance and Diversity Penalty strategies. 1 Introduction As the rapid development of the Internet, document summarization has become an important task since document collections are growing larger and larger. Document summarization, which aims at producing a condensed version of the original document(s), helps users to acquire information that is both important and relevant to their information need. So far, researchers have mainly focused on extractive methods which choose a set of salient textual units to form a summary. Such textual units are typically sentences, sub-sentences (Gillick and Favre, 2009), or excerpts (Sauper and Barzilay, 2009). Almost all extractive summarization methods face two key problems: the first problem is how to rank textual units, and the second one is how to select a subset of those ranked units. The ranking problem requires systems model the relevance of a textual unit to a topic or a query. In this paper, the ranking problem refers to either sentence ranking or concept ranking. Concepts can be unigrams, bigrams, semantic content units, etc., although in our experiment, only bigrams are used as concepts. The selection problem requires systems improve diversity or"
C10-2060,hovy-etal-2006-automated,0,0.015235,"selection. Kupiec et al. (1995) developed a naive Bayes classifier to decide whether a sentence is worthy to extract. Recently, Conditional Random Field (CRF) and Structural SVM have been employed for single document summarization (Shen et al., 2007; Li et al., 2009). Besides ranking sentences directly, there are some approaches that select sentences based on 526 concept ranking. Radev et al. (2004) used centroid words whose tf*idf scores are above a threshold. Filatova and Hatzivassiloglou (2004) used atomic event as concept. Moreover, summarization evaluation metrics such as Basic Element (Hovy et al., 2006), ROUGE (Lin and Hovy, 2003) and Pyramid (Passonneau et al., 2005) are all counting the concept overlap between generated summaries and human-written summaries. Another important issue existing in extractive summarization is to find an optimal sentence subset which can cover diverse information. Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998) and Diversity Penalty (Wan, 2007) are most widely used approaches to reduce redundancy. The two methods are essentially based on greedy search. By contrast, ILP based approaches view summary generation as a global optimization problem. Mc"
C10-2060,N03-1020,0,0.302308,"1995) developed a naive Bayes classifier to decide whether a sentence is worthy to extract. Recently, Conditional Random Field (CRF) and Structural SVM have been employed for single document summarization (Shen et al., 2007; Li et al., 2009). Besides ranking sentences directly, there are some approaches that select sentences based on 526 concept ranking. Radev et al. (2004) used centroid words whose tf*idf scores are above a threshold. Filatova and Hatzivassiloglou (2004) used atomic event as concept. Moreover, summarization evaluation metrics such as Basic Element (Hovy et al., 2006), ROUGE (Lin and Hovy, 2003) and Pyramid (Passonneau et al., 2005) are all counting the concept overlap between generated summaries and human-written summaries. Another important issue existing in extractive summarization is to find an optimal sentence subset which can cover diverse information. Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998) and Diversity Penalty (Wan, 2007) are most widely used approaches to reduce redundancy. The two methods are essentially based on greedy search. By contrast, ILP based approaches view summary generation as a global optimization problem. McDonald (2007) proposed a sen"
C10-2060,W09-1801,0,0.0221996,"Goldstein, 1998) and Diversity Penalty (Wan, 2007) are most widely used approaches to reduce redundancy. The two methods are essentially based on greedy search. By contrast, ILP based approaches view summary generation as a global optimization problem. McDonald (2007) proposed a sentence-level ILP solution. Sauper and Barzilay (2009) presented an excerpt-level ILP method to generate Wikipedia articles. Gillick and Favre (2009) proposed a concept-level ILP, but they used document frequency to score concepts (bigrams), without any learning process. Some recent studies (Gillick and Favre, 2009; Martins and Smith, 2009) also modeled sentence selection and compression jointly using ILP. Our ILP framework proposed here is based on these studies. Although various selection strategies have been proposed, there is no work to systematically compare these strategies yet. Learning to rank attracts much attention in the information retrieval community recently. Pointwise, pairwise and listwise learning-torank approaches have been extensively studied (Liu, 2009). Some of those have been applied to document summarization, such as SVR (Ouyang et al., 2007), classification SVM (Wang et al., 2007), and RankNet (Svore et a"
C10-2060,P09-1024,0,0.0583753,"ty strategies. 1 Introduction As the rapid development of the Internet, document summarization has become an important task since document collections are growing larger and larger. Document summarization, which aims at producing a condensed version of the original document(s), helps users to acquire information that is both important and relevant to their information need. So far, researchers have mainly focused on extractive methods which choose a set of salient textual units to form a summary. Such textual units are typically sentences, sub-sentences (Gillick and Favre, 2009), or excerpts (Sauper and Barzilay, 2009). Almost all extractive summarization methods face two key problems: the first problem is how to rank textual units, and the second one is how to select a subset of those ranked units. The ranking problem requires systems model the relevance of a textual unit to a topic or a query. In this paper, the ranking problem refers to either sentence ranking or concept ranking. Concepts can be unigrams, bigrams, semantic content units, etc., although in our experiment, only bigrams are used as concepts. The selection problem requires systems improve diversity or remove redundancy so that more relevant"
C10-2060,D07-1047,0,0.056092,"ith, 2009) also modeled sentence selection and compression jointly using ILP. Our ILP framework proposed here is based on these studies. Although various selection strategies have been proposed, there is no work to systematically compare these strategies yet. Learning to rank attracts much attention in the information retrieval community recently. Pointwise, pairwise and listwise learning-torank approaches have been extensively studied (Liu, 2009). Some of those have been applied to document summarization, such as SVR (Ouyang et al., 2007), classification SVM (Wang et al., 2007), and RankNet (Svore et al., 2007). Again, there is no work to systematically compare these ranking algorithms. To the best of our knowledge, this is the first time that a listwise learning-to-rank algorithm, ListNet (Cao et al., 2007), is adapted to document summarization in this paper. Moreover, pairwise and listwise learning-to-rank algorithms have never been used to perform concept ranking for extractive summarization. 3 Ranking Sentences or Concepts Given a query and a collection of relevant documents, an extractive summarization system is required to generate a summary consisting of a set of text units (usually sentences"
C10-2060,E09-1089,0,0.00336336,"∑ exp( f j =1 w ( x j )) (8) ∂f w ( x j ) ∂w During training, w is updated in a gradient descent manner: w=w -η∆w and η is the learning rate. For details, refer to (Cao et al., 2007). 4 ∑ z * |u u j s.t. ILP-based Selection Framework After we have a way of ranking sentences or concepts, we face a sentence selection problem: selecting an optimal subset of sentences as the final summary. To integrate sentence/concept ranking, we adopted an integer linear programming (ILP) framework to find the optimal sentence subset (Filatova and Hatzivassiloglou, 2004; McDonald, 2007; Gillick and Favre, 2009; Takamura and Okumura, 2009). ILP is a global 528 j |≤ Lim j ∑z (5) It is easy to prove that (Ps(1), Ps(2), …, Ps(n)) is a probability distribution, as the sum of them equals to 1. Therefore, the cross entropy can be used to define the loss between the gold standard distribution Py(j) and the distribution Pf(j), as follows: Δw = optimization problem whose objective and constraints are linear in a set of integer variables. Formally, we define the problem of sentence selection as follows: ⎧ ⎫ (9) maximize: ⎨∑ f ( xi )* zix ⎬ ⎩ i ⎭ u j * I (i, j ) ≥ zix , ∀i j ( z + z xj ) * sim( xi , x j ) < δ ∀i, j x i zix , z uj ∈ {0,1},"
C10-2060,W04-3252,0,\N,Missing
C16-1062,D15-1038,0,0.279837,"r of different entities and relations. The rest of this paper are organized as follows. In Section 2, we introduce some related works. In Section 3, we detail the proposed method of graph aware knowledge embedding. Section 4 describes the data and presents experimental results to validate our method. Section 5 concludes the paper. 642 Table 1: A summary of different knowledge embedding methods. Method NTN(Socher et al., 2013) TransE(Bordes et al., 2013) TransH(Wang et al., 2014) TransR(Lin et al., 2015b) TransD(Ji et al., 2015) TranSparse(Ji et al., 2016) PTransE(Lin et al., 2015a) Traversing(Gu et al., 2015) GAKE(ours) 2 Triple X X X X X X X X X Path × × × × × × X X X Edge × × × × × × × × X Related Work In this section, we review some existing work relevant to our paper. Generally, our work is closely related to the following two topics: (1) knowledge base embedding (2) Graph embedding. 2.1 Knowledge Base Embedding A variety of approaches have been explored for knowledge base embedding, such as general linear based models, such as SE (Bordes et al., 2011), bilinear based models, like LFM (Jenatton et al., 2012; Sutskever et al., 2009), neural network based models, like SLM (Socher et al., 2013),"
C16-1062,P15-1009,0,0.0146091,"there are still some works(Xiao et al., 2016b; Xiao et al., 2016a) follow the principle h + r ≈ t, although they do not share the same form of score function. Particularly, (Xiao et al., 2016b) proposes to use a generative model to deal with multiple semantic meanings of a relation. To accommondate more flexible knowledge embedding, (Xiao et al., 2016a) proposes a manifold principle instead of a point-wise estimation of entity and relation embeddings. There are some other works incorporate additional information, such as text(Toutanova and Chen, 2015; Toutanova et al., 2015) and entity types(Guo et al., 2015). Above knowledge base embedding models all treat the knowledge base as a set of triples. However, in fact, knowledge base is a graph with its graph structure which can be used to better embed the entities and relations in knowledge base. Although (Gu et al., 2015) and PTransE(Lin et al., 2015a) introduce the relation path instead of only considering the direct relations between entities, they just treat the relation path as a new relation and the path length is limited to the model complexity. However, (Feng et al., 2016) claims the principle h + r ≈ t is too strict to model the complex and d"
C16-1062,P15-1067,0,0.672745,"edding models. 1 Introduction Knowledge bases, such as DBpedia, YAGO, and Freebase, are important resources to store complex structured facts about the real world in the form of triplets as (head entity, relation, tail entity). These knowledge bases have benefited many applications, such as web search and question answer. In the meanwhile, knowledge base embedding, which aims to learn a D-dimensional vector for each subject (i.e., an entity or a relation) in a given knowledge base, has attracted considerable research efforts recently (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b; Ji et al., 2015). For instance, TransE method (Bordes et al., 2013) regards the relation in a triplet as a translation between the embedding of the two entities. In other words, TransE learns a preference of h + r = t for each triple, where h, r, and t are the representation vector of head entity, relation, and tail entity respectively. Similar ideas are also proposed in TransH (Wang et al., 2014), TransR (Lin et al., 2015b), TransSparse (Ji et al., 2016), etc. Despite the success of above methods in learning knowledge representations, most of them mainly consider knowledge base as a set of triples and models"
C16-1062,D15-1082,0,0.609577,"f-art knowledge embedding models. 1 Introduction Knowledge bases, such as DBpedia, YAGO, and Freebase, are important resources to store complex structured facts about the real world in the form of triplets as (head entity, relation, tail entity). These knowledge bases have benefited many applications, such as web search and question answer. In the meanwhile, knowledge base embedding, which aims to learn a D-dimensional vector for each subject (i.e., an entity or a relation) in a given knowledge base, has attracted considerable research efforts recently (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b; Ji et al., 2015). For instance, TransE method (Bordes et al., 2013) regards the relation in a triplet as a translation between the embedding of the two entities. In other words, TransE learns a preference of h + r = t for each triple, where h, r, and t are the representation vector of head entity, relation, and tail entity respectively. Similar ideas are also proposed in TransH (Wang et al., 2014), TransR (Lin et al., 2015b), TransSparse (Ji et al., 2016), etc. Despite the success of above methods in learning knowledge representations, most of them mainly consider knowledge base as a set of"
C16-1062,D15-1161,0,0.0208951,"ily. 3.3 Attention Mechanism So far, the translation of a graph context, π(·), takes the embedding results of each subject contained in the context equally. However, in reality, different subjects may have different power of influence to represent the target subject. As an example shown in Figure 1, in edge context, “SingSong” relation is more unique and preventative than “Nationality” as only few people like singers will connect with this “SingSong” while everyone has “Nationality”. In this work, we model representative powers of different subjects in graph context by an attention mechanism (Ling et al., 2015; Hermann et al., 2015). The basic idea of the attention mechanism is using an attention model a(si ) to represent how subject si selectively focuses on representing another subject sj when si is a part of sj ’s context (Kelvin Xu, 2015). In this work, we define the attention model a(si ) as exp(θi ) sj ∈C(si ) exp(θj ) a(si ) = P (6) where θ is the parameters we aim to estimate. Figure 2 illustrates the attention for a path context when predicting the entity “English”, where darker color indicates a greater attention. We see that entities like “Washington” and relations like “LocateInCountry”"
C16-1062,W15-4007,0,0.116253,"ned by the number of entities linked by the relations. In addition, there are still some works(Xiao et al., 2016b; Xiao et al., 2016a) follow the principle h + r ≈ t, although they do not share the same form of score function. Particularly, (Xiao et al., 2016b) proposes to use a generative model to deal with multiple semantic meanings of a relation. To accommondate more flexible knowledge embedding, (Xiao et al., 2016a) proposes a manifold principle instead of a point-wise estimation of entity and relation embeddings. There are some other works incorporate additional information, such as text(Toutanova and Chen, 2015; Toutanova et al., 2015) and entity types(Guo et al., 2015). Above knowledge base embedding models all treat the knowledge base as a set of triples. However, in fact, knowledge base is a graph with its graph structure which can be used to better embed the entities and relations in knowledge base. Although (Gu et al., 2015) and PTransE(Lin et al., 2015a) introduce the relation path instead of only considering the direct relations between entities, they just treat the relation path as a new relation and the path length is limited to the model complexity. However, (Feng et al., 2016) claims the"
C16-1062,D15-1174,0,0.0613821,"ies linked by the relations. In addition, there are still some works(Xiao et al., 2016b; Xiao et al., 2016a) follow the principle h + r ≈ t, although they do not share the same form of score function. Particularly, (Xiao et al., 2016b) proposes to use a generative model to deal with multiple semantic meanings of a relation. To accommondate more flexible knowledge embedding, (Xiao et al., 2016a) proposes a manifold principle instead of a point-wise estimation of entity and relation embeddings. There are some other works incorporate additional information, such as text(Toutanova and Chen, 2015; Toutanova et al., 2015) and entity types(Guo et al., 2015). Above knowledge base embedding models all treat the knowledge base as a set of triples. However, in fact, knowledge base is a graph with its graph structure which can be used to better embed the entities and relations in knowledge base. Although (Gu et al., 2015) and PTransE(Lin et al., 2015a) introduce the relation path instead of only considering the direct relations between entities, they just treat the relation path as a new relation and the path length is limited to the model complexity. However, (Feng et al., 2016) claims the principle h + r ≈ t is to"
C16-1062,P16-1219,1,0.589397,"are projected into a relationspecific hyperplane wr , say hr = h − wr&gt; hwr , tr = t − wr&gt; twr . In TransR (Lin et al., 2015b), hr = hMr , tr = tMr , where entities are projected from the entity space to the relation space by Mr . In TransD (Ji et al., 2015), hr = Mrh h, tr = Mrt t, where the mapping matrices Mrh and Mrt are both related to the entity and relation. In TransSparse (Ji et al., 2016), hr = Mr (θr )h , tr = Mr (θr )t, where Mr is an adaptive sparse matrix, whose sparse degrees are determined by the number of entities linked by the relations. In addition, there are still some works(Xiao et al., 2016b; Xiao et al., 2016a) follow the principle h + r ≈ t, although they do not share the same form of score function. Particularly, (Xiao et al., 2016b) proposes to use a generative model to deal with multiple semantic meanings of a relation. To accommondate more flexible knowledge embedding, (Xiao et al., 2016a) proposes a manifold principle instead of a point-wise estimation of entity and relation embeddings. There are some other works incorporate additional information, such as text(Toutanova and Chen, 2015; Toutanova et al., 2015) and entity types(Guo et al., 2015). Above knowledge base embed"
C16-1106,P15-1153,0,0.0487759,"them make the ﬁnal decision. However, the vast availability of such reviews becomes overwhelming to users when there is just too much to digest. Product review summarization is the task to address this problem. It summarizes the large number of reviews and generates a short readable summary which contains the overall rating of the opinions in the reviews. Traditional extractive summarization has been studied for a long time, such as (Hovy and Lin, 1999; Kupiec et al., 1995; Paice, 1990). Recently, there are also a number of studies on abstractive summarization, such as (Banerjee et al., 2015; Bing et al., 2015; Liu et al., 2015). However, applying traditional summarization methods directly on product reviews doesn’t yield satisfying results. This is due to that product review summarization is quite different from traditional extractive summarization. From the perspective of data size, the number of reviews of a product is often much larger than that of traditional data such as news articles. Another important difference is that sentences in product reviews are usually colloquial and contain lots of noises. Directly extractive summaries may contain a large number of undesired information. A number o"
C16-1106,W14-4408,0,0.225569,"Missing"
C16-1106,C12-1047,0,0.0603627,"Missing"
C16-1106,C12-1056,0,0.0590086,"Missing"
C16-1106,C10-1039,0,0.401842,"on methods directly on product reviews doesn’t yield satisfying results. This is due to that product review summarization is quite different from traditional extractive summarization. From the perspective of data size, the number of reviews of a product is often much larger than that of traditional data such as news articles. Another important difference is that sentences in product reviews are usually colloquial and contain lots of noises. Directly extractive summaries may contain a large number of undesired information. A number of researchers have studied the task of review summarization. (Ganesan et al., 2010) proposed a graph-based method for generating ultra concise opinion summaries of products. They used predeﬁned rules for ﬁnding valid sub-paths in the graph and converted those sub-paths into sentences. Since the sentence generation was rule-based, their method didn’t provide a well-formed grammatical summary. (Gerani et al., 2014) generated product review summaries by using discourse structure. After simplifying the discourse graph, they used a template-based NLG framework to generate natural language summaries. Their summary produced a statistical overview of the product but lacked detailed"
C16-1106,D14-1168,0,0.314393,"r important difference is that sentences in product reviews are usually colloquial and contain lots of noises. Directly extractive summaries may contain a large number of undesired information. A number of researchers have studied the task of review summarization. (Ganesan et al., 2010) proposed a graph-based method for generating ultra concise opinion summaries of products. They used predeﬁned rules for ﬁnding valid sub-paths in the graph and converted those sub-paths into sentences. Since the sentence generation was rule-based, their method didn’t provide a well-formed grammatical summary. (Gerani et al., 2014) generated product review summaries by using discourse structure. After simplifying the discourse graph, they used a template-based NLG framework to generate natural language summaries. Their summary produced a statistical overview of the product but lacked detailed information. (Ganesan et al., 2012) proposed some heuristic rules to generate phrases, they used a modiﬁed mutual information function and an n-gram language model to ensure the representativeness and readability of the phrases. However, their method didn’t consider the descriptiveness of the phrases. This work is licensed under a"
C16-1106,E09-1059,0,0.385012,"Missing"
C16-1106,C10-1074,1,0.937337,"Missing"
C16-1106,N15-1114,0,0.0132115,"decision. However, the vast availability of such reviews becomes overwhelming to users when there is just too much to digest. Product review summarization is the task to address this problem. It summarizes the large number of reviews and generates a short readable summary which contains the overall rating of the opinions in the reviews. Traditional extractive summarization has been studied for a long time, such as (Hovy and Lin, 1999; Kupiec et al., 1995; Paice, 1990). Recently, there are also a number of studies on abstractive summarization, such as (Banerjee et al., 2015; Bing et al., 2015; Liu et al., 2015). However, applying traditional summarization methods directly on product reviews doesn’t yield satisfying results. This is due to that product review summarization is quite different from traditional extractive summarization. From the perspective of data size, the number of reviews of a product is often much larger than that of traditional data such as news articles. Another important difference is that sentences in product reviews are usually colloquial and contain lots of noises. Directly extractive summaries may contain a large number of undesired information. A number of researchers have"
C16-1106,P04-1035,0,0.0479276,"Missing"
C16-1106,W02-1011,0,0.0218297,"Missing"
C16-1106,N07-1038,0,0.109955,"Missing"
C16-1106,P08-1036,0,0.0297951,"04b) used an effective method based on WordNet. (Ku et al., 2006) also used a set of positive and negative words from GI and CNSD to predict sentiments of aspects. (Zhuang et al., 2006) used dependency relationships to identify opinions associated with feature words. Summary generation involves aggregating the results of aspect extraction and sentiment detection and generate the ﬁnal opinion summary in an effective and easy to understand format. Statistical summary 1121 is the most commonly adopted format, such as (Hu and Liu, 2004a; Hu and Liu, 2004b; Hu and Liu, 2006; Zhuang et al., 2006). (Titov and McDonald, 2008b) used a topic modeling method to provide a word level summary for each topic. (Popescu and Etzioni, 2007) also provided a word level summary by ranking opinion words associated to features and showing the strongest opinionated word for each aspect. (Mei et al., 2007) scored the probability of each sentence using TSM model and generated a sentence level summary. (Ku et al., 2006) used TF-IDF to score sentences and select the most relevant and discriminative sentence to be shown as summary. Besides texts, aggregated ratings can also be shown for summary, such as (Lu et al., 2009). (Ku et al.,"
C16-1106,C14-1157,0,0.0592707,"Missing"
C16-1106,D15-1012,0,0.0559966,"Missing"
C16-1191,P06-4018,0,0.00511708,"s. The act types and slot-value pairs are labeled in the dataset. The details about the dialogue act are provided in Table 1. The training, validation and testing set are partitioned in the ratio of 3:1:1. And upsampling w.r.t act type is applied to make the corpus more uniform similar to (Wen et al., 2015). 4.2 Implementation Details We use Theano (Bergstra et al., 2010) to implement the proposed model. For each dialogue act and input question, we generate 20 responses and select the top 5 responses as the output after reranking. The BLEU-4 metric (Papineni et al., 2002) implemented by NLTK (Bird, 2006) is used for quantitative evaluation. And the references set of the BLEU-4 metric are built by grouping the references of the same dialogue acts after delexicalising the responses and lexicalizing them by the correct values. Since the performance of CA-LSTM depends on initialisation, the results shown below are averaged over 5 randomly initialised CA-LSTM and the corpus are partitioned after random shuffle as well. 4.3 Quantitative Evaluation We compare our proposed model with several baselines including: the handcrafted generator (hdc), k-nearest neighbour (kNN), class-based LMs (classlm) as"
C16-1191,D16-1127,0,0.0494517,"open domain dialogue. In addition to the input text, the hierarchical model encodes the context information to generate the response. Data-driven statistical approaches have also been studied for the text planning phase. In the text planning phase, NLG chooses the proper information of every sentence to be presented to users. The generation models mentioned above are trained by predicting the system response in a given conversational context using the maximum-likelihood estimation (MLE) objective so that they tend to generate nonsense responses such as “I dont know”. To address this problem, Li et al. (2016) applies deep reinforcement learning to model long-term reward in chatbot dialogue which can plan the information in the response and avoid generating the nonsense responses in the dialogue. 2.2 Task-oriented NLG for Specific Domain The statistical methods mentioned above are designed for open-domain chatbots, which emphasize on generating relevant and fluent responses according to the input text. While these methods are not suitable for task-solving scenarios (for instance, dialogue systems for restaurant and hotel reservation), which aims at providing correct answers to the input questions,"
C16-1191,W00-0306,0,0.133133,"quantitative evaluation. And the references set of the BLEU-4 metric are built by grouping the references of the same dialogue acts after delexicalising the responses and lexicalizing them by the correct values. Since the performance of CA-LSTM depends on initialisation, the results shown below are averaged over 5 randomly initialised CA-LSTM and the corpus are partitioned after random shuffle as well. 4.3 Quantitative Evaluation We compare our proposed model with several baselines including: the handcrafted generator (hdc), k-nearest neighbour (kNN), class-based LMs (classlm) as proposed by Oh and Rudnicky (2000), the 2-hidder-layer semantically conditioned LSTM network (SC-LSTM) proposed by Wen et al. (2015). For our own method, we experiment with several settings: the basic setting (denoted by CA-LSTM), the Context-Aware LSTM with attention (CA-LSTM+att) which encodes the question vector with an attention mechanism, and the Context-Aware LSTM with attention and act type embeddings (CALSTM+att+emb). The result is shown in Table 2. As we can see, the performances of our methods have been greatly improved compared to the baselines shown in the first block (hdc,kNN,classlm and SC-LSTM). By combining mor"
C16-1191,P02-1040,0,0.103079,"ponse turns sampled from about 1000 dialogues. The act types and slot-value pairs are labeled in the dataset. The details about the dialogue act are provided in Table 1. The training, validation and testing set are partitioned in the ratio of 3:1:1. And upsampling w.r.t act type is applied to make the corpus more uniform similar to (Wen et al., 2015). 4.2 Implementation Details We use Theano (Bergstra et al., 2010) to implement the proposed model. For each dialogue act and input question, we generate 20 responses and select the top 5 responses as the output after reranking. The BLEU-4 metric (Papineni et al., 2002) implemented by NLTK (Bird, 2006) is used for quantitative evaluation. And the references set of the BLEU-4 metric are built by grouping the references of the same dialogue acts after delexicalising the responses and lexicalizing them by the correct values. Since the performance of CA-LSTM depends on initialisation, the results shown below are averaged over 5 randomly initialised CA-LSTM and the corpus are partitioned after random shuffle as well. 4.3 Quantitative Evaluation We compare our proposed model with several baselines including: the handcrafted generator (hdc), k-nearest neighbour (kN"
C16-1191,D14-1162,0,0.0788637,"Missing"
C16-1191,D11-1054,0,0.0382846,"ogue or question answering system. NLG can be treated as a single-turn dialogue generation. Traditional approaches to NLG problem are mostly rule-based or template-based (Bateman and Henschel, 1999; Busemann and Horacek, 2002). However, these methods tend to generate rigid and stylised language without the natural variation of human language. In addition, they need a heavy workload to design the templates or rules. Recently due to the growth of artificial neural networks and the increase of labeled data available on the Internet, data-driven approaches are developed to attack the NLG problem (Ritter et al., 2011; Shang et al., 2015). Shang et al. (2015) and Serban et al. (2015) apply the RNN-based general encoder-decoder framework to the open-domain dialogue response generation task. Although their model can generate the relevant and variant responses according to the input text in a statistical manner, the quality and content of responses depend on the quality and quantum of the training corpus. Wen et al. (2015) propose a taskoriented NLG model that can generate the responses providing the correct answers given the dialogue act (for instance, confirm or request some information), including the answ"
C16-1191,P15-1152,0,0.0253425,"ering system. NLG can be treated as a single-turn dialogue generation. Traditional approaches to NLG problem are mostly rule-based or template-based (Bateman and Henschel, 1999; Busemann and Horacek, 2002). However, these methods tend to generate rigid and stylised language without the natural variation of human language. In addition, they need a heavy workload to design the templates or rules. Recently due to the growth of artificial neural networks and the increase of labeled data available on the Internet, data-driven approaches are developed to attack the NLG problem (Ritter et al., 2011; Shang et al., 2015). Shang et al. (2015) and Serban et al. (2015) apply the RNN-based general encoder-decoder framework to the open-domain dialogue response generation task. Although their model can generate the relevant and variant responses according to the input text in a statistical manner, the quality and content of responses depend on the quality and quantum of the training corpus. Wen et al. (2015) propose a taskoriented NLG model that can generate the responses providing the correct answers given the dialogue act (for instance, confirm or request some information), including the answer information. Howev"
C16-1191,D15-1199,0,0.46474,"rules. Recently due to the growth of artificial neural networks and the increase of labeled data available on the Internet, data-driven approaches are developed to attack the NLG problem (Ritter et al., 2011; Shang et al., 2015). Shang et al. (2015) and Serban et al. (2015) apply the RNN-based general encoder-decoder framework to the open-domain dialogue response generation task. Although their model can generate the relevant and variant responses according to the input text in a statistical manner, the quality and content of responses depend on the quality and quantum of the training corpus. Wen et al. (2015) propose a taskoriented NLG model that can generate the responses providing the correct answers given the dialogue act (for instance, confirm or request some information), including the answer information. However the context information, such as the input question and dialogue act, is ignored. Yin et al. (2016) propose a neural network model that can generate answers to simple factoid questions based on a knowledge base. But a large error rate is observed due to the complex architecture introduced. In this paper, we deal with the NLG problem in this setting: given a question, the correspondin"
C16-1191,W16-0106,0,0.176671,"coder framework to the open-domain dialogue response generation task. Although their model can generate the relevant and variant responses according to the input text in a statistical manner, the quality and content of responses depend on the quality and quantum of the training corpus. Wen et al. (2015) propose a taskoriented NLG model that can generate the responses providing the correct answers given the dialogue act (for instance, confirm or request some information), including the answer information. However the context information, such as the input question and dialogue act, is ignored. Yin et al. (2016) propose a neural network model that can generate answers to simple factoid questions based on a knowledge base. But a large error rate is observed due to the complex architecture introduced. In this paper, we deal with the NLG problem in this setting: given a question, the corresponding dialogue act, and the semantic slots to be addressed in the response, how to generate a natural language response in a dialogue. We present a statistical task-oriented NLG model based on a Context-Aware Long Short-term Memory network (CA-LSTM), which adopts the general encoder-decoder framework to incorporate"
C16-1191,W98-1425,0,\N,Missing
C18-1091,P11-1049,0,0.0316708,"Marcu (2000) proposed statistical approaches to mimic the sentence compression process, they used both noisy-channel and decision-tree to solve the problem. McDonald (2006) presented a discriminative large-margin learning framework coupled with a feature set and syntactic representations for sentence compression. Clarke and Lapata (2006) compared different models for sentence compression across domains and assessed a number of automatic evaluation measures. Clarke and Lapata (2008) used integer linear programming to infer globally optimal compression with linguistically motivated constraints. Berg-Kirkpatrick et al. (2011) proposed a joint model of sentence extraction and compression for multi-document summarization. Filippova and Altun (2013) presented a method for automatically building delete-based sentence compression corpus and proposed an compression method which used structured prediction. Abstractive sentence compression. Abstractive sentence compression extends delete-based compression methods with additional operations, such as substitution, reordering and insertion. Cohn and Lapata (2008) proposed a discriminative tree-to-tree transduction model which incorporated a grammar extraction method and used"
C18-1091,D14-1179,0,0.00895027,"Missing"
C18-1091,N16-1012,0,0.26706,"ess of the sequence-to-sequence (Seq2Seq) model, the task of abstractive sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of abstractive sentence compression work has been built upon the Seq2Seq architecture with attention mechanism, such as (Chopra et al., 2016; Wubben et al., 2016; Nallapati et al., 2016; See et al., 2017). These abstractive models (which will be termed generate-based models hereafter) have the ability to reorder words or rephrase. However, none of these models consider explicit word deletion. As Coster and Kauchak (2011b) pointed out, deletion is a frequently occurring phenomena in sentence compression dataset. Coster and Kauchak (2011a) imposed delete operation on their sentence compression model and improved the performance significantly. Thus, deletion is also very important for abstractive sentence compression task. Inspired b"
C18-1091,P06-1048,0,0.603936,"on-redundancy aspect. 1073 6 Related Work Delete-based sentence compression. A large number of work is devoted to delete-based sentence compression. Jing (2000) presented a system that used multiple sources of knowledge to decide which phrases in a sentence can be removed. Knight and Marcu (2000) proposed statistical approaches to mimic the sentence compression process, they used both noisy-channel and decision-tree to solve the problem. McDonald (2006) presented a discriminative large-margin learning framework coupled with a feature set and syntactic representations for sentence compression. Clarke and Lapata (2006) compared different models for sentence compression across domains and assessed a number of automatic evaluation measures. Clarke and Lapata (2008) used integer linear programming to infer globally optimal compression with linguistically motivated constraints. Berg-Kirkpatrick et al. (2011) proposed a joint model of sentence extraction and compression for multi-document summarization. Filippova and Altun (2013) presented a method for automatically building delete-based sentence compression corpus and proposed an compression method which used structured prediction. Abstractive sentence compress"
C18-1091,D07-1008,0,0.0378157,"e compression, since it needs deeper understanding of the source sentence. Delete-based sentence compression treats the task as a word deletion problem: given an input source sentence x = x1 , x2 , ..., xn (where xi stands for the ith word in the sentence x), the goal is to produce a target sentence by removing any subset of words in the source sentence x (Knight and Marcu, 2002). Delete-based sentence compression has been widely explored across different modeling paradigms, such as noisy-channel model (Knight and Marcu, 2002; Turner and Charniak, 2005), large-margin learning (McDonald, 2006; Cohn and Lapata, 2007), integer linear programming (Clarke and Lapata, 2008) and variational auto-encoder (Miao and Blunsom, 2016). In delete-based sentence compression models, only delete operations are allowed, thus the order of the remaining words can not be changed. These constraints make delete-based sentence compression a relatively easier task. However, in spite of the strong ability of deleting undesired words, delete-based models are not able to rephrase the words, which is far † Corresponding author: Minlie Huang (aihuang@tsinghua.edu.cn) This work is licensed under a Creative Commons Attribution 4.0 Inte"
C18-1091,C08-1018,0,0.61979,"Conference on Computational Linguistics, pages 1065–1076 Santa Fe, New Mexico, USA, August 20-26, 2018. from human sentence compression. For example, in human sentence compression, the word “remove” can replace the phrase “get rid of” under some particular circumstance, but this substitution can not be accomplished by delete-only models. Abstractive sentence compression has the ability to reorder, substitute words or rephrase, thus it is more coherent to human sentence compression. Due to the difficulty of abstractive sentence compression, there was only a limited number of work on the task (Cohn and Lapata, 2008; Cohn and Lapata, 2013; Galanis and Androutsopoulos, 2011; Coster and Kauchak, 2011a). However, with the recent success of the sequence-to-sequence (Seq2Seq) model, the task of abstractive sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of a"
C18-1091,W11-1601,0,0.0244585,"SA, August 20-26, 2018. from human sentence compression. For example, in human sentence compression, the word “remove” can replace the phrase “get rid of” under some particular circumstance, but this substitution can not be accomplished by delete-only models. Abstractive sentence compression has the ability to reorder, substitute words or rephrase, thus it is more coherent to human sentence compression. Due to the difficulty of abstractive sentence compression, there was only a limited number of work on the task (Cohn and Lapata, 2008; Cohn and Lapata, 2013; Galanis and Androutsopoulos, 2011; Coster and Kauchak, 2011a). However, with the recent success of the sequence-to-sequence (Seq2Seq) model, the task of abstractive sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of abstractive sentence compression work has been built upon the Seq2Seq architecture wi"
C18-1091,P11-2117,0,0.0248599,"SA, August 20-26, 2018. from human sentence compression. For example, in human sentence compression, the word “remove” can replace the phrase “get rid of” under some particular circumstance, but this substitution can not be accomplished by delete-only models. Abstractive sentence compression has the ability to reorder, substitute words or rephrase, thus it is more coherent to human sentence compression. Due to the difficulty of abstractive sentence compression, there was only a limited number of work on the task (Cohn and Lapata, 2008; Cohn and Lapata, 2013; Galanis and Androutsopoulos, 2011; Coster and Kauchak, 2011a). However, with the recent success of the sequence-to-sequence (Seq2Seq) model, the task of abstractive sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of abstractive sentence compression work has been built upon the Seq2Seq architecture wi"
C18-1091,D13-1155,0,0.337619,"on-tree to solve the problem. McDonald (2006) presented a discriminative large-margin learning framework coupled with a feature set and syntactic representations for sentence compression. Clarke and Lapata (2006) compared different models for sentence compression across domains and assessed a number of automatic evaluation measures. Clarke and Lapata (2008) used integer linear programming to infer globally optimal compression with linguistically motivated constraints. Berg-Kirkpatrick et al. (2011) proposed a joint model of sentence extraction and compression for multi-document summarization. Filippova and Altun (2013) presented a method for automatically building delete-based sentence compression corpus and proposed an compression method which used structured prediction. Abstractive sentence compression. Abstractive sentence compression extends delete-based compression methods with additional operations, such as substitution, reordering and insertion. Cohn and Lapata (2008) proposed a discriminative tree-to-tree transduction model which incorporated a grammar extraction method and used a language model for coherent output. Galanis and Androutsopoulos (2011) presented a dataset for extractive and abstractiv"
C18-1091,D15-1042,0,0.304499,"ng and insertion. Cohn and Lapata (2008) proposed a discriminative tree-to-tree transduction model which incorporated a grammar extraction method and used a language model for coherent output. Galanis and Androutsopoulos (2011) presented a dataset for extractive and abstractive sentence compression and proposed a SVR based abstractive sentence compressor which utilized additional PMI-based and LDA-based features. Shafieibavani et al. (2016) proposed a word graph-based model which can improve both informativeness and grammaticality of the sentence at the same time. Neural sentence compression. Filippova et al. (2015) proposed a delete-based sentence compression system which took as input a sentence and output a binary sequence corresponding to word deletion decisions in the sentence. The model was trained on a set of 2 millions sentence pairs which was constructed by the same approach used in Filippova and Altun (2013). There are also some neural approaches for abstractive sentence compression. Rush et al. (2015) proposed a fully data-driven approach which utilized neural language models for abstractive sentence compression. They tried different kinds of encoders to encode the input sentence into vector r"
C18-1091,W11-2701,0,0.126061,"s 1065–1076 Santa Fe, New Mexico, USA, August 20-26, 2018. from human sentence compression. For example, in human sentence compression, the word “remove” can replace the phrase “get rid of” under some particular circumstance, but this substitution can not be accomplished by delete-only models. Abstractive sentence compression has the ability to reorder, substitute words or rephrase, thus it is more coherent to human sentence compression. Due to the difficulty of abstractive sentence compression, there was only a limited number of work on the task (Cohn and Lapata, 2008; Cohn and Lapata, 2013; Galanis and Androutsopoulos, 2011; Coster and Kauchak, 2011a). However, with the recent success of the sequence-to-sequence (Seq2Seq) model, the task of abstractive sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of abstractive sentence compression work has been built upon t"
C18-1091,P16-1154,0,0.0225553,"erate decoder for further calculation. 4.2 Copy-Generate Decoder The Copy-Generate decoder produces output the compressed sentence word by word, and the output words are either copied from the input words which are filtered by the delete decoder, or generated with a fixed vocabulary. In other words, our model integrates copy, generate, delete operations together to produce the output sequence. We implement the Copy-Generate decoder as a hybrid network between the basic Seq2Seq network and a pointer network (Vinyals et al., 2015). The structure of the Copy-Generate decoder is close to CopyNet (Gu et al., 2016), Pointer Softmax (Gulcehre et al., 2016) and Pointer-Generator (See et al., 2017). However, the Copy-Generate decoder model has some unique characteristic designed for abstractive sentence compression task. The major difference is that our Copy-Generate decoder incorporates the result of the delete decoder, to make sure that unnecessary words will not be copied back by accident. Another difference from the other models is that our model generates explicit operations. During the 1068 0 0 He said 1 0 companies engaged 0 1 1 1 to set up offices Context Vectors Figure 2: Delete Decoder. training"
C18-1091,P16-1014,0,0.014366,"on. 4.2 Copy-Generate Decoder The Copy-Generate decoder produces output the compressed sentence word by word, and the output words are either copied from the input words which are filtered by the delete decoder, or generated with a fixed vocabulary. In other words, our model integrates copy, generate, delete operations together to produce the output sequence. We implement the Copy-Generate decoder as a hybrid network between the basic Seq2Seq network and a pointer network (Vinyals et al., 2015). The structure of the Copy-Generate decoder is close to CopyNet (Gu et al., 2016), Pointer Softmax (Gulcehre et al., 2016) and Pointer-Generator (See et al., 2017). However, the Copy-Generate decoder model has some unique characteristic designed for abstractive sentence compression task. The major difference is that our Copy-Generate decoder incorporates the result of the delete decoder, to make sure that unnecessary words will not be copied back by accident. Another difference from the other models is that our model generates explicit operations. During the 1068 0 0 He said 1 0 companies engaged 0 1 1 1 to set up offices Context Vectors Figure 2: Delete Decoder. training procedure, we also add supervision on the"
C18-1091,A00-1043,0,0.140282,"results in Table 2 show that combined with the delete decoder, our model can effectively delete unimportant contents without losing much grammar quality of the text. This exactly matches what we expect from our model. Pointer-Generator model performs better on grammaticality aspect than our model, however, our model outperforms the other baselines on non-redundancy aspect. The basic Seq2Seq model performs poorly on both grammaticality aspect and non-redundancy aspect. 1073 6 Related Work Delete-based sentence compression. A large number of work is devoted to delete-based sentence compression. Jing (2000) presented a system that used multiple sources of knowledge to decide which phrases in a sentence can be removed. Knight and Marcu (2000) proposed statistical approaches to mimic the sentence compression process, they used both noisy-channel and decision-tree to solve the problem. McDonald (2006) presented a discriminative large-margin learning framework coupled with a feature set and syntactic representations for sentence compression. Clarke and Lapata (2006) compared different models for sentence compression across domains and assessed a number of automatic evaluation measures. Clarke and La"
C18-1091,W04-1013,0,0.0610612,"periment Metric In the experiments, we compare our model and the baselines with the following metrics. Compression Ratio: The common assumption in compression research is that the system can make the determination of the optimal compression length. Thus, compression ratios can vary drastically across systems. Different systems can be compared only when they are compressing at similar ratios (Napoles et al., 2011). Compression ratio is defined as: CompRatio = # of tokens in compressed text # of tokens in source text (20) ROUGE: We evaluated our models with the standard ROUGE metric proposed by Lin (2004). ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is commonly used for measuring the quality of the summary by comparing computer-generated summaries to reference summaries generated by humans. The basic idea of ROUGE is to count the number of overlapping units such as n-grams, word sequences, and word pairs between computer-generated summaries and the reference summaries. In our experiments, we considered ROUGE-1, ROUGE-2 and ROUGE-L (which respectively measures the word-overlap, bigram-overlap, and longest common sequence between the reference summary and the summary t"
C18-1091,E06-1038,0,0.263039,"te-based sentence compression, since it needs deeper understanding of the source sentence. Delete-based sentence compression treats the task as a word deletion problem: given an input source sentence x = x1 , x2 , ..., xn (where xi stands for the ith word in the sentence x), the goal is to produce a target sentence by removing any subset of words in the source sentence x (Knight and Marcu, 2002). Delete-based sentence compression has been widely explored across different modeling paradigms, such as noisy-channel model (Knight and Marcu, 2002; Turner and Charniak, 2005), large-margin learning (McDonald, 2006; Cohn and Lapata, 2007), integer linear programming (Clarke and Lapata, 2008) and variational auto-encoder (Miao and Blunsom, 2016). In delete-based sentence compression models, only delete operations are allowed, thus the order of the remaining words can not be changed. These constraints make delete-based sentence compression a relatively easier task. However, in spite of the strong ability of deleting undesired words, delete-based models are not able to rephrase the words, which is far † Corresponding author: Minlie Huang (aihuang@tsinghua.edu.cn) This work is licensed under a Creative Comm"
C18-1091,D16-1031,0,0.0349658,"n treats the task as a word deletion problem: given an input source sentence x = x1 , x2 , ..., xn (where xi stands for the ith word in the sentence x), the goal is to produce a target sentence by removing any subset of words in the source sentence x (Knight and Marcu, 2002). Delete-based sentence compression has been widely explored across different modeling paradigms, such as noisy-channel model (Knight and Marcu, 2002; Turner and Charniak, 2005), large-margin learning (McDonald, 2006; Cohn and Lapata, 2007), integer linear programming (Clarke and Lapata, 2008) and variational auto-encoder (Miao and Blunsom, 2016). In delete-based sentence compression models, only delete operations are allowed, thus the order of the remaining words can not be changed. These constraints make delete-based sentence compression a relatively easier task. However, in spite of the strong ability of deleting undesired words, delete-based models are not able to rephrase the words, which is far † Corresponding author: Minlie Huang (aihuang@tsinghua.edu.cn) This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creativecommons.org/licenses/by/4.0/ 1065 Proceedings of the 27th"
C18-1091,K16-1028,0,0.0828148,"model, the task of abstractive sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of abstractive sentence compression work has been built upon the Seq2Seq architecture with attention mechanism, such as (Chopra et al., 2016; Wubben et al., 2016; Nallapati et al., 2016; See et al., 2017). These abstractive models (which will be termed generate-based models hereafter) have the ability to reorder words or rephrase. However, none of these models consider explicit word deletion. As Coster and Kauchak (2011b) pointed out, deletion is a frequently occurring phenomena in sentence compression dataset. Coster and Kauchak (2011a) imposed delete operation on their sentence compression model and improved the performance significantly. Thus, deletion is also very important for abstractive sentence compression task. Inspired by previous work, we propose an Operation Netw"
C18-1091,W11-1611,0,0.0532476,"Missing"
C18-1091,P02-1040,0,0.104339,"mparing computer-generated summaries to reference summaries generated by humans. The basic idea of ROUGE is to count the number of overlapping units such as n-grams, word sequences, and word pairs between computer-generated summaries and the reference summaries. In our experiments, we considered ROUGE-1, ROUGE-2 and ROUGE-L (which respectively measures the word-overlap, bigram-overlap, and longest common sequence between the reference summary and the summary to be evaluated). BLEU: We also report BLEU scores of the baseline models and Operation Network on the test dataset. BLEU is proposed by Papineni et al. (2002), and is usually used for automatic evaluation of statistical machine translation systems. However, it can also be used for evaluating sentence compression task (Napoles et al., 2011). We use the multi-bleu script3 for BLEU score calculation. 5.5 Result Analysis We present the average ratios of the operations in Operation Network’s outputs and the human-written references on the test dataset in Figure 3. Note that the delete ratio is calculated as the number of delete operations divide by the number of tokens in source text, and the copy and generate ratio is calculated as the number of copy a"
C18-1091,D15-1044,0,0.0752913,"atures. Shafieibavani et al. (2016) proposed a word graph-based model which can improve both informativeness and grammaticality of the sentence at the same time. Neural sentence compression. Filippova et al. (2015) proposed a delete-based sentence compression system which took as input a sentence and output a binary sequence corresponding to word deletion decisions in the sentence. The model was trained on a set of 2 millions sentence pairs which was constructed by the same approach used in Filippova and Altun (2013). There are also some neural approaches for abstractive sentence compression. Rush et al. (2015) proposed a fully data-driven approach which utilized neural language models for abstractive sentence compression. They tried different kinds of encoders to encode the input sentence into vector representation of fixed dimensions. Chopra et al. (2016) further improved the model with Recurrent Neural Networks. However, both works used vocabularies of fixed size for target sentence generation. Wubben et al. (2016) used a Seq2Seq model with bi-directional LSTMs for abstractive compression of captions. Toutanova et al. (2016) manually created a multi-reference dataset for sentence and short paragr"
C18-1091,P17-1099,0,0.425321,"active sentence compression has become viable. Seq2Seq has an encoder-decoder architecture where the encoder encodes the input sequence into hidden states, and the decoder then generates the output sequence from the hidden states. The attention mechanism (Bahdanau et al., 2014), which can align the output sequence with the input sequence automatically, boosts the performance of Seq2Seq significantly. A number of abstractive sentence compression work has been built upon the Seq2Seq architecture with attention mechanism, such as (Chopra et al., 2016; Wubben et al., 2016; Nallapati et al., 2016; See et al., 2017). These abstractive models (which will be termed generate-based models hereafter) have the ability to reorder words or rephrase. However, none of these models consider explicit word deletion. As Coster and Kauchak (2011b) pointed out, deletion is a frequently occurring phenomena in sentence compression dataset. Coster and Kauchak (2011a) imposed delete operation on their sentence compression model and improved the performance significantly. Thus, deletion is also very important for abstractive sentence compression task. Inspired by previous work, we propose an Operation Network for abstractive"
C18-1091,D16-1033,0,0.251834,"TY 1 X copy gen loss = (switch losst + copy losst + gen losst ) TY (19) t=1 where TY is the length of the target word sequence Y . 5 Experiments In this section, we introduce the experiments for abstractive sentence compression with our proposed Operation Network. First, we present a brief description of the dataset, and the pre-processing procedure in our experiments. Then, we introduce baselines that are compared with our model. Next, we introduce parameters of our models in the experiments. At last we present and analyze the experiment results. 5.1 Dataset We adopt the dataset provided by Toutanova et al. (2016) for our experiments. It’s a manually-created, multi-reference dataset for sentence and short paragraph compression. It contains 6,169 source texts with multiple compressions (26,423 pairs of source and compressed texts), consisting of business letters, 1070 news journals, and technical documents sampled from the Open American National Corpus (OANC1 ). Of all the source texts, 3,769 are single sentences and the rest are 2-sentence short paragraphs. Each pair of the source and compressed text is aligned by the state-of-the-art monolingual aligner Jacana (Yao et al., 2013). The dataset is split"
C18-1091,P05-1036,0,0.226013,"ctive sentence compression is much harder than delete-based sentence compression, since it needs deeper understanding of the source sentence. Delete-based sentence compression treats the task as a word deletion problem: given an input source sentence x = x1 , x2 , ..., xn (where xi stands for the ith word in the sentence x), the goal is to produce a target sentence by removing any subset of words in the source sentence x (Knight and Marcu, 2002). Delete-based sentence compression has been widely explored across different modeling paradigms, such as noisy-channel model (Knight and Marcu, 2002; Turner and Charniak, 2005), large-margin learning (McDonald, 2006; Cohn and Lapata, 2007), integer linear programming (Clarke and Lapata, 2008) and variational auto-encoder (Miao and Blunsom, 2016). In delete-based sentence compression models, only delete operations are allowed, thus the order of the remaining words can not be changed. These constraints make delete-based sentence compression a relatively easier task. However, in spite of the strong ability of deleting undesired words, delete-based models are not able to rephrase the words, which is far † Corresponding author: Minlie Huang (aihuang@tsinghua.edu.cn) This"
C18-1091,W16-6608,0,0.720592,"Missing"
C18-1091,P13-2123,0,0.071311,"Missing"
C18-1171,D17-2011,0,0.413853,"questions with multiple triples in KB. Results show that our model obtains state-of-the-art performance. 2. Our model is more interpretable than existing reasoning networks in that the intermediate entities and relations predicted by the hop-by-hop reasoning process construct traceable reasoning paths to clearly reveal how the answer is derived. 2 Related Works Recent works on QA can be roughly classified into two types: one is semantic-parsing-based and the other is embedding-based. Semantic parsing approaches map questions to logical form queries (Pasupat and Liang, 2015; Yih et al., 2016; Abujabal et al., 2017). These systems are effective but at the cost of heavy data annotation and pattern/grammar engineering. What’s more, parsing systems are often constrained on a specific domain and broken down when executing logical queries on incomplete KBs. Our work follows the line of Embedding-based models (Bordes et al., 2014b; Dong et al., 2015; Xu et al., 2016; Hao et al., 2017; Yavuz et al., 2017) which are recently introduced into the QA community where questions and KB entities are represented by distributed vectors, and QA is formulated as a problem of matching between vectors of questions and answer"
C18-1171,N16-1181,0,0.0161629,"rsing the questions. Other studies applying hop-by-hop inference into QA can be seen in Neural Programmer (Neelakantan et al., 2015; Neelakantan et al., 2016) and Neural Enquirer (Yin et al., 2015), where deep networks are proposed to parse a question and execute a query on tables. However, Neural Programmer needs to predefine symbolic operations, while Neural Enquirer lacks explicit interpretation. Mou et al. (2017) proposed a model coupling distributed and symbolic execution with REINFORCE algorithm, however, training such a model is challenging. Neural Module Network (Andreas et al., 2015; Andreas et al., 2016) customized network architectures for different patterns of reasoning, making the reasoning network interpretable. However, a dependency parser and the REINFORCE algorithm are required. 2011 3 Interpretable Reasoning Network 3.1 Task Definition Our goal is to offer an interpretable reasoning network to answer multi-relation questions. Given a question q and its topic entity or subject es which can be annotated by some NER tools, the task is to find an entity a in KB as the answer. In this work, we consider two typical categories of multi-relation questions, a path question (Guu et al., 2015) a"
C18-1171,D13-1160,0,0.0791093,"016). 4.1 PathQuestion We adopted two subsets of Freebase (Bollacker et al., 2008) as Knowledge Bases to construct the PathQuestion (PQ) and the PathQuestion-Large (PQL) datasets. We extracted paths between two enr1 r2 r1 r2 r3 tities which span two hops (es −→ e1 −→ a, denoted by -2H) or three hops (es −→ e1 −→ e2 −→ a, denoted by -3H) and then generated natural language questions with templates. To make the generated questions analogical to real-world questions, we included paraphrasing templates and synonyms for relations by searching the Internet and two real-world datasets, WebQuestions (Berant et al., 2013) and WikiAnswers (Fader et al., 2013). In this way, the syntactic structure and surface wording of the generated questions have been greatly enriched. PQL is more challenging than PQ in that PQL utilizes larger KB and provides less training instances. The statistics are shown in Table 1 and more details are described in the Appendix 6. 4.2 WorldCup2014 We also evaluated our model on the WorldCup2014 (WC2014) dataset constructed by (Zhang et al., 2016). The dataset contains single-relation questions (denoted by WC-1H), two-hop path questions (WC2H), and conjunctive questions (WC-C). WC-M is the"
C18-1171,D14-1067,0,0.256853,"ons such as “Name a soccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models (Bordes et al., 2014b; Hao et al., 2017; Yavuz et al., 2017) can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability. Recent reasoning models (Miller et al., 2016; Wang et al., 2017) mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. However, transferring existing RC methods to KBQA is not trivial. For one reason, the focus of reasoning in RC is usually on understanding the document rather than parsing questions. For another reason, existing reasoning netw"
C18-1171,P15-1026,0,0.04849,"derived. 2 Related Works Recent works on QA can be roughly classified into two types: one is semantic-parsing-based and the other is embedding-based. Semantic parsing approaches map questions to logical form queries (Pasupat and Liang, 2015; Yih et al., 2016; Abujabal et al., 2017). These systems are effective but at the cost of heavy data annotation and pattern/grammar engineering. What’s more, parsing systems are often constrained on a specific domain and broken down when executing logical queries on incomplete KBs. Our work follows the line of Embedding-based models (Bordes et al., 2014b; Dong et al., 2015; Xu et al., 2016; Hao et al., 2017; Yavuz et al., 2017) which are recently introduced into the QA community where questions and KB entities are represented by distributed vectors, and QA is formulated as a problem of matching between vectors of questions and answer entities. These models need less grammars as well as annotated data, and are more flexible to deal with incomplete KBs. To make better matching, subgraphs of an entity in KB (Bordes et al., 2014a), answer aspects (Dong et al., 2015; Hao et al., 2017) and external contexts (Xu et al., 2016) can be used to enrich the representation o"
C18-1171,P13-1158,0,0.0259847,"subsets of Freebase (Bollacker et al., 2008) as Knowledge Bases to construct the PathQuestion (PQ) and the PathQuestion-Large (PQL) datasets. We extracted paths between two enr1 r2 r1 r2 r3 tities which span two hops (es −→ e1 −→ a, denoted by -2H) or three hops (es −→ e1 −→ e2 −→ a, denoted by -3H) and then generated natural language questions with templates. To make the generated questions analogical to real-world questions, we included paraphrasing templates and synonyms for relations by searching the Internet and two real-world datasets, WebQuestions (Berant et al., 2013) and WikiAnswers (Fader et al., 2013). In this way, the syntactic structure and surface wording of the generated questions have been greatly enriched. PQL is more challenging than PQ in that PQL utilizes larger KB and provides less training instances. The statistics are shown in Table 1 and more details are described in the Appendix 6. 4.2 WorldCup2014 We also evaluated our model on the WorldCup2014 (WC2014) dataset constructed by (Zhang et al., 2016). The dataset contains single-relation questions (denoted by WC-1H), two-hop path questions (WC2H), and conjunctive questions (WC-C). WC-M is the mixture of WC-1H and WC-2H. The stat"
C18-1171,D15-1038,0,0.0261814,"dreas et al., 2016) customized network architectures for different patterns of reasoning, making the reasoning network interpretable. However, a dependency parser and the REINFORCE algorithm are required. 2011 3 Interpretable Reasoning Network 3.1 Task Definition Our goal is to offer an interpretable reasoning network to answer multi-relation questions. Given a question q and its topic entity or subject es which can be annotated by some NER tools, the task is to find an entity a in KB as the answer. In this work, we consider two typical categories of multi-relation questions, a path question (Guu et al., 2015) and a conjunctive question (Zhang et al., 2016), while the former is our major focus. A path question contains only one topic entity (subject es ) and its answer (object a) can be found by walking down an answer path consisting of a few relations and the corresponding intermediate entities. We define an answer path as a sequence of entities and relations in KB which starts from the subject r1 r2 rn and ends with the answer like es −→ e1 −→ ... −→ a. Relations (ri ) are observable (in various natural language forms) in the question, however, the intermediate entities (e1 · · · eH ) are not. Fo"
C18-1171,P17-1021,0,0.161121,"ccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models (Bordes et al., 2014b; Hao et al., 2017; Yavuz et al., 2017) can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability. Recent reasoning models (Miller et al., 2016; Wang et al., 2017) mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. However, transferring existing RC methods to KBQA is not trivial. For one reason, the focus of reasoning in RC is usually on understanding the document rather than parsing questions. For another reason, existing reasoning networks are usually de"
C18-1171,D16-1147,0,0.201485,"Missing"
C18-1171,P17-2047,0,0.0719795,"s task has recently been facilitated by large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008). However, due to the variety and complexity of language and knowledge, open-domain question answering over knowledge bases (KBQA) is still a challenging task. Question answering over knowledge bases falls into two types, namely single-relation QA and multirelation QA, as argued by Yin et al. (2016). Single-relation questions, such as “How old is Obama?”, can be answered by finding one fact triple in KB, and this task has been widely studied (Bordes et al., 2015; Xu et al., 2016; Savenkov and Agichtein, 2017). In comparison, reasoning over multiple fact triples is required to answer multi-relation questions such as “Name a soccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annota"
C18-1171,P17-1018,0,0.277386,"dge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models (Bordes et al., 2014b; Hao et al., 2017; Yavuz et al., 2017) can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability. Recent reasoning models (Miller et al., 2016; Wang et al., 2017) mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. However, transferring existing RC methods to KBQA is not trivial. For one reason, the focus of reasoning in RC is usually on understanding the document rather than parsing questions. For another reason, existing reasoning networks are usually designed in a black-box style, making the models less interpretable. While in multi-relation question answering, we believe that an interpretable reasoning process is essential. In this paper, we propose a novel Interpretable Reasoning Netwo"
C18-1171,P16-1220,0,0.192007,"pic in AI and this task has recently been facilitated by large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008). However, due to the variety and complexity of language and knowledge, open-domain question answering over knowledge bases (KBQA) is still a challenging task. Question answering over knowledge bases falls into two types, namely single-relation QA and multirelation QA, as argued by Yin et al. (2016). Single-relation questions, such as “How old is Obama?”, can be answered by finding one fact triple in KB, and this task has been widely studied (Bordes et al., 2015; Xu et al., 2016; Savenkov and Agichtein, 2017). In comparison, reasoning over multiple fact triples is required to answer multi-relation questions such as “Name a soccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-cra"
C18-1171,D17-1094,0,0.216687,"ays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models (Bordes et al., 2014b; Hao et al., 2017; Yavuz et al., 2017) can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability. Recent reasoning models (Miller et al., 2016; Wang et al., 2017) mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. However, transferring existing RC methods to KBQA is not trivial. For one reason, the focus of reasoning in RC is usually on understanding the document rather than parsing questions. For another reason, existing reasoning networks are usually designed in a black-box"
C18-1171,P14-2105,0,0.0254562,"triple in KB, and this task has been widely studied (Bordes et al., 2015; Xu et al., 2016; Savenkov and Agichtein, 2017). In comparison, reasoning over multiple fact triples is required to answer multi-relation questions such as “Name a soccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models (Bordes et al., 2014b; Hao et al., 2017; Yavuz et al., 2017) can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability. Recent reasoning models (Miller et al., 2016; Wang et al., 2017) mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. Howev"
C18-1171,P16-2033,0,0.261631,"this task has been widely studied (Bordes et al., 2015; Xu et al., 2016; Savenkov and Agichtein, 2017). In comparison, reasoning over multiple fact triples is required to answer multi-relation questions such as “Name a soccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models (Yih et al., 2014; Yih et al., 2016) obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models (Bordes et al., 2014b; Hao et al., 2017; Yavuz et al., 2017) can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability. Recent reasoning models (Miller et al., 2016; Wang et al., 2017) mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. However, transferring ex"
C18-1171,C16-1164,0,0.0524942,"easoning analysis and failure diagnosis, thereby allowing manual manipulation in predicting the final answer. 1 Introduction Open-domain Question Answering (QA) has always been a hot topic in AI and this task has recently been facilitated by large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008). However, due to the variety and complexity of language and knowledge, open-domain question answering over knowledge bases (KBQA) is still a challenging task. Question answering over knowledge bases falls into two types, namely single-relation QA and multirelation QA, as argued by Yin et al. (2016). Single-relation questions, such as “How old is Obama?”, can be answered by finding one fact triple in KB, and this task has been widely studied (Bordes et al., 2015; Xu et al., 2016; Savenkov and Agichtein, 2017). In comparison, reasoning over multiple fact triples is required to answer multi-relation questions such as “Name a soccer player who plays at forward position at the club Borussia Dortmund.” where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed. Previous studies on QA over knowledge bases can be roughly categ"
C18-1171,D14-1071,0,\N,Missing
D14-1169,P08-1031,0,0.0321242,"owledge to provide a better initialization for EM. In Zhai et al. (2011a), an EM-based unsupervised version was proposed. The so-called L-EM model first generated softly labeled data by grouping feature expressions that share words in common, and then merged the groups by lexical similarity. Zhai et al. (2011b) proposed a LDA-based method that incorporates must-link and cannot-link constraints. Another line of work aimed to extract and cluster aspect words simultaneously using topic modeling. Titov and McDonald (2008) proposed the multi-grain topic models to discover global and local aspects. Branavan et al. (2008) proposed a method which first clustered the key-phrases in Pros and Cons into some aspect categories based on distributional similarity, then built a topic model modeling the topics or aspects. Zhao et al. (2010) proposed the MaxEnt-LDA (a Maximum Entropy and LDA combination) hybrid model to jointly discover both aspect words and aspectspecific opinion words, which can leverage syntactic features to separate aspects and sentiment words. Mukherjee and Liu (2012) proposed a semi-supervised topic model which used userprovided seeds to discover aspects. Chen et al. (2013) proposed a knowledge-bas"
D14-1169,D13-1172,0,0.150438,"ovel unsupervised model in the framework of Posterior Regularization (PR) to cluster aspectrelated phrases. Experiments demonstrate that our approach outperforms baselines remarkably. 1 Introduction Aspect-level sentiment analysis has become a central task in sentiment analysis because it can aggregate various opinions according to a product’s properties, and provide much detailed, complete, and in-depth summaries of a large number of reviews. Aspect finding and clustering, a precursor process of aspect-level sentiment analysis, has attracted more and more attentions (Mukherjee and Liu, 2012; Chen et al., 2013; Zhai et al., 2011a; Zhai et al., 2010). Aspect finding and clustering has never been a trivial task. People often use different words or phrases to refer to the same product property (also called product aspect or feature in the literature). Some terms are lexically dissimilar while semantically close, which makes the task more challenging. For example, “price”, “money” , “worth” and Figure 1: A semi-structured Review. This new angle is inspired by this simple observation (as illustrated in Fig. 1): two phrases within the same cluster are not likely to be simultaneously placed in Pros and Co"
D14-1169,P09-1028,0,0.0604815,"Missing"
D14-1169,P12-1036,0,0.217566,"onstraint, we propose a novel unsupervised model in the framework of Posterior Regularization (PR) to cluster aspectrelated phrases. Experiments demonstrate that our approach outperforms baselines remarkably. 1 Introduction Aspect-level sentiment analysis has become a central task in sentiment analysis because it can aggregate various opinions according to a product’s properties, and provide much detailed, complete, and in-depth summaries of a large number of reviews. Aspect finding and clustering, a precursor process of aspect-level sentiment analysis, has attracted more and more attentions (Mukherjee and Liu, 2012; Chen et al., 2013; Zhai et al., 2011a; Zhai et al., 2010). Aspect finding and clustering has never been a trivial task. People often use different words or phrases to refer to the same product property (also called product aspect or feature in the literature). Some terms are lexically dissimilar while semantically close, which makes the task more challenging. For example, “price”, “money” , “worth” and Figure 1: A semi-structured Review. This new angle is inspired by this simple observation (as illustrated in Fig. 1): two phrases within the same cluster are not likely to be simultaneously pl"
D14-1169,D11-1088,0,0.0132666,"n criteria (Druck et al., 2008) (GE) is a framework for incorporating preferences about model expectations into parameter estimation objective functions. Liang et al. (2009) developed a Bayesian decision-theoretic framework to learn an exponential family model using general measurements on the unlabeled data. In this paper, we model our problem in the framework of posterior regularization. Many works promoted the performance of sentiment analysis by incorporating prior knowledge as weak supervision. Li and Zhang (2009) injected lexical prior knowledge to non-negative matrix tri-factorization. Shen and Li (2011) further extended the matrix factorization framework to model dual supervision from both document and word labels. Vikas Sindhwani (2008) proposed a general framework for incorporating lexical information as well as unlabeled data within standard regularized least squares for sentiment prediction tasks. Fang (2013)proposed a structural learning model with a handful set of aspect signature terms that are encoded as weak supervision to extract latent sentiment explanations. 5 Conclusions Aspect finding and clustering is an important task for aspect-level sentiment analysis. In order to cluster a"
D14-1169,C10-1143,0,0.258662,"Missing"
D14-1169,D10-1006,0,0.0828585,"at share words in common, and then merged the groups by lexical similarity. Zhai et al. (2011b) proposed a LDA-based method that incorporates must-link and cannot-link constraints. Another line of work aimed to extract and cluster aspect words simultaneously using topic modeling. Titov and McDonald (2008) proposed the multi-grain topic models to discover global and local aspects. Branavan et al. (2008) proposed a method which first clustered the key-phrases in Pros and Cons into some aspect categories based on distributional similarity, then built a topic model modeling the topics or aspects. Zhao et al. (2010) proposed the MaxEnt-LDA (a Maximum Entropy and LDA combination) hybrid model to jointly discover both aspect words and aspectspecific opinion words, which can leverage syntactic features to separate aspects and sentiment words. Mukherjee and Liu (2012) proposed a semi-supervised topic model which used userprovided seeds to discover aspects. Chen et al. (2013) proposed a knowledge-based topic model to incorporate must-link and cannot-link information. Their model can adjust topic numbers automatically by leveraging cannot-link. Our work is also related to general constraintdriven(or knowledge-"
D16-1058,P14-2009,0,0.803983,"Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qian et al., 2015), Recursive Neural Tensor Network (Socher et al., 2013), Recurrent Neural Network (Mikolov et al., 2010; Tang et al., 2015b), LSTM (Hochreiter and Schmidhuber, 1997) and Tree-LSTMs (Tai et al., 2015) were applied into sentiment analysis currently. By utilizing syntax structures of sentences, tree-based LSTMs have been proved to be quite effective for many NLP tasks. However, such methods may suffer from syntax parsing errors which are common in resourcelacking languages. LSTM has achieved a great success in various NLP tasks. TD-LSTM and TC-LSTM (Tang et al., 2015a), which"
D16-1058,D16-1166,0,0.0948827,"sentence. To this end, we propose an Attention-based Long Short-Term Memory Network for aspect-level sentiment classification. The attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input. We experiment on the SemEval 2014 dataset and results show that our model achieves state-ofthe-art performance on aspect-level sentiment classification. 1 Neural networks have achieved state-of-the-art performance in a variety of NLP tasks such as machine translation (Lample et al., 2016), paraphrase identification (Yin et al., 2015), question answering (Golub and He, 2016) and text summarization (Rush et al., 2015). However, neural network models are still in infancy to deal with aspectlevel sentiment classification. In some works, target dependent sentiment classification can be benefited from taking into account target information, such as in Target-Dependent LSTM (TD-LSTM) and Target-Connection LSTM (TC-LSTM) (Tang et al., 2015a). However, those models can only take into consideration the target but not aspect information which is proved to be crucial for aspect-level classification. Introduction Sentiment analysis (Nasukawa and Yi, 2003), also known as opin"
D16-1058,D07-1115,0,0.0074877,"tion briefly. 2.1 Sentiment Classification at Aspect-level Aspect-level sentiment classification is typically considered as a classification problem in the liter607 ature. As we mentioned before, aspect-level sentiment classification is a fine-grained classification task. The majority of current approaches attempt to detecting the polarity of the entire sentence, regardless of the entities mentioned or aspects. Traditional approaches to solve those problems are to manually design a set of features. With the abundance of sentiment lexicons (Rao and Ravichandran, 2009; Perez-Rosas et al., 2012; Kaji and Kitsuregawa, 2007), the lexicon-based features were built for sentiment analysis (Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical"
D16-1058,N16-1030,0,0.173152,"fore, it is worthwhile to explore the connection between an aspect and the content of a sentence. To this end, we propose an Attention-based Long Short-Term Memory Network for aspect-level sentiment classification. The attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input. We experiment on the SemEval 2014 dataset and results show that our model achieves state-ofthe-art performance on aspect-level sentiment classification. 1 Neural networks have achieved state-of-the-art performance in a variety of NLP tasks such as machine translation (Lample et al., 2016), paraphrase identification (Yin et al., 2015), question answering (Golub and He, 2016) and text summarization (Rush et al., 2015). However, neural network models are still in infancy to deal with aspectlevel sentiment classification. In some works, target dependent sentiment classification can be benefited from taking into account target information, such as in Target-Dependent LSTM (TD-LSTM) and Target-Connection LSTM (TC-LSTM) (Tang et al., 2015a). However, those models can only take into consideration the target but not aspect information which is proved to be crucial for aspect-level clas"
D16-1058,S13-2053,0,0.0134082,"ation is typically considered as a classification problem in the liter607 ature. As we mentioned before, aspect-level sentiment classification is a fine-grained classification task. The majority of current approaches attempt to detecting the polarity of the entire sentence, regardless of the entities mentioned or aspects. Traditional approaches to solve those problems are to manually design a set of features. With the abundance of sentiment lexicons (Rao and Ravichandran, 2009; Perez-Rosas et al., 2012; Kaji and Kitsuregawa, 2007), the lexicon-based features were built for sentiment analysis (Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qia"
D16-1058,W04-3253,0,0.0108208,"assification task. The majority of current approaches attempt to detecting the polarity of the entire sentence, regardless of the entities mentioned or aspects. Traditional approaches to solve those problems are to manually design a set of features. With the abundance of sentiment lexicons (Rao and Ravichandran, 2009; Perez-Rosas et al., 2012; Kaji and Kitsuregawa, 2007), the lexicon-based features were built for sentiment analysis (Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qian et al., 2015), Recursive Neural Tensor Network (Socher et al., 2013), Recurrent Neural Network (Mikolov et al., 2010; Tang et al., 2015b), LSTM (Hochreiter and Schm"
D16-1058,D14-1162,0,0.121008,"Missing"
D16-1058,perez-rosas-etal-2012-learning,0,0.0156931,"s for sentiment classification briefly. 2.1 Sentiment Classification at Aspect-level Aspect-level sentiment classification is typically considered as a classification problem in the liter607 ature. As we mentioned before, aspect-level sentiment classification is a fine-grained classification task. The majority of current approaches attempt to detecting the polarity of the entire sentence, regardless of the entities mentioned or aspects. Traditional approaches to solve those problems are to manually design a set of features. With the abundance of sentiment lexicons (Rao and Ravichandran, 2009; Perez-Rosas et al., 2012; Kaji and Kitsuregawa, 2007), the lexicon-based features were built for sentiment analysis (Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analy"
D16-1058,S14-2004,0,0.8804,"o a specific aspect. We design an aspect-tosentence attention mechanism that can concentrate 606 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 606–615, c Austin, Texas, November 1-5, 2016. 2016 Association for Computational Linguistics on the key part of a sentence given the aspect. We explore the potential correlation of aspect and sentiment polarity in aspect-level sentiment classification. In order to capture important information in response to a given aspect, we design an attentionbased LSTM. We evaluate our approach on a benchmark dataset (Pontiki et al., 2014), which contains restaurants and laptops data. The main contributions of our work can be summarized as follows: • We propose attention-based Long Short-Term memory for aspect-level sentiment classification. The models are able to attend different parts of a sentence when different aspects are concerned. Results show that the attention mechanism is effective. • Since aspect plays a key role in this task, we propose two ways to take into account aspect information during attention: one way is to concatenate the aspect vector into the sentence hidden representations for computing attention weight"
D16-1058,P15-1132,1,0.401601,"13). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qian et al., 2015), Recursive Neural Tensor Network (Socher et al., 2013), Recurrent Neural Network (Mikolov et al., 2010; Tang et al., 2015b), LSTM (Hochreiter and Schmidhuber, 1997) and Tree-LSTMs (Tai et al., 2015) were applied into sentiment analysis currently. By utilizing syntax structures of sentences, tree-based LSTMs have been proved to be quite effective for many NLP tasks. However, such methods may suffer from syntax parsing errors which are common in resourcelacking languages. LSTM has achieved a great success in various NLP tasks. TD-LSTM and TC-LSTM (Tang et al., 2015a), which took target informat"
D16-1058,E09-1077,0,0.00451146,"ification and neural networks for sentiment classification briefly. 2.1 Sentiment Classification at Aspect-level Aspect-level sentiment classification is typically considered as a classification problem in the liter607 ature. As we mentioned before, aspect-level sentiment classification is a fine-grained classification task. The majority of current approaches attempt to detecting the polarity of the entire sentence, regardless of the entities mentioned or aspects. Traditional approaches to solve those problems are to manually design a set of features. With the abundance of sentiment lexicons (Rao and Ravichandran, 2009; Perez-Rosas et al., 2012; Kaji and Kitsuregawa, 2007), the lexicon-based features were built for sentiment analysis (Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networ"
D16-1058,D15-1044,0,0.0568654,"on-based Long Short-Term Memory Network for aspect-level sentiment classification. The attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input. We experiment on the SemEval 2014 dataset and results show that our model achieves state-ofthe-art performance on aspect-level sentiment classification. 1 Neural networks have achieved state-of-the-art performance in a variety of NLP tasks such as machine translation (Lample et al., 2016), paraphrase identification (Yin et al., 2015), question answering (Golub and He, 2016) and text summarization (Rush et al., 2015). However, neural network models are still in infancy to deal with aspectlevel sentiment classification. In some works, target dependent sentiment classification can be benefited from taking into account target information, such as in Target-Dependent LSTM (TD-LSTM) and Target-Connection LSTM (TC-LSTM) (Tang et al., 2015a). However, those models can only take into consideration the target but not aspect information which is proved to be crucial for aspect-level classification. Introduction Sentiment analysis (Nasukawa and Yi, 2003), also known as opinion mining (Liu, 2012), is a key NLP task t"
D16-1058,D11-1014,0,0.00578556,"sentiment analysis (Mohammad et al., 2013). Most of these studies focus on building sentiment classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qian et al., 2015), Recursive Neural Tensor Network (Socher et al., 2013), Recurrent Neural Network (Mikolov et al., 2010; Tang et al., 2015b), LSTM (Hochreiter and Schmidhuber, 1997) and Tree-LSTMs (Tai et al., 2015) were applied into sentiment analysis currently. By utilizing syntax structures of sentences, tree-based LSTMs have been proved to be quite effective for many NLP tasks. However, such methods may suffer from syntax parsing errors which are common in resourcelacking languages. LSTM has achieved a great success in various NLP tasks. TD-LSTM and TC-LSTM (Tang et"
D16-1058,D13-1170,0,0.0441153,"t classifiers with features, which include bag-of-words and sentiment lexicons, using SVM (Mullen and Collier, 2004). However, the results highly depend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qian et al., 2015), Recursive Neural Tensor Network (Socher et al., 2013), Recurrent Neural Network (Mikolov et al., 2010; Tang et al., 2015b), LSTM (Hochreiter and Schmidhuber, 1997) and Tree-LSTMs (Tai et al., 2015) were applied into sentiment analysis currently. By utilizing syntax structures of sentences, tree-based LSTMs have been proved to be quite effective for many NLP tasks. However, such methods may suffer from syntax parsing errors which are common in resourcelacking languages. LSTM has achieved a great success in various NLP tasks. TD-LSTM and TC-LSTM (Tang et al., 2015a), which took target information into consideration, achieved state-of-the-art perfo"
D16-1058,P15-1150,0,0.0439382,"epend on the quality of features. In addition, feature engineering is labor intensive. 2.2 Sentiment Classification with Neural Networks Since a simple and effective approach to learn distributed representations was proposed (Mikolov et al., 2013), neural networks advance sentiment analysis substantially. Classical models including Recursive Neural Network (Socher et al., 2011; Dong et al., 2014; Qian et al., 2015), Recursive Neural Tensor Network (Socher et al., 2013), Recurrent Neural Network (Mikolov et al., 2010; Tang et al., 2015b), LSTM (Hochreiter and Schmidhuber, 1997) and Tree-LSTMs (Tai et al., 2015) were applied into sentiment analysis currently. By utilizing syntax structures of sentences, tree-based LSTMs have been proved to be quite effective for many NLP tasks. However, such methods may suffer from syntax parsing errors which are common in resourcelacking languages. LSTM has achieved a great success in various NLP tasks. TD-LSTM and TC-LSTM (Tang et al., 2015a), which took target information into consideration, achieved state-of-the-art performance in target-dependent sentiment classification. TCLSTM obtained a target vector by averaging the vectors of words that the target phrase co"
D16-1058,D15-1167,0,0.614855,"el sentiment classification. 1 Neural networks have achieved state-of-the-art performance in a variety of NLP tasks such as machine translation (Lample et al., 2016), paraphrase identification (Yin et al., 2015), question answering (Golub and He, 2016) and text summarization (Rush et al., 2015). However, neural network models are still in infancy to deal with aspectlevel sentiment classification. In some works, target dependent sentiment classification can be benefited from taking into account target information, such as in Target-Dependent LSTM (TD-LSTM) and Target-Connection LSTM (TC-LSTM) (Tang et al., 2015a). However, those models can only take into consideration the target but not aspect information which is proved to be crucial for aspect-level classification. Introduction Sentiment analysis (Nasukawa and Yi, 2003), also known as opinion mining (Liu, 2012), is a key NLP task that receives much attention these years. Aspect-level sentiment analysis is a fine-grained task that can provide complete and in-depth results. In this paper, we deal with aspect-level sentiment classification and we find that the sentiment polarity of a sentence is highly dependent on both content and aspect. For exampl"
D19-1010,D18-1547,0,0.175141,"Missing"
D19-1010,D18-1256,0,0.0400106,"ok a 3-star hotel without confirming with the user at the first turn in Table 1. On the other hand, an explicit user goal is essential to evaluate the task success in the reward design, but user goals are hardly available in real situations (Su et al., Introduction Dialog policy, deciding the next action that the dialog agent should take at each turn, is a crucial component of a task-oriented dialog system. Among many models, Reinforcement Learning (RL) is commonly used to learn dialog policy (Fatemi et al., 2016; Peng et al., 2017; Chen et al., 2017; Yarats and Lewis, 2018; Lei et al., 2018; He et al., 2018; Su et al., 2018), where users are modeled as a part of the environment and the policy is learned through interactions with users. While it is too expensive to learn directly from real users since RL requires a large number of ∗ Corresponding author 100 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 100–110, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics and evaluate the policy using state-action pairs to better guide dialog policy le"
D19-1010,N18-2112,0,0.0537425,"Missing"
D19-1010,D17-1260,0,0.236981,"ete the task properly. For example, it is inappropriate to book a 3-star hotel without confirming with the user at the first turn in Table 1. On the other hand, an explicit user goal is essential to evaluate the task success in the reward design, but user goals are hardly available in real situations (Su et al., Introduction Dialog policy, deciding the next action that the dialog agent should take at each turn, is a crucial component of a task-oriented dialog system. Among many models, Reinforcement Learning (RL) is commonly used to learn dialog policy (Fatemi et al., 2016; Peng et al., 2017; Chen et al., 2017; Yarats and Lewis, 2018; Lei et al., 2018; He et al., 2018; Su et al., 2018), where users are modeled as a part of the environment and the policy is learned through interactions with users. While it is too expensive to learn directly from real users since RL requires a large number of ∗ Corresponding author 100 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 100–110, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics and evaluate the polic"
D19-1010,P18-1133,0,0.0716408,"nappropriate to book a 3-star hotel without confirming with the user at the first turn in Table 1. On the other hand, an explicit user goal is essential to evaluate the task success in the reward design, but user goals are hardly available in real situations (Su et al., Introduction Dialog policy, deciding the next action that the dialog agent should take at each turn, is a crucial component of a task-oriented dialog system. Among many models, Reinforcement Learning (RL) is commonly used to learn dialog policy (Fatemi et al., 2016; Peng et al., 2017; Chen et al., 2017; Yarats and Lewis, 2018; Lei et al., 2018; He et al., 2018; Su et al., 2018), where users are modeled as a part of the environment and the policy is learned through interactions with users. While it is too expensive to learn directly from real users since RL requires a large number of ∗ Corresponding author 100 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 100–110, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics and evaluate the policy using state-action pairs to better guide"
D19-1010,P17-1045,0,0.391772,"s remarkably higher task success than state-of-the-art baselines. 1 Table 1: An example of the multi-domain task-oriented dialog between the user (U) and the system (S). The dialog proceeds successfully because the system informs the user that no matching hotel exists (the first turn), identifies the new user goal about parking (the second turn), and shifts the topic to the restaurant domain (the third turn), which well understands the user’s demand. samples to train, most existing studies use datadriven approaches to build a dialog system from conversational corpora (Zhao and Eskenazi, 2016; Dhingra et al., 2017; Shah et al., 2018; Shi and Yu, 2018), where a common strategy is to build a user simulator, and then to learn dialog policy through making simulated interactions between an agent and the simulator. A typical reward function on policy learning consists of a small negative penalty at each turn to encourage a shorter session, and a large positive reward when the session ends successfully if the agent completes the user goal. However, specifying an effective reward function is challenging in task-oriented dialog. On one hand, the short dialogs resulted from the negative constant rewards are not"
D19-1010,W18-5041,0,0.141261,"d learning algorithms have been proposed to find better rewards, including supervised learning on expert dialogs (Li et al., 2014), online active learning from user feedback (Su et al., 2016), multiobject RL to aggregate measurements of various aspects of user satisfaction (Ultes et al., 2017), etc. However, these methods still require some knowledge about user goals or annotations of dialog ratings from real users. Boularias et al. (2010) and Barahona and Cerisara (2014) learn the reward from dialogs using linear programming based on IRL, but do not scale well in real applications. Recently, Liu and Lane (2018) use adversarial rewards as the only source of reward signal. It trains a Bi-LSTM as a discriminator that works on the entire session to predict the task success. • We build a reward estimator via Inverse Reinforcement Learning (IRL) to infer an appropriate reward from multi-domain dialog sessions, in order to avoid manual design of reward function. 2.3 Adversarial Inverse Reinforcement Learning IRL aims to infer the reward function R underlying expert demonstrations sampled from humans • We integrate Adversarial Learning (AL) to train the policy and estimator simultaneously, 101 User Simulato"
D19-1010,D17-1237,0,0.282465,"oo quickly to complete the task properly. For example, it is inappropriate to book a 3-star hotel without confirming with the user at the first turn in Table 1. On the other hand, an explicit user goal is essential to evaluate the task success in the reward design, but user goals are hardly available in real situations (Su et al., Introduction Dialog policy, deciding the next action that the dialog agent should take at each turn, is a crucial component of a task-oriented dialog system. Among many models, Reinforcement Learning (RL) is commonly used to learn dialog policy (Fatemi et al., 2016; Peng et al., 2017; Chen et al., 2017; Yarats and Lewis, 2018; Lei et al., 2018; He et al., 2018; Su et al., 2018), where users are modeled as a part of the environment and the policy is learned through interactions with users. While it is too expensive to learn directly from real users since RL requires a large number of ∗ Corresponding author 100 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 100–110, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics and"
D19-1010,W16-3613,0,0.380575,"Missing"
D19-1010,P00-1013,0,0.194333,"ents by combining AL with IRL. Inspired by this, we apply AIRL to complex, multi-domain task-oriented dialog, which faces new issues such as discrete action space and language understanding. 3 3.2 A dialog state tracker keeps track of the dialog session to update the dialog state (Williams et al., 2016; Zhang et al., 2019). It records informable slots about the constraints from users and requestable slots that indicates what users want to inquiry. DST maintains a separate belief state for each slot. Given a user action, the belief state of its slot type is updated according to its slot value (Roy et al., 2000). Action and state in our algorithm are defined as follows: Guided Dialog Policy Learning Action : Each system action a or user action au is a subset of dialog act set A as there may be multiple intents in one dialog turn. A dialog act is an abstract representation of an intention (Stolcke et al., 2000), which can be represented in a quadruple composed of domain, intent, slot type and slot value in the multi-domain setting (e.g. [restaurant, inform, food, Italian]). In practice, dialog acts are delexicalized in the dialog policy. We replace the slot value with a count placeholder and refill it"
D19-1010,D14-1007,0,0.0377517,"t with two different user simulators. The contributions of our work are in three folds: • We conduct experiments on the multidomain, multi-intent task-oriented dialog corpus, with different types of user simulators. Results show the superiority of our model to the state-of-the-art baselines. 2 2.1 Related Work Multi-Domain Dialog Policy Learning Some recent efforts have been paid to multidomain task-oriented dialog systems where users converse with the agent across multiple domains. A natural way to handle multi-domain dialog systems is to learn multiple independent singledomain sub-policies (Wang et al., 2014; Gaˇsi´c et al., 2015; Cuay´ahuitl et al., 2016). Multidomain dialog completion was also addressed by hierarchical RL which decomposes the task into several sub-tasks in terms of temporal order (Peng et al., 2017) or space abstraction (Casanueva et al., 2018), but the hierarchical structure can be very complex and constraints between different domains should be considered if an agent conveys multiple intents. 2.2 Reward Learning in Dialog Systems Handcrafted reward functions for dialog policy learning require elaborate design. Several reward learning algorithms have been proposed to find bett"
D19-1010,N07-2038,0,0.714212,"under the new and old policies, Aˆ is the estimated advantage, δ is TD residual, λ and  are hyper-parameters. In summary, a brief script for GPDL algorithm is shown in Algorithm 1. 4 Evaluation Metrics Inform F1 : This evaluates whether all the requested information (e.g. address, phone number of a hotel) has been informed. Here we compute the F1 score so that a policy which greedily answers all the attributes of an entity will only get a high recall but a low precision. (3) T X We apply two user simulators as the interaction environment for the agent. One is the agendabased user simulator (Schatzmann et al., 2007) which uses heuristics, and the other is a datadriven neural model, namely, Variational Hierarchical User Simulator (VHUS) derived from (G¨ur et al., 2018). Both simulators initialize a user goal when the dialog starts2 , provide the agent with a simulated user response at each dialog turn, and work at the dialog act level. Since the original corpus only annotates the dialog acts at the system side, we use the annotation at the user side from ConvLab (Lee et al., 2019) to implement the two simulators. Experimental Setting Data and Simulators We use MultiWOZ (Budzianowski et al., 2018), a multi"
D19-1010,N18-3006,0,0.0874633,"Missing"
D19-1010,P18-1140,0,0.0166105,"te-of-the-art baselines. 1 Table 1: An example of the multi-domain task-oriented dialog between the user (U) and the system (S). The dialog proceeds successfully because the system informs the user that no matching hotel exists (the first turn), identifies the new user goal about parking (the second turn), and shifts the topic to the restaurant domain (the third turn), which well understands the user’s demand. samples to train, most existing studies use datadriven approaches to build a dialog system from conversational corpora (Zhao and Eskenazi, 2016; Dhingra et al., 2017; Shah et al., 2018; Shi and Yu, 2018), where a common strategy is to build a user simulator, and then to learn dialog policy through making simulated interactions between an agent and the simulator. A typical reward function on policy learning consists of a small negative penalty at each turn to encourage a shorter session, and a large positive reward when the session ends successfully if the agent completes the user goal. However, specifying an effective reward function is challenging in task-oriented dialog. On one hand, the short dialogs resulted from the negative constant rewards are not always efficient. The agent may end a"
D19-1010,W16-3601,0,0.0705395,"d reward function achieves remarkably higher task success than state-of-the-art baselines. 1 Table 1: An example of the multi-domain task-oriented dialog between the user (U) and the system (S). The dialog proceeds successfully because the system informs the user that no matching hotel exists (the first turn), identifies the new user goal about parking (the second turn), and shifts the topic to the restaurant domain (the third turn), which well understands the user’s demand. samples to train, most existing studies use datadriven approaches to build a dialog system from conversational corpora (Zhao and Eskenazi, 2016; Dhingra et al., 2017; Shah et al., 2018; Shi and Yu, 2018), where a common strategy is to build a user simulator, and then to learn dialog policy through making simulated interactions between an agent and the simulator. A typical reward function on policy learning consists of a small negative penalty at each turn to encourage a shorter session, and a large positive reward when the session ends successfully if the agent completes the user goal. However, specifying an effective reward function is challenging in task-oriented dialog. On one hand, the short dialogs resulted from the negative con"
D19-1010,J00-3003,0,0.77622,"Missing"
D19-1010,P16-1230,0,0.175143,"Missing"
D19-1010,D18-1416,0,0.0945316,"without confirming with the user at the first turn in Table 1. On the other hand, an explicit user goal is essential to evaluate the task success in the reward design, but user goals are hardly available in real situations (Su et al., Introduction Dialog policy, deciding the next action that the dialog agent should take at each turn, is a crucial component of a task-oriented dialog system. Among many models, Reinforcement Learning (RL) is commonly used to learn dialog policy (Fatemi et al., 2016; Peng et al., 2017; Chen et al., 2017; Yarats and Lewis, 2018; Lei et al., 2018; He et al., 2018; Su et al., 2018), where users are modeled as a part of the environment and the policy is learned through interactions with users. While it is too expensive to learn directly from real users since RL requires a large number of ∗ Corresponding author 100 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 100–110, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics and evaluate the policy using state-action pairs to better guide dialog policy learning. 2016). In"
D19-1010,W17-5509,0,0.115236,"Missing"
D19-1010,P97-1035,0,0.668488,"d templates to make the dialog readable. Given a certain user goal, Turkers first read two simulated dialog sessions, one from the interaction between GDPL and the agenda-based user simulator, the other from another baseline with the same simulator. Then, they are asked to judge which dialog is better (win, draw or lose) according to different subjective assessments. In addition to Task Success, we examine another two measures concerning Dialog Cost in the human evaluation: Efficiency such as dialog turn cost or response delay, and Quality such as redundant information or inappropriate reply (Walker et al., 1997). Since the text is generated by templates for all policies, we do not evaluate language generation here (including grammar, diversity, etc.). We randomly sample 300 user goals from the test set, 100 each for one baseline, and each session pair is evaluated by 3 Turkers. Table 6 presents the results of human evaluation. GDPL outperforms three baselines significantly in all aspects (sign test, p-value < 0.01) except for the quality compared with ACER. Among all the baselines, GDPL obtains the most preference against PPO. Note that the difference between PPO and GDPL is only in the reward signal"
D19-1321,K16-1002,0,0.102899,"Missing"
D19-1321,W14-4012,0,0.0301727,"Missing"
D19-1321,D16-1032,0,0.363241,"te natural language texts from structured data (Gatt and Krahmer, 2018), which has a wide range of applications (for weather forecast, game report, product description, advertising document, etc.). Most neural methods focus on devising encoding scheme and attention mechanism, namely, (1) exploiting input structure to learn better representation of input data (Lebret et al., 2016; Liu et al., 2018), and (2) devising attention mechanisms to better employ input data (Mei et al., 2016; Liu et al., 2018; Nema et al., 2018) or to dynamically trace which part of input has been covered in generation (Kiddon et al., 2016). These models are able to pro∗ *Corresponding author: Minlie Huang. duce fluent and coherent short texts in some applications. However, to generate long and diverse texts such as product descriptions, existing methods are still unable to capture the complex semantic structures and diversified surface forms of long texts. First, existing methods are not good at modeling input data dynamically during generation. Some neural methods (Kiddon et al., 2016; Feng et al., 2018) propose to record the accumulated attention devoted to each input item. However, these records may accumulate errors in repr"
D19-1321,W04-3250,0,0.0379699,"Missing"
D19-1321,J05-1002,0,0.0980966,"Missing"
D19-1321,W03-1016,0,0.102778,"an be better captured. To capture expression diversity, we devise a hierarchical latent structure which injects variations at both high-level planning and low-level realization. 2 Related Work Traditional methods (Reiter and Dale, 1997; Stent et al., 2004) for data-to-text generation consist of three components: content planning, sentence planning, and surface realization. Content planning and sentence planning are responsible for what to say and how to say respectively; they are typically based on hand-crafted (Kukich, 1983; Dalianis and Hovy, 1993; Hovy, 1993) or automatically-learnt rules (Duboue and McKeown, 2003). Surface realization generates natural language by carrying out the plan, which is template-based (McRoy et al., 2003; van Deemter et al., 2005) or grammar-based (Bateman, 1997; Espinosa et al., 2008). As these models are shallow and the two stages (planning and realization) often function separately, traditional methods are unable to capture rich variations of texts. Recently, neural methods have become the mainstream models for data-to-text generation due to their strong ability of representation learning and scalability. These methods perform well in generating weather forecasts (Mei et al"
D19-1321,P08-1022,0,0.0119656,"methods (Reiter and Dale, 1997; Stent et al., 2004) for data-to-text generation consist of three components: content planning, sentence planning, and surface realization. Content planning and sentence planning are responsible for what to say and how to say respectively; they are typically based on hand-crafted (Kukich, 1983; Dalianis and Hovy, 1993; Hovy, 1993) or automatically-learnt rules (Duboue and McKeown, 2003). Surface realization generates natural language by carrying out the plan, which is template-based (McRoy et al., 2003; van Deemter et al., 2005) or grammar-based (Bateman, 1997; Espinosa et al., 2008). As these models are shallow and the two stages (planning and realization) often function separately, traditional methods are unable to capture rich variations of texts. Recently, neural methods have become the mainstream models for data-to-text generation due to their strong ability of representation learning and scalability. These methods perform well in generating weather forecasts (Mei et al., 2016) or very short biographies (Lebret et al., 2016; Liu 3258 Input Encoder gt p ~z h1 h2 h3 d1 d2 d3 … &lt;SG&gt; bow(g1) dN g1 g2 … group … … hN Plan Decoder bow(gT-1) bow(gT-1) gt … d1 d3 Plan Encoder"
D19-1321,D13-1157,0,0.0233552,"k the ability to model diversity of expressions. As for long text generation, recent studies tackle the incoherence problem from different perspectives. To keep the decoder aware of the crucial information in the already generated prefix, Shao et al. (2017) appended the generated prefix to the encoder, and Guo et al. (2018) leaked the extracted features of the generated prefix from the discriminator to the generator in a Generative Adversarial Nets (Goodfellow et al., 2014). To model dependencies among sentences, Li et al. (2015) utilized a hierarchical recurrent neural network (RNN) decoder. Konstas and Lapata (2013) proposed to plan content organization with grammar rules while Puduppully et al. (2019) planned by reordering input data. Most recently, Moryossef et al. (2019) proposed to select plans from all possible ones, which is infeasible for large inputs. As for diverse text generation, existing methods can be divided into three categories: enriching conditions (Xing et al., 2017), post-processing with beam search and rerank (Li et al., 2016), and designing effective models (Xu et al., 2018). Some text-to-text generation models (Serban et al., 2017; Zhao et al., 2017) inject high-level variations wit"
D19-1321,P83-1022,0,0.156408,"n sub-tasks. Thus, input data can be better modeled and inter-sentence coherence can be better captured. To capture expression diversity, we devise a hierarchical latent structure which injects variations at both high-level planning and low-level realization. 2 Related Work Traditional methods (Reiter and Dale, 1997; Stent et al., 2004) for data-to-text generation consist of three components: content planning, sentence planning, and surface realization. Content planning and sentence planning are responsible for what to say and how to say respectively; they are typically based on hand-crafted (Kukich, 1983; Dalianis and Hovy, 1993; Hovy, 1993) or automatically-learnt rules (Duboue and McKeown, 2003). Surface realization generates natural language by carrying out the plan, which is template-based (McRoy et al., 2003; van Deemter et al., 2005) or grammar-based (Bateman, 1997; Espinosa et al., 2008). As these models are shallow and the two stages (planning and realization) often function separately, traditional methods are unable to capture rich variations of texts. Recently, neural methods have become the mainstream models for data-to-text generation due to their strong ability of representation"
D19-1321,D16-1128,0,0.0527432,"Missing"
D19-1321,N16-1014,0,0.128154,"Nets (Goodfellow et al., 2014). To model dependencies among sentences, Li et al. (2015) utilized a hierarchical recurrent neural network (RNN) decoder. Konstas and Lapata (2013) proposed to plan content organization with grammar rules while Puduppully et al. (2019) planned by reordering input data. Most recently, Moryossef et al. (2019) proposed to select plans from all possible ones, which is infeasible for large inputs. As for diverse text generation, existing methods can be divided into three categories: enriching conditions (Xing et al., 2017), post-processing with beam search and rerank (Li et al., 2016), and designing effective models (Xu et al., 2018). Some text-to-text generation models (Serban et al., 2017; Zhao et al., 2017) inject high-level variations with latent variables. Variational Hierarchical Conversation RNN (VHCR) (Park et al., 2018) is a most similar model to ours, which also adopts a hierarchical latent structure. Our method differs from VHCR in two aspects: (1) VHCR has no planning mechanism, and the global latent variable is mainly designed to address the KL collapse problem, while our global latent variable captures the diversity of reasonable planning; (2) VHCR injects di"
D19-1321,P15-1107,0,0.0287674,": they often generate incoherent texts. In fact, these methods also lack the ability to model diversity of expressions. As for long text generation, recent studies tackle the incoherence problem from different perspectives. To keep the decoder aware of the crucial information in the already generated prefix, Shao et al. (2017) appended the generated prefix to the encoder, and Guo et al. (2018) leaked the extracted features of the generated prefix from the discriminator to the generator in a Generative Adversarial Nets (Goodfellow et al., 2014). To model dependencies among sentences, Li et al. (2015) utilized a hierarchical recurrent neural network (RNN) decoder. Konstas and Lapata (2013) proposed to plan content organization with grammar rules while Puduppully et al. (2019) planned by reordering input data. Most recently, Moryossef et al. (2019) proposed to select plans from all possible ones, which is infeasible for large inputs. As for diverse text generation, existing methods can be divided into three categories: enriching conditions (Xing et al., 2017), post-processing with beam search and rerank (Li et al., 2016), and designing effective models (Xu et al., 2018). Some text-to-text g"
D19-1321,N16-1086,0,0.172296,"odel outperforms state-of-theart baselines in long and diverse text generation. 1 Introduction Data-to-text generation is to generate natural language texts from structured data (Gatt and Krahmer, 2018), which has a wide range of applications (for weather forecast, game report, product description, advertising document, etc.). Most neural methods focus on devising encoding scheme and attention mechanism, namely, (1) exploiting input structure to learn better representation of input data (Lebret et al., 2016; Liu et al., 2018), and (2) devising attention mechanisms to better employ input data (Mei et al., 2016; Liu et al., 2018; Nema et al., 2018) or to dynamically trace which part of input has been covered in generation (Kiddon et al., 2016). These models are able to pro∗ *Corresponding author: Minlie Huang. duce fluent and coherent short texts in some applications. However, to generate long and diverse texts such as product descriptions, existing methods are still unable to capture the complex semantic structures and diversified surface forms of long texts. First, existing methods are not good at modeling input data dynamically during generation. Some neural methods (Kiddon et al., 2016; Feng et"
D19-1321,N19-1236,0,0.0457418,"Missing"
D19-1321,N18-1139,0,0.100053,"Missing"
D19-1321,P02-1040,0,0.104109,"the plan decoder, and the plan encoder all have a hidden size of 100. Recipe Text Generation We embedded a multiword title (ingredient) by taking average pooling 4 Our corpus and code are available https://github.com/ZhihongShao/Planning-basedHierarchical-Variational-Model. at of the embeddings of its constituent words. Embedding dimensions for title word and ingredient word are 100 and 200 respectively. The input encoder, the plan decoder, and the plan encoder all have a hidden size of 200. 5.4 Automatic Evaluation Metrics We adopted the following automatic metrics. (1) Corpus BLEU: BLEU-4 (Papineni et al., 2002). (2) Coverage: This metric measures the average proportion of input items that are covered by a generated text. We recognized attribute values (ingredients) with string match heuristics. For the advertising text generation task, synonyms were also considered. (3) Length: The average length of the generated texts. (4) Distinct-4: Distinctn (Li et al., 2016) is a common metric for diversity which measures the ratio of distinct n-grams in generated tokens. We adopted distinct-4. (5) Repetition-4: This metric measures redundancy with the percentage of generated texts that repeat at least one 4-gr"
D19-1321,N18-1162,0,0.0214811,"ully et al. (2019) planned by reordering input data. Most recently, Moryossef et al. (2019) proposed to select plans from all possible ones, which is infeasible for large inputs. As for diverse text generation, existing methods can be divided into three categories: enriching conditions (Xing et al., 2017), post-processing with beam search and rerank (Li et al., 2016), and designing effective models (Xu et al., 2018). Some text-to-text generation models (Serban et al., 2017; Zhao et al., 2017) inject high-level variations with latent variables. Variational Hierarchical Conversation RNN (VHCR) (Park et al., 2018) is a most similar model to ours, which also adopts a hierarchical latent structure. Our method differs from VHCR in two aspects: (1) VHCR has no planning mechanism, and the global latent variable is mainly designed to address the KL collapse problem, while our global latent variable captures the diversity of reasonable planning; (2) VHCR injects distinct local latent variables without direct dependencies, while our method explicitly models the dependencies among local latent variables to better capture inter-sentence connections. Shen et al. (2019) proposed ml-VAE-D with multi-level latent va"
D19-1321,D17-1235,0,0.016175,"inter-sentence coherence. et al., 2018; Sha et al., 2018; Nema et al., 2018) using well-designed data encoder and attention mechanisms. However, as demonstrated in Wiseman et al. (2017) (a game report generation task), existing neural methods are still problematic for long text generation: they often generate incoherent texts. In fact, these methods also lack the ability to model diversity of expressions. As for long text generation, recent studies tackle the incoherence problem from different perspectives. To keep the decoder aware of the crucial information in the already generated prefix, Shao et al. (2017) appended the generated prefix to the encoder, and Guo et al. (2018) leaked the extracted features of the generated prefix from the discriminator to the generator in a Generative Adversarial Nets (Goodfellow et al., 2014). To model dependencies among sentences, Li et al. (2015) utilized a hierarchical recurrent neural network (RNN) decoder. Konstas and Lapata (2013) proposed to plan content organization with grammar rules while Puduppully et al. (2019) planned by reordering input data. Most recently, Moryossef et al. (2019) proposed to select plans from all possible ones, which is infeasible f"
D19-1321,P19-1200,0,0.0801873,"Missing"
D19-1321,P04-1011,0,0.0956437,"ith attractive wording. The goal of writing such texts is to advertise a product and attract users to buy it. • We propose a novel planning mechanism which segments the input data into a sequence of groups, thereby decomposing long text generation into dependent sentence generation sub-tasks. Thus, input data can be better modeled and inter-sentence coherence can be better captured. To capture expression diversity, we devise a hierarchical latent structure which injects variations at both high-level planning and low-level realization. 2 Related Work Traditional methods (Reiter and Dale, 1997; Stent et al., 2004) for data-to-text generation consist of three components: content planning, sentence planning, and surface realization. Content planning and sentence planning are responsible for what to say and how to say respectively; they are typically based on hand-crafted (Kukich, 1983; Dalianis and Hovy, 1993; Hovy, 1993) or automatically-learnt rules (Duboue and McKeown, 2003). Surface realization generates natural language by carrying out the plan, which is template-based (McRoy et al., 2003; van Deemter et al., 2005) or grammar-based (Bateman, 1997; Espinosa et al., 2008). As these models are shallow"
D19-1321,D17-1239,0,0.071664,"Missing"
D19-1321,D18-1428,0,0.0298353,"ies among sentences, Li et al. (2015) utilized a hierarchical recurrent neural network (RNN) decoder. Konstas and Lapata (2013) proposed to plan content organization with grammar rules while Puduppully et al. (2019) planned by reordering input data. Most recently, Moryossef et al. (2019) proposed to select plans from all possible ones, which is infeasible for large inputs. As for diverse text generation, existing methods can be divided into three categories: enriching conditions (Xing et al., 2017), post-processing with beam search and rerank (Li et al., 2016), and designing effective models (Xu et al., 2018). Some text-to-text generation models (Serban et al., 2017; Zhao et al., 2017) inject high-level variations with latent variables. Variational Hierarchical Conversation RNN (VHCR) (Park et al., 2018) is a most similar model to ours, which also adopts a hierarchical latent structure. Our method differs from VHCR in two aspects: (1) VHCR has no planning mechanism, and the global latent variable is mainly designed to address the KL collapse problem, while our global latent variable captures the diversity of reasonable planning; (2) VHCR injects distinct local latent variables without direct depen"
D19-1321,P17-1061,0,0.0524088,"Missing"
D19-1321,P11-1015,0,\N,Missing
D19-1321,P09-1011,0,\N,Missing
D19-1321,P17-1017,0,\N,Missing
D19-1436,P18-1060,0,0.0137772,"the ability to generate more diverse sentences. We also provide standard deviation of each metric in Table 4, reflecting the stability of each model’s performance. Our model ARAML nearly achieves the smallest standard deviation in all the metrics, indicating that our framework outperforms policy gradient in the stability of adversarial training. 80 60 40 4.5 Dialogue Generation on WeiboDial 20 0 50 100 150 200 250 Epoch Dialogue evaluation is an open problem and existing works have found that automatic metrics have low correlation to human evaluation (Liu et al., 2016; Novikova et al., 2017; Chaganty et al., 2018). Thus, we resorted to manual evaluation to assess the generation quality on WeiboDial. We randomly sampled 200 posts from the test set and collected the generated results from all the models. For each pair of responses (one from ARAML and the other from a baseline, given the same input post), five annotators were hired to label which response is better (i.e. win, lose or tie) in terms of grammaticality (whether a response itself is gramFigure 2: PPL-F/PPL-R curves of ARAML, SeqGAN, LeakGAN, MaliGAN and IRL in the training process. The shade area indicates the standard deviation at each data p"
D19-1436,W14-4012,0,0.0815704,"Missing"
D19-1436,P82-1020,0,0.82805,"Missing"
D19-1436,P18-1139,1,0.835699,"ML training into adversarial training paradigm. Experimental results on three text generation tasks show the effectiveness of our method. 2 Related Work Recently, text generation has been widely studied with neural models trained with maximum likelihood estimation (Graves, 2013). However, MLE tends to generate universal text (Li et al., 2016). Various methods have been proposed to enhance the generation quality by refining the objective function (Li et al., 2016; Mou et al., 2016) or modifying the generation distribution with external information like topic (Xing et al., 2017), sentence type (Ke et al., 2018), emotion (Zhou et al., 2018a) and knowledge (Zhou et al., 2018b). As mentioned above, MLE suffers from the exposure bias problem (Bengio et al., 2015; Ranzato et al., 2016). Thus, reinforcement learning has been introduced to text generation tasks such as policy gradient (Ranzato et al., 2016) and actorcritic (Bahdanau et al., 2017). (Norouzi et al., 2016) proposed an efficient and stable approach called Reward Augmented Maximum Likelihood (RAML), which connects the log-likelihood and expected rewards to incorporate MLE training objective into RL framework. Since some text generation tasks ha"
D19-1436,N16-1014,0,0.0372014,"butions are mainly as follows: • We analyze the fundamental issue of current GANs for text generation from the perspectives of training instability. • We propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML), which incorporates stable RAML training into adversarial training paradigm. Experimental results on three text generation tasks show the effectiveness of our method. 2 Related Work Recently, text generation has been widely studied with neural models trained with maximum likelihood estimation (Graves, 2013). However, MLE tends to generate universal text (Li et al., 2016). Various methods have been proposed to enhance the generation quality by refining the objective function (Li et al., 2016; Mou et al., 2016) or modifying the generation distribution with external information like topic (Xing et al., 2017), sentence type (Ke et al., 2018), emotion (Zhou et al., 2018a) and knowledge (Zhou et al., 2018b). As mentioned above, MLE suffers from the exposure bias problem (Bengio et al., 2015; Ranzato et al., 2016). Thus, reinforcement learning has been introduced to text generation tasks such as policy gradient (Ranzato et al., 2016) and actorcritic (Bahdanau et al."
D19-1436,D17-1230,0,0.15585,"sues of training GANs on discrete data are more severe than exposure bias (Semeniuta1 et al., 2018; Caccia et al., 2018). One of the fundamental issues when generating discrete text samples with GANs is training instability. Updating the generator with policy gradient always leads to an unstable training process because it’s difficult for the generator to derive positive and stable reward signals from the discriminator even with careful pretraining (Che et al., 2017). As a result, the generator gets lost due to the high variance of reward signals and the training process may finally collapse (Li et al., 2017). In this paper, we propose a novel adversarial training framework called Adversarial Reward Augmented Maximum Likelihood (ARAML) to deal with the instability issue of training GANs for text generation. At each iteration of adversarial training, we first train the discriminator to assign higher rewards to real data than to generated samples. Then, inspired by reward augmented maximum likelihood (RAML) (Norouzi et al., 2016), the generator is updated on the samples acquired from a stationary distribution with maximum likelihood estimation (MLE), weighted by the discriminator’s rewards. This sta"
D19-1436,D16-1230,0,0.0162778,"elp of the MLE training objective and has the ability to generate more diverse sentences. We also provide standard deviation of each metric in Table 4, reflecting the stability of each model’s performance. Our model ARAML nearly achieves the smallest standard deviation in all the metrics, indicating that our framework outperforms policy gradient in the stability of adversarial training. 80 60 40 4.5 Dialogue Generation on WeiboDial 20 0 50 100 150 200 250 Epoch Dialogue evaluation is an open problem and existing works have found that automatic metrics have low correlation to human evaluation (Liu et al., 2016; Novikova et al., 2017; Chaganty et al., 2018). Thus, we resorted to manual evaluation to assess the generation quality on WeiboDial. We randomly sampled 200 posts from the test set and collected the generated results from all the models. For each pair of responses (one from ARAML and the other from a baseline, given the same input post), five annotators were hired to label which response is better (i.e. win, lose or tie) in terms of grammaticality (whether a response itself is gramFigure 2: PPL-F/PPL-R curves of ARAML, SeqGAN, LeakGAN, MaliGAN and IRL in the training process. The shade area"
D19-1436,C12-1173,0,0.0538465,"Missing"
D19-1436,C16-1316,0,0.0159788,"ability. • We propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML), which incorporates stable RAML training into adversarial training paradigm. Experimental results on three text generation tasks show the effectiveness of our method. 2 Related Work Recently, text generation has been widely studied with neural models trained with maximum likelihood estimation (Graves, 2013). However, MLE tends to generate universal text (Li et al., 2016). Various methods have been proposed to enhance the generation quality by refining the objective function (Li et al., 2016; Mou et al., 2016) or modifying the generation distribution with external information like topic (Xing et al., 2017), sentence type (Ke et al., 2018), emotion (Zhou et al., 2018a) and knowledge (Zhou et al., 2018b). As mentioned above, MLE suffers from the exposure bias problem (Bengio et al., 2015; Ranzato et al., 2016). Thus, reinforcement learning has been introduced to text generation tasks such as policy gradient (Ranzato et al., 2016) and actorcritic (Bahdanau et al., 2017). (Norouzi et al., 2016) proposed an efficient and stable approach called Reward Augmented Maximum Likelihood (RAML), which connects t"
D19-1436,D17-1238,0,0.0155499,"ining objective and has the ability to generate more diverse sentences. We also provide standard deviation of each metric in Table 4, reflecting the stability of each model’s performance. Our model ARAML nearly achieves the smallest standard deviation in all the metrics, indicating that our framework outperforms policy gradient in the stability of adversarial training. 80 60 40 4.5 Dialogue Generation on WeiboDial 20 0 50 100 150 200 250 Epoch Dialogue evaluation is an open problem and existing works have found that automatic metrics have low correlation to human evaluation (Liu et al., 2016; Novikova et al., 2017; Chaganty et al., 2018). Thus, we resorted to manual evaluation to assess the generation quality on WeiboDial. We randomly sampled 200 posts from the test set and collected the generated results from all the models. For each pair of responses (one from ARAML and the other from a baseline, given the same input post), five annotators were hired to label which response is better (i.e. win, lose or tie) in terms of grammaticality (whether a response itself is gramFigure 2: PPL-F/PPL-R curves of ARAML, SeqGAN, LeakGAN, MaliGAN and IRL in the training process. The shade area indicates the standard"
D19-1436,D18-1428,0,0.21573,"Although widely used, MLE suffers from the exposure bias problem (Bengio et al., 2015; Ranzato et al., 2016): during test, the model sequentially predicts the next word conditioned on its previous generated words while during training conditioned on ground-truth words. To tackle this ∗ † Equal contribution Corresponding author: Minlie Huang problem, generative adversarial networks (GAN) with reinforcement learning (RL) training approaches have been introduced to text generation tasks (Yu et al., 2017; Che et al., 2017; Lin et al., 2017; Fedus et al., 2018; Guo et al., 2018; Shi et al., 2018; Xu et al., 2018), where the discriminator is trained to distinguish real and generated text samples to provide reward signals for the generator, and the generator is optimized via policy gradient (Yu et al., 2017). However, recent studies have shown that potential issues of training GANs on discrete data are more severe than exposure bias (Semeniuta1 et al., 2018; Caccia et al., 2018). One of the fundamental issues when generating discrete text samples with GANs is training instability. Updating the generator with policy gradient always leads to an unstable training process because it’s difficult for the gene"
I11-1042,N10-1020,0,0.0237827,"2010) proposed a real-time earthquake detection framework by treating each Twitter user as a sensor. Petrovic et al. (2010) addressed the problem of detecting new events from a stream of Twitter posts and adopted a method based on localitysensitive hashing to make event detection feasible on web-scale corpora. To facilitate fine-grained information extraction on news tweets, Liu et al. (2010) presented a work on semantic role labeling for such texts. Corvey et al. (2010) proposed a work for entity detection and entity class annotation on tweets that were posted during times of mass emergency. Ritter et al. (2010) proposed a topic model to detect conversational threads among tweets. Since a large amount of tweets are posted every day, ranking strategies is extremely important for users to find information quickly. Current ranking strategy on Twitter considers relevance to an input query, information recency (the latest tweets are preferred), and popularity (the retweet times by other users). The recency information, which is useful for real-time web search, has also been explored by Dong et al. (2010) who used fresh URLs present in tweets to rank documents in response to recency sensitive queries. Duan"
I11-1042,N10-1021,0,0.0848092,"Missing"
I11-1042,C10-1034,0,0.253764,"010) proposed a topic model to detect conversational threads among tweets. Since a large amount of tweets are posted every day, ranking strategies is extremely important for users to find information quickly. Current ranking strategy on Twitter considers relevance to an input query, information recency (the latest tweets are preferred), and popularity (the retweet times by other users). The recency information, which is useful for real-time web search, has also been explored by Dong et al. (2010) who used fresh URLs present in tweets to rank documents in response to recency sensitive queries. Duan et al. (2010) proposed a ranking SVM approach to rank tweets with various features. 3 Problem Formulation and Methodology Given a set of queries Q = {q1 , q2 , · · · , qn }, for each query qk , we have a set of short documents Dk = {d1k , d2k , · · · } which are retrieved by our builtin search engine. The document set Dk is partially labeled, i.e., a small portion of documents in Dk 1 2 were annotated with a category set C={1, 2, 3, 4, 5} where 5 means the highest quality and 1 lowest. Therefore, we denote Dk = DkU ∪ DkL , where DkU indicates the unlabeled documents, and DkL the labeled documents. Each doc"
I11-1042,W06-1650,0,0.0386186,"ed several factors on assessing review helpfulness including reviewer characteristics, reviewer history, and review readability and subjectivity. Lu et al. (2010) proposed a linear regression model with various social contexts for review quality prediction. The authors employed author consistency, trust consistency and co-citation consistency hypothesis to predict more consistently. Liu et al. (2008) studied three factors, i.e., reviewer expertise, writing style, and timeliness, and proposed a non-linear regression model with radial basis functions to predict the helpfulness of movie reviews. Kim et al. (2006) used SVM regression with various features to predict review helpfulness. Finding high-quality content and reliable users is also very important for question answering. Agichtein et al. (2008) proposed a classification framework of estimating answer quality. They studied content-based features (e.g. the answer length) and usage-based features derived from question answering communities. Jeon et al. (2006) used nontextual features extracted from the Naver Q&A service to predict the quality of answers. Bian et al. (2009) proposed a mutual reinforcement learning framework to simultaneously predic"
I11-1042,W10-0513,0,0.359402,"lity prediction has been a very important problem in many tasks. In review mining, quality prediction has two lines of research: one line is to detect spam reviews (Jindal and Liu, 2008) or spam reviewers (Lim et al., 2010), which is helpful to exclude misleading information; the other is to identify high-quality reviews, on which we will focus in this survey. Various factors and contexts have been studied to produce reliable and consistent quality prediction. Danescu-Niculescu-Mizil et al. (2009) stud374 ied several factors on helpfulness voting of Amazon product reviews. Ghose and Ipeirotis (2010) studied several factors on assessing review helpfulness including reviewer characteristics, reviewer history, and review readability and subjectivity. Lu et al. (2010) proposed a linear regression model with various social contexts for review quality prediction. The authors employed author consistency, trust consistency and co-citation consistency hypothesis to predict more consistently. Liu et al. (2008) studied three factors, i.e., reviewer expertise, writing style, and timeliness, and proposed a non-linear regression model with radial basis functions to predict the helpfulness of movie rev"
I11-1042,C10-1079,0,\N,Missing
N10-1072,P98-1012,0,0.133866,"next section we will briefly review the related work. We present our framework for entity linking in section 3. We then describe in section 4 learning to rank methods and features for entity linking. A top1 candidate validation module will be explained in section 5. Experiment results will be discussed in section 6. Finally, we conclude the paper and discusses the future work in section 7. 2 Infoboxes are tables with semi-structured information in some pages of Wikipedia 484 2 Related Work There are a number of studies on named entity disambiguation, which is quite relevant to entity linking. Bagga and Baldwin (1998) used a Bag of Words (BOW) model to resolve ambiguities among people. Mann and Yarowsky (2003) improved the performance of personal names disambiguation by adding biographic features. Fleischman (2004) trained a Maximum Entropy model with Web Features, Overlap Features, and some other features to judge whether two names refer to the same individual. Pedersen (2005) developed features to represent the context of an ambiguous name with the statistically significant bigrams. These methods determined to which entity a specific name refer by measuring the similarity between the context of the speci"
N10-1072,W03-0405,0,0.0202154,"ing in section 3. We then describe in section 4 learning to rank methods and features for entity linking. A top1 candidate validation module will be explained in section 5. Experiment results will be discussed in section 6. Finally, we conclude the paper and discusses the future work in section 7. 2 Infoboxes are tables with semi-structured information in some pages of Wikipedia 484 2 Related Work There are a number of studies on named entity disambiguation, which is quite relevant to entity linking. Bagga and Baldwin (1998) used a Bag of Words (BOW) model to resolve ambiguities among people. Mann and Yarowsky (2003) improved the performance of personal names disambiguation by adding biographic features. Fleischman (2004) trained a Maximum Entropy model with Web Features, Overlap Features, and some other features to judge whether two names refer to the same individual. Pedersen (2005) developed features to represent the context of an ambiguous name with the statistically significant bigrams. These methods determined to which entity a specific name refer by measuring the similarity between the context of the specific name and the context of the entities. They measured similarity with a BOW model. Since the"
N10-1072,W04-0701,0,0.053274,"Missing"
N10-1072,D07-1074,0,0.67023,"ekkerman and McCallum (2005) disambiguated web appearances of people based on the link structure of Web pages. These methods tried to add background knowledge via social networks. Social networks can capture the relatedness between terms, so the problem of a BOW model can be solved to some extent. Xianpei and Jun (2009) proposed to use Wikipedia as the background knowledge for disambiguation. By leveraging Wikipedia’s semantic knowledge like social relatedness between named entities and associative relatedness between concepts, they can measure the similarity between entities more accurately. Cucerzan (2007) and Bunescu (2006) used Wikipedia’s category information in the disambiguation process. Using different background knowledge, researcher may find different efficient features for disambiguation. Hence researchers have proposed so many efficient features for disambiguation. It is important to integrate these features to improve the system performance. Some researchers combine features by manual rules or weights. However, it is not convenient to directly use these rules or weights in another data set. Some researchers also try to use machine learning methods to combine the features. Milne and W"
N10-1072,E06-1002,0,0.421818,"Missing"
N10-1072,P05-1045,0,0.00689089,"the queries which are expansions of Q’s nameString. ∙ ExactEqualSurface. The feature value is 1 if there is a string s in set C’s titleExpand same as the Q’s nameString, or the Candidate C is extracted from the disambiguation page. In other case, the feature value is set to 0. ∙ C’s title represents the title of corresponding Wikipedia article of C. C’s titleExpand represents the union set of the redirect set of C and the anchor text set of C. C’s article represents the Wikipedia article of C. ∙ C’s nameEntitySet represents the set of all named entities in C’s article labeled by Stanford NER (Finkel et al., 2005). Q’s nameEntitySet represents the set of all named entities in Q’s sourceText. ∙ C’s countrySet represents the set of all countries in C’s article, and we detect the countries from text via a manual edited country list. Q’s countrySet represents the set of all countries in Q’s sourceText. C’s countrySetInTitle represents the set of countries exist in one of the string s from C’s titleExpand. ∙ C’s citySetInTitle represents the set of all cities exist in one of the string s from C’s titleExpand, and we detect the cities from text via a manual edited list of famous cities. Q’s citySet represent"
N10-1072,C98-1012,0,\N,Missing
P09-1083,W05-0620,0,0.0136438,"j |vi ∈ Vs , oj ∈ Vo } corresponds to the Auth(n+1) (vi ) = sen X (n) γ· twij · topic score(j) · Hubtopic (tj ) (2) twij &gt;0 + (1 − γ) · (n) X owij · Hubopinion (oj ) owij &gt;0 (n+1) Hubtopic (ti ) = X twki · Auth(n) sen (vi ) (3) owki · Auth(n) sen (vi ) (4) twki &gt;0 (n+1) Hubopinion (oi ) = X owki &gt;0 740 types of features, including a set of pattern features, and then design a classifier to identify sentiment polarity for each question (similar as (Yu and Hatzivassiloglou, 2003)). 2).Topic Set Expansion: The opinion question asks opinions about a particular target. Semantic role labeling based (Carreras and Marquez, 2005) and rule based techniques can be employed to extract this target as topic word. We also expand the topic word with several external knowledge bases: Since all the entity synonyms are redirected into the same page in Wikipedia (Rodrigo et al., 2007), we collect these redirection synonym words to expand topic set. We also collect some related lists as topic words. For example, given question “What reasons did people give for liking Ed Norton’s movies?”, we collect all the Norton’s movies from IMDB as this question’s topic words. Document Retrieval: The PRISE search engine, supported by NIST (Da"
P09-1083,P06-1136,0,0.0610266,"Missing"
P09-1083,W04-3247,0,0.049984,"r, most approaches simply combined these two scores by a weighted sum, or removed candidates that didn’t match the polarity of questions, in order to extract the opinion answers. Algorithms based on Markov Random Walk have been proposed to solve different kinds of ranking problems, most of which are inspired by the PageRank algorithm (Page et al., 1998) and the HITS algorithm (Kleinberg, 1999). These two algorithms were initially applied to the task of Web search and some of their variants have been proved successful in a number of applications, including fact-based QA and text summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Otterbacher et al., 2005; Wan and Yang, 2008). Generally, such models would first construct a directed or undirected graph to represent the relationship between sentences and then certain graph-based ranking methods are applied on the graph to compute the ranking score for each sentence. Sentences with high scores are then added into the answer set or the summary. However, to the best of our knowledge, all previous Markov Random Walk-based sentence ranking models only make use of topic relevance information, i.e. whether this sentence is relevant to the fact we are"
P09-1083,esuli-sebastiani-2006-sentiwordnet,0,0.00569774,"on of positive/negative Chinese words Words with a positive or negative score above 0.6 Words appeared in both 1 and 2 Words appeared in 1 or 2 All words appeared in 1 or 2 without distinguishing pos or neg Table 1: Sentiment lexicon description For lexicon-based opinion analysis, the selection of opinion thesaurus plays an important role in the final performance. HowNet2 is a knowledge database of the Chinese language, and provides an online word list with tags of positive and negative polarity. We use the English translation of those sentiment words as the sentimental lexicon. SentiWordNet (Esuli and Sebastiani, 2006) is another popular lexical resource for opinion mining. Table 1 shows the detail information of our used sentiment lexicons. In our models, the positive opinion words are used only for positive questions, and negative opinion words just for negative questions. We initially set parameter λ in Opinion PageRank as 0 as (Liu and Ma, 2005), and other parameters simply as 0.5, including µ in Opinion PageRank, γ in Opinion HITS, and α in baseline. The experiment results are shown in Figure 4. We can make three conclusions from Figure 4: 1. Opinion PageRank and Opinion HITS are both effective. The be"
P09-1083,O07-1013,0,0.108741,"ludes this paper and provides possible directions for future work. 2 Related Work Few previous studies have been done on opinion QA. To our best knowledge, (Stoyanov et al., 2005) first created an opinion QA corpus OpQA. They find that opinion QA is a more challenging task than factual question answering, and they point out that traditional fact-based QA approaches may have difficulty on opinion QA tasks if unchanged. (Somasundaran et al., 2007) argues that making finer grained distinction of subjective types (sentiment and arguing) further improves the QA system. For non-English opinion QA, (Ku et al., 2007) creates a Chinese opinion QA corpus. They classify opinion questions into six types and construct three components to retrieve opinion answers. Relevant answers are further processed by focus detection, opinion scope identification and polarity detection. Some works on opinion mining are motivated by opinion question answering. (Yu and Hatzivassiloglou, 2003) discusses a necessary component for an opinion question answering system: separating opinions from fact at both the document and sentence level. (Soo-Min and Hovy, 2005) addresses another important component of opinion question answering"
P09-1083,H05-1115,0,0.156503,"Missing"
P09-1083,H05-1116,0,0.271644,"ihuang,zxy-dcs}@tsinghua.edu.cn Abstract lies?”(Stoyanov et al., 2005) and “Why do people like Subway Sandwiches?” from TAC 2008 (Dang, 2008). Systems designed to deal with such questions are called opinion QA systems. Researchers (Stoyanov et al., 2005) have found that opinion questions have very different characteristics when compared with fact-based questions: opinion questions are often much longer, more likely to represent partial answers rather than complete answers and vary much more widely. These features make opinion QA a harder problem to tackle than fact-based QA. Also as shown in (Stoyanov et al., 2005), directly applying previous systems designed for fact-based QA onto opinion QA tasks would not achieve good performances. Similar to other complex QA tasks (Chen et al., 2006; Cui et al., 2007), the problem of opinion QA can be viewed as a sentence ranking problem. The Opinion QA task needs to consider not only the topic relevance of a sentence (to identify whether this sentence matches the topic of the question) but also the sentiment of a sentence (to identify the opinion polarity of a sentence). Current solutions to opinion QA tasks are generally in ad hoc styles: the topic score and the o"
P09-1083,W03-1017,0,0.27067,"based QA approaches may have difficulty on opinion QA tasks if unchanged. (Somasundaran et al., 2007) argues that making finer grained distinction of subjective types (sentiment and arguing) further improves the QA system. For non-English opinion QA, (Ku et al., 2007) creates a Chinese opinion QA corpus. They classify opinion questions into six types and construct three components to retrieve opinion answers. Relevant answers are further processed by focus detection, opinion scope identification and polarity detection. Some works on opinion mining are motivated by opinion question answering. (Yu and Hatzivassiloglou, 2003) discusses a necessary component for an opinion question answering system: separating opinions from fact at both the document and sentence level. (Soo-Min and Hovy, 2005) addresses another important component of opinion question answering: finding opinion holders. 3 Our Models for Opinion Sentence Ranking In this section, we formulate the opinion question answering problem as a topic and sentiment based sentence ranking task. In order to naturally integrate the topic and opinion information into the graph based sentence ranking framework, we propose two random walk based models for solving the"
P09-1083,W04-3252,0,\N,Missing
P10-1078,P09-4001,0,0.051703,"mental aspects: it took in consideration the peculiarities of the data in input by exploiting the nature of UGC and available metadata; additionally, along with relevance, we addressed challenges that are specific to Question Answering, such as Coverage and Novelty. For an investigation of Coverage in the context of Search Engines, refer to Swaminathan et al. (2009). At the core of our work laid information trustfulness, summarization techniques and alternative concept representation. A general approach to the broad problem of evaluating information credibility on the Internet is presented by Akamine et al. (2009) with a system that makes use of semantic-aware Natural Language Preprocessing techniques. With analogous goals, but a focus on UGC, are the papers of Stvilia et al. (2005), Mcguinness et al. (2006), Hu et al. (2007) and ness of the content and the good level of readability make it a successful instance of metadata-aware summarization of information in cQA systems. Less satisfying examples include summaries to questions that require a specific order of sentences or a compromise between strongly discordant opinions; in those cases, the summarized answer might lack logical consistency. the total"
P10-1078,C08-1063,0,0.214101,"Aware Measures for Answer Summarization in Community Question Answering Mattia Tomasoni ∗ Minlie Huang Dept. of Information Technology Dept. Computer Science and Technology Uppsala University, Uppsala, Sweden Tsinghua University, Beijing 100084, China mattia.tomasoni.8371@student.uu.se aihuang@tsinghua.edu.cn Abstract 2006; Wang et al., 2009b; Suryanto et al., 2009). Interestingly, a great amount of information is embedded in the metadata generated as a byproduct of users’ action and interaction on Social Media. Much valuable information is contained in answers other than the chosen best one (Liu et al., 2008). Our work aims to show that such information can be successfully extracted and made available by exploiting metadata to distill cQA content. To this end, we casted the problem to an instance of the query-biased multi-document summarization task, where the question was seen as a query and the available answers as documents to be summarized. We mapped each characteristic that an ideal answer should present to a measurable property that we wished the final summary could exhibit: This paper presents a framework for automatically processing information coming from community Question Answering (cQA"
P10-1078,C08-1124,0,0.0321788,"n 2.1. Our approach merged trustfulness estimation and summarization techniques: we adapted the automatic concept-level model presented by Gillick and Favre (2009) to our needs; related work in multi-document summarization has been carried out by Wang et al. (2008) and McDonald (2007). A relevant selection of approaches that instead make use of ML techniques for query-biased summarization is the following: Wang et al. (2007), Metzler and Kanungo (2008) and Li et al. (2009). An aspect worth investigating is the use of partially labeled or totally unlabeled data for summarization in the work of Wong et al. (2008) and Amini and Gallinari (2002). Our final contribution was to explore the use of Basic Elements document representation instead of the widely used n-gram paradigm: in this regard, we suggest the paper by Zhou et al. (2006). 6 Acknowledgments This work was partly supported by the Chinese Natural Science Foundation under grant No. 60803075, and was carried out with the aid of a grant from the International Development Research Center, Ottawa, Canada. We would like to thank Prof. Xiaoyan Zhu, Mr. Yang Tang and Mr. Guillermo Rodriguez for the valuable discussions and comments and for their suppor"
P10-1078,zhou-etal-2006-summarizing,0,0.142066,"sed; training a classifier on all of them would no doubt increase the performances. 761 2.2 Given two concepts c and k: ( c≡k c ./ k E c ∩ E k 6= ∅ Bag-of-BEs and semantic overlap The properties that remain to be discussed, namely Coverage, Relevance and Novelty, are measures of semantic overlap between concepts; a concept is the smallest unit of meaning in a portion of written text. To represent sentences and answers we adopted an alternative approach to classical ngrams that could be defined bag-of-BEs. a BE is “a head|modifier|relation triple representation of a document developed at ISI” (Zhou et al., 2006). BEs are a strong theoretical instrument to tackle the ambiguity inherent in natural language that find successful practical applications in realworld query-based summarization systems. Different from n-grams, they are variant in length and depend on parsing techniques, named entity detection, part-of-speech tagging and resolution of syntactic forms such as hyponyms, pronouns, pertainyms, abbreviation and synonyms. To each BE is associated a class of semantically equivalent BEs as result of what is called a transformation of the original BE; the mentioned class uniquely defines the concept. W"
P10-1078,W09-1802,0,\N,Missing
P12-2065,N10-1122,0,0.443399,"Missing"
P12-2065,D11-1105,0,0.0639504,"eployed the framework of latent structural SVMs(Yu and Joachims., 2009) for multilevel sentiment classification. As for aspect level rating, ranking, or summarization, Benjamin(2007) em333 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics ployed the good grief algorithm for multiple aspect ranking and the extensions of the generative topic models were also widely studied, such as (Titov and McDonald., 2008; Brody and Elhadad., 2010; Wang et al., 2010; Li et al., 2011; Lu et al., 2011; Jo and Oh., 2011; Lin and He, 2009). In this paper, we build a general structural learning model for joint sentiment classification and aspect analysis using a latent discriminate method. Our model is able to predict the sentiment polarity of document as well as to identify aspect-specific sentences and predict the polarity of such sentences. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 2 ing formulation of the discriminate function w  T Ψ(x, y, s) = ) 1 ∑( T j T j"
P12-2065,P07-1055,0,0.0420431,"Missing"
P12-2065,W02-1011,0,0.013418,"Missing"
P12-2065,N07-1038,0,0.0372577,"Missing"
P12-2065,P08-1036,0,0.227541,"Missing"
P12-2065,D10-1102,0,0.119918,"ing the vector of feature weight for aspect a to calculate the polarity and subjectivity score. T w  pol Model  T w  pol a0   =  ...  , T w  pol a T w  subj k k 2.1 Document Structure We assume that the polarity of document is closely related to some aspects for the reason that people are writing reviews to praise or criticize certain aspects. Therefore, each informative sentence of the document characterizes one aspect, expressing aspect specific polarity or subjective features. Similar to previous work on aspect analysis (Wang et al., 2010) and multi-level sentiment classification (Yessenalina et al., 2010), we define the aspect as a collection of synonyms. For instance, the word set {“value”, “price”, “cost”, “worth”, “quality”} is a synonym set corresponding to the aspect “price”. For each document, an aspect is described by one or several sentences expressing aspect specific polarity or subjective information. Let document be denoted by x, and y ∈ {+1, −1} represents the positive or negative polarity of the document, s is the set of informative sentences, in which each sentence is attached with certain aspect ai ∈ A = {a1 , ..., ak }. Yessenalina (2010) chooses a sentence set that best explai"
P14-1050,P98-1010,0,0.147938,"Missing"
P14-1050,C10-1014,1,0.670234,"Missing"
P14-1050,P05-2003,0,0.213804,"Missing"
P14-1050,C02-1049,0,0.0497514,"Missing"
P14-1050,C04-1081,0,0.0372318,"Missing"
P14-1050,W03-1721,0,0.0714455,"Missing"
P14-1050,J11-1002,0,0.181446,"Missing"
P14-1050,W01-0513,0,0.0220238,"Missing"
P14-1050,W03-1719,0,0.0171807,"Missing"
P14-1050,J90-1003,0,0.446175,"Missing"
P14-1050,P12-1027,0,0.0401365,"Missing"
P14-1050,J93-1003,0,0.364587,"Missing"
P14-1050,W03-1730,0,0.0476908,"Missing"
P14-1050,I05-1047,0,0.66772,"Missing"
P14-1050,C98-1010,0,\N,Missing
P14-1050,W03-1726,0,\N,Missing
P15-1132,P13-1088,0,0.0722726,"e of the text is not yet fully employed in these models. Two ideas are motivated by the example shown in Figure 2: First, the composition function for the noun phrase ‘the movie/NP’ should be different from that for the adjective phrase ‘very interesting/ADJP’ since the two phrases are quite syntactically different. More specifically to sentiment analysis, a noun phrase is much less likely to express sentiment than an adjective phrase. There are two notable works mentioned here: (Socher et al., 2013a) presented to combine the parsing and composition processes, but the purpose is for parsing; (Hermann and Blunsom, 2013) designed composition functions according to the combinatory rules and categories in CCG grammar, however, only marginal improvement against Naive Bayes was reported. Our proposed model, tag guided RNN (TG-RNN), is designed to use the syntactic tag of the parent phrase to guide the composition process from the child nodes. As an example, we design a function for composing noun phrase (NP) and another one for adjective phrase (ADJP). This simple strategy obtains remarkable improvements against strong baselines. ing/JJ’ apparently contributes more to sentiment expression. To address this issue,"
P15-1132,P14-1062,0,0.00735143,"RNN (ours) TE-RNN (ours) TE-RNTN (ours) CNN DCNN Para-Vec for composition function which could model the meaning of longer phrases and capture negation rules. • AdaMC. Adaptive Multi-Compositionality for RNN and RNTN (Dong et al., 2014) trains more than one composition functions and adaptively learns the weight for each function. We compare our models with several methods which are evaluated on the Sentiment Treebank corpus. The baseline results are reported in (Dong et al., 2014) and (Kim, 2014). We make comparison to the following baselines: • DCNN/CNN. Dynamic Convolutional Neural Network (Kalchbrenner et al., 2014) and a simple Convolutional Neural Network (Kim, 2014), though these models are of different genres to RNN, we include them here for fair comparison since they are among top performing approaches on this task. • SVM. A SVM model with bag-of-words representation (Pang and Lee, 2008). • MNB/bi-MNB. Multinomial Naive Bayes and its bigram variant, adopted from (Wang and Manning, 2012). • Para-Vec. A word2vec variant (Le and Mikolov, 2014) that encodes paragraph information into word embedding learning. A simple but very competitive model. • RNN. The first Recursive Neural Network model proposed by"
P15-1132,D14-1181,0,0.0442612,"01 and a constant learning rate of 0.005. Method SVM MNB bi-MNB RNN MV-RNN RNTN AdaMC-RNN AdaMC-RNTN DRNN TG-RNN (ours) TE-RNN (ours) TE-RNTN (ours) CNN DCNN Para-Vec for composition function which could model the meaning of longer phrases and capture negation rules. • AdaMC. Adaptive Multi-Compositionality for RNN and RNTN (Dong et al., 2014) trains more than one composition functions and adaptively learns the weight for each function. We compare our models with several methods which are evaluated on the Sentiment Treebank corpus. The baseline results are reported in (Dong et al., 2014) and (Kim, 2014). We make comparison to the following baselines: • DCNN/CNN. Dynamic Convolutional Neural Network (Kalchbrenner et al., 2014) and a simple Convolutional Neural Network (Kim, 2014), though these models are of different genres to RNN, we include them here for fair comparison since they are among top performing approaches on this task. • SVM. A SVM model with bag-of-words representation (Pang and Lee, 2008). • MNB/bi-MNB. Multinomial Naive Bayes and its bigram variant, adopted from (Wang and Manning, 2012). • Para-Vec. A word2vec variant (Le and Mikolov, 2014) that encodes paragraph information i"
P15-1132,D13-1054,1,0.596359,"ie Huang, Yang Liu*, Xuan Zhu*, Xiaoyan Zhu State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology, Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, PR China *Samsung R&D Institute Beijing, China qianqiaodecember29@126.com , smxtianbo@gmail.com aihuang@tsinghua.edu.cn , yang.liu@samsung.com xuan.zhu@samsung.com , zxy-dcs@tsinghua.edu.cn Abstract semantic relationship classification (Socher et al., 2012), syntactic parsing (Socher et al., 2013a), sentiment analysis (Socher et al., 2013b), and machine translation (Li et al., 2013). The key component of RNN and its variants is the composition function: how to compose the vector representation for a longer text from the vector of its child words or phrases. For instance, as shown in Figure 2, the vector of ‘is very interesting’ can be composed from the vector of the left node ‘is’ and that of the right node ‘very interesting’. It’s worth to mention again, the composition process is conducted with the syntactic structure of the text, making RNN more interpretable than other deep learning models. Recursive neural network is one of the most successful deep learning models f"
P15-1132,P08-1028,0,0.0144891,"are considered. In order to distinguish antonyms with similar contexts, neural word vectors (Bengio et al., 2003) are proposed and can be learnt in an unsupervised manner. Word2vec (Mikolov et al., 2013a) introduces a simpler network structure making computation more efficiently and makes billions of samples feasible for training. Semantic composition deals with representing a longer text from its shorter components, which is extensively studied recently. In many previous works, a phrase vector is usually obtained by average (Landauer and Dumais, 1997), addition, element-wise multiplication (Mitchell and Lapata, 2008) or tensor product (Smolensky, 1990) of word vectors. In addition to using vector representations, matrices can also be used to represent phrases and the composition process can be done through matrix multiplication (Rudolph and Giesbrecht, 2010; Yessenalina and Cardie, 2011). Recursive neural models utilize the recursive structure (usually a parse tree) of a phrase or sentence for semantic composition. In Recursive Neural Network (Socher et al., 2011), the tree with the least reconstruction error is built and the vectors for interior nodes is composed by a global matrix. Matrix-Vector Recursi"
P15-1132,J07-2002,0,0.0165882,"Missing"
P15-1132,P10-1093,0,0.037432,"e making computation more efficiently and makes billions of samples feasible for training. Semantic composition deals with representing a longer text from its shorter components, which is extensively studied recently. In many previous works, a phrase vector is usually obtained by average (Landauer and Dumais, 1997), addition, element-wise multiplication (Mitchell and Lapata, 2008) or tensor product (Smolensky, 1990) of word vectors. In addition to using vector representations, matrices can also be used to represent phrases and the composition process can be done through matrix multiplication (Rudolph and Giesbrecht, 2010; Yessenalina and Cardie, 2011). Recursive neural models utilize the recursive structure (usually a parse tree) of a phrase or sentence for semantic composition. In Recursive Neural Network (Socher et al., 2011), the tree with the least reconstruction error is built and the vectors for interior nodes is composed by a global matrix. Matrix-Vector Recursive Neural Network (MV-RNN) (Socher et al., 2012) assigns matrices for every words so that it could capture the relationship between two children. In Recursive Neural Tensor Networks (RNTN) (Socher et al., 2013b), the composition process is perfo"
P15-1132,D11-1014,0,0.70505,"node ‘is very interesting’ is composed from the phrase node ‘very interesting’ and the word node ‘is’ . Introduction Among a variety of deep learning models for natural language processing, Recursive Neural Network (RNN) may be one of the most popular models. Thanks to the compositional nature of natural text, recursive neural network utilizes the recursive structure of the input such as a phrase or sentence, and has shown to be very effective for many natural language processing tasks including There are various attempts to design the composition function in RNN (or related models). In RNN (Socher et al., 2011), a global matrix is used to linearly combine the elements of vectors. In RNTN (Socher et al., 2013b), a global tensor is used to compute the tensor products of dimensions to favor the association between different el1365 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1365–1374, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics ements of the vectors. Sometimes it is challenging to find a single function to model the composition process. As a"
P15-1132,D12-1110,0,0.459358,"er et al., 2013b), a global tensor is used to compute the tensor products of dimensions to favor the association between different el1365 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1365–1374, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics ements of the vectors. Sometimes it is challenging to find a single function to model the composition process. As an alternative, multiple composition functions can be used. For instance, in MV-RNN (Socher et al., 2012), different matrices is designed for different words though the model is suffered from too much parameters. In AdaMC RNN/RNTN (Dong et al., 2014), a fixed number of composition functions is linearly combined and the weight for each function is adaptively learned. In spite of the success of RNN and its variants, the syntactic knowledge of the text is not yet fully employed in these models. Two ideas are motivated by the example shown in Figure 2: First, the composition function for the noun phrase ‘the movie/NP’ should be different from that for the adjective phrase ‘very interesting/ADJP’ sinc"
P15-1132,P13-1045,0,0.103785,"and Tag-specific Composition Functions in Recursive Neural Network Qiao Qian, Bo Tian, Minlie Huang, Yang Liu*, Xuan Zhu*, Xiaoyan Zhu State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology, Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, PR China *Samsung R&D Institute Beijing, China qianqiaodecember29@126.com , smxtianbo@gmail.com aihuang@tsinghua.edu.cn , yang.liu@samsung.com xuan.zhu@samsung.com , zxy-dcs@tsinghua.edu.cn Abstract semantic relationship classification (Socher et al., 2012), syntactic parsing (Socher et al., 2013a), sentiment analysis (Socher et al., 2013b), and machine translation (Li et al., 2013). The key component of RNN and its variants is the composition function: how to compose the vector representation for a longer text from the vector of its child words or phrases. For instance, as shown in Figure 2, the vector of ‘is very interesting’ can be composed from the vector of the left node ‘is’ and that of the right node ‘very interesting’. It’s worth to mention again, the composition process is conducted with the syntactic structure of the text, making RNN more interpretable than other deep learni"
P15-1132,D13-1170,0,0.432546,"and Tag-specific Composition Functions in Recursive Neural Network Qiao Qian, Bo Tian, Minlie Huang, Yang Liu*, Xuan Zhu*, Xiaoyan Zhu State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology, Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, PR China *Samsung R&D Institute Beijing, China qianqiaodecember29@126.com , smxtianbo@gmail.com aihuang@tsinghua.edu.cn , yang.liu@samsung.com xuan.zhu@samsung.com , zxy-dcs@tsinghua.edu.cn Abstract semantic relationship classification (Socher et al., 2012), syntactic parsing (Socher et al., 2013a), sentiment analysis (Socher et al., 2013b), and machine translation (Li et al., 2013). The key component of RNN and its variants is the composition function: how to compose the vector representation for a longer text from the vector of its child words or phrases. For instance, as shown in Figure 2, the vector of ‘is very interesting’ can be composed from the vector of the left node ‘is’ and that of the right node ‘very interesting’. It’s worth to mention again, the composition process is conducted with the syntactic structure of the text, making RNN more interpretable than other deep learni"
P15-1132,P12-2018,0,0.00831717,"valuated on the Sentiment Treebank corpus. The baseline results are reported in (Dong et al., 2014) and (Kim, 2014). We make comparison to the following baselines: • DCNN/CNN. Dynamic Convolutional Neural Network (Kalchbrenner et al., 2014) and a simple Convolutional Neural Network (Kim, 2014), though these models are of different genres to RNN, we include them here for fair comparison since they are among top performing approaches on this task. • SVM. A SVM model with bag-of-words representation (Pang and Lee, 2008). • MNB/bi-MNB. Multinomial Naive Bayes and its bigram variant, adopted from (Wang and Manning, 2012). • Para-Vec. A word2vec variant (Le and Mikolov, 2014) that encodes paragraph information into word embedding learning. A simple but very competitive model. • RNN. The first Recursive Neural Network model proposed by (Socher et al., 2011). • RNTN. Recursive Neural Tenser Network (Socher et al., 2013b) employs a tensor Pos./Neg. 79.4 81.8 83.1 82.4 82.9 85.4 87.1 88.5 87.7 86.3 86.8 87.7 88.1 86.8 87.8 Table 1: Classification accuray. Fine-grained stands for 5-class prediction and Pos./Neg. means binary prediction which ignores all neutral instances. All the accuracy is at the sentence level ("
P15-1132,D11-1016,0,0.00905229,"ciently and makes billions of samples feasible for training. Semantic composition deals with representing a longer text from its shorter components, which is extensively studied recently. In many previous works, a phrase vector is usually obtained by average (Landauer and Dumais, 1997), addition, element-wise multiplication (Mitchell and Lapata, 2008) or tensor product (Smolensky, 1990) of word vectors. In addition to using vector representations, matrices can also be used to represent phrases and the composition process can be done through matrix multiplication (Rudolph and Giesbrecht, 2010; Yessenalina and Cardie, 2011). Recursive neural models utilize the recursive structure (usually a parse tree) of a phrase or sentence for semantic composition. In Recursive Neural Network (Socher et al., 2011), the tree with the least reconstruction error is built and the vectors for interior nodes is composed by a global matrix. Matrix-Vector Recursive Neural Network (MV-RNN) (Socher et al., 2012) assigns matrices for every words so that it could capture the relationship between two children. In Recursive Neural Tensor Networks (RNTN) (Socher et al., 2013b), the composition process is performed on a parse tree in which e"
P16-1053,N06-1047,0,0.0422816,"een long phrases is relatively rare, and in addition, the QA pairs in the WikiQA dataset may be insufficient for training such a complex model with long convolution windows. 4.2 MAP 0.599 0.511 0.619 0.660 0.634 0.657 0.674 MRR 0.609 0.516 0.628 0.677 0.648 0.672 0.693 Table 2: Results on answer selection4 . Dialogue Act Analysis Dialogue acts (DA), such as Statement, Yes-NoQuestion, Agreement, indicate the sentence pragmatic role as well as the intention of the speakers (Williams, 2012). They are widely used in natural language generation (Wen et al., 2015), speech and meeting summarization (Murray et al., 2006; Murray et al., 2010), etc. In a dialogue, the DA of a sentence is highly relevant to the content of itself and the previous sentences. As a result, to model the interactions and long-range dependence between sentences in a dialogue is crucial for dialogue act analysis. Given a dialogue (n sentences) d = [s1 , s2 , ..., sn ], we first use a LSTM (LSTM1 ) to model all the sentences independently. The hidden states of sentence si obtained at this step are used to compute the interaction states of sentence si+1 , and SIN will generate a sentence vector vsi using another LSTM (LSTM2 ) for each se"
P16-1053,W10-4211,0,0.0275794,"elatively rare, and in addition, the QA pairs in the WikiQA dataset may be insufficient for training such a complex model with long convolution windows. 4.2 MAP 0.599 0.511 0.619 0.660 0.634 0.657 0.674 MRR 0.609 0.516 0.628 0.677 0.648 0.672 0.693 Table 2: Results on answer selection4 . Dialogue Act Analysis Dialogue acts (DA), such as Statement, Yes-NoQuestion, Agreement, indicate the sentence pragmatic role as well as the intention of the speakers (Williams, 2012). They are widely used in natural language generation (Wen et al., 2015), speech and meeting summarization (Murray et al., 2006; Murray et al., 2010), etc. In a dialogue, the DA of a sentence is highly relevant to the content of itself and the previous sentences. As a result, to model the interactions and long-range dependence between sentences in a dialogue is crucial for dialogue act analysis. Given a dialogue (n sentences) d = [s1 , s2 , ..., sn ], we first use a LSTM (LSTM1 ) to model all the sentences independently. The hidden states of sentence si obtained at this step are used to compute the interaction states of sentence si+1 , and SIN will generate a sentence vector vsi using another LSTM (LSTM2 ) for each sentence si in the dialo"
P16-1053,D14-1162,0,0.0795723,"SIN, which improves the ability to model interactions between phrases. • We obtain significant improvements on Answer Selection and Dialogue Act Analysis without any handcrafted features. The rest of the paper is structured as follows: We survey related work in Section 2, introduce our method in Section 3, present the experiments in Section 4, and summarize our work in Section 5. 2 Related Work Our work is mainly related to deep learning for sentence modeling and sentence pair modeling. For sentence modeling, we have to first represent each word as a real-valued vector (Mikolov et al., 2010; Pennington et al., 2014) , and then compose word vectors into a sentence vector. Several methods have been proposed for sentence modeling. Recurrent Neural Network (RNN) (Elman, 1990; Mikolov et al., 2010) introduces a hidden state to represent contexts, and repeatedly feed the Our work is also related to context modeling. Hermann et al. (2015) proposed a LSTM-based method for reading comprehension. Their model is able to effectively utilize the context (given by a document) to answer questions. Ghosh et al. (2016) proposed a Contextual LSTM (CLSTM) which introduces a topic vector into LSTM for context modeling. The"
P16-1053,P15-1132,1,0.839946,"ings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 558–567, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics hidden state and word embeddings to the network to update the context representation. RNN suffers from gradient vanishing and exploding problems which limit the length of reachable context. RNN with Long Short-Time Memory Network unit (LSTM) (Hochreiter and Schmidhuber, 1997; Gers, 2001) solves such problems by introducing a “memory cell” and “gates” into the network. Recursive Neural Network (Socher et al., 2013; Qian et al., 2015) and LSTM over tree structures (Zhu et al., 2015; Tai et al., 2015) are able to utilize some syntactic information for sentence modeling. Kim (2014) proposed a Convolutional Neural Network (CNN) for sentence classification which models a sentence in multiple granularities. state is regarded as the “influence” of xτ to xt , and is actually the “information flow” from xτ to xt mentioned above. By summing over all the “candidate interaction states”, we generate an “interaction state” for xt , which represents the influence of the whole sentence s2 to word xt . When feeding the “interaction state”"
P16-1053,D13-1170,0,0.00512086,"ce author 558 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 558–567, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics hidden state and word embeddings to the network to update the context representation. RNN suffers from gradient vanishing and exploding problems which limit the length of reachable context. RNN with Long Short-Time Memory Network unit (LSTM) (Hochreiter and Schmidhuber, 1997; Gers, 2001) solves such problems by introducing a “memory cell” and “gates” into the network. Recursive Neural Network (Socher et al., 2013; Qian et al., 2015) and LSTM over tree structures (Zhu et al., 2015; Tai et al., 2015) are able to utilize some syntactic information for sentence modeling. Kim (2014) proposed a Convolutional Neural Network (CNN) for sentence classification which models a sentence in multiple granularities. state is regarded as the “influence” of xτ to xt , and is actually the “information flow” from xτ to xt mentioned above. By summing over all the “candidate interaction states”, we generate an “interaction state” for xt , which represents the influence of the whole sentence s2 to word xt . When feeding the"
P16-1053,W13-3214,0,0.0959101,"1 , Minlie Huang1∗, Song Liu2 , Xuan Zhu2 , Xiaoyan Zhu1 1 State Key Lab. of Intelligent Technology and Systems 1 National Lab. for Information Science and Technology 1 Dept. of Computer Science and Technology, Tsinghua University, Beijing, China 2 Samsung R&D Institute, Beijing, China 1 liubiao2638@gmail.com, {aihuang, zxy-dcs}@tsinghua.edu.cn Abstract For sentence pair modeling, some methods first project the two sentences to fix-sized vectors separately without considering the interactions between them, and then fed the sentence vectors to other classifiers as features for a specific task (Kalchbrenner and Blunsom, 2013; Tai et al., 2015). Such methods suffer from being unable to encode context information during sentence embedding. A more reasonable way to capture sentence interactions is to introduce some mechanisms to utilize information from both sentences at the same time. Some methods attempt to introduce an attention matrix which contains similarity scores between words and phrases to approach sentence interactions (Socher et al., 2011; Yin et al., 2015). While the meaning of words and phrases may drift from contexts to contexts, simple similarity scores may be too weak to capture the complex interact"
P16-1053,J00-3003,0,0.503768,"Missing"
P16-1053,D14-1181,0,0.0120728,"Missing"
P16-1053,P15-1150,0,0.478849,"Xuan Zhu2 , Xiaoyan Zhu1 1 State Key Lab. of Intelligent Technology and Systems 1 National Lab. for Information Science and Technology 1 Dept. of Computer Science and Technology, Tsinghua University, Beijing, China 2 Samsung R&D Institute, Beijing, China 1 liubiao2638@gmail.com, {aihuang, zxy-dcs}@tsinghua.edu.cn Abstract For sentence pair modeling, some methods first project the two sentences to fix-sized vectors separately without considering the interactions between them, and then fed the sentence vectors to other classifiers as features for a specific task (Kalchbrenner and Blunsom, 2013; Tai et al., 2015). Such methods suffer from being unable to encode context information during sentence embedding. A more reasonable way to capture sentence interactions is to introduce some mechanisms to utilize information from both sentences at the same time. Some methods attempt to introduce an attention matrix which contains similarity scores between words and phrases to approach sentence interactions (Socher et al., 2011; Yin et al., 2015). While the meaning of words and phrases may drift from contexts to contexts, simple similarity scores may be too weak to capture the complex interactions, and a more po"
P16-1053,D15-1199,0,0.0127025,"rs. The reason may be the fact that interactions between long phrases is relatively rare, and in addition, the QA pairs in the WikiQA dataset may be insufficient for training such a complex model with long convolution windows. 4.2 MAP 0.599 0.511 0.619 0.660 0.634 0.657 0.674 MRR 0.609 0.516 0.628 0.677 0.648 0.672 0.693 Table 2: Results on answer selection4 . Dialogue Act Analysis Dialogue acts (DA), such as Statement, Yes-NoQuestion, Agreement, indicate the sentence pragmatic role as well as the intention of the speakers (Williams, 2012). They are widely used in natural language generation (Wen et al., 2015), speech and meeting summarization (Murray et al., 2006; Murray et al., 2010), etc. In a dialogue, the DA of a sentence is highly relevant to the content of itself and the previous sentences. As a result, to model the interactions and long-range dependence between sentences in a dialogue is crucial for dialogue act analysis. Given a dialogue (n sentences) d = [s1 , s2 , ..., sn ], we first use a LSTM (LSTM1 ) to model all the sentences independently. The hidden states of sentence si obtained at this step are used to compute the interaction states of sentence si+1 , and SIN will generate a sent"
P16-1053,W12-1812,0,0.0142778,"onvolution filters (window size ≥ 3) or stacking more convolution layers. The reason may be the fact that interactions between long phrases is relatively rare, and in addition, the QA pairs in the WikiQA dataset may be insufficient for training such a complex model with long convolution windows. 4.2 MAP 0.599 0.511 0.619 0.660 0.634 0.657 0.674 MRR 0.609 0.516 0.628 0.677 0.648 0.672 0.693 Table 2: Results on answer selection4 . Dialogue Act Analysis Dialogue acts (DA), such as Statement, Yes-NoQuestion, Agreement, indicate the sentence pragmatic role as well as the intention of the speakers (Williams, 2012). They are widely used in natural language generation (Wen et al., 2015), speech and meeting summarization (Murray et al., 2006; Murray et al., 2010), etc. In a dialogue, the DA of a sentence is highly relevant to the content of itself and the previous sentences. As a result, to model the interactions and long-range dependence between sentences in a dialogue is crucial for dialogue act analysis. Given a dialogue (n sentences) d = [s1 , s2 , ..., sn ], we first use a LSTM (LSTM1 ) to model all the sentences independently. The hidden states of sentence si obtained at this step are used to comput"
P16-1053,D15-1237,0,0.158787,"ingle similarity score, it is able to encode more information for word or phrase interactions. Second, the interaction mechanism in SIN can be adapted to different functions for different tasks during training, such as “word meaning adjustment” for Dialogue Act Analysis or “Answering” for Answer Selection. Our main contributions are as follows: For sentence pair modeling, a simple idea is to first project the sentences to two sentence vectors separately with sentence modeling methods, and then feed these two vectors into other classifiers for classification (Tai et al., 2015; Yu et al., 2014; Yang et al., 2015). The drawback of such methods is that separately modeling the two sentences is unable to capture the complex sentence interactions. Socher et al. (2011) model the two sentences with Recursive Neural Networks (Unfolding Recursive Autoencoders), and then feed similarity scores between words and phrases (syntax tree nodes) to a CNN with dynamic pooling to capture sentence interactions. Hu et al. (2014) first create an “interaction space” (matching score matrix) by feeding word and phrase pairs into a multilayer perceptron (MLP), and then apply CNN to such a space for interaction modeling. Yin et"
P16-1053,P13-1171,0,0.183674,"sentence interactions. Hu et al. (2014) first create an “interaction space” (matching score matrix) by feeding word and phrase pairs into a multilayer perceptron (MLP), and then apply CNN to such a space for interaction modeling. Yin et al. (2015) proposed an Attention based Convolutional Neural Network (ABCNN) for sentence pair modeling. ABCNN introduces an attention matrix between the convolution layers of the two sentences, and feed the matrix back to CNN to model sentence interactions. There are also some methods that make use of rich lexical semantic features for sentence pair modeling (Yih et al., 2013; Yang et al., 2015), but these methods can not be easily adapted to different tasks. • We propose a Sentence Interaction Network (SIN) which utilizes a new mechanism to model sentence interactions. • We add convolution layers to SIN, which improves the ability to model interactions between phrases. • We obtain significant improvements on Answer Selection and Dialogue Act Analysis without any handcrafted features. The rest of the paper is structured as follows: We survey related work in Section 2, introduce our method in Section 3, present the experiments in Section 4, and summarize our work i"
P16-1219,P11-1055,0,0.0266318,"Missing"
P16-1219,D15-1082,0,0.288185,"Missing"
P16-1219,Y14-1039,0,0.34255,"Missing"
P16-1219,1993.eamt-1.1,0,0.673487,"Missing"
P16-1219,P15-1009,0,0.161379,"Missing"
P17-1154,W12-3802,0,0.0183136,"of the sentiment value of the modified text (Polanyi and Zaenen, 2006; Kennedy and Inkpen, 2006). The shifting hyothesis assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Since each negator can affect the modified text in different ways, the constant amount can be extended to be negatorspecific (Zhu et al., 2014), and further, the effect of negators could also depend on the syntax and semantics of the modified text (Zhu et al., 2014). Other approaches to negation modeling can be seen in (Jia et al., 2009; Wiegand et al., 2010; Benamara et al., 2012; Lapponi et al., 2012). Sentiment intensity of a phrase indicates the strength of associated sentiment, which is quite important for fine-grained sentiment classification or rating. Intensity words can change the valence degree (i.e., sentiment intensity) of the modified text. In (Wei et al., 2011) the authors propose a linear regression model to predict the valence value for content words. In (Malandrakis et al., 2013), a kernel-based model is proposed to combine semantic information for predicting sentiment score. In the SemEval-2016 task 7 subtask A, a learningto-rank model with a pair-wis"
P17-1154,P14-2063,0,0.0155399,"dge and sentiment resources, such as sentiment lexicons, negation words (not, never, neither, etc.) or negators, and intensity words (very, extremely, etc.) or intensifiers, are useful for sentiment analysis in general. Sentiment lexicon (Hu and Liu, 2004; Wilson et al., 2005) usually defines prior polarity of a lexical entry, and is valuable for lexicon-based models (Turney, 2002; Taboada et al., 2011), and machine learning approaches (Pang and Lee, 2008). There are recent works for automatic construction of sentiment lexicons from social data (Vo and Zhang, 2016) and for multiple languages (Chen and Skiena, 2014). A noticeable work that ultilizes sentiment lexicons can be seen in (Teng et al., 2016) which treats the sentiment score of a sentence as a weighted sum of prior sentiment scores of negation words and sentiment words, where the weights are learned by a neural network. Negation words play a critical role in modifying sentiment of textual expressions. Some early negation models adopt the reversing assumption that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2006; Kennedy and Inkpen, 2006). The shifting hyothesis assumes that negators change the se"
P17-1154,J15-2004,0,0.0184039,"valence value for content words. In (Malandrakis et al., 2013), a kernel-based model is proposed to combine semantic information for predicting sentiment score. In the SemEval-2016 task 7 subtask A, a learningto-rank model with a pair-wise strategy is proposed to predict sentiment intensity scores (Wang 1680 et al., 2016). Linguistic intensity is not limited to sentiment or intensity words, and there are works that assign low/medium/high intensity scales to adjectives such as okay, good, great (Sharma et al., 2015) or to gradable terms (e.g. large, huge, gigantic) (Shivade et al., 2015). In (Dong et al., 2015), a sentiment parser is proposed, and the authors studied how sentiment changes when a phrase is modified by negators or intensifiers. Applying linguistic regularization to text classification can be seen in (Yogatama and Smith, 2014) which introduces three linguistically motivated structured regularizers based on parse trees, topics, and hierarchical word clusters for text categorization. Our work differs in that (Yogatama and Smith, 2014) applies group lasso regularizers to logistic regression on model parameters while our regularizers are applied on intermediate outputs with KL divergence."
P17-1154,P16-1047,0,0.0774501,"cross entropy loss: ∑ ∑∑ L(θ) = − yˆi log yi + α Lt,i + β||θ||2 i i t (4) where yˆi is the gold distribution for sentence i, yi is the predicted distribution, Lt,i is one of the above regularizers or combination of these regularizers on sentence i, α is the weight for the regularization term, and t is the word position in a sentence. Note that we do not consider the modification span of negation and intensity words to preserve the simplicity of the proposed models. Negation scope resolution is another complex problem which has been extensively studied (Zou et al., 2013; Packard et al., 2014; Fancellu et al., 2016), which is beyond the scope of this work. Instead, we resort to sequence LSTMs for encoding surrounding contexts at a given position. 4.1 Non-Sentiment Regularizer (NSR) This regularizer constrains that the sentiment distributions of adjacent positions should not vary much if the additional input word xt is not a sentiment word, formally as follows: (N SR) Lt = max(0, DKL (pt ||pt−1 ) − M ) (5) where M is a hyperparameter for margin, pt is the predicted distribution at state of position t, (i.e., ht ), and DKL (p||q) is a symmetric KL divergence defined as follows: C 1∑ p(l) log q(l) + q(l) lo"
P17-1154,P82-1020,0,0.822845,"Missing"
P17-1154,P15-1162,0,0.0165846,"Missing"
P17-1154,P14-1062,0,0.0819215,"apture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation. S"
P17-1154,D14-1181,0,0.016407,"e able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with s"
P17-1154,D15-1180,0,0.12824,"of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation. Second, linguistic k"
P17-1154,P14-1007,0,0.0674053,"term into the original cross entropy loss: ∑ ∑∑ L(θ) = − yˆi log yi + α Lt,i + β||θ||2 i i t (4) where yˆi is the gold distribution for sentence i, yi is the predicted distribution, Lt,i is one of the above regularizers or combination of these regularizers on sentence i, α is the weight for the regularization term, and t is the word position in a sentence. Note that we do not consider the modification span of negation and intensity words to preserve the simplicity of the proposed models. Negation scope resolution is another complex problem which has been extensively studied (Zou et al., 2013; Packard et al., 2014; Fancellu et al., 2016), which is beyond the scope of this work. Instead, we resort to sequence LSTMs for encoding surrounding contexts at a given position. 4.1 Non-Sentiment Regularizer (NSR) This regularizer constrains that the sentiment distributions of adjacent positions should not vary much if the additional input word xt is not a sentiment word, formally as follows: (N SR) Lt = max(0, DKL (pt ||pt−1 ) − M ) (5) where M is a hyperparameter for margin, pt is the predicted distribution at state of position t, (i.e., ht ), and DKL (p||q) is a symmetric KL divergence defined as follows: C 1∑"
P17-1154,P05-1015,0,0.676356,"tic role of sentiment lexicons, negation words, and intensity words. Results show that our models are able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensi"
P17-1154,W02-1011,0,0.0268907,"o model the linguistic role of sentiment lexicons, negation words, and intensity words. Results show that our models are able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree s"
P17-1154,D14-1162,0,0.112451,"those words that have conflicting sentiment labels, and produce a lexicon of 9, 750 words with 4 sentiment labels. For negation and intensity words, we collect them manually since the number is small, some of which can be seen in Table 2. Dataset # sentences in total #sen containing sentiment word #sen containing negation word #sen containing intensity word MR 10,662 10,446 1,644 2,687 SST 11,885 11,211 1,832 2,472 Table 1: The data statistics. 5.2 The Details of Experiment Setting In order to let others reproduce our results, we present all the details of our models. We adopt Glove vectors (Pennington et al., 2014) as the initial setting of word embeddings V . The shifting vector for each sentiment class (sc ), and the transformation matrices for negation and intensity (Tm ) are initialized with a prior value. The other parameters for hidden layers (W (∗) , U (∗) , S) are initialized with U nif orm(0, 1/sqrt(d)), where d is the dimension of hidden representation, and we set d=300. We adopt adaGrad to train the models, and the learning rate is 0.1. It’s worth noting that, we adopt stochastic gradient descent to update the word embeddings (V ), with a learning rate of 0.2 but without momentum. The optimal"
P17-1154,P15-1132,1,0.127763,"k. In Section 3, we briefly introduce the background of LSTM and bidirectional LSTM, and then describe in detail the lingistic regularizers for sentiment/negation/intensity words in Section 4. Experiments are presented in Section 5, and Conclusion follows in Section 6. 2 Related Work 2.1 Neural Networks for Sentiment Classification There are many neural networks proposed for sentiment classification. The most noticeable models may be the recursive autoencoder neural network which builds the representation of a sentence from subphrases recursively (Socher et al., 2011, 2013; Dong et al., 2014; Qian et al., 2015). Such recursive models usually depend on a tree structure of input text, and in order to obtain competitive results, usually require annotation of all subphrases. Sequence models, for instance, convolutional neural network (CNN), do not require tree-structured data, which are widely adopted for sentiment classification (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015). Long short-term memory models are also common for learning sentence-level representation due to its capability of modeling the prefix or suffix context (Hochreiter and Schmidhuber, 1997). LSTM can be commonly applied to"
P17-1154,D15-1300,0,0.0127721,"e modified text. In (Wei et al., 2011) the authors propose a linear regression model to predict the valence value for content words. In (Malandrakis et al., 2013), a kernel-based model is proposed to combine semantic information for predicting sentiment score. In the SemEval-2016 task 7 subtask A, a learningto-rank model with a pair-wise strategy is proposed to predict sentiment intensity scores (Wang 1680 et al., 2016). Linguistic intensity is not limited to sentiment or intensity words, and there are works that assign low/medium/high intensity scales to adjectives such as okay, good, great (Sharma et al., 2015) or to gradable terms (e.g. large, huge, gigantic) (Shivade et al., 2015). In (Dong et al., 2015), a sentiment parser is proposed, and the authors studied how sentiment changes when a phrase is modified by negators or intensifiers. Applying linguistic regularization to text classification can be seen in (Yogatama and Smith, 2014) which introduces three linguistically motivated structured regularizers based on parse trees, topics, and hierarchical word clusters for text categorization. Our work differs in that (Yogatama and Smith, 2014) applies group lasso regularizers to logistic regression on"
P17-1154,D11-1014,0,0.690416,"ensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation. Second, linguistic knowledge such as sentiment lexicon, negation"
P17-1154,D09-1017,0,0.0241467,"e seen in (Teng et al., 2016) which treats the sentiment score of a sentence as a weighted sum of prior sentiment scores of negation words and sentiment words, where the weights are learned by a neural network. Negation words play a critical role in modifying sentiment of textual expressions. Some early negation models adopt the reversing assumption that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2006; Kennedy and Inkpen, 2006). The shifting hyothesis assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Since each negator can affect the modified text in different ways, the constant amount can be extended to be negatorspecific (Zhu et al., 2014), and further, the effect of negators could also depend on the syntax and semantics of the modified text (Zhu et al., 2014). Other approaches to negation modeling can be seen in (Jia et al., 2009; Wiegand et al., 2010; Benamara et al., 2012; Lapponi et al., 2012). Sentiment intensity of a phrase indicates the strength of associated sentiment, which is quite important for fine-grained sentiment classification or rating. Intensity words can change the v"
P17-1154,D13-1170,0,0.073158,"individual words. Negation/Intensity effect also depends on the syntax and semantics of the modified text, however, for simplicity we resort to sequence LSTM for encoding surrounding contexts in this paper. We partially address the modification scope issue by applying the minimization operator in Eq. 11 and Eq. 14, and the bidirectional LSTM. 5 Experiment 5.1 Dataset and Sentiment Lexicon Two datasets are used for evaluating the proposed models: Movie Review (MR) (Pang and Lee, 2005) where each sentence is annotated with two classes as negative, positive and Stanford Sentiment Treebank (SST) (Socher et al., 2013) with five classes { very negative, negative, neutral, positive, very positive}. Note that SST has provided phrase-level annotation on all inner nodes, but we only use the sentence-level annotation since one of our goals is to avoid expensive phrase-level annotation. The sentiment lexicon contains two parts. The first part comes from MPQA (Wilson et al., 2005), which contains 5, 153 sentiment words, each with polarity rating. The second part consists of the leaf nodes of the SST dataset (i.e., all sentiment words) and there are 6, 886 polar words except neural ones. We combine the two parts an"
P17-1154,J11-2001,0,0.643048,"models trained with sentence-level annotation, but also attempt to model the linguistic role of sentiment lexicons, negation words, and intensity words. Results show that our models are able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM ("
P17-1154,P15-1150,0,0.232855,"y text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation. Second, linguistic knowledge such as sentiment lexicon, negation words or negators (e.g., not, never), and intensity words or intensifiers (e.g., very, abs"
P17-1154,D16-1169,0,0.0339412,"Missing"
P17-1154,P02-1053,0,0.0708854,"ropose simple models trained with sentence-level annotation, but also attempt to model the linguistic role of sentiment lexicons, negation words, and intensity words. Results show that our models are able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression. 1 Introduction Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. ∗ Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoe"
P17-1154,P16-2036,0,0.00635839,"e for Sentiment Classification Linguistic knowledge and sentiment resources, such as sentiment lexicons, negation words (not, never, neither, etc.) or negators, and intensity words (very, extremely, etc.) or intensifiers, are useful for sentiment analysis in general. Sentiment lexicon (Hu and Liu, 2004; Wilson et al., 2005) usually defines prior polarity of a lexical entry, and is valuable for lexicon-based models (Turney, 2002; Taboada et al., 2011), and machine learning approaches (Pang and Lee, 2008). There are recent works for automatic construction of sentiment lexicons from social data (Vo and Zhang, 2016) and for multiple languages (Chen and Skiena, 2014). A noticeable work that ultilizes sentiment lexicons can be seen in (Teng et al., 2016) which treats the sentiment score of a sentence as a weighted sum of prior sentiment scores of negation words and sentiment words, where the weights are learned by a neural network. Negation words play a critical role in modifying sentiment of textual expressions. Some early negation models adopt the reversing assumption that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2006; Kennedy and Inkpen, 2006). The shi"
P17-1154,S16-1080,0,0.0302136,"Missing"
P17-1154,W10-3111,0,0.0157848,"tor reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2006; Kennedy and Inkpen, 2006). The shifting hyothesis assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Since each negator can affect the modified text in different ways, the constant amount can be extended to be negatorspecific (Zhu et al., 2014), and further, the effect of negators could also depend on the syntax and semantics of the modified text (Zhu et al., 2014). Other approaches to negation modeling can be seen in (Jia et al., 2009; Wiegand et al., 2010; Benamara et al., 2012; Lapponi et al., 2012). Sentiment intensity of a phrase indicates the strength of associated sentiment, which is quite important for fine-grained sentiment classification or rating. Intensity words can change the valence degree (i.e., sentiment intensity) of the modified text. In (Wei et al., 2011) the authors propose a linear regression model to predict the valence value for content words. In (Malandrakis et al., 2013), a kernel-based model is proposed to combine semantic information for predicting sentiment score. In the SemEval-2016 task 7 subtask A, a learningto-ran"
P17-1154,H05-1044,0,0.433297,"mmon for learning sentence-level representation due to its capability of modeling the prefix or suffix context (Hochreiter and Schmidhuber, 1997). LSTM can be commonly applied to sequential data but also tree-structured data (Zhu et al., 2015; Tai et al., 2015). 2.2 Applying Linguistic Knowledge for Sentiment Classification Linguistic knowledge and sentiment resources, such as sentiment lexicons, negation words (not, never, neither, etc.) or negators, and intensity words (very, extremely, etc.) or intensifiers, are useful for sentiment analysis in general. Sentiment lexicon (Hu and Liu, 2004; Wilson et al., 2005) usually defines prior polarity of a lexical entry, and is valuable for lexicon-based models (Turney, 2002; Taboada et al., 2011), and machine learning approaches (Pang and Lee, 2008). There are recent works for automatic construction of sentiment lexicons from social data (Vo and Zhang, 2016) and for multiple languages (Chen and Skiena, 2014). A noticeable work that ultilizes sentiment lexicons can be seen in (Teng et al., 2016) which treats the sentiment score of a sentence as a weighted sum of prior sentiment scores of negation words and sentiment words, where the weights are learned by a n"
P17-1154,P14-1074,0,0.0180569,"h a pair-wise strategy is proposed to predict sentiment intensity scores (Wang 1680 et al., 2016). Linguistic intensity is not limited to sentiment or intensity words, and there are works that assign low/medium/high intensity scales to adjectives such as okay, good, great (Sharma et al., 2015) or to gradable terms (e.g. large, huge, gigantic) (Shivade et al., 2015). In (Dong et al., 2015), a sentiment parser is proposed, and the authors studied how sentiment changes when a phrase is modified by negators or intensifiers. Applying linguistic regularization to text classification can be seen in (Yogatama and Smith, 2014) which introduces three linguistically motivated structured regularizers based on parse trees, topics, and hierarchical word clusters for text categorization. Our work differs in that (Yogatama and Smith, 2014) applies group lasso regularizers to logistic regression on model parameters while our regularizers are applied on intermediate outputs with KL divergence. 3 where g (LST M ) is the same as that in Eq (1). Particularly, parameters in the two LSTMs are shared. The representation of the entire sentence − → ← − is [ h n , h 1 ], where n is the length of the sentence. At each position t, the"
P17-1154,P14-1029,0,0.140699,"n. Firstly, we attempts to develop simple models that do not depend on parsing trees and do not require phrase-level annotation which is too expensive in real-world applications. Secondly, in order to obtain competitive performance, simple models can benefit from linguistic resources. Three types of resources will be addressed in this paper: sentiment lexicon, negation words, and intensity words. Sentiment lexicon offers the prior polarity of a word which can be useful in determining the sentiment polarity of longer texts such as phrases and sentences. Negators are typical sentiment shifters (Zhu et al., 2014), which constantly change the polarity of sentiment expression. Intensifiers change the valence degree of the modified text, which is important for fine-grained sentiment classification. In order to model the linguistic role of sentiment, negation, and intensity words, our central idea is to regularize the difference between the predicted sentiment distribution of the current position 1 , and that of the previous or next positions, in a sequence model. For instance, if the cur1 Note that in sequence models, the hidden state of the current position also encodes forward or backward contexts. 167"
P17-1154,D13-1099,0,0.0294612,"e plug a new loss term into the original cross entropy loss: ∑ ∑∑ L(θ) = − yˆi log yi + α Lt,i + β||θ||2 i i t (4) where yˆi is the gold distribution for sentence i, yi is the predicted distribution, Lt,i is one of the above regularizers or combination of these regularizers on sentence i, α is the weight for the regularization term, and t is the word position in a sentence. Note that we do not consider the modification span of negation and intensity words to preserve the simplicity of the proposed models. Negation scope resolution is another complex problem which has been extensively studied (Zou et al., 2013; Packard et al., 2014; Fancellu et al., 2016), which is beyond the scope of this work. Instead, we resort to sequence LSTMs for encoding surrounding contexts at a given position. 4.1 Non-Sentiment Regularizer (NSR) This regularizer constrains that the sentiment distributions of adjacent positions should not vary much if the additional input word xt is not a sentiment word, formally as follows: (N SR) Lt = max(0, DKL (pt ||pt−1 ) − M ) (5) where M is a hyperparameter for margin, pt is the predicted distribution at state of position t, (i.e., ht ), and DKL (p||q) is a symmetric KL divergence de"
P18-1139,K16-1002,0,0.200612,"coding position, and the type distribution will be used in the mixture model of the decoder for final word generation. During the decoding process, the decoder’s state st and the latent variable z are taken as input to estimate the type distribution as follows: P (wt|st , z) = sof tmax(W0 · MLPtype (st , z)) (10) Noticeably, the latent variable z introduced to the RNN encoder-decoder framework often fails to learn a meaningful representation and has little influence on language generation, because the RNN decoder may ignore z during generation, known as the issue of vanishing latent variable (Bowman et al., 2016). By contrast, our model allows z to directly control the word type at each decoding position, which has more influence on language generation. 1502 3.6 Decoder Compared with the traditional decoder described in Section 3.2, our decoder updates the hidden state st with both the input information c and the latent variable z, and generates the response in a mixture form which is combined with the type distribution obtained from the type controller: st = GRU(st−1 , e(yt−1 ), cvt−1 , c, z) (11) P (yt |y&lt;t , c, z) = P (yt |yt−1 , st , c, z) = 3 X P (wt = i|st , z)P (yt |yt−1 , st , c, z, wt = i) i="
P18-1139,W14-4012,0,0.0699369,"Missing"
P18-1139,J90-1003,0,0.596855,"P (Y |z, c)] X = −Eqφ (z|Y,c) [ log P (yt |y&lt;t , z, c)] (16) t 3.7 Loss Function The overall loss L is a linear combination of the KL term L1 , the classification loss of the discriminator L2 , and the generation loss of the decoder L3 : L = αL1 + L2 + L3 (17) We let α gradually increase from 0 to 1. This technique of KL cost annealing can address the optimization challenges of vanishing latent variables in the RNN encoder-decoder (Bowman et al., 2016). 3.8 Topic Word Prediction Topic words play a key role in generating an informative response. We resort to pointwise mutual information (PMI) (Church and Hanks, 1990) for predicting a list of topic words that are relevant to a post. Let x and y indicate a word in a post X and its response Y respectively, and PMI is computed as follows: P M I(x, y) = log P (x, y) P (x)P (y) (18) Then, the relevance score of a topic word to a given post x1 x2 · · · xn can be approximated as follows, similar to (Mou et al., 2016): REL(x1 , ..., xn , y) ≈ n X P M I(xi , y) (19) i=1 During training, the words in a response with high REL scores to the post are treated as topic words. During test, we use REL to select the top ranked words as topic words for a post. 4 Experiment 4"
P18-1139,E17-1059,0,0.0200574,"n be used to avoid stalemates (Li et al., 2016b), which can be viewed as important proactive behaviors in conversation (Yu et al., 2016). Thus, conversational systems equipped with the ability to control the sentence function can adjust its strategy for different purposes within different contexts, behave more proactively, and may lead the dialogue to go further. Generating responses with controlled sentence functions differs significantly from other tasks on controllable text generation (Hu et al., 2017; Ficler and Goldberg, 2017; Asghar et al., 2017; Ghosh et al., 2017; Zhou and Wang, 2017; Dong et al., 2017; Murakami et al., 2017). These studies, involving the control of sentiment polarity, emotion, or tense, fall into local control, more or less, because the controllable variable can be locally re1 Note that we did not include the exclamatory category in this paper because an exclamatory sentence in conversation is only a strong emotional expression of the original sentence with few changes. 1499 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1499–1508 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Lin"
P18-1139,W17-4912,0,0.240126,"make statements to state or explain something.1 Interrogative and imperative responses can be used to avoid stalemates (Li et al., 2016b), which can be viewed as important proactive behaviors in conversation (Yu et al., 2016). Thus, conversational systems equipped with the ability to control the sentence function can adjust its strategy for different purposes within different contexts, behave more proactively, and may lead the dialogue to go further. Generating responses with controlled sentence functions differs significantly from other tasks on controllable text generation (Hu et al., 2017; Ficler and Goldberg, 2017; Asghar et al., 2017; Ghosh et al., 2017; Zhou and Wang, 2017; Dong et al., 2017; Murakami et al., 2017). These studies, involving the control of sentiment polarity, emotion, or tense, fall into local control, more or less, because the controllable variable can be locally re1 Note that we did not include the exclamatory category in this paper because an exclamatory sentence in conversation is only a strong emotional expression of the original sentence with few changes. 1499 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1499–1508 c"
P18-1139,P17-1059,0,0.19224,"Interrogative and imperative responses can be used to avoid stalemates (Li et al., 2016b), which can be viewed as important proactive behaviors in conversation (Yu et al., 2016). Thus, conversational systems equipped with the ability to control the sentence function can adjust its strategy for different purposes within different contexts, behave more proactively, and may lead the dialogue to go further. Generating responses with controlled sentence functions differs significantly from other tasks on controllable text generation (Hu et al., 2017; Ficler and Goldberg, 2017; Asghar et al., 2017; Ghosh et al., 2017; Zhou and Wang, 2017; Dong et al., 2017; Murakami et al., 2017). These studies, involving the control of sentiment polarity, emotion, or tense, fall into local control, more or less, because the controllable variable can be locally re1 Note that we did not include the exclamatory category in this paper because an exclamatory sentence in conversation is only a strong emotional expression of the original sentence with few changes. 1499 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1499–1508 c Melbourne, Australia, July 15 - 20, 2018"
P18-1139,P82-1020,0,0.846242,"Missing"
P18-1139,P15-1152,0,0.318681,"Missing"
P18-1139,N16-1014,0,0.681453,"u have at breakfast? Let’s have dinner together! tions, but surprisingly, this problem is rather untouched in dialogue systems. As shown in Figure 1, responses with different functions can be used to achieve different conversational purposes: Interrogative responses can be used to acquire further information from the user; imperative responses are used to make requests, directions, instructions or invitations to elicit further interactions; and declarative responses commonly make statements to state or explain something.1 Interrogative and imperative responses can be used to avoid stalemates (Li et al., 2016b), which can be viewed as important proactive behaviors in conversation (Yu et al., 2016). Thus, conversational systems equipped with the ability to control the sentence function can adjust its strategy for different purposes within different contexts, behave more proactively, and may lead the dialogue to go further. Generating responses with controlled sentence functions differs significantly from other tasks on controllable text generation (Hu et al., 2017; Ficler and Goldberg, 2017; Asghar et al., 2017; Ghosh et al., 2017; Zhou and Wang, 2017; Dong et al., 2017; Murakami et al., 2017). The"
P18-1139,C16-1316,0,0.566909,"., 2018; Zhou and Wang, 2017), and was for past tense (Hu et al., 2017). By contrast, sentence function is a global attribute of text, and controlling sentence function is more challenging in that it requires to adjust the global structure of the entire text, including changing word order and word patterns. Controlling sentence function in conversational systems faces another challenge: in order to generate informative and meaningful responses, it has to deal with the compatibility of the sentence function and the content. Similar to most existing neural conversation models (Li et al., 2016a; Mou et al., 2016; Xing et al., 2017), we are also struggling with universal and meaningless responses for different sentence functions, e.g., “Is that right?” for interrogative responses, “Please!” for imperative responses and “Me, too.” for declarative responses. The lack of meaningful topics in responses will definitely degrade the utility of the sentence function so that the desired conversational purpose can not be achieved. Thus, the task needs to generate responses with both informative content and controllable sentence functions. In this paper, we propose a conversation generation model to deal with th"
P18-1139,W16-3649,0,0.0204493,"rather untouched in dialogue systems. As shown in Figure 1, responses with different functions can be used to achieve different conversational purposes: Interrogative responses can be used to acquire further information from the user; imperative responses are used to make requests, directions, instructions or invitations to elicit further interactions; and declarative responses commonly make statements to state or explain something.1 Interrogative and imperative responses can be used to avoid stalemates (Li et al., 2016b), which can be viewed as important proactive behaviors in conversation (Yu et al., 2016). Thus, conversational systems equipped with the ability to control the sentence function can adjust its strategy for different purposes within different contexts, behave more proactively, and may lead the dialogue to go further. Generating responses with controlled sentence functions differs significantly from other tasks on controllable text generation (Hu et al., 2017; Ficler and Goldberg, 2017; Asghar et al., 2017; Ghosh et al., 2017; Zhou and Wang, 2017; Dong et al., 2017; Murakami et al., 2017). These studies, involving the control of sentiment polarity, emotion, or tense, fall into loca"
P18-1139,P17-1061,0,0.293087,"ed from the recognition network which is supervised by the function label in the discriminator. In the type controller, the latent variable and the decoder’s state are used to estimate a type distribution which modulates the final generation distribution. During test, z is sampled from the prior network whose input is only the post. The response encoder in the dotted box appears only in training. plan the words globally to realize the function type to be controlled. (2) The compatibility of controllable variables and content quality is less studied in the literature. The most similar work in (Zhao et al., 2017) proposed to control the dialogue act of a response, which is also a global attribute. However, the model controls dialog act by directly feeding a latent variable into the decoder, instead, our model has a stronger control on the generation process via a type controller in which words of different types are concretely modeled. 3 3.1 Model Task Definition and Model Overview Our problem is formulated as follows: given a post X = x1 x2 · · · xn and a sentence function category l, our task is to generate a response Y = y1 y2 · · · ym that is not only coherent with the specified function category"
P18-1204,2010.jeptalnrecital-court.36,0,0.0344837,"the answer is known and is part of the input to the generated question. Meanwhile, the generation tasks are not required to predict additional topics since all the information has been provided in the input. They are applicable in scenarios such as designing questions for reading comprehension (Du et al., 2017; Zhou et al., 2017a; Yuan et al., 2017), and justifying the visual understanding by generating questions to a given image (video) (Mostafazadeh et al., 2016). In general, traditional QG tasks can be addressed by the heuristic rule-based reordering methods (Andrenucci and Sneiders, 2005; Ali et al., 2010; Heilman and Smith, 2010), slotfilling with question templates (Popowich and Winne, 2013; Chali and Golestanirad, 2016; Labutov et al., 2015), or implicitly modeled by recent neural models(Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017; Song et al., 2017; Subramanian et al., 2017). These tasks generally do not require to generate a question with various patterns: for a given answer and a supporting text, the question type is usually decided by the input. Question generation in large-scale, opendomain dialogue systems is relatively unexplored. Li et al. (2016) showed that asking questi"
P18-1204,P16-1170,0,0.393978,"e, and ordinary words play syntactical and grammatical roles in making a natural sentence. We devise two typed decoders (soft typed decoder and hard typed decoder) in which a type distribution over the three types is estimated and used to modulate the final generation distribution. Extensive experiments show that the typed decoders outperform state-of-the-art baselines and can generate more meaningful questions. 1 Introduction Learning to ask questions (or, question generation) aims to generate a question to a given input. Deciding what to ask and how is an indicator of machine understanding (Mostafazadeh et al., 2016), as demonstrated in machine comprehension (Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017) and question answering (Tang et al., 2017; Wang et al., 2017). Raising good questions is essential to conversational systems because a good system can well interact with users by asking and responding (Li et al., 2016). Furthermore, asking ∗ † Authors contributed equally to this work. Corresponding author: Minlie Huang. questions is one of the important proactive behaviors that can drive dialogues to go deeper and further (Yu et al., 2016). Question generation (QG) in open-domain conversational"
P18-1204,W13-2114,0,0.265154,"e of this task is to spark novel yet related information to drive the interactions to continue. Due to the different purposes, this task is unique in two aspects: it requires to question not only in various patterns but also about diverse yet relevant topics. First, there are various questioning patterns for the same input, such as Yes-no questions and Wh-questions with different interrogatives. Diversified questioning patterns make dialogue interactions richer and more flexible. Instead, traditional QG tasks can be roughly addressed by syntactic transformation (Andrenucci and Sneiders, 2005; Popowich and Winne, 2013), or implicitly modeled by neural models (Du et al., 2017). In such tasks, the information questioned on is pre-specified and usually determines the pattern of questioning. For instance, asking Whoquestion for a given person, or Where-question for a given location. Second, this task requires to address much more transitional topics of a given input, which is the nature of conversational systems. For instance, for the input “I went to dinner with my friends”, we may question about topics such as friend, cuisine, 2193 Proceedings of the 56th Annual Meeting of the Association for Computational Li"
P18-1204,W16-6635,0,0.01363,"not required to predict additional topics since all the information has been provided in the input. They are applicable in scenarios such as designing questions for reading comprehension (Du et al., 2017; Zhou et al., 2017a; Yuan et al., 2017), and justifying the visual understanding by generating questions to a given image (video) (Mostafazadeh et al., 2016). In general, traditional QG tasks can be addressed by the heuristic rule-based reordering methods (Andrenucci and Sneiders, 2005; Ali et al., 2010; Heilman and Smith, 2010), slotfilling with question templates (Popowich and Winne, 2013; Chali and Golestanirad, 2016; Labutov et al., 2015), or implicitly modeled by recent neural models(Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017; Song et al., 2017; Subramanian et al., 2017). These tasks generally do not require to generate a question with various patterns: for a given answer and a supporting text, the question type is usually decided by the input. Question generation in large-scale, opendomain dialogue systems is relatively unexplored. Li et al. (2016) showed that asking questions in task-oriented dialogues can offer useful feedback to facilitate learning through interactions. Several questioni"
P18-1204,J90-1003,0,0.260487,"ly as Y ∗ = argmax P(Y |X). Y As aforementioned, asking good questions in conversational systems requires to question with diversified patterns and address transitional topics naturally in a question. To this end, we classify the words in a sentence into three types: interrogative, topic word, and ordinary word, as shown in Figure 1. During training, the type of each word in a question is decided automatically2 . We manually collected about 20 interrogatives. The verbs and nouns in a question are treated as topic words, and all the other words as ordinary words. During test, we resort to PMI (Church and Hanks, 1990) to predict a few topic words for a given post. On top of an encoder-decoder framework, we propose two decoders to effectively use word types in question generation. The first model is soft typed decoder (STD). It estimates a type distribution over word types and three type-specific generation distributions over the vocabulary, and then obtains a mixture of type-specific distributions for word generation. The second one is a hard form of STD, hard typed decoder (HTD), in which we can control the decoding process more explicitly by approximating the operation of argmax with Gumbel-softmax (Jang"
P18-1204,P17-1123,0,0.375017,"a natural sentence. We devise two typed decoders (soft typed decoder and hard typed decoder) in which a type distribution over the three types is estimated and used to modulate the final generation distribution. Extensive experiments show that the typed decoders outperform state-of-the-art baselines and can generate more meaningful questions. 1 Introduction Learning to ask questions (or, question generation) aims to generate a question to a given input. Deciding what to ask and how is an indicator of machine understanding (Mostafazadeh et al., 2016), as demonstrated in machine comprehension (Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017) and question answering (Tang et al., 2017; Wang et al., 2017). Raising good questions is essential to conversational systems because a good system can well interact with users by asking and responding (Li et al., 2016). Furthermore, asking ∗ † Authors contributed equally to this work. Corresponding author: Minlie Huang. questions is one of the important proactive behaviors that can drive dialogues to go deeper and further (Yu et al., 2016). Question generation (QG) in open-domain conversational systems differs substantially from the traditional QG tasks"
P18-1204,D17-1090,0,0.169457,"Missing"
P18-1204,P17-1059,0,0.047829,"Missing"
P18-1204,N10-1086,0,0.0798675,"n and is part of the input to the generated question. Meanwhile, the generation tasks are not required to predict additional topics since all the information has been provided in the input. They are applicable in scenarios such as designing questions for reading comprehension (Du et al., 2017; Zhou et al., 2017a; Yuan et al., 2017), and justifying the visual understanding by generating questions to a given image (video) (Mostafazadeh et al., 2016). In general, traditional QG tasks can be addressed by the heuristic rule-based reordering methods (Andrenucci and Sneiders, 2005; Ali et al., 2010; Heilman and Smith, 2010), slotfilling with question templates (Popowich and Winne, 2013; Chali and Golestanirad, 2016; Labutov et al., 2015), or implicitly modeled by recent neural models(Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017; Song et al., 2017; Subramanian et al., 2017). These tasks generally do not require to generate a question with various patterns: for a given answer and a supporting text, the question type is usually decided by the input. Question generation in large-scale, opendomain dialogue systems is relatively unexplored. Li et al. (2016) showed that asking questions in task-oriented dialo"
P18-1204,P15-1086,0,0.0250609,"ional topics since all the information has been provided in the input. They are applicable in scenarios such as designing questions for reading comprehension (Du et al., 2017; Zhou et al., 2017a; Yuan et al., 2017), and justifying the visual understanding by generating questions to a given image (video) (Mostafazadeh et al., 2016). In general, traditional QG tasks can be addressed by the heuristic rule-based reordering methods (Andrenucci and Sneiders, 2005; Ali et al., 2010; Heilman and Smith, 2010), slotfilling with question templates (Popowich and Winne, 2013; Chali and Golestanirad, 2016; Labutov et al., 2015), or implicitly modeled by recent neural models(Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017; Song et al., 2017; Subramanian et al., 2017). These tasks generally do not require to generate a question with various patterns: for a given answer and a supporting text, the question type is usually decided by the input. Question generation in large-scale, opendomain dialogue systems is relatively unexplored. Li et al. (2016) showed that asking questions in task-oriented dialogues can offer useful feedback to facilitate learning through interactions. Several questioning mechanisms were devi"
P18-1204,W16-3649,0,0.0976934,"how is an indicator of machine understanding (Mostafazadeh et al., 2016), as demonstrated in machine comprehension (Du et al., 2017; Zhou et al., 2017b; Yuan et al., 2017) and question answering (Tang et al., 2017; Wang et al., 2017). Raising good questions is essential to conversational systems because a good system can well interact with users by asking and responding (Li et al., 2016). Furthermore, asking ∗ † Authors contributed equally to this work. Corresponding author: Minlie Huang. questions is one of the important proactive behaviors that can drive dialogues to go deeper and further (Yu et al., 2016). Question generation (QG) in open-domain conversational systems differs substantially from the traditional QG tasks. The ultimate goal of this task is to enhance the interactiveness and persistence of human-machine interactions, while for traditional QG tasks, seeking information through a generated question is the major purpose. The response to a generated question will be supplied in the following conversations, which may be novel but not necessarily occur in the input as that in traditional QG (Du et al., 2017; Yuan et al., 2017; Tang et al., 2017; Wang et al., 2017; Mostafazadeh et al., 2"
P18-1204,D15-1166,0,0.0555462,"bution is dominated by interrogatives and ordinary words. Ultimately, we obtained the dataset comprising about 491,000 post-response pairs. We randomly selected 5,000 pairs for testing and another 5,000 for validation. The average number of words in post/response is 8.3/9.3 respectively. The dataset contains 66,547 different words, and 18,717 words appear more than 10 times. The dataset is available at: http://coai.cs.tsinghua.edu. cn/hml/dataset/. 4.2 Baselines We compared the proposed decoders with four state-of-the-art baselines. Seq2Seq: A simple encoder-decoder with attention mechanisms (Luong et al., 2015). MA: The mechanism-aware (MA) model applies multiple responding mechanisms represented by real-valued vectors (Zhou et al., 2017a). The number of mechanisms is set to 4 and we randomly picked one response from the generated responses for evaluation to avoid selection bias. TA: The topic-aware (TA) model generates informative responses by incorporating topic words predicted from the input post (Xing et al., 2017). ERM: Elastic responding machine (ERM) adaptively selects a subset of responding mechanisms using reinforcement learning (Zhou et al., 2018a). The settings are the same as the origina"
P19-1075,C16-1167,0,0.622747,"uage usage. Machine reading comprehension aims to assess the ability to comprehend natural language and answer questions from a given document or passage. As a classical method of assessing language proficiency (Fotos, 1991; Jonz, 1991; Tremblay, 2011), cloze test (Taylor, 1953) has been widely employed due to its simplicity in form. Recently, a number of datasets for cloze test have been proposed for different languages. For instance, CNN/Daily Mail (Hermann et al., 2015) provides a benchmark for machine comprehension of English text, while the People Daily and Children’s Fairy Tale dataset (Cui et al., 2016) and CMRC2017 (Cui et al., 2018) pioneer explorations in Chinese language. In this paper we explore idiom comprehension (Wray, 2002; Jackendoff and Jackendoff, 2002; Cacciari and Tabossi, 2014; Jiang et al., 2018) in cloze test. Idiom , which is called “成 语” (chengyu) in Chinese, is an interesting linguistic phenomena in Chinese language, and this work is in parallel to several datasets (Hill et al., 2016; Xie et al., 2018) that have considered different language phenomena in English. Compared to other types of words, many idioms are unique for their non-compositionality and metaphorical meani"
P19-1075,P17-1168,0,0.0242266,"ance, CNN/Daily Mail (Hermann et al., 2015) collects news articles and uses the cloze test (Taylor, 1953) to assess the ability of reading comprehension in English. RACE (Lai et al., 2017) and CLOTH (Xie et al., 2018) are constructed from questions in examinations designed for secondary and high school students. A number of question-answer datasets (Rajpurkar et al., 2016; Reddy et al., 2018) are also proposed and there are many other large-scale datasets (Nguyen et al., 2016; He et al., 2018). These corpora inspire various neural models (Chen et al., 2016; Cui et al., 2016; Seo et al., 2017; Dhingra et al., 2017; Cui et al., 2017). In Table 3, we present a survey on existing cloze-style reading comprehension datasets. As the earliest cloze-style dataset for machine reading comprehension, CNN/Daily Mail (Hermann et al., 2015) has a very large scale. It collects news articles paired with a number of bullet points, which summarise key aspects of an article. Based on the fact that these summary points are abstractive and do not simply copy sentences from a news article, the corpus is constructed by transforming these bullet points into cloze-style questions, i.e., replacing one entity with a placeholder."
P19-1075,W18-2605,0,0.0416042,"ed Work Recently, machine reading comprehension has been advanced by many corpora with various task settings. For instance, CNN/Daily Mail (Hermann et al., 2015) collects news articles and uses the cloze test (Taylor, 1953) to assess the ability of reading comprehension in English. RACE (Lai et al., 2017) and CLOTH (Xie et al., 2018) are constructed from questions in examinations designed for secondary and high school students. A number of question-answer datasets (Rajpurkar et al., 2016; Reddy et al., 2018) are also proposed and there are many other large-scale datasets (Nguyen et al., 2016; He et al., 2018). These corpora inspire various neural models (Chen et al., 2016; Cui et al., 2016; Seo et al., 2017; Dhingra et al., 2017; Cui et al., 2017). In Table 3, we present a survey on existing cloze-style reading comprehension datasets. As the earliest cloze-style dataset for machine reading comprehension, CNN/Daily Mail (Hermann et al., 2015) has a very large scale. It collects news articles paired with a number of bullet points, which summarise key aspects of an article. Based on the fact that these summary points are abstractive and do not simply copy sentences from a news article, the corpus is"
P19-1075,W15-0903,0,0.0219302,"ry. LAMBADA (Paperno et al., 2016) removed the last word from a given passage and evaluates the ability of word prediction. By contrast, the Story Cloze Test dataset (Mostafazadeh et al., 2017) evaluates the ability of story understanding and script learning, where the task requires to select or generate a reasonable sentence to complete the story context. Many idioms are non-compositional and have metaphorical meanings (see an example in Table 1), which has also made idiom translation a challenging problem and attracted considerable research attentions (Anastasiou, 2010; Salton et al., 2014; Cap et al., 2015; Shao et al., 2017). The meaning of such idioms is generally different from the literal meanings of the constituent characters. Such idioms are usually originated from ancient cultural stories, but the meaning is reserved along the long history of language use. For instance, “塞 翁失马” has a metaphorical meaning, which is derived from this story: Near China’s northern borders lived an old man who bred many horses. One day, one of his horses, for no reason at all, escaped into the territory of the northern tribes. Everyone commiserated with him. “Perhaps this will soon turn out to be a blessing,”"
P19-1075,P16-1223,0,0.0675801,"Missing"
P19-1075,P17-1055,0,0.0255976,"Hermann et al., 2015) collects news articles and uses the cloze test (Taylor, 1953) to assess the ability of reading comprehension in English. RACE (Lai et al., 2017) and CLOTH (Xie et al., 2018) are constructed from questions in examinations designed for secondary and high school students. A number of question-answer datasets (Rajpurkar et al., 2016; Reddy et al., 2018) are also proposed and there are many other large-scale datasets (Nguyen et al., 2016; He et al., 2018). These corpora inspire various neural models (Chen et al., 2016; Cui et al., 2016; Seo et al., 2017; Dhingra et al., 2017; Cui et al., 2017). In Table 3, we present a survey on existing cloze-style reading comprehension datasets. As the earliest cloze-style dataset for machine reading comprehension, CNN/Daily Mail (Hermann et al., 2015) has a very large scale. It collects news articles paired with a number of bullet points, which summarise key aspects of an article. Based on the fact that these summary points are abstractive and do not simply copy sentences from a news article, the corpus is constructed by transforming these bullet points into cloze-style questions, i.e., replacing one entity with a placeholder. Children’s Book Te"
P19-1075,D17-1082,0,0.0833213,"l strategies of selecting candidate idioms. We evaluate several stateof-the-art models on the proposed corpus with different representations of idioms. Results show that machine performs much worse than human, which indicates a large room for further research. Our contributions are summarized as follows: Related Work Recently, machine reading comprehension has been advanced by many corpora with various task settings. For instance, CNN/Daily Mail (Hermann et al., 2015) collects news articles and uses the cloze test (Taylor, 1953) to assess the ability of reading comprehension in English. RACE (Lai et al., 2017) and CLOTH (Xie et al., 2018) are constructed from questions in examinations designed for secondary and high school students. A number of question-answer datasets (Rajpurkar et al., 2016; Reddy et al., 2018) are also proposed and there are many other large-scale datasets (Nguyen et al., 2016; He et al., 2018). These corpora inspire various neural models (Chen et al., 2016; Cui et al., 2016; Seo et al., 2017; Dhingra et al., 2017; Cui et al., 2017). In Table 3, we present a survey on existing cloze-style reading comprehension datasets. As the earliest cloze-style dataset for machine reading com"
P19-1075,N18-2028,0,0.0507912,"m options. Firstly, we noted that both human and models achieve worse performance on Test than on Ran, while the accuracy on Sim is even lower than Test, which indicates that including more similar candidate idioms makes the task more difficult. Secondly, the inter-annotator agreement on Ran (Fleiss’ kappa=0.953) is much higher than those (9) Implementation Details All the models were implemented with Tensorflow (Abadi et al., 2016). We employed the Jieba Chinese word segmenter6 to tokenize passages. We set the vocabulary size to 100K and used the 200dimensional word embeddings initialized by Song et al. (2018). Those word embeddings that were not matched in Song et al. (2018) were initialized from a uniform distribution between (-0.1, 0.1). We applied a dropout rate of 0.5 on word embeddings. The number of hidden units of RNN cells were all set to 100. The cross entropy cost function is used to compute the training loss. ADAM (Kingma and Ba, 2015) was used to optimize all the models with the initial learning rate to 0.001 and the gradient was clipped when the norm of the gradient was larger than 5. We set the batch size to 32. The training was stopped when the accuracy on Dev did not improve within"
P19-1075,D18-1257,0,0.364654,"or instance, CNN/Daily Mail (Hermann et al., 2015) provides a benchmark for machine comprehension of English text, while the People Daily and Children’s Fairy Tale dataset (Cui et al., 2016) and CMRC2017 (Cui et al., 2018) pioneer explorations in Chinese language. In this paper we explore idiom comprehension (Wray, 2002; Jackendoff and Jackendoff, 2002; Cacciari and Tabossi, 2014; Jiang et al., 2018) in cloze test. Idiom , which is called “成 语” (chengyu) in Chinese, is an interesting linguistic phenomena in Chinese language, and this work is in parallel to several datasets (Hill et al., 2016; Xie et al., 2018) that have considered different language phenomena in English. Compared to other types of words, many idioms are unique for their non-compositionality and metaphorical meaning (see an example in Table 1). This feature requires a good representation of idiom. Meanwhile, the characteristic of near-synonym, i.e., words that have similar but not identical meanings (see an example in Table 2), may challenge a machine to choose an accurate idiom in a given context. Due to the fact that idioms are widely used in daily communication and in various literary genres, it is a new challenge to assess the a"
P19-1075,D16-1241,0,0.042781,"rt models. Results show that the performance of these models is substantially worse than that of human. • ChID provides a benchmark to evaluate the ability of understanding idioms, a unique yet common language phenomenon in Chinese. To our knowledge, this is the first work where this linguistic phenomenon is studied in the form of machine reading comprehension. 779 3.1 while the key differences from CNN/Daily Mail include: a list of candidate choices is provided for each query, and more types of words are removed, including named entities, (common) nouns, verbs and prepositions. Who-did-What (Onishi et al., 2016) collects its corpus from news and provides options for questions similar to CBT. Each question is formed from two independent articles: an article is treated as context to be read and a separate article on the same event is used to form the query. LAMBADA (Paperno et al., 2016) removed the last word from a given passage and evaluates the ability of word prediction. By contrast, the Story Cloze Test dataset (Mostafazadeh et al., 2017) evaluates the ability of story understanding and script learning, where the task requires to select or generate a reasonable sentence to complete the story conte"
P19-1075,P16-1144,0,0.0442349,"e this linguistic phenomenon is studied in the form of machine reading comprehension. 779 3.1 while the key differences from CNN/Daily Mail include: a list of candidate choices is provided for each query, and more types of words are removed, including named entities, (common) nouns, verbs and prepositions. Who-did-What (Onishi et al., 2016) collects its corpus from news and provides options for questions similar to CBT. Each question is formed from two independent articles: an article is treated as context to be read and a separate article on the same event is used to form the query. LAMBADA (Paperno et al., 2016) removed the last word from a given passage and evaluates the ability of word prediction. By contrast, the Story Cloze Test dataset (Mostafazadeh et al., 2017) evaluates the ability of story understanding and script learning, where the task requires to select or generate a reasonable sentence to complete the story context. Many idioms are non-compositional and have metaphorical meanings (see an example in Table 1), which has also made idiom translation a challenging problem and attracted considerable research attentions (Anastasiou, 2010; Salton et al., 2014; Cap et al., 2015; Shao et al., 201"
P19-1075,D16-1264,0,0.0606877,"forms much worse than human, which indicates a large room for further research. Our contributions are summarized as follows: Related Work Recently, machine reading comprehension has been advanced by many corpora with various task settings. For instance, CNN/Daily Mail (Hermann et al., 2015) collects news articles and uses the cloze test (Taylor, 1953) to assess the ability of reading comprehension in English. RACE (Lai et al., 2017) and CLOTH (Xie et al., 2018) are constructed from questions in examinations designed for secondary and high school students. A number of question-answer datasets (Rajpurkar et al., 2016; Reddy et al., 2018) are also proposed and there are many other large-scale datasets (Nguyen et al., 2016; He et al., 2018). These corpora inspire various neural models (Chen et al., 2016; Cui et al., 2016; Seo et al., 2017; Dhingra et al., 2017; Cui et al., 2017). In Table 3, we present a survey on existing cloze-style reading comprehension datasets. As the earliest cloze-style dataset for machine reading comprehension, CNN/Daily Mail (Hermann et al., 2015) has a very large scale. It collects news articles paired with a number of bullet points, which summarise key aspects of an article. Base"
P19-1075,W14-0806,0,0.0207249,"used to form the query. LAMBADA (Paperno et al., 2016) removed the last word from a given passage and evaluates the ability of word prediction. By contrast, the Story Cloze Test dataset (Mostafazadeh et al., 2017) evaluates the ability of story understanding and script learning, where the task requires to select or generate a reasonable sentence to complete the story context. Many idioms are non-compositional and have metaphorical meanings (see an example in Table 1), which has also made idiom translation a challenging problem and attracted considerable research attentions (Anastasiou, 2010; Salton et al., 2014; Cap et al., 2015; Shao et al., 2017). The meaning of such idioms is generally different from the literal meanings of the constituent characters. Such idioms are usually originated from ancient cultural stories, but the meaning is reserved along the long history of language use. For instance, “塞 翁失马” has a metaphorical meaning, which is derived from this story: Near China’s northern borders lived an old man who bred many horses. One day, one of his horses, for no reason at all, escaped into the territory of the northern tribes. Everyone commiserated with him. “Perhaps this will soon turn out"
P19-1075,W17-0906,0,\N,Missing
P19-1075,W18-0516,0,\N,Missing
P19-3011,D18-1547,0,0.0887227,"Missing"
P19-3011,P17-1163,0,0.058692,"Missing"
P19-3011,D17-1237,1,0.931587,"prior studies, it is been impractical to perform a rigorous comparative study under the same condition. ConvLab is the first dialog research platform that covers a full range of trainable statistical models with fully annotated datasets, differing from previous toolkits whose focus is largely concentrated on the system policy component while other components are mostly limited to pre-fixed baseline models (Ultes, 2017; Miller et al., 2017; Li et al., 2018). There is also an increasing interest in building bots that seamlessly intertwine multiple subdomains to accomplish high-level user goals (Peng et al., 2017; Budzianowski et al., 2018). The development of multi-domain dialog system adds additional complexities to both data collection and annotation, and the models for dialog system components. For the former, Budzianowski et al. (2018) collected the MultiWOZ dataset, a dialog corpus with dialogs ranging over multiple domains for the trip information setting, whereas there is no open-platform yet that is designed to handle multi-domain, multi-intent phenomena. To foster multi-domain dialog research, ConvLab features the MultiWOZ task and offers a complete set of reference models ranging from indiv"
P19-3011,P18-2069,0,0.0841428,"Missing"
P19-3011,P07-2045,0,0.00643389,"Missing"
P19-3011,N07-2038,0,0.54107,"Understanding For natural language understanding, ConvLab provides three reference models: Semantic Tuple Classifier (STC) (Mairesse et al., 2009), OneNet (Kim et al., 2017) and Multi-intent LU (MILU). STC can handle multi-domain, multi-intent dialog acts but cannot detect out-of-vocabulary (OOV) values. While OneNet can capture OOVs, it cannot handle multi-intent dialog acts. Thus, ConvLab offers a new MILU model which extends OneNet to process multi-intent dialog acts. For more details on MILU, please refer to the ConvLab site. User Policy For user policy, ConvLab provides an agenda-based (Schatzmann et al., 2007) user model and data-driven approaches such as HUS and its variational variants (Gur et al., 2018). Similar to the system side, each model works at the dialog act level, and can be pipelined with NLU and NLG modules to construct a whole user simulator. Dialog State Tracking The dialog state tracker is responsible for updating the belief state. ConvLab provides a rule-based tracker similar to the baselines in DSTCs (Williams et al., 2013) that are adapted to handle multi-domain interactions. End-to-end Model ConvLab makes available two end-to-end dialog system models: Mem2Seq (Madotto et al., 2"
P19-3011,W18-5007,0,0.0124046,"slight modifications in the configuration file. Some example configuration files are presented in Section 4. 2.2 Figure 3: An environment configuration view. As shown in Figure 3, there are also many different ways of combining components to build an environment. For example, the top layer corresponds to a user simulator operating at the dialog act level which is the typical setting of prior works focusing on developing reinforcement learning methods for dialog policy optimization. As with dialog agent, there are recent attempts on end-toend approaches to avoid requiring expensive annotation (Kreyssig et al., 2018). For human evaluation, ConvLab also provides an integration of crowd source platform such as Amazon Mechanical Turk3 as shown in the bottom layer. Dialog Agent Configuration 2.4 Reference Models This section describes a set of reference models for each component that are available in the initial release. As we will keep adding new state-of-theart models, the set of reference models available in ConvLab will be extended. Figure 2: A dialog system configuration view. In Figure 2, each layer represents a different way of constructing a dialog system. The top 2 Environment Configuration 3 ConvLab"
P19-3011,P18-1133,0,0.0586765,"-driven approaches such as HUS and its variational variants (Gur et al., 2018). Similar to the system side, each model works at the dialog act level, and can be pipelined with NLU and NLG modules to construct a whole user simulator. Dialog State Tracking The dialog state tracker is responsible for updating the belief state. ConvLab provides a rule-based tracker similar to the baselines in DSTCs (Williams et al., 2013) that are adapted to handle multi-domain interactions. End-to-end Model ConvLab makes available two end-to-end dialog system models: Mem2Seq (Madotto et al., 2018) and Sequicity (Lei et al., 2018). To support multi-domain intents, Sequicity resets the belief span when the model predicts a topic shift between domains. Word-level Dialog State Tracking Word-level DSTs directly take system and user natural language as inputs and update dialog state. ConvLab imports MDBT (Ramadan et al., 2018) model which jointly identifies the domain and tracks the belief states by utilizing the semantic similarity between dialog utterances and ontology terms. 3 Domains The initial release of ConvLab offers two domains of differing complexity: MultiWOZ and Movie. MultiWOZ The main task of the MultiWOZ doma"
P19-3011,P17-4013,0,0.21599,"Missing"
P19-3011,P18-1136,0,0.0410831,"ann et al., 2007) user model and data-driven approaches such as HUS and its variational variants (Gur et al., 2018). Similar to the system side, each model works at the dialog act level, and can be pipelined with NLU and NLG modules to construct a whole user simulator. Dialog State Tracking The dialog state tracker is responsible for updating the belief state. ConvLab provides a rule-based tracker similar to the baselines in DSTCs (Williams et al., 2013) that are adapted to handle multi-domain interactions. End-to-end Model ConvLab makes available two end-to-end dialog system models: Mem2Seq (Madotto et al., 2018) and Sequicity (Lei et al., 2018). To support multi-domain intents, Sequicity resets the belief span when the model predicts a topic shift between domains. Word-level Dialog State Tracking Word-level DSTs directly take system and user natural language as inputs and update dialog state. ConvLab imports MDBT (Ramadan et al., 2018) model which jointly identifies the domain and tracks the belief states by utilizing the semantic similarity between dialog utterances and ontology terms. 3 Domains The initial release of ConvLab offers two domains of differing complexity: MultiWOZ and Movie. MultiWOZ T"
P19-3011,D15-1199,0,0.116547,"Missing"
P19-3011,P14-5010,0,0.00241576,"m who is new to the area to quickly develop a reasonable baseline system for task-oriented dialog due to the lack of a well-structured, easy-to-use open-source system that allows researchers to build and evaluate dialog bots. ConvLab is aimed to fill the gap. ConvLab is an open-source multi-domain end-toend dialog system that allows researchers to automatically train dialog models, build and evaluate task-completion dialog bots. Such open-source systems have been instrumental in many AI research breakthroughs. For example, among many, Moses (Koehn, 2007), HTK (Young et al., 2002) and CoreNLP (Manning et al., 2014) have been widely used to facilitate subsequent research in machine translation, speech recognition and natural language processing, respectively. ConvLab consists of a rich set of modeling tools and runtime engines for building task-oriented bots of different types, and an end-to-end evaluation platform. There are roughly two architectures 64 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 64–69 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics Agents-Environments-Bodies (AEB) desig"
P19-3011,W13-4065,0,0.021667,"process multi-intent dialog acts. For more details on MILU, please refer to the ConvLab site. User Policy For user policy, ConvLab provides an agenda-based (Schatzmann et al., 2007) user model and data-driven approaches such as HUS and its variational variants (Gur et al., 2018). Similar to the system side, each model works at the dialog act level, and can be pipelined with NLU and NLG modules to construct a whole user simulator. Dialog State Tracking The dialog state tracker is responsible for updating the belief state. ConvLab provides a rule-based tracker similar to the baselines in DSTCs (Williams et al., 2013) that are adapted to handle multi-domain interactions. End-to-end Model ConvLab makes available two end-to-end dialog system models: Mem2Seq (Madotto et al., 2018) and Sequicity (Lei et al., 2018). To support multi-domain intents, Sequicity resets the belief span when the model predicts a topic shift between domains. Word-level Dialog State Tracking Word-level DSTs directly take system and user natural language as inputs and update dialog state. ConvLab imports MDBT (Ramadan et al., 2018) model which jointly identifies the domain and tracks the belief states by utilizing the semantic similarit"
P19-3011,D17-2014,0,0.0321439,"n down the pipeline. There also have emerged some models in-between (Wen et al., 2016; Mrkˇsi´c et al., 2016). Due to the wide range of approaches and different metrics used in prior studies, it is been impractical to perform a rigorous comparative study under the same condition. ConvLab is the first dialog research platform that covers a full range of trainable statistical models with fully annotated datasets, differing from previous toolkits whose focus is largely concentrated on the system policy component while other components are mostly limited to pre-fixed baseline models (Ultes, 2017; Miller et al., 2017; Li et al., 2018). There is also an increasing interest in building bots that seamlessly intertwine multiple subdomains to accomplish high-level user goals (Peng et al., 2017; Budzianowski et al., 2018). The development of multi-domain dialog system adds additional complexities to both data collection and annotation, and the models for dialog system components. For the former, Budzianowski et al. (2018) collected the MultiWOZ dataset, a dialog corpus with dialogs ranging over multiple domains for the trip information setting, whereas there is no open-platform yet that is designed to handle mu"
W04-1204,J95-4004,0,0.212793,"Missing"
W09-1312,W97-0702,0,0.0923059,"c evaluation by measuring the amount of overlap between the machine-selected sentences and human-written summaries. Our metric for the evaluation was ROUGE 1 , a widely used intrinsic summarization evaluation metric. 2 Related Work Summarization systems aim to extract salient text fragments, especially sentences, from the original documents to form a summary. A number of methods for sentence scoring and ranking have been developed. Approaches based on sentence position (Edmundson, 1969), cue phrase (McKeown and Radev, 1995), word frequency (Teufel and Moens, 1997), and discourse segmentation (Boguraev and Kennedy, 1997) have been reported. Radev et al. (Radev et al., 2004) developed an extractive multidocument summarizer, MEAD, which extracts a summary from multiple documents based on the document cluster centroid, position and firstsentence overlap. Recently, graph-based ranking methods, such as LexPageRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004), 1 http://haydn.isi.edu/ROUGE/ 98 have been proposed for multi-document summarization. Similar to the original PageRank algorithm, these methods make use of similarity relationships between sentences and then rank sentences according to the"
W09-1312,W04-3247,0,0.248938,"by this gene is a receptor for interleukin 20 (IL20), a cytokine that may be involved in epidermal function. The receptor of IL20 is a heterodimeric receptor complex consisting of this protein and interleukin 20 receptor beta (IL20B). This gene and IL20B are highly expressed in skin. The expression of both genes is found to be upregulated in Psoriasis. Table1. Two examples of human-written gene summaries not include enough informative words for gene summaries. Next, the remaining sentences are ranked by the sum of two individual scores: a) an authority score from a lexical PageRank algorithm (Erkan and Radev, 2004) and b) a similarity score between the sentence and the Gene Ontology (GO) terms with which the gene is annotated (To date, over 190,000 genes have two or more associated GO terms). Finally, redundant sentences are removed and top ranked sentences are nominated for the target gene. In order to evaluate our system, we assembled a gold standard dataset consisting of handwritten summaries for 7,294 human genes and conducted an intrinsic evaluation by measuring the amount of overlap between the machine-selected sentences and human-written summaries. Our metric for the evaluation was ROUGE 1 , a wi"
W09-1312,P07-2049,0,0.272715,"Missing"
W09-1312,C00-1072,0,0.448319,"d an extractive multidocument summarizer, MEAD, which extracts a summary from multiple documents based on the document cluster centroid, position and firstsentence overlap. Recently, graph-based ranking methods, such as LexPageRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004), 1 http://haydn.isi.edu/ROUGE/ 98 have been proposed for multi-document summarization. Similar to the original PageRank algorithm, these methods make use of similarity relationships between sentences and then rank sentences according to the “votes” or “recommendations” from their neighboring sentences. Lin and Hovy (2000) first introduced topic signatures which are topic relevant terms for summarization. Afterwards, this technique was successfully used in a number of summarization systems (Hickl et al., 2007, Gupta and Nenkova et al., 2007). In order to improve sentence selection, we adopted the idea in a similar way to identify terms that tend to appear frequently in gene summaries and subsequently filter sentences that include none or few such terms. Compared with newswire document summarization, much less attention has been paid to summarizing MEDLINE documents for genic information. Ling et al. (Ling et al"
W09-1312,N03-1020,0,0.0890458,"with a preexisting handwritten summary downloaded from the NCBI’s FTP site5. The handwritten summaries were used as reference summaries (i.e. a gold standard) to compare with the automatically generated summaries. Although the length of reference summaries varies, the majority of these summaries contain 80 to 120 words. To produce a summary of similar length, we decided to select five sentences consisting of about 100 words. For the intrinsic evaluation of a large number of summaries, we made use of the ROUGE metrics that has been widely used in automatic evaluation of summarization systems (Lin and Hovy, 2003; Hickl et al., 2007). It provides a set of evaluation metrics to measure the quality of a summary by counting overlapping units such as n-grams or word sequences between the generated summary and its reference summary. 5 102 Evaluation Metrics ftp://ftp.ncbi.nih.gov/gene/DATA/ASN_BINARY/ We computed three ROUGE measures for each summary, namely ROUGE-1 (unigram based), ROUGE-2 (bigram based) and ROUGE-SU4 (skip-bigram and unigram) (Lin and Hovy, 2003). Among them, ROUGE-1 has been shown to agree most with human judgments (Lin and Hovy, 2003). However, as biomedical concepts usually contain mo"
W09-1312,W04-3252,0,\N,Missing
W10-1902,P08-1081,1,0.838227,"2) improving matching 11 to enhance the recall. Finkel et al. (2005) used Gibbs Sampling to add non-local dependencies into linear-chain CRF model for information extraction. However, the CRF models used in these systems were all linear-chain CRFs. To the best of our knowledge, no previous work has been done on using non-linear-chain CRF in the biomedical NER task. Beyond the biomedical domain, skip-chain CRF has been used in several studies to model long distance dependency. In (Galley, 2006), skip edges were linked between sentences with nonlocal pragmatic dependencies to rank meetings. In (Ding et al., 2008), skip-chain CRF was used to detect the context and answers from online forums. The most close work to ours was in (Sutton and McCallum, 2004), which used skip-chain CRF to extract information from email messages announcing seminars. By linking the same words whose initial letter is capital, the method obtained improvements on extracting speakers’ name. Our work is in the spirit of this idea, but we approach it in a different way. We found that the problem is much more difficult in the biomedical NER task: that is why we systematically studied the principles of linking skip edges and the quali"
W10-1902,P05-1045,0,0.0502115,"rom the two directions. Huang et al. (2007) combines a linear-chain CRF and two SVM models Related work NER is a widely studied topic in text mining research, and many new challenges are seen in domain-specific applications, such as biomedical NER (Zhou et al., 2004). The dictionary based method is a common technique as biomedical thesauruses play a key role in understanding such text. Most dictionary based NER systems focused on: (1) integrating and normalizing different biomedical databases to improve the quality of the dictionary to be used; (2) improving matching 11 to enhance the recall. Finkel et al. (2005) used Gibbs Sampling to add non-local dependencies into linear-chain CRF model for information extraction. However, the CRF models used in these systems were all linear-chain CRFs. To the best of our knowledge, no previous work has been done on using non-linear-chain CRF in the biomedical NER task. Beyond the biomedical domain, skip-chain CRF has been used in several studies to model long distance dependency. In (Galley, 2006), skip edges were linked between sentences with nonlocal pragmatic dependencies to rank meetings. In (Ding et al., 2008), skip-chain CRF was used to detect the context an"
W10-1902,N03-1028,0,0.0606232,"Department of Computer Science and Technology Tsinghua University, Beijing 100084, China liu-jc04@mails.tsinghua.edu.cn {aihuang, zxy-dcs}@tsinghua.edu.cn 2004 and BioCreAtIvE II in 20062 . The overview reports from these competitions, presenting stateof-the-art of biomedical NER studies, show that linear-chain Conditional Random Fields (CRF) is one of the most commonly used models and has the most competitive results (Yeh et al., 2005; Smith et al., 2008). Linear-chain CRF has also been successfully applied to other NLP tasks such as POS-tagging (Lafferty et al., 2001) and sentence chunking (Sha and Pereira, 2003). However, in most of these applications, only linear-chain CRF was fully exploited, assuming that only adjacent words are inter-dependent. The dependency between distant words, which occurs frequently in the biomedical literature, is yet to be captured. In the biomedical literature, the repeated appearance of same or similar words in one sentence is a common type of long distance dependencies. This phenomenon is due to the complicated syntactic structures and the various biomedical terminologies in nature. See the following example: Abstract Linear-chain Conditional Random Fields (CRF) has be"
W10-1902,W06-1643,0,\N,Missing
W10-1902,W02-0301,0,\N,Missing
