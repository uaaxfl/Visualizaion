2021.sigdial-1.32,Rare-Class Dialogue Act Tagging for {A}lzheimer{'}s Disease Diagnosis,2021,-1,-1,3,0,1529,shamila nasreen,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Alzheimer{'}s Disease (AD) is associated with many characteristic changes, not only in an individual{'}s language but also in the interactive patterns observed in dialogue. The most indicative changes of this latter kind tend to be associated with relatively rare dialogue acts (DAs), such as those involved in clarification exchanges and responses to particular kinds of questions. However, most existing work in DA tagging focuses on improving average performance, effectively prioritizing more frequent classes; it thus gives a poor performance on these rarer classes and is not suited for application to AD analysis. In this paper, we investigate tagging specifically for rare class DAs, using a hierarchical BiLSTM model with various ways of incorporating information from previous utterances and DA tags in context. We show that this can give good performance for rare DA classes on both the general Switchboard corpus (SwDA) and an AD-specific conversational dataset, the Carolinas Conversation Collection (CCC); and that the tagger outputs then contribute useful information for distinguishing patients with and without AD"
2021.sigdial-1.56,Mitigating Topic Bias when Detecting Decisions in Dialogue,2021,-1,-1,4,0,1116,mladen karan,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This work revisits the task of detecting decision-related utterances in multi-party dialogue. We explore performance of a traditional approach and a deep learning-based approach based on transformer language models, with the latter providing modest improvements. We then analyze topic bias in the models using topic information obtained by manual annotation. Our finding is that when detecting some types of decisions in our data, models rely more on topic specific words that decisions are about rather than on words that more generally indicate decision making. We further explore this by removing topic information from the train data. We show that this resolves the bias issues to an extent and, surprisingly, sometimes even boosts performance."
2021.reinact-1.4,Communicative Grounding of Analogical Explanations in Dialogue: A Corpus Study of Conversational Management Acts and Statistical Sequence Models for Tutoring through Analogy,2021,-1,-1,3,0,2546,jorge delbosquetrevino,Proceedings of the Reasoning and Interaction Conference (ReInAct 2021),0,"We present a conversational management act (CMA) annotation schema for one-to-one tutorial dialogue sessions where a tutor uses an analogy to teach a student a concept. CMAs are more fine-grained sub-utterance acts compared to traditional dialogue act mark-up. The schema achieves an inter-annotator agreement (IAA) Cohen Kappa score of at least 0.66 across all 10 classes. We annotate a corpus of analogical episodes with the schema and develop statistical sequence models from the corpus which predict tutor content related decisions, in terms of the selection of the analogical component (AC) and tutor conversational management act (TCMA) to deploy at the current utterance, given the student{'}s behaviour. CRF sequence classifiers perform well on AC selection and robustly on TCMA selection, achieving respective accuracies of 61.9{\%} and 56.3{\%} on a cross-validation experiment over the corpus."
2021.hackashop-1.5,Zero-shot Cross-lingual Content Filtering: Offensive Language and Hate Speech Detection,2021,-1,-1,5,0,6078,andravz pelicon,Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation,0,We present a system for zero-shot cross-lingual offensive language and hate speech classification. The system was trained on English datasets and tested on a task of detecting hate speech and offensive social media content in a number of languages without any additional training. Experiments show an impressive ability of both models to generalize from English to other languages. There is however an expected gap in performance between the tested cross-lingual models and the monolingual models. The best performing model (offensive content classifier) is available online as a REST API.
2021.hackashop-1.14,"{EMBEDDIA} Tools, Datasets and Challenges: Resources and Hackathon Contributions",2021,-1,-1,3,0,6075,senja pollak,Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation,0,"This paper presents tools and data sources collected and released by the EMBEDDIA project, supported by the European Union{'}s Horizon 2020 research and innovation program. The collected resources were offered to participants of a hackathon organized as part of the EACL Hackashop on News Media Content Analysis and Automated Report Generation in February 2021. The hackathon had six participating teams who addressed different challenges, either from the list of proposed challenges or their own news-industry-related tasks. This paper goes beyond the scope of the hackathon, as it brings together in a coherent and compact form most of the resources developed, collected and released by the EMBEDDIA project. Moreover, it constitutes a handy source for news media industry and researchers in the fields of Natural Language Processing and Social Science."
2021.findings-emnlp.174,Natural {SQL}: Making {SQL} Easier to Infer from Natural Language Specifications,2021,-1,-1,4,1,6868,yujian gan,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Addressing the mismatch between natural language descriptions and the corresponding SQL queries is a key challenge for text-to-SQL translation. To bridge this gap, we propose an SQL intermediate representation (IR) called Natural SQL (NatSQL). Specifically, NatSQL preserves the core functionalities of SQL, while it simplifies the queries as follows: (1) dispensing with operators and keywords such as GROUP BY, HAVING, FROM, JOIN ON, which are usually hard to find counterparts in the text descriptions; (2) removing the need of nested subqueries and set operators; and (3) making the schema linking easier by reducing the required number of schema items. On Spider, a challenging text-to-SQL benchmark that contains complex and nested SQL queries, we demonstrate that NatSQL outperforms other IRs, and significantly improves the performance of several previous SOTA models. Furthermore, for existing models that do not support executable SQL generation, NatSQL easily enables them to generate executable SQL queries, and achieves the new state-of-the-art execution accuracy."
2021.emnlp-main.702,Exploring Underexplored Limitations of Cross-Domain Text-to-{SQL} Generalization,2021,-1,-1,3,1,6868,yujian gan,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Recently, there has been significant progress in studying neural networks for translating text descriptions into SQL queries under the zero-shot cross-domain setting. Despite achieving good performance on some public benchmarks, we observe that existing text-to-SQL models do not generalize when facing domain knowledge that does not frequently appear in the training data, which may render the worse prediction performance for unseen domains. In this work, we investigate the robustness of text-to-SQL models when the questions require rarely observed domain knowledge. In particular, we define five types of domain knowledge and introduce Spider-DK (DK is the abbreviation of domain knowledge), a human-curated dataset based on the Spider benchmark for text-to-SQL translation. NL questions in Spider-DK are selected from Spider, and we modify some samples by adding domain knowledge that reflects real-world question paraphrases. We demonstrate that the prediction accuracy dramatically drops on samples that require such domain knowledge, even if the domain knowledge appears in the training set, and the model provides the correct predictions for related training samples."
2021.acl-long.195,Towards Robustness of Text-to-{SQL} Models against Synonym Substitution,2021,-1,-1,4,1,6868,yujian gan,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Recently, there has been significant progress in studying neural networks to translate text descriptions into SQL queries. Despite achieving good performance on some public benchmarks, existing text-to-SQL models typically rely on the lexical matching between words in natural language (NL) questions and tokens in table schemas, which may render the models vulnerable to attacks that break the schema linking mechanism. In this work, we investigate the robustness of text-to-SQL models to synonym substitution. In particular, we introduce Spider-Syn, a human-curated dataset based on the Spider benchmark for text-to-SQL translation. NL questions in Spider-Syn are modified from Spider, by replacing their schema-related words with manually selected synonyms that reflect real-world question paraphrases. We observe that the accuracy dramatically drops by eliminating such explicit correspondence between NL questions and table schemas, even if the synonyms are not adversarially selected to conduct worst-case attacks. Finally, we present two categories of approaches to improve the model robustness. The first category of approaches utilizes additional synonym annotations for table schemas by modifying the model input, while the second category is based on adversarial training. We demonstrate that both categories of approaches significantly outperform their counterparts without the defense, and the first category of approaches are more effective."
2020.tacl-1.20,How Furiously Can Colorless Green Ideas Sleep? Sentence Acceptability in Context,2020,49,1,4,0,3097,jey lau,Transactions of the Association for Computational Linguistics,0,"We study the influence of context on sentence acceptability. First we compare the acceptability ratings of sentences judged in isolation, with a relevant context, and with an irrelevant context. Our results show that context induces a cognitive load for humans, which compresses the distribution of ratings. Moreover, in relevant contexts we observe a discourse coherence effect that uniformly raises acceptability. Next, we test unidirectional and bidirectional language models in their ability to predict acceptability ratings. The bidirectional models show very promising results, with the best model achieving a new state-of-the-art for unsupervised acceptability prediction. The two sets of experiments provide insights into the cognitive aspects of sentence processing and central issues in the computational modeling of text and discourse."
2020.semeval-1.3,{S}em{E}val-2020 Task 3: Graded Word Similarity in Context,2020,-1,-1,2,0,14408,carlos armendariz,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"This paper presents the Graded Word Similarity in Context (GWSC) task which asked participants to predict the effects of context on human perception of similarity in English, Croatian, Slovene and Finnish. We received 15 submissions and 11 system description papers. A new dataset (CoSimLex) was created for evaluation in this task: it contains pairs of words, each annotated within two different contexts. Systems beat the baselines by significant margins, but few did well in more than one language or subtask. Almost every system employed a Transformer model, but with many variations in the details: WordNet sense embeddings, translation of contexts, TF-IDF weightings, and the automatic creation of datasets for fine-tuning were all used to good effect."
2020.nlpcovid19-2.7,Temporal Mental Health Dynamics on Social Media,2020,-1,-1,2,0,16233,tom tabak,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"We describe a set of experiments for building a temporal mental health dynamics system. We utilise a pre-existing methodology for distant- supervision of mental health data mining from social media platforms and deploy the system during the global COVID-19 pandemic as a case study. Despite the challenging nature of the task, we produce encouraging results, both explicit to the global pandemic and implicit to a global phenomenon, Christmas Depres- sion, supported by the literature. We propose a methodology for providing insight into tem- poral mental health dynamics to be utilised for strategic decision-making."
2020.lrec-1.720,{C}o{S}im{L}ex: A Resource for Evaluating Graded Word Similarity in Context,2020,-1,-1,2,0,14408,carlos armendariz,Proceedings of the 12th Language Resources and Evaluation Conference,0,"State of the art natural language processing tools are built on context-dependent word embeddings, but no direct method for evaluating these representations currently exists. Standard tasks and datasets for intrinsic evaluation of embeddings are based on judgements of similarity, but ignore context; standard tasks for word sense disambiguation take account of context but do not provide continuous measures of meaning similarity. This paper describes an effort to build a new dataset, CoSimLex, intended to fill this gap. Building on the standard pairwise similarity task of SimLex-999, it provides context-dependent similarity measures; covers not only discrete differences in word sense but more subtle, graded changes in meaning; and covers not only a well-resourced language (English) but a number of less-resourced languages. We define the task and evaluation metrics, outline the dataset collection methodology, and describe the status of the dataset so far."
2020.aacl-srw.16,A Review of Cross-Domain Text-to-{SQL} Models,2020,-1,-1,2,1,6868,yujian gan,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop,0,"WikiSQL and Spider, the large-scale cross-domain text-to-SQL datasets, have attracted much attention from the research community. The leaderboards of WikiSQL and Spider show that many researchers propose their models trying to solve the text-to-SQL problem. This paper first divides the top models in these two leaderboards into two paradigms. We then present details not mentioned in their original paper by evaluating the key components, including schema linking, pretrained word embeddings, and reasoning assistance modules. Based on the analysis of these models, we want to promote understanding of the text-to-SQL field and find out some interesting future works, for example, it is worth studying the text-to-SQL problem in an environment where it is more challenging to build schema linking and also worth studying combing the advantage of each model toward text-to-SQL."
W17-6813,A Geometric Method for Detecting Semantic Coercion,2017,30,0,3,1,24875,stephen mcgregor,{IWCS} 2017 - 12th International Conference on Computational Semantics - Long papers,0,None
W17-4210,Incongruent Headlines: Yet Another Way to Mislead Your Readers,2017,20,9,4,0,31705,sophie chesney,Proceedings of the 2017 {EMNLP} Workshop: Natural Language Processing meets Journalism,0,"This paper discusses the problem of incongruent headlines: those which do not accurately represent the information contained in the article with which they occur. We emphasise that this phenomenon should be considered separately from recognised problematic headline types such as clickbait and sensationalism, arguing that existing natural language processing (NLP) methods applied to these related concepts are not appropriate for the automatic detection of headline incongruence, as an analysis beyond stylistic traits is necessary. We therefore suggest a number of alternative methodologies that may be appropriate to the task at hand as a foundation for future work in this area. In addition, we provide an analysis of existing data sets which are related to this work, and motivate the need for a novel data set in this domain."
W16-5508,Process Based Evaluation of Computer Generated Poetry,2016,10,3,2,1,24875,stephen mcgregor,Proceedings of the {INLG} 2016 Workshop on Computational Creativity in Natural Language Generation,0,None
P16-3009,Robust Co-occurrence Quantification for Lexical Distributional Semantics,2016,28,2,3,1,31909,dmitrijs milajevs,Proceedings of the {ACL} 2016 Student Research Workshop,0,"Previous optimisations of parameters affecting the word-context association measure used in distributional vector space models have focused either on highdimensional vectors with hundreds of thousands of dimensions, or dense vectors with dimensionality of a few hundreds; but dimensionality of a few thousands is often applied in compositional tasks as it is still computationally feasible and does not require the dimensionality reduction step. We present a systematic study of the interaction of the parameters of the association measure and vector dimensionality, and derive parameter selection heuristics that achieve performance across word similarity and relevance datasets competitive with the results previously reported in the literature achieved by highly dimensional or dense models."
W15-0130,Feedback in Conversation as Incremental Semantic Update,2015,32,24,5,1,2543,arash eshghi,Proceedings of the 11th International Conference on Computational Semantics,0,"In conversation, interlocutors routinely indicate whether something said or done has been processed and integrated. Such feedback includes backchannels such as xe2x80x98okayxe2x80x99 or xe2x80x98mhmxe2x80x99, the production of a next relevant turn, and repair initiation via clarification requests. Importantly, such feedback can be produced not only at sentence/turn boundaries, but also sub-sententially. In this paper, we extend an existing model of incremental semantic processing in dialogue, based around the Dynamic Syntax (DS) grammar framework, to provide a low-level, integrated account of backchannels, clarification requests and their responses; demonstrating that they can be accounted for as part of the core semantic structure-building mechanisms of the grammar, rather than via higher level pragmatic phenomena such as intention recognition, or treatment as an xe2x80x9cuno cialxe2x80x9d part of the conversation. The end result is an incremental model in which words, not turns, are seen as procedures for contextual update and backchannels serve to align participant semantic processing contexts and thus ease the production and interpretation of subsequent conversational actions. We also show how clarification requests and their following responses and repair can be modelled within the same DS framework, wherein the divergence and re-alignment e ort in participantsxe2x80x99 semantic processing drives conversations forward."
W14-5318,A Simple Baseline for Discriminating Similar Languages,2014,14,7,1,1,1531,matthew purver,"Proceedings of the First Workshop on Applying {NLP} Tools to Similar Languages, Varieties and Dialects",0,This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedingsn footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
W14-3202,Linguistic Indicators of Severity and Progress in Online Text-based Therapy for Depression,2014,-1,-1,2,1,2556,christine howes,Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,0,None
W14-1505,Investigating the Contribution of Distributional Semantic Information for Dialogue Act Classification,2014,24,16,2,1,31909,dmitrijs milajevs,Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality ({CVSC}),0,"This paper presents a series of experiments in applying compositional distributional semantic models to dialogue act classification. In contrast to the widely used bag-ofwords approach, we build the meaning of an utterance from its parts by composing the distributional word vectors using vector addition and multiplication. We investigate the contribution of word sequence, dialogue act sequence, and distributional information to the performance, and compare with the current state of the art approaches. Our experiment suggests that that distributional information is useful for dialogue act tagging but that simple models of compositionality fail to capture crucial information from word and utterance sequence; more advanced approaches (e.g. sequence- or grammar-driven, such as categorical, word vector composition) are required."
W14-1410,Probabilistic Type Theory for Incremental Dialogue Processing,2014,23,13,2,1,1530,julian hough,Proceedings of the {EACL} 2014 Workshop on Type Theory and Natural Language Semantics ({TTNLS}),0,"We present an adaptation of recent work on probabilistic Type Theory with Records (Cooper et al., 2014) for the purposes of modelling the incremental semantic processing of dialogue participants. After presenting the formalism and dialogue framework, we show how probabilistic TTR type judgements can be integrated into the inference system of an incremental dialogue system, and discuss how this could be used to guide parsing and dialogue management decisions."
D14-1009,Strongly Incremental Repair Detection,2014,26,6,2,1,1530,julian hough,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We present STIR (STrongly Incremental Repair detection), a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency. STIR uses information-theoretic measures from n-gram models as its principal decision features in a pipeline of classifiers detecting the different stages of repairs. Results on the Switchboard disfluency tagged corpus show utterance-final accuracy on a par with state-of-the-art incremental repair detection methods, but with better incremental accuracy, faster time-to-detection and less computational overhead. We evaluate its performance using incremental metrics and propose new repair processing evaluation standards."
D14-1079,Evaluating Neural Word Representations in Tensor-Based Compositional Settings,2014,40,38,4,1,31909,dmitrijs milajevs,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We provide a comparative study between neural word representations and traditional vector spaces based on cooccurrence counts, in a number of compositional tasks. We use three different semantic spaces and implement seven tensor-based compositional models, which we then test (together with simpler additive and multiplicative approaches) in tasks involving verb disambiguation and sentence similarity. To check their scalability, we additionally evaluate the spaces using simple compositional methods on larger-scale tasks with less constrained language: paraphrase detection and dialogue act tagging. In the more constrained tasks, co-occurrence vectors are competitive, although choice of compositional method is important; on the largerscale tasks, they are outperformed by neural word embeddings, which show robust, stable performance across the tasks."
W13-2611,Incremental Grammar Induction from Child-Directed Dialogue Utterances,2013,35,0,3,1,2543,arash eshghi,Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics ({CMCL}),0,"We describe a method for learning an incremental semantic grammar from data in which utterances are paired with logical forms representing their meaning. Working in an inherently incremental framework, Dynamic Syntax, we show how words can be associated with probabilistic procedures for the incremental projection of meaning, providing a grammar which can be used directly in incremental probabilistic parsing and generation. We test this on child-directed utterances from the CHILDES corpus, and show that it results in good coverage and semantic accuracy, without requiring annotation at the word level or any independent notion of syntax."
W13-0402,Investigating Topic Modelling for Therapy Dialogue Analysis,2013,-1,-1,2,1,2556,christine howes,Proceedings of the {IWCS} 2013 Workshop on Computational Semantics in Clinical Text ({CSCT} 2013),0,None
W13-0110,Probabilistic induction for an incremental semantic grammar,2013,23,5,2,1,2543,arash eshghi,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,"We describe a method for learning an incremental semantic grammar from a corpus in which sentences are paired with logical forms as predicate-argument structure trees. Working in the framework of Dynamic Syntax, and assuming a set of generally available compositional mechanisms, we show how lexical entries can be learned as probabilistic procedures for the incremental projection of semantic structure, providing a grammar suitable for use in an incremental probabilistic parser. By inducing these from a corpus generated using an existing grammar, we demonstrate that this results in both good coverage and compatibility with the original entries, without requiring annotation at the word level. We show that this semantic approach to grammar induction has the novel ability to learn the syntactic and semantic constraints on pronouns."
W12-1610,Predicting Adherence to Treatment for Schizophrenia from Dialogue Transcripts,2012,11,12,2,1,2556,christine howes,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Recent work on consultations between out-patients with schizophrenia and psychiatrists has shown that adherence to treatment can be predicted by patterns of repair -- specifically, the pro-activity of the patient in checking their understanding, i.e. patient clarification. Using machine learning techniques, we investigate whether this tendency can be predicted from high-level dialogue features, such as backchannels, overlap and each participant's proportion of talk. The results indicate that these features are not predictive of a patient's adherence to treatment or satisfaction with the communication, although they do have some association with symptoms. However, all these can be predicted if we allow features at the word level. These preliminary experiments indicate that patient adherence is predictable from dialogue transcripts, but further work is necessary to develop a meaningful, general and reliable feature set."
E12-1049,Experimenting with Distant Supervision for Emotion Classification,2012,19,113,1,1,1531,matthew purver,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We describe a set of experiments using automatically labelled data to train supervised classifiers for multi-class emotion detection in Twitter messages with no manual intervention. By cross-validating between models trained on different labellings for the same six basic emotion classes, and testing on manually labelled data, we conclude that the method is suitable for some emotions (happiness, sadness and anger) but less able to distinguish others; and that different labelling conventions are more suitable for some emotions than others."
W11-0144,Incremental Semantic Construction in a Dialogue System,2011,18,38,1,1,1531,matthew purver,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"This paper describes recent work on the DynDial project* towards incremental semantic interpretation in dialogue. We outline our domain-general grammar-based approach, using a variant of Dynamic Syntax integrated with Type Theory with Records and a Davidsonian event-based semantics. We describe a Java-based implementation of the parser, used within the Jindigo framework to produce an incremental dialogue system capable of handling inherently incremental phenomena such as split utterances, adjuncts, and mid-sentence clarification requests or backchannels."
W09-3937,Split Utterances in Dialogue: a Corpus Study,2009,23,28,1,1,1531,matthew purver,Proceedings of the {SIGDIAL} 2009 Conference,0,"This paper presents a preliminary English corpus study of split utterances (SUs), single utterances split between two or more dialogue turns or speakers. It has been suggested that SUs are a key phenomenon of dialogue, which this study confirms: almost 20% of utterances were found to fit this general definition, with nearly 3% being the between-speaker case most often studied. Other claims/assumptions in the literature about SUs' form and distribution are investigated, with preliminary results showing: splits can occur within syntactic constituents, apparently at any point in the string; it is unusual for the separate parts to be complete units in their own right; explicit repair of the antecedent does not occur very often. The theoretical consequences of these results for claims in the literature are pointed out. The practical implications for dialogue systems are mentioned too."
W09-3944,Cascaded Lexicalised Classifiers for Second-Person Reference Resolution,2009,8,11,1,1,1531,matthew purver,Proceedings of the {SIGDIAL} 2009 Conference,0,"This paper examines the resolution of the second person English pronoun you in multi-party dialogue. Following previous work, we attempt to classify instances as generic or referential, and in the latter case identify the singular or plural addressee. We show that accuracy and robustness can be improved by use of simple lexical features, capturing the intuition that different uses and addressees are associated with different vocabularies; and we show that there is an advantage to treating referentiality and addressee identification as separate (but connected) problems."
W08-0125,Modelling and Detecting Decisions in Multi-party Dialogue,2008,20,37,4,0,936,raquel fernandez,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"We describe a process for automatically detecting decision-making sub-dialogues in transcripts of multi-party, human-human meetings. Extending our previous work on action item identification, we propose a structured approach that takes into account the different roles utterances play in the decision-making process. We show that this structured approach outperforms the accuracy achieved by existing decision detection systems based on flat annotations, while enabling the extraction of more fine-grained information that can be used for summarization and reporting."
P07-2027,Disambiguating Between Generic and Referential {``}You{''} in Dialog,2007,13,16,2,0,49155,surabhi gupta,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,We describe an algorithm for a novel task: disambiguating the pronoun you in conversation. You can be generic or referential; finding referential you is important for tasks such as addressee identification or extracting 'owners' of action items. Our classifier achieves 84% accuracy in two-person conversations; an initial study shows promising performance even on more complex multi-party meetings.
N07-4012,A Conversational In-Car Dialog System,2007,3,7,8,0,46468,baoshi yan,Proceedings of Human Language Technologies: The Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics ({NAACL}-{HLT}),0,"In this demonstration we present a conversational dialog system for automobile drivers. The system provides a voice-based interface to playing music, finding restaurants, and navigating while driving. The design of the system as well as the new technologies developed will be presented. Our evaluation showed that the system is promising, achieving high task completion rate and good user satisfation."
2007.sigdial-1.4,Detecting and Summarizing Action Items in Multi-Party Dialogue,2007,35,44,1,1,1531,matthew purver,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"This paper addresses the problem of identifying action items discussed in open-domain conversational speech, and does so in two stages: firstly, detecting the subdialogues in which action items are proposed, discussed and committed to; and secondly, extracting the phrases that accurately capture or summarize the tasks they involve. While the detection problem is hard, we show that we can improve accuracy by taking account of dialogue structure. We then describe a semantic parser that identifies potential summarizing phrases, and show that for some task properties these can be more informative than plain utterance transcriptions."
2007.sigdial-1.17,{CHAT} to Your Destination,2007,21,18,11,0,40114,fuliang weng,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"In the past few years, we have been developing a robust, wide-coverage, and cognitive load-sensitive spoken dialog interface, CHAT (Conversational Helper for Automotive Tasks). New progress has been made to address issues related to dynamic and attention-demanding environments, such as driving. Specifically, we try to address imperfect input and imperfect memory issues through robust understanding, knowledge-based interpretation, flexible dialog management, sensible information communication, and user-adaptive responses. In addition to the MP3 player and restaurant finder applications reported in previous publications, a third domain, navigation, has been developed, where one has to deal with dynamic information, domain switch, and error recovery. Evaluation in the new domain has shown a good degree of success: including high task completion rate, dialog efficiency, and improved user experience."
2007.sigdial-1.40,Resolving {``}You{''} in Multi-Party Dialog,2007,11,20,3,0,49155,surabhi gupta,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"This paper presents experiments into the resolution of xe2x80x9cyouxe2x80x9d in multi-party dialog, dividing this process into two tasks: distinguishing between generic and referential uses; and then, for referential uses, identifying the referred-to addressee(s). On the first task we achieve an accuracy of 75% on multi-party data. We achieve an accuracy of 47% on determining the actual identity of the referent. All results are achieved without the use of visual information."
W06-3405,Shallow Discourse Structure for Action Item Detection,2006,13,8,1,1,1531,matthew purver,Proceedings of the Analyzing Conversations in Text and Speech,0,"We investigated automatic action item detection from transcripts of multi-party meetings. Unlike previous work (Gruenstein et al., 2005), we use a new hierarchical annotation scheme based on the roles utterances play in the action item assignment process, and propose an approach to automatic detection that promises improved classification accuracy while enabling the extraction of useful information for summarization and reporting."
P06-1003,Unsupervised Topic Modelling for Multi-Party Spoken Discourse,2006,20,119,1,1,1531,matthew purver,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present a method for unsupervised topic modelling which adapts methods used in document classification (Blei et al., 2003; Griffiths and Steyvers, 2004) to unsegmented multi-party discourse transcripts. We show how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification: automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods (Galley et al., 2003) while simultaneously extracting topics which rate highly when assessed for coherence by human judges. We also show that this method appears robust in the face of off-topic dialogue and speech recognition errors."
U05-1032,Combining Confidence Scores with Contextual Features for Robust Multi-Device Dialogue,2005,13,0,2,0,33533,lawrence cavedon,Proceedings of the Australasian Language Technology Workshop 2005,0,"We present an approach to multi-device dialogue that evaluates and selects amongst candidate dialogue moves based on features at multiple levels. Multiple sources of information can be combined, multiple speech recognition and parsing hypotheses tested, and multiple devices and moves considered to choose the highest scoring hypothesis overall. The approach has the added benefit of potentially re-ordering n-best lists of inputs, effectively correcting errors in speech recognition or parsing. A current application includes conversational interaction with a collection of in-car devices."
2005.sigdial-1.13,Meeting Structure Annotation: Data and Tools,2005,26,35,3,0,47779,alexander gruenstein,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,"We present a set of annotations of hierarchical topic segmentations and action item subdialogues collected over 65 meetings from the ICSI and ISL meeting corpora, designed to support automatic meeting understanding and analysis. We describe an architecture for representing, annotating, and analyzing multi-party discourse, including: an ontology of multimodal discourse, a programming interface for that ontology, and an audiovisual toolkit which facilitates browsing and annotating discourse, as well as visualizing and adjusting features for machine learning tasks."
W04-0312,"Incremental Parsing, or Incremental Grammar?",2004,15,2,1,1,1531,matthew purver,Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together,0,"Standard grammar formalisms are defined without reflection of the incremental and serial nature of language processing, and incrementality must therefore be reflected by independently defined parsing and/or generation techniques. We argue that this leads to a poor setup for modelling dialogue, with its rich speaker-hearer interaction, and instead propose context-based parsing and generation models defined in terms of an inherently incremental grammar formalism (Dynamic Syntax), which allow a straight-forward model of otherwise problematic dialogue phenomena such as shared utterances, ellipsis and alignment."
W03-2311,Incremental Generation by Incremental Parsing: Tactical Generation in Dynamic Syntax,2003,18,17,1,1,1531,matthew purver,Proceedings of the 9th {E}uropean Workshop on Natural Language Generation ({ENLG}-2003) at {EACL} 2003,0,"The paper shows how an incremental tactical generator can be constructed based on the incremental parsing framework described in Dynamic Syntax (DS)(Kempson et al., 2001), without adding a generator-specific vocabulary or intermediate levels of representation. The resulting generator is defined purely in terms of the parsing process, together with a notion of tree subsumption. This is shown to have various advantages including easy self-monitoring and psycholinguistic plausibility. A simple Prolog implementation is described, together with various possible improvements in efficiency."
W03-2103,Answering Clarification Questions,2003,12,15,1,1,1531,matthew purver,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,"This paper describes the results of corpus and experimental investigation into the factors that affect the way clarification questions in dialogue are interpreted, and the way they are responded to. We present some results from an investigation using the BNC which show some general correlations between clarification request type, likelihood of answering, answer type and distance between question and answer. We then describe a new experimental technique for integrating manipulations into text-based synchronous dialogue, and give more specific results concerning the effect of word category and level of grounding on interpretation and response type."
W02-0222,Processing Unknown Words in a Dialogue System,2002,14,13,1,1,1531,matthew purver,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"This paper describes a method of processing unknown words in a HPSG-based dialogue system, with acquisition of lexical semantics via clarification questions answered by the user. Use of a highly contextualized semantic representation, together with an utterance-anaphoric view of clarification, allows the clarificational dialogue to be integrated within the grammar and governed by standard rules of conversation."
W01-1616,On the Means for Clarification in Dialogue,2001,10,62,1,1,1531,matthew purver,Proceedings of the Second {SIG}dial Workshop on Discourse and Dialogue,0,"The ability to request clarification of utterances is a vital part of the communicative process. In this paper we discuss the range of possible forms for clarification requests, together with the range of readings they can convey. We present the results of corpus analysis which show a correlation between certain forms and possible readings, together with some indication of maximum likely distance between request and the utterance being clarified. We then explain the implications of these results for a possible HPSG analysis of clarification requests and for an ongoing implementation of a clarification-capable dialogue system.1"
