2021.gwc-1.16,A (Non)-Perfect Match: Mapping pl{W}ord{N}et onto {P}rinceton{W}ord{N}et,2021,-1,-1,3,0.67915,6142,ewa rudnicka,Proceedings of the 11th Global Wordnet Conference,0,"The paper reports on the methodology and final results of a large-scale synset mapping between plWordNet and Princeton WordNet. Dedicated manual and semi-automatic mapping procedures as well as interlingual relation types for nouns, verbs, adjectives and adverbs are described. The statistics of all types of interlingual relations are also provided."
2021.gwc-1.26,Neural Language Models vs {W}ordnet-based Semantically Enriched Representation in {CST} Relation Recognition,2021,-1,-1,2,1,6130,arkadiusz janz,Proceedings of the 11th Global Wordnet Conference,0,"Neural language models, including transformer-based models, that are pre-trained on very large corpora became a common way to represent text in various tasks, including recognition of textual semantic relations, e.g. Cross-document Structure Theory. Pre-trained models are usually fine tuned to downstream tasks and the obtained vectors are used as an input for deep neural classifiers. No linguistic knowledge obtained from resources and tools is utilised. In this paper we compare such universal approaches with a combination of rich graph-based linguistically motivated sentence representation and a typical neural network classifier applied to a task of recognition of CST relation in Polish. The representation describes selected levels of the sentence structure including description of lexical meanings on the basis of the wordnet (plWordNet) synsets and connected SUMO concepts. The obtained results show that in the case of difficult relations and medium size training corpus semantically enriched text representation leads to significantly better results."
2020.lrec-1.233,Brand-Product Relation Extraction Using Heterogeneous Vector Space Representations,2020,-1,-1,3,1,6130,arkadiusz janz,Proceedings of the 12th Language Resources and Evaluation Conference,0,Relation Extraction is a fundamental NLP task. In this paper we investigate the impact of underlying text representation on the performance of neural classification models in the task of Brand-Product relation extraction. We also present the methodology of preparing annotated textual corpora for this task and we provide valuable insight into the properties of Brand-Product relations existing in textual corpora. The problem is approached from a practical angle of applications Relation Extraction in facilitating commercial Internet monitoring.
R19-1048,Sparse Coding in Authorship Attribution for {P}olish Tweets,2019,0,0,3,0,25299,piotr grzybowski,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,The study explores application of a simple Convolutional Neural Network for the problem of authorship attribution of tweets written in Polish. In our solution we use two-step compression of tweets using Byte Pair Encoding algorithm and vectorisation as an input to the distributional model generated for the large corpus of Polish tweets by word2vec algorithm. Our method achieves results comparable to the state-of-the-art approaches for the similar task on English tweets and expresses a very good performance in the classification of Polish tweets. We tested the proposed method in relation to the number of authors and tweets per author. We also juxtaposed results for authors with different topic backgrounds against each other.
R19-1061,Word Sense Disambiguation based on Constrained Random Walks in Linked Semantic Networks,2019,0,0,2,1,6130,arkadiusz janz,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Word Sense Disambiguation remains a challenging NLP task. Due to the lack of annotated training data, especially for rare senses, the supervised approaches are usually designed for specific subdomains limited to a narrow subset of identified senses. Recent advances in this area have shown that knowledge-based approaches are more scalable and obtain more promising results in all-words WSD scenarios. In this work we present a faster WSD algorithm based on the Monte Carlo approximation of sense probabilities given a context using constrained random walks over linked semantic networks. We show that the local semantic relatedness is mostly sufficient to successfully identify correct senses when an extensive knowledge base and a proper weighting scheme are used. The proposed methods are evaluated on English (SenseEval, SemEval) and Polish (Sk{\l}adnica, KPWr) datasets."
R19-1148,Tagger for {P}olish Computer Mediated Communication Texts,2019,0,0,2,0,6172,wiktor walentynowicz,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"In this paper we present a morpho-syntactic tagger dedicated to Computer-mediated Communication texts in Polish. Its construction is based on an expanded RNN-based neural network adapted to the work on noisy texts. Among several techniques, the tagger utilises fastText embedding vectors, sequential character embedding vectors, and Brown clustering for the coarse-grained representation of sentence structures. In addition a set of manually written rules was proposed for post-processing. The system was trained to disambiguate descriptions of words in relation to Parts of Speech tags together with the full morphological information in terms of values for the different grammatical categories. We present also evaluation of several model variants on the gold standard annotated CMC data, comparison to the state-of-the-art taggers for Polish and error analysis. The proposed tagger shows significantly better results in this domain and demonstrates the viability of adaptation."
2019.gwc-1.45,"pl{W}ord{N}et 4.1 - a Linguistically Motivated, Corpus-based Bilingual Resource",2019,-1,-1,2,1,6171,agnieszka dziob,Proceedings of the 10th Global Wordnet Conference,0,"The paper presents the latest release of the Polish WordNet, namely plWordNet 4.1. The most significant developments since 3.0 version include new relations for nouns and verbs, mapping semantic role-relations from the valency lexicon Walenty onto the plWordNet structure and sense-level inter-lingual mapping. Several statistics are presented in order to illustrate the development and contemporary state of the wordnet."
2019.gwc-1.46,A Comparison of Sense-level Sentiment Scores,2019,-1,-1,3,0,6126,francis bond,Proceedings of the 10th Global Wordnet Conference,0,"In this paper, we compare a variety of sense-tagged sentiment resources, including SentiWordNet, ML-Senticon, plWordNet emo and the NTU Multilingual Corpus. The goal is to investigate the quality of the resources and see how well the sentiment polarity annotation maps across languages."
L18-1665,Classifier-based Polarity Propagation in a {W}ord{N}et,2018,0,0,3,0,12469,jan kocon,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
2018.gwc-1.6,Towards Mapping Thesauri onto pl{W}ord{N}et,2018,-1,-1,2,1,6131,marek maziarz,Proceedings of the 9th Global Wordnet Conference,0,"plWordNet, the wordnet of Polish, has become a very comprehensive description of the Polish lexical system. This paper presents a plan of its semi-automated integration with thesauri, terminological databases and ontologies, as a further necessary step in its development. This will improve linking of plWordNet into Linked Open Data, and facilitate applications in, e.g., WSD, keyword extraction or automated metadata generation. We present an overview of resources relevant to Polish and a plan for their linking to plWordNet."
2018.gwc-1.14,Implementation of the Verb Model in pl{W}ord{N}et 4.0,2018,-1,-1,2,1,6171,agnieszka dziob,Proceedings of the 9th Global Wordnet Conference,0,"The paper presents an expansion of the verb model for plWordNet {--} the wordnet of Polish. A modified system of constitutive features (register, aspect and verb classes), synset and lexical relations is presented. A special attention is given to the proposed new relations and changes in the verb classification. We discuss also the results of its verification by application to the description of a relatively large sample of Polish verbs. The model introduces a new class of relations, namely non-constitutive synset relations that are shared among lexical units, but describe, not define synsets. The proposed model is compared to the entailment relations in other wordnets, and the description of verbs based on valency frames."
2018.gwc-1.18,Towards Emotive Annotation in pl{W}ord{N}et 4.0,2018,-1,-1,2,1,25311,monika zaskozielinska,Proceedings of the 9th Global Wordnet Conference,0,"The paper presents an approach to building a very large emotive lexicon for Polish based on plWordNet. An expanded annotation model is discussed, in which lexical units (word senses) are annotated with basic emotions, fundamental human values and sentiment polarisation. The annotation process is performed manually in the 2+1 scheme by pairs of linguists and psychologies. Guidelines referring to the usage in corpora, substitution tests as well linguistic properties of lexical units (e.g. derivational associations) are discussed. Application of the model in a substantial extension of the emotive annotation of plWordNet is presented. The achieved high inter-annotator agreement shows that with relatively small workload a promising emotive resource can be created."
2018.gwc-1.22,{W}ordnet{L}oom {--} a Multilingual {W}ordnet Editing System Focused on Graph-based Presentation,2018,-1,-1,3,0,17480,tomasz naskrket,Proceedings of the 9th Global Wordnet Conference,0,"The paper presents a new re-built and expanded, version 2.0 of WordnetLoom {--} an open wordnet editor. It facilitates work on a multilingual system of wordnets, is based on efficient software architecture of thin client, and offers more flexibility in enriching wordnet representation. This new version is built on the experience collected during the use of the previous one for more than 10 years of plWordNet development. We discuss its extensions motivated by the collected experience. A special focus is given to the development of a variant for the needs of MultiWordnet of Portuguese, which is based on a very different wordnet development model."
2018.gwc-1.24,Lexical Perspective on {W}ordnet to {W}ordnet Mapping,2018,14,0,4,0.67915,6142,ewa rudnicka,Proceedings of the 9th Global Wordnet Conference,0,"The paper presents a feature-based model of equivalence targeted at (manual) sense linking between Princeton WordNet and plWordNet. The model incorporates insights from lexicographic and translation theories on bilingual equivalence and draws on the results of earlier synset-level mapping of nouns between Princeton WordNet and plWordNet. It takes into account all basic aspects of language such as form, meaning and function and supplements them with (parallel) corpus frequency and translatability. Three types of equivalence are distinguished, namely strong, regular and weak depending on the conformity with the proposed features. The presented solutions are language-neutral and they can be easily applied to language pairs other than Polish and English. Sense-level mapping is a more fine-grained mapping than the existing synset mappings and is thus of great potential to human and machine translation."
2018.gwc-1.26,{W}ordnet-based Evaluation of Large Distributional Models for {P}olish,2018,-1,-1,1,1,6159,maciej piasecki,Proceedings of the 9th Global Wordnet Conference,0,"The paper presents construction of large scale test datasets for word embeddings on the basis of a very large wordnet. They were next applied for evaluation of word embedding models and used to assess and compare the usefulness of different word embeddings extracted from a very large corpus of Polish. We analysed also and compared several publicly available models described in literature. In addition, several large word embeddings models built on the basis of a very large Polish corpus are presented."
2018.gwc-1.29,Recognition of Hyponymy and Meronymy Relations in Word Embeddings for {P}olish,2018,-1,-1,2,0,31044,gabriela czachor,Proceedings of the 9th Global Wordnet Conference,0,"Word embeddings were used for the extraction of hyponymy relation in several approaches, but also it was recently shown that they should not work, in fact. In our work we verified both claims using a very large wordnet of Polish as a gold standard for lexico-semantic relations and word embeddings extracted from a very large corpus of Polish. We showed that a hyponymy extraction method based on linear regression classifiers trained on clusters of vectors can be successfully applied on large scale. We presented also a possible explanation for contradictory findings in the literature. Moreover, in order to show the feasibility of the method we extended it to the recognition of meronymy."
2018.gwc-1.39,Context-sensitive Sentiment Propagation in {W}ord{N}et,2018,-1,-1,3,0,12469,jan kocon,Proceedings of the 9th Global Wordnet Conference,0,"In this paper we present a comprehensive overview of recent methods of the sentiment propagation in a wordnet. Next, we propose a fully automated method called Classifier-based Polarity Propagation, which utilises a very rich set of features, where most of them are based on wordnet relation types, multi-level bag-of-synsets and bag-of-polarities. We have evaluated our solution using manually annotated part of plWordNet 3.1 emo, which contains more than 83k manual sentiment annotations, covering more than 41k synsets. We have demonstrated that in comparison to existing rule-based methods using a specific narrow set of semantic relations our method has achieved statistically significant and better results starting with the same seed synsets."
kedzia-etal-2017-graph,Graph-Based Approach to Recognizing {CST} Relations in {P}olish Texts,2017,0,0,2,1,31046,pawel kkedzia,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"This paper presents an supervised approach to the recognition of Cross-document Structure Theory (CST) relations in Polish texts. In the proposed, graph-based representation is constructed for sentences. Graphs are built on the basis of lexicalised syntactic-semantic relation extracted from text. Similarity between sentences is calculated from graph, and the similarity values are input to classifiers trained by Logistic Model Tree. Several different configurations of graph, as well as graph similarity methods were analysed for this tasks. The approach was evaluated on a large open corpus annotated manually with 17 types of selected CST relations. The configuration of experiments was similar to those known from SEMEVAL and we obtained very promising results."
piasecki-etal-2017-recognition,Recognition of Genuine {P}olish Suicide Notes,2017,0,0,1,1,6159,maciej piasecki,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"In this article we present the result of the recent research in the recognition of genuine Polish suicide notes (SNs). We provide useful method to distinguish between SNs and other types of discourse, including counterfeited SNs. The method uses a wide range of word-based and semantic features and it was evaluated using Polish Corpus of Suicide Notes, which contains 1244 genuine SNs, expanded with manually prepared set of 334 counterfeited SNs and 2200 letter-like texts from the Internet. We utilized the algorithm to create the class-related sense dictionaries to improve the result of SNs classification. The obtained results show that there are fundamental differences between genuine SNs and counterfeited SNs. The applied method of the sense dictionary construction appeared to be the best way of improving the model."
C16-1213,pl{W}ord{N}et 3.0 {--} a Comprehensive Lexical-Semantic Resource,2016,22,12,2,1,6131,marek maziarz,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We have released plWordNet 3.0, a very large wordnet for Polish. In addition to what is expected in wordnets {--} richly interrelated synsets {--} it contains sentiment and emotion annotations, a large set of multi-word expressions, and a mapping onto WordNet 3.1. Part of the release is enWordNet 1.0, a substantially enlarged copy of WordNet 3.1, with material added to allow for a more complete mapping. The paper discusses the design principles of plWordNet, its content, its statistical portrait, a comparison with similar resources, and a partial list of applications."
2016.gwc-1.41,pl{W}ord{N}et in Word Sense Disambiguation task,2016,-1,-1,1,1,6159,maciej piasecki,Proceedings of the 8th Global WordNet Conference (GWC),0,"The paper explores the application of plWordNet, a very large wordnet of Polish, in weakly supervised Word Sense Disambiguation (WSD). Because plWordNet provides only partial descriptions by glosses and usage examples, and does not include sense-disambiguated glosses, PageRank-based WSD methods perform slightly worse than for English. However, we show that the use of weights for the relation types and the order in which lexical units have been added for sense re-ranking can significantly improve WSD precision. The evaluation was done on two Polish corpora (KPWr and Sk{\l}adnica) including manual WSD. We discuss the fundamental difference in the construction of both corpora and very different test results."
2016.gwc-1.42,pl{W}ord{N}et 3.0 {--} Almost There,2016,-1,-1,1,1,6159,maciej piasecki,Proceedings of the 8th Global WordNet Conference (GWC),0,"It took us nearly ten years to get from no wordnet for Polish to the largest wordnet ever built. We started small but quickly learned to dream big. Now we are about to release plWordNet 3.0-emo {--} complete with sentiment and emotions annotated {--} and a domestic version of Princeton WordNet, larger than WordNet 3.1 by nearly ten thousand newly added words. The paper retraces the road we travelled and talks a little about the future."
R15-1056,A Procedural Definition of Multi-word Lexical Units,2015,17,2,3,1,6131,marek maziarz,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"Multi-word expressions evade a closed definition. Linguists and computational linguists rely on intuition or build lists of MWE types; while practical, that is scientifically and aesthetically unsatisfying. Without presuming to solve a daunting theoretical problem, we propose a decision procedure which steers a lexicographer toward acceptance or rejection of an N-gram as a lexical unit: a decision tree classifies N-grams as MWE or not MWE. It will succeed if it agrees with the native speakersxe2x80x99 judgment. We need a small, linguistically credible set of features, to contend with the multiplicity of adequate trees. Decision tree induction works with a fixed set of annotated classification examples, but the lexical material for MWE recognition is too large to make annotation feasible. We rely on small-scale statistically significant sampling, and on intuition. Of a few decision trees produced by informed trial and error, we select one we consider best in our circumstances. That tree, deployed in a large-scale wordnet construction project, allowed us to gather dependable statistics on its usefulness in lexicographersxe2x80x99 work. Our goal: systematic expansion of a wordnet by tens of thousands of MWEs in a manner as free of personal biases as possible."
R15-1067,Extraction of the Multi-word Lexical Units in the Perspective of the {W}ordnet Expansion,2015,13,3,1,1,6159,maciej piasecki,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"The paper focuses on selecting an optimal set of the Multiword Expressions Extraction methods used as a tool during wordnet expansion. Wordnet multiword lexical units are a broad class and it is difficult to find a single extraction method fulfilling the task. Many extraction association measures were tested on very large corpora and a very large wordnet, namely plWordNet. Several new measures are proposed and compared with selected methods in the literature. Two ways of combining measures into ensembles were analysed too. We showed that method selection and the tuning of their parameters can be transferred between two large corpora. The comparison of the extracted collocations with the huge set of plWordNet multiword lexical units revealed that the performance of the methods is much below the optimistic levels reported in the literature. However, the carefully selected set and combination of the methods can be a valuable tool for lexicographers."
R15-1092,A Large {W}ordnet-based Sentiment Lexicon for {P}olish,2015,25,7,2,1,25311,monika zaskozielinska,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"The applications of plWordNet, a very large wordnet for Polish, do not yet include work on sentiment and emotions. We present a pilot project to annotate plWordNet manually with sentiment polarity values and basic emotion values. We work with lexical units, plWordNetxe2x80x99s basic building blocks.1 So far, we have annotated about 30,000 nominal and adjectival LUs. The resulting lexicon is already one of the largest sentiment and emotion resources, in particular among those based on wordnets. We opted for manual annotation to ensure high accuracy, and to provide a reliable starting point for future semi-automated expansion. The paper lists the principal assumptions, outlines the annotation process, and introduces the resulting resource, plWordNetemo. We discuss the selection of the material for the pilot study, show the distribution of annotations across the wordnet, and consider the statistics, including interannotator agreement and the resolution of disagreement."
W14-0142,pl{W}ord{N}et as the Cornerstone of a Toolkit of Lexico-semantic Resources,2014,23,4,2,1,6131,marek maziarz,Proceedings of the Seventh Global {W}ordnet Conference,0,"A wordnet is many things to many people: a graph of inter-related lexicalised concepts, a taxonomy, a thesaurus, and so on. A wordnet makes good sense as the mainstay of any deep automated semantic analysis of text. We have begun the construction of a multi-component, multi-use toolkit of natural language processing tools with plWordNet, a very large Polish wordnet, at its centre. The components will include plWordNet and its mapping onto an ontology (the upper level and elements of the middle level), a lexicon of proper names and a semantic valency lexicon. Some of those elements will be aligned with plWordNet, and there will be a mapping onto Princeton WordNet. Several challenging applications will show the utility of the toolkit in practice. 1 How wordnets evolve Wordnets start small but quickly grow to account for much of the lexical material of the given language. The size of version 3.1 of Princeton WordNet (PWN) (Fellbaum, 1998) is a de facto standard, even if this mature wordnet also keeps growing, albeit slowly.1 One of the resources which approach this size standard is plWordNet (Piasecki et al., 2009), now in version 2.1. Languages change continually, so lexicographers never rest, but one can still ask when the development of a wordnet ought to slow down, and whether there is an appropriate steady state of a wordnet. That clearly is a loaded question, and much depends on the language. For example, suppose that a wordnet for PWN began as a test of a theory of human semantic representation and memory (Collins and Quillian, 1969). It now features a comprehensive vocabulary, a set of universally useful semantic relations, glosses, links to ontologies, and more. a richly inflected language with complex and varied derivation was originally a translation of PWN. Such a wordnet should, sooner or later, acquire semantic relations which account accurately for its unique lexical system.. A wordnet, even as developed as PWN, GermaNet (Hamp and Feldweg, 1997) or plWordNet (Maziarz et al., 2013a), serves many natural language processing (NLP) applications, yet it seems neither feasible nor necessary to remake wordnets into universal NLP resources. Instead, we propose to mark clear boundaries around a wordnet (what it should and what it should not include), and treat it as a pivotal element of an organic toolkit of inter-connected tools and resources for the semantic analysis of texts, along with the auxiliary morphological and syntactic analysis tools. Our case study is such a toolkit, now under development, centred on plWordNet 3.0 (also in development), and intended first and foremost for research in the humanities. In the remainder of the paper, we present the main design assumptions and principles of that project. We explain how comprehensive we want plWordNet 3.0 to become, what size and what coverage we envisage. We attempt to describe how the toolkit will be built around plWordNet, and we outline plans for its large-scale illustrative applications in several domains. We discuss how the components of the toolkit will be expanded or constructed: plWordNet 3.0, its mapping to an ontology, and a semantic lexicon of proper names. We also briefly present resources for morphological and structural description, associated with the plWordNet system, among them a lexicon of lexico-syntactic structures of multiword expressions and a valency lexicon linked to plWordNet but developed independently. This work is meant to take several years of initial effort and years of maintenance. We cannot answer many design questions yet, but many will be answered as the project unfolds. That is to say. we want to interlace theory and practice."
W14-0146,Registers in the System of Semantic Relations in pl{W}ord{N}et,2014,13,2,2,1,6131,marek maziarz,Proceedings of the Seventh Global {W}ordnet Conference,0,"Lexicalised concepts are represented in wordnets by word-sense pairs. The strength of markedness is one of the factors which influence word use. Stylistically unmarked words are largely contextneutral. Technical terms, obsolete words, xe2x80x9cofficialesexe2x80x9d, slangs, obscenities and so on are all marked, often strongly, and that limits their use considerably. We discuss the position of register and markedness in wordnets with respect to semantic relations, and we list typical values of register. We illustrate the discussion with the system of registers in plWordNet, the largest Polish wordnet. We present a decision tree for the assignment of marking labels, and examine the consistency of the editing decisions based on that tree."
kedzia-piasecki-2014-ruled,"Ruled-based, Interlingual Motivated Mapping of pl{W}ord{N}et onto {SUMO} Ontology",2014,13,2,2,1,31046,pawel kkedzia,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper we study a rule-based approach to mapping plWordNet onto SUMO Upper Ontology on the basis of the already existing mappings: plWordNet -- the Princeton WordNet -- SUMO. Information acquired from the inter-lingual relations between plWordNet and Princeton WordNet and the relations between Princeton WordNet and SUMO ontology are used in the proposed rules. Several mapping rules together with the matching examples are presented. The automated mapping results were evaluated in two steps, (i) we automatically checked formal correctness of the mappings for the pairs of plWordNet synset and SUMO concept, (ii) a subset of 160 mapping examples was manually checked by two+one linguists. We analyzed types of the mapping errors and their causes. The proposed rules expressed very high precision, especially when the errors in the resources are taken into account. Because both wordnets were constructed independently and as a result the obtained rules are not trivial and they reveal the differences between both wordnets and both languages."
R13-1056,Evaluation of baseline information retrieval for {P}olish open-domain Question Answering system,2013,23,2,3,0.5,6176,michal marcinczuk,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"We report on our efforts aimed at building an Open Domain Question Answering system for Polish. Our contribution is twofold: we gathered a set of questionxe2x80x90answer pairs from various Polish sources and we performed an empirical evaluation of two re-ranking methods. The gathered collection contains factoid, list, non-factoid and yes-no questions, which makes a challenging material for experiments. We show that using two re-ranking methods based on term proximity allows to obtain significant improvement on simple information retrieval baseline. The improvement is observed as finding more answer-bearing documents among the topn search results."
R13-1058,Beyond the Transfer-and-Merge {W}ordnet Construction: pl{W}ord{N}et and a Comparison with {W}ord{N}et,2013,32,8,2,1,6131,marek maziarz,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"Wordnets are lexico-semantic resources essential in many NLP tasks. Princeton WordNet is the most widely known, and the most influential, among them. Word- nets for languages other than English tend to adopt unquestioningly WordNet's struc- ture and its net of lexicalised concepts. We discuss a large wordnet constructed inde- pendently of WordNet, upon a model with a small yet significant difference. A map- ping onto WordNet is under way; the large portions already linked open up a unique perspective on the comparison of similar but not fully compatible lexical resources. We also try to characterise numerically a wordnet's aptitude for NLP applications."
R13-1073,Information Spreading in Expanding {W}ordnet Hypernymy Structure,2013,23,1,1,1,6159,maciej piasecki,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"The paper presents a wordnet expansion algorithm, which is based on lexicosemantic relations extracted from large text corpora. We do not assume that the extracted relation instances (i.e. word pairs) are described by probabilities. Thus, results produced by any method, including pattern-based and Distributional Semantics approaches can be used. The algorithm is based on a general spreading activation model. Support for word-to-word semantic associations is first mapped on the existing wordnet structure. Next, the support is spread over the wordnet network in order to find attachment areas for a new word. Evaluation and comparison with other approaches in experiments on Princeton WordNet 3.0 is presented."
broda-etal-2012-tools,Tools for pl{W}ord{N}et Development. Presentation and Perspectives,2012,15,5,3,0.441176,39630,bartosz broda,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Building a wordnet is a serious undertaking. Fortunately, Language Technology (LT) can improve the process of wordnet construction both in terms of quality and cost. In this paper we present LT tools used during the construction of plWordNet and their influence on the lexicographer's work-flow. LT is employed in plWordNet development on every possible step: from data gathering through data analysis to data presentation. Nevertheless, every decision requires input from the lexicographer, but the quality of supporting tools is an important factor. Thus a limited evaluation of usefulness of employed tools is carried out on the basis of questionnaires."
piasecki-etal-2012-recognition,Recognition of {P}olish Derivational Relations Based on Supervised Learning Scheme,2012,13,9,1,1,6159,maciej piasecki,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The paper presents construction of {\textbackslash}emph{Derywator} -- a language tool for the recognition of Polish derivational relations. It was built on the basis of machine learning in a way following the bootstrapping approach: a limited set of derivational pairs described manually by linguists in plWordNet is used to train {\textbackslash}emph{Derivator}. The tool is intended to be applied in semi-automated expansion of plWordNet with new instances of derivational relations. The training process is based on the construction of two transducers working in the opposite directions: one for prefixes and one for suffixes. Internal stem alternations are recognised, recorded in a form of mapping sequences and stored together with transducers. Raw results produced by {\textbackslash}emph{Derivator} undergo next corpus-based and morphological filtering. A set of derivational relations defined in plWordNet is presented. Results of tests for different derivational relations are discussed. A problem of the necessary corpus-based semantic filtering is analysed. The presented tool depends to a very little extent on the hand-crafted knowledge for a particular language, namely only a table of possible alternations and morphological filtering rules must be exchanged and it should not take longer than a couple of working days."
kurc-etal-2012-constraint,Constraint Based Description of {P}olish Multiword Expressions,2012,7,6,2,0,43337,roman kurc,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present an approach to the description of Polish Multi-word Expressions (MWEs) which is based on expressions in the WCCL language of morpho-syntactic constraints instead of grammar rules or transducers. For each MWE its basic morphological form and the base forms of its constituents are specified but also each MWE is assigned to a class on the basis of its syntactic structure. For each class a WCCL constraint is defined which is parametrised by string variables referring to MWE constituent base forms or inflected forms. The constraint specifies a minimal set of conditions that must be fulfilled in order to recognise an occurrence of the given MWE in text with high accuracy. Our formalism is focused on the efficient description of large MWE lexicons for the needs of utilisation in text processing. The formalism allows for the relatively easy representation of flexible word order and discontinuous constructions. Moreover, there is no necessity for the full specification of the MWE grammatical structure. Only some aspects of the particular MWE structure can be selected in way facilitating the target accuracy of recognition. On the basis of a set of simple heuristics, WCCL-based representation of MWEs can be automatically generated from a list of MWE base forms. The proposed representation was applied on a practical scale for the description of a large set of Polish MWEs included in plWordNet."
C12-2101,A Strategy of Mapping {P}olish {W}ord{N}et onto {P}rinceton {W}ord{N}et,2012,16,20,3,0.625,6142,ewa rudnicka,Proceedings of {COLING} 2012: Posters,0,"We present a strategy and the early results of the mapping of plWordNet xe2x80x90 one of the largest such language resources in existence xe2x80x90 onto Princeton Wo rdNet. The fundamental structural premise of plWordNet differs from those of most other wordnets: lexical units rather than synsets are the basic building blocks. The addition of new material to plWordNet is consistently informed by semantic relations and by various analyses of large corpora. The mapping is difficult because of the subtly distinct structures and because of WordN etxe2x80x99s focus on synsets. We have designed a set of inter-lingual semantic relations and an effectiv e mapping procedure. In the course of mapping, we have discovered a range of systematic difference s between plWordNet and WordNet, and proposed ways of accounting for such differences."
wittenburg-etal-2010-resource,Resource and Service Centres as the Backbone for a Sustainable Service Infrastructure,2010,0,12,10,0,39140,peter wittenburg,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Currently, research infrastructures are being designed and established in many disciplines since they all suffer from an enormous fragmentation of their resources and tools. In the domain of language resources and tools the CLARIN initiative has been funded since 2008 to overcome many of the integration and interoperability hurdles. CLARIN can build on knowledge and work from many projects that were carried out during the last years and wants to build stable and robust services that can be used by researchers. Here service centres will play an important role that have the potential of being persistent and that adhere to criteria as they have been established by CLARIN. In the last year of the so-called preparatory phase these centres are currently developing four use cases that can demonstrate how the various pillars CLARIN has been working on can be integrated. All four use cases fulfil the criteria of being cross-national."
broda-etal-2010-building,Building a Node of the Accessible Language Technology Infrastructure,2010,15,5,3,0,39630,bartosz broda,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"A limited prototype of the CLARIN Language Technology Infrastructure (LTI) node is presented. The node prototype provides several types of web services for Polish. The functionality encompasses morpho-syntactic processing, shallow semantic processing of corpus on the basis of the SuperMatrix system and plWordNet browsing. We take the prototype as the starting point for the discussion on requirements that must be fulfilled by the LTI. Some possible solutions are proposed for less frequently discussed problems, e.g. streaming processing of language data on the remote processing node. We experimentally investigate how to tackle with several requirements from many discussed. Such aspects as processing large volumes of data, asynchronous mode of processing and scalability of the architecture to large number of users got especial attention in the constructed prototype of the Web Service for morpho-syntactic processing of Polish called TaKIPI-WS (http://plwordnet.pwr.wroc.pl/clarin/ws/takipi/). TaKIPI-WS is a distributed system with a three-layer architecture, an asynchronous model of request handling and multi-agent-based processing. TaKIPI-WS consists of three layers: WS Interface, Database and Daemons. The role of the Database is to store and exchange data between the Interface and the Daemons. The Daemons (i.e. taggers) are responsible for executing the requests queued in the database. Results of the performance tests are presented in the paper, too."
broda-etal-2008-corpus,Corpus-based Semantic Relatedness for the Construction of {P}olish {W}ord{N}et,2008,16,14,3,0,39630,bartosz broda,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The construction of a wordnet, a labour-intensive enterprise, can be significantly assisted by automatic grouping of lexical material and discovery of lexical semantic relations. The objective is to ensure high quality of automatically acquired results before they are presented for lexicographersÂ approval. We discuss a software tool that suggests synset members using a measure of semantic relatedness with a given verb or adjective; this extends previous work on nominal synsets in Polish WordNet. Syntactically-motivated constraints are deployed on a large morphologically annotated corpus of Polish. Evaluation has been performed via the WordNet-Based Similarity Test and additionally supported by human raters. A lexicographer also manually assessed a suitable sample of suggestions. The results compare favourably with other known methods of acquiring semantic relations."
