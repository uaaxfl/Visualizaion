2021.emnlp-main.539,{L}evenshtein Training for Word-level Quality Estimation,2021,-1,-1,3,0.666667,4416,shuoyang ding,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"We propose a novel scheme to use the Levenshtein Transformer to perform the task of word-level quality estimation. A Levenshtein Transformer is a natural fit for this task: trained to perform decoding in an iterative manner, a Levenshtein Transformer can learn to post-edit without explicit supervision. To further minimize the mismatch between the translation task and the word-level QE task, we propose a two-stage transfer learning procedure on both augmented data and human post-editing data. We also propose heuristics to construct reference labels that are compatible with subword-level finetuning and inference. Results on WMT 2020 QE shared task dataset show that our proposed method has superior data efficiency under the data-constrained setting and competitive performance under the unconstrained setting."
2021.emnlp-main.576,Robust Open-Vocabulary Translation from Visual Text Representations,2021,-1,-1,3,0,1275,elizabeth salesky,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Machine translation models have discrete vocabularies and commonly use subword segmentation techniques to achieve an {`}open vocabulary.{'} This approach relies on consistent and correct underlying unicode sequences, and makes models susceptible to degradation from common types of noise and variation. Motivated by the robustness of human language processing, we propose the use of visual text representations, which dispense with a finite set of text embeddings in favor of continuous vocabularies created by processing visually rendered text with sliding windows. We show that models using visual text representations approach or match performance of traditional text models on small and larger datasets. More importantly, models with visual embeddings demonstrate significant robustness to varied types of noise, achieving e.g., 25.9 BLEU on a character permuted German{--}English task where subword models degrade to 1.9."
2021.acl-long.309,A unified approach to sentence segmentation of punctuated text in many languages,2021,-1,-1,2,0,13138,rachel wicks,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"The sentence is a fundamental unit of text processing. Yet sentences in the wild are commonly encountered not in isolation, but unsegmented within larger paragraphs and documents. Therefore, the first step in many NLP pipelines is \textit{sentence segmentation}. Despite its importance, this step is the subject of relatively little research. There are no standard test sets or even methods for evaluation, leaving researchers and engineers without a clear footing for evaluating and selecting models for the task. Existing tools have relatively small language coverage, and efforts to extend them to other languages are often ad hoc. We introduce a modern context-based modeling approach that provides a solution to the problem of segmenting punctuated text in many languages, and show how it can be trained on noisily-annotated data. We also establish a new 23-language multilingual evaluation set. Our approach exceeds high baselines set by existing methods on prior English corpora (WSJ and Brown corpora), and also performs well on average on our new evaluation set. We release our tool, ersatz, as open source."
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,20,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.wmt-1.67,Paraphrase Generation as Zero-Shot Multilingual Translation: Disentangling Semantic Similarity from Lexical and Syntactic Diversity,2020,-1,-1,2,0,13891,brian thompson,Proceedings of the Fifth Conference on Machine Translation,0,"Recent work has shown that a multilingual neural machine translation (NMT) model can be used to judge how well a sentence paraphrases another sentence in the same language (Thompson and Post, 2020); however, attempting to generate paraphrases from such a model using standard beam search produces trivial copies or near copies. We introduce a simple paraphrase generation algorithm which discourages the production of n-grams that are present in the input. Our approach enables paraphrase generation in many languages from a single multilingual NMT model. Furthermore, the amount of lexical diversity between the input and output can be controlled at generation time. We conduct a human evaluation to compare our method to a paraphraser trained on the large English synthetic paraphrase database ParaBank 2 (Hu et al., 2019c) and find that our method produces paraphrases that better preserve meaning and are more gramatical, for the same level of lexical diversity. Additional smaller human assessments demonstrate our approach also works in two non-English languages."
2020.wmt-1.98,{P}ar{BLEU}: Augmenting Metrics with Automatic Paraphrases for the {WMT}{'}20 Metrics Shared Task,2020,-1,-1,4,0,7687,rachel bawden,Proceedings of the Fifth Conference on Machine Translation,0,"We describe parBLEU, parCHRF++, and parESIM, which augment baseline metrics with automatically generated paraphrases produced by PRISM (Thompson and Post, 2020a), a multilingual neural machine translation system. We build on recent work studying how to improve BLEU by using diverse automatically paraphrased references (Bawden et al., 2020), extending experiments to the multilingual setting for the WMT2020 metrics shared task and for three base metrics. We compare their capacity to exploit up to 100 additional synthetic references. We find that gains are possible when using additional, automatically paraphrased references, although they are not systematic. However, segment-level correlations, particularly into English, are improved for all three metrics and even with higher numbers of paraphrased references."
2020.tacl-1.4,Membership Inference Attacks on Sequence-to-Sequence Models: {I}s My Data In Your Machine Translation System?,2020,7,0,2,0,14394,sorami hisamoto,Transactions of the Association for Computational Linguistics,0,"Data privacy is an important issue for {``}machine learning as a service{''} providers. We focus on the problem of membership inference attacks: Given a data sample and black-box access to a model{'}s API, determine whether the sample existed in the model{'}s training data. Our contribution is an investigation of this problem in the context of sequence-to-sequence models, which are important in applications such as machine translation and video captioning. We define the membership inference problem for sequence generation, provide an open dataset based on state-of-the-art machine translation models, and report initial results on whether these models leak private information against several kinds of membership inference attacks."
2020.ngt-1.22,The {JHU} Submission to the 2020 {D}uolingo Shared Task on Simultaneous Translation and Paraphrase for Language Education,2020,-1,-1,6,1,4575,huda khayrallah,Proceedings of the Fourth Workshop on Neural Generation and Translation,0,"This paper presents the Johns Hopkins University submission to the 2020 Duolingo Shared Task on Simultaneous Translation and Paraphrase for Language Education (STAPLE). We participated in all five language tasks, placing first in each. Our approach involved a language-agnostic pipeline of three components: (1) building strong machine translation systems on general-domain data, (2) fine-tuning on Duolingo-provided data, and (3) generating n-best lists which are then filtered with various score-based techniques. In addi- tion to the language-agnostic pipeline, we attempted a number of linguistically-motivated approaches, with, unfortunately, little success. We also find that improving BLEU performance of the beam-search generated translation does not necessarily improve on the task metric{---}weighted macro F1 of an n-best list."
2020.lrec-1.325,Benchmarking Neural and Statistical Machine Translation on Low-Resource {A}frican Languages,2020,-1,-1,3,0,5136,kevin duh,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Research in machine translation (MT) is developing at a rapid pace. However, most work in the community has focused on languages where large amounts of digital resources are available. In this study, we benchmark state of the art statistical and neural machine translation systems on two African languages which do not have large amounts of resources: Somali and Swahili. These languages are of social importance and serve as test-beds for developing technologies that perform reasonably well despite the low-resource constraint. Our findings suggest that statistical machine translation (SMT) and neural machine translation (NMT) can perform similarly in low-resource scenarios, but neural systems require more careful tuning to match performance. We also investigate how to exploit additional data, such as bilingual text harvested from the web, or user dictionaries; we find that NMT can significantly improve in performance with the use of these additional data. Finally, we survey the landscape of machine translation resources for the languages of Africa and provide some suggestions for promising future research directions."
2020.lrec-1.352,The {J}ohns {H}opkins {U}niversity {B}ible Corpus: 1600+ Tongues for Typological Exploration,2020,-1,-1,8,0,1305,arya mccarthy,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present findings from the creation of a massively parallel corpus in over 1600 languages, the Johns Hopkins University Bible Corpus (JHUBC). The corpus consists of over 4000 unique translations of the Christian Bible and counting. Our data is derived from scraping several online resources and merging them with existing corpora, combining them under a common scheme that is verse-parallel across all translations. We detail our effort to scrape, clean, align, and utilize this ripe multilingual dataset. The corpus captures the great typological variety of the world{'}s languages. We catalog this by showing highly similar proportions of representation of Ethnologue{'}s typological features in our corpus. We also give an example application: projecting pronoun features like clusivity across alignments to richly annotate languages which do not mark the distinction."
2020.findings-emnlp.82,A Study in Improving {BLEU} Reference Coverage with Diverse Automatic Paraphrasing,2020,-1,-1,5,0,7687,rachel bawden,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"We investigate a long-perceived shortcoming in the typical use of BLEU: its reliance on a single reference. Using modern neural paraphrasing techniques, we study whether automatically generating additional *diverse* references can provide better coverage of the space of valid translations and thereby improve its correlation with human judgments. Our experiments on the into-English language directions of the WMT19 metrics task (at both the system and sentence level) show that using paraphrased references does generally improve BLEU, and when it does, the more diverse the better. However, we also show that better results could be achieved if those paraphrases were to specifically target the parts of the space most relevant to the MT outputs being evaluated. Moreover, the gains remain slight even when human paraphrases are used, suggesting inherent limitations to BLEU{'}s capacity to correctly exploit multiple references. Surprisingly, we also find that adequacy appears to be less important, as shown by the high results of a strong sampling approach, which even beats human paraphrases when used with sentence-level BLEU."
2020.eval4nlp-1.7,On the Evaluation of Machine Translation n-best Lists,2020,-1,-1,4,0,5710,jacob bremerman,Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems,0,"The standard machine translation evaluation framework measures the single-best output of machine translation systems. There are, however, many situations where n-best lists are needed, yet there is no established way of evaluating them. This paper establishes a framework for addressing n-best evaluation by outlining three different questions one could consider when determining how one would define a {`}good{'} n-best list and proposing evaluation measures for each question. The first and principal contribution is an evaluation measure that characterizes the translation quality of an entire n-best list by asking whether many of the valid translations are placed near the top of the list. The second is a measure that uses gold translations with preference annotations to ask to what degree systems can produce ranked lists in preference order. The third is a measure that rewards partial matches, evaluating the closeness of the many items in an n-best list to a set of many valid references. These three perspectives make clear that having access to many references can be useful when n-best evaluation is the goal."
2020.emnlp-main.7,Simulated multiple reference training improves low-resource machine translation,2020,30,0,3,1,4575,huda khayrallah,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Many valid translations exist for a given sentence, yet machine translation (MT) is trained with a single reference translation, exacerbating data sparsity in low-resource settings. We introduce Simulated Multiple Reference Training (SMRT), a novel MT training method that approximates the full space of possible translations by sampling a paraphrase of the reference sentence from a paraphraser and training the MT model to predict the paraphraser{'}s distribution over possible tokens. We demonstrate the effectiveness of SMRT in low-resource settings when translating to English, with improvements of 1.2 to 7.0 BLEU. We also find SMRT is complementary to back-translation."
2020.emnlp-main.8,Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing,2020,83,0,2,0,13891,brian thompson,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"We frame the task of machine translation evaluation as one of scoring machine translation output with a sequence-to-sequence paraphraser, conditioned on a human reference. We propose training the paraphraser as a multilingual NMT system, treating paraphrasing as a zero-shot translation task (e.g., Czech to Czech). This results in the paraphraser{'}s output mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a human reference. Our method is simple and intuitive, and does not require human judgements for training. Our single model (trained in 39 languages) outperforms or statistically ties with all prior metrics on the WMT 2019 segment-level shared metrics task in all languages (excluding Gujarati where the model had no training data). We also explore using our model for the task of quality estimation as a metric{---}conditioning on the source instead of the reference{---}and find that it significantly outperforms every submission to the WMT 2019 shared task on quality estimation in every language pair."
W19-6618,An Exploration of Placeholding in Neural Machine Translation,2019,0,0,1,1,9757,matt post,Proceedings of Machine Translation Summit XVII: Research Track,0,None
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,14,0,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
W19-5366,{JHU} 2019 Robustness Task System Description,2019,0,2,1,1,9757,matt post,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"We describe the JHU submissions to the French{--}English, Japanese{--}English, and English{--}Japanese Robustness Task at WMT 2019. Our goal was to evaluate the performance of baseline systems on both the official noisy test set as well as news data, in order to ensure that performance gains in the latter did not come at the expense of general-domain performance. To this end, we built straightforward 6-layer Transformer models and experimented with a handful of variables including subword processing (FRâEN) and a handful of hyperparameters settings (JAâEN). As expected, our systems performed reasonably."
N19-1090,Improved Lexically Constrained Decoding for Translation and Monolingual Rewriting,2019,0,7,6,0,26105,edward hu,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Lexically-constrained sequence decoding allows for explicit positive or negative phrase-based constraints to be placed on target output strings in generation tasks such as machine translation or monolingual text rewriting. We describe vectorized dynamic beam allocation, which extends work in lexically-constrained decoding to work with batching, leading to a five-fold improvement in throughput when working with positive constraints. Faster decoding enables faster exploration of constraint strategies: we illustrate this via data augmentation experiments with a monolingual rewriter applied to the tasks of natural language inference, question answering and machine translation, showing improvements in all three."
K19-1005,"Large-Scale, Diverse, Paraphrastic Bitexts via Sampling and Clustering",2019,0,0,4,0,26105,edward hu,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"Producing diverse paraphrases of a sentence is a challenging task. Natural paraphrase corpora are scarce and limited, while existing large-scale resources are automatically generated via back-translation and rely on beam search, which tends to lack diversity. We describe ParaBank 2, a new resource that contains multiple diverse sentential paraphrases, produced from a bilingual corpus using negative constraints, inference sampling, and clustering.We show that ParaBank 2 significantly surpasses prior work in both lexical and syntactic diversity while being meaning-preserving, as measured by human judgments and standardized metrics. Further, we illustrate how such paraphrastic resources may be used to refine contextualized encoders, leading to improvements in downstream tasks."
D19-1084,A Discriminative Neural Model for Cross-Lingual Word Alignment,2019,0,3,3,0,666,elias stengeleskin,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"We introduce a novel discriminative word alignment model, which we integrate into a Transformer-based machine translation model. In experiments based on a small number of labeled examples (â¼1.7K{--}5K sentences) we evaluate its performance intrinsically on both English-Chinese and English-Arabic alignment, where we achieve major improvements over unsupervised baselines (11{--}27 F1). We evaluate the model extrinsically on data projection for Chinese NER, showing that our alignments lead to higher performance when used to project NER tags from English to Chinese. Finally, we perform an ablation analysis and an annotation experiment that jointly support the utility and feasibility of future manual alignment elicitation."
W18-6319,A Call for Clarity in Reporting {BLEU} Scores,2018,21,43,1,1,9757,matt post,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to {``}the{''} BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SACREBLEU, to facilitate this."
W18-1820,The Sockeye Neural Machine Translation Toolkit at {AMTA} 2018,2018,0,9,7,0,9985,felix hieber,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,None
N18-1119,Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation,2018,0,19,1,1,9757,matt post,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"The end-to-end nature of neural machine translation (NMT) removes many ways of manually guiding the translation process that were available in older paradigms. Recent work, however, has introduced a new capability: lexically constrained or guided decoding, a modification to beam search that forces the inclusion of pre-specified words and phrases in the output. However, while theoretically sound, existing approaches have computational complexities that are either linear (Hokamp and Liu, 2017) or exponential (Anderson et al., 2017) in the number of constraints. We present a algorithm for lexically constrained decoding with a complexity of O(1) in the number of constraints. We demonstrate the algorithm{'}s remarkable ability to properly place these constraints, and use it to explore the shaky relationship between model and BLEU scores. Our implementation is available as part of Sockeye."
W17-4717,Findings of the 2017 Conference on Machine Translation ({WMT}17),2017,0,109,13,0,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,"This paper presents the results of the WMT17 shared tasks, which includedn three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task."
W17-4724,The {JHU} Machine Translation Systems for {WMT} 2017,2017,0,2,4,0.666667,4416,shuoyang ding,Proceedings of the Second Conference on Machine Translation,0,None
P17-2030,Error-repair Dependency Parsing for Ungrammatical Texts,2017,20,1,2,0.9,6885,keisuke sakaguchi,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We propose a new dependency parsing scheme which jointly parses a sentence and repairs grammatical errors by extending the non-directional transition-based formalism of Goldberg and Elhadad (2010) with three additional actions: SUBSTITUTE, DELETE, INSERT. Because these actions may cause an infinite loop in derivation, we also introduce simple constraints that ensure the parser termination. We evaluate our model with respect to dependency accuracy and grammaticality improvements for ungrammatical sentences, demonstrating the robustness and applicability of our scheme."
I17-2004,Neural Lattice Search for Domain Adaptation in Machine Translation,2017,17,7,4,1,4575,huda khayrallah,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Domain adaptation is a major challenge for neural machine translation (NMT). Given unknown words or new domains, NMT systems tend to generate fluent translations at the expense of adequacy. We present a stack-based lattice search algorithm for NMT and show that constraining its search space with lattices generated by phrase-based machine translation (PBMT) improves robustness. We report consistent BLEU score gains across four diverse domain adaptation tasks involving medical, IT, Koran, or subtitles texts."
I17-2062,Grammatical Error Correction with Neural Reinforcement Learning,2017,0,7,2,0.9,6885,keisuke sakaguchi,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We propose a neural encoder-decoder model with reinforcement learning (NRL) for grammatical error correction (GEC). Unlike conventional maximum likelihood estimation (MLE), the model directly optimizes towards an objective that considers a sentence-level, task-specific evaluation metric, avoiding the exposure bias issue in MLE. We demonstrate that NRL outperforms MLE both in human and automated evaluation metrics, achieving the state-of-the-art on a fluency-oriented GEC corpus."
E17-2018,A Rich Morphological Tagger for {E}nglish: Exploring the Cross-Linguistic Tradeoff Between Morphology and Syntax,2017,11,4,5,0,6613,christo kirov,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"A traditional claim in linguistics is that all human languages are equally expressive{---}able to convey the same wide range of meanings. Morphologically rich languages, such as Czech, rely on overt inflectional and derivational morphology to convey many semantic distinctions. Languages with comparatively limited morphology, such as English, should be able to accomplish the same using a combination of syntactic and contextual cues. We capitalize on this idea by training a tagger for English that uses syntactic features obtained by automatic parsing to recover complex morphological tags projected from Czech. The high accuracy of the resulting model provides quantitative confirmation of the underlying linguistic hypothesis of equal expressivity, and bodes well for future improvements in downstream HLT tasks including machine translation."
W16-2301,Findings of the 2016 Conference on Machine Translation,2016,113,137,15,0,292,ondvrej bojar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 shared tasks, which included five machine translation (MT) tasks (standard news, IT-domain, biomedical, multimodal, pronoun), three evaluation tasks (metrics, tuning, run-time estimation of MT quality), and an automatic post-editing task and bilingual document alignment task. This year, 102 MT systems from 24 institutions (plus 36 anonymized online systems) were submitted to the 12 translation directions in the news translation task. The IT-domain task received 31 submissions from 12 institutions in 7 directions and the Biomedical task received 15 submissions systems from 5 institutions. Evaluation was both automatic and manual (relative ranking and 100-point scale assessments). The quality estimation task had three subtasks, with a total of 14 teams, submitting 39 entries. The automatic post-editing task had a total of 6 teams, submitting 11 entries."
W16-2310,The {JHU} Machine Translation Systems for {WMT} 2016,2016,29,8,5,0.666667,4416,shuoyang ding,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the submission of Johns Hopkins University for the shared translation task of ACL 2016 First Conference on Machine Translation (WMT 2016). We set up phrase-based, hierarchical phrase-based and syntax-based systems for all 12 language pairs of this yearxe2x80x99s evaluation campaign. Novel research directions we investigated include: neural probabilistic language models, bilingual neural network language models, morphological segmentation, and the attentionbased neural machine translation model as reranking feature."
Q16-1013,Reassessing the Goals of Grammatical Error Correction: Fluency Instead of Grammaticality,2016,28,21,3,0.9,6885,keisuke sakaguchi,Transactions of the Association for Computational Linguistics,0,"The field of grammatical error correction (GEC) has grown substantially in recent years, with research directed at both evaluation metrics and improved system performance against those metrics. One unvisited assumption, however, is the reliance of GEC evaluation on error-coded corpora, which contain specific labeled corrections. We examine current practices and show that GEC{'}s reliance on such corpora unnaturally constrains annotation and automatic evaluation, resulting in (a) sentences that do not sound acceptable to native speakers and (b) system rankings that do not correlate with human judgments. In light of this, we propose an alternate approach that jettisons costly error coding in favor of unannotated, whole-sentence rewrites. We compare the performance of existing metrics over different gold-standard annotations, and show that automatic evaluation with our new annotation scheme has very strong correlation with expert rankings (Ï = 0.82). As a result, we advocate for a fundamental and necessary shift in the goal of GEC, from correcting small, labeled error types, to producing text that has native fluency."
N16-3013,Sentential Paraphrasing as Black-Box Machine Translation,2016,12,6,3,0.657895,21492,courtney napoles,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,None
2016.amta-users.29,Putting the {``}human{''} back in {HLT}: The importance of human evaluation in assessing the quality and potential uses of translation technology,2016,-1,-1,4,0,36245,erica michael,Conferences of the Association for Machine Translation in the Americas: MT Users' Track,0,None
2016.amta-researchers.14,"Automatic Construction of Morphologically Motivated Translation Models for Highly Inflected, Low-Resource Languages",2016,-1,-1,2,0,4107,john hewitt,Conferences of the Association for Machine Translation in the Americas: MT Researchers' Track,0,"Statistical Machine Translation (SMT) of highly inflected, low-resource languages suffers from the problem of low bitext availability, which is exacerbated by large inflectional paradigms. When translating into English, rich source inflections have a high chance of being poorly estimated or out-of-vocabulary (OOV). We present a source language-agnostic system for automatically constructing phrase pairs from foreign-language inflections and their morphological analyses using manually constructed datasets, including Wiktionary. We then demonstrate the utility of these phrase tables in improving translation into English from Finnish, Czech, and Turkish in simulated low-resource settings, finding substantial gains in translation quality. We report up to +2.58 BLEU in a simulated low-resource setting and +1.65 BLEU in a moderateresource setting. We release our morphologically-motivated translation models, with tens of thousands of inflections in each of 8 languages."
W15-3001,Findings of the 2015 Workshop on Statistical Machine Translation,2015,78,107,11,0.07424,292,ondvrej bojar,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT15 shared tasks, which included a standard news translation task, a metrics task, a tuning task, a task for run-time estimation of machine translation quality, and an automatic post-editing task. This year, 68 machine translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries."
P15-2097,Ground Truth for Grammatical Error Correction Metrics,2015,11,50,3,0.657895,21492,courtney napoles,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,None
W14-3301,Efficient Elicitation of Annotations for Human Evaluation of Machine Translation,2014,12,25,2,1,6885,keisuke sakaguchi,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"A main output of the annual Workshop on Statistical Machine Translation (WMT) is a ranking of the systems that participated in its shared translation tasks, produced by aggregating pairwise sentencelevel comparisons collected from human judges. Over the past few years, there have been a number of tweaks to the aggregation formula in attempts to address issues arising from the inherent ambiguity and subjectivity of the task, as well as weaknesses in the proposed models and the manner of model selection. We continue this line of work by adapting the TrueSkill TM algorithm xe2x80x94 an online approach for modeling the relative skills of players in ongoing competitions, such as Microsoftxe2x80x99s Xbox Live xe2x80x94 to the human evaluation of machine translation output. Our experimental results show that TrueSkill outperforms other recently proposed models on accuracy, and also can significantly reduce the number of pairwise annotations that need to be collected by sampling non-uniformly from the space of system competitions."
W14-3302,Findings of the 2014 Workshop on Statistical Machine Translation,2014,75,148,9,0.0864455,292,ondvrej bojar,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT14 shared tasks, which included a standard news translation task, a separate medical translation task, a task for run-time estimation of machine translation quality, and a metrics task. This year, 143 machine translation systems from 23 institutions were submitted to the ten translation directions in the standard translation task. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had four subtasks, with a total of 10 teams, submitting 57 entries"
Q14-1007,The Language Demographics of {A}mazon {M}echanical {T}urk,2014,37,42,2,0,7335,ellie pavlick,Transactions of the Association for Computational Linguistics,0,"We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers{'} self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems."
drexler-etal-2014-wikipedia,A {W}ikipedia-based Corpus for Contextualized Machine Translation,2014,13,1,5,0,39407,jennifer drexler,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We describe a corpus for target-contextualized machine translation (MT), where the task is to improve the translation of source documents using language models built over presumably related documents in the target language. The idea presumes a situation where most of the information about a topic is in a foreign language, yet some related target-language information is known to exist. Our corpus comprises a set of curated English Wikipedia articles describing news events, along with (i) their Spanish counterparts and (ii) some of the Spanish source articles cited within them. In experiments, we translated these Spanish documents, treating the English articles as target-side context, and evaluate the effect on translation quality when including target-side language models built over this English context and interpolated with other, separately-derived language model data. We find that even under this simplistic baseline approach, we achieve significant improvements as measured by BLEU score."
W13-2201,Findings of the 2013 {W}orkshop on {S}tatistical {M}achine {T}ranslation,2013,86,192,8,0.0864455,292,ondvrej bojar,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries."
W13-2226,"{J}oshua 5.0: Sparser, Better, Faster, Server",2013,27,16,1,1,9757,matt post,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,None
Q13-1014,Learning to translate with products of novices: a suite of open-ended challenge problems for teaching {MT},2013,57,5,2,0,1313,adam lopez,Transactions of the Association for Computational Linguistics,0,"Machine translation (MT) draws from several different disciplines, making it a complex subject to teach. There are excellent pedagogical texts, but problems in MT and current algorithms for solving them are best learned by doing. As a centerpiece of our MT course, we devised a series of open-ended challenges for students in which the goal was to improve performance on carefully constrained instances of four key MT tasks: alignment, decoding, evaluation, and reranking. Students brought a diverse set of techniques to the problems, including some novel solutions which performed remarkably well. A surprising and exciting outcome was that student solutions or their combinations fared competitively on some tasks, demonstrating that even newcomers to the field can help improve the state-of-the-art on hard NLP problems while simultaneously learning a great deal. The problems, baseline code, and results are freely available."
P13-2150,Explicit and Implicit Syntactic Features for Text Classification,2013,36,31,1,1,9757,matt post,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duy, 2001) have been perhaps the most robust and eective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the dicult question of which tree features to use for a given task. We compare tree kernels to dierent explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly available tools), we suggest they should always be included as baseline comparisons in tree kernel method evaluations."
2013.iwslt-papers.14,Improved speech-to-text translation with the Fisher and Callhome {S}panish-{E}nglish speech translation corpus,2013,25,39,1,1,9757,matt post,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"Research into the translation of the output of automatic speech recognition (ASR) systems is hindered by the dearth of datasets developed for that explicit purpose. For SpanishEnglish translation, in particular, most parallel data available exists only in vastly different domains and registers. In order to support research on cross-lingual speech applications, we introduce the Fisher and Callhome Spanish-English Speech Translation Corpus, supplementing existing LDC audio and transcripts with (a) ASR 1-best, lattice, and oracle output produced by the Kaldi recognition system and (b) English translations obtained on Amazon{'}s Mechanical Turk. The result is a four-way parallel dataset of Spanish audio, transcriptions, ASR lattices, and English translations of approximately 38 hours of speech, with defined training, development, and held-out test sets. We conduct baseline machine translation experiments using models trained on the provided training data, and validate the dataset by corroborating a number of known results in the field, including the utility of in-domain (information, conversational) training data, increased performance translating lattices (instead of recognizer 1-best output), and the relationship between word error rate and BLEU score."
W12-3102,Findings of the 2012 Workshop on Statistical Machine Translation,2012,63,247,4,0.0104116,3274,chris callisonburch,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT12 shared tasks, which included a translation task, a task for machine translation evaluation metrics, and a task for run-time estimation of machine translation quality. We conducted a large-scale manual evaluation of 103 machine translation systems submitted by 34 teams. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 12 evaluation metrics. We introduced a new quality estimation task this year, and evaluated submissions from 11 teams."
W12-3134,"{J}oshua 4.0: Packing, {PRO}, and Paraphrases",2012,21,29,4,0.652174,37410,juri ganitkevitch,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We present Joshua 4.0, the newest version of our open-source decoder for parsing-based statistical machine translation. The main contributions in this release are the introduction of a compact grammar representation based on packed tries, and the integration of our implementation of pairwise ranking optimization, J-PRO. We further present the extension of the Thrax SCFG grammar extractor to pivot-based extraction of syntactically informed sentential paraphrases."
W12-3152,Constructing Parallel Corpora for Six {I}ndian Languages via Crowdsourcing,2012,19,69,1,1,9757,matt post,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"Recent work has established the efficacy of Amazon's Mechanical Turk for constructing parallel corpora for machine translation research. We apply this to building a collection of parallel corpora between English and six languages from the Indian subcontinent: Bengali, Hindi, Malayalam, Tamil, Telugu, and Urdu. These languages are low-resource, under-studied, and exhibit linguistic phenomena that are difficult for machine translation. We conduct a variety of baseline experiments and analysis, and release the data to the community."
W12-2013,Judging Grammaticality with Count-Induced Tree Substitution Grammars,2012,20,4,2,0,4358,francis ferraro,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"Prior work has shown the utility of syntactic tree fragments as features in judging the grammaticality of text. To date such fragments have been extracted from derivations of Bayesian-induced Tree Substitution Grammars (TSGs). Evaluating on discriminative coarse and fine grammaticality classification tasks, we show that a simple, deterministic, count-based approach to fragment identification performs on par with the more complicated grammars of Post (2011). This represents a significant reduction in complexity for those interested in the use of such fragments in the development of systems for the educational domain."
W12-1904,Toward Tree Substitution Grammars with Latent Annotations,2012,21,0,3,0,4358,francis ferraro,Proceedings of the {NAACL}-{HLT} Workshop on the Induction of Linguistic Structure,0,"We provide a model that extends the splitmerge framework of Petrov et al. (2006) to jointly learn latent annotations and Tree Substitution Grammars (TSGs). We then conduct a variety of experiments with this model, first inducing grammars on a portion of the Penn Treebank and the Korean Treebank 2.0, and next experimenting with grammar refinement from a single nonterminal and from the Universal Part of Speech tagset. We present qualitative analysis showing promising signs across all experiments that our combined approach successfully provides for greater flexibility in grammar induction within the structured guidance provided by the treebank, leveraging the complementary natures of these two approaches."
N12-1033,Stylometric Analysis of Scientific Articles,2012,54,61,2,0,39132,shane bergsma,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present an approach to automatically recover hidden attributes of scientific articles, such as whether the author is a native English speaker, whether the author is a male or a female, and whether the paper was published in a conference or workshop proceedings. We train classifiers to predict these attributes in computational linguistics papers. The classifiers perform well in this challenging domain, identifying non-native writing with 95% accuracy (over a baseline of 67%). We show the benefits of using syntactic features in stylometry; syntax leads to significant improvements over bag-of-words models on all three tasks, achieving 10% to 25% relative error reduction. We give a detailed analysis of which words and syntax most predict a particular attribute, and we show a strong correlation between our predictions and a paper's number of citations."
W11-2160,{J}oshua 3.0: Syntax-based Machine Translation with the Thrax Grammar Extractor,2011,22,28,4,0.784314,40079,jonathan weese,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"We present progress on Joshua, an open-source decoder for hierarchical and syntax-based machine translation. The main focus is describing Thrax, a flexible, open source synchronous context-free grammar extractor. Thrax extracts both hierarchical (Chiang, 2007) and syntax-augmented machine translation (Zollmann and Venugopal, 2006) grammars. It is built on Apache Hadoop for efficient distributed performance, and can easily be extended with support for new grammars, feature functions, and output formats."
P11-2038,Judging Grammaticality with Tree Substitution Grammar Derivations,2011,27,20,1,1,9757,matt post,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we show that local features computed from the derivations of tree substitution grammars --- such as the identify of particular fragments, and a count of large and small fragments --- are useful in binary grammatical classification tasks. Such features outperform n-gram features and various model scores by a wide margin. Although they fall short of the performance of the hand-crafted feature set of Charniak and Johnson (2005) developed for parse tree reranking, they do so with an order of magnitude fewer features. Furthermore, since the TSGs employed are learned in a Bayesian setting, the use of their derivations can be viewed as the automatic discovery of tree patterns useful for classification. On the BLLIP dataset, we achieve an accuracy of 89.9% in discriminating between grammatical text and samples from an n-gram language model."
W10-1406,Factors Affecting the Accuracy of {K}orean Parsing,2010,27,14,2,0,2983,tagyoung chung,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"We investigate parsing accuracy on the Korean Treebank 2.0 with a number of different grammars. Comparisons among these grammars and to their English counterparts suggest different aspects of Korean that contribute to parsing difficulty. Our results indicate that the coarseness of the Treebank's nonterminal set is a even greater problem than in the English Treebank. We also find that Korean's relatively free word order does not impact parsing results as much as one might expect, but in fact the prevalence of zero pronouns accounts for a large portion of the difference between Korean and English parsing scores."
W09-3815,Weight Pushing and Binarization for Fixed-Grammar Parsing,2009,14,8,1,1,9757,matt post,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We apply the idea of weight pushing (Mohri, 1997) to CKY parsing with fixed context-free grammars. Applied after rule binarization, weight pushing takes the weight from the original grammar rule and pushes it down across its binarized pieces, allowing the parser to make better pruning decisions earlier in the parsing process. This process can be viewed as generalizing weight pushing from transducers to hypergraphs. We examine its effect on parsing efficiency with various binarization schemes applied to tree substitution grammars from previous work. We find that weight pushing produces dramatic improvements in efficiency, especially with small amounts of time and with large grammars."
P09-2012,{B}ayesian Learning of a Tree Substitution Grammar,2009,9,61,1,1,9757,matt post,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"Tree substitution grammars (TSGs) offer many advantages over context-free grammars (CFGs), but are hard to learn. Past approaches have resorted to heuristics. In this paper, we learn a TSG using Gibbs sampling with a nonparametric prior to control subtree size. The learned grammars perform significantly better than heuristically extracted ones on parsing accuracy."
2008.amta-papers.16,Parsers as language models for statistical machine translation,2008,20,21,1,1,9757,matt post,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Most work in syntax-based machine translation has been in translation modeling, but there are many reasons why we may instead want to focus on the language model. We experiment with parsers as language models for machine translation in a simple translation model. This approach demands much more of the language models, allowing us to isolate their strengths and weaknesses. We find that unmodified parsers do not improve BLEU scores over ngram language models, and provide an analysis of their strengths and weaknesses."
