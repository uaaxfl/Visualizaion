2021.acl-short.16,Machine Translation into Low-resource Language Varieties,2021,-1,-1,3,0.952381,5228,sachin kumar,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"State-of-the-art machine translation (MT) systems are typically trained to generate {``}standard{''} target language; however, many languages have multiple varieties (regional varieties, dialects, sociolects, non-native varieties) that are different from the standard language. Such varieties are often low-resource, and hence do not benefit from contemporary NLP solutions, MT included. We propose a general framework to rapidly adapt MT systems to generate language varieties that are close to, but different from, the standard target language, using no parallel (source{--}variety) data. This also includes adaptation of MT systems to low-resource typologically-related target languages. We experiment with adapting an English{--}Russian MT system to generate Ukrainian and Belarusian, an English{--}Norwegian Bokm{\aa}l system to generate Nynorsk, and an English{--}Arabic system to generate four Arabic dialects, obtaining significant improvements over competitive baselines."
R19-1130,Automatic Detection of Translation Direction,2019,0,0,2,0,25360,ilia sominsky,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Parallel corpora are crucial resources for NLP applications, most notably for machine translation. The direction of the (human) translation of parallel corpora has been shown to have significant implications for the quality of statistical machine translation systems that are trained with such corpora. We describe a method for determining the direction of the (manual) translation of parallel corpora at the sentence-pair level. Using several linguistically-motivated features, coupled with a neural network model, we obtain high accuracy on several language pairs. Furthermore, we demonstrate that the accuracy is correlated with the (typological) distance between the two languages."
D19-1425,Topics to Avoid: Demoting Latent Confounds in Text Classification,2019,0,2,2,0.952381,5228,sachin kumar,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Despite impressive performance on many text classification tasks, deep neural networks tend to learn frequent superficial patterns that are specific to the training data and do not always generalize well. In this work, we observe this limitation with respect to the task of \textit{native language identification}. We find that standard text classifiers which perform well on the test set end up learning topical features which are confounds of the prediction task (e.g., if the input text mentions Sweden, the classifier predicts that the author{'}s native language is Swedish). We propose a method that represents the latent topical confounds and a model which {``}unlearns{''} confounding features by predicting both the label of the input text and the confound; but we train the two predictors adversarially in an alternating fashion to learn a text representation that predicts the correct label but is less prone to using information about the confound. We show that this model generalizes better and learns features that are indicative of the writing style rather than the content."
Q18-1024,Native Language Cognate Effects on Second Language Lexical Choice,2018,20,0,3,1,8815,ella rabinovich,Transactions of the Association for Computational Linguistics,0,"We present a computational analysis of cognate effects on the spontaneous linguistic productions of advanced non-native speakers. Introducing a large corpus of highly competent non-native English speakers, and using a set of carefully selected lexical items, we show that the lexical choices of non-natives are affected by cognates in their native language. This effect is so powerful that we are able to reconstruct the phylogenetic language tree of the Indo-European language family solely from the frequencies of specific lexical items in the English of authors with various native languages. We quantitatively analyze non-native lexical choice, highlighting cognate facilitation as one of the important phenomena shaping the language of non-native speakers."
D18-1393,Framing and Agenda-setting in {R}ussian News: a Computational Analysis of Intricate Political Strategies,2018,0,9,3,0,11320,anjalie field,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Amidst growing concern over media manipulation, NLP attention has focused on overt strategies like censorship and {``}fake news{''}. Here, we draw on two concepts from political science literature to explore subtler strategies for government media manipulation: agenda-setting (selecting what topics to cover) and framing (deciding how topics are covered). We analyze 13 years (100K articles) of the Russian newspaper Izvestia and identify a strategy of distraction: articles mention the U.S. more frequently in the month directly following an economic downturn in Russia. We introduce embedding-based methods for cross-lingually projecting English frames to Russian, and discover that these articles emphasize U.S. moral failings and threats to the U.S. Our work offers new ways to identify subtle media manipulation strategies at the intersection of agenda-setting and framing."
D18-1395,Native Language Identification with User Generated Content,2018,0,5,3,0,30630,gili goldin,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We address the task of native language identification in the context of social media content, where authors are highly-fluent, advanced nonnative speakers (of English). Using both linguistically-motivated features and the characteristics of the social media outlet, we obtain high accuracy on this challenging task. We provide a detailed analysis of the features that sheds light on differences between native and nonnative speakers, and among nonnative speakers with different backgrounds."
P17-1049,Found in Translation: Reconstructing Phylogenetic Language Trees from Translations,2017,34,1,3,1,8815,ella rabinovich,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Translation has played an important role in trade, law, commerce, politics, and literature for thousands of years. Translators have always tried to be invisible; ideal translations should look as if they were written originally in the target language. We show that traces of the source language remain in the translation product to the extent that it is possible to uncover the history of the source language by looking only at the translation. Specifically, we automatically reconstruct phylogenetic language trees from monolingual texts (translated from several source languages). The signal of the source language is so powerful that it is retained even after two phases of translation. This strongly indicates that source language interference is the most dominant characteristic of translated texts, overshadowing the more subtle signals of universal properties of translation."
E17-1101,Personalized Machine Translation: Preserving Original Author Traits,2017,26,16,5,1,8815,ella rabinovich,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"The language that we produce reflects our personality, and various personal and demographic characteristics can be detected in natural language texts. We focus on one particular personal trait of the author, gender, and study how it is manifested in original texts and in translations. We show that author{'}s gender has a powerful, clear signal in originals texts, but this signal is obfuscated in human and machine translation. We then propose simple domain-adaptation techniques that help retain the original gender traits in the translation, without harming the quality of the translation, thereby creating more personalized machine translation systems."
P16-1176,"On the Similarities Between Native, Non-native and Translated Texts",2016,61,4,4,1,8815,ella rabinovich,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a computational analysis of three language varieties: native, advanced non-native, and translation. Our goal is to investigate the similarities and differences between non-native language productions and translations, contrasting both with native language. Using a collection of computational methods we establish three main results: (1) the three types of texts are easily distinguishable; (2) nonnative language and translations are closer to each other than each of them is to native language; and (3) some of these characteristics depend on the source or native language, while others do not, reflecting, perhaps, unified principles that similarly affect translations and non-native language."
L16-1664,"A Corpus of Native, Non-native and Translated Texts",2016,0,3,4,0,18363,sergiu nisioi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We describe a monolingual English corpus of original and (human) translated texts, with an accurate annotation of speaker properties, including the original language of the utterances and the speaker{'}s country of origin. We thus obtain three sub-corpora of texts reflecting native English, non-native English, and English translated from a variety of European languages. This dataset will facilitate the investigation of similarities and differences between these kinds of sub-languages. Moreover, it will facilitate a unified comparative study of translations and language produced by (highly fluent) non-native speakers, two closely-related phenomena that have only been studied in isolation so far."
C16-3005,{T}ranslationese: Between Human and Machine Translation,2016,0,1,1,1,12510,shuly wintner,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Tutorial Abstracts",0,"Translated texts, in any language, have unique characteristics that set them apart from texts originally written in the same language. Translation Studies is a research field that focuses on investigating these characteristics. Until recently, research in machine translation (MT) has been entirely divorced from translation studies. The main goal of this tutorial is to introduce some of the findings of translation studies to researchers interested mainly in machine translation, and to demonstrate that awareness to these findings can result in better, more accurate MT systems."
W15-3002,Statistical Machine Translation with Automatic Identification of Translationese,2015,16,2,3,0,36850,naama twitto,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"Translated texts (in any language) are so markedly different from original ones that text classification techniques can be used to tease them apart. Previous work has shown that awareness to these differences can significantly improve statistical machine translation. These results, however, required meta-information on the ontological status of texts (original or translated) which is typically unavailable. In this work we show that the predictions of translationese classifiers are as good as meta-information. First, when a monolingual corpus in the target language is given, to be used for constructing a language model, predicting the translated portions of the corpus, and using only them for the language model, is as good as using the entire corpus. Second, identifying the portions of a parallel corpus that are translated in the direction of the translation task, and using only them for the translation model, is as good as using the entire corpus. We present results from several language pairs and various data sets, indicating that these results are robust and general."
Q15-1030,Unsupervised Identification of Translationese,2015,21,17,2,1,8815,ella rabinovich,Transactions of the Association for Computational Linguistics,0,"Translated texts are distinctively different from original ones, to the extent that supervised text classification methods can distinguish between them with high accuracy. These differences were proven useful for statistical machine translation. However, it has been suggested that the accuracy of translation detection deteriorates when the classifier is evaluated outside the domain it was trained on. We show that this is indeed the case, in a variety of evaluation scenarios. We then show that unsupervised classification is highly accurate on this task. We suggest a method for determining the correct labels of the clustering outcomes, and then use the labels for voting, improving the accuracy even further. Moreover, we suggest a simple method for clustering in the challenging case of mixed-domain datasets, in spite of the dominance of domain-related features over translation-related ones. The result is an effective, fully-unsupervised method for distinguishing between original and translated texts that can be applied to new domains with reasonable accuracy."
J14-2007,Identification of Multiword Expressions by Combining Multiple Linguistic Information Sources,2014,-1,-1,2,0.833333,3965,yulia tsvetkov,Computational Linguistics,0,None
W13-1736,Identifying the {L}1 of non-native writers: the {CMU}-Haifa system,2013,29,13,7,1,3965,yulia tsvetkov,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We show that it is possible to learn to identify, with high accuracy, the native language of English test takers from the content of the essays they write. Our method uses standard text classification techniques based on multiclass logistic regression, combining individually weak indicators to predict the most probable native language from a set of 11 possibilities. We describe the various features used for classification, as well as the settings of the classifier that yielded the highest accuracy."
J13-4007,Improving Statistical Machine Translation by Adapting Translation Models to Translationese,2013,35,17,3,1,41636,gennadi lembersky,Computational Linguistics,0,"Translation models used for statistical machine translation are compiled from parallel corpora that are manually translated. The common assumption is that parallel texts are symmetrical: The direction of translation is deemed irrelevant and is consequently ignored. Much research in Translation Studies indicates that the direction of translation matters, however, as translated language translationese has many unique properties. It has already been shown that phrase tables constructed from parallel corpora translated in the same direction as the translation task outperform those constructed from corpora translated in the opposite direction.n n We reconfirm that this is indeed the case, but emphasize the importance of also using texts translated in the wrong direction. We take advantage of information pertaining to the direction of translation in constructing phrase tables by adapting the translation model to the special properties of translationese. We explore two adaptation techniques: First, we create a mixture model by interpolating phrase tables trained on texts translated in the right and the wrong directions. The weights for the interpolation are determined by minimizing perplexity. Second, we define entropy-based measures that estimate the correspondence of target-language phrases to translationese, thereby eliminating the need to annotate the parallel corpus with information pertaining to the direction of translation. We show that incorporating these measures as features in the phrase tables of statistical machine translation systems results in consistent, statistically significant improvement in the quality of the translation."
W12-0904,A Morphologically Annotated {H}ebrew {CHILDES} Corpus,2012,5,4,4,0,42508,aviad albert,Proceedings of the Workshop on Computational Models of Language Acquisition and Loss,0,"We present a corpus of transcribed spoken Hebrew that reflects spoken interactions between children and adults. The corpus is an integral part of the CHILDES database, which distributes similar corpora for over 25 languages. We introduce a dedicated transcription scheme for the spoken Hebrew data that is sensitive to both the phonology and the standard orthography of the language. We also introduce a morphological analyzer that was specifically developed for this corpus. The analyzer adequately covers the entire corpus, producing detailed correct analyses for all tokens. Evaluation on a new corpus reveals high coverage as well. Finally, we describe a morphological disambiguation module that selects the correct analysis of each token in context. The result is a high-quality morphologically-annotated CHILDES corpus of Hebrew, along with a set of tools that can be applied to new corpora."
W12-0514,Incorporating Linguistic Knowledge in Statistical Machine Translation: Translating Prepositions,2012,23,9,3,0,24423,reshef shilon,Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data,0,"Prepositions are hard to translate, because their meaning is often vague, and the choice of the correct preposition is often arbitrary. At the same time, making the correct choice is often critical to the coherence of the output text. In the context of statistical machine translation, this difficulty is enhanced due to the possible long distance between the preposition and the head it modifies, as opposed to the local nature of standard language models. In this work we use monolingual language resources to determine the set of prepositions that are most likely to occur with each verb. We use this information in a transfer-based Arabic-to-Hebrew statistical machine translation system. We show that incorporating linguistic knowledge on the distribution of prepositions significantly improves the translation quality."
J12-4004,Language Models for Machine Translation: Original vs. Translated Texts,2012,18,0,3,1,41636,gennadi lembersky,Computational Linguistics,0,We investigate the differences between language models compiled from original target-language texts and those compiled from texts manually translated to the target language. Corroborating establish...
E12-1026,Adapting Translation Models to Translationese Improves {SMT},2012,28,30,3,1,41636,gennadi lembersky,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Translation models used for statistical machine translation are compiled from parallel corpora; such corpora are manually translated, but the direction of translation is usually unknown, and is consequently ignored. However, much research in Translation Studies indicates that the direction of translation matters, as translated language (translationese) has many unique properties. Specifically, phrase tables constructed from parallel corpora translated in the same direction as the translation task perform better than ones constructed from corpora translated in the opposite direction.n n We reconfirm that this is indeed the case, but emphasize the importance of using also texts translated in the 'wrong' direction. We take advantage of information pertaining to the direction of translation in constructing phrase tables, by adapting the translation model to the special properties of translationese. We define entropy-based measures that estimate the correspondence of target-language phrases to translationese, thereby eliminating the need to annotate the parallel corpus with information pertaining to the direction of translation. We show that incorporating these measures as features in the phrase tables of statistical machine translation systems results in consistent, statistically significant improvement in the quality of the translation."
J11-1003,Towards Modular Development of Typed Unification Grammars,2011,49,2,2,0,44749,yael sygal,Computational Linguistics,0,"Development of large-scale grammars for natural languages is a complicated endeavor: Grammars are developed collaboratively by teams of linguists, computational linguists, and computer scientists, in a process very similar to the development of large-scale software. Grammars are written in grammatical formalisms that resemble very-high-level programming languages, and are thus very similar to computer programs. Yet grammar engineering is still in its infancy: Few grammar development environments support sophisticated modularized grammar development, in the form of distribution of the grammar development effort, combination of sub-grammars, separate compilation and automatic linkage, information encapsulation, and so forth.n n This work provides preliminary foundations for modular construction of (typed) unification grammars for natural languages. Much of the information in such formalisms is encoded by the type signature, and we subsequently address the problem through the distribution of the signature among the different modules. We define signature modules and provide operators of module combination. Modules may specify only partial information about the components of the signature and may communicate through parameters, similarly to function calls in programming languages. Our definitions are inspired by methods and techniques of programming language theory and software engineering and are motivated by the actual needs of grammar developers, obtained through a careful examination of existing grammars. We show that our definitions meet these needs by conforming to a detailed set of desiderata. We demonstrate the utility of our definitions by providing a modular design of the HPSG grammar of Pollard and Sag."
D11-1034,Language Models for Machine Translation: Original vs. Translated Texts,2011,40,61,3,1,41636,gennadi lembersky,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We investigate the differences between language models compiled from original target-language texts and those compiled from texts manually translated to the target language. Corroborating established observations of Translation Studies, we demonstrate that the latter are significantly better predictors of translated sentences than the former, and hence fit the reference set better. Furthermore, translated texts yield better language models for statistical machine translation than original texts."
D11-1077,Identification of Multi-word Expressions by Combining Multiple Linguistic Information Sources,2011,56,25,2,1,3965,yulia tsvetkov,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We propose an architecture for expressing various linguistically-motivated features that help identify multi-word expressions in natural language texts. The architecture combines various linguistically-motivated classification features in a Bayesian Network. We introduce novel ways for computing many of these features, and manually define linguistically-motivated interrelationships among them, which the Bayesian network models. Our methodology is almost entirely unsupervised and completely language-independent; it relies on few language resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines."
kirschenbaum-wintner-2010-general,A General Method for Creating a Bilingual Transliteration Dictionary,2010,11,11,2,0,45829,amit kirschenbaum,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Transliteration is the rendering in one language of terms from another language (and, possibly, another writing system), approximating spelling and/or phonetic equivalents between the two languages. A transliteration dictionary is a crucial resource for a variety of natural language applications, most notably machine translation. We describe a general method for creating bilingual transliteration dictionaries from Wikipedia article titles. The method can be applied to any language pair with Wikipedia presence, independently of the writing systems involved, and requires only a single simple resource that can be provided by any literate bilingual speaker. It was successfully applied to extract a Hebrew-English transliteration dictionary which, when incorporated in a machine translation system, indeed improved its performance."
tsvetkov-wintner-2010-automatic,Automatic Acquisition of Parallel Corpora from Websites with Dynamic Content,2010,12,18,2,1,3965,yulia tsvetkov,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Parallel corpora are indispensable resources for a variety of multilingual natural language processing tasks. This paper presents a technique for fully automatic construction of constantly growing parallel corpora. We propose a simple and effective dictionary-based algorithm to extract parallel document pairs from a large collection of articles retrieved from the Internet, potentially containing manually translated texts. This algorithm was implemented and tested on Hebrew-English parallel texts. With properly selected thresholds, precision of 100{\%} can be obtained."
nir-etal-2010-morphologically,A Morphologically-Analyzed {CHILDES} Corpus of {H}ebrew,2010,9,7,3,0,42509,bracha nir,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,We present a corpus of transcribed spoken Hebrew that forms an integral part of a comprehensive data system that has been developed to suit the specific needs and interests of child language researchers: CHILDES (Child Language Data Exchange System). We introduce a dedicated transcription scheme for the spoken Hebrew data that is aware both of the phonology and of the standard orthography of the language. We also introduce a morphological analyzer that was specifically developed for this corpus.
C10-2144,Extraction of Multi-word Expressions from Small Parallel Corpora,2010,49,25,2,1,3965,yulia tsvetkov,Coling 2010: Posters,0,"We present a general methodology for extracting multi-word expressions (of various types), along with their translations, from small parallel corpora. We automatically align the parallel corpus and focus on misalignments; these typically indicate expressions in the source language that are translated to the target in a non-compositional way. We then use a large monolingual corpus to rank and filter the results. Evaluation of the quality of the extraction algorithm reveals significant improvements over naive alignment-based methods. External evaluation shows an improvement in the performance of machine translation that uses the extracted dictionary."
C10-1002,Identifying Multi-word Expressions by Leveraging Morphological and Syntactic Idiosyncrasy,2010,21,20,2,0,45511,hassan alhaj,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Multi-word expressions constitute a significant portion of the lexicon of every natural language, and handling them correctly is mandatory for various NLP applications. Yet such entities are notoriously hard to define, and are consequently missing from standard lexicons and dictionaries. Multi-word expressions exhibit idiosyncratic behavior on various levels: orthographic, morphological, syntactic and semantic. In this work we take advantage of the morphological and syntactic idiosyncrasy of Hebrew noun compounds and employ it to extract such expressions from text corpora. We show that relying on linguistic information dramatically improves the accuracy of compound extraction, reducing over one third of the errors compared with the best baseline."
2010.amta-srw.4,"Machine Translation between {H}ebrew and {A}rabic: Needs, Challenges and Preliminary Solutions",2010,14,9,4,0,24423,reshef shilon,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Student Research Workshop,0,"Hebrew and Arabic are related but mutually incomprehensible languages with complex morphology and scarce parallel corpora. Machine translation between the two languages is therefore interesting and challenging. We discuss similarities and differences between Hebrew and Arabic, the benefits and challenges that they induce, respectively, and their implications for machine translation. We highlight the shortcomings of using English as a pivot language and advocate a direct, transfer-based and linguistically-informed (but still statistical, and hence scalable) approach. We report preliminary results of such a system that we are currently developing."
J09-4012,Last Words: What Science Underlies Natural Language Engineering?,2009,21,21,1,1,12510,shuly wintner,Computational Linguistics,0,"One of the most thought-provoking proposals I have heard recently came from Lori Levin during the discussion that concluded the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics. Lori proposed that we should form an ACL Special Interest Group on Linguistics. At first blush, I found the idea weird: Isnxe2x80x99t it a little like the American Academy of Pediatrics forming a SIG on Medicine (or on Children)? Second thoughts, however, revealed the appropriateness of the idea: In essence, linguistics is altogether missing in contemporary natural language engineering research. In the following pages I want to call for the return of linguistics to computational linguistics. The last two decades were marked by a complete paradigm shift in computational linguistics. Frustrated by the inability of applications based on explicit linguistic knowledge to scale up to real-world needs, and, perhaps more deeply, frustrated with the dominating theories in formal linguistics, we looked instead to corpora that reflect language use as our sources of (implicit) knowledge. With the shift in methodology came a subtle change in the goals of our entire enterprise. Two decades ago, a computational linguist could be interested in developing NLP applications; or in formalizing (and reasoning about) linguistic processes. These days, it is the former only. A superficial look at the papers presented in our main conferences reveals that the vast majority of them are engineering papers, discussing engineering solutions to practical problems. Virtually none addresses fundamental issues in linguistics. Therexe2x80x99s nothing wrong with engineering work, of course. Every school of technology has departments of engineering in areas as diverse as Chemical Engineering, Mechanical Engineering, Aeronautical Engineering, or Biomedical Engineering; therexe2x80x99s no reason why there shouldnxe2x80x99t also be a discipline of Natural Language Engineering. But in the more established disciplines, engineering departments conduct research that is informed by some well-defined branch of science. Chemical engineers study chemistry; electrical engineers study physics; aeronautical engineers study dynamics; and biomedical engineers study biology, physiology, medical sciences, and so on. The success of engineering is also in part due to the choice of the xe2x80x9crightxe2x80x9d mathematics. The theoretical development of several scientific areas, notably physics, went alongside mathematical developments. Physics could not have accounted for natural phenomena without such mathematical infrastructure. For example, the development of (partial) differential equations went hand in hand with some of the greatest achievement in physics, and this branch of mathematics later turned out to be applicable also to chemistry, electrical engineering, and economics, among many other scientific fields."
E09-1050,Lightly Supervised Transliteration for Machine Translation,2009,35,12,2,0,45829,amit kirschenbaum,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"We present a Hebrew to English transliteration method in the context of a machine translation system. Our method uses machine learning to determine which terms are to be transliterated rather than translated. The training corpus for this purpose includes only positive examples, acquired semi-automatically. Our classifier reduces more than 38% of the errors made by a baseline method. The identified terms are then transliterated. We present an SMT-based transliteration model trained with a parallel corpus extracted from Wikipedia using a fairly simple method which requires minimal knowledge. The correct result is produced in more than 76% of the cases, and in 92% of the instances it is one of the top-5 results. We also demonstrate a small improvement in the performance of a Hebrew-to-English MT system that uses our transliteration module."
J08-3005,Identifying {S}emitic Roots: Machine Learning with Linguistic Constraints,2008,26,13,3,0,42592,ezra daya,Computational Linguistics,0,"Words in Semitic languages are formed by combining two morphemes: a root and a pattern. The root consists of consonants only, by default three, and the pattern is a combination of vowels and consonants, with non-consecutive xe2x80x9cslotsxe2x80x9d into which the root consonants are inserted. Identifying the root of a given word is an important task, considered to be an essential part of the morphological analysis of Semitic languages, and information on roots is important for linguistics research as well as for practical applications. We present a machine learning approach, augmented by limited linguistic knowledge, to the problem of identifying the roots of Semitic words. Although programs exist which can extract the root of words in Arabic and Hebrew, they are all dependent on labor-intensive construction of large-scale lexicons which are components of full-scale morphological analyzers. The advantage of our method is an automation of this process, avoiding the bottleneck of having to laboriously list the root and pattern of each lexeme in the language. To the best of our knowledge, this is the first application of machine learning to this problem, and one of the few attempts to directly address non-concatenative morphology using machine learning. More generally, our results shed light on the problem of combining classifiers under (linguistically motivated) constraints."
W07-0909,Cross Lingual and Semantic Retrieval for Cultural Heritage Appreciation,2007,23,5,5,0,9890,idan szpektor,Proceedings of the Workshop on Language Technology for Cultural Heritage Data ({L}a{T}e{CH} 2007).,0,"We describe a system which enhances the experience of museum visits by providing users with language-technology-based information retrieval capabilities. The system consists of a cross-lingual search engine, augmented by state of the art semantic expansion technology, specifically designed for the domain of the museum (history and archaeology of Israel). We discuss the technology incorporated in the system, its adaptation to the specific domain and its contribution to cultural heritage appreciation."
W07-0604,High-accuracy Annotation and Parsing of {CHILDES} Transcripts,2007,14,45,5,0,6910,kenji sagae,Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition,0,"Corpora of child language are essential for psycholinguistic research. Linguistic annotation of the corpora provides researchers with better means for exploring the development of grammatical constructions and their usage. We describe an ongoing project that aims to annotate the English section of the CHILDES database with grammatical relations in the form of labeled dependency structures. To date, we have produced a corpus of over 65,000 words with manually curated gold-standard grammatical relation annotations. Using this corpus, we have developed a highly accurate data-driven parser for English CHILDES data. The parser and the manually annotated data are freely available for research purposes."
D07-1046,Morphological Disambiguation of {H}ebrew: A Case Study in Classifier Combination,2007,29,16,2,0,49030,danny shacham,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Morphological analysis and disambiguation are crucial stages in a variety of natural language processing applications, especially when languages with complex morphology are concerned. We present a system which disambiguates the output of a morphological analyzer for Hebrew. It consists of several simple classifiers and a module that combines them under the constraints imposed by the analyzer. We explore several approaches to classifier combination, as well as a back-off mechanism that relies on a large unannotated corpus. Our best result, around 83 percent accuracy, compares favorably with the state of the art on this task."
P06-1019,Partially Specified Signatures: A Vehicle for Grammar Modularity,2006,17,5,2,1,49964,yael cohensygal,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"This work provides the essential foundations for modular construction of (typed) unification grammars for natural languages. Much of the information in such grammars is encoded in the signature, and hence the key is facilitating a modularized development of type signatures. We introduce a definition of signature modules and show how two modules combine. Our definitions are motivated by the actual needs of grammar developers obtained through a careful examination of large scale grammars. We show that our definitions meet these needs by conforming to a detailed set of desiderata."
P06-1137,Highly Constrained Unification Grammars,2006,28,3,2,0,49997,daniel feinstein,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Unification grammars are widely accepted as an expressive means for describing the structure of natural languages. In general, the recognition problem is undecidable for unification grammars. Even with restricted variants of the formalism, offline parsable grammars, the problem is computationally hard. We present two natural constraints on unification grammars which limit their expressivity. We first show that non-reentrant unification grammars generate exactly the class of context-free languages. We then relax the constraint and show that one-reentrant unification grammars generate exactly the class of tree-adjoining languages. We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages."
itai-etal-2006-computational,A Computational Lexicon of Contemporary {H}ebrew,2006,4,14,2,0,39817,alon itai,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Computational lexicons are among the most important resources for natural language processing (NLP). Their importance is even greater in languages with rich morphology, where the lexicon is expected to provide morphological analyzers with enough information to enable themto correctly process intricately inflected forms. We describe the Haifa Lexicon of Contemporary Hebrew, the broadest-coverage publicly available lexicon of Modern Hebrew, currently consisting of over 20,000 entries.While other lexical resources of Modern Hebrew have been developed in the past, this is the first publicly available large-scale lexicon of the language. In addition to supporting morphological processors (analyzers and generators), which was our primary objective, thelexicon is used as a research tool in Hebrew lexicography and lexical semantics. It is open for browsing on the web and several search tools and interfaces were developed which facilitate on-line access to its information. The lexicon is currently used for a variety of NLP applications."
J06-1004,Finite-State Registered Automata for Non-Concatenative Morphology,2006,27,20,2,1,49964,yael cohensygal,Computational Linguistics,0,"We introduce finite-state registered automata (FSRAs), a new computational device within the framework of finite-state technology, specifically tailored for implementing non-concatenative morphological processes. This model extends and augments existing finite-state techniques, which are presently not optimized for describing this kind of phenomena. We first define the model and discuss its mathematical and computational properties. Then, we provide an extended regular language whose expressions denote FSRAs. Finally, we exemplify the utility of the model by providing several examples of complex morphological and phonological phenomena, which are elegantly implemented with FSRAs."
W05-1108,{XFST}2{FSA}: Comparing Two Finite-State Toolboxes,2005,19,4,2,1,49964,yael cohensygal,Proceedings of Workshop on Software,0,"This paper introduces xfst2fsa, a compiler which translates grammars expressed in the syntax of the XFST finite-state tool-box to grammars in the language of the FSA Utilities package. Compilation to FSA facilitates the use of grammars developed with the proprietary XFST tool-box on a publicly available platform. The paper describes the non-trivial issues of the compilation process, highlighting several shortcomings of some published algorithms, especially where replace rules are concerned. The compiler augments FSA with most of the operators supported by XFST. Furthermore, it provides a means for comparing the two systems on comparable grammars. The paper presents the results of such a comparison."
W05-0702,A Finite-State Morphological Grammar of {H}ebrew,2005,15,10,2,0,50121,shlomo yona,Proceedings of the {ACL} Workshop on Computational Approaches to {S}emitic Languages,0,"Morphological analysis is a crucial component of several natural language processing tasks, especially for languages with a highly productive morphology, where stipulating a full lexicon of surface forms is not feasible. We describe HAMSAH (HAifa Morphological System for Analyzing Hebrew), a morphological processor for Modern Hebrew, based on finite-state linguistically motivated rules and a broad coverage lexicon. The set of rules comprehensively covers the morphological, morpho-phonological and orthographic phenomena that are observable in contemporary Hebrew texts. Reliance on finite-state technology facilitates the construction of a highly efficient, completely bidirectional system for analysis and generation. HAMSAH is currently the broadest-coverage and most accurate freely-available system for Hebrew."
W04-3246,Learning {H}ebrew Roots: Machine Learning with Linguistic Constraints,2004,10,13,3,0,42592,ezra daya,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"The morphology of Semitic languages is unique in the sense that the major word-formation mechanism is an inherently non-concatenative process of interdigitation, whereby two morphemes, a root and a pattern, are interwoven. Identifying the root of a given word in a Semitic language is an important task, in some cases a crucial part of morphological analysis. It is also a non-trivial task, which many humans find challenging. We present a machine learning approach to the problem of extracting roots of Hebrew words. Given the large number of potential roots (thousands), we address the problem as one of combining several classifiers, each predicting the value of one of the rootxe2x80x99s consonants. We show that when these predictors are combined by enforcing some fairly simple linguistics constraints, high accuracy, which compares favorably with human performance on this task, can be achieved."
2004.tmi-1.1,Rapid prototyping of a transfer-based {H}ebrew-to-{E}nglish machine translation system,2004,8,28,4,0,13539,alon lavie,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"We describe the rapid development of a preliminary Hebrew-to-English Machine Translation system under a transfer-based framework specifically designed for rapid MT prototyping for languages with limited linguistic resources. The task is particularly challenging due to two main reasons: the high lexical and morphological ambiguity of Hebrew and the dearth of available resources for the language. Existing, publicly available resources were adapted in novel ways to support the MT task. The methodology behind the system combines two separate modules: a transfer engine which produces a lattice of possible translation segments, and a decoder which searches and selects the most likely translation according to an English language model. We demonstrate that a small manually crafted set of transfer rules suffices to produce legible translations. Performance results are evaluated using state of the art measures and are shown to be encouraging."
2003.mtsummit-tutorials.2,Finite state technology and its applications to machine translation,2003,-1,-1,1,1,12510,shuly wintner,Proceedings of Machine Translation Summit IX: Tutorials,0,None
2003.mtsummit-semit.12,Resources for processing Israeli {H}ebrew,2003,12,9,1,1,12510,shuly wintner,Workshop on Machine Translation for Semitic languages: issues and approaches,0,"We describe work in progress whose main objective is to create a collection of resources and tools for processing Hebrew. These resources include corpora of written texts, some of them annotated in various degrees of detail; tools for collecting, expanding and maintaining corpora; tools for annotation; lexicons, both monolingual and bilingual; a rule-based, linguistically motivated morphological analyzer and generator; and a WordNet for Hebrew. We emphasize the methodological issue of well-defined standards for the resources to be developed. The design of the resources guarantees their reusability, such that the output of one system can naturally be the input to another."
W02-0110,Formal Language Theory for Natural Language Processing,2002,18,10,1,1,12510,shuly wintner,Proceedings of the {ACL}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,0,"This paper reports on a course whose aim is to introduce Formal Language Theory to students with little formal background (mostly linguistics students). The course was first taught at the European Summer School for Logic, Language and Information to a mixed audience of students, undergraduate, graduate and postgraduate, with various backgrounds. The challenges of teaching such a course include preparation of highly formal, mathematical material for students with relatively little formal background; attracting the attention of students of different backgrounds; preparing examples that will emphasize the practical importance of material which is basically theoretical; and evaluation of students' achievements."
J02-3005,Squibs and Discussions: A Note on Typing Feature Structures,2002,-1,-1,1,1,12510,shuly wintner,Computational Linguistics,0,None
C02-1066,Guaranteeing Parsing Termination of Unification Grammars,2002,10,3,3,0,53627,efrat jaeger,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Unification grammars are known to be Turing-equivalent; given a grammar G and a word w, it is undecidable whether w e L (G). In order to ensure decidability, several constraints on grammars, commonly known as off-line parsability (OLP) were suggested. The recognition problem is decidable for grammars which satisfy OLP. An open question is whether it is decidable if a given grammar satisfies OLP. In this paper we investigate various definitions of OLP, discuss their inter-relations and show that some of them are undecidable."
P99-1013,Compositional Semantics for Linguistic Formalisms,1999,14,8,1,1,12510,shuly wintner,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"In what sense is a grammar the union of its rules? This paper adapts the notion of composition, well developed in the context of programming languages, to the domain of linguistic formalisms. We study alternative definitions for the semantics of such formalisms, suggesting a denotational semantics that we show to be compositional and fully-abstract. This facilitates a clear, mathematically sound way for defining grammar modularity."
W98-1429,System Demonstration Natural Language Generation With Abstract Machine,1998,9,0,3,0,47853,evgeniy gabrilovich,Natural Language Generation,0,None
W98-1011,Towards a linguistically motivated computational grammar for {H}ebrew,1998,11,4,1,1,12510,shuly wintner,Computational Approaches to {S}emitic Languages,0,"While the morphology of Modern Hebrew is well accounted for computationally, there are few computational grammars describing the syntax of the language. Existing grammars are scarcely based on solid linguistic grounds: they do not conform to any particular linguistic theory and do not provide a linguistically plausible analysis for the data they cover. This paper presents a first attempt towards the construction of a formal grammar for a fragment of Hebrew that is both linguistically motivated and computationally implementable. The grammar, concentrating on the structure of noun phrases, is designed in accordance with HPSG, a linguistic theory that lends itself most naturally to computational implementation. It is the first application of HPSG to any Semitic language. Several theoretical issues are addressed, including the status of the definite article, the application of the DP hypothesis to Hebrew, definiteness agreement in the noun phrase as well as definiteness inheritance in constructs. All the analyses presented in the paper were tested and their predictions were verified. This is a work in progress, and the results described herein are preliminary."
1995.iwpt-1.33,Parsing with Typed Feature Structures,1995,-1,-1,1,1,12510,shuly wintner,Proceedings of the Fourth International Workshop on Parsing Technologies,0,"In this paper we provide for parsing with respect to grammars expressed in a general TFS-based formalism, a restriction of ALE ([2]). Our motivation being the design of an abstract (WAM-like) machine for the formalism ([14]), we consider parsing as a computational process and use it as an operational semantics to guide the design of the control structures for the abstract machine. We emphasize the notion of \textit{abstract typed feature structures} (AFSs) that encode the essential information of TFSs and define unification over AFSs rather than over TFSs. We then introduce an explicit construct of \textit{multi-rooted feature structures} (MRSs) that naturally extend TFSs and use them to represent phrasal signs as well as grammar rules. We also employ abstractions of MRSs and give the mathematical foundations needed for manipulating them. We then present a simple bottom-up chart parser as a model for computation: grammars written in the TFS-based formalism are executed by the parser. Finally, we show that the parser is correct."
