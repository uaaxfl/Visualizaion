2021.hackashop-1.2,Related Named Entities Classification in the Economic-Financial Context,2021,-1,-1,3,0,6068,daniel reyes,Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation,0,"The present work uses the Bidirectional Encoder Representations from Transformers (BERT) to process a sentence and its entities and indicate whether two named entities present in a sentence are related or not, constituting a binary classification problem. It was developed for the Portuguese language, considering the financial domain and exploring deep linguistic representations to identify a relation between entities without using other lexical-semantic resources. The results of the experiments show an accuracy of 86{\%} of the predictions."
2020.lrec-1.568,Embeddings for Named Entity Recognition in Geoscience {P}ortuguese Literature,2020,-1,-1,5,0,17802,bernardo consoli,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This work focuses on Portuguese Named Entity Recognition (NER) in the Geology domain. The only domain-specific dataset in the Portuguese language annotated for NER is the GeoCorpus. Our approach relies on BiLSTM-CRF neural networks (a widely used type of network for this area of research) that use vector and tensor embedding representations. Three types of embedding models were used (Word Embeddings, Flair Embeddings, and Stacked Embeddings) under two versions (domain-specific and generalized). The domain specific Flair Embeddings model was originally trained with a generalized context in mind, but was then fine-tuned with domain-specific Oil and Gas corpora, as there simply was not enough domain corpora to properly train such a model. Each of these embeddings was evaluated separately, as well as stacked with another embedding. Finally, we achieved state-of-the-art results for this domain with one of our embeddings, and we performed an error analysis on the language model that achieved the best results. Furthermore, we investigated the effects of domain-specific versus generalized embeddings."
2020.lrec-1.594,Word Embedding Evaluation in Downstream Tasks and Semantic Analogies,2020,-1,-1,3,0,17803,joaquim santos,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Language Models have long been a prolific area of study in the field of Natural Language Processing (NLP). One of the newer kinds of language models, and some of the most used, are Word Embeddings (WE). WE are vector space representations of a vocabulary learned by a non-supervised neural network based on the context in which words appear. WE have been widely used in downstream tasks in many areas of study in NLP. These areas usually use these vector models as a feature in the processing of textual data. This paper presents the evaluation of newly released WE models for the Portuguese langauage, trained with a corpus composed of 4.9 billion tokens. The first evaluation presented an intrinsic task in which WEs had to correctly build semantic and syntactic relations. The second evaluation presented an extrinsic task in which the WE models were used in two downstream tasks: Named Entity Recognition and Semantic Similarity between Sentences. Our results show that a diverse and comprehensive corpus can often outperform a larger, less textually diverse corpus, and that batch training may cause quality loss in WE models."
L18-1105,{B}log{S}et-{BR}: A {B}razilian {P}ortuguese Blog Corpus,2018,0,3,3,1,29622,henrique santos,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-6606,Wheel of Life: an initial investigation. Topic-Related Polarity Visualization in Personal Stories,2017,8,0,2,1,29622,henrique santos,Proceedings of the 11th {B}razilian Symposium in Information and Human Language Technology,0,User-generated content is a rich source of information regarding human behavior in Internet social media. Sentiment analysis is a powerful tool to understand human psychological meanings in text. Visualizing these sentiments and knowledge about users is crucial to figure out the trends in data and to then use this information to make decisions. This work presents an initial investigation about a visualization chart considering topic-related polarities in personal stories by Brazilian bloggers. Visualizing these sentiments allows specialists to rapidly understand user-affected areas of life.
W17-6609,Processo de constru{\\c{c}}{\\~a}o de um corpus anotado com Entidades Geol{\\'o}gicas visando {REN} (Building an annotated corpus with geological entities for {NER})[In {P}ortuguese],2017,-1,-1,4,1,31367,daniela amaral,Proceedings of the 11th {B}razilian Symposium in Information and Human Language Technology,0,None
W17-5225,{PLN}-{PUCRS} at {E}mo{I}nt-2017: Psycholinguistic features for emotion intensity prediction in tweets,2017,0,0,2,1,29622,henrique santos,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"Linguistic Inquiry and Word Count (LIWC) is a rich dictionary that map words into several psychological categories such as Affective, Social, Cognitive, Perceptual and Biological processes. In this work, we have used LIWC psycholinguistic categories to train regression models and predict emotion intensity in tweets for the EmoInt-2017 task. Results show that LIWC features may boost emotion intensity prediction on the basis of a low dimension set."
L16-1023,Adapting an Entity Centric Model for {P}ortuguese Coreference Resolution,2016,12,1,2,1,34753,evandro fonseca,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents the adaptation of an Entity Centric Model for Portuguese coreference resolution, considering 10 named entity categories. The model was evaluated on named e using the HAREM Portuguese corpus and the results are 81.0{\%} of precision and 58.3{\%} of recall overall, the resulting system is freely available"
L16-1301,A Sequence Model Approach to Relation Extraction in {P}ortuguese,2016,13,1,3,0,31368,sandra collovini,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The task of Relation Extraction from texts is one of the main challenges in the area of Information Extraction, considering the required linguistic knowledge and the sophistication of the language processing techniques employed. This task aims at identifying and classifying semantic relations that occur between entities recognized in a given text. In this paper, we evaluated a Conditional Random Fields classifier for the extraction of any relation descriptor occurring between named entities (Organisation, Person and Place categories), as well as pre-defined relation types between these entities in Portuguese texts."
L16-1324,Summ-it++: an Enriched Version of the Summ-it Corpus,2016,10,5,5,1,34753,evandro fonseca,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents Summ-it++, an enriched version the Summ-it corpus. In this new version, the corpus has received new semantic layers, named entity categories and relations between named entities, adding to the previous coreference annotation. In addition, we change the original Summ-it format to SemEval"
W15-5603,Comparative Analysis between Notations to Classify Named Entities using Conditional Random Fields,2015,0,2,3,1,31367,daniela amaral,Proceedings of the 10th {B}razilian Symposium in Information and Human Language Technology,0,None
W15-5613,Building and Applying Profiles Through Term Extraction,2015,0,3,2,1,36452,lucelene lopes,Proceedings of the 10th {B}razilian Symposium in Information and Human Language Technology,0,"This paper proposes a technique to build entity profiles starting from a set of defining corpora, i.e., a corpus considered as the definition of each entity. The proposed technique is applied in a classification task in order to determine how much a text, or corpus, is related to each of the profiled entities. This technique is general enough to be applied to any kind of entity, however, this paper experiments are conduct over entities describing a set of professors of a computer science graduate school through their advised M.Sc. thesis and Ph.D. dissertations. The profiles of each entity are applied to categorize other texts into one of the builded profiles. The analysis of the obtained results illustrates the power of the proposed technique."
hilgert-etal-2014-building,Building Domain Specific Bilingual Dictionaries,2014,10,1,4,0,39349,lucas hilgert,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper proposes a method to build bilingual dictionaries for specific domains defined by a parallel corpora. The proposed method is based on an original method that is not domain specific. Both the original and the proposed methods are constructed with previously available natural language processing tools. Therefore, this paper contribution resides in the choice and parametrization of the chosen tools. To illustrate the proposed method benefits we conduct an experiment over technical manuals in English and Portuguese. The results of our proposed method were analyzed by human specialists and our results indicates significant increases in precision for unigrams and muli-grams. Numerically, the precision increase is as big as 15{\%} according to our evaluation."
amaral-etal-2014-comparative,Comparative Analysis of {P}ortuguese Named Entities Recognition Tools,2014,14,5,4,1,31367,daniela amaral,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes an experiment to compare four tools to recognize named entities in Portuguese texts. The experiment was made over the HAREM corpora, a golden standard for named entities recognition in Portuguese. The tools experimented are based on natural language processing techniques and also machine learning. Specifically, one of the tools is based on Conditional random fields, an unsupervised machine learning model that has being used to named entities recognition in several languages, while the other tools follow more traditional natural language approaches. The comparison results indicate advantages for different tools according to the different classes of named entities. Despite of such balance among tools, we conclude pointing out foreseeable advantages to the machine learning based tool."
severo-etal-2014-voar,{VOAR}: A Visual and Integrated Ontology Alignment Environment,2014,18,4,3,0,39894,bernardo severo,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Ontology alignment is a key process for enabling interoperability between ontology-based systems in the Linked Open Data age. From two input ontologies, this process generates an alignment (set of correspondences) between them. In this paper we present VOAR, a new web-based environment for ontology alignment visualization and manipulation. Within this graphical environment, users can manually create/edit correspondences and apply a set of operations on alignments (filtering, merge, difference, etc.). VOAR allows invoking external ontology matching systems that implement a specific alignment interface, so that the generated alignments can be manipulated within the environment. Evaluating multiple alignments together against a reference one can also be carried out, using classical evaluation metrics (precision, recall and f-measure). The status of each correspondence with respect to its presence or absence in reference alignment is visually represented. Overall, the main new aspect of VOAR is the visualization and manipulation of alignments at schema level, in an integrated, visual and web-based environment."
W13-4807,{O} Reconhecimento de Entidades Nomeadas por meio de Conditional Random Fields para a L{\\'\\i}ngua Portuguesa (Named Entity Recognition with Conditional Random Fields for the {P}ortuguese Language) [in {P}ortuguese],2013,0,1,2,1,31367,daniela amaral,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,None
W13-4809,Aplicando Pontos de Corte para Listas de Termos Extra{\\'\\i}dos (Applying Cut-off Points to Lists of Extracted Terms) [in {P}ortuguese],2013,-1,-1,2,1,36452,lucelene lopes,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,None
W13-4818,"Gera{\\c{c}}{\\~a}o de features para resolu{\\c{c}}{\\~a}o de correfer{\\^e}ncia: Pessoa, Local e Organiza{\\c{c}}{\\~a}o (Feature Generation for Coreference Resolution: Person, Location and Organization) [in {P}ortuguese]",2013,-1,-1,2,1,34753,evandro fonseca,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,None
W13-4821,Entity-centric Sentiment Analysis on {T}witter data for the Potuguese Language,2013,16,1,2,0,40607,marlo souza,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,"Twitter is a popular microblogging platform which is commonly used to express opinions about entities of the world. The solutions provided to per- form Sentiment Analysis in such a media, however, relies on classifying an entire sentence regarding the opinion it express, rather than the content and reference of the opinion expressed in the text. We propose and evaluate a Entity-centric Sentiment Analysis method over Twitter data for the Portuguese language."
W13-4825,Extra{\\c{c}}{\\~a}o de Vocabul{\\'a}rio Multil{\\'\\i}ngue para Tradu{\\c{c}}{\\~a}o em Dom{\\'\\i}nios Especializados (Multilingual Vocabulary Extraction for Machine Translation in Specialized Domains) [in {P}ortuguese],2013,-1,-1,2,0,39349,lucas hilgert,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,None
W12-3904,A Comparable Corpus Based on Aligned Multilingual Ontologies,2012,11,5,5,0,42183,roger granada,Proceedings of the First Workshop on Multilingual Modeling,0,"In this paper we present a methodology for building comparable corpus, using multilingual ontologies of a scpecific domain. This resource can be exploited to foster research on multilingual corpus-based ontology learning, population and matching. The building resource process is exemplified by the construction of annotated comparable corpora in English, Portuguese, and French. The corpora, from the conference organization domain, are built using the multilingual ontology concept labels as seeds for crawling relevant documents from the web through a search engine. Using ontologies allows a better coverage of the domain. The main goal of this paper is to describe the design methodology followed by the creation of the corpora. We present a preliminary evaluation and discuss their characteristics and potential applications."
fernandes-etal-2012-fast,"A Fast, Memory Efficient, Scalable and Multilingual Dictionary Retriever",2012,5,3,5,0,43281,paulo fernandes,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents a novel approach to deal with dictionary retrieval. This new approach is based on a very efficient and scalable theoretical structure called Multi-Terminal Multi-valued Decision Diagrams (MTMDD). Such tool allows the definition of very large, even multilingual, dictionaries without significant increase in memory demands, and also with virtually no additional processing cost. Besides the general idea of the novel approach, this paper presents a description of the technologies involved, and their implementation in a software package called WAGGER. Finally, we also present some examples of usage and possible applications of this dictionary retriever."
castilho-etal-2012-corpus,{C}orpus+{W}ord{N}et thesaurus generation for ontology enriching,2012,17,1,5,0,43359,fernando castilho,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents a model to enrich an ontology with a thesaurus based on a domain corpus and WordNet. The model is applied to the data privacy domain and the initial domain resources comprise a data privacy ontology, a corpus of privacy laws, regulations and guidelines for projects. Based on these resources, a thesaurus is automatically generated. The thesaurus seeds are composed by the ontology concepts. For these seeds similar terms are extracted from the corpus using known thesaurus generation methods. A filtering process searches for semantic relations between seeds and similar terms within WordNet. As a result, these semantic relations are used to expand the ontology with relations between them and related terms in the corpus. The resulting resource is a hierarchical structure that can help on the ontology investigation and maintenance. The results allow the investigation of the domain knowledge with the support of semantic relations not present on the original ontology."
W11-4507,Construction of a {P}ortuguese Opinion Lexicon from multiple resources,2011,14,27,2,0,40607,marlo souza,Proceedings of the 8th {B}razilian Symposium in Information and Human Language Technology,0,"Opinion Lexicons are linguistic resources annotated with semantic orientation of terms (positive and negative) and are important for opinion min- ing tasks. In the literature we see a variety of proposals for the construction of opinion lexicons using different linguistic resources and techniques. In this work, we propose and evaluate the integration of such linguistic resources to create a single lexicon for the Portuguese language."
W11-4513,Extra{\\c{c}}{\\~a}o de Contextos Definit{\\'o}rios a partir de Textos em L{\\'\\i}ngua Portuguesa (Extraction of Defining Contexts from Texts in {P}ortuguese) [in {P}ortuguese],2011,-1,-1,2,0,44002,igor wendt,Proceedings of the 8th {B}razilian Symposium in Information and Human Language Technology,0,None
trojahn-etal-2010-api,An {API} for Multi-lingual Ontology Matching,2010,7,20,3,1,31339,cassia trojahn,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Ontology matching consists of generating a set of correspondences between the entities of two ontologies. This process is seen as a solution to data heterogeneity in ontology-based applications, enabling the interoperability between them. However, existing matching systems are designed by assuming that the entities of both source and target ontologies are written in the same languages ( English, for instance). Multi-lingual ontology matching is an open research issue. This paper describes an API for multi-lingual matching that implements two strategies, direct translation-based and indirect. The first strategy considers direct matching between two ontologies (i.e., without intermediary ontologies), with the help of external resources, i.e., translations. The indirect alignment strategy, proposed by (Jung et al., 2009), is based on composition of alignments. We evaluate these strategies using simple string similarity based matchers and three ontologies written in English, French, and Portuguese, an extension of the OAEI benchmark test 206."
trojahn-etal-2008-framework,A Framework for Multilingual Ontology Mapping,2008,10,31,3,1,31339,cassia trojahn,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In the field of ontology mapping, multilingual ontology mapping is an issue that is not well explored. This paper proposes a framework for mapping of multilingual Description Logics (DL) ontologies. First, the DL source ontology is translated to the target ontology language, using a lexical database or a dictionary, generating a DL translated ontology. The target and the translated ontologies are then used as input for the mapping process. The mappings are computed by specialized agents using different mapping approaches. Next, these agents use argumentation to exchange their local results, in order to agree on the obtained mappings. Based on their preferences and confidence of the arguments, the agents compute their preferred mapping sets. The arguments in such preferred sets are viewed as the set of globally acceptable arguments. A DL mapping ontology is generated as result of the mapping process. In this paper we focus on the process of generating the DL translated ontology."
W04-1909,Mining Linguistically Interpreted Texts,2004,6,12,2,0,51507,cassiana silva,Proceedings of the 5th International Workshop on Linguistically Interpreted Corpora,0,None
W04-0706,Using Word Similarity Lists for Resolving Indirect Anaphora,2004,-1,-1,2,0,45422,caroline gasperin,Proceedings of the Conference on Reference Resolution and Its Applications,0,None
W04-0707,Discourse-New Detectors for Definite Description Resolution: A Survey and a Preliminary Proposal,2004,17,26,3,0.316702,1743,massimo poesio,Proceedings of the Conference on Reference Resolution and Its Applications,0,None
W03-1902,From Concrete to Virtual Annotation Mark-up Language: The Case of {COMMO}n-{REF}s,2003,15,0,1,1,6070,renata vieira,Proceedings of the {ACL} 2003 Workshop on Linguistic Annotation: Getting the Model Right,0,"This work presents the data model we adopted for annotating coreference. Our data model includes different levels of annotation, such as part-of-speech, syntax and discourse. We compare our encoding schemes to the abstract XML encoding being proposed as standard. We also present our tool for coreference resolution that handles our data model."
poesio-etal-2002-acquiring,Acquiring Lexical Knowledge for Anaphora Resolution,2002,26,79,4,0.55874,1743,massimo poesio,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The lack of adequate bases of commonsense or even lexical knowledge is perhaps the main obstacle to the development of highperformance, robust tools for semantic interpretation. It is also generally accepted that, notwithstanding the increasing availability in recent years of substantial hand-coded lexical resources such as WordNet and EuroWordNet, addressing the commonsense knowledge bottleneck will eventually require the development of effective techniques for acquiring such information automatically, e.g., from corpora. We discuss research aimed at improving the performance of anaphora resolution systems by acquiring the commonsense knowledge require to resolve the more complex cases of anaphora, such as bridging references. We focus in particular on the problem of acquiring information about part-of relations."
salmon-alt-vieira-2002-nominal,Nominal Expressions in Multilingual Corpora: Definites and Demonstratives,2002,29,8,2,0,50134,susanne salmonalt,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper presents the results of a multilingual corpus study on definite descriptions and demonstrative noun phrases. The analysis made on a parallel corpus (French and Portuguese) reinforces previous findings regarding the predominance of non-anaphoric uses of definite descriptions in English corpus. It is also shown that the use of demonstrative noun phrases, on the other hand, is more regularly based on discourse salient entities. The analysis involves syntactic issues and is oriented to the design of natural language processing tools."
J00-4003,An Empirically-based System for Processing Definite Descriptions,2000,75,171,1,1,6070,renata vieira,Computational Linguistics,0,"We present an implemented system for processing definite descriptions in arbitrary domains. The design of the system is based on the results of a corpus analysis previously reported, which highlighted the prevalence of discourse-new descriptions in newspaper corpora. The annotated corpus was used to extensively evaluate the proposed techniques for matching definite descriptions with their antecedents, discourse segmentation, recognizing discourse-new descriptions, and suggesting anchors for bridging descriptions."
C00-2130,Corpus-based Development and Evaluation of a System for Processing Definite Descriptions,2000,20,6,1,1,6070,renata vieira,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"We present an implemented system for processing definite descriptions. The system is based on the results of a corpus analysis previously reported, which showed how common discourse-new descriptions are in newspaper corpora, and identified several problems to be dealt with when developing computational methods for interpreting bridging descriptions. The annotated corpus produced in this earlier work was used to extensively evaluate the proposed techniques for matching definite descriptions with their antecedents, discourse segmentation, recognizing discourse-new descriptions, and suggesting anchors for bridging descriptions."
J98-2001,A Corpus-based Investigation of Definite Description Use,1998,36,224,2,1,1743,massimo poesio,Computational Linguistics,0,"We present the results of a study of the use of definite descriptions in written texts aimed at assessing the feasibility of annotating corpora with information about definite description interpretation. We ran two experiments, in which subjects were asked to classify the uses of definite descriptions in a corpus of 33 newspaper articles, containing a total of 1,412 definite descriptions. We measured the agreement among annotators about the classes assigned to definite descriptions, as well as the agreement about the antecedent assigned to those definites that the annotators classified as being related to an antecedent in the text. The most interesting result of this study from a corpus annotation perspective was the rather low agreement (K = 0.63) that we obtained using versions of Hawkins's and Prince's classification schemes; better results (K = 0.76) were obtained using the simplified scheme proposed by Fraurud that includes only two classes, first-mention and subsequent-mention. The agreement about antecedents was also not complete. These findings raise questions concerning the starategy of evaluating systems for definite description interpretation by comparing their results with a standardized annotation. From a linguistic point of view, the most interesting observations were the great number of discourse-new definites in our corpus (in one of our experiments, about 50% of the definites in the collection were classified as discourse-new, 30% as anaphoric, and 18% as associative/bridging) and the presence of definites that did not seem to require a complete disambiguation."
W97-1301,Resolving bridging references in unrestricted text,1997,13,63,2,0,1743,massimo poesio,"Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts",0,"Our goal is to develop a system capable of treating the largest possible subset of definite descriptions in unrestricted written texts. A previous prototype resolved anaphoric uses of definite descriptions and identified some types of first-mention uses, achieving a recall of 56%. In this paper we present the latest version of our system, which handles some types of bridging references, uses WordNet as a source of lexical knowledge, and achieves a recall of 65%."
P97-1072,Towards resolution of bridging descriptions,1997,8,14,1,1,6070,renata vieira,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,We present preliminary results concerning robust techniques for resolving bridging definite descriptions. We report our analysis of a collection of 20 Wall Street Journal articles from the Penn Treebank Corpus and our experiments with WordNet to identify relations between bridging descriptions and their antecedents.
