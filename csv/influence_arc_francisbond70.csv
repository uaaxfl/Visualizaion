1995.tmi-1.1,1991.mtsummit-papers.16,0,0.0383605,"Missing"
1995.tmi-1.1,1993.tmi-1.18,0,0.200721,"Missing"
1995.tmi-1.1,1993.tmi-1.20,1,0.836934,"Missing"
1995.tmi-1.1,C92-2118,0,0.0545751,"Missing"
1997.tmi-1.11,C92-4190,0,0.0723094,"Missing"
1997.tmi-1.11,E93-1020,0,0.0519605,"Missing"
1997.tmi-1.11,1991.mtsummit-papers.16,1,0.872434,"Missing"
1997.tmi-1.11,A94-1035,1,0.899527,"Missing"
1997.tmi-1.7,1991.mtsummit-papers.16,0,0.0604465,"Missing"
1999.mtsummit-1.66,P98-2160,0,0.0240101,"anese sentences are typically SOV, with the subject followed by the object and the verb final, whereas Malay is SVO, like English. Within the noun phrase, in Japanese, modifiers come before the head noun (like in English), whereas in Malay they typically follow the head. ALT-J/M runs under Unix and is written mainly in LISP and C. Currently the translation rate is between 5,000 and 10,000 words an hour. As it is still an experimental system it has not been optimized for speed. Our original system ALT-J/E, was not designed to quickly ramp-up to new languages like, for example, the BOAS system (Nirenberg & Raskin 1998). However, we were able to produce a functional Japaneseto-Malay prototype in approximately 7 person-months. -444- MT Summit VII__________ _____________________________________________ Sept. 1999 Figure 1: The Multi-Level Translation Method 3 Lexicon Our dictionaries provide detailed information about the meanings and use of words. Most words can express several concepts. Which concept a word expresses in a text is determined by its relationship with the other words in the text. For example the noun hotel is used as a place in I walked straight to the hotel and as an organization in The hotel"
1999.mtsummit-1.66,C96-2146,0,0.0302711,"). 4.2 Correct translation of nouns In Japanese hana “nose” is used for both elephants and pigs, however in Malay it is better to use belalai “trunk” for an elephant&apos;s trunk. ALT-J/M&apos;s Japanese-to-Malay transfer dictionary specifies that elephant&apos;s nose should be translated as belalai “trunk”. This sentence also shows how ALT-J/M is able to generate appropriate Malay sentence structures, even - 447- when they are different from the Japanese. Japanese allows the &apos;double subject&apos; construction, when the first subject possesses the second, literally translated as As for elephants, noses are long (Oku 1996). In Malay, the possessed entity follows the verb, but must be marked with a possessive pronoun. In this case the third person possessive pronoun dia joins onto the proceeding noun as the suffix -nya. 5 Discussion and Conclusion Our prototype Japanese-to-Malay system shows that the framework we developed for Japanese-to-English machine translation can be applied to other target languages. Adding a new language for generation was relatively simple because of our well developed ontology. The word selection rules are all lexically based, so the bulk of the work was in producing the lexicon. The i"
1999.mtsummit-1.66,C98-2155,0,\N,Missing
1999.mtsummit-1.66,1991.mtsummit-papers.16,0,\N,Missing
1999.tmi-1.21,1999.tmi-1.20,1,0.707675,"994). What is undoubtedly the most integral component of alternation description, however, is a listing of individual case slots and associated features. Case slots are presented in canonical ordering and annotated with: constituent structure (: cs), including case marker and an optional obligatoriness flag for Japanese, prepositional marker in the case of English, and a phrase-level part-of-speech; grammatical relation (:gs); case-role (:role — 24 roles), and argument status (:stat — 7 levels), based on the case grid representation and valency binding hierarchy proposed by Somers (1987) (see Baldwin & Tanaka (1999) for more detail); and an index back to the sense-level list of argument constraints (:sem-arg). The dictionary used in the Mikrokosmos project (Viegas et al. 1998), appears to have a comparable amount of information, but does not, as far as we are aware, treat the core meaning separately from its alternations. 214 Figure 6: The separated and relinked dictionary 5 Use in MT: the linking lexicon In order to use mono-lingual alternation-based lexicons for machine translation, it must be linked together. To do this we use a linking lexicon. The basic idea is that lexical choice is left to the gen"
1999.tmi-1.21,C94-1042,0,0.012763,"languages into a single system architecture. More information is kept in the monolingual dictionaries, which can be maintained by monolinguals. The linking lexicons are basically reversible, although it is likely that different constraints may be more useful for different directions. There will still be 2Cn2 linking lexicons for n languages, but the overhead for constructing a linking lexicon is considerably less than that for constructing a disambiguated transfer dictionary. In order to develop our architecture, we examined several existing resources: GoiTaikei (Ikehara et al. 1997), COMLEX (Grishman et al. 1994), WordNet (Fellbaum 1998), EVCA (English Verb Classes and Alternations: Levin (1993)) and Jing & McKeown's (1998) combined lexicon, which incorporates information from COMLEX, WordNet and EVCA. The remainder of this paper is structured as follows. Section 2 describes several linguistic resources. Section 3 discusses what the appropriate granularity is for monolingual senses. Section 4 describes the proposed dictionary architecture and the interrelation between the various levels of representation. Section 5 details a number of implementation issues related to the linking lexicon. 2 Linguistic"
1999.tmi-1.21,W98-0718,0,0.0141796,". For example, the word gather appears in three classes: the “Get” subclass of the “Verbs of Change 210 of Possession” family, the “Shake” class of the “Verbs of Combining and Attaching” and the “Herd” subclass of the “Verbs of Existence” family. Jing & McKeown’s (1998) combined lexicon Jing & McKeown’s (1998) dictionary incorporates syntactic frames from COMLEX and alternation pairs from EVCA into WordNet senses, along with frequency of occurrence of each sense in the Brown corpus. The combined dictionary has the strengths of all three resources, and has been successfully used in generation (Jing 1998). It has some rudimentary semantic constraints on arguments, but only at the level of something or somebody. There has been other research combining EVCA and WordNet, notably Kohl et al. (1998) and related work. In this work, frames are added to WordNet sense, along with prototypical fillers, to allow example sentences to be generated. Some semantic constraints are given on arguments, but they are still quite limited. 3 A definition of sense In order to avoid spurious ambiguities, we keep the number of senses to a minimum, as argued for by Wierzbicka (1996:244).2 This is in line with the curre"
1999.tmi-1.21,P98-1099,0,0.142868,"Missing"
1999.tmi-1.21,C94-2106,0,0.225129,"Missing"
1999.tmi-1.21,C98-2211,0,0.0521934,"presented in canonical ordering and annotated with: constituent structure (: cs), including case marker and an optional obligatoriness flag for Japanese, prepositional marker in the case of English, and a phrase-level part-of-speech; grammatical relation (:gs); case-role (:role — 24 roles), and argument status (:stat — 7 levels), based on the case grid representation and valency binding hierarchy proposed by Somers (1987) (see Baldwin & Tanaka (1999) for more detail); and an index back to the sense-level list of argument constraints (:sem-arg). The dictionary used in the Mikrokosmos project (Viegas et al. 1998), appears to have a comparable amount of information, but does not, as far as we are aware, treat the core meaning separately from its alternations. 214 Figure 6: The separated and relinked dictionary 5 Use in MT: the linking lexicon In order to use mono-lingual alternation-based lexicons for machine translation, it must be linked together. To do this we use a linking lexicon. The basic idea is that lexical choice is left to the generation stage, but constrained by the input text. This allows for flexible, fluent generation. There are also several practical advantages. The lexicon is easy to u"
1999.tmi-1.21,C94-1038,0,\N,Missing
1999.tmi-1.21,P98-2216,0,\N,Missing
1999.tmi-1.21,C98-1096,0,\N,Missing
2001.mtsummit-papers.10,C94-1048,0,\N,Missing
2001.mtsummit-papers.10,1999.mtsummit-1.66,1,\N,Missing
2001.mtsummit-papers.10,1991.mtsummit-papers.16,0,\N,Missing
2002.tmi-papers.2,1999.tmi-1.21,1,0.910795,"xample illustrates the nature of case marking variation, the principal form of morphological variation considered in this research. In its original form, the valency dictionary does not contain any explicitly-annotated alternations. Rather, alternants (e.g. akeru and aku) are described independently of one another, and any systematic variation that exists between them is incidental. The driving mechanism employed in the extraction of alternations is the assumption that the selectional restrictions associated with corresponding case slots are unchanged under alternation, originally proposed by Baldwin et al. (1999). That is, in the case of akeru/aku, the selectional restrictions associated with the direct object of akeru 1 Note that for the purposes of this paper, we do not make explicit reference to the non-lexical effects of alternation, such as transformation of grammatical relation. We focus instead on the surface manifestation of such effects, e.g. in the form of case marking alternation. 2 The following abbreviations are used in glosses: nom = nominative and acc = accusative. “opentrans ” are identical to those of the subject of aku “openintrans ”, onto which it maps under alternation. It is impor"
2002.tmi-papers.2,Y00-1002,1,0.85202,"classify these as synthetic. We make a number of assumptions about alternations in this research: 1. The selectional restrictions and lexical fillers on matching case slots are preserved under alternation 2. Alternations are monotonic in valency terms 3. A given alternation type has fixed direction The first of these assumptions states that corresponding case slots in the two alternants of a given alternation token, display the same selectional restrictions and lexical fillers. That is not to say that the same distribution of lexicalisations will be observable for the two case slots (e.g. see Baldwin & Tanaka (2000) for details of the impact of pragmatics and facilitation on argument realisation), but rather that they have the same basic scope for instantiation. The second assumption states that a given alternation type cannot involve both case slot insertion and deletion. That is, alternations must be strictly valency-reducing, valency-increasing or valency-preserving. A corollary of this assumption is that all case slots in at least one of the two alternant case frames must be linked to a case slot in the second alternant case frame (with all case slots in both case frames mapping to a case slot in the"
2002.tmi-papers.2,2002.tmi-papers.6,1,0.763787,"e most plausible (if any) alternation for each from the set of all possible valence-monotonic case slot mappings between them. We then analyse trends in the alternation data and feed this directly into the lexicon. Alternation candidates are scored by evaluating the quality of match of selectional restrictions on corresponding case slots. Case slot match quality is rated empirically in the manner described below. We could also use the existence of identical English translations as an indicator that two candidates are related by way of alternation (cf. the valency frame generation procedure of Fujita & Bond (2002)). For example, akeru and aku are both linked to the English translation open. 3.1 Scoring case slot matches The quality of match between case slots is quantitatively described by comparing the relative proximity of the selectional restrictions describing each, within the Goi-Taikei thesaurus tree. As stated above, selectional restrictions are provided as thesaurus node indices, and the greater the topological overlap between and conceptual cohesion within the regions described for the two case slots, the higher the match quality. This is intended to reflect the intuition that the higher the s"
2002.tmi-papers.2,1991.mtsummit-papers.16,0,0.0330506,"Missing"
2002.tmi-papers.2,H92-1086,0,0.0152486,"Missing"
2002.tmi-papers.2,A00-2034,0,0.0675442,"Missing"
2002.tmi-papers.2,C94-2106,0,0.0596368,"Missing"
2002.tmi-papers.2,C00-2108,0,0.0611112,"Missing"
2002.tmi-papers.6,2002.tmi-papers.2,1,0.831629,"eat” has only the frame-type of 1. This is a gap in our lexicon, ideally            konmou-suru “entreat” should also have a frame-type like in Figure 2. We should fill in these gaps before using these verbs as exemplars to add new entries. The most obvious way to do so would be to reorganize the lexicon into the alternation based architecture proposed by Baldwin et al. (1999). Further, if we could properly identify these as alternations, then there would be no need to build two patterns, just a single alternation. We are currently investigating ways to do this automatically (Baldwin & Bond 2002). In the current implementation, we make no use of the lexicographers’ different kinds of similarity judgments. However, if a verb has a broader or narrower meaning, then the selectional restrictions need to be adjusted to fit this. Akiba et al. (2000) has shown that it is more efficient to adjust selectional restrictions from a reasonable start than to start from the most or least possible restrictions. By choosing a similar verb’s entry as starting point, and handing the constructed pattern on to a another round of semi-automatically adjusting the restrictions, we can further improve the qua"
2002.tmi-papers.6,1999.tmi-1.21,1,0.773124,"of the 1 We use the following abbreviations: top: topic postposition; dat: dative postposition; quot: quotative postposition. 2 The subordinate class is incorrectly translated as a that-clause. This is a bug in the English generation, the Japanese parse and semantic structure are correct. other, and only 2 are genuinely different. Therefore, in order to make new frames for predicates that translate into English report, we need to add only two patterns, one of the types in Figure 1 and one in Figure 2. Ideally, we should combine these into a single alternation and link to that as suggested in Baldwin et al. (1999). 3 3.1 Experimental Method Method of Making New Patterns Our method is based on two facts: (1) verbs with similar meanings typically have similar valency structures; (2) verbs with identical translations typically have similar meanings. We use three resources: (1) ALT-J/E’s valency dictionary; (2) a plain JapaneseEnglish bilingual dictionary which contains Japanese-English word pairs without valency information (such as ALT-J/E’s word dictionary); and (3) a Japanese monolingual corpus (such as newspaper text). Our method creates valency patterns for words in the word dictionary (or any biling"
2002.tmi-papers.6,P96-1018,0,0.0751505,"Missing"
2002.tmi-tmiw.2,1999.tmi-1.12,0,0.0413307,"hen it should be a likely sentence, and if it is an unlikely sentence it should sound unnatural. I take this step to suggest a translation model which generates all possible variations (translations with almost identical semantic restrictions) and chooses the best one based on a target language model. This is similar to the system proposed by Knight et al. (1994), who use n-grams as the target model. 2.7 Studying the reactions of other receptors In order to decide which parts of the translation are of high quality, the text should be parsed by a target language parser, and scored in some way. Bernth (1999) has shown that a confidence index is useful when presenting text to end users, and suggested a score based on the translation process. This is a good idea, but requires detailed knowledge of the transfer process. A simple monolingual metric measured on the target text is more robust. 2.8 Submitting a translation to other translators’ scrutiny By using a confidence measure on the output text, it is possible to rank the outputs of more than one translation system. Callison-Burch & Flournoy (2001) trained a trigram language model on 2,000,000 words of English and used it to choose among the outp"
2002.tmi-tmiw.2,2001.mtsummit-papers.12,0,0.0368562,"processing in general. In this sense I agree with Och & Ney (2001), although I would like to incorporate statistical models into a rule-based system, rather than add linguistic knowledge to a statistical model. I hope that this architecture, and the advances in natural language processing it is based on, will help to bring machine translation ever closer to the capabilities of human translators. 3.2 Multi-Engine Multi-Pass Machine Translation System At the current level of success of machine translation systems, a multi-engine Multi-Pass Machine Translation system along the lines suggested by Callison-Burch & Flournoy (2001) seems worth building. This system translates a text with multiple translation systems, and then chooses the best output for each sentence. The passes could in fact be carried out in parallel, even on different machines. Callison-Burch & Flournoy (2001) used n-grams to select the best result from several rule-based systems. This could be a problem if a statistical system was included, as its results will always be smooth, thus an n-gram-based ranking would be biased towards its results. To choose fairly, the ranking would have to be based on fidelity as well as fluency. However, for really hig"
2002.tmi-tmiw.2,1993.tmi-1.17,0,0.0395275,"larify the meaning of a section they find hard to understand. Wu (1997) shows a way of exploiting a translation to parse a text using an inversion transduction grammar. 2.4 Making a first draft The actual translation process itself should use a good rule-based system with the correct domain dictionaries and unknown words and their translations identified and put into a user dictionary, possibly combined with a translation memory to translate previously encountered text. This creates the first draft. 2.5 Revising the first draft There have been some suggestions to check for deceptive cognates (Isabelle et al. 1993), or omissions in translation (Russell 1999), and to choose articles (Chander 1998). At present, these techniques are not yet so useful in practice, probably because the revision systems are not able to consider the meaning of the text. Naruedomkul & Cercone (1997) suggested an MT architecture that would first translate and then revise poor translations but they did not implement the revision part of the system. One task that could be considered a revision is the addition of translator’s footnotes or notes. Whether they are appropriate or not depends on the target audience. A translator’s note"
2002.tmi-tmiw.2,1994.amta-1.18,0,0.0188223,"dd such notes either during the translation, as part of an initial revision, or as part of the final revision before publishing. 2.6 Reading aloud for style and rhythm The style and rhythm of a text are analogous to its probability: if it sounds natural then it should be a likely sentence, and if it is an unlikely sentence it should sound unnatural. I take this step to suggest a translation model which generates all possible variations (translations with almost identical semantic restrictions) and chooses the best one based on a target language model. This is similar to the system proposed by Knight et al. (1994), who use n-grams as the target model. 2.7 Studying the reactions of other receptors In order to decide which parts of the translation are of high quality, the text should be parsed by a target language parser, and scored in some way. Bernth (1999) has shown that a confidence index is useful when presenting text to end users, and suggested a score based on the translation process. This is a good idea, but requires detailed knowledge of the transfer process. A simple monolingual metric measured on the target text is more robust. 2.8 Submitting a translation to other translators’ scrutiny By usi"
2002.tmi-tmiw.2,1999.mtsummit-1.95,0,0.031175,"Missing"
2002.tmi-tmiw.2,A00-2002,0,0.0295484,"e with a transfer model to chose between alternatives. Finally, the target language text is generated from the target language semantic representation. In order to benefit from work in mono-lingual parsers, generators and lexicons, it is desirable to keep the analysis and generation systems as modular as possible. The enhancement of this system by the multi-pass model is shown in Figure 1. Although here I assume that the translation is done sentence by sentence, as all the current systems I know of do, the architecture is equally applicable to a discourse-based system such as that proposed by Marcu et al. (2000). 1. Identify the source text language (if unknown) • Check the language of each unit (sentence or paragraph) 2. Pre-parse the text (a) Extract named entities Put named entities into local dictionary (b) Run a morphological analyser to identify any unknown words Add unknown word candidates to local dictionary (c) Identify the genre and domain(s) 3. Find translations for the named entities and unknown words Enter them into local transfer and target dictionaries 4. Train the source and target language target models using text from similar genre and domain(s) • If there are any existing translati"
2002.tmi-tmiw.2,1997.tmi-1.8,0,0.0485345,"ed system with the correct domain dictionaries and unknown words and their translations identified and put into a user dictionary, possibly combined with a translation memory to translate previously encountered text. This creates the first draft. 2.5 Revising the first draft There have been some suggestions to check for deceptive cognates (Isabelle et al. 1993), or omissions in translation (Russell 1999), and to choose articles (Chander 1998). At present, these techniques are not yet so useful in practice, probably because the revision systems are not able to consider the meaning of the text. Naruedomkul & Cercone (1997) suggested an MT architecture that would first translate and then revise poor translations but they did not implement the revision part of the system. One task that could be considered a revision is the addition of translator’s footnotes or notes. Whether they are appropriate or not depends on the target audience. A translator’s note is useful if a word without a good translation equivalent, but with a known definition, appears several times. In this case it should be glossed with a definition (the note) the first time and then transliterated in subsequent uses (possible in a different font)."
2002.tmi-tmiw.2,2001.mtsummit-road.6,0,0.0292788,"otes or footnotes Figure 1: Single Engine Multi-Pass Machine Translation The multi-pass method relies critically on two things. The first is having enough processing power and training data to be able parse several times, and retrain models on the fly. Although this is only just becoming available, it is part of the general trend to push more grunt work onto the computer, so that humans can do other things. The other thing is an integrated mixture of rules and stochastic rankings, which I see becoming more and more dominant in natural language processing in general. In this sense I agree with Och & Ney (2001), although I would like to incorporate statistical models into a rule-based system, rather than add linguistic knowledge to a statistical model. I hope that this architecture, and the advances in natural language processing it is based on, will help to bring machine translation ever closer to the capabilities of human translators. 3.2 Multi-Engine Multi-Pass Machine Translation System At the current level of success of machine translation systems, a multi-engine Multi-Pass Machine Translation system along the lines suggested by Callison-Burch & Flournoy (2001) seems worth building. This system"
2002.tmi-tmiw.2,1999.mtsummit-1.48,0,0.111301,"Missing"
2002.tmi-tmiw.2,1999.tmi-1.13,0,0.0343073,"derstand. Wu (1997) shows a way of exploiting a translation to parse a text using an inversion transduction grammar. 2.4 Making a first draft The actual translation process itself should use a good rule-based system with the correct domain dictionaries and unknown words and their translations identified and put into a user dictionary, possibly combined with a translation memory to translate previously encountered text. This creates the first draft. 2.5 Revising the first draft There have been some suggestions to check for deceptive cognates (Isabelle et al. 1993), or omissions in translation (Russell 1999), and to choose articles (Chander 1998). At present, these techniques are not yet so useful in practice, probably because the revision systems are not able to consider the meaning of the text. Naruedomkul & Cercone (1997) suggested an MT architecture that would first translate and then revise poor translations but they did not implement the revision part of the system. One task that could be considered a revision is the addition of translator’s footnotes or notes. Whether they are appropriate or not depends on the target audience. A translator’s note is useful if a word without a good translat"
2002.tmi-tmiw.2,1999.tmi-1.11,0,0.111221,"Missing"
2002.tmi-tmiw.2,J97-3002,0,0.00785344,"tility of comparing with existing translations is the well-attested benefits of the use of translation memories (Planas 1999). Their value is so widely known that there is little need to say more. If existing translations are available they can also be used to extract rules (Yamada et al. 1995), or provide data for example-based machine translation. Further, a translation can help to guide a system’s understanding of the source text by adding extra constraints on its parse, in the same way that a human may look to a translation to clarify the meaning of a section they find hard to understand. Wu (1997) shows a way of exploiting a translation to parse a text using an inversion transduction grammar. 2.4 Making a first draft The actual translation process itself should use a good rule-based system with the correct domain dictionaries and unknown words and their translations identified and put into a user dictionary, possibly combined with a translation memory to translate previously encountered text. This creates the first draft. 2.5 Revising the first draft There have been some suggestions to check for deceptive cognates (Isabelle et al. 1993), or omissions in translation (Russell 1999), and"
2002.tmi-tmiw.2,1997.tmi-1.2,0,0.0496304,"Missing"
2003.mtsummit-papers.3,2001.mtsummit-papers.16,0,0.0536134,"Missing"
2003.mtsummit-papers.3,1985.tmi-1.5,0,0.0392697,"Missing"
2003.mtsummit-papers.3,W02-1608,1,0.26879,"Missing"
2003.mtsummit-papers.3,2002.tmi-papers.6,1,0.823773,"Missing"
2003.mtsummit-papers.3,H01-1043,0,0.121987,"ions. We evaluate the effects of various measures of similarity in increasing accuracy. 1 Introduction Although great progress has been made in learning statistical models from annotated corpora, most machine translation systems rely on detailed information compiled in lexicons. These are typically handbuilt (Dorr, 1997). However, adding this detailed information to dictionaries is both time consuming and costly. Several automatic and semi-automatic methods have been proposed to construct lexicons. A common method is to attempt to learn information from corpora (Manning, 1993; Li & Abe, 1998; Kawahara & Kurohashi, 2001). Other work has attempted to extract knowledge from heterogeneous sources, such as existing lexicons (Fujita & Bond, 2002a; Dorr et al., 2002). Our work differs from corpus-based work such as Manning (1993) or Kawahara & Kurohashi (2001) in that we are using existing lexical resources rather than a corpus. Our method is applicable to rare words, so long as we can find them in a bilingual dictionary, and know the English translation. In order to demonstrate the utility of the valency information, we give an example of a sentence translated with the system default information (basically a choic"
2003.mtsummit-papers.3,J98-2002,0,0.222594,"anguage translations. We evaluate the effects of various measures of similarity in increasing accuracy. 1 Introduction Although great progress has been made in learning statistical models from annotated corpora, most machine translation systems rely on detailed information compiled in lexicons. These are typically handbuilt (Dorr, 1997). However, adding this detailed information to dictionaries is both time consuming and costly. Several automatic and semi-automatic methods have been proposed to construct lexicons. A common method is to attempt to learn information from corpora (Manning, 1993; Li & Abe, 1998; Kawahara & Kurohashi, 2001). Other work has attempted to extract knowledge from heterogeneous sources, such as existing lexicons (Fujita & Bond, 2002a; Dorr et al., 2002). Our work differs from corpus-based work such as Manning (1993) or Kawahara & Kurohashi (2001) in that we are using existing lexical resources rather than a corpus. Our method is applicable to rare words, so long as we can find them in a bilingual dictionary, and know the English translation. In order to demonstrate the utility of the valency information, we give an example of a sentence translated with the system default i"
2003.mtsummit-papers.3,A00-2034,0,0.0204791,"ed dictionary linked by the Causative/Inchoative Alternation. We make patterns for both of them, allowing us to match both (2) and (3).     (2)       doukasen ga chakka-shita. fuse ACC ignited The fuse ignited. (3)      kare wa doukasen ni chakka-shita. He TOP fuse DAT ignited. He ignited the fuse. This can only be done if the seed dictionary contains information about alternations, but currently much research is being done to identify them and add them to lexicons, both by linguists (Furumaki & Tanaka, 2003) and computational linguists (Bond et al., 2002; McCarthy, 2000). 2.1.2 Method of Merging Patterns Merging similar candidates is an important problem for corpus-based approaches, which normally have 10s to 1000s of candidates to merge (Li & Abe, 1998; McCarthy, 2000). In our case we have fewer candidates, and they have more information. Although the existence of very similar patterns does not effect the translation quality, the redundancy creates spurious ambiguity, which slows the system down and makes debugging harder. We reduce the number of redundant patterns by merging similar entries. First, if two patterns were identical, we merge them. We then merg"
2004.tmi-1.6,2003.mtsummit-papers.3,1,0.816287,"a non-target plain dictionary (S − X) – Replace SK by SU then create a new entry (SU -TU K ) for pairs which have at least one translation (X U K ) in common Figure 2: Creating New Entries tions)1 . The only word that matches is the head. Fujita & Bond (2002) examined various variations in matching other elements apart from the head, but found no improvement. So we determined the head using information in the valency dictionary in Step 1. Because of this there was additional overgeneration for complex verbs such as give up and give back. To reduce the overgeneration, Fujita & Bond (2002) and Bond & Fujita (2003) used human judgement. But in this paper, we automatically filter out incorrect entries using matching in other languages (Step 2). Because we match the entire translation in language X, there is no overgeneration due to complex verbs. If there are multiple plain dictionaries, then the criterion in Step 2 can be varied further — for example to use all dictionaries and select these words which have at least one matching translation of X (we call this UNION) or to use all dictionaries and select only those words which have matching translations in all languages (we call this INTER). 3 Resources"
2004.tmi-1.6,J95-4004,0,0.226488,"Missing"
2004.tmi-1.6,C02-1051,0,0.0257105,"Missing"
2004.tmi-1.6,H01-1043,0,\N,Missing
2004.tmi-1.6,W02-1608,1,\N,Missing
2004.tmi-1.6,2001.mtsummit-papers.10,1,\N,Missing
2005.mtsummit-papers.1,1999.tmi-1.19,1,\N,Missing
2005.mtsummit-papers.1,W03-1024,0,\N,Missing
2005.mtsummit-papers.1,C04-1050,0,\N,Missing
2005.mtsummit-papers.1,W02-1210,0,\N,Missing
2005.mtsummit-papers.1,P98-2180,0,\N,Missing
2005.mtsummit-papers.1,C98-2175,0,\N,Missing
2005.mtsummit-papers.1,C04-1185,0,\N,Missing
2005.mtsummit-papers.22,W02-1503,1,0.809591,"ationship between the two formalisms in general, while our task goes beyond that. We need to interrelate speciﬁc f-structures and MRS representations which are not only well-formed, but which also satisfy further, mutually independent constraints. In the ﬁrst place, already the fact that f-structures are syntactic representations and MRSs semantic representations designed to capture translational relations frequently motivates diﬀerent packagings of information on the two levels. Furthermore, the NorGram f-structures meet the requirements for f-structures developed within the ParGram project (Butt, Dyvik, King, Masuichi, & Rohrer, 2002; Dyvik, 2003), while the NorGram MRS representations are constructed according to the same general principles as the MRS representations of the target ERG grammar. As a result the f-structure and MRS analyses of the same sentence are not always in a simple structural correspondence with each other. One example is nominal phrases with several speciﬁers in the f-structure, and phrases with no speciﬁers (Norwegian bare singulars), contrasted with the MRS requirement that a variable must always be bound by one single quantiﬁer; other examples involve diﬀerent dominance relations among predicates"
2005.mtsummit-papers.22,1995.tmi-1.2,1,0.840886,"ally grounded component of each grammar, capturing several classes of lexical regularities while also serving the crucial engineering function of supplying a reliable and complete speciﬁcation of the elementary predications the grammar can realize. We make extensive use of underspeciﬁcation and type hierarchies to maximize generality and precision. 1 Introduction In this paper we introduce two interesting features of the Norwegian-to-English machine translation system LOGON. (1) It is the ﬁrst system to use the full power of Minimal Recursion Semantics in translation (originally introduced by Copestake, Flickinger, Malouf, Riehemann, & Sag, 1995). (2) The transfer modules use the SEM-I, an interface speciﬁcation designed to allow the use of deep grammars in various applications without knowledge of the grammar internals (Copestake & Flickinger, 2003). The motivation for the SEM-I is threefold. First, it allows the semantic representation to be underspeciﬁed. In the LOGON system, if the analysis system does not have enough information to commit to an interpretation then the ambiguity is retained. Doing this by naively expanding all interpretations is so ineﬃcient as to be unworkable. Second, it exposes only the information that is rel"
2005.mtsummit-papers.22,P97-1052,0,0.0715544,"Missing"
2005.mtsummit-papers.22,1997.tmi-1.18,0,0.00828586,"ular count {IND +} nouns, we will generate for example She wrote a good paper but not *She wrote good paper. The underspeciﬁed ﬁrst entry above will be useful in translating between English and, say, German, where in both languages one word can be used for both senses, and where for some sentences no disambiguation is required, as in That paper is good. This approach diﬀers from many semantic-transfer based systems, particularly knowledge-based MT. In these systems lexical semantic information (including word senses, semantic classes and selectional preferences) is used to disambiguate input (Mahesh et al., 1997; Ikehara et al., 1996). The interface between transfer and generation is then a single fully speciﬁed semantic representation (although often with scope issues ignored), rather than an underspeciﬁed one. The SEM-I is compatible with such an approach — it would then link the grammars to the ontology of lexical semantic information and provide the input to the sense disambiguation module. 5.2 Productive Derivation Languages typically include productive derivational processes which result in multiple words whose syntactic and semantic properties are related but distinct. One such common process"
2005.mtsummit-papers.22,2004.tmi-1.2,1,0.832796,"Missing"
2007.tmi-papers.17,2005.mtsummit-papers.22,1,0.846744,"(h) indicating scopal relations, events (e), and entities (x). Figure 2 gives the MRS for the sentence “Research is fun.” The sentence is a statement, and the message, proposition m rel(e2) indicates this. tanoshii a rel(e2,x6)is an event, and takes kenkyuu s rel(x6)as its subject. noun-relation(x6) nominalizes kenkyuu s rel(x6), which is normally an event, turning it into an entity. MRS provides several features that make it attractive as a transfer language, such as uniform representation of pronouns, specifiers, temporal expressions, and the like over grammars. More details can be found in Flickinger et al. (2005). MRS 3.3 Transfer Rules As illustrated in Oepen et al. (2004), transfer rules take the form of MRS tuples: 136 v L }WD [ LTOP: h1 INDEX: e2 [ e TENSE: PRES MOOD: INDICATIVE PROG: - PERF: - ] RELS: < [ PRED proposition_m_rel LBL: h1 ARG0: e2 MARG: h3 ] [ PRED &quot;_kenkyuu_s_rel&quot; LBL: h4 ARG0: x5 ARG1: u7 ARG2: u6 ] [ PRED &quot;noun-relation&quot; LBL: h8 ARG0: x5 ARG1: h9 ] [ PRED proposition_m_rel LBL: h9 ARG0: x5 MARG: h10 ] [ PRED udef_rel LBL: h11 ARG0: x5 RSTR: h12 BODY: h13 ] [ PRED &quot;_tanoshii_a_rel&quot; LBL: h14 ARG0: e2 ARG1: x5 ] > HCONS: < h3 qeq h14, h10 qeq h4, h12 qeq h8 > ] Figure 2: MRS for v L"
2007.tmi-papers.17,2006.eamt-1.29,0,0.0476002,"Missing"
2007.tmi-papers.17,2005.mtsummit-tutorials.1,0,0.0211357,"osition that translation is a problem of meaning preservation, and that deep NLP is essential in meeting goals of high quality translation. Our ultimate aim is to have a robust, high quality and easily extensible Japanese↔English machine translation system. Current stochastic MT systems are both robust and of high quality, but only for those domains and language pairs where there is a large amount of existing parallel text. Changing the type of the text to be translated causes the quality to drop off dramatically (Paul, 2006). Quality is proportional to the log of the amount of training data (Och, 2005), which makes it hard to quickly extend a system. Rulebased systems can also produce high quality in a limited domain (Oepen et al., 2004). Further, it is relatively easy to tweak rule-based systems by the use of user dictionaries (Sukehiro et al., 2001), although these changes are limited in scope. Our approach to producing a robust, high quality system is to concentrate on translation quality and system extensibility, without worrying so much about coverage. We are able to do this because of the availability of a robust open source statistical machine translation systems (Koehn et al., 2007)"
2007.tmi-papers.17,J03-1002,0,0.00330736,"actic categories • Translations that match indicate existence of compatible rule template 4. Create a transfer rule by combining the rule template and lists of source and target MRS relations 138 RBMT (Jaen) Ranking engine Source text SMT (Moses) Target text Figure 3: The combined Jaen and Moses system 00 [ g“a; g“X] <gloss>farmland</gloss> <gloss>rice field or paddy</gloss> → <gloss>rice field</gloss> <gloss>rice paddy</gloss> Using this algorithm we can extract rules from any list of word pairs and have created rules from the EDR5 Electronic Dictionary, Wikipedia6 article links, and GIZA++ (Och and Ney, 2003) word alignments from the IWSLT 2006 training data. Our primary source of rules, however, is JMDict. The results of open category transfer rule acquisition from JMDict are summarized in Table 1. These two extensions make it possible to produce transfer rules only for those entries which are true translations. 4.2.1 4.3 Enhancing the Bilingual Dictionary The resource bottleneck is a well know problem for machine translation systems. As part of our strategy to overcome it, we are consciously avoiding the creation of specialty lexicons. Instead we are reusing and contributing to an existing dicti"
2007.tmi-papers.17,2004.tmi-1.2,0,0.0535076,"Missing"
2007.tmi-papers.17,2007.tmi-papers.18,0,0.0969807,"anese→English system (hereafter referred to as “Jaen”) is semantic transfer via rewrite rules, as shown in Figure 1. The source text is parsed using an HPSG grammar for the source language, and a semantic analysis in the form of Minimal Recursion Semantics (MRS) is produced. That semantic structure is rewritten using transfer rules into a target-language MRS structure, which is finally used to generate text from a target-language HPSG grammar. Statistical models are used at various stages in the process. There are seperate models for analyses, transfer and generation, combined as described in Oepen et al. (2007). At each stage we prune the search space, only passing n different results (5 by default) to the next stage. Although we mainly discuss Jaen in this paper, we have also built a reverse system, Enja, using the same components. 1 http://logos-os.dfki.de/ 135 3.1 System Components The grammars and processing systems we use are all being developed within the DELPH - IN 2 project (Deep Linguistic Processing with HPSG Initiative) and are available for download. The lexicon is from an unconnected project (JMdict 3 ). 3.1.1 Processing Engines Jaen uses the LKB (Copestake, 2002) for both parsing and g"
2007.tmi-papers.17,2001.mtsummit-papers.59,0,0.0346266,"slation system. Current stochastic MT systems are both robust and of high quality, but only for those domains and language pairs where there is a large amount of existing parallel text. Changing the type of the text to be translated causes the quality to drop off dramatically (Paul, 2006). Quality is proportional to the log of the amount of training data (Och, 2005), which makes it hard to quickly extend a system. Rulebased systems can also produce high quality in a limited domain (Oepen et al., 2004). Further, it is relatively easy to tweak rule-based systems by the use of user dictionaries (Sukehiro et al., 2001), although these changes are limited in scope. Our approach to producing a robust, high quality system is to concentrate on translation quality and system extensibility, without worrying so much about coverage. We are able to do this because of the availability of a robust open source statistical machine translation systems (Koehn et al., 2007). As long as we can produce a system that produces good translations for those sentences it can translate, we can fall back on the SMT system for sentences that it cannot translate. This leaves the problem of how to build a system that is both high quali"
2007.tmi-papers.17,W04-2209,0,\N,Missing
2007.tmi-papers.17,W02-1502,0,\N,Missing
2007.tmi-papers.17,P07-2045,0,\N,Missing
2007.tmi-papers.17,2005.mtsummit-osmtw.3,1,\N,Missing
2007.tmi-papers.17,2006.iwslt-evaluation.1,0,\N,Missing
2008.iwslt-papers.2,P05-1074,0,0.0857514,"ons o the same meaning it it can be derived from preexisting training corpora and automatically aligned with the same target training sentence in a bilingual corpora. Including generated paraphrases as additional training data gives an SMT system the ability to make a richer model and thus positively affecting model quality during evaluation. There are several areas where paraphrases can be readily introduced into standard phrase-based SMT systems: source and target sides and even during the parameter tuning phase as references. Work has been done to extract paraphrases from bilingual corpora [1] and to extract paraphrase patterns as in [2]. By pivoting on target language phrases, source phrases and potential paraphrases can be found; for extracting patterns the task extends to a generalization of phrases with slots instead Proceedings of IWSLT 2008, Hawaii - U.S.A. of words. [3] found that it is possible to translate unknown source words by paraphrasing them and then do a translation on the paraphrase. The classic example of the pivot approach from [3] follows: (2) what is more, the relevant cost dynamic is completely under control im u¨ brigen ist die diesbez¨ugliche kostenentwicklu"
2008.iwslt-papers.2,P08-1089,0,0.0117653,"rom preexisting training corpora and automatically aligned with the same target training sentence in a bilingual corpora. Including generated paraphrases as additional training data gives an SMT system the ability to make a richer model and thus positively affecting model quality during evaluation. There are several areas where paraphrases can be readily introduced into standard phrase-based SMT systems: source and target sides and even during the parameter tuning phase as references. Work has been done to extract paraphrases from bilingual corpora [1] and to extract paraphrase patterns as in [2]. By pivoting on target language phrases, source phrases and potential paraphrases can be found; for extracting patterns the task extends to a generalization of phrases with slots instead Proceedings of IWSLT 2008, Hawaii - U.S.A. of words. [3] found that it is possible to translate unknown source words by paraphrasing them and then do a translation on the paraphrase. The classic example of the pivot approach from [3] follows: (2) what is more, the relevant cost dynamic is completely under control im u¨ brigen ist die diesbez¨ugliche kostenentwicklung v¨ollig unter kontrolle (3) wir sind es de"
2008.iwslt-papers.2,N06-1003,0,0.529709,"s positively affecting model quality during evaluation. There are several areas where paraphrases can be readily introduced into standard phrase-based SMT systems: source and target sides and even during the parameter tuning phase as references. Work has been done to extract paraphrases from bilingual corpora [1] and to extract paraphrase patterns as in [2]. By pivoting on target language phrases, source phrases and potential paraphrases can be found; for extracting patterns the task extends to a generalization of phrases with slots instead Proceedings of IWSLT 2008, Hawaii - U.S.A. of words. [3] found that it is possible to translate unknown source words by paraphrasing them and then do a translation on the paraphrase. The classic example of the pivot approach from [3] follows: (2) what is more, the relevant cost dynamic is completely under control im u¨ brigen ist die diesbez¨ugliche kostenentwicklung v¨ollig unter kontrolle (3) wir sind es den steuerzahlern die kosten schuldig unter kontrolle zu haben we owe it to the taxpayers to keep the costs in check By holding the german phrase unter kontrolle as a pivot the English phrase under control can be paraphrased as in check. [2] exte"
2008.iwslt-papers.2,2006.iwslt-evaluation.11,0,0.101827,"e directly to the training corpus. As for the BLEU scores, they only ever achieve an increase of about 1 BLEU point and this is on limited corpora sizes. Some examples from [4] are as follows: (5) of members of the Irish parliament of irish parliament members of irish parliament’s members (6) action at community level community level action To the extent that paraphrasing techniques are comparable to more implicit methods of language to language manipulation we explore previous research related to reordering models where a form of paraphras- 151 - ing does occur in how translation is done. In [5] proposed a reordering model that took into account predicateargument structure in Japanese and followed a heuristic for reordering sentences in the training data as a preprocessing step. This sort of reordering, while unnatural to native speakers, is still grammatically correct and easier to align to English during model training, it is also a type of paraphrasing. [6] made use of parses of source sentences and then applied a reordering heuristic as well. [7] also discusses the use altering German word order to correspond to English word order there is also some use of annotations on verbs wi"
2008.iwslt-papers.2,P05-1066,0,0.0326932,"ng techniques are comparable to more implicit methods of language to language manipulation we explore previous research related to reordering models where a form of paraphras- 151 - ing does occur in how translation is done. In [5] proposed a reordering model that took into account predicateargument structure in Japanese and followed a heuristic for reordering sentences in the training data as a preprocessing step. This sort of reordering, while unnatural to native speakers, is still grammatically correct and easier to align to English during model training, it is also a type of paraphrasing. [6] made use of parses of source sentences and then applied a reordering heuristic as well. [7] also discusses the use altering German word order to correspond to English word order there is also some use of annotations on verbs with identifying prefixes to solve the long distance dependency of German verbs types that allow for separation of the prefix from the verb in the sentence structure. 3. Resources In this section we describe the major resources used. For the SMT system we used the open source Moses system1 . For paraphrasing we used the open source English Resource Grammar. We tested on t"
2008.iwslt-papers.2,2001.mtsummit-papers.45,0,0.030743,"e explore previous research related to reordering models where a form of paraphras- 151 - ing does occur in how translation is done. In [5] proposed a reordering model that took into account predicateargument structure in Japanese and followed a heuristic for reordering sentences in the training data as a preprocessing step. This sort of reordering, while unnatural to native speakers, is still grammatically correct and easier to align to English during model training, it is also a type of paraphrasing. [6] made use of parses of source sentences and then applied a reordering heuristic as well. [7] also discusses the use altering German word order to correspond to English word order there is also some use of annotations on verbs with identifying prefixes to solve the long distance dependency of German verbs types that allow for separation of the prefix from the verb in the sentence structure. 3. Resources In this section we describe the major resources used. For the SMT system we used the open source Moses system1 . For paraphrasing we used the open source English Resource Grammar. We tested on two JapaneseEnglish corpora, the Tanaka Corpus and the IWSLT corpus. We chose the Tanaka corp"
2008.iwslt-papers.2,P07-2045,0,0.00468382,"For paraphrasing we used the open source English Resource Grammar. We tested on two JapaneseEnglish corpora, the Tanaka Corpus and the IWSLT corpus. We chose the Tanaka corpus primarily because of its easy availability (it is in the public domain). This will make our results easy to reproduce. We also tested on the IWSLT corpus, as it has been used in several competitions, in order to facilitate comparisons with other systems. In the spirit of open science, the paraphrased Tanaka Corpus data and our scripts will be put on line at www2. nict.go.jp/x/x161/en/member/bond/data/. 3.1. Moses Moses [8] is an open-source toolkit for phrase-based statistical machine translation with support for factors. The toolkit is one of the first highly efficient and free SMT decoders and tool kits; it supports building factored statistical models. Factors such as part-of-speech, morphology, and lemmas are applied using translation models and generation models, two features of moses which in conjunction with the user specified decoding steps help to create stories of how one language might translate best to another. We used the multi-threaded Giza++ [9] as it fixed a bug in how probabilities are assigned"
2008.iwslt-papers.2,W06-1661,0,0.0282395,"ersity since 1993. The ERG was originally developed within the Verbmobil machine translation effort, but over the past few years has been ported to additional domains and significantly extended. The grammar includes a hand-built lexicon of around 43,000 lexemes. We are using the development release LinGO (Apr-08). The ERG and the associated parsers and generators are freely available from the Deep Linguistic Processing with HPSG Initiative (DELPH-IN: www. delph-in.net/). Generally, we use the default settings and the language models trained in the LOGON project both for parsing and generation [12]. However, we set the root condition, which controls which sentences are treated as grammatical, to be robust for parsing and strict for generation. This means that robust rules (for example a rule to allow verbs not to agree in number with their subject) will apply in parsing but not in generation. The grammar will thus parse The dog bark or The dog barks but only generate The dog barks. 3.3. Corpora We used two corpora, one freely available, and one standard test set. 3.3.1. Tanaka Corpus The Tanaka corpus is an open corpus of Japanese-English sentence pairs compiled by Professor Yasuhito Ta"
2008.iwslt-papers.2,2004.iwslt-evaluation.1,1,0.799203,"ong sentences (> 40 tokens) as part of the SMT cleaning process, there were 147,007 sentences in the training set. The average number of tokens per sentence is 11.6 for Japanese and 9.1 for English (with the tokenization used in the SMT). 3.3.2. The IWSLT Corpus We also tested our system on the IWSLT 2005 evaluation corpus [15]. This is a subset of the Basic Travel Expression Corpus (BTEC), which contains tourismrelated sentences similar to those that are usually found in phrase books for tourists going abroad [16]. Parts of this corpus were already used in previous IWSLT evaluation campaigns [17]. We used the evaluation and development data sets of 2004, although only with the first of the multiple reference translations, for our development corpora and the 500 sentence IWSLT 2005 evaluation set, again with only the first of the 16 references, as the evaluation corpus. The IWSLT corpus has 42,682 sentence pairs. The average number of tokens per sentence is 9.0 for Japanese and 8.0 for English (with the tokenization used in the SMT). The sentences are both shorter and more homogeneous than those in the Tanaka Corpus. 4. Method 4.1. Paraphrasing We paraphrase by parsing a sentence to an"
2008.iwslt-papers.2,W04-3230,0,0.0113819,"82 0.74 0.79 0.83 0.77 0.82 0.81 0.80 0.82 +0.14 +0.29 +0.67 +0.20 +0.14 +0.32 +0.17 -0.13 +0.34 -0.33 -0.04 +0.15 +0.34 +0.17 +0.27 +0.44 Table 2: Results of adding paraphrases to Tanaka Corpus training data We replicated the baseline in the ACL 2007 Second Workshop on Statistical Machine Translation. The baseline is a factorless Moses system with a 5-gram language model. We followed the online tutorial3 as-is, with the exception that we used external morphological analyzers to tokenize our data instead of using the provided scripts. We used the Tree Tagger [21] for English and MeCab [22] for Japanese. Part-of-speech information was discarded after tokenization. All data was tokenized, separating punctuation from words and converted to lowercase prior to training and translation. Translations were detokenized and recased prior to evaluation using the helper scripts distributed as part of the baseline system for the ACL 2007 SMT Workshop. Prior to evaluation we conducted Minimum Error Rate Training on each system using the development data from the target corpus. We used the MERT implementation distributed with Moses. All results reported in this paper are post-mert Bleu scores"
2008.iwslt-papers.2,W04-3250,0,0.00898498,"ata 5.2. Results We compared a baseline of no paraphrases added (d:0) to systems with progressively larger numbers of new paraphrased sentence pairs added to the training data. We tested three distributions (d, f and v ). v always gave results below the baseline, so we do not report them in more detail. The results for d and f are summarized in Tables 2 and 3 with 2, 4, 6 and 8 paraphrases. All deltas and significance results are calculated against the baseline of no paraphrases (0). We calculated Bleu score variance and measured statistical significance with the bootstrap methods outlined in [23] using Jun-ya Norimatsu’s MIT-Licensed Bleu Kit.4 Variance scores are reported with p = 0:05 in Tables 2 and 3. In Tables 2 and 3 results with an improvement of p < 0:10 over the baseline are shown in bold. 6. Discussion The results for En!Ja show gains of up to 0.67 Bleu points on the Tanaka Corpus and 0.19 on the IWSLT 4 www.mibel.cs.tsukuba.ac.jp/˜norimatsu/ bleu_kit/ - 155 - 2005 evaluation data. The results for Ja!En show gains of 0.44 on the Tanaka Corpus and 0.61 on the IWSLT 2005 evaluation data. There is a statistically significant improvement for each language pair and paraphrase dis"
2008.iwslt-papers.2,2007.tmi-papers.18,0,0.0109645,"raphrases. Compared to [3] or [4] we are very conservative in our paraphrasing, and this is probably why we get a slightly lower improvement in quality. We could do more extravagant paraphrasing, but would have to retrain the generation model. At the moment, it expects fully specified input MRSs, if we were going to allow variation in, for example, noun phrase structure or open class lexical variation, then we should treat it as a monolingual translation problem, and also train a transfer (paraphrase) model. An example of how to do this (for bilingual transfer (Norwegian-English)) is given in [24]. Our syntactic reordering is not aimed at matching the target language like [5]. We correspondingly get a slighter improvement, but can hope to get a similar improvement even for different language pairs. Also, our improvement is still there after MERT training, whereas theirs did not survive the optimization. 7. Further Work MT system [26]. We can easily write noun phrase rewriting rules of the type used by [4]. For lexical substitution we will try using WordNet, after first disambiguating the input. Finally, we would like to enhance Moses (primarily GIZA++) so that input sentences can be we"
2008.iwslt-papers.2,2005.mtsummit-osmtw.3,1,0.82132,"xample, noun phrase structure or open class lexical variation, then we should treat it as a monolingual translation problem, and also train a transfer (paraphrase) model. An example of how to do this (for bilingual transfer (Norwegian-English)) is given in [24]. Our syntactic reordering is not aimed at matching the target language like [5]. We correspondingly get a slighter improvement, but can hope to get a similar improvement even for different language pairs. Also, our improvement is still there after MERT training, whereas theirs did not survive the optimization. 7. Further Work MT system [26]. We can easily write noun phrase rewriting rules of the type used by [4]. For lexical substitution we will try using WordNet, after first disambiguating the input. Finally, we would like to enhance Moses (primarily GIZA++) so that input sentences can be weighted. That way, if we have n paraphrases for one sentence and m for another, each can just be entered with a weight of 1=n and 1=m respectively. If we could do this, we could then experiment with setting a probability based threshold on the number of paraphrases, for example, to select all paraphrases within of the probability of the origi"
2008.iwslt-papers.2,2005.iwslt-1.1,0,\N,Missing
2016.gwc-1.33,C04-1193,1,0.829351,"the best of our knowledge, the Asian Wordnet project is the only project that translated the English definitions of some synsets in PWN into Indonesian. However, the definitions were crowd sourced and had little quality control so not all of 14,190 definitions could be directly transferred. Many of the definitions had problems and needed to be cleaned up. The definitions for nouns and verbs which had been cleaned up were exploited to extract relations, such as synonym, hyponym, hypernym and instance hypernym, between lemmas and definitions. The method of extracting these relations was done in Bond et al. (2004) to build an ontology. We used Python (3.4, Python Software Foundation) and the Natural Language Toolkit (NLTK) (Bird et al., 2009) to process the data. This paper is organized as follows: Section 2 describes the process of cleaning up the definitions, Section 3 explains the process of extracting hypernyms and other relations from the definitions. Section 4 presents the results and discussion and Section 5 concludes. 2 Cleaning up the definitions As mentioned in Section 1 above, the definitions we had available were not clean. Many infelicities were found, such as misspellings, definitions usi"
2016.gwc-1.33,Y11-1027,1,0.789786,"terlinked through a number of semantic relations (Fellbaum, 1998; Fellbaum, 2005). Since its creation, many other wordnets in different languages have been built based on Princeton Wordnet (PWN) (Bond and Paik, 2012; Bond and Foster, 2013). One of them, Wordnet Bahasa, is built as a lexical database of the Malay language. At present, it consists of two language variants: Indonesian and Standard Malay. It combines data from several lexical resources: the French-English-Malay dictionary (FEM), the KAmus Melayu-Inggeris (KAMI), and wordnets for English, French and Chinese (Nurril Hirfana Mohamed Noor et al., 2011, p. 258). We added Indonesian definitions from the Asian Wordnet project (Riza et al., 2010) to Wordnet Bahasa. To the best of our knowledge, the Asian Wordnet project is the only project that translated the English definitions of some synsets in PWN into Indonesian. However, the definitions were crowd sourced and had little quality control so not all of 14,190 definitions could be directly transferred. Many of the definitions had problems and needed to be cleaned up. The definitions for nouns and verbs which had been cleaned up were exploited to extract relations, such as synonym, hyponym, h"
2016.gwc-1.33,W10-3202,0,0.0185217,"creation, many other wordnets in different languages have been built based on Princeton Wordnet (PWN) (Bond and Paik, 2012; Bond and Foster, 2013). One of them, Wordnet Bahasa, is built as a lexical database of the Malay language. At present, it consists of two language variants: Indonesian and Standard Malay. It combines data from several lexical resources: the French-English-Malay dictionary (FEM), the KAmus Melayu-Inggeris (KAMI), and wordnets for English, French and Chinese (Nurril Hirfana Mohamed Noor et al., 2011, p. 258). We added Indonesian definitions from the Asian Wordnet project (Riza et al., 2010) to Wordnet Bahasa. To the best of our knowledge, the Asian Wordnet project is the only project that translated the English definitions of some synsets in PWN into Indonesian. However, the definitions were crowd sourced and had little quality control so not all of 14,190 definitions could be directly transferred. Many of the definitions had problems and needed to be cleaned up. The definitions for nouns and verbs which had been cleaned up were exploited to extract relations, such as synonym, hyponym, hypernym and instance hypernym, between lemmas and definitions. The method of extracting these"
2016.gwc-1.59,W04-2214,0,0.0601204,"adhere to some version of the Princeton WordNet also means that the fund of concepts is biased towards an AngloSaxon worldview and is not open to concepts from other languages and cultures. It could be argued that these problems would go away if a single multilingual database was developed instead. This would, in theory, solve problems of incompatible formats and coordination. In practice, however there is no single group that has expertise in all the world’s languages. Further, much experimentation is done in the different projects; adding new relations (Vossen, 1998), adding richer domains (Bentivogli et al., 2004), adding new parts-of-speech (Seah and Bond, 2014) and so forth. This would be harder to do in one monolithic project. As time passes, and PWN now celebrates its 25th anniversary, the need for implementing the GWG becomes more urgent. The GWG should be a platform for achieving linguistic and conceptual interoperability across wordnets and all related machinery. It should allow researchers to study the universals and idiosyncracies in lexicalisation across languages, to address fundamental questions about what is a word and what is a concept (Fellbaum and Vossen, 2010; Vossen and Fellbaum, 2011"
2016.gwc-1.59,2016.gwc-1.9,1,0.711705,"ike license (CC BY SA). In order to keep compatibility across the grid, any projects in the Global Wordnet Grid must have a license compatible with CC BY SA (such as the original wordnet license, CC BY, MIT and many others), and the entire grid will be released under this license. The individual projects, starting with PWN, are the foundations upon which the GWG is built, the CILI links them and the platform ties them together, allows for versioning and adaptation through the community. 4 The Collaborative ILI (CILI) The Collaborative ILI is an extension of the ILI defined in EuroWordNet (see Bond et al., 2016, for more details). As a base for the CILI we take the synsets currently in Princeton Wordnet 3.0, the de facto ILI for the Open Multilingual Wordnet. This shows its central position in the current wordnet community. Each synset in PWN 3.0 gives rise to a concept in the CILI. The CILI is just a collection of concepts to which all wordnets are linked. It does not duplicate the relations between these concepts as represented in any wordnet and it does not have any lexicalizations. Concepts and concept identifiers in the CILI are permanent. They will never be removed or changed. However, new con"
2016.gwc-1.59,P15-4013,1,0.881799,"Missing"
2016.gwc-1.59,2016.gwc-1.43,1,0.805029,"Missing"
2016.gwc-1.59,Q14-1018,0,0.021166,"Missing"
2016.gwc-1.59,vossen-etal-2014-newsreader,1,0.789611,"Missing"
2016.gwc-1.8,P13-1133,1,0.902443,"Missing"
2016.gwc-1.8,P91-1034,0,0.878633,"Missing"
2016.gwc-1.8,P00-1064,0,0.0280715,"Missing"
2016.gwc-1.8,P02-1033,0,0.0866873,"ty inter-linked sense inventories exist for all the languages considered. 1 Introduction Cross-lingual Word Sense Disambiguation (CLWSD) is an approach to Word Sense Disambiguation (WSD) that exploits the similarities and the differences across languages to disambiguate text in an automatic fashion. Using existing multilingual parallel corpora for this purpose is a natural choice, as shown by a long series of works in the literature; see for instance Brown and Mercer (1991), Gale et al. (1992), Ide et al. (2002), Ng et al. (2003), Chan and Ng (2005), and Khapra et al. (2011) more recently. As Diab and Resnik (2002) showed, the translation correspondences in a parallel corpus provide valuable semantic information that can be exploited to perform WSD. For instance, Tufis¸ et al. (2004) used parallel corpora to validate the interlingual alignments in different WordNets (WNs). Specifically, they looked at the sense intersection between the lexical items found in all the reciprocal translations of a parallel corpus. Gliozzo et al. (2005) showed how CL-WSD can help to sense-annotate a bilingual corpus by looking at the semantic differences in a language pair. Bentivogli and Pianta (2005), on the other hand, f"
2016.gwc-1.8,P03-1058,0,0.215342,"is in that it can be applied to any parallel corpus, as long as large, highquality inter-linked sense inventories exist for all the languages considered. 1 Introduction Cross-lingual Word Sense Disambiguation (CLWSD) is an approach to Word Sense Disambiguation (WSD) that exploits the similarities and the differences across languages to disambiguate text in an automatic fashion. Using existing multilingual parallel corpora for this purpose is a natural choice, as shown by a long series of works in the literature; see for instance Brown and Mercer (1991), Gale et al. (1992), Ide et al. (2002), Ng et al. (2003), Chan and Ng (2005), and Khapra et al. (2011) more recently. As Diab and Resnik (2002) showed, the translation correspondences in a parallel corpus provide valuable semantic information that can be exploited to perform WSD. For instance, Tufis¸ et al. (2004) used parallel corpora to validate the interlingual alignments in different WordNets (WNs). Specifically, they looked at the sense intersection between the lexical items found in all the reciprocal translations of a parallel corpus. Gliozzo et al. (2005) showed how CL-WSD can help to sense-annotate a bilingual corpus by looking at the sema"
2016.gwc-1.8,1992.tmi-1.9,0,0.762509,"ns. The main advantage of this approach is in that it can be applied to any parallel corpus, as long as large, highquality inter-linked sense inventories exist for all the languages considered. 1 Introduction Cross-lingual Word Sense Disambiguation (CLWSD) is an approach to Word Sense Disambiguation (WSD) that exploits the similarities and the differences across languages to disambiguate text in an automatic fashion. Using existing multilingual parallel corpora for this purpose is a natural choice, as shown by a long series of works in the literature; see for instance Brown and Mercer (1991), Gale et al. (1992), Ide et al. (2002), Ng et al. (2003), Chan and Ng (2005), and Khapra et al. (2011) more recently. As Diab and Resnik (2002) showed, the translation correspondences in a parallel corpus provide valuable semantic information that can be exploited to perform WSD. For instance, Tufis¸ et al. (2004) used parallel corpora to validate the interlingual alignments in different WordNets (WNs). Specifically, they looked at the sense intersection between the lexical items found in all the reciprocal translations of a parallel corpus. Gliozzo et al. (2005) showed how CL-WSD can help to sense-annotate a bi"
2016.gwc-1.8,W02-0808,0,0.216368,"ge of this approach is in that it can be applied to any parallel corpus, as long as large, highquality inter-linked sense inventories exist for all the languages considered. 1 Introduction Cross-lingual Word Sense Disambiguation (CLWSD) is an approach to Word Sense Disambiguation (WSD) that exploits the similarities and the differences across languages to disambiguate text in an automatic fashion. Using existing multilingual parallel corpora for this purpose is a natural choice, as shown by a long series of works in the literature; see for instance Brown and Mercer (1991), Gale et al. (1992), Ide et al. (2002), Ng et al. (2003), Chan and Ng (2005), and Khapra et al. (2011) more recently. As Diab and Resnik (2002) showed, the translation correspondences in a parallel corpus provide valuable semantic information that can be exploited to perform WSD. For instance, Tufis¸ et al. (2004) used parallel corpora to validate the interlingual alignments in different WordNets (WNs). Specifically, they looked at the sense intersection between the lexical items found in all the reciprocal translations of a parallel corpus. Gliozzo et al. (2005) showed how CL-WSD can help to sense-annotate a bilingual corpus by l"
2016.gwc-1.8,P11-1057,0,0.0234023,"lel corpus, as long as large, highquality inter-linked sense inventories exist for all the languages considered. 1 Introduction Cross-lingual Word Sense Disambiguation (CLWSD) is an approach to Word Sense Disambiguation (WSD) that exploits the similarities and the differences across languages to disambiguate text in an automatic fashion. Using existing multilingual parallel corpora for this purpose is a natural choice, as shown by a long series of works in the literature; see for instance Brown and Mercer (1991), Gale et al. (1992), Ide et al. (2002), Ng et al. (2003), Chan and Ng (2005), and Khapra et al. (2011) more recently. As Diab and Resnik (2002) showed, the translation correspondences in a parallel corpus provide valuable semantic information that can be exploited to perform WSD. For instance, Tufis¸ et al. (2004) used parallel corpora to validate the interlingual alignments in different WordNets (WNs). Specifically, they looked at the sense intersection between the lexical items found in all the reciprocal translations of a parallel corpus. Gliozzo et al. (2005) showed how CL-WSD can help to sense-annotate a bilingual corpus by looking at the semantic differences in a language pair. Bentivogl"
2016.gwc-1.8,P06-1014,0,0.0483874,"ity of WN senses can occasionally, depending on the application, be more of a practical disadvantage than a quality. In this analysis, for instance, error analysis suggested that the senses found through SI were often very close, but it may happen that they are discarded as wrong outputs just because one language has a WN more developed and granular than another. We should also bear in mind that the correct senses against which we evaluate were picked by trained human annotators in the first place, and human annotators tend to describe a word as precisely as possible. Conscious of this limit, Navigli (2006) devised an automatic methodology to find a reasonable sense clustering for the senses in WN 2.1. Sense clustering can be of great help in tasks where minor sense distinctions can be ignored, allowing a coarse-grained evaluation. They found 29,974 main clusters, some of which were manually validated by an expert lexicographer for the Semeval all-word task. We mapped the senses in the clusters found to WN 3.0, losing 101 of them in the process (typically one-element clusters). When evaluating the results of SI, we performed a coarse-grained evalMethod Coarse-grained MFS Coarse-grained 4-SI Engl"
2016.gwc-1.8,tufis-etal-2004-word,0,0.0872537,"Missing"
2018.gwc-1.19,W04-2209,0,0.0647191,"i “said term’s meaning” という意味は to iu imi wa “as for the said term’s meaning” の意味は/のいみは no imi wa “as for the meaning of” 169,756,339 19,134,679/1,207,555 5,360,613/167,095 4,544,800/10,364 51,726 1,979,108/1,169 Table 1: Google n-gram Corpus Frequencies of Text Patterns terms and are probably worth further investigation. 4.2 Testing Contexts of Known New Terms We also investigated the sorts of contexts in which known new terms are being used to see if any useful additional patterns could be identified. As an initial exploration 5 terms were chosen from recent additions to the JMdict database (Breen, 2004) which had been noted as popular new words/expressions. The 5 terms were: • マタハラ matahara abbreviation meaning “workplace discrimination against pregnant women”; • こじらせ女子 kojirase joshi “girl who has low self-esteem”; • ナマポ namapo slang for “welfare recipient” • 美魔女 bimajo “middle-aged woman who looks very young for her age” • 隠 れ メ タ ボ kakure metabo abbreviation meaning “normal weight obesity” 10 sentences for each term were extracted using a WWW search. While this is clearly a small number of samples, it emerged that there were relatively few of the と い う/と は/etc. sorts of patterns used; onl"
2018.gwc-1.19,P14-1119,0,0.0249622,"Singapore bond@ieee.org will do a WWW search for “⟨term⟩ とは”, etc. when encountering an unfamiliar term in order to identify cases where the term is being described, discussed or otherwise highlighted. The investigation broadly breaks into two components: a. the identification of the sorts of language patterns used to describe, discuss, highlight, etc. terms; b. the extraction and evaluation of terms so targeted by those language patterns. 2 Prior Work Research into the use of linguistic patterns in text to detect terms of interest has taken place in several contexts. In keyphrase extraction Hasan and Ng (2014) have produced a wide-ranging survey of the various techniques used in keyphrase extraction and their relative effectiveness, and Kim et al. (2013) evaluate the performance of a variety of supervised and unsupervised approaches. In term extraction, which is a major part of the broader field of terminology, usually in technical contexts (Kageura (2000)), Takeuchi et al. (2009) adapted the French ACABIT system, which detects morpho-syntactic sequences, to isolate terms in Japanese for later analysis. Le et al. (2013) used patterns of phrases to identify particular Japanese legal documents of int"
2018.gwc-1.19,W04-3230,0,0.036189,"Missing"
2018.gwc-1.19,sato-kaide-2010-person,0,0.0233685,"se was restricted to kanji sequences. The relationship between a text pattern and a term of interest is a form of collocation, i.e. lying between idiomatic expressions and free word combinations. In their survey of collocations in language processing, McKeown and Radev (2000) explore the role of the extraction of collocations in lexicography, although the focus is on the identification of general terms rather than those which are highlighted as being of interest. Prior published research into the use of Japanese text patterns which target general terms of interest appears to be quite limited. Sato and Kaide (2010) employed a related technique for extracting English–Japanese name pairs by scanning texts for nearby occurrences of Mr, Mrs, etc. and the Japanese equivalents, e.g. さん (san). 3 Text Corpora An essential element of the investigation is the availability of substantial quantities of Japanese text, preferably from a variety of sources. While there are number of Japanese corpora available for use in NLP work, most are actually quite small. In this study we used two text collections: a. the Kyoto WWW Corpus. This is a collection of 500 million Japanese sentences collected from WWW pages in 2004. Th"
2018.gwc-1.24,W14-0142,1,0.803292,"systems between English and Polish e.g. {big fishn:1 , ...} linked by Domain Usage relation to {colloquialismn:1 } and via I-partial synonymy relation to the Polish synset {gruba ryban:1 ‘big fish’, wa˙zniakn:2 ‘VIP’} with both its LUs marked for the colloquial register. However, such simple cases are rare. Both in Princeton WordNet and in plWordNet, LUs of different registers can co-occur in the same synset. However, in the latter only LUs of compatible register can be grouped in one synset or linked by some relation, e.g. hypernymy. A set of rules was defined for this purpose in plWordNet (Maziarz et al., 2014), while this aspect is largely unconstrained in Princeton WordNet. General, specialist, literary, and official registers can co-occur in one synset; the same holds for general and colloquial ones (provided that that specialist, literary and official are not found in the same synset). Colloquial, common and vulgar can also come together. On the other hand, regional, obsolete, slang/argot and non-normative always come on their own. An example is the Polish synset {okularyn:1 ‘glasses’: general register, patrzałkin:1 , szkłan:1 ‘specs’: colloquial register, binoklen:2 ‘eyeglasses’: colloquial reg"
2018.gwc-1.24,C16-1213,1,0.878716,"Missing"
2018.gwc-1.24,P13-1133,1,0.827848,"on and supplements them with (parallel) corpus frequency and translatability. Three types of equivalence are distinguished, namely strong, regular and weak depending on the conformity with the proposed features. The presented solutions are languageneutral and they can be easily applied to language pairs other than Polish and English. Sense-level mapping is a more finegrained mapping than the existing synset mappings and is thus of great potential to human and machine translation. 1 Introduction Currently, bi- and multilingual wordnets are most commonly inter-linked on the synset level, (e.g., Bond and Foster, 2013). Synsets can be composed of one or more lexical units (lemma-PoS-synset triples, also called senses; henceforth, LUs), so such inter-wordnet links may be of three types: 1-to-1 sense link (between two synsets each built of a single LU); 1-to-many sense link (between two synsets, one built of a single LU, the other of more than one); and many-to-many sense link (between two multiple-LU synsets). The (large) majority of inter-linked wordnets use one simple equivalence relation to connect their synsets (effectively synonymy). If, due to substantial differences between languages, such a link cann"
2018.gwc-1.24,W99-0603,0,0.255854,"are already partially mapped on the synset level, and, eventually, to verbs after some mapping between verb synsets is accomplished. It may well be that additional features will need to be introduced while some of the ones proposed for nouns might be dismissed as irrelevant. The proposed strategy is designed for manual mapping, but we plan to develop an automatic system of prompts that will support lexicographers’ work. The new system will be an extension of an earlier system of automatic prompts for mapping of noun synsets and based on a modification of the Relaxation Labelling algorithm of Daudé et al. (1999) joined with lemma-pair checking and filtering by a large Polish-English cascade dictionary K˛edzia et al. (2013) and translation probabilities from bilingual corpora. As regards future avenues, this study may be continued in a number of possible ways. Firstly, the strategy of sense-level mapping described in this paper should be further tested on a structured and balanced sample of concrete and abstract nouns representing the whole variety of semantic domains (lexicographers’ files). We plan to extract the lists of Polish-English lexical unit pairs from the Polish-English pairs of synsets lin"
2018.gwc-1.24,C12-2101,1,0.838454,"treated as ‘given’. The interlingual relations that will be taken into consideration include I-synonymy, I-partial synonymy, Ihyponymy and I-hypernymy, all of which hold between the same part of speech synsets. Our focus will be the relations between nouns. The more interesting formal features are number and countability. For regular, countable nouns, agreement in these features is usually also given, because both in plWordNet and in Princeton WordNet lemmas appear in singular form. Still, some cases of ‘mixed’ Princeton WordNetsynsets were already tracked e.g. {dumplingn:1 , dumplingsn:1 } (Rudnicka et al., 2012, 2016). Such mixed synsets currently serve as inter-lingual hypernyms for both singular and plural Polish synsets e.g.{pierógn:2 , pierogn:1 } ‘dumpling’ or {pierogi ruskien:1 } ‘Russian dumplings’. Still, sense level mapping will allow to resolve such inconsistencies in the synset built-up. In regular cases, the agreement in number will always be observed in the mapping. A different case are pluralia and singularia tantum that have regular countable nouns as equivalents in another language such as, for instance, {drzwin:1 } ‘doorpl ’ I-syn {doorn:1 }, {grabien:1 } ‘rakepl ’ I-syn {raken:1 },"
2018.gwc-1.24,2016.gwc-1.49,1,0.769409,"one language there should not exist two different forms that share identical function and meaning, so there have to be slight differences between component LUs of a given synset, and even larger differences between the LUs from two synsets representing two different languages (even if those synsets are linked by I-synonymy). Existing research on interwordnet mapping between plWordNet (Maziarz et al., 2016) and Princeton WordNet (Fellbaum, 1998), especially 1-to-many and many-to many sense links, has shown the potential for creating stronger links between some LUs from a given pair of synsets (Rudnicka et al., 2016). To give an example, in the pair of synsets: {złoton:3 , Aun:1 }P L I-syn {goldn:3 , Aun:1 , atomic number 79n:1 }EN — złoton:3 P L and goldn:3 EN and Aun:1 P L and Aun:1 EN seem the best-fitted equivalents due to the agreement not only in sense, but also in register. The words from the first pair belong to the general register, while the ones from the second pair are from the specialist register. Biand multilingual wordnets are used by translators who would certainly appreciate such a more detailed mapping. 2 Background Equivalence is a popular concept used in, among others, translation stud"
2018.gwc-1.32,P16-1143,1,0.831395,"d embeddings among the top 10 word embeddings are measured based on the human-relevant judgment. • Rank Biased Overlap (RBO) - The rank correlation metrics that measures similarity and dissimilarity between two ranked list. 4.1 Baseline We have taken two baseline approaches. One based on the corpus frequency based approach and the other based on the Topic model distribution score (LexSemTm). Corpus frequencybased approach ranks the synset based on the frequency of occurrence of the lemma across the corpus whereas the LexSemTm used an unsupervised sense distribution learning method (LexSemTm) (Bennett et al., 2016), that utilizes HDP-WSI based sense learning (Lau et al., 2014). In Bennett et al. (2016), the sense distribution of words for each sense is obtained by estimating the maximum likelihood of terms with the topics. Both the baseline approaches used SemCor Dataset. Here the SemCor Dataset is separated into groups of lemmas with frequency 1-3(Group I), 4-8(Group II), 9-20(Group III) and greater than 21(Group IV) as described by Bennett et al. (2016). In each group, the sense distribution for each lemma is obtained from LexSemTm and the senses are ranked in descending order based on the sense distr"
2018.gwc-1.32,N15-1132,0,0.151619,"Missing"
2018.gwc-1.32,C12-3044,0,0.0334543,"Missing"
2018.gwc-1.32,elkateb-etal-2006-building,0,0.0598119,"rd2Vec (Mikolov et al., 2013; Rong, 2014) and Glove model (Pennington et al., 2014). Polyglot (Al-Rfou et al., 2013) is a natural language pipeline that supports many NLP based tasks such as tokenization, Language detection, Named Entity Recognition, Part of Speech Tagging, Sentiment Analysis, Word Embeddings, Morphological analysis and Transliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015;"
2018.gwc-1.32,isahara-etal-2008-development,1,0.642398,"ogical analysis and Transliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015; Raffaelli et al., 2008; Toral et al., 2010). We use corpus based frequencies for five of these languages (English, Chinese, Japanese, Italian and Indonesian) from the NTU Multilingual Corpus (NTU-MC: Tan and Bond, 2013) and use them to evaluate the learned sense rankings. Our major contribution is training and testin"
2018.gwc-1.32,W16-4905,0,0.0480968,"Missing"
2018.gwc-1.32,P14-1025,0,0.0614199,"Missing"
2018.gwc-1.32,P15-1145,0,0.0172046,"The experimentation on OMW sense ranking proves that the rank correlation is generally similar to the human ranking. Hence distributional semantics can aid in Wordnet Sense Ranking. 1 Introduction Most of the existing Word-net sense rankings (Navigli, 2009) use document level statistics to find the prominent sense of the given word. McCarthy and Carroll (2003) showed that predominate senses could be learned from a sufficiently large corpus, and this work has since been extended by various researchers. Words that appear nearest to the given word convey the context/meaning of a word (Lim, 2014; Liu et al., 2015; Pocostales, 2016; Rong, 2014; Long et al., 2016), and this can be used to estimate the most frequently used senses. This proposed work uses nearest context words to predict the senses and computes the frequency of occurrence of these senses within the corpus. Since most of the existing WSD systems utilize the Most Frequent Sense (MFS) as a baseline, it is important to rank the Wordnet senses in a meaningful way. Two well-known software packages used to train word embeddings, are Word2Vec (Mikolov et al., 2013; Rong, 2014) and Glove model (Pennington et al., 2014). Polyglot (Al-Rfou et al., 2"
2018.gwc-1.32,P16-2019,0,0.0171988,"that the rank correlation is generally similar to the human ranking. Hence distributional semantics can aid in Wordnet Sense Ranking. 1 Introduction Most of the existing Word-net sense rankings (Navigli, 2009) use document level statistics to find the prominent sense of the given word. McCarthy and Carroll (2003) showed that predominate senses could be learned from a sufficiently large corpus, and this work has since been extended by various researchers. Words that appear nearest to the given word convey the context/meaning of a word (Lim, 2014; Liu et al., 2015; Pocostales, 2016; Rong, 2014; Long et al., 2016), and this can be used to estimate the most frequently used senses. This proposed work uses nearest context words to predict the senses and computes the frequency of occurrence of these senses within the corpus. Since most of the existing WSD systems utilize the Most Frequent Sense (MFS) as a baseline, it is important to rank the Wordnet senses in a meaningful way. Two well-known software packages used to train word embeddings, are Word2Vec (Mikolov et al., 2013; Rong, 2014) and Glove model (Pennington et al., 2014). Polyglot (Al-Rfou et al., 2013) is a natural language pipeline that supports"
2018.gwc-1.32,J03-4004,0,0.120647,"languages. The results are evaluated for Semcor sense corpora for 5 languages using Word2Vec and Glove models. The Glove model achieves an average accuracy of 0.47 and Word2Vec achieves 0.31 for languages such as English, Italian, Indonesian, Chinese and Japanese. The experimentation on OMW sense ranking proves that the rank correlation is generally similar to the human ranking. Hence distributional semantics can aid in Wordnet Sense Ranking. 1 Introduction Most of the existing Word-net sense rankings (Navigli, 2009) use document level statistics to find the prominent sense of the given word. McCarthy and Carroll (2003) showed that predominate senses could be learned from a sufficiently large corpus, and this work has since been extended by various researchers. Words that appear nearest to the given word convey the context/meaning of a word (Lim, 2014; Liu et al., 2015; Pocostales, 2016; Rong, 2014; Long et al., 2016), and this can be used to estimate the most frequently used senses. This proposed work uses nearest context words to predict the senses and computes the frequency of occurrence of these senses within the corpus. Since most of the existing WSD systems utilize the Most Frequent Sense (MFS) as a ba"
2018.gwc-1.32,Y11-1027,1,0.800404,"Embeddings, Morphological analysis and Transliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015; Raffaelli et al., 2008; Toral et al., 2010). We use corpus based frequencies for five of these languages (English, Chinese, Japanese, Italian and Indonesian) from the NTU Multilingual Corpus (NTU-MC: Tan and Bond, 2013) and use them to evaluate the learned sense rankings. Our major contribution"
2018.gwc-1.32,C10-2097,0,0.0246823,"ansliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015; Raffaelli et al., 2008; Toral et al., 2010). We use corpus based frequencies for five of these languages (English, Chinese, Japanese, Italian and Indonesian) from the NTU Multilingual Corpus (NTU-MC: Tan and Bond, 2013) and use them to evaluate the learned sense rankings. Our major contribution is training and testing on large numbers of multi"
2018.gwc-1.32,P10-1023,0,0.0483075,"arch. Similar to this proposed work, (Bhingardive et al., 2015b) computes word embeddings with the help of pretrained Word2Vec(Mikolov et al., 2013; Rong, 2014) and matches with the sense embeddings obtained from the Wordnet features. They have attempted Wordnet sense ranking for Hindi and English. Since the Word2Vec (Mikolov et al., 2013; Rong, 2014) model is based on the words frequency of occurrence in the corpus, finding the nearest context words that occur infrequently in the corpus is difficult. Panchenko (2016) compares sense embeddings of AdaGram (Bartunov et al., 2015) with BabelNet (Navigli and Ponzetto, 2010) synsets and proved that sense embeddings can be retrieved by automatically learned sense vectors. Sense embeddings for a given target word are identified by finding the similarity between the AdaGram Word embeddings list with the BabelNet Synsets words list. Rothe and Schütze (2015) proposed an approach that takes word embeddings as input and produces synset, lexeme embeddings without retraining them. They used WordNet lexical resource to improve word embeddings. Arora et al. (2016) showed that word vectors can capture polysemy and word vectors can be thought of as linear superpositions of ea"
2018.gwc-1.32,L16-1421,0,0.0185359,"mbedding techniques have been popular in recent years in Word Sense Disambiguation (WSD) research. Similar to this proposed work, (Bhingardive et al., 2015b) computes word embeddings with the help of pretrained Word2Vec(Mikolov et al., 2013; Rong, 2014) and matches with the sense embeddings obtained from the Wordnet features. They have attempted Wordnet sense ranking for Hindi and English. Since the Word2Vec (Mikolov et al., 2013; Rong, 2014) model is based on the words frequency of occurrence in the corpus, finding the nearest context words that occur infrequently in the corpus is difficult. Panchenko (2016) compares sense embeddings of AdaGram (Bartunov et al., 2015) with BabelNet (Navigli and Ponzetto, 2010) synsets and proved that sense embeddings can be retrieved by automatically learned sense vectors. Sense embeddings for a given target word are identified by finding the similarity between the AdaGram Word embeddings list with the BabelNet Synsets words list. Rothe and Schütze (2015) proposed an approach that takes word embeddings as input and produces synset, lexeme embeddings without retraining them. They used WordNet lexical resource to improve word embeddings. Arora et al. (2016) showed"
2018.gwc-1.32,D14-1162,0,0.0816627,"Missing"
2018.gwc-1.32,S16-1202,0,0.020971,"n on OMW sense ranking proves that the rank correlation is generally similar to the human ranking. Hence distributional semantics can aid in Wordnet Sense Ranking. 1 Introduction Most of the existing Word-net sense rankings (Navigli, 2009) use document level statistics to find the prominent sense of the given word. McCarthy and Carroll (2003) showed that predominate senses could be learned from a sufficiently large corpus, and this work has since been extended by various researchers. Words that appear nearest to the given word convey the context/meaning of a word (Lim, 2014; Liu et al., 2015; Pocostales, 2016; Rong, 2014; Long et al., 2016), and this can be used to estimate the most frequently used senses. This proposed work uses nearest context words to predict the senses and computes the frequency of occurrence of these senses within the corpus. Since most of the existing WSD systems utilize the Most Frequent Sense (MFS) as a baseline, it is important to rank the Wordnet senses in a meaningful way. Two well-known software packages used to train word embeddings, are Word2Vec (Mikolov et al., 2013; Rong, 2014) and Glove model (Pennington et al., 2014). Polyglot (Al-Rfou et al., 2013) is a natural"
2018.gwc-1.32,P15-1173,0,0.0562595,"Missing"
2018.gwc-1.32,simov-osenova-2010-constructing,0,0.0146392,"gton et al., 2014). Polyglot (Al-Rfou et al., 2013) is a natural language pipeline that supports many NLP based tasks such as tokenization, Language detection, Named Entity Recognition, Part of Speech Tagging, Sentiment Analysis, Word Embeddings, Morphological analysis and Transliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015; Raffaelli et al., 2008; Toral et al., 2010). We use corpus based fr"
2018.gwc-1.32,stamou-etal-2004-exploring,0,0.0563547,", Named Entity Recognition, Part of Speech Tagging, Sentiment Analysis, Word Embeddings, Morphological analysis and Transliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015; Raffaelli et al., 2008; Toral et al., 2010). We use corpus based frequencies for five of these languages (English, Chinese, Japanese, Italian and Indonesian) from the NTU Multilingual Corpus (NTU-MC: Tan and Bond, 2013) a"
2018.gwc-1.32,W13-4302,1,0.843526,"line that supports many NLP based tasks such as tokenization, Language detection, Named Entity Recognition, Part of Speech Tagging, Sentiment Analysis, Word Embeddings, Morphological analysis and Transliteration for many languages. This work utilizes their Word embeddings. Existing polyglot word embeddings (Al-Rfou et al., 2013) support 137 languages. We have planned to use the word embeddings for the 35 handbuilt wordnets currently in OMW (Ruci, 2008; Elkateb et al., 2006; Borin et al., 2013; Pedersen et al., 2009; Simov and Osenova, 2010; Gonzalez-Agirre et al., 2012; Pociello et al., 2011; Wang and Bond, 2013; Huang et al., 2010; Pedersen et al., 2009; Fellbaum, 1998; Stamou et al., 2004; Sagot and Fišer, 2008; Ordan and Wintner, 2007; Mohamed Noor et al., 2011; Isahara et al., 2008; Montazery and Faili, 2010; Lindén and Carlson., 2010; Garabík and Pileckytė, 2013; Vossen and Postma, 2014; Piasecki et al., 2009; de Paiva et al., 2012; Tufiş et al., 2008; Darja et al., 2012; Borin et al., 2013; Thoongsup et al., 2009; Pianta et al., 2002; Oliver et al., 2015; Raffaelli et al., 2008; Toral et al., 2010). We use corpus based frequencies for five of these languages (English, Chinese, Japanese, Italian"
2018.gwc-1.35,P06-4018,0,\N,Missing
2018.gwc-1.46,P13-1133,1,0.86057,"Missing"
2018.gwc-1.46,D14-1112,0,0.0719158,"Missing"
2018.gwc-1.46,C12-3044,0,0.0253443,"Missing"
2018.gwc-1.46,W06-1108,0,0.214544,"Missing"
2018.gwc-1.46,W12-0210,0,0.0442681,"Missing"
2018.gwc-1.50,2016.gwc-1.9,1,0.930757,"only a single wordnet. An external layer contains synsets defined in project wordnets that do not fulfill the CILI inclusion criteria. One of the advantages of the GWG is that the resource is no longer limited to networks of single-word units, but is now open to phrasenets (frequent adjective-noun, nounprep-noun, and verb-object combinations, as well as proverbs, idioms, and compounds). This feature creates the possibility to link wordnets to domainspecific terminologies, which often include multiword expressions. The Open Multilingual Wordnet (OMW) is the reference instantiation of the GWG (Bond et al., 2016) adding the constraint that all member wordnets must be open according to the open definition.1 To date no specialized terminologies have been included in the OMW. Consequently, there is no established procedure for mapping technical concepts to the CILI nor for determining whether a technical concept ought to be indexed in the CILI. We report a preliminary biomedical wordnet based on the National Cancer Institute Thesaurus (NCIt) called the NCIt Derived Wordnet (ncitWN) and preliminary mappings to the CILI. By mapping the NCIt to the CILI and thereby integrating it into the OMW, we are develo"
2018.gwc-1.50,W06-1001,0,0.0499838,"athesaurus can be viewed as a domain specific analogue of the Open Multilingual Wordnet (OMW). The UMLS Metathesaurus also includes translations of some of its source vocabularies into languages other than English. It is available in two data formats, the Rich Release Format and the Original Release Format. Semantic types such as “Drug” have been added to the UMLS Metathesaurus to impose more structure and to organize concepts (National Library of Medicine, 2009). 2.4 Wordnet-Lexical Markup Framework Wordnet-Lexical Markup Framework is a wordnet-implementation of the Lexical Markup Framework (Francopoulo et al., 2006) (LMF), an ISO standard for NLP lexicons and Machine Readable Dictionaries based on the eXtensible Markup Language (XML) format. It encodes linguistic knowledge of the lexicalized concepts represented in the wordnets and supports integration of wordnets with OMW (Morgado da Costa and Bond, 2015; Vossen et al., 2013; Bond and Foster, 2013). Although no domain specific resources have been integrated into the CILI to date, this schema is well suited for the integration of an external resource such as the NCIt. Wordnet-LMF allows for a greater inventory of semantic relations than the NCIt currentl"
2018.gwc-1.50,P15-4013,1,0.899836,"Missing"
2018.gwc-1.50,C04-1054,0,0.0769116,"dical wordnet based on the National Cancer Institute Thesaurus (NCIt) called the NCIt Derived Wordnet (ncitWN) and preliminary mappings to the CILI. By mapping the NCIt to the CILI and thereby integrating it into the OMW, we are developing the first specialized vocabulary mapped to the CILI. The two outcomes will be: (i) the NCIt mapped to the CILI and integrated into OMW, but just as significantly (ii) groundwork for a method to reliably integrate open and freely available specialized terminologies with these lexical resources. This work is a first step toward realizing the goals outlined in Smith and Fellbaum (2004). 2 Resources 2.1 The Collaborative Interlingual Index The CILI is implemented as a collaborative opensource software based on the best-practices of the Semantic Web – persistent IDs, Creative Commons Attribution 4.0 (CC BY) license allowing redistribution, and versioning (Bond et al., 2016). It integrates and extends the list of concepts in the OMW, including all concepts in Princeton WordNet of English (PWN) (Fellbaum, 1998). Each concept in the CILI is described with a unique definition in English. Currently, most of these definitions are derived from PWN 3.0. The CILI is compatible with th"
2018.gwc-1.50,Y11-1038,1,0.671059,"n process is based on a few assumptions, to be tested further: (1) all concepts are lexicalized as nouns, and (2) the child-parent relationship in the thesaurus can be modeled as simple hypernymy. The UMLS Semantic Types could be modeled as external links or as links within the wordnet (as PWN does). Currently we add them as metadata on each synset (using dc:type). We validate the ncitWN data format with (1) the LMF Document Type Definition, which validates the XML representation of the Wordnet-LMF documents (Vossen et al., 2016) and (2) the OMW’s online tool (Morgado da Costa and Bond, 2015; Tan and Bond, 2011) that detects content violations such as duplicate or missing definitions. 3.2 Map ncitWN to the CILI We have tested the feasibility of mapping the ncitWN to the CILI using two approaches. The first, automatic, approach uses the prototype Wordnet-LMF formatted version of NCIt to automatically generate candidate mappings to the CILI using lemma overlap and compatibility of UMLS Semantic Types with WordNet coarse domains. The score is the sum of the Jaccard similarity calculated over lemma overlap with a boost of 0.1 each time there is a match between the wordnet coarse domains and the UMLS Sema"
2019.gwc-1.31,L16-1686,0,0.0607604,"Missing"
2019.gwc-1.31,D16-1041,0,0.0173731,"kipedia and this may require the project to adopt the more restrictive CCBY-SA license of Wikipedia. Moreover, it is not Figure 1: Screenshot of the new English WordNet interface clear how many of the entries have been reviewed by native speakers of English. Finally, a long term goal would be to introduce a principled method for introducing new synsets, which are of high quality and this would have to involve reviewing of all the links between synsets that have been introduced. It is expected that this could be achieved by a semi-automatic procedure where potential links are learnt from text (Espinosa-Anke et al., 2016) combined with a crowd-sourced reviews. Another important aspect of each synset is also its definition and as many of the definitions in WordNet are of poor quality (McCrae and Prangnawarat, 2016), it is necessary to adopt some general guidelines for writing definitions that can ensure high quality, such as those defined for ontological definitions (Sepp¨al¨a et al., 2017). Further, we will implement and further extend the validations that are available and automate the checking such that it is clear if any changes are breaking issues. In particular, we currently implement simple DTD validatio"
2019.gwc-1.31,francopoulo-etal-2006-lexical,0,0.0760954,"y of the minor errors into their own resources. 3 The Open English WordNet Project The Open English WordNet Project2 takes the form of a single Git repository, published on GitHub, and consisting for the most part of a collection of XML files describing the synsets and lexical entries in the resource. These XML files represent each of the lexicographer file sections of the original resource and a simple script is provided to stitch them together into a single XML file. The XML files are compliant with the GWC LMF model (McCrae et al., 2019)3 , which is itself based partially on the LMF model (Francopoulo et al., 2006) and in particular the WordNet (a.k.a 2 https://github.com/globalwordnet/ english-wordnet 3 https://globalwordnet.github.io/ schemas/ Kyoto) LMF variant (Soria et al., 2009). Due to its basis on LMF, a particular challenge was that the entire wordnet should be represented as a single XML document. However, due to the relative verbosity of the LMF format, the final data ended up as 97 MB, exceeding the upload limits of GitHub, so instead the single XML file was divided by lexicographer sections. Even still, this creates several very large files (over 10 MB) and this has resulted in some challen"
2019.gwc-1.31,E12-1059,0,0.150764,"Missing"
2019.gwc-1.31,N18-1014,0,0.0137142,"ordNet 2019, which has been developed by multiple people around the world through GitHub, fixes many errors in previous wordnets for English. We give some details of the changes that have been made in this version and give some perspectives about likely future changes that will be made as this project continues to evolve. 1 Introduction WordNet (Miller, 1995; Fellbaum, 1998) is one of the most widely-used language resources in natural language processing and continues to find usage in a wide variety of applications including sentiment analysis (Wang et al., 2018), natural language generation (Juraska et al., 2018) and textual entailment (Silva et al., 2018). However, in the recent few years there has been only one update since version 3.0 was released in 2006, in spite of its wide use and the interest in the data. In the meantime, a number of other wordnet teams working with the WordNet data have proposed modifications or extensions to its latest release. These two facts have provided the chief motivation for our present initiative, namely developing an opensource WordNet for English on the basis of Princeton WordNet (to be released under the name English WordNet 2019). In order to allow for meaningful"
2019.gwc-1.31,C16-1213,1,0.92792,"ton WordNet (Miller, 1995; Fellbaum, 2010) is the first wordnet for English, however it is not the only one that has been developed for this language. Moreover, it has been the case that during the development of several wordnets for other languages signficant changes and/or additions were made to the underlying structure and content of the English section of the wordnet. In at least one case, namely the development of the Polish wordnet, plWordNet, the additions to the underlying English wordnet have been so numerous that they were released as a new wordnet, enWordnet (Rudnicka et al., 2015; Maziarz et al., 2016). These involved the addition of new lemmas (over 11k), lexical units (over 11k) and synsets (7.5k). The latter were linked to WordNet 3.1 synsets via hyponymy relation. Still, no alterations to the original WordNet synsets or relations were made within this project. Currently, enWordnet is only available as part of the plWordNet project and does not constitute a ‘drop-in’ replacement for Princeton WordNet. Some projects have attempted to expand Princeton WordNet with new terminology in other directions, for example the Colloquial WordNet project (McCrae et al., 2017), has been working on addi"
2019.gwc-1.31,2018.gwc-1.8,1,0.739086,"r by providing a suitable modification, for example the example of ‘double negative’ was ‘I don’t never go’ and was updated to ‘double negative such as ‘I don’t never go” to include the lemma. 6 7 corrected to ‘certain’ https://www.sketchengine.eu/ • An issue was logged, as it was identified that this example shows a more signficant change. This was often the case when the example used a lemma or a hypernym and it was not clear if the distinction between synsets was meaningful. A third major change was to introduce new synset members based on a previously calculated WordNet-Wikipedia mapping (McCrae, 2018). In particular, if this mapping, which has already been manually verified, linked to a page title that did not match the lemma, the page title was added as a new lemma to the synset. This was, as with all changes, manually verified in its entirety before the change was made. Finally, the repository has been open to new suggestions of changes and there have been many suggestions already contributed about sporadic and various changes to the wordnet. A sample of these include: • The sense of ‘threepenny’ as a size was incorrect in the actual length in inches of a threepenny. • Grammatical errors"
2019.gwc-1.31,C12-3044,1,0.889346,"Missing"
2019.gwc-1.31,2018.gwc-1.40,1,0.702996,"ent and further extend the validations that are available and automate the checking such that it is clear if any changes are breaking issues. In particular, we currently implement simple DTD validation of the merged XML, which also catches many other issues, such as senses without synsets, but we are working to extend this validation to include issues, such as hypernyms without hyponyms, etc. In order to achieve this, it is important that strong tools are available for the creation and maintenance of the resource and it is likely that tools coming out of the ELEXIS project (Krek et al., 2018; Pedersen et al., 2018) will be adapted to this task. 6 Results for this release This release represents a mostly maintenance release where obvious errors have been fixed. In Table 2 we see that most of the updates are to the definitions and examples used to describe the synsets in English WordNet. There have also been a number of removals relative to the previous version of Princeton WordNet: mispelled lemmas were removed and replaced with a correctly spelled variant and these were counted as both a removal and addition of a lemma. Secondly, due to an issue11 two links were removed as they were deemed clearly incor"
2019.gwc-1.31,strapparava-valitutti-2004-wordnet,0,0.125518,"Missing"
2019.gwc-1.44,P13-1133,1,0.807617,"nets include: Princeton WordNet (henceforth, PWN) (Fellbaum, 1998), Polish WordNet (henceforth, plWN) (Maziarz et al., 2016), Wordnet Libre du Français (henceforth, WOLF), Multilingual Central Repository (henceforth, MCR) (GonzalezAgirre et al., 2012), Japanese Wordnet (henceforth, WNJA) (Bond et al., 2008), Wordnet Bahasa (WNB) (Bond et al., 2014), and Chinese Open Wordnet (henceforth, COW) (Wang and Bond, 2013). The wordnets are listed in Table 2 together with languages they represent, number of lemmas from wordnets and corpus coverage. They all appear in the Open Multilingual WordNet 1.09 (Bond and Foster, 2013) and are thus inter-linked via PWN. The numbers are given with the exclusion of multi-word lexical units and synsets not linked to Princeton WordNet and, hence, not linked to CILI. 3.2 Data sets: Corpora To test Zipf’s meaning-frequency law, we have inspected two types of text data sets: (i) general corpora for English, Spanish, French, Portuguese, Chinese, Japanese and Polish built at Centre for 9 http://compling.hss.ntu.edu.sg/omw/ wordnet COW+ WNJA MCR OpenWN-PT plWN+ PWN+ WNB WOLF lang. zh jp es pt pl en id fr #S [103 ] 8.1 158.1 57.8 74.0 288.4 218.6 95.3 102.7 #L [103 ] 3.2 92.0 36.7 54."
2019.gwc-1.44,bond-etal-2008-boot,1,0.381251,"real polysemy of a lemma. The choice of wordnets is motivated by their shared properties (e.g. similar relational description models, existence of synsets, glosses) which allow us to directly compare Zipfian curves for different languages. For the purposes of our study, we have chosen eight wordnets. The wordnets include: Princeton WordNet (henceforth, PWN) (Fellbaum, 1998), Polish WordNet (henceforth, plWN) (Maziarz et al., 2016), Wordnet Libre du Français (henceforth, WOLF), Multilingual Central Repository (henceforth, MCR) (GonzalezAgirre et al., 2012), Japanese Wordnet (henceforth, WNJA) (Bond et al., 2008), Wordnet Bahasa (WNB) (Bond et al., 2014), and Chinese Open Wordnet (henceforth, COW) (Wang and Bond, 2013). The wordnets are listed in Table 2 together with languages they represent, number of lemmas from wordnets and corpus coverage. They all appear in the Open Multilingual WordNet 1.09 (Bond and Foster, 2013) and are thus inter-linked via PWN. The numbers are given with the exclusion of multi-word lexical units and synsets not linked to Princeton WordNet and, hence, not linked to CILI. 3.2 Data sets: Corpora To test Zipf’s meaning-frequency law, we have inspected two types of text data set"
2019.gwc-1.44,gonzalez-agirre-etal-2012-multilingual,0,0.0809635,"Missing"
2019.gwc-1.44,C16-1213,1,0.905778,"Missing"
2019.gwc-1.44,W13-4302,1,0.838147,"ational description models, existence of synsets, glosses) which allow us to directly compare Zipfian curves for different languages. For the purposes of our study, we have chosen eight wordnets. The wordnets include: Princeton WordNet (henceforth, PWN) (Fellbaum, 1998), Polish WordNet (henceforth, plWN) (Maziarz et al., 2016), Wordnet Libre du Français (henceforth, WOLF), Multilingual Central Repository (henceforth, MCR) (GonzalezAgirre et al., 2012), Japanese Wordnet (henceforth, WNJA) (Bond et al., 2008), Wordnet Bahasa (WNB) (Bond et al., 2014), and Chinese Open Wordnet (henceforth, COW) (Wang and Bond, 2013). The wordnets are listed in Table 2 together with languages they represent, number of lemmas from wordnets and corpus coverage. They all appear in the Open Multilingual WordNet 1.09 (Bond and Foster, 2013) and are thus inter-linked via PWN. The numbers are given with the exclusion of multi-word lexical units and synsets not linked to Princeton WordNet and, hence, not linked to CILI. 3.2 Data sets: Corpora To test Zipf’s meaning-frequency law, we have inspected two types of text data sets: (i) general corpora for English, Spanish, French, Portuguese, Chinese, Japanese and Polish built at Centr"
2019.gwc-1.46,baccianella-etal-2010-sentiwordnet,0,0.601331,"nz♢ and Maciej Piasecki♢ ♠ Nanyang Technological University, Singapore ♢ Wrocław University of Science and Technology, Poland bond@ieee.org, {arkadius.janz|maciej.piasecki}@pwr.edu.pl Abstract In this paper, we compare a variety of sense-tagged sentiment resources, including SentiWordNet, ML-Senticon, plWordNet emo and the NTU Multilingual Corpus. The goal is to investigate the quality of the resources and see how well the sentiment polarity annotation maps across languages. 1 Introduction There are several semantic resources with senses annotated by sentiment polarity, e.g. SentiWordNet 3.0 (Baccianella et al., 2010) and even emotions, e.g. WordNet-Affect (Strapparava and Valitutti, 2004; Torii et al., 2011). However, most of them were built on the basis of automated expansion of a small subset of senses described manually. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZieliń"
2019.gwc-1.46,P13-1133,1,0.804304,"nd Bond, 2012) has a variety of texts and their translations, many of which are sense annotated.2 Two stories from the Sherlock Holmes Canon (The Adventure of the Speckled Band and The Adventure of the Dancing Men) have been both sense tagged with wordnet senses and annotated for sentiment (Bond et al., 2016a). Princeton Wordnet (Fellbaum, 1998) was used for English, the Chinese Open Wordnet for Chinese (Wang and Bond, 2013) and the Japanese wordnet for Japanese (Bond et al., 2009). These are linked through Princeton WordNet 3.0 (Fellbaum, 1998) with the help of the open multilingual wordnet (Bond and Foster, 2013). In addition, pronouns (Seah and Bond, 2014) and new concepts that were discovered in the corpus during the annotation have been added. A continuous scale was used for tagging sentiment, with scores from -100 to 100. The tagging tool splits these into seven values by default (-95, -64, -34, 0, 34, 64, 95), and there are keyboard shortcuts to select these values. Three values were chosen for each polarity, in order to be able to show the changes in chunks: quite good is less positive than good and this is less positive than very good. Annotators could select different, more fine-grained values"
2019.gwc-1.46,2016.gwc-1.9,1,0.842256,"ly. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZielińska et al., 2015); the annotation of two English short stories (The Adventure of the Speckled Band and The Adventure of the Dancing Men (Conan Doyle, 1892, 1905)) and their Chinese and Japanese translations (Bond et al., 2016a). As the stories have been annotated on the basis of senses, not words – i.e. all words were assigned Princeton WordNet synsets – this opens an unique possibility of cross-lingual comparison of manual sentiment annotation at the level of word senses. These are then compared with SentiWordNet and MLSentiCon and finally they are all compared to a small gold standard sample Micro-WNOp Corpus (Cerini et al., 2007). Our technical goal is to analyse the feasibility and technical means of correlation between independently created resources as the first step towards cross-lingual applications. Takin"
2019.gwc-1.46,W13-2319,1,0.807562,"nses. When we compare across languages, if a synset appears in the corpus multiple times, we add it to the comparison set as often as the least frequent language. Thus for example, if between Chinese and English, 02433000-a “showing the wearing effects of overwork or care or suffering” appeared three times in Chinese (as 憔悴 qiáo cuì) with an average score of -48.5 and twice in English with a score of −64 (as haggard and drawn), we would count this as two occurrences of −48.5 (in Chinese) and −64 (in English). In general, fewer than half of the concepts align directly across any two languages (Bond et al., 2013). Even though we have over 12,000 occurences concepts in English and more in Chinese and Japanese (Table 2) fewer than 7,000 appear in both (Table 4). Pair Chinese-English Chinese-Japanese English-Japanese ρ .73 .77 .76 # samples 6,843 4,099 4,163 Table 4: Correlation between the different language pairs For most concepts, the agreement across languages was high, although rarely identical. There was high agreement for the polarity but not necessarily in intensity/magnitude. For example, for the concept 02433000-a “haggard”, the English words drawn and haggard were given scores of −64, while Ch"
2019.gwc-1.46,esuli-sebastiani-2006-sentiwordnet,0,0.22212,"Missing"
2019.gwc-1.46,C16-1213,1,0.932383,"ted by sentiment polarity, e.g. SentiWordNet 3.0 (Baccianella et al., 2010) and even emotions, e.g. WordNet-Affect (Strapparava and Valitutti, 2004; Torii et al., 2011). However, most of them were built on the basis of automated expansion of a small subset of senses described manually. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZielińska et al., 2015); the annotation of two English short stories (The Adventure of the Speckled Band and The Adventure of the Dancing Men (Conan Doyle, 1892, 1905)) and their Chinese and Japanese translations (Bond et al., 2016a). As the stories have been annotated on the basis of senses, not words – i.e. all words were assigned Princeton WordNet synsets – this opens an unique possibility of cross-lingual comparison of manual sentiment annotation at the level of word senses. These are then compared with SentiWordNet and MLSentiCon and finally"
2019.gwc-1.46,P10-1114,0,0.0234995,"http://www.globalwordnet.org/ili/ixxx. 2.5 The Micro-WNOp Corpus We evaluated the Micro-WNOp Corpus (Cerini et al., 2007) as it is the only sense-tagged sentiment lexicon we could find.4 It was used to evaluate SentiWordNet and build ML-SentiCon, and consists of 1,105 Wordnet synsets chosen from the General Inquirer lexicon (Stone et al., 1966) and annotated by 1–3 annotators. There are many corpora tagged for sentiment, for example the Stanford Sentiment Treebank (Socher et al., 2013), but few multilingual (Balahur and Turchi, 2014) and no multilingual sentiment corpora for Asian languages. (Prettenhofer and Stein, 2010) contains English, French, German and Japanese product reviews, but they are comparable (reviews of the same product) or machine translated, not translated text, so while useful it is not suitable for studying close correspondences. 3 Comparisons We are going to compare four languages and two types of resources: a corpus and a lexicon from the perspective of sentiment polarity annotation. In order to make the comparison feasible, we focus on word senses – that can be represented by concepts – and their mappings across languages, as links between the different resources. There are both manually"
2019.gwc-1.46,D13-1170,0,0.00719287,"e over all the lemmas in all the languages. The concepts are identified with the Interlingual Index (Bond et al., 2016b).3 3 LOD: http://www.globalwordnet.org/ili/ixxx. 2.5 The Micro-WNOp Corpus We evaluated the Micro-WNOp Corpus (Cerini et al., 2007) as it is the only sense-tagged sentiment lexicon we could find.4 It was used to evaluate SentiWordNet and build ML-SentiCon, and consists of 1,105 Wordnet synsets chosen from the General Inquirer lexicon (Stone et al., 1966) and annotated by 1–3 annotators. There are many corpora tagged for sentiment, for example the Stanford Sentiment Treebank (Socher et al., 2013), but few multilingual (Balahur and Turchi, 2014) and no multilingual sentiment corpora for Asian languages. (Prettenhofer and Stein, 2010) contains English, French, German and Japanese product reviews, but they are comparable (reviews of the same product) or machine translated, not translated text, so while useful it is not suitable for studying close correspondences. 3 Comparisons We are going to compare four languages and two types of resources: a corpus and a lexicon from the perspective of sentiment polarity annotation. In order to make the comparison feasible, we focus on word senses – t"
2019.gwc-1.46,strapparava-valitutti-2004-wordnet,0,0.513871,"Missing"
2019.gwc-1.46,W11-1710,0,0.0210103,"nce and Technology, Poland bond@ieee.org, {arkadius.janz|maciej.piasecki}@pwr.edu.pl Abstract In this paper, we compare a variety of sense-tagged sentiment resources, including SentiWordNet, ML-Senticon, plWordNet emo and the NTU Multilingual Corpus. The goal is to investigate the quality of the resources and see how well the sentiment polarity annotation maps across languages. 1 Introduction There are several semantic resources with senses annotated by sentiment polarity, e.g. SentiWordNet 3.0 (Baccianella et al., 2010) and even emotions, e.g. WordNet-Affect (Strapparava and Valitutti, 2004; Torii et al., 2011). However, most of them were built on the basis of automated expansion of a small subset of senses described manually. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZielińska et al., 2015); the annotation of two English short stories (The Adventure of the Speckled"
2019.gwc-1.46,W13-4302,1,0.897056,"comparison we aim for is limited only to sentiment polarity, both emotions and fundamental values will be ignored in comparison. 2.4 NTU Multilingual Corpus The NTU Multilingual Corpus (Tan and Bond, 2012) has a variety of texts and their translations, many of which are sense annotated.2 Two stories from the Sherlock Holmes Canon (The Adventure of the Speckled Band and The Adventure of the Dancing Men) have been both sense tagged with wordnet senses and annotated for sentiment (Bond et al., 2016a). Princeton Wordnet (Fellbaum, 1998) was used for English, the Chinese Open Wordnet for Chinese (Wang and Bond, 2013) and the Japanese wordnet for Japanese (Bond et al., 2009). These are linked through Princeton WordNet 3.0 (Fellbaum, 1998) with the help of the open multilingual wordnet (Bond and Foster, 2013). In addition, pronouns (Seah and Bond, 2014) and new concepts that were discovered in the corpus during the annotation have been added. A continuous scale was used for tagging sentiment, with scores from -100 to 100. The tagging tool splits these into seven values by default (-95, -64, -34, 0, 34, 64, 95), and there are keyboard shortcuts to select these values. Three values were chosen for each polari"
2019.gwc-1.46,R15-1092,1,0.837705,"ation, basic emotions and fundamental human values. The latter two provide additional characteristics and help annotators to determine the sentiment polarity and its intensity expressed in the 5 grade scale: strong or weak vs negative and positive. Each annotator’s decision for polarised senses is supported by use examples – a sentence including the given sense and illustrating the postulated sentiment polarity and its strength. Concerning emotions, due to the compatibility with other wordnet-based annotations, the set of eight basic emotions recognised by Plutchik (Plutchik, 1980) were used (Zaśko-Zielińska et al., 2015). It contains Ekman’s six basic emotions (Ekman, 1992): joy , fear, surprise, sadness, disgust, anger, complemented by Plutchik’s trust and anticipation. As a result, negative emotions do not prevail in the set. One sense can be assigned more than one emotion and, as a result, complex emotions can be represented by using the same eightelement set, following the observations of Plutchik (1980). However, as the comparison we aim for is limited only to sentiment polarity, both emotions and fundamental values will be ignored in comparison. 2.4 NTU Multilingual Corpus The NTU Multilingual Corpus (T"
2019.gwc-1.49,P13-1133,1,0.858745,"Missing"
2019.gwc-1.49,buscaldi-rosso-2008-geo,0,0.22154,"pproach is to merge completely, into a vast combined resources such as YAGO (Suchanek et al., 2007) or BabelNet (Navigli and Ponzetto, 2012). This can cause problems 1 https://www.GeoNames.org/ Arthur Bond United World College of Southeast Asia artcbond@gmail.com when a subsidiary resource updates: propagating the corrections into the merged resource is an unsolved problem. For example, the version of GeoNames used in BabelNet 4.0 is from April 2015, a four year diﬀerence.2 Apart from general merging, there are two main resources made from merging Wordnet with GeoNames. The ﬁrst, Geo-Wordnet (Buscaldi and Rosso, 2008) links locations in Princeton Wordnet (PWN: Fellbaum, 1998) to GeoNames (we will call this GWN-link). The second, GeoWordnet (Giunchiglia et al., 2010) links the supertypes in GeoNames to PWN synsets (we will call this GWNsuper). These are complimentary mappings, but as far as we know, no one has combined them. GeoWordNetDomains (Frontini et al., 2016) further reﬁnes the mappings from GeoWordnet and adds some more internal structure. Both GeoWordnet and GeoWordNetDomains link the synsets to English and Italian (the Multiwordnet (Pianta et al., 2002) and Italwordnet (Toral et al., 2010) respect"
2020.lrec-1.389,2016.gwc-1.8,1,0.75415,"urulatih, pengasuh, guru    educator  art teacher, bahai catechist, coach, dancing-master, demonstrator, docent, … Figure 2: Simplified Wordnet Entry for teacher Lemmas that also appear in the TUFS vocabulary are shown in bold. Figure 3: TUFS Translation Set for Teacher shown in Table 3.4 4 New open wordnets have been released for Turkish, Burmese, Russian and German. We hope to include their results in a follow up study. 3.1 Mapping Process The mapping process was done through a naive algorithm inspired by multilingual sense intersection (Bond and Foster, 2013; Bond and Bonansinga, 2015; Bonansinga and Bond, 2016). The abstract idea behind multilingual sense intersection has a simple logical foundation: the semantic 3184 Language Arabic Arabic in Syria German English Spanish French Indonesian Japanese Central Khmer Korean Lao Mongolian Malay Burmese Por. in Brazil Portuguese Russian Thai Tagalog Turkish Urdu Vietnamese Mandarin Chinese Total ar as de en es fr id ja km ko lo mn ms my pb pt ru th tl tr ur vi zh Concepts 2,043 1,184 521 525 587 969 621 829 517 527 526 553 829 829 527 519 556 520 525 537 755 629 596 16,224 Words 2,928 1,053 1,221 1,255 1,207 2,076 899 1,945 465 1,011 492 497 829 829 1,238"
2020.lrec-1.389,P13-1133,1,0.864981,"ed into synsets linked by semantic relations, with examples and definitions for some languages. The links can be used to (i) evaluate existing wordnets, (ii) add data to these wordnets and (iii) create new open wordnets for Khmer, Korean, Lao, Mongolian, Russian, Tagalog, Urdu and Vietnamese. Keywords: basic vocabulary, wordnet, language teaching, multilingual lexicon 1 Introduction In this paper we describe linking two complementary linguistic resources — the TUFS Basic Vocabulary Modules, created for online language learning (Kawaguchi et al., 2007), with the Open Multilingual Wordnet (OMW: Bond and Foster, 2013). Multilingual lexicons are still quite rare, with most created by linking various bilingual lexicons. The TUFS Basic Vocabulary Modules are hand created, using commonly occurring vocabulary (designed for beginning language learners). It includes some languages with few online language resources, like Lao and Khmer. Because the lexicons are used by learners of single languages, the current interfaces do not allow easy access to them as a single multilingual resource. The first product of this paper is an easily accessible multilingual lexicon, based on the TUFS vocabulary, fully documented and"
2020.lrec-1.389,2016.gwc-1.9,1,0.787753,"fed back into the original data. (1) Mrs. McDonald is my English teacher. [en] (2) Ein Schüler fragt den Lehrer. [de] “A student asks the teacher a question.” (3) Akiko, Pak Yanto adalah dosen tata bahasa. [id] “Akiko, Mr Yanto is a grammar teacher.” 1.2 The Open Multilingual Wordnet The Open Multilingual Wordnet, version 1.2, is a collection of wordnets linked through the Princeton wordnet. We use the extended version produced at Nanyang Technological University that includes some extra vocabulary, including Japanese and Chinese lexicalized time expressions, pronouns, exclamations and more (Bond et al., 2016). The individual wordnets used are the Princeton Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013), the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond 2011 , Malay and Indonesian), the Wordnet Libre du Français (Fišer and Sagot, 2008, French), the Arabic Wordnet (AWN) (Elkateb et al., 2006), the Multilingual Central Repository (MSR) (Gonzalez-Agirre et al., 2012, Spanish), OpenWordNet-PT (de Paiva et al., 2012, Portuguese) and the Thai Wordnet (Thoongsup et al., 2009). Wordnets are organized into synsets linked to the PW"
2020.lrec-1.389,C12-3044,0,0.0433531,"Missing"
2020.lrec-1.389,elkateb-etal-2006-building,0,0.229902,"ed through the Princeton wordnet. We use the extended version produced at Nanyang Technological University that includes some extra vocabulary, including Japanese and Chinese lexicalized time expressions, pronouns, exclamations and more (Bond et al., 2016). The individual wordnets used are the Princeton Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013), the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond 2011 , Malay and Indonesian), the Wordnet Libre du Français (Fišer and Sagot, 2008, French), the Arabic Wordnet (AWN) (Elkateb et al., 2006), the Multilingual Central Repository (MSR) (Gonzalez-Agirre et al., 2012, Spanish), OpenWordNet-PT (de Paiva et al., 2012, Portuguese) and the Thai Wordnet (Thoongsup et al., 2009). Wordnets are organized into synsets linked to the PWN entries. Each wordnet may have one or more lemmas, definitions and examples. There are also semantic links to other synsets. We give a simplified example of the entry for one sense of teacher in Figure 2: note that the hypernyms and hyponyms link to other synsets. We omit languages in OMW but not TUFS (31 wordnets had translations for teacher). We also do not s"
2020.lrec-1.389,Y11-1027,1,0.837961,"Missing"
2020.lrec-1.389,W13-4302,1,0.801067,", Pak Yanto adalah dosen tata bahasa. [id] “Akiko, Mr Yanto is a grammar teacher.” 1.2 The Open Multilingual Wordnet The Open Multilingual Wordnet, version 1.2, is a collection of wordnets linked through the Princeton wordnet. We use the extended version produced at Nanyang Technological University that includes some extra vocabulary, including Japanese and Chinese lexicalized time expressions, pronouns, exclamations and more (Bond et al., 2016). The individual wordnets used are the Princeton Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013), the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond 2011 , Malay and Indonesian), the Wordnet Libre du Français (Fišer and Sagot, 2008, French), the Arabic Wordnet (AWN) (Elkateb et al., 2006), the Multilingual Central Repository (MSR) (Gonzalez-Agirre et al., 2012, Spanish), OpenWordNet-PT (de Paiva et al., 2012, Portuguese) and the Thai Wordnet (Thoongsup et al., 2009). Wordnets are organized into synsets linked to the PWN entries. Each wordnet may have one or more lemmas, definitions and examples. There are also semantic links to other synsets. We give a simplified example of the entry fo"
2020.lrec-1.389,isahara-etal-2008-development,1,0.673723,"A student asks the teacher a question.” (3) Akiko, Pak Yanto adalah dosen tata bahasa. [id] “Akiko, Mr Yanto is a grammar teacher.” 1.2 The Open Multilingual Wordnet The Open Multilingual Wordnet, version 1.2, is a collection of wordnets linked through the Princeton wordnet. We use the extended version produced at Nanyang Technological University that includes some extra vocabulary, including Japanese and Chinese lexicalized time expressions, pronouns, exclamations and more (Bond et al., 2016). The individual wordnets used are the Princeton Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013), the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond 2011 , Malay and Indonesian), the Wordnet Libre du Français (Fišer and Sagot, 2008, French), the Arabic Wordnet (AWN) (Elkateb et al., 2006), the Multilingual Central Repository (MSR) (Gonzalez-Agirre et al., 2012, Spanish), OpenWordNet-PT (de Paiva et al., 2012, Portuguese) and the Thai Wordnet (Thoongsup et al., 2009). Wordnets are organized into synsets linked to the PWN entries. Each wordnet may have one or more lemmas, definitions and examples. There are also semantic links to other synse"
2020.lrec-1.390,P13-1133,1,0.892147,"Abstract In this paper we discuss the experience of bringing together over 40 different wordnets. We introduce some extensions to the GWA wordnet LMF format proposed in Vossen et al. (2016) and look at how this new information can be displayed. Notable extensions include: confidence, corpus frequency, orthographic variants, lexicalized and non-lexicalized synsets and lemmas, new parts of speech, and more. Many of these extensions already exist in multiple wordnets – the challenge was to find a compatible representation. To this end, we introduce a new version of the Open Multilingual Wordnet (Bond and Foster, 2013), that integrates a new set of tools that tests the extensions introduced by this new format, while also ensuring the integrity of the Collaborative Interlingual Index (CILI: Bond et al., 2016), avoiding the same new concept to be introduced through multiple projects. Keywords: multilingual lexicon, wordnet, collaborative development 1. Introduction This paper provides a summary and update of some of the issues involved with coordinating multiple lexical wordnets. The Princeton WordNet (PWN) is one of the most cited lexical resources in the world with over 1.8 as many citations as the most cit"
2020.lrec-1.390,2016.gwc-1.9,1,0.935642,"k at how this new information can be displayed. Notable extensions include: confidence, corpus frequency, orthographic variants, lexicalized and non-lexicalized synsets and lemmas, new parts of speech, and more. Many of these extensions already exist in multiple wordnets – the challenge was to find a compatible representation. To this end, we introduce a new version of the Open Multilingual Wordnet (Bond and Foster, 2013), that integrates a new set of tools that tests the extensions introduced by this new format, while also ensuring the integrity of the Collaborative Interlingual Index (CILI: Bond et al., 2016), avoiding the same new concept to be introduced through multiple projects. Keywords: multilingual lexicon, wordnet, collaborative development 1. Introduction This paper provides a summary and update of some of the issues involved with coordinating multiple lexical wordnets. The Princeton WordNet (PWN) is one of the most cited lexical resources in the world with over 1.8 as many citations as the most cited paper in the ACL anthology1 (Marcus et al. (2004) according to Joseph and Radev (2007)). This success has inspired wordnets in many languages, and many attempts to link them, such as EuroWor"
2020.lrec-1.390,2019.gwc-1.50,1,0.722496,"lems, then the projects will have the option to upload it onto the OMW system, which will make it immediately available on its online interface. This automated validation effort, though sometimes challenging to set up, has been a great way to catch problems that would otherwise most certainly be overlooked in our previous system. 2.3. Graph Checks When we attempted to use the OMW for sense disambiguation, it turned out that it had cycles. This led us to check the individual wordnets, and we found that some wordnets (including PWN 3.0!) had ill-formed graph structures such as loops and cycles (Lohk et al., 2019). These are not caught by the XML structure, but make the wordnet graph impossible to manage, so we added checks for these, and pro3191 Figure 2: Screenshot of Stage 3 of the Validation Report vided feedback to all wordnets for which we found errors. These checks are now done after upload as part of the validation, and must be passed for the wordnet to be accepted into OMW 2.0. We check for three things. The first is loops: does a synset in the new wordnet link to itself (using any semantic relation). The second is cycles in the hypernym graph of the new wordnet: if we claim A is-a B, B is-a C"
2020.lrec-1.390,W14-0116,0,0.0223601,"lexicalized=false in English. If a sense has lexicalized=true then it has been validated in some standard lexicon for the language. If it has lexicalized=false, then it is believed to be compositional and only added as an aid to multilingual users (similar to phrase in multiwordnet). For example harimau anak “young tiger” in the Indonesian synset for tiger cub is lexicalized=false, or dedos pedas “foot finger-andtoe” in the synset for toe in Spanish. These allow the lexicographers to put in useful translation equivalents while acknowledging that they are not necessarily part of the language. Vincze and Almázi (2014) discuss other synsets that may not be lexicalized in Hungarian, such as place names or culturally specific concepts. 4. Duplicate Sense Detection One difficult challenge with integrating many wordnets of different languages is that they may define identical concepts and as such this would lead to duplicates in the CILI index. As such, we have introduced a system for duplicate sense detection based on the Naisc system introduced by McCrae and Buitelaar (2018). This system is intended for dataset linking and is being specialized for sense linking in the ELEXIS project (Krek et al., 2018). In th"
2020.lrec-1.390,W99-0512,0,0.404156,"that most existing wordnets are built by translating the PWN: the extend model (Vossen, 1998). For example, dogn:1 is linked to the lemmas chien in French, anjing in Malay, and so on. The overall structure of PWN serves as a useful scaffold and the fact that, for example, a dogn:1 is an animaln:1 is language independent. The main innovations of the OMW 1.0 were an emphasis on open licenses (so that all the data could be legally shared) and a simple shared format (so that resources could be easily converted). The second version of the OMW (2.0) revived the idea of the InterLingual Index (ILI: Vossen et al., 1999) with the Collaborative Interlingual Index (CILI: Bond et al., 2016). In this vision, there is a shared set of concepts, which the wordnets agree to link to. In the Collaborative ILI, new wordnet projects can propose candidate ILI concepts, instantiated by synsets in the wordnet for that language. In this paper, we introduce other information added to the Open-Multilingual Wordnet and the motivation for it. The structure of the paper is as follows: in § 2 we talk about challenges in the process of integrating the wordnets; in § 3 we look at how the wordnet format has been extended; in § 4 we l"
2020.lrec-1.46,W19-4406,0,0.057227,"pare and attest the impact of the latest available technology. Some recent efforts in organizing shared-tasks within these topics include: the 2011 Helping Our Own (Dale and Kilgarriff, 2011, HOO) shared-task on GEC; the more focused 2012 HOO shared-task on Preposition and Determiner Error Correction (Dale et al., 2012); the 2013 and 2014 CoNLL shared-tasks on English GEC (Ng et al., 2013; Ng et al., 2014); the 2016 shared-task on Automated Evaluation of Scientific Writing, focusing on error detection (Daudaravicius et al., 2016, AESW); and, most recently, the 2019 shared-task on English GEC (Bryant et al., 2019). Most of these tasks aim to test the ability to perform generalized GEC, and often include a large variety of common errors attested by learner corpora. While we agree that these efforts are of utmost importance for the field, this paper is best aligned with the spirit of the shared-task on AESW – where the focus is on the detection of issues (i.e. not strictly errors), and the goal is to assist authors in writing better academic papers. As Daudaravicius (2015) rightfully describes, the task of assisting academic writing includes monitoring language quality in dimensions that go well beyond g"
2020.lrec-1.46,copestake-flickinger-2000-open,0,0.782072,"r of English should reject (1) as a proper sentence. However, the decision of how to correct this sentence is not simple. Without context, at least four corrections (2 to 5) should be considered – but other options could also be considered. From a pedagogical point of view, each of these corrections should elicit different kinds of corrective feedback. (2) These systems correct the error. (3) These systems correct errors. (4) This system corrects the error. This system corrects errors. English Resource Grammar The system presented in this paper uses, at its core, the English Resource Grammar (Copestake and Flickinger, 2000; Flickinger, 2000, ERG) as the main parser. The ERG is a symbolic grammar with a very large lexicon and wide coverage of syntactic phenomena. It has, in fact, been used by a different team in the 2016 AESW task (Flickinger et al., 2016). The team that used the ERG ranked second in the probabilistic estimation track, and fourth in the boolean decision track. Of special interest for our system is the fact that this grammar has had substantial work to allow it to parse and identify both ungrammatical and stylistically deprecated sentences (Bender et al., 2004; Flickinger and Yu, 2013; Suppes et"
2020.lrec-1.46,W13-1703,0,0.086658,"g, Applied Linguistics and, perhaps not surprisingly, also to GED and GEC. The types of errors language learners make, as well as the frequency with which each error occur, are implicitly encoded in the labeling process – which is the necessary training data over which statistical GED and GEC systems learn. Even though our system did not require statistical learning over labeled data, its development was profoundly inspired by previous work done on English Learner Corpora. Deserving notable mention are the NTU Corpus of Learner English (Winder et al., 2017), the NUS Corpus of Learner English (Dahlmeier et al., 2013) and the Cambridge Learner Corpus (Nicholls, 2003). The process of selecting which checks to include in our system was a combination of firsthand experience of our tutors, data driven analysis based on the Learner Corpora mentioned above, and ease of implementation given the available tools. Fortunately, as mentioned above, the ERG alSystem Architecture The system is fully developed on top of existing open-source platforms. At its core, it is a web system developed using Python and Flask, fully open-source, and scalable. 5.1. Submission Submission to the system is done online, using any modern"
2020.lrec-1.46,W11-2838,0,0.192772,"performance has shown measurable improvements in the quality of student assignments. Keywords: technology-enhanced learning, blended learning, immediate feedback, grammar engineering, tertiary teaching 1. Introduction Automated Grammar Error Detection (GED) and Correction (GEC) are tasks that have attracted some attention within the NLP community. This is especially true for English, where a myriad of shared-tasks periodically compare and attest the impact of the latest available technology. Some recent efforts in organizing shared-tasks within these topics include: the 2011 Helping Our Own (Dale and Kilgarriff, 2011, HOO) shared-task on GEC; the more focused 2012 HOO shared-task on Preposition and Determiner Error Correction (Dale et al., 2012); the 2013 and 2014 CoNLL shared-tasks on English GEC (Ng et al., 2013; Ng et al., 2014); the 2016 shared-task on Automated Evaluation of Scientific Writing, focusing on error detection (Daudaravicius et al., 2016, AESW); and, most recently, the 2019 shared-task on English GEC (Bryant et al., 2019). Most of these tasks aim to test the ability to perform generalized GEC, and often include a large variety of common errors attested by learner corpora. While we agree t"
2020.lrec-1.46,W12-2006,0,0.128418,"ning, immediate feedback, grammar engineering, tertiary teaching 1. Introduction Automated Grammar Error Detection (GED) and Correction (GEC) are tasks that have attracted some attention within the NLP community. This is especially true for English, where a myriad of shared-tasks periodically compare and attest the impact of the latest available technology. Some recent efforts in organizing shared-tasks within these topics include: the 2011 Helping Our Own (Dale and Kilgarriff, 2011, HOO) shared-task on GEC; the more focused 2012 HOO shared-task on Preposition and Determiner Error Correction (Dale et al., 2012); the 2013 and 2014 CoNLL shared-tasks on English GEC (Ng et al., 2013; Ng et al., 2014); the 2016 shared-task on Automated Evaluation of Scientific Writing, focusing on error detection (Daudaravicius et al., 2016, AESW); and, most recently, the 2019 shared-task on English GEC (Bryant et al., 2019). Most of these tasks aim to test the ability to perform generalized GEC, and often include a large variety of common errors attested by learner corpora. While we agree that these efforts are of utmost importance for the field, this paper is best aligned with the spirit of the shared-task on AESW – w"
2020.lrec-1.46,W16-0506,0,0.456995,"munity. This is especially true for English, where a myriad of shared-tasks periodically compare and attest the impact of the latest available technology. Some recent efforts in organizing shared-tasks within these topics include: the 2011 Helping Our Own (Dale and Kilgarriff, 2011, HOO) shared-task on GEC; the more focused 2012 HOO shared-task on Preposition and Determiner Error Correction (Dale et al., 2012); the 2013 and 2014 CoNLL shared-tasks on English GEC (Ng et al., 2013; Ng et al., 2014); the 2016 shared-task on Automated Evaluation of Scientific Writing, focusing on error detection (Daudaravicius et al., 2016, AESW); and, most recently, the 2019 shared-task on English GEC (Bryant et al., 2019). Most of these tasks aim to test the ability to perform generalized GEC, and often include a large variety of common errors attested by learner corpora. While we agree that these efforts are of utmost importance for the field, this paper is best aligned with the spirit of the shared-task on AESW – where the focus is on the detection of issues (i.e. not strictly errors), and the goal is to assist authors in writing better academic papers. As Daudaravicius (2015) rightfully describes, the task of assisting aca"
2020.lrec-1.46,W13-3609,0,0.807097,"mar (Copestake and Flickinger, 2000; Flickinger, 2000, ERG) as the main parser. The ERG is a symbolic grammar with a very large lexicon and wide coverage of syntactic phenomena. It has, in fact, been used by a different team in the 2016 AESW task (Flickinger et al., 2016). The team that used the ERG ranked second in the probabilistic estimation track, and fourth in the boolean decision track. Of special interest for our system is the fact that this grammar has had substantial work to allow it to parse and identify both ungrammatical and stylistically deprecated sentences (Bender et al., 2004; Flickinger and Yu, 2013; Suppes et al., 2014). This is made available through a variety of methods, including mal-rules and the ability to define parsing strictness using root conditions of the tree (e.g. disable parsing of sentence fragments). In addition, the ERG provides a deep linguistic representation for each sentence (with detailed syntactic and semantic information), as opposed to a shallower representation such as an ngram language model. The information contained in this representation, such as verbal 370 mood, can be very useful for designing extra-grammatical checks. 3. 5. Motivation The motivation behin"
2020.lrec-1.46,W16-4914,1,0.409444,"Missing"
2020.lrec-1.46,W13-3601,0,0.0156495,"duction Automated Grammar Error Detection (GED) and Correction (GEC) are tasks that have attracted some attention within the NLP community. This is especially true for English, where a myriad of shared-tasks periodically compare and attest the impact of the latest available technology. Some recent efforts in organizing shared-tasks within these topics include: the 2011 Helping Our Own (Dale and Kilgarriff, 2011, HOO) shared-task on GEC; the more focused 2012 HOO shared-task on Preposition and Determiner Error Correction (Dale et al., 2012); the 2013 and 2014 CoNLL shared-tasks on English GEC (Ng et al., 2013; Ng et al., 2014); the 2016 shared-task on Automated Evaluation of Scientific Writing, focusing on error detection (Daudaravicius et al., 2016, AESW); and, most recently, the 2019 shared-task on English GEC (Bryant et al., 2019). Most of these tasks aim to test the ability to perform generalized GEC, and often include a large variety of common errors attested by learner corpora. While we agree that these efforts are of utmost importance for the field, this paper is best aligned with the spirit of the shared-task on AESW – where the focus is on the detection of issues (i.e. not strictly errors"
2020.lrec-1.46,W14-1701,0,0.0731383,"Grammar Error Detection (GED) and Correction (GEC) are tasks that have attracted some attention within the NLP community. This is especially true for English, where a myriad of shared-tasks periodically compare and attest the impact of the latest available technology. Some recent efforts in organizing shared-tasks within these topics include: the 2011 Helping Our Own (Dale and Kilgarriff, 2011, HOO) shared-task on GEC; the more focused 2012 HOO shared-task on Preposition and Determiner Error Correction (Dale et al., 2012); the 2013 and 2014 CoNLL shared-tasks on English GEC (Ng et al., 2013; Ng et al., 2014); the 2016 shared-task on Automated Evaluation of Scientific Writing, focusing on error detection (Daudaravicius et al., 2016, AESW); and, most recently, the 2019 shared-task on English GEC (Bryant et al., 2019). Most of these tasks aim to test the ability to perform generalized GEC, and often include a large variety of common errors attested by learner corpora. While we agree that these efforts are of utmost importance for the field, this paper is best aligned with the spirit of the shared-task on AESW – where the focus is on the detection of issues (i.e. not strictly errors), and the goal is"
2020.lrec-1.46,P98-2196,0,0.887006,"al Parsers Using symbolic parsers, such as computational grammars, for GED or GEC has both advantages and disadvantages. The main disadvantage is, most definitely, coverage. Symbolic parsers take a long time to develop before being able to compete against statistical parses on coverage. When coverage is not an issue, however, symbolic parsers are often able to provide much higher quality and richer structure to language. Our system takes advantage of this benefit to perform error detection and select feedback based on a concept known as mal-rules. The concept of mal-rule was first proposed by Schneider and McCoy (1998). These rules are used to extend descriptive grammars in order to allow specific ungrammatical phenomena, while reconstructing structures that were violated. Although the design of mal-rules is time consuming, they can enable fine-tuned error distinctions that statistical parsers would have a hard time dealing with. Consider example (1), below: (1) * These system corrrect error. (5) While dealing this ambiguity might seem daunting for some statistical systems, a few mal-rules would allow this sentence to be parsed while reconstructing all of the meanings shown above. This would require: a mal-"
2020.lrec-1.46,W17-5901,1,0.390258,"research, including Second Language Teaching and Learning, Applied Linguistics and, perhaps not surprisingly, also to GED and GEC. The types of errors language learners make, as well as the frequency with which each error occur, are implicitly encoded in the labeling process – which is the necessary training data over which statistical GED and GEC systems learn. Even though our system did not require statistical learning over labeled data, its development was profoundly inspired by previous work done on English Learner Corpora. Deserving notable mention are the NTU Corpus of Learner English (Winder et al., 2017), the NUS Corpus of Learner English (Dahlmeier et al., 2013) and the Cambridge Learner Corpus (Nicholls, 2003). The process of selecting which checks to include in our system was a combination of firsthand experience of our tutors, data driven analysis based on the Learner Corpora mentioned above, and ease of implementation given the available tools. Fortunately, as mentioned above, the ERG alSystem Architecture The system is fully developed on top of existing open-source platforms. At its core, it is a web system developed using Python and Flask, fully open-source, and scalable. 5.1. Submissi"
2020.mmw-1.3,W14-4724,1,0.709436,"satellite adjectives should be marked as similar to a head adjective; this is called the ‘dumbbell’ model. The distinction is made at the part-of-speech level in the resource, although no other part-of-speech catalogue or dictionary to our knowledge makes the distinction this way.9 This means that there is often fewer links to other synsets and also shorter definitions; in fact adjectives typically have 1.44 synset links against a general average of 2.43. The plan for a future version, is to revamp the adjective so that they follow a more conventional classification such as that proposed by (McCrae et al., 2014), where the formal categories are: Open Multilingual WordNet Intersective These refer to properties that the adjective indicates the presence of. The most significant group of these are pertainyms, which mean that a concept is of or pertaining to a noun, e.g., “French” pertaining to “France”. The existing pertainym relation marks many of these but can be expanded. The Open Multilingual WordNet (Bond and Paik, 2012; Bond and Foster, 2013) project has also introduced new synsets and made changes related to the English WordNet. We are in the process of integrating these changes, one of the most m"
2020.mmw-1.3,2019.gwc-1.31,1,0.589223,"second release of this resource entitled “English WordNet 2020”. The work has focused firstly, on the introduction of new synsets and senses and developing guidelines for this and secondly, on the integration of contributions from other projects. We present the changes in this edition, which total over 15,000 changes over the previous release. Keywords: WordNet, lexicons, open source, lexicography, NLP 1. Introduction improving the procedure for development of the resource, in particular with the format and the issue of ensuring backwards compatibility with Princeton WordNet. English WordNet (McCrae et al., 2019) is a fork of Princeton WordNet (Fellbaum, 2010; Miller, 1995), which aims to further the development of a wordnet for English. Wordnets are one of the most widely used resources in natural language processing1 and as the English language is not static, it is necessary to continually update the resource so that it remains relevant for these tasks. Wordnets group words into sets of synonyms, called synsets, and each sense of a word corresponds to its membership in one synset. These synsets are then organized in a graph containing relationships such as hypernym/hyponym (broader or narrower), ant"
2020.mmw-1.3,2018.gwc-1.8,1,0.793344,"y not an encyclopedia. For this reason, it should not contain long lists of people, places, organizations, etc. Proper nouns are generally not expected to be included in the resource and many kinds of common nouns for narrow domains or geographical usage should not be included, examples of this would include elements of different cuisines around the world. As a rule of thumb, if there is a Wikipedia page for this concept it should not be in English WordNet.4 For future releases a more complete alignment of the resource and Wikipedia is planned based on previous works(De Melo and Weikum, 2009; McCrae, 2018) to address the introduction of synsets already welldescribed in Wikipedia. New Synset A synset covering a new concept is being proposed; Synset Duplicate Two synsets are not possible to distinguish or refer to the same concept. This is fixed by either creating a new concept for all synsets or by deleting all but one of the duplicates; Synset Split A synset refers to two distinct concepts and should be split into two new synsets; Synset Member A word in a synset should be added or removed; Enhancement A request for an improvement in the tooling around English WordNet or for a new kind of data;"
2020.mmw-1.3,2018.gwc-1.17,1,0.830348,"Missing"
2020.mmw-1.3,C12-3044,1,0.903984,"Missing"
2020.mmw-1.3,W04-2807,0,0.127532,"for this concept that is distinct from other concepts in English WordNet. A good definition consists of a genus and a differentia. Genus The type of the thing, often the hypernym, Differentia Something that makes this word unique An example of a good definition is: a piece of furniture having a smooth flat top that is usually supported by one or more vertical legs Where a poor definition would be: a piece of furniture used for eating 2.2.7. Sense distinctions One particular issue that has been common in the reported set of issues is the issue of sense distinction. WordNet has been criticized (Palmer et al., 2004; Snow et al., 2007) for a long time for issues related to its sense granularity. As such, there have been many issues claiming that synsets are duplicated as the meanings are quite hard to distinguish. In order to simplify these decisions, we have developed a few key principles that help us in distinguishing senses.6 In addition an example should be provided with a link to a website where the example is used as follows: &lt;Synset id=&quot;ewn-...&quot;&gt; ... &lt;Example dc:source= &quot;https://en.wikipedia.org/wiki/Example.com&quot;&gt; The example domains have one subdomain name defined in the Domain Name System &lt;/Exam"
2020.mmw-1.3,D07-1107,0,0.102197,"Missing"
2020.mmw-1.3,2018.gwc-1.18,0,0.0367778,"Missing"
2020.mmw-1.3,2016.gwc-1.9,1,0.838125,"ded into a number of source files that correspond to the original lexicographer files in WordNet, but are now in XML. New synsets proposed from issues should be assigned to one of these lexicographer files as they are created. For contributed resources (see below), we merged them into the original resource according to the hypernym. Sense keys were a mechanism that provided stability between releases of WordNet, and sense keys were (mostly) stable identifiers between different versions of Princeton WordNet. Instead, English WordNet has adopted the CILI interlingual index (Vossen et al., 2016; Bond et al., 2016) as the principal method of providing cross-version stability. Moreover, for new senses the calculation of stable sense identifiers is complicated as the Princeton WordNet formula relied on information in lexicographer files that is no longer present. Initial proposals were just to jettison sense keys, however community feedback has encouraged the creation of new methodology for assigning sense keys.5 In addition, we now also track the changes of sense keys, caused for example changes in the spelling of a lemma or if a sense has been moved across lexicographer files. 2.2.4. Well-defined It sho"
2020.mmw-1.3,2018.gwc-1.14,0,0.056166,"Missing"
2020.mmw-1.3,W15-0904,0,0.0218255,"the term should not be derivable from its components, e.g., “French Army” could be tagged with the synsets for “French” and “Army”; in contrast “operational system” refers not to a system that is operational, but it is a computer science term for the system that runs on every computer. Another case of MWE is the conventionalized ones. Conventionalization refers to the situation where a sequence of words that refer to a particular concept is commonly accepted in such a way that its constituents cannot easily be substituted for near-synonyms, because of some cultural or historical conventions (Farahmand et al., 2015). Consider the expression “geologic fault”. It is compositional but no one would consider substituting it with “geologic defect”. There are many types of MWE and a extensive literature about them (Sag et al., 2002), here we just want to emphasize that expressions that could have their parts annotated with senses already in the resource don’t need to be explicitly added. For single words, the word should not be derived in a systematic manner, these include: Contribution Issues related to large external contributions (see Section 3.); Bug A technical flaw that needs to be addressed in the data f"
2021.gwc-1.11,2019.gwc-1.49,1,0.758591,"s requirement is partially just to satisfy XML validators, but can also serve as a check on the dependent lexicon’s assumptions about the structure of the primary wordnet. lishing IDs for linking, these elements allow for augmenting the elements themselves, such as for adding senses to an existing lexical entry or relations to a synset. However, these elements do not allow one to change information in the provider wordnet, so lemmas on lexical entries, ILIs on synsets, and other required information may not be speciﬁed on the corresponding external elements. For example, the Geonames Wordnet (Bond and Bond, 2019) provides additional synset relations on top of the PWN as well as an extended lexical hierarchy of location names in the PWN and many other wordnets. The extension would specify that it extends the PWN as follows: &lt;LexiconExtension id=&quot;geonames-pwn&quot; version=&quot;1.0&quot;&gt; &lt;Extends id=&quot;pwn&quot; version=&quot;3.0&quot;/&gt; &lt;/LexiconExtension&gt; In some cases it might make sense to use both the Extends and Requires elements. For instance, if we want to extend the Japanese Wordnet with its entries from the Geonames Wordnet and reuse the relations from the English Geonames extension, we could specify the relationships as f"
2021.gwc-1.11,P13-1133,1,0.913743,"me perspectives on how these changes help in the integration of wordnets. 1 Introduction The introduction of the Global WordNet Grid (Vossen et al., 2016) and the Collaborative Interlingual Index (Bond et al., 2016) presented a need for greater compatibility between individual wordnet projects through a common format for the representation of wordnets. As such the Global WordNet Association introduced a format with several serialization methods1 that have been used by several projects, including the new open English WordNet (EWN; McCrae et al., 2020, 2019), the Open Multilingual Wordnet (OMW; Bond and Foster, 2013) and the Wn Python library (Goodman and Bond, 2021). Along with the increased adoption came the perception of shortcomings in the format as it was initially deﬁned, such as the inability to capture all of the information present in Princeton WordNet (PWN; Miller, 1995; Fellbaum, 2012) or to capture some key information that other projects wished to use in their modelling. It was therefore deemed necessary to extend the model and, for this reason, we have introduced a new extended version (v1.1) of the format that covers some of these use cases. 1 https://globalwordnet.github.io/schemas In this"
2021.gwc-1.11,bond-etal-2008-boot,1,0.549775,"htforward to use a wordnet in isolation of the full OMW, e.g., for experimental purposes. This issue is even more pronounced for wordnets that are not included in the OMW. What we need, then, is a way for a wordnet to specify what other resources are required, much as how software projects specify their dependencies. We therefore introduce a new Requires element which selects the id and version attributes of an external lexicon that should be loaded along with the current lexicon for it to behave as expected. For example, the following speciﬁes that the Japanese Wordnet (Isahara et al., 2008; Bond et al., 2008) depends on the PWN for its synset relations: &lt;Lexicon id=&quot;wnja&quot; id=&quot;2.0&quot;&gt; &lt;Requires id=&quot;pwn&quot; version=&quot;3.0&quot;/&gt; &lt;/Lexicon&gt; The purpose is to declare what, exactly, is required so that an application that hosts the wordnets can signal to the user if dependencies are unmet, or to limit the wordnets that may be used when traversing external synset relations. It is left implicit which elements or kinds of elements from the external wordnet become available to the dependent wordnet but, following the OMW’s behaviour, an application may choose to only allow synset relations and not, say, synsets or le"
2021.gwc-1.11,2016.gwc-1.9,1,0.776872,"t can be integrated through the Global WordNet Grid. As a result of their adoption, a number of shortcomings of the format were identiﬁed, and in this paper we describe the extensions to the formats that address these issues. These include: ordering of senses, dependencies between wordnets, pronunciation, syntactic modelling, relations, sense keys, metadata and RDF support. Furthermore, we provide some perspectives on how these changes help in the integration of wordnets. 1 Introduction The introduction of the Global WordNet Grid (Vossen et al., 2016) and the Collaborative Interlingual Index (Bond et al., 2016) presented a need for greater compatibility between individual wordnet projects through a common format for the representation of wordnets. As such the Global WordNet Association introduced a format with several serialization methods1 that have been used by several projects, including the new open English WordNet (EWN; McCrae et al., 2020, 2019), the Open Multilingual Wordnet (OMW; Bond and Foster, 2013) and the Wn Python library (Goodman and Bond, 2021). Along with the increased adoption came the perception of shortcomings in the format as it was initially deﬁned, such as the inability to cap"
2021.gwc-1.11,2020.mmw-1.7,0,0.0268947,"mes-pwn&quot; version=&quot;1.0&quot;&gt; &lt;Extends id=&quot;pwn&quot; version=&quot;3.0&quot;/&gt; &lt;/LexiconExtension&gt; In some cases it might make sense to use both the Extends and Requires elements. For instance, if we want to extend the Japanese Wordnet with its entries from the Geonames Wordnet and reuse the relations from the English Geonames extension, we could specify the relationships as follows: &lt;LexiconExtension id=&quot;geonames-wnja&quot; version=&quot;1.0&quot;&gt; &lt;Extends id=&quot;wnja&quot; version=&quot;2.0&quot;/&gt; &lt;Requires id=&quot;geonames-pwn&quot; version=&quot;1.0&quot;/&gt; &lt;/LexiconExtension&gt; 3.3 Pronunciation One of the extensions that has been requested by other projects (Declerck et al., 2020) is the ability to represent phonetic information giving the pronunciation of lemmas in a schema such as the International Phonetic Alphabet. As well as giving the IPA text, it was also desired that we should be able to provide information about the speciﬁc variety, as well as further notes about the form of the pronunciation. In addition, we want to indicate whether the transcription is phonemic or phonetic, that is whether it includes expected features of the language such as aspiration. For ‘variety’, we decided to support the use of IETF language tags to indicate dialect, for example encod"
2021.gwc-1.11,francopoulo-etal-2006-lexical,0,0.416051,"inly inspired by plWordNet (Piasecki et al., 2009). Finally, there were some technical issues to do with the modelling of syntactic behaviours, and while the current formats could capture the information, they did so in a way that was quite verbose and lead to bloated ﬁles. In addition, we ﬁxed a few minor issues related to the representation of lexicographer ﬁles, sense keys and metadata. 2 Background The Global WordNet Association’s formats are a common data model with three(-plus) serializations in XML, JSON and various RDF formats.2 The XML format is based on the Lexical Markup Framework (Francopoulo et al., 2006) and in particular on the version developed in the Kyoto project (Soria and Monachini, 2008). This represents the wordnet as a LexicalResource with a number of Lexicons, one for each language, along with multiple metadata elements about the lexicon, including identiﬁers, version, language, license, contact email, 2 Any RDF serialization is valid, but for this paper we consider the Turtle form of RDF. citation, etc. The format splits the data into two distinct elements, the LexicalEntry, which contains the syntactic information about the usage of individual words, and the Synset, which provides"
2021.gwc-1.11,2021.gwc-1.12,1,0.667854,"ntegration of wordnets. 1 Introduction The introduction of the Global WordNet Grid (Vossen et al., 2016) and the Collaborative Interlingual Index (Bond et al., 2016) presented a need for greater compatibility between individual wordnet projects through a common format for the representation of wordnets. As such the Global WordNet Association introduced a format with several serialization methods1 that have been used by several projects, including the new open English WordNet (EWN; McCrae et al., 2020, 2019), the Open Multilingual Wordnet (OMW; Bond and Foster, 2013) and the Wn Python library (Goodman and Bond, 2021). Along with the increased adoption came the perception of shortcomings in the format as it was initially deﬁned, such as the inability to capture all of the information present in Princeton WordNet (PWN; Miller, 1995; Fellbaum, 2012) or to capture some key information that other projects wished to use in their modelling. It was therefore deemed necessary to extend the model and, for this reason, we have introduced a new extended version (v1.1) of the format that covers some of these use cases. 1 https://globalwordnet.github.io/schemas In this paper, we describe the model as a reference for us"
2021.gwc-1.11,isahara-etal-2008-development,1,0.669223,"ired, it is not straightforward to use a wordnet in isolation of the full OMW, e.g., for experimental purposes. This issue is even more pronounced for wordnets that are not included in the OMW. What we need, then, is a way for a wordnet to specify what other resources are required, much as how software projects specify their dependencies. We therefore introduce a new Requires element which selects the id and version attributes of an external lexicon that should be loaded along with the current lexicon for it to behave as expected. For example, the following speciﬁes that the Japanese Wordnet (Isahara et al., 2008; Bond et al., 2008) depends on the PWN for its synset relations: &lt;Lexicon id=&quot;wnja&quot; id=&quot;2.0&quot;&gt; &lt;Requires id=&quot;pwn&quot; version=&quot;3.0&quot;/&gt; &lt;/Lexicon&gt; The purpose is to declare what, exactly, is required so that an application that hosts the wordnets can signal to the user if dependencies are unmet, or to limit the wordnets that may be used when traversing external synset relations. It is left implicit which elements or kinds of elements from the external wordnet become available to the dependent wordnet but, following the OMW’s behaviour, an application may choose to only allow synset relations and not"
2021.gwc-1.11,2019.gwc-1.31,1,0.83942,"Missing"
2021.gwc-1.11,2020.mmw-1.3,1,0.730115,"sense keys, metadata and RDF support. Furthermore, we provide some perspectives on how these changes help in the integration of wordnets. 1 Introduction The introduction of the Global WordNet Grid (Vossen et al., 2016) and the Collaborative Interlingual Index (Bond et al., 2016) presented a need for greater compatibility between individual wordnet projects through a common format for the representation of wordnets. As such the Global WordNet Association introduced a format with several serialization methods1 that have been used by several projects, including the new open English WordNet (EWN; McCrae et al., 2020, 2019), the Open Multilingual Wordnet (OMW; Bond and Foster, 2013) and the Wn Python library (Goodman and Bond, 2021). Along with the increased adoption came the perception of shortcomings in the format as it was initially deﬁned, such as the inability to capture all of the information present in Princeton WordNet (PWN; Miller, 1995; Fellbaum, 2012) or to capture some key information that other projects wished to use in their modelling. It was therefore deemed necessary to extend the model and, for this reason, we have introduced a new extended version (v1.1) of the format that covers some of"
2021.gwc-1.11,C12-3044,1,0.81435,"Missing"
2021.gwc-1.11,van-assem-etal-2006-conversion,0,0.130729,"Missing"
2021.gwc-1.12,2020.lrec-1.390,1,0.707415,"rom a local WN-LMF file using the wn.add() function: 4 &gt;&gt;&gt; wn.add(&apos;wnja.xml &apos;) Added wnja :2.0 ( Japanese Wordnet ) Usage In this section we give a brief tour of Wn’s programming interface. 4.1 Loading Wordnets Wn was created for wordnets following the WNLMF schema (Vossen et al., 2013; Bond et al., 2020) as this format requires synsets to declare their association with a CILI ID, if any. Older formats, such as WNDB,8 are not directly supported, but conversion tools exist.9 The Wn project keeps an index of publicly available and open wordnets in the WN-LMF format, such as the English WordNet (McCrae et al., 2020) and OdeNet, the Open German WordNet (Siegel &gt;&gt;&gt; wn. download ( url_of_odenet ) Download complete (2001396 bytes) Added odenet :1.3 ( Offenes Deutsches WordNet ) Wn is robust to small errors in the wordnet file (like different parts of speech in the synset and word or a confidence less than 0 or greater than 1) but will generally warn the user when they occur. The wn.lexicons() function lists all installed lexicons. The objects returned by this function can be inspected to find the name, version, language, license, contact email, and other kinds of metadata of a lexicon: &gt;&gt;&gt; for l in wn. lexic"
2021.gwc-1.12,2018.gwc-1.47,0,0.0374057,"rd formats and methods for interoperability, namely the WNLMF schema (Vossen et al., 2013; Bond et al., 2020) and the Collaborative Interlingual Index (Bond et al., 2016). Wn is open-source, easily available,1 and well-documented.2 1 Introduction Wordnet is a popular tool for natural language processing, and there are interfaces in many programming languages. For Python alone, there are 99 packages that mention wordnet in the Python Package Index.3 Many of them provide an interface to a single language, like Romanian (Dumitrascu et al., 2019), or multiple languages from the same project, like Panjwani et al. (2018) for the Indian languages. Of course, there are many interfaces for English, of which the Natural Language Tool Kit’s implementation is very widely used (Bird et al., 2009). The NLTK has a very well documented and clear interface to the Princeton WordNet (PWN; Fellbaum, 1998), with several distance metrics also implemented. The interface makes some design decisions that simplify wordnet structure, such as treating the word ↔ sense ↔ synset triad as a lemma ↔ synset dyad. The Wn library introduced by this paper differs from the existing Python packages in several ways. 1 https://pypi.org/projec"
2021.gwc-1.22,P15-4002,1,0.897012,"Missing"
2021.gwc-1.22,P13-1133,1,0.647091,"Missing"
2021.gwc-1.22,2016.gwc-1.9,1,0.808274,"listed in http://pcai056.informatik. uni-leipzig.de/downloads/etc/legacy/ Papers/top1000de.txt ysis of German nominal compounds and used this information for the addition of hypernym relations. 3.1 Linking OpenThesaurus Synsets with the Multilingual Wordnet The OpenThesaurus data can be downloaded as txt. The text file contains one synset per line, such that the lexical items in each synset are divided by semicolons, e.g.: Mobilit¨ at;Unabh¨ angigkeit;Beweglichkeit The target of the transfer process of this synset is to have three lexical entries and a synset entry. The format is described in Bond et al. (2016). We start with the synset: <Synset id=""de-9784-n"" ili=""i62097"" partOfSpeech=""n"" dc:description=""the quality of moving freely""&gt; <SynsetRelation targets=’odenet-23172-n’ relType=’hypernym’/&gt; </Synset&gt; The synset has a unique synset ID, a link to the international wordnet IDs in “ili”, a POS, a definition, and relations to other synsets. The first task is to find POS information. POS information is not included in the OpenThesaurus download data. We use the Python library TextBlob for POS annotation.4 OdeNet just uses “n”, “v” and “a” as POS tags, such that we map the Penn Treebank POS tags that"
2021.gwc-1.22,2021.gwc-1.12,1,0.922074,"an language is also in this context. To save development time, existing resources were combined and recompiled. The result was then evaluated and improved. In a relatively short time a resource was created that can be used in projects and continuously improved and extended. 1 Introduction The goal of this initiative is to have a German resource in a multilingual wordnet initiative, where the concepts ( synsets) of the languages are linked, and where the resources are under an open-source license, being included in the NLTK language processing package ((Bird et al., 2009)) via the Wn package ((Goodman and Bond, 2021)). Wordnet resources are largely used in NLP projects all over the world. Our idea is to create a German resource that starts from a crowddeveloped thesaurus; is open; and included in the NLTK package. Then it can be further developed by researchers while using the resource for their NLP projects. For the first version, we combined existing resources: The OpenThesaurus German synonym lexicon,1 the Open Multilingual Wordnet2 (OMW: Bond and Foster, 2013) the English resource, the Princeton WordNet of English (PWN: Fellbaum, 1 2 https://www.openthesaurus.de/ http://compling.hss.ntu.edu.sg/omw/ Fr"
2021.gwc-1.22,W97-0802,0,0.329213,"Missing"
2021.gwc-1.32,2019.gwc-1.46,1,0.732687,"students (discussed in the next section). Some published research that relied on student contributions include: work on Japanese derivational relations (Bond and Wei, 2019); on pronoun representation for Japanese, Mandarin and English (Seah and Bond, 2014); as well as work on exclamatives and classifiers (Mok et al., 2012; Morgado da Costa and Bond, 2016). Other important contributions that came either in the form of theses or research reports include extensive work cleaning up and expanding the Wordnet Bahasa. The resources have been used by students for sentiment analysis (Le et al., 2016; Bond et al., 2019), cross-lingual sense annotation (Bonansinga and Bond, 2016), multilingual crosswords (Tan, 2012) and more. 4 Quality Control and Expert Tagging Given that the annotation that happens in our classrooms is done by untrained students from diverse backgrounds and often lacking linguistic intuition, it is not surprising that our corpus needs to go through multiple layers of quality control before being suitable for release. The large majority of this quality control is done by student RAs. This usually happens in phases, and each phase (or RA) focuses on a particular task. These different tasks in"
2021.gwc-1.32,2016.gwc-1.9,1,0.825223,"e feel that the wordnets needs to go through several more iterations of tagging and fixing before all the commonly appearing issues are fixed, and of course annotation in new domains will bring new families of problems. One non-trivial problem is coordinating our improvements with others: we are available on GitHub. (i) Preprocess (ii) Tag (independent) (v) Re-Tag (expert) (iii) Tag (adjudicate) (iv) Fix (Corpus & Wordnet) Figure 2: Sense Annotation Spiral doing our best to coordinate with the English Wordnet (McCrae et al., 2019) and linking through the Collaborative Interlingual Index (CILI Bond et al., 2016b). However, this integration is not seamless. There are still many questions left unsolved. We still have many lexical semantic phenomena not covered: auxiliary verbs, conjunctions and prepositions; light verb+noun combinations; decomposable semantics (e.g. unADJ is productively the antonym of ADJ); multiple interpretations, …These are often taken up by students as final year projects or research projects in other classes. 5 Conclusion and Future Work We need more annotated text: linking text to analysis is an important task. We expect linking to lead to changes in the linked resource: it is"
2021.gwc-1.32,ho-etal-2014-identifying,1,0.847988,"Missing"
2021.gwc-1.32,isahara-etal-2008-development,1,0.722453,"Missing"
2021.gwc-1.32,W04-2710,0,0.257996,"in context with sentiment (from -100 to +100). Figure 1 shows a passage that has been tagged. The text is shown on the left. Words with positive and negative sentiment are shown with red and green underlines respectively. The annotator thinks that there is no suitable sense for the word being tagged (hell-hound) so has suggested a new entry in the comments. Existing senses for hell-hound are shown on the right. The students only tag a small sample, so they tag as a sequential task: annotating chunks of text word-by-word. Targeted tagging (annotating by word type) is known to be more accurate (Langone et al., 2004). Our tool, IMI, supports both and the RAs typically use targeted tagging when they add new senses or correct common errors. 2.4 Wordnets The senses are tagged with enhanced versions of the Princeton WordNet of English (PWN: Fellbaum, 1998), the Chinese Open Wordnet (COW: Wang Figure 1: The Sequential Tagging Interface and Bond, 2013), the Wordnet Bahasa (Bond et al., 2014) and the Japanese wordnet (Isahara et al., 2008). They included systematic extensions for pronouns, chengyu,2 exclamatives and classifiers (Seah and Bond, 2014; Ho et al., 2014; Morgado da Costa and Bond, 2016) extended with"
2021.gwc-1.32,W16-5415,0,0.0146751,"gging done by our students (discussed in the next section). Some published research that relied on student contributions include: work on Japanese derivational relations (Bond and Wei, 2019); on pronoun representation for Japanese, Mandarin and English (Seah and Bond, 2014); as well as work on exclamatives and classifiers (Mok et al., 2012; Morgado da Costa and Bond, 2016). Other important contributions that came either in the form of theses or research reports include extensive work cleaning up and expanding the Wordnet Bahasa. The resources have been used by students for sentiment analysis (Le et al., 2016; Bond et al., 2019), cross-lingual sense annotation (Bonansinga and Bond, 2016), multilingual crosswords (Tan, 2012) and more. 4 Quality Control and Expert Tagging Given that the annotation that happens in our classrooms is done by untrained students from diverse backgrounds and often lacking linguistic intuition, it is not surprising that our corpus needs to go through multiple layers of quality control before being suitable for release. The large majority of this quality control is done by student RAs. This usually happens in phases, and each phase (or RA) focuses on a particular task. Thes"
2021.gwc-1.32,2019.gwc-1.31,1,0.679885,"re developing the wordnet, corpus and tools) the process becomes gradually better. We feel that the wordnets needs to go through several more iterations of tagging and fixing before all the commonly appearing issues are fixed, and of course annotation in new domains will bring new families of problems. One non-trivial problem is coordinating our improvements with others: we are available on GitHub. (i) Preprocess (ii) Tag (independent) (v) Re-Tag (expert) (iii) Tag (adjudicate) (iv) Fix (Corpus & Wordnet) Figure 2: Sense Annotation Spiral doing our best to coordinate with the English Wordnet (McCrae et al., 2019) and linking through the Collaborative Interlingual Index (CILI Bond et al., 2016b). However, this integration is not seamless. There are still many questions left unsolved. We still have many lexical semantic phenomena not covered: auxiliary verbs, conjunctions and prepositions; light verb+noun combinations; decomposable semantics (e.g. unADJ is productively the antonym of ADJ); multiple interpretations, …These are often taken up by students as final year projects or research projects in other classes. 5 Conclusion and Future Work We need more annotated text: linking text to analysis is an im"
2021.gwc-1.32,P15-4013,1,0.873685,"Missing"
2021.gwc-1.32,W13-4302,1,0.870301,"Missing"
2021.gwc-1.34,W02-0805,0,0.188034,"53). The lexicographic process of splitting and clustering senses was widely studied in the context of Word Sense Disambiguation (e.g. Passonneau et al. (2010)). We relate to several research studies which are most relevant to our approach. Resnik and Yarowsky (1999) proposed a method of measuring sense distances on Hector – a hierarchical dictionary (Atkins, 1992, cf. Tab. 3). They postulated that the penalty applied to a homonymous pair should be much higher than the cost of a polysemy step. In some aspects our methodology resembles this approach to the construction of an adjacency matrix.3 Chugur et al. (2002) counterargued against the possibility of an honest measure based on hierarchical dictionaries. The argument is as follows: since in metaphorical shifts extended senses completely change their semantic domain, dictionary provided sense relations do not mirror mental lexicon sense proximities. To this plea we answer that polysemy topologies are often multicentred (Brugman and Lakoff, 2006) and are governed by their own rules (naming = knowing, see (Malt et al., 1999)). Véronis (1998) executed experiments in the assessment of the number of word senses obtained from a tagged corpus which was col"
2021.gwc-1.34,W04-0807,0,0.363349,"Missing"
2021.gwc-1.34,passonneau-etal-2010-word,0,0.0401141,"specialised vocabulary), differences in syntactic frames (cf. transitive - intransitive frame) or other grammatical properties, like grammatical number (cf. pluralia and singularia tantum) (Svensén, 2009; Jackson, 2002). Yet another way to tame lexicographers’ intuitions is to rely on taxonomic and other sense relationships, in such a way genus proximum (a hypernym) and differentia specifica (a meronym/holonym, antonym etc.) might be captured (Stock, 2008, p. 153). The lexicographic process of splitting and clustering senses was widely studied in the context of Word Sense Disambiguation (e.g. Passonneau et al. (2010)). We relate to several research studies which are most relevant to our approach. Resnik and Yarowsky (1999) proposed a method of measuring sense distances on Hector – a hierarchical dictionary (Atkins, 1992, cf. Tab. 3). They postulated that the penalty applied to a homonymous pair should be much higher than the cost of a polysemy step. In some aspects our methodology resembles this approach to the construction of an adjacency matrix.3 Chugur et al. (2002) counterargued against the possibility of an honest measure based on hierarchical dictionaries. The argument is as follows: since in metaph"
2021.gwc-1.34,W06-2503,0,0.0512401,"he same part of speech, share the same lemma, but are not related semantically and etymologically (Svensén, 2009, pp. 96-7). A pair of polysemous senses (polysemes) – on the contrary – is constituted by the two senses of the same POS category, sharing the same lemma, semantically related and of the same etymology. homonyms is the diachronic process of word shortening due to their frequent use (Fenk-Oczlon and Fenk, 2008, p. 59). Though homonyms are frequent in text and speech, they remain a tough nut to crack for Natural Language Processing (Hauer and Kondrak, 2020; Klimenkov and Pokid, 2019; McCarthy, 2006; Mihalcea, 2003). One of the reasons is that wordnets lack any explicit links between the related meanings of the same word and do not discern between the two types of lexical ambiguity (Freihat et al., 2013). The goals of this paper are two-fold: (i) we check the degree of agreement between polysemy descriptions in two general English dictionaries, namely Oxford Lexico and American English Merriam-Webster Dictionary, and in WordNet, (ii) we test the applicability of WordNet in measuring semantic similarity between senses (that is assessing polysemy vs. homonymy distinctions). For these purpo"
2021.gwc-1.5,P13-1133,1,0.760181,"ry expands on an existing list of Japanese offensive words and provides categorization and proper linking to synsets within the multilingual wordnet. This paper then discusses the evaluation of the vocabulary as a resource for representing and classifying offensive words and as a possible resource for offensive word use detection in social media. Content Warning: this paper deals with obscene words and contains many examples of them. 1 Introduction The aim of this paper is to create a sense-based lexicon of offensive and potentially inappropriate terms linked to the Open Multilingual Wordnet (Bond and Foster, 2013). As well as adding new terms, we will categorize existing terms. The categorization is designed to be useful for both human and machine users. We distinguish between offensive terms, where the word itself has a negative connotation, and inappropriate terms, which may fine in some contexts, but not in others. Real-life communication and socializing are rapidly being replaced by their online counterparts due to the overwhelming popularity and exponential growth of the use of social media platforms. Social media platforms allow people to express their opinions and feelings on various topics, inc"
2021.gwc-1.5,C18-1248,0,0.0622122,"Missing"
2021.gwc-1.5,2021.gwc-1.12,1,0.719593,"oswearing.com/ which gave another 38 vulgar synsets. We end up with a total of 912 synsets marked in some way, with many being marked with multiple tags. The breakdown per tag is given in Table 3. These categorizations will be made available as a stand-alone file at https://github.com/ bond-lab/taboown, along with links to the original J-Lex categories. In addition, we will share them with the English Wordnet Project (McCrae et al., 2020). We will also release scripts to use the Open Multilingual Wordnet to generate offensive word lists for any language in the OMW using the Wn Python Library (Goodman and Bond, 2021). 8 We also added some new words to this domain as part of a separate project by our annotators to improve the coverage of LGBTQ+ terms. Lexicon Wordnik # Words 1,282 Wordnet Original Wordnet Offensive Wordnet Extended 50 1,512 2,095 HurtLex Conservative HurtLex Inclusive 2,228 5,965 Comment 645 synsets 912 synsets Lexicon Wordnet Original Wordnet Offensive Wordnet Extended HurtLex Conservative HurtLex Inclusive in Wordnik 18 82 163 singular 18 86 172 98 139 95 137 Table 5: Comparison with Wordnik Table 4: Offensive Word Lists 5 Evaluation We used a curated list to test the coverage of our enh"
2021.gwc-1.5,isahara-etal-2008-development,1,0.66683,"enuinely inappropriate. For example 巨乳 kyonyu “huge breasts” is generally used positively but would be inappropriate in a work place. 短足 tansoku “short-legs” is generally insulting, but does not absolutely have to be. Words like ブヨブヨ (buyobuyo) meaning soft and flabby is generally offensive while 同和地区 (dowa chiku) meaning “untouchable area, slums” is always offensive. We made a new Japanese extension of wordnet, that adds the new lexical entries from J-Lex to the appropriate synsets. It will be made available at https://github.com/bond-lab/taboown and shared with the Japanese Wordnet Project (Isahara et al., 2008). 4.2 Re-Labeling Wordnet We decided to mark words in two different ways. First, we use the general domain category link to link words into topic domains, that are not necessarily taboo, but may be of interest to research into taboo terms. Existing topic domains include things like ⟨law⟩, ⟨music⟩ or ⟨terrorism⟩. To these we will add: ⟨sexual activity⟩, ⟨excrement⟩ and ⟨LGBTQ+⟩ (a new synset). At least in English and Japanese, these domains are potentially inappropriate without being necessarily offensive. In general, anything marked in J-Lex with sex* will be put into the ⟨sexual activity⟩ top"
2021.gwc-1.5,S19-2010,0,0.0172476,"tionally, online lexicons can be updated and edited at any time while being easily shared across the world. This paper presents the development of a lexicon of Japanese inappropriate words that will be added to the Open Multilingual Wordnet (OMW) with links to existing synsets and the creation of new synsets to define new inappropriate words. These words in the OMW can then be used as an online lexical resource to build awareness while analyzing and identifying inappropriate words in a multilingual context. 2 Background While there is much relevant work on the detection of offensive language (Zampieri et al., 2019, 2020) 1 lexicons of abusive words receive little attention in literature, especially for lexicons in languages other than English. Lexicons of abusive words are often manually compiled and processed specifically for a task and are not reusable in other contexts or tasks and are rarely updated once the task it was created for has been completed. One exception is Hurtlex (Bassignana et al., 2018). It was created as a multilingual lexicon that is reusable and not task-specific or limited by context of its development. The creators of Hurtlex expanded on the lexicon of Le parole per ferire “word"
A94-1032,A92-1028,1,0.890861,"Missing"
A94-1032,C92-2088,0,\N,Missing
bond-etal-2008-boot,isahara-etal-2008-development,1,\N,Missing
bond-etal-2008-boot,W04-2209,0,\N,Missing
bond-etal-2008-boot,kanzaki-etal-2008-extraction,1,\N,Missing
bond-etal-2008-boot,2001.mtsummit-papers.10,1,\N,Missing
bond-etal-2008-boot,W07-0734,0,\N,Missing
bond-etal-2008-boot,W06-0601,0,\N,Missing
bond-etal-2008-boot,kaji-watanabe-2006-automatic,0,\N,Missing
C00-1014,C96-1023,1,0.935191,"Missing"
C00-1014,P98-1023,1,0.885506,"in English.1 In many languages, including most South-East Asian languages, Chinese, Japanese and Korean, the majority of nouns are uncountable and must be quantified by numeral classifier combinations. These languages typically have many different classifiers. There has been some work on the analysis of numeral classifiers in natural language processing, particularly for Japanese (Asahioka et al., 1990; Kamei and Muraki, 1995; Bond et al., 3 Visiting CSLI, Stanford University (1999-2000). 1 Numeral-classifier combinations are shown in bold, the noun phrases they quantify are underlined. 1996; Bond et al., 1998; Yokoyama and Ochiai, 1999), but very little on their generation. We could only find one paper on generating classifiers in Thai (Sornlertlamvanich et al., 1994). One immediate application for the generation of classifiers is machine translation, and we shall take examples from there, but it is in fact needed for the generation of any quantified noun phrase with an uncountable head noun. The second question we address is: how far can an ontology be reused for a different task to the one it was originally designed for. There are several large ontologies now in use (WordNet (Fellbaum, 1998); Go"
C00-1014,1989.mtsummit-1.27,0,0.027367,"on their generation. We could only find one paper on generating classifiers in Thai (Sornlertlamvanich et al., 1994). One immediate application for the generation of classifiers is machine translation, and we shall take examples from there, but it is in fact needed for the generation of any quantified noun phrase with an uncountable head noun. The second question we address is: how far can an ontology be reused for a different task to the one it was originally designed for. There are several large ontologies now in use (WordNet (Fellbaum, 1998); Goi-Taikei (Ikehara et al., 1997); Mikrokosmos (Nirenburg, 1989)) and it is impractical to rebuild one for every application. However, there is no guarantee that an ontology built for one task will be useful for another. The paper is structured as follows. In Section 2, we discuss the properties of numeral classifiers in more detail and suggest an improved algorithm for generating them. Section 3 introduces the ontology we have chosen, the Goi-Taikei ontology (Ikehara et al., 1997). Then we show how to use the ontology to generate classifiers in Section 4. Finally, we discuss how well it performs in Section 5. 2 Generating Numeral Classifiers In this secti"
C00-1014,C94-1091,0,0.30235,"ust be quantified by numeral classifier combinations. These languages typically have many different classifiers. There has been some work on the analysis of numeral classifiers in natural language processing, particularly for Japanese (Asahioka et al., 1990; Kamei and Muraki, 1995; Bond et al., 3 Visiting CSLI, Stanford University (1999-2000). 1 Numeral-classifier combinations are shown in bold, the noun phrases they quantify are underlined. 1996; Bond et al., 1998; Yokoyama and Ochiai, 1999), but very little on their generation. We could only find one paper on generating classifiers in Thai (Sornlertlamvanich et al., 1994). One immediate application for the generation of classifiers is machine translation, and we shall take examples from there, but it is in fact needed for the generation of any quantified noun phrase with an uncountable head noun. The second question we address is: how far can an ontology be reused for a different task to the one it was originally designed for. There are several large ontologies now in use (WordNet (Fellbaum, 1998); Goi-Taikei (Ikehara et al., 1997); Mikrokosmos (Nirenburg, 1989)) and it is impractical to rebuild one for every application. However, there is no guarantee that an"
C00-1014,C98-1023,1,\N,Missing
C02-1052,C94-1002,1,0.951495,"as though it were arbitrary and encode it as a lexical property of nouns. Copestake (1992) has gone some way toward representing countability at the semantic level using a type form with subtypes countable and uncountable with further subtypes below these. Words that undergo conversion between different values of form can be linked with lexical rules, such as the grinding rule that links a countable animal with its uncountable interpretation as meat. These are not, however directly linked to a full ontology. Therefore there is no direct connection between being an animal and being countable. Bond et al. (1994) suggested a division of countability into five major types, based on Allan (1980)’s noun countability preferences (NCPs). Nouns which rarely undergo conversion are marked as either fully countable, uncountable or plural only. Nouns that are non-specified are marked as either strongly countable (for count nouns that can be converted to mass, such as cake) or weakly countable (for mass nouns that are readily convertible to count, such as beer ). Conversion is triggered by surrounding context. Noun phrases headed by uncountable nouns can be converted to countable noun phrases by generating class"
C02-1052,J99-4002,0,0.0124707,"fault, such as cake, and weakly countable, those that refer to nonbounded referents by default, such as beer . At present, these distinctions were made by the lexicographers’ intuition, as there are no large sense-tagged corpora to train from. In fact, almost all English nouns can be used in uncountable environments, for example, if they are given the ground interpretation. The only exception is classifiers such as piece or bit, which refer to quanta, and thus have no uncountable interpretation. Language users are sensitive to relative frequencies of variant forms and senses of lexical items (Briscoe and Copestake, 1999, p511). The division into fully, strongly, weakly 1 We ignore the two subclasses in this paper: collective nouns are treated as fully countable and semi-countable as uncountable.  Index       sense 1      usagi  English Translation  Part of Speech  Noun Countability Pref.  Default Number   Semantic Classes          i  rabbit noun strongly countable singular h common noun animal, meat Figure 1: Japanese-English Noun Lexical Entry (usagi ⇔ rabbit) Table 1: Noun Countability Preferences Noun Countability Preference fully countable strongly countable weak"
C02-1052,1991.mtsummit-papers.16,0,0.0566114,"ive speakers, particularly those whose native grammar does not mark countability. Presumably, their knowledge of the world is just as complete as English native speakers, but they tend to have difficulty with the English specific conceptual encoding of countability. In the next section (§ 3) we describe the resources we use to measure the predictability of countability by meaning, and then describe our experiment (§ 4). 3 Resources We use the five noun countability classes of Bond et al. (1994), and the 2,710 semantic classes used in the Japanese-to-English machine translation system ALT-J/E (Ikehara et al., 1991). These are combined in the machine translation lexicons, allowing us to quantify how well semantic classes predict countability. 3.1 Semantic Transfer Dictionary We use the common noun part of ALT-J/E’s Japanese-to-English semantic transfer dictionary. It contains 71,833 linked JapaneseEnglish pairs. A simplified example of the entry for usagi “rabbit” is given in Figure 1. Each record of the dictionary has a Japanese index form, a sense number, an English index form, English syntactic information, English semantic information, domain information and so on. English syntactic information inclu"
C02-1052,Y96-1005,0,0.0148668,"y numbers, and have a morphologically marked plural form: one dog, two dogs. Uncountable nouns cannot be modified by denumerators, but can be modified by unspecific quantifiers such as much, and do not show any number distinction (prototypically being singular): * one equipment, some equipment, *two equipments. Knowledge of countability is important when translating from a source language without obligatory number and countability distinctions to a target language that does make number distinctions. Some examples are Japaneseto-English (Ehara and Tanaka, 1993; Bond, 2001), Japanese-to-German (Siegel, 1996), and Chinese-to-English. For a system generating English, it is important to know the countability of the head noun, as this determines whether it can become plural, and the range of possible determiners. Knowledge of countability is particularly important in machine translation, because the closest trans∗∗ This research was done while the second author was visiting the NTT Communication Science Laboratories lation equivalent may have different countability from the source noun. Many languages, such as Chinese and Japanese, do not mark countability, which means that the choice of countability"
C04-1193,C02-1052,1,0.889476,"Missing"
C04-1193,P01-1019,0,0.0322057,"Bender, 2002), which we have extended to cover the dictionary definition sentences (Bond et al., 2004). We have treebanked 23,000 sentences using the [incr tsdb()] profiling environment (Oepen and Carroll, 2000) and used them to train a parse ranking model for the PET parser (Callmeier, 2002) to selectively rank the parser output. These tools, and the grammar, are available from the Deep Linguistic Processing with HPSG Initiative (DELPH-IN: http://www.delph-in. net/). We use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics (MRS: Copestake et al. (2001)). 3 Ontology Extraction In this section we present our work on creating an ontology. Past research on knowledge acquisition from definition sentences in Japanese has primarily dealt with the task of automatically generating hierarchical structures. Tsurumaru et al. (1991) developed a system for automatic thesaurus construction based on information derived from analysis of the terminal clauses of definition sentences. It was successful in classifying hyponym, meronym, and synonym relationships between words. However, it lacked any concrete evaluation of the accuracy of the hierarchies created,"
C04-1193,fillmore-etal-2002-seeing,0,0.0562491,"Missing"
C04-1193,C04-1093,0,0.0239123,"“driver” (with English glosses) English (Barnbrook, 2002) and Japanese (Tsurumaru et al., 1991; Tokunaga et al., 2001). Regular expressions are extremely robust, and relatively easy to construct. However, we use a parser for four reasons. The first is that it makes our knowledge acquisition more language independent. If we have a parser that can produce MRS, and a machine readable dictionary for that language, the knowledge acquisition system can easily be ported. The second reason is that we can go on to use the parser and acquisition system to acquire knowledge from non-dictionary sources. Fujii and Ishikawa (2004) have shown how it is possible to identify definitions semi automatically, however these sources are not as standard as dictionaries and thus harder to parse using only regular expressions. The third reason is that we can more easily acquire knowledge beyond simple hypernyms, for example, identifying synonyms through common definition patterns as proposed by Tsuchiya et al. (2001). The final reason is that we are ultimately interested in language understanding, and thus wish to develop a parser. Any effort spent in building and refining regular expressions is not reusable, while creating and i"
C04-1193,W02-1210,0,0.117635,"sentences). An example entry for  doraib¯a “driver” is given in the word Figure 1, with English glosses added. The underlined material was not in Lexeed originally, we extract it in this paper. doraib¯ a “driver” has a familiarity of 6.55, and three senses. The first sense was originally defined as just the synonym nejimawashi “screwdriver”, which has a familiarity below 5.0. This was rewritten to the explanation: “A tool for inserting and removing screws”. 2.2 The Hinoki Treebank In order to produce semantic representations we are using an open source HPSG grammar of Japanese: JACY (Siegel and Bender, 2002), which we have extended to cover the dictionary definition sentences (Bond et al., 2004). We have treebanked 23,000 sentences using the [incr tsdb()] profiling environment (Oepen and Carroll, 2000) and used them to train a parse ranking model for the PET parser (Callmeier, 2002) to selectively rank the parser output. These tools, and the grammar, are available from the Deep Linguistic Processing with HPSG Initiative (DELPH-IN: http://www.delph-in. net/). We use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics (MRS: Copestake et a"
C04-1193,P97-1007,0,\N,Missing
C14-2019,W08-0336,0,0.0191928,"Missing"
C14-2019,J93-1004,0,0.628001,"Missing"
C14-2019,W04-3230,0,0.119639,"Missing"
C14-2019,J02-1004,0,0.109052,"Missing"
C14-2019,N03-1033,0,0.0939264,"Missing"
C94-1002,1993.tmi-1.18,0,0.246185,"Missing"
C94-1002,1991.mtsummit-papers.16,1,\N,Missing
C96-1023,C94-1002,1,0.834803,"Missing"
C96-1023,1995.tmi-1.1,1,0.727828,"y Countable Uncountable Pluralia Tanta 1 1 l 1 set set set set 1 set of of of of of Species (Si) dogs cakes beer information scissors 1. kind 1 kind 1 kind 1. kind 1 kind Whether a notln is a GIll)UP classifier or not carl also be used to help determine the Irtlmber of ascriptive and appositive noun phrases. For example, in A L T - J / E the countability and number of two at)positive noun phrases are made to match each other, unless one element is plural and the other is a GI{OUP classifier. For example, m a n y insects, a whole swarm, . . . as opposed to m a n y insects, bees I think, . . . (Bond, Ogura, and Kawaoka, 1995). Examples of (;Rein, classifiers are given in Table 3. 3.4 Speeies classifiers The last type of classifier is sP,,;cn,;s classifiers. SI&apos;ECII:S classifiers are partitives of quality and (;an o c c u r w i t h countable or u n e o , l n t & b l e llOlln phrases. The embedded noun phr~se will agree in number with the head noun phrase if flflly or strongly countable: a kind of car, 2 kinds of cars; a kind of equipment, 2 kinds of equipment. Exalnples of SPE(:mS classifier&apos;s are given in Table 3. 4 When is a C l a s s i f i e r a Classifier? In the analysis given above for Japanese noun phrases"
C96-1023,C94-1005,0,0.05538,"Missing"
C96-1023,1991.mtsummit-papers.16,1,0.902023,"Missing"
C96-1023,1993.tmi-1.18,0,0.0443561,"Missing"
C96-1023,P87-1018,0,0.0882342,"Missing"
C96-1023,C94-1091,0,0.176024,"Missing"
C98-1023,C96-1023,1,0.849876,"tifying the conditions under which a quantifier can appear in the adjunct position. The explanations range from configurational (Inoue, 1983; Miyagawa, 1989) to discourse based (Downing, 1996; Alam, 1997), we shall discuss these further below. There has been almost no discussion of other floating quantifiers, such as quantiflcational nouns. We call the process of identifying the noun phrase being quantified by a floating quantifier 'anchoring' the quantifier. The necessity of anchoring floating quantifiers for many natural language processing tasks is widely recognized (Asahioka et al., 1990; Bond et al., 1996), and is important not only for machine translation but for the interpretation of Japanese in general. However, although there are several NLP systems that incorporate some solution to the problem of floating quantifiers, to the best of our knowledge, no algorithm for anchoring floating quantifiers has been given. We propose such an algorithm in this paper. The algorithm uses information about case-marking, sentence structure, part-of-speech, noun and verb meaning. The algorithm has been implemented and tested within the Japanese-to-English machine translation system A L T - J / E (Ikehara et"
C98-1023,1991.mtsummit-papers.16,1,0.760595,"al., 1996), and is important not only for machine translation but for the interpretation of Japanese in general. However, although there are several NLP systems that incorporate some solution to the problem of floating quantifiers, to the best of our knowledge, no algorithm for anchoring floating quantifiers has been given. We propose such an algorithm in this paper. The algorithm uses information about case-marking, sentence structure, part-of-speech, noun and verb meaning. The algorithm has been implemented and tested within the Japanese-to-English machine translation system A L T - J / E (Ikehara et al., 1991). The next section describes the phenomenon of quantifier float in more detail. We then propose our algorithm to identify and anchor floating quantifiers in Section 3. The results of implementing the algorithm in A L T - J / E are disaThe name 'float' comes from early transformational accounts, where the quantifier was said to 'float' out of the noun phrase. Although this analysis has largely been abandoned, and we disagree with it, we shall continue with accepted practice and call a quantifier in the adjunct position a floating quantifier. cussed in Section 4 and some remaining problems ident"
copestake-etal-2002-multiword,W98-0707,0,\N,Missing
copestake-etal-2002-multiword,P97-1018,1,\N,Missing
copestake-etal-2004-lexicon,copestake-flickinger-2000-open,1,\N,Missing
copestake-etal-2004-lexicon,villavicencio-etal-2004-multilingual,1,\N,Missing
copestake-etal-2004-lexicon,copestake-etal-2002-multiword,1,\N,Missing
copestake-etal-2004-lexicon,W02-1210,0,\N,Missing
D07-1050,W07-1204,1,0.843758,"the SemCor corpus (Fellbaum, 1998) which is annotated with parse trees and WordNet senses, but it is fairly small, and does not explicitly include any structural semantic information. Therefore, we decided to construct and use a treebank with both syntactic information (e.g. HPSG parses) and lexical semantic information (e.g. sense tags): the Hinoki treebank (Bond et al., 2004). This can be used to train word sense disambiguation and parse ranking models using both syntactic and lexical semantic features. In this paper, we discuss only word sense disambiguation. Parse ranking is discussed in Fujita et al. (2007). 2 The Hinoki Corpus The Hinoki corpus consists of the Lexeed Semantic Database of Japanese (Kasahara et al., 2004) and corpora annotated with syntactic and semantic infor477 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 477–485, Prague, June 2007. 2007 Association for Computational Linguistics mation. 2.1 Lexeed Lexeed is a database built from on a dictionary, which defines word senses used in the Hinoki corpus and has around 49,000 dictionary definition sentences and 46,000 example sentences wh"
D07-1050,P05-1050,0,0.0210164,"Missing"
D07-1050,P03-1054,0,0.00495422,"del using only bag of words and n-gram features. 1 Introduction Recently, significant improvements have been made in combining symbolic and statistical approaches to various natural language processing tasks. In parsing, for example, symbolic grammars are being combined with stochastic models (Riezler et al., 2002; Oepen et al., 2002; Malouf and van Noord, 2004). Statistical techniques have also been shown to be useful for word sense disambiguation (Stevenson, 2003). However, to date, there have been few combinations of sense information together with symbolic grammars and statistical models. Klein and Manning (2003) show that much of the gain in statistical parsing using lexicalized models comes from the use of a small set of function words. Features based on general relations provide little improvement, presumably because the data is too sparse: in the Penn treebank normally used to train and test statistical parsers stocks and skyrocket never appear together. They note that this should motivate the use of similarity and/or class based approaches: the superordinate concepts capital (⊃ stocks) and move upward (⊃ sky rocket) frequently appear together. However, there has been little success in this area t"
D07-1050,J03-4004,0,0.0237773,"parsers stocks and skyrocket never appear together. They note that this should motivate the use of similarity and/or class based approaches: the superordinate concepts capital (⊃ stocks) and move upward (⊃ sky rocket) frequently appear together. However, there has been little success in this area to date. For example, Xiong et al. (2005) use semantic knowledge to parse Chinese, but gain only a marginal improvement. Focusing on WSD, Stevenson (2003) and others have shown that the use of syntactic information (predicate-argument relations) improve the quality of word sense disambiguation (WSD). McCarthy and Carroll (2003) have shown the effectiveness of the selectional preference information for WSD. However, there is still little work on combining WSD and parse selection. We hypothesize that one of the reasons for the lack of success is that there has been no resource annotated with both syntactic (or structural semantic information) and lexical semantic information. For English, there is the SemCor corpus (Fellbaum, 1998) which is annotated with parse trees and WordNet senses, but it is fairly small, and does not explicitly include any structural semantic information. Therefore, we decided to construct and u"
D07-1050,C02-2025,0,0.023192,"Missing"
D07-1050,P02-1035,0,0.0501663,"Missing"
D07-1050,W02-1210,0,0.0181814,"were then hand verified. Goi-Taikei has about 400,000 words including proper nouns, most nouns are classified into about 2,700 semantic classes. These semantic classes are arranged in a hierarchical structure (11 levels). The Goi-Taikei Semantic Class for untenshu “chauffeur” is shown in Figure 1: hC292:driveri at level 9 which is subordinate to hC4:personi. þ U3 2.5 Syntactic and Structural Semantics Annotation Syntactic annotation is done by selecting the best parse (or parses) from the full analyses derived by a broad-coverage precision grammar. The grammar is an HPSG implementation (JACY: Siegel and Bender, 2002), which provides a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. As the grammar is based on a monostratal theory of grammar (HPSG: Pollard and Sag, 1994) it is possible to simultaneously annotate syntactic and semantic structure without overburdening the annotator. Using a grammar enforces treebank consistency — all sentences annotated are guaranteed to have well I NDEX POS   L EX -T YPE  FAMILIARITY          S ENSE 1      þU3  untenshu noun noun-lex 6.2 [1–7] (≥ 5)  D EFINITION    E XAMPLE    H"
D07-1050,W06-0608,1,0.894014,"Missing"
D07-1050,N04-4003,0,0.0206929,"tion 4. In the initial state, some of the semantic features, e.g. semantic collocations (SEM-Col) and word sense extensions for semantic dependencies (SEM-Dep) are not available, since no word senses for polysemous words have been determined. It is not practical to count all combinations of word senses for target words, therefore, we first try to decide the sense for that word which is most plausible among all the ambiguous words, then, disambiguate the next word by using the sense. We use the beam search algorithm, which is similar to that used for decoder in statistical machine translation (Watanabe, 2004), for finding the plausible combination of word sense tags. We trained and tested on the Lexeed Dictionary Definition (LXD-DEF) and Example sections (LXD-EX) of the Hinoki corpus (Bond et al., 2007). These have about 75,000 definition and 46,000 example sentences respectively. Some 54,000 and 36,000 sentences of them are treebanked, i.e., they have the syntactic trees and structural semantic information. We used these sentences with the complete information and selected 1,000 sentences out of each sentence class as test sets (LXD-DEFtest , LXD-EXtest ), and the remainder is combined and used a"
D07-1050,I05-1007,0,\N,Missing
D09-1097,bond-etal-2008-boot,1,0.581211,"Missing"
D09-1097,P99-1016,0,0.0133585,"ctic pattern-based methods by using dependency path features for machine learning. Then, they extended the framework such that this method was capable of making use of heterogenous evidence (Snow et al. 2006). These pattern-based methods require the co-occurrences of a target word and the hypernym in a document. It should be noted that the requirement of such cooccurrences actually poses a problem when we extract a large set of hyponymy relations since they are not frequently observed (Shinzato et al. 2004, Pantel et al. 2004b). Clustering-based methods have been proposed as another approach. Caraballo (1999), Pantel et al. (2004b), and Shinzato et al. (2004) proposed a method to find a common hypernym for word classes, which are automatically constructed using some measures of word similarities or hierarchical structures in HTML documents. Etzioni et Documents hypernym ..… word The same hypernym is selected for all words in a class. Pattern-based method (Hearst 1992, Pantel et al. 2004a, Ando et al. 2003, Snow et al. 2005, Snow et al. 2006, and Etzioni et al. 2005) word word word word word Word Class Clustering-based method (Caraballo 1999, Pantel et al. 2004b, Shinzato et al. 2004, and Etzioni e"
D09-1097,C92-2082,0,0.762187,"pproach. duce some related works in Section 2. Section 3 describes the Wikipedia relation database. Section 4 describes the distributional similarity calculated by the two methods. In Section 5, we describe a method to discover an appropriate hypernym for each target word. The experimental results are presented in Section 6 before concluding the paper in Section 7. 2 Corpus/documents hypernym such as word Co-occurrences in a pattern are needed Related Works Most previous researchers have relied on lexico-syntactic patterns for hyponymy acquisition. Lexico-syntactic patterns were first used by Hearst (1992). The patterns used by her included “NP0 such as NP1,” in which NP0 is a hypernym of NP1. Using these patterns as seeds, Hearst discovered new patterns by which to semiautomatically extract hyponymy relations. Pantel et al. (2004a) proposed a method to automatically discover the patterns using a minimal edit distance. Ando et al. (2003) applied predefined lexico-syntactic patterns to Japanese news articles. Snow et al. (2005) generalized these lexicosyntactic pattern-based methods by using dependency path features for machine learning. Then, they extended the framework such that this method wa"
D09-1097,P08-1047,1,0.864076,"Missing"
D09-1097,P99-1004,0,0.0542805,"etween v and n. In Japanese, a relation rel is represented by postpositions attached to n and the phrase composed of n and rel modifies v. Each triple is divided into two parts. The first is &lt;v, rel&gt; and the second is n. Then, we consider the conditional probability of occurrence of the pair &lt;v, rel&gt;: P(&lt;v, rel&gt;|n). P(&lt;v, rel&gt;|n) can be regarded as the distribution of the grammatical contexts of the noun phrase n. The distributional similarity can be defined as the distance between these distributions. There are several kinds of functions for evaluating the distance between two distributions (Lee 1999). Our method uses the Jensen-Shannon divergence. The Jensen-Shannon divergence between two probability distributions, P (⋅ |n1 ) and P (⋅ |n2 ) , can be calculated as follows: DJS ( P (⋅ |n1 ) ||P (⋅ |n2 )) P (⋅ |n1 ) + P (⋅ |n2 ) 1 ) ( DKL ( P (⋅ |n1 ) || 2 2 P (⋅ |n1 ) + P (⋅ |n2 ) + DKL ( P (⋅ |n2 ) || )), 2 = &lt;v ,rel &gt;∈D if f (&lt; v, rel , n &gt;) &gt; 0, where f(&lt;v, rel, n&gt;) is the frequency of a triple &lt;v, rel, n&gt; and D is the set defined as { &lt;v, rel &gt; | f(&lt;v, rel, n&gt;) &gt; 0 }. In the case of f(&lt;v, rel, n&gt;) = 0, P(&lt;v, rel&gt;|n) is set to 0. Instead of using the observed frequency directly as in the"
D09-1097,P06-1101,0,0.0472608,"P1,” in which NP0 is a hypernym of NP1. Using these patterns as seeds, Hearst discovered new patterns by which to semiautomatically extract hyponymy relations. Pantel et al. (2004a) proposed a method to automatically discover the patterns using a minimal edit distance. Ando et al. (2003) applied predefined lexico-syntactic patterns to Japanese news articles. Snow et al. (2005) generalized these lexicosyntactic pattern-based methods by using dependency path features for machine learning. Then, they extended the framework such that this method was capable of making use of heterogenous evidence (Snow et al. 2006). These pattern-based methods require the co-occurrences of a target word and the hypernym in a document. It should be noted that the requirement of such cooccurrences actually poses a problem when we extract a large set of hyponymy relations since they are not frequently observed (Shinzato et al. 2004, Pantel et al. 2004b). Clustering-based methods have been proposed as another approach. Caraballo (1999), Pantel et al. (2004b), and Shinzato et al. (2004) proposed a method to find a common hypernym for word classes, which are automatically constructed using some measures of word similarities o"
D09-1097,sumida-etal-2008-boosting,1,0.937771,"aper, we use the term “word” for both “a single-word word” and “a multi-word word.” 929 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 929–937, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP A hypernym is selected for each word independently. Wikipedia relation database Wikipedia Hyponymy relations are extracted using the layout information of Wikipedia. hypernym : Selected from hypernyms in the Wikipedia relation database. No direct co-occurrences of hypernym and hyponym in corpora are needed. Wikipedia-based approach (Ponzetto et al. 2007 and Sumida et al. 2008) Target word: Selected from the Web : word k similar words Figure 1: Overview of the proposed approach. duce some related works in Section 2. Section 3 describes the Wikipedia relation database. Section 4 describes the distributional similarity calculated by the two methods. In Section 5, we describe a method to discover an appropriate hypernym for each target word. The experimental results are presented in Section 6 before concluding the paper in Section 7. 2 Corpus/documents hypernym such as word Co-occurrences in a pattern are needed Related Works Most previous researchers have relied on le"
D09-1097,N04-1041,0,0.0180963,"Missing"
D09-1097,P99-1014,0,0.0117575,"rel&gt;|n) is set to 0. Instead of using the observed frequency directly as in the usual maximum likelihood estimation, we modified it as above. Although this might seems strange, this kind of modification is common in information retrieval as a term weighing method (Manning et al. 1999) and it is also applied in some studies to yield better word similarities (Terada et al. 2006, Kazama et al. 2009). We also adopted this idea in this study. 4.2 P(⋅ |n1 ) . P(⋅ |n2 ) Finally, the distributional similarity between two words, n1 and n2, is defined as follows: Distributional Similarity Based on CVD Rooth et al. (1999) and Torisawa (2001) showed that EM-based clustering using verb-noun dependencies can produce semantically clean noun clusters. We exploit these EM-based clustering results as the smoothed contexts for noun n. In Torisawa’s model (2001), the probability of occurrence of the triple &lt;v, rel, n&gt; is defined as follows: P(&lt; v, rel, n &gt;) where DKL indicates the Kullback-Leibler divergence and is defined as follows: DKL ( P(⋅ |n1 ) ||P(⋅ |n2 ))= ∑ P(⋅ |n1 ) log log( f (&lt; v, rel , n &gt;)) + 1 ∑ log( f (&lt; v, rel , n &gt;) + 1 =def ∑a∈A P(&lt; v, rel &gt; |a) P(n |a) P(a), where a denotes a hidden class of &lt;v,rel&gt;"
D09-1097,N04-1010,1,0.869582,"Missing"
D09-1097,shinzato-etal-2008-large,0,\N,Missing
D19-6013,P13-1133,1,0.832565,"Missing"
D19-6013,P17-1025,0,0.0201271,"and Levin, 2010), there is still a lack of detailed account of potential causality that could be denoted by an action verb (Gao et al., 2016). From the AI domain, there were investigations 2 In the article we do not consider the follow-up step in the transformation of action verbs into action primitives for further execution by AI agent. This kind of transformation depends on the type of the agent. 105 devoted to learning the physics of the world from videos (Fire and Zhu, 2016) and simulations (Wu et al., 2017). However, except for a few works that explored the physical properties of verbs (Forbes and Choi, 2017; Zellers and Choi, 2017), how verbs and their corresponding actions affect the state of the physical world is still largely underexplored. Well-known knowledge bases like Freebase, YAGO or DBPedia, even being automatically populated by modern NLP methods, do not contain commonsense inferences we are going to create. Crowd-sourcing resources such as ConceptNet have an incomplete coverage, which is its main drawback. A human knowledge engineer may not list all possible events related to a particular action verb or a result verb. For example, the inference scrub → clean might be listed while oth"
D19-6013,P16-1171,0,0.209335,"Figure 1: Transformation of high-level command for an agent. cup under the faucet, turn on the faucet, turn off the faucet, etc. In other words, natural language command decomposition is a necessary step for an agent to be capable of executing. To make such transformations possible, previous works (Misra et al., 2015; She and Chai, 2016) explicitly model verbs with predicates describing the resulting states of actions. Their empirical evaluations have demonstrated how incorporating result states into verb representations can link language with underlying planning modules for robotic systems (Gao et al., 2016). Recent investigations use reinforcement learning to transform language commands into primitive actions (Misra et al., 2017) or representation of actions (Arumugam et al., 2017). The current studies in human-robot communication (She and Chai, 2017; Chai et al., 2018) show that natural language understanding of commands is difﬁcult for machines because commands in human-human communications are usually expressed through a desired change of state. 2 Problem Statement As Rappaport Hovav and Levin (2010) pointed out, any action can be expressed in two different ways. Firstly, there are manner ver"
D19-6013,2018.gwc-1.52,1,0.831587,"Missing"
D19-6013,W04-3205,0,0.127406,". Even if the semantic representation for a verb may indicate that a change of state is involved, it does not provide the speciﬁcs associated with the verb’s meaning (e.g., to what attribute of its patient the changes might occur) (Gao et al., 2016). WordNet, manually created by professional linguists, to the best of our knowledge, is the only linguistic resource that partly provides information about causal links between action verbs and result verbs. As we will indicate below, these links overlap with the hypernym-hyponym relations in WordNet. Finally, the broad-coverage resource VerbOcean (Chklovski and Patel, 2004) set a semantic relation “enablement” between verbs using the following 4 patterns: “Xed * by Ying the”; “Xed * by Ying or”; “to X * by Ying the” and “to X * by Ying or”, where “X” and “Y” are verbs; (*) matches any single word. The patterns are similar to the one we are going to use. The only signiﬁ- Figure 3: Transformation of high-level command. cant difference is that all of them do not include a noun after a verb “X”. As it was mentioned in the section 3 (2nd point), a result verb being applied to different objects assumes different action verbs. 4 Proposed Approach We consider the transf"
D19-6013,2019.gwc-1.31,1,0.707649,"998) which is widely used in a variety of tasks related to extraction of semantic relations. The verb part of WN contains 3. A verb in WN is an action verb if it represents movement in any direction: lift, turn, descend, etc. 4. A verb in WN is an action verb if its hypernym is an action verb. In other words, once a verb is an action verb, all branches located below consist of action verbs as well, regardless of their glosses. The procedure of using conditions 1-4 goes from all top verbs to the bottom verbs. For ex4 https://wordnet.princeton.edu/documentation/wnstats 7wn. The following paper (McCrae et al., 2019) outlines a roadmap for adding new entries to WordNet, so the number of verbs is not ﬁxed, but increasing over time. 5 Note that these are deﬁned on verb-senses, not verbs. For example, the verb see “perceive: I see the picture” will behave differently from the verb see “understand: I see the problem”. 6 These 4 conditions elaborate the approach developed in (Huminski and Zhang, 2018a,b) 107 ample, we start from the top synset {change, alter, modify} (gloss: cause to change; make different; cause a transformation). It doesn’t satisfy the 1st or the 2nd condition, so we go down on 1 level and e"
D19-6013,P15-1096,0,0.0303192,"d into a sequence of these 3 actions to be performed (KressGazit et al., 2008). For smarter agents with more primitives, complicated commands like ﬁll up the cup with water can be executed by transformation into a long sequence of the lower-level actions: pick up the cup, move to your left, put the Figure 1: Transformation of high-level command for an agent. cup under the faucet, turn on the faucet, turn off the faucet, etc. In other words, natural language command decomposition is a necessary step for an agent to be capable of executing. To make such transformations possible, previous works (Misra et al., 2015; She and Chai, 2016) explicitly model verbs with predicates describing the resulting states of actions. Their empirical evaluations have demonstrated how incorporating result states into verb representations can link language with underlying planning modules for robotic systems (Gao et al., 2016). Recent investigations use reinforcement learning to transform language commands into primitive actions (Misra et al., 2017) or representation of actions (Arumugam et al., 2017). The current studies in human-robot communication (She and Chai, 2017; Chai et al., 2018) show that natural language unders"
D19-6013,D17-1106,0,0.0165265,", etc. In other words, natural language command decomposition is a necessary step for an agent to be capable of executing. To make such transformations possible, previous works (Misra et al., 2015; She and Chai, 2016) explicitly model verbs with predicates describing the resulting states of actions. Their empirical evaluations have demonstrated how incorporating result states into verb representations can link language with underlying planning modules for robotic systems (Gao et al., 2016). Recent investigations use reinforcement learning to transform language commands into primitive actions (Misra et al., 2017) or representation of actions (Arumugam et al., 2017). The current studies in human-robot communication (She and Chai, 2017; Chai et al., 2018) show that natural language understanding of commands is difﬁcult for machines because commands in human-human communications are usually expressed through a desired change of state. 2 Problem Statement As Rappaport Hovav and Levin (2010) pointed out, any action can be expressed in two different ways. Firstly, there are manner verbs that describe how actions are carried out – i.e. manners of doing: hit, stab, scrub, sweep, wipe, yell, etc. Secondly, the"
D19-6013,P16-1011,0,0.0181865,"these 3 actions to be performed (KressGazit et al., 2008). For smarter agents with more primitives, complicated commands like ﬁll up the cup with water can be executed by transformation into a long sequence of the lower-level actions: pick up the cup, move to your left, put the Figure 1: Transformation of high-level command for an agent. cup under the faucet, turn on the faucet, turn off the faucet, etc. In other words, natural language command decomposition is a necessary step for an agent to be capable of executing. To make such transformations possible, previous works (Misra et al., 2015; She and Chai, 2016) explicitly model verbs with predicates describing the resulting states of actions. Their empirical evaluations have demonstrated how incorporating result states into verb representations can link language with underlying planning modules for robotic systems (Gao et al., 2016). Recent investigations use reinforcement learning to transform language commands into primitive actions (Misra et al., 2017) or representation of actions (Arumugam et al., 2017). The current studies in human-robot communication (She and Chai, 2017; Chai et al., 2018) show that natural language understanding of commands i"
D19-6013,P17-1150,0,0.013599,"o make such transformations possible, previous works (Misra et al., 2015; She and Chai, 2016) explicitly model verbs with predicates describing the resulting states of actions. Their empirical evaluations have demonstrated how incorporating result states into verb representations can link language with underlying planning modules for robotic systems (Gao et al., 2016). Recent investigations use reinforcement learning to transform language commands into primitive actions (Misra et al., 2017) or representation of actions (Arumugam et al., 2017). The current studies in human-robot communication (She and Chai, 2017; Chai et al., 2018) show that natural language understanding of commands is difﬁcult for machines because commands in human-human communications are usually expressed through a desired change of state. 2 Problem Statement As Rappaport Hovav and Levin (2010) pointed out, any action can be expressed in two different ways. Firstly, there are manner verbs that describe how actions are carried out – i.e. manners of doing: hit, stab, scrub, sweep, wipe, yell, etc. Secondly, there are verbs that describe results of an action or a change of state: break, clean, crush, destroy, shatter, etc. Further w"
D19-6013,P06-1101,0,0.237365,"Missing"
D19-6013,W13-4302,1,0.88848,"Missing"
D19-6013,H89-1033,0,0.591332,"umans are still constrained. The article addresses a gap in natural language understanding about actions, speciﬁcally that of understanding commands. We propose a new method for commonsense inference (grounding) of high-level natural language commands into speciﬁc action commands for further execution by a robotic system. The method allows to build a knowledge base that consists of a large set of commonsense inferences. The preliminary results have been presented. 1 Introduction There is a signiﬁcant progress in movement from early natural language understanding computer programs like SHRDLU (Winograd, 1972) with its deterministic actions in the virtual world to modern cognitive robots operating in the physical world and mapping language to actions. Artiﬁcial agents enter our lives and the end users of such systems are not technical experts. The only way for them to communicate with AI is to use natural language. For example, humans can give a natural language command expecting a follow-up action by the agent. Nowadays in robotics, in order to execute a natural language command which is considered as a high-level instruction, an agent needs to transform it to a sequence of lower-level primitive a"
D19-6013,D17-1099,0,0.0256513,"e is still a lack of detailed account of potential causality that could be denoted by an action verb (Gao et al., 2016). From the AI domain, there were investigations 2 In the article we do not consider the follow-up step in the transformation of action verbs into action primitives for further execution by AI agent. This kind of transformation depends on the type of the agent. 105 devoted to learning the physics of the world from videos (Fire and Zhu, 2016) and simulations (Wu et al., 2017). However, except for a few works that explored the physical properties of verbs (Forbes and Choi, 2017; Zellers and Choi, 2017), how verbs and their corresponding actions affect the state of the physical world is still largely underexplored. Well-known knowledge bases like Freebase, YAGO or DBPedia, even being automatically populated by modern NLP methods, do not contain commonsense inferences we are going to create. Crowd-sourcing resources such as ConceptNet have an incomplete coverage, which is its main drawback. A human knowledge engineer may not list all possible events related to a particular action verb or a result verb. For example, the inference scrub → clean might be listed while others such as mop → clean,"
ho-etal-2014-identifying,W13-2319,1,\N,Missing
ho-etal-2014-identifying,Y11-1038,1,\N,Missing
ho-etal-2014-identifying,W13-4302,1,\N,Missing
ho-etal-2014-identifying,P13-1133,1,\N,Missing
I05-6004,W97-1504,0,0.375723,"OMLEX examples were created specifically for the project. Finally, we are dealing with all kinds of lexical types that appear in the treebank, but the COMLEX project targets only nouns, adjectives, and verbs. expressions in Japanese. That describes each expression’s linguistic behavior, usage and examples in depth. Notable differences between their database and ours are that their database is mostly constructed manually while ours is constructed semi-automatically, and that they target only functional expressions while we deal with all kinds of lexical types. Hypertextual Grammar development (Dini and Mazzini, 1997) attempted a similar task, but focused on documenting the grammar, not on linking it to a dynamic treebank. They suggested creating the documentation in the same file along with the grammar, in the style of literate programming. This is an attractive approach, especially for grammars that change constantly. However, we prefer the flexibility of combining different knowledge sources (the grammar, treebank and linguistic description, in addition to external resources). The Montage project (Bender et al., 2004) aims to develop a suite of software whose primary audience is field linguists working"
I05-6004,1991.mtsummit-papers.16,0,0.00985388,"y stored in the database. Rather, it is dynamically compiled from the database together with a lexicon database, one of the component databases explained below, when triggered by a user query. User queries are words like ni. 34 – TODOs (3ciii) Links to other dictionaries This information helps us to compare our grammar’s treatment with that of other dictionaries. This comparison would then facilitate understanding of lexical types and extension of the lexicon. We currently link lexical types of our grammar to those of ChaSen (Matsumoto et al., 2000), Juman (Kurohashi and Nagao, 2003), ALTJ/E (Ikehara et al., 1991) and EDICT (Breen, 2004). For example, ga-wo-ni-case-p-lex is linked to ChaSen’s ഥ -ᩰ ഥ -৻ ⥸ (particle-case particle-general), Juman’s ᩰ ഥ  (case particle), and ALT-J/E’s ઃ ዻ ⺆-ᩰ ഥ -ฬ ഥ  ᓟ ធ (adjunct-case particle-noun/particle suffix). Figure 2 shows the document generated from the lexical type database that describes the lexical type, ga-wo-ni-p-lex. 3.2.1 Component Databases To understand the construction process, description of the four databases that feed the lexical type database is in order. These are the grammar database, the treebank database, the lexicon database, and the Othe"
I05-6004,C94-2144,0,0.0514669,"ᩰ ഥ  (case particle), and ALT-J/E’s ઃ ዻ ⺆-ᩰ ഥ -ฬ ഥ  ᓟ ធ (adjunct-case particle-noun/particle suffix). Figure 2 shows the document generated from the lexical type database that describes the lexical type, ga-wo-ni-p-lex. 3.2.1 Component Databases To understand the construction process, description of the four databases that feed the lexical type database is in order. These are the grammar database, the treebank database, the lexicon database, and the OtherLex database. • The grammar database contains the actual implementation of the grammar, written as typed feature structures using TDL (Krieger and Schafer, 1994). Although it contains the whole implementation (lexical types, phrasal types, types for principles and so on), only lexical types are relevant to our task. • The lexicon database gives us mappings between words in the grammar, their orthography, and their lexical types. Thus we can see what words belong to a given lexical type. The data could be stored as TDL, but we use the Postgresql lexdb (Copestake et al., 2004), which simplifies access. 3.2 Method of Database Construction The next question is how to construct such a database. Needless to say, fully manual construction of the database is"
I05-6004,H94-1003,0,0.0438812,"d in the treebank and the computational grammar understandable to humans. Also, some tools they use are used in our project as well. Consequently, their process of grammatical description and documentation looks quite similar to ours. The difference is that their target is underdocumented languages whose grammatical knowledge has so far not been made clear enough, while we target a familiar language, Japanese, that is well understood but whose computational implementation is so large and complex as to be difficult to fully comprehend. Another notable related work is the COMLEX syntax project (Macleod et al., 1994). Their goal is to create a moderately-broad-coverage lexicon recording the syntactic features of English words 6 Future Work We are currently experimenting with moving some of the information (in particular the type name and criteria) into the actual grammar files, in the same way as Dini and Mazzini (1997). This would make it easier to keep the information in sync with the actual grammar. We have discussed the motivation, contents and construction of the lexical type database. We plan to evaluate the database (i) by measuring treebank inter-annotator agreement and (ii) by evaluating the cove"
I05-6004,W04-1901,1,0.890717,"Missing"
I05-6004,C04-1193,1,0.897915,"Missing"
I05-6004,W04-2209,0,0.0286046,"it is dynamically compiled from the database together with a lexicon database, one of the component databases explained below, when triggered by a user query. User queries are words like ni. 34 – TODOs (3ciii) Links to other dictionaries This information helps us to compare our grammar’s treatment with that of other dictionaries. This comparison would then facilitate understanding of lexical types and extension of the lexicon. We currently link lexical types of our grammar to those of ChaSen (Matsumoto et al., 2000), Juman (Kurohashi and Nagao, 2003), ALTJ/E (Ikehara et al., 1991) and EDICT (Breen, 2004). For example, ga-wo-ni-case-p-lex is linked to ChaSen’s ഥ -ᩰ ഥ -৻ ⥸ (particle-case particle-general), Juman’s ᩰ ഥ  (case particle), and ALT-J/E’s ઃ ዻ ⺆-ᩰ ഥ -ฬ ഥ  ᓟ ធ (adjunct-case particle-noun/particle suffix). Figure 2 shows the document generated from the lexical type database that describes the lexical type, ga-wo-ni-p-lex. 3.2.1 Component Databases To understand the construction process, description of the four databases that feed the lexical type database is in order. These are the grammar database, the treebank database, the lexicon database, and the OtherLex database. • The gra"
I05-6004,W02-1210,1,0.903948,"moto@pine.kuee.kyoto-u.ac.jp ∗ {takaaki,bond}@cslab.kecl.ntt.co.jp § siegel@dfki.de Abstract multiple people, often in different locations, participate in a development activity, and because deep linguistic treebanks and grammars are complicated by nature. Thus, it is often the case that developers lose sight of the current state of the treebank and grammar, resulting in inconsistency. We have constructed a linguistically enriched treebank named ‘Hinoki’ (Bond et al., 2004a), which is based on the same framework as the Redwoods treebank (Oepen et al., 2002) and uses the Japanese grammar JACY (Siegel and Bender, 2002) to construct the treebank. 1 In the construction process, we have also encountered the problem just mentioned. We are aiming to resolve this problem, which we expect many other project groups that are constructing detailed linguistic treebanks have encountered. Our strategy is to take a “snapshot” of one important aspect of the treebank and grammar for each development cycle. To be more precise, we extract information about lexical items that are being used in treebanking from the treebank and grammar and convert it into an electronically accesible structured database (the lexical-type databa"
I05-6004,callmeier-etal-2004-deepthought,1,0.822778,"Missing"
I05-6004,copestake-etal-2004-lexicon,1,0.85346,"abase, the lexicon database, and the OtherLex database. • The grammar database contains the actual implementation of the grammar, written as typed feature structures using TDL (Krieger and Schafer, 1994). Although it contains the whole implementation (lexical types, phrasal types, types for principles and so on), only lexical types are relevant to our task. • The lexicon database gives us mappings between words in the grammar, their orthography, and their lexical types. Thus we can see what words belong to a given lexical type. The data could be stored as TDL, but we use the Postgresql lexdb (Copestake et al., 2004), which simplifies access. 3.2 Method of Database Construction The next question is how to construct such a database. Needless to say, fully manual construction of the database is not realistic, since there are about 300 lexical types and more than 30,000 words in our grammar. In addition, we assume that we will refer to the database each time we annotate parser outputs to build the treebank and that we develop the grammar based on the treebanking result. Thus the database construction process must be quick enough not to delay the treebanking and grammar development cycles. To meet the require"
I08-2108,P01-1004,1,0.808695,"ally expensive. We thus adopt a cheaper scoring mechanism which normalises relative to the length of w and di,j , but ignores the length of substring matches. Namely, we use the Dice coefficient. 4.2 Tokenisation Tokenisation is particularly important in Japanese because it is a non-segmenting language with a logographic orthography (kanji). As such, we can chose to either word tokenise via a word splitter such as ChaSen, or character tokenise. Character and word tokenisation have been compared in the context of Japanese information retrieval (Fujii and Croft, 1993) and translation retrieval (Baldwin, 2001), and in both cases, characters have been found to be the superior representation overall. Orthogonal to the question of whether to tokenise into words or characters, we adopt an n-gram segment representation, in the form of simple unigrams and simple bigrams. In the case of word tokenisation and simple bigrams, e.g., example (1) would be represented as { おとなしい犬 , 犬を , を飼いたい }. 4.3 Extended Glosses The main direction in which Banerjee and Pedersen (2002) successfully extended the Lesk algorithm was in including hierarchically-adjacent glosses (i.e. hyponyms and hypernyms). We take this a step"
I08-2108,J98-1006,0,0.0481197,"is applicable to all-words with minimal effort. Banerjee and Pedersen (2002) extended the Lesk method for WordNetbased WSD tasks, to include hierarchical data from the WordNet ontology (Fellbaum, 1998). They observed that the hierarchical relations significantly enhance the basic model. Both these methods will be described extensively in Section 3.1, as our approach is based on them. Other notable unsupervised and semi-supervised approaches are those of McCarthy et al. (2004), who combine ontological relations and untagged corpora to automatically rank word senses in relation to a corpus, and Leacock et al. (1998) who use untagged data to build sense-tagged data automatically based on monosemous words. Parallel corpora have also been used to avoid the need for hand-tagged data, e.g. by Chan and Ng (2005). 3 Background As background to our work, we first describe the basic and extended Lesk algorithms that form the core of our approach. Then we present the Lexeed lexical resource we have used in our experiments, and finally we outline aspects of Japanese relevant for this work. 3.1 Basic and Extended Lesk The original Lesk algorithm (Lesk, 1986) performs WSD by calculating the relative word overlap betw"
I08-2108,P04-1036,0,0.226288,"l definitions. In our experiments, we will make clear when hand-tagged sense information is being used. Unsupervised methods rely on different knowledge sources to build their models. Primarily the following types of lexical resources have been used for WSD: MRDs, lexical ontologies, and untagged corpora (monolingual corpora, second language corpora, and parallel corpora). Although early approaches focused on exploiting a single resource (Lesk, 1986), recent trends show the benefits of combining different knowledge sources, such as hierarchical relations from an ontology and untagged corpora (McCarthy et al., 2004). In this summary, we will focus on a few representative systems that make use of different resources, noting that this is an area of very active research which we cannot do true justice to within the confines of this paper. The Lesk method (Lesk, 1986) is an MRD-based system that relies on counting the overlap between the words in the target context and the dictionary definitions of the senses. In spite of its simplicity, it has been shown to be a hard baseline for unsupervised methods in Senseval, and it is applicable to all-words with minimal effort. Banerjee and Pedersen (2002) extended th"
I08-2108,W03-2408,0,0.0276544,"o the knowledge sources they use to build their models. A top-level distinction is made between supervised and unsupervised systems. The former rely on training instances that have been hand-tagged, while the latter rely on other types of knowledge, such as lexical databases or untagged corpora. The Senseval evaluation tracks have shown that supervised systems perform better when sufficient training data is available, but they do not scale well to all words in context. This is known as the knowledge acquisition bottleneck, and is the main motivation behind research on unsupervised techniques (Mihalcea and Chklovski, 2003). In this paper, we aim to exploit an existing lexical resource to build an all-words Japanese word-sense disambiguator. The resource in question is the Lexeed Sensebank (Tanaka et al., 2006) and consists of the 28,000 most familiar words of Japanese, each of which has one or more basic senses. The senses take the form of a dictionary definition composed from the closed vocabulary of the 28,000 words contained in the dictionary, each of which is further manually sense annotated according to the Lexeed sense inventory. Lexeed also has a semi-automatically constructed ontology. Through the Lexee"
I08-2108,shirai-2002-construction,0,0.48783,"the POS tag of the target word should match the word class of the word sense, and this provides a coarse-grained filter for discriminating homographs with different word classes. We also experiment with a stop word-based filter which ignores a closed set of 18 lexicographic markers commonly found in definitions (e.g. 略 [ryaku] “an abbreviation for ...”), in line with those used by Nichols et al. (2005) in inducing the ontology. 5 Evaluation We evaluate our various extensions over two datasets: (1) the example sentences in the Lexeed sensebank, and (2) the Senseval-2 Japanese dictionary task (Shirai, 2002). All results below are reported in terms of simple precision, following the conventions of Senseval evaluations. For all experiments, precision and recall are identical as our systems have full coverage. For the two datasets, we use two baselines: a random baseline and the first-sense baseline. Note that the first-sense baseline has been shown to be hard to beat for unsupervised systems (McCarthy et al., 2004), and it is considered supervised when, as in this case, the first-sense is the most frequent sense from hand-tagged corpora. 5.1 Lexeed Example Sentences The goal of these experiments i"
I08-2108,W06-0608,1,0.912613,"hile the latter rely on other types of knowledge, such as lexical databases or untagged corpora. The Senseval evaluation tracks have shown that supervised systems perform better when sufficient training data is available, but they do not scale well to all words in context. This is known as the knowledge acquisition bottleneck, and is the main motivation behind research on unsupervised techniques (Mihalcea and Chklovski, 2003). In this paper, we aim to exploit an existing lexical resource to build an all-words Japanese word-sense disambiguator. The resource in question is the Lexeed Sensebank (Tanaka et al., 2006) and consists of the 28,000 most familiar words of Japanese, each of which has one or more basic senses. The senses take the form of a dictionary definition composed from the closed vocabulary of the 28,000 words contained in the dictionary, each of which is further manually sense annotated according to the Lexeed sense inventory. Lexeed also has a semi-automatically constructed ontology. Through the Lexeed sensebank, we investigate a number of areas of general interest to the WSD community. First, we test extensions of the Lesk algorithm (Lesk, 1986) over Japanese, focusing specifically on th"
isahara-etal-2008-development,vossen-etal-2008-kyoto,1,\N,Missing
isahara-etal-2008-development,kanzaki-etal-2008-extraction,1,\N,Missing
isahara-etal-2008-development,kaji-watanabe-2006-automatic,0,\N,Missing
kanzaki-etal-2008-extraction,isahara-etal-2008-development,1,\N,Missing
kanzaki-etal-2008-extraction,C92-2082,0,\N,Missing
kanzaki-etal-2008-extraction,P99-1016,0,\N,Missing
kanzaki-etal-2008-extraction,P99-1008,0,\N,Missing
kanzaki-etal-2008-extraction,bond-etal-2008-boot,1,\N,Missing
kanzaki-etal-2008-extraction,N04-1041,0,\N,Missing
L16-1386,2016.gwc-1.9,1,0.821562,"gy, since they are used as domain specific ontologies. Additionally, other supporting ontologies have been added, such as GeoNames for the named entities; PROTON as an upper ontology; SKOS as a mapper between ontologies and terminological lexicons; Dublin Core as a metadata ontology. Also, for the purposes of search, Web Interface Querying EUCases Linking Platform was designed. For its Web Interface, the EUCases Linking Platform relies on a customized version of the GraphDB Workbench27 , developed by Ontotext AD. 5.2. Wordnet Interlingual Index (ILI) A recent development (Vossen et al., 2016; Bond et al., 2016) has been the adoption of LLOD technology by the wordnet community, with a new plan that uses LLOD as the basic mechanism for the creation of links between wordnets in different languages. This Collaborative InterLingual Index enables wordnets to share and link their resources for concepts lexicalized in any of the group’s languages. This was supported directly by a workshop at the 2016 Global WordNet Conference and will lead to the adoption of LLOD technology by a new community. In addition, the open multilingual wordnet (Bond et al., 2014) provides all open wordnets for download using the le"
L16-1386,calzolari-etal-2012-lre,0,0.0712075,"Missing"
L16-1386,ehrmann-etal-2014-representing,1,0.804428,"lable by attempting to download it and discarding all resources that are no longer available. We have attempted to notify the authors of resources that no longer meet the criteria for inclusion in the cloud. However, our experience has been that this did not motivate many authors to update their resources. 2.5. Vocabularies The Linguistic Linked Open Data Cloud has grown significantly in the last few years and most notably, unlike the non-linguistic LOD Cloud, is not centered around one nucleus but instead has used many different vocabularies and datasets to link to. Among these are BabelNet (Ehrmann et al., 2014), LexInfo (Cimiano et al., 2011), and Lexvo (de Melo, 2015). In addition, a number of new vocabularies have emerged including the OntoLex model,13 the NLP Interchange format NIF (Hellmann et al., 2013), the WordNet Interlingual Index (Sect. 5.2.), and the FrameBase schema (Rouces et al., 2015a) (Sect. 5.3.). These vocabularies have increased the power of linked data to represent the complete spectrum of language resources and show that new resources can be created that use the power of linked data to link across different types of languages resources, such as terminologies and dictionaries (Si"
L16-1386,federmann-etal-2012-meta,0,0.0601026,"Missing"
L16-1386,W15-4205,1,0.920405,"not necessarily created for this purpose, e.g., large collections of texts such as news articles, terminological or encyclopedic and general-purpose knowledge bases such as DBpedia (Bizer et al., 2009), or metadata collections. 2.2. Infrastructure and Metadata The OWLG provides guidelines to data publishers on how to include their resources in the LLOD cloud.6 The cloud diagram is currently generated from metadata maintained at DataHub7 and hence contains only resources described in DataHub. An alternative metadata repository specialized for linguistic resources is under development: Linghub (McCrae et al., 2015a).8 It aims to provide a search engine and index for linguistic resources and attempts to harmonize metadata from a number of different sources, including Metashare (Federmann et al., 2012), CLARIN VLO (Van Uytvanck et al., 2012), DataHub and LRE Map (Calzolari et al., 2012). It will soon replace DataHub in the generation of the cloud diagram. LingHub, 4 http://lod2.eu/ http://qtleap.eu/ 6 http://wiki.okfn.org/Working_Groups/ Linguistics/How_to_contribute 7 http://datahub.io 8 http://linghub.org 5 Datasets Links 28 53 103 126 128 41 78 167 203 209 February 2012 September 2013 November 2014 Ma"
L16-1386,W15-4201,0,0.02663,"Missing"
L16-1386,W15-4207,1,0.813122,"4), LexInfo (Cimiano et al., 2011), and Lexvo (de Melo, 2015). In addition, a number of new vocabularies have emerged including the OntoLex model,13 the NLP Interchange format NIF (Hellmann et al., 2013), the WordNet Interlingual Index (Sect. 5.2.), and the FrameBase schema (Rouces et al., 2015a) (Sect. 5.3.). These vocabularies have increased the power of linked data to represent the complete spectrum of language resources and show that new resources can be created that use the power of linked data to link across different types of languages resources, such as terminologies and dictionaries (Siemoneit et al., 2015) and corpora and dictionaries (McGovern et al., 2015). 3. OWLG members have been very active in promoting the development and adoption of linguistic linked data, which had an effect not only in the growth of the LLOD cloud but in the development of representation models, guidelines, and best practices. These activities have been developed in the context of a number of W3C groups and projects, as it is detailed in the rest of this section. 13 12 http://lodvader.aksw.org/ Other Community Group Efforts http://cimiano.github.io/ontolex/ specification.html 2437 3.1. OntoLex 8. LLOD aware services 1"
L16-1386,van-uytvanck-etal-2012-semantic,0,0.0695217,"Missing"
L16-1685,P13-1133,1,0.898727,"h non-referential, interjections and classifiers possess interesting semantics features that can be well captured by lexical resources like wordnets. In this paper, we will further motivate our decision to include non-referential concepts in wordnets and give an account of the current state of this expansion. Keywords: Non-Referential Concepts, Wordnet Interjections, Classifiers, Exclamatory Pronouns 1. Introduction In this paper we motivate and describe our ongoing efforts to expand the Open Multilingual Wordnet (OMW)’s coverage by introducing non-referential concepts to wordnet hierarchies (Bond and Foster, 2013). Namely, the introduction of interjections as a language independent class of concepts, and the introduction of numeral classifiers as a language specific class of concepts. This expansion has mainly been motivated by and done in parallel with the ongoing semantic annotation of the NTUMultilingual Corpus: NTU-MC (Tan and Bond, 2011). The NTU-MC is a multilingual, multi-genre parallel corpus that is currently being tagged with the Princetong Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril"
L16-1685,C00-1014,1,0.596162,"and authoritative native Chinese grammar, splits CLs into nine different classes. Cheng and Sybesma (1998) draw a binary distinction between count-classifiers and massifiers. Erbaugh (2002) splits CLs into three categories (measure, collective and sortal classifiers). Measure classifiers describe quantities (e.g. ‘a bottle of’, ‘a mouthful of’), collective classifiers describe arrangement of objects (‘a row of’, ‘a bunch of’), and sortal classifiers refer to a particular noun category (which can be defined, for example, by shape). In our analysis, we follow the taxonomy previously proposed in Bond and Paik (2000), distinguishing between five major classes of classifiers: sortal (which classify the kind of the noun phrase they quantify); event (which are used to quantify events); mensural (which are used to measure the amount of some property); group (which refer to a collection of members); and taxonomic (which force the noun phrase to be interpreted as a generic kind). 三 台 电脑 s¯an t´ai di`annˇao 3 CL computer “three computers” (6) languages (e.g. Chinese or Japanese), classifiers can be used as anaphoric references to elided nouns. This means that in (4) and (5), the words for dog and computer can be"
L16-1685,W10-3409,0,0.030367,"(2016) to provide an automatic mapping between classifiers and other wordnet concepts. There is existing data that can be easily imported to Chinese Open Wordnet, and we will be looking into repeating the method for the other languages (i.e. Japanese and Indonesian). These links can be immensely useful for second language learning, in tasks like machine translation, or any other domain where the knowledge of which classifier can be used with a specific noun or verb can be of value. So far we have focused specifically on sortal classifiers. For Chinese, we started from the taxonomy provided by Gao (2010) to select sortal classifiers. For Japanese and Indonesian we worked from existing lists collated from corpora (Mok et al., 2012). Our initial efforts include the inclusion of 71 Chinese sortal classifiers in the Chinese Open Wordnet, 47 Japanese sortal classifiers in the Japanese Wordnet, and 30 Indonesian sortal classifiers in Wordnet Bahasa.  80000005-x 4327 4. Conclusions and Future Work In this paper we have motivated and described the introduction of two non-propositional classes of words into wordnet. We introduced a new part-of-speech ’x’ to be used by both interjections and classifie"
L16-1685,isahara-etal-2008-development,1,0.902006,"MW)’s coverage by introducing non-referential concepts to wordnet hierarchies (Bond and Foster, 2013). Namely, the introduction of interjections as a language independent class of concepts, and the introduction of numeral classifiers as a language specific class of concepts. This expansion has mainly been motivated by and done in parallel with the ongoing semantic annotation of the NTUMultilingual Corpus: NTU-MC (Tan and Bond, 2011). The NTU-MC is a multilingual, multi-genre parallel corpus that is currently being tagged with the Princetong Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond, 2011) through the OMW. The original design of PWN, which the other three wordnet projects are based on, includes only contentful/referential open class words: nouns, verbs, adjectives and adverbs. These classes of concepts are related by a coherent set of semantic relations (hypernmy, antonymy, meronymy, . . . ) within this lexical resource, and can be used to sense tag the most part of any given corpus. Most wordnet projects follow PWN, hence restricting the classes of words available for"
L16-1685,Y11-1027,1,0.895942,"Missing"
L16-1685,2016.gwc-1.36,1,0.727989,"emplifies  classifies   classifies classifies   振 furi   a sortal classifier used for weapons with  a blade, such as knifes, swords or dag-   gers   06308436-n (classifier)   03624134-n (knife)   04373894-n (sword)  03158885-n (dagger)   ind-lemmas  definition    exemplifies  classifies   classifies classifies  utas   a sortal classifier used with threadlike  objects, such as threads, ropes or wires    06308436-n (classifier)   04426788-n (thread)   04108268-n (rope)  04594218-n (wire) 80000004-x We plan to adapt the work presented in Morgado da Costa et al. (2016) to provide an automatic mapping between classifiers and other wordnet concepts. There is existing data that can be easily imported to Chinese Open Wordnet, and we will be looking into repeating the method for the other languages (i.e. Japanese and Indonesian). These links can be immensely useful for second language learning, in tasks like machine translation, or any other domain where the knowledge of which classifier can be used with a specific noun or verb can be of value. So far we have focused specifically on sortal classifiers. For Chinese, we started from the taxonomy provided by Gao (2"
L16-1685,W15-1612,0,0.0684518,"Missing"
L16-1685,Y11-1038,1,0.837168,"oncepts, Wordnet Interjections, Classifiers, Exclamatory Pronouns 1. Introduction In this paper we motivate and describe our ongoing efforts to expand the Open Multilingual Wordnet (OMW)’s coverage by introducing non-referential concepts to wordnet hierarchies (Bond and Foster, 2013). Namely, the introduction of interjections as a language independent class of concepts, and the introduction of numeral classifiers as a language specific class of concepts. This expansion has mainly been motivated by and done in parallel with the ongoing semantic annotation of the NTUMultilingual Corpus: NTU-MC (Tan and Bond, 2011). The NTU-MC is a multilingual, multi-genre parallel corpus that is currently being tagged with the Princetong Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond, 2011) through the OMW. The original design of PWN, which the other three wordnet projects are based on, includes only contentful/referential open class words: nouns, verbs, adjectives and adverbs. These classes of concepts are related by a coherent set of semantic relations (hypernmy, antonymy, meronymy, . ."
L16-1685,W13-4302,1,0.851299,"cepts to wordnet hierarchies (Bond and Foster, 2013). Namely, the introduction of interjections as a language independent class of concepts, and the introduction of numeral classifiers as a language specific class of concepts. This expansion has mainly been motivated by and done in parallel with the ongoing semantic annotation of the NTUMultilingual Corpus: NTU-MC (Tan and Bond, 2011). The NTU-MC is a multilingual, multi-genre parallel corpus that is currently being tagged with the Princetong Wordnet, PWN (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril Hirfana, Suerya and Bond, 2011) through the OMW. The original design of PWN, which the other three wordnet projects are based on, includes only contentful/referential open class words: nouns, verbs, adjectives and adverbs. These classes of concepts are related by a coherent set of semantic relations (hypernmy, antonymy, meronymy, . . . ) within this lexical resource, and can be used to sense tag the most part of any given corpus. Most wordnet projects follow PWN, hence restricting the classes of words available for annotation tasks using these resources. During"
P03-1059,W03-1010,1,0.830295,"Missing"
P03-1059,C02-1052,1,0.742646,"Missing"
P03-1059,C94-1002,1,0.810442,"Missing"
P03-1059,briscoe-carroll-2002-robust,0,0.00981866,"yle regular expression over Penn POS tags: (PDT)* DT (RB|JJ[RS]?|NNS?)* NNS? [ˆN]. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjong Kim Sang and Buchholz, 2000) chunkconverted versions of the full Brown and WSJ corpora. For the NP-internal features (e.g. determiners, head number), we used the noun chunks directly, or applied POS-based templates locally within noun chunks. For inter-chunk features (e.g. subject–verb agreement), we looked at only adjacent chunk pairs so as to maintain a high level of precision. As the full parser, we used RASP (Briscoe and Carroll, 2002), a robust tag sequence grammarbased parser. RASP’s grammatical relation output function provides the phrase structure in the form of lemmatised dependency tuples, from which it is possible to read off the feature information. RASP has the advantage that recall is high, although precision is potentially lower than chunking or tagging as the parser is forced into resolving phrase attachment ambiguities and committing to a single phrase structure analysis. Although all three systems map onto an identical feature space, the feature vectors generated for a given target noun diverge in content due"
P03-1059,1991.mtsummit-papers.16,0,0.0175845,"and Japanese, do not mark countability, which means that the choice of countability will be largely the responsibility of the generation component (Bond, 2001). In addition, knowledge of countability obtained from examples of use is an important resource for dictionary construction. In this paper, we learn the countability preferences of English nouns from unannotated corpora. We first annotate them automatically, and then train classifiers using a set of gold standard data, taken from COMLEX (Grishman et al., 1998) and the transfer dictionaries used by the machine translation system ALT-J/E (Ikehara et al., 1991). The classifiers and their training are described in more detail in Baldwin and Bond (2003). These are then run over the corpus to extract nouns as members of four classes — countable: dog; uncountable: furniture; bipartite: [pair of] scissors and plural only: clothes. We first discuss countability in more detail (§ 2). Then we present the lexical resources used in our experiment (§ 3). Next, we describe the learning process (§ 4). We then present our results and evaluation (§ 5). Finally, we discuss the theoretical and practical implications (§ 6). 2 Background Grammatical countability is mo"
P03-1059,P96-1004,0,0.418037,"Missing"
P03-1059,N01-1006,0,0.0164125,"P and PP boundaries, determining subject–verb agreement and deconstructing NPs in order to recover conjuncts and noun-modifier data. We adopt three approaches. First, we use part-of-speech (POS) tagged data and POS-based templates to extract out the necessary information. Second, we use chunk data to determine NP and PP boundaries, and mediumrecall chunk adjacency templates to recover interphrasal dependency. Third, we fully parse the data and simply read off all necessary data from the dependency output. With the POS extraction method, we first Penntagged the BNC using an fnTBL-based tagger (Ngai and Florian, 2001), training over the Brown and WSJ corpora with some spelling, number and hyphenation normalisation. We then lemmatised this data using a version of morph (Minnen et al., 2001) customised to the Penn POS tagset. Finally, we implemented a range of high-precision, low-recall POS-based templates to extract out the features from the processed data. For example, NPs are in many cases recoverable with the following Perl-style regular expression over Penn POS tags: (PDT)* DT (RB|JJ[RS]?|NNS?)* NNS? [ˆN]. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjon"
P03-1059,J00-4004,0,0.0305492,"Missing"
P03-1059,W00-0726,0,0.0249334,"ning over the Brown and WSJ corpora with some spelling, number and hyphenation normalisation. We then lemmatised this data using a version of morph (Minnen et al., 2001) customised to the Penn POS tagset. Finally, we implemented a range of high-precision, low-recall POS-based templates to extract out the features from the processed data. For example, NPs are in many cases recoverable with the following Perl-style regular expression over Penn POS tags: (PDT)* DT (RB|JJ[RS]?|NNS?)* NNS? [ˆN]. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjong Kim Sang and Buchholz, 2000) chunkconverted versions of the full Brown and WSJ corpora. For the NP-internal features (e.g. determiners, head number), we used the noun chunks directly, or applied POS-based templates locally within noun chunks. For inter-chunk features (e.g. subject–verb agreement), we looked at only adjacent chunk pairs so as to maintain a high level of precision. As the full parser, we used RASP (Briscoe and Carroll, 2002), a robust tag sequence grammarbased parser. RASP’s grammatical relation output function provides the phrase structure in the form of lemmatised dependency tuples, from which it is poss"
P05-1041,H91-1060,0,0.0486623,"Missing"
P05-1041,brants-2000-inter,0,0.0246506,"When broken down by pairs of annotators and sets of 1,000 items each, which have been annotated in strict sequential order, F scores in Table 2 confirm that: (a) inter-annotator agreement is stable, all three annotators appear to have performed equally (well); (b) with growing experience, there is a slight increase in F scores over time, particularly when taking into account that set E exhibits a noticeably higher average ambiguity rate (1208 parses per item) than set D (820 average parses); and (c) Hinoki inter-annotator agreement compares favorably to results reported for the German NeGra (Brants, 2000) and Spanish Cast3LB (Civit et al., 2003) treebanks, both of which used manual mark-up seeded from automated POS tagging and chunking. Compared to the 92.43 per cent labeled F score reported by Brants (2000), Hinoki achieves an ‘error’ (i.e. disagreement) rate of less than half, even though our structures are richer in information and should probably be contrasted with the ‘edge label’ F score for NeGra, which is 88.53 per cent. At the same time, it is unknown to what extent results are influenced by differences in text genre, i.e. average sentence length of our dictionary definitions is notic"
P05-1041,W97-1502,0,0.318075,"panese and building an ontology from the results. Arguably the most common method in building a treebank still is manual annotation, annotators (often linguistics students) marking up linguistic properties of words and phrases. In some semi-automated treebank efforts, annotators are aided by POS taggers or phrase-level chunkers, which can propose mark-up for manual confirmation, revision, or extension. As computational grammars and parsers have increased in coverage and accuracy, an alternate approach has become feasible, in which utterances are parsed and the annotator selects the best parse Carter (1997); Oepen et al. (2002) from the full analyses derived by the grammar. We adopted the latter approach. There were four main reasons. The first was that we wanted to develop a precise broad-coverage grammar in tandem with the treebank, as part of our research into natural language understanding. Treebanking the output of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, ma"
P05-1041,C02-2025,1,0.878669,"ding an ontology from the results. Arguably the most common method in building a treebank still is manual annotation, annotators (often linguistics students) marking up linguistic properties of words and phrases. In some semi-automated treebank efforts, annotators are aided by POS taggers or phrase-level chunkers, which can propose mark-up for manual confirmation, revision, or extension. As computational grammars and parsers have increased in coverage and accuracy, an alternate approach has become feasible, in which utterances are parsed and the annotator selects the best parse Carter (1997); Oepen et al. (2002) from the full analyses derived by the grammar. We adopted the latter approach. There were four main reasons. The first was that we wanted to develop a precise broad-coverage grammar in tandem with the treebank, as part of our research into natural language understanding. Treebanking the output of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, marking not only depend"
P05-1041,W02-1210,0,0.0124955,"sons. The first was that we wanted to develop a precise broad-coverage grammar in tandem with the treebank, as part of our research into natural language understanding. Treebanking the output of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. By using a Japanese grammar (JACY: Siegel and Bender, 2002) based on a monostratal theory of grammar (HPSG: Pollard and Sag, 1994) we could simultaneously annotate syntactic and semantic structure without overburdening the annota330 Proceedings of the 43rd Annual Meeting of the ACL, pages 330–337, c Ann Arbor, June 2005. 2005 Association for Computational Linguistics tor. The third reason was that we expected the use of the grammar to aid in enforcing consistency — at the very least all sentences annotated are guaranteed to have well-formed parses. The flip side to this is that any sentences which the parser cannot parse remain unannotated, at least u"
P06-4017,I05-6004,1,0.846759,"Missing"
P06-4017,C02-2025,0,0.110429,"Missing"
P06-4017,W06-0608,1,0.749783,"we can specialize the relations to relations between senses, rather than just words: hhypernym: doraib¯a 3 , kurabu3 i. 3.2 Sense Annotation All open class words were annotated with their sense by five annotators. Inter-annotator agreement ranges from 0.79 to 0.83. For example, the word クラ ブ kurabu “club” is tagged as sense 3 in the definition sentence for driver3 , with the meaning “golf-club”. For each sense, we calculate the entropy and per sense probabilities over four corpora: the Lexeed definition and example sentences and Newspaper text from the Kyoto University and Senseval 2 corpora (Tanaka et al., 2006). Once we have synonym/hypernym relations, we can link the lexicon to other lexical resources. For example, for the manually constructed Japanese ontology Goi-Taikei (Ikehara et al., 1997) we link to its semantic classes by the following heuristic: look up the semantic classes C for both the headword (wi ) and hypernym(s) (wg ). If at least one of the index word’s classes is subsumed by at least one of the genus’ classes, then we consider the relationship confirmed. To link cross-linguistically, we look up the headwords and hypernym(s) in a translation lexicon and compare the set of translatio"
P06-4017,P05-1041,1,\N,Missing
P09-2028,dickinson-lee-2008-detecting,0,0.0506974,"Missing"
P09-2028,P04-1057,0,0.0784226,"Missing"
P09-2028,2008.iwslt-papers.2,1,\N,Missing
P12-2025,D08-1092,0,0.0239557,"sambiguated by the Japanese. 125 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 125–129, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics Way (2008) automatically generate parallel treebanks for training of statistical machine translation (SMT) systems through sub-tree alignment. We do not aim to carry out the complete treebanking process, but to optimize speed and precision of manual creation of high-quality treebanks. Wu (1997) and others have tried to simultaneously learn grammars from bilingual texts. Burkett and Klein (2008) induce node-alignments of syntactic trees with a log-linear model, in order to guide bilingual parsing. Chen et al. (2011) translate an existing treebank using an SMT system and then project parse results from the treebank to the other language. This results in a very noisy treebank, that they then clean. These approaches align at the syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic representation as the appropriate level for cross-lingual processing. We compare semantic sub-structures, as t"
P12-2025,D11-1007,0,0.0178726,"25–129, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics Way (2008) automatically generate parallel treebanks for training of statistical machine translation (SMT) systems through sub-tree alignment. We do not aim to carry out the complete treebanking process, but to optimize speed and precision of manual creation of high-quality treebanks. Wu (1997) and others have tried to simultaneously learn grammars from bilingual texts. Burkett and Klein (2008) induce node-alignments of syntactic trees with a log-linear model, in order to guide bilingual parsing. Chen et al. (2011) translate an existing treebank using an SMT system and then project parse results from the treebank to the other language. This results in a very noisy treebank, that they then clean. These approaches align at the syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic representation as the appropriate level for cross-lingual processing. We compare semantic sub-structures, as those are more straightforwardly comparable across different languages. As a consequence, our system is applicable to any co"
P12-2025,W11-2927,0,0.0528405,"Missing"
P12-2025,W11-0814,1,0.876162,"Missing"
P12-2025,J97-3002,0,0.0142152,"it has four, as they can be either plural or the androgynous singular, this is also disambiguated by the Japanese. 125 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 125–129, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics Way (2008) automatically generate parallel treebanks for training of statistical machine translation (SMT) systems through sub-tree alignment. We do not aim to carry out the complete treebanking process, but to optimize speed and precision of manual creation of high-quality treebanks. Wu (1997) and others have tried to simultaneously learn grammars from bilingual texts. Burkett and Klein (2008) induce node-alignments of syntactic trees with a log-linear model, in order to guide bilingual parsing. Chen et al. (2011) translate an existing treebank using an SMT system and then project parse results from the treebank to the other language. This results in a very noisy treebank, that they then clean. These approaches align at the syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic represen"
P12-2025,zhang-kordoni-2008-robust,0,0.0525602,"Missing"
P12-2025,C08-1139,0,0.0354582,"Missing"
P13-1133,hanoka-sagot-2012-wordnet,0,0.0211857,"ics of a language or languages to be able to access wordnets for those languages with a minimum of legal and technical barriers. In practice this means making it possible to access multiple wordnets with a common interface. We also use sources of semi-structured data that have minimal legal restrictions to automatically extend existing freely available wordnets and to create additional wordnets which can be added to our open wordnet grid. Previous studies have leveraged multiple wordnets and Wiktionary (Wikimedia, 2013) to extend existing wordnets or create new ones (de Melo and Weikum, 2009; Hanoka and Sagot, 2012). These studies passed over the valuable sense groupings of translations within Wiktionary and merely used Wiktionary as a source of translations that were not disambiguated according to sense. The present study built and extended wordnets by directly linking Wiktionary senses to WordNet senses. Meyer and Gurevych (2011) demonstrated the ability to automatically identify many matching senses in Wiktionary and WordNet based on the similarity of monolingual features. Our study combines monolingual features with the disambiguating power of multiple languages. In addition to differences in linking"
P13-1133,Y11-1027,1,0.366005,"Missing"
P13-1133,C10-2097,0,0.0108932,"eyed wordnet licenses in 2011, six projects have newly released data un1353 der open licenses and eight projects have updated their data. Our combined wordnet includes English (Fellbaum, 1998); Albanian (Ruci, 2008); Arabic (Black et al., 2006); Chinese (Huang et al., 2010); Danish (Pedersen et al., 2009); Finnish (Lind´en and Carlson., 2010); French (Sagot and Fiˇser, 2008); Hebrew (Ordan and Wintner, 2007); Indonesian and Malaysian (Nurril Hirfana et al., 2011); Italian (Pianta et al., 2002); Japanese (Isahara et al., 2008); Norwegian (Bokm˚al and Nynorsk: Lars Nygaard 2012, p.c.); Persian (Montazery and Faili, 2010); Portuguese (de Paiva and Rademaker, 2012); Polish (Piasecki et al., 2009); Thai (Thoongsup et al., 2009) and Basque, Catalan, Galician and Spanish from the Multilingual Common Repository (Gonzalez-Agirre et al., 2012). On our server, the wordnets are all in a shared sqlite database using the schema produced by the Japanese WordNet project (Isahara et al., 2008). The database is based on the logical structure of the Princeton WordNet, with an additional language attribute for lemmas, examples, definitions and senses. It is a single open multilingual resource. When we redistribute the data, ea"
P13-1133,isahara-etal-2008-development,1,\N,Missing
P13-1133,W09-3420,0,\N,Missing
P13-1133,I11-1099,0,\N,Missing
P13-1133,elkateb-etal-2006-building,0,\N,Missing
P13-1133,J08-3010,0,\N,Missing
P15-4002,isahara-etal-2008-development,1,0.869115,"news, and tourism). The corpus started off with monolingual part-of-speech (POS) annotation and crosslingual linking of sentences. We are extending it to include monolingual sense annotation and crosslingual word and concept alignments (Bond et al., 2013). Out of the available languages, Chinese, English, Japanese and Indonesian were chosen for further processing and annotation (due to the availability of lexical and human resources). As part of the annotation, we are also expanding the sense and concept inventory of the wordnets: Princeton Wordnet (PWN: Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril Hirfana et al. 2011) through the Open Multingual Wordnet (Bond and Foster, 2013). 2.2 The Open Multilingual Wordnet The task of semantic annotating a corpus involves the manual (and often automated) disambiguation of words using lexical semantic resources – selecting, for each word, the best match in a pool of available concepts. Among this type of resources, the PWN has, perhaps, attained the greatest visibility. As a resource, a wordnet is simply a huge net of concepts, senses and definitions linked through many"
P15-4002,2005.mtsummit-papers.11,0,0.059073,". A series of undergraduate linguistics students were trained on the tool and annotated the corpus over several years. They also offered extensive qualitative and quantitative feedback on the usage of our system. 1 Introduction The remainder of this paper is arranged as follows. In Section 2 we introduce related work. Section 3 describes the main functionality of our system then we finish with Section 4, which summarizes and discusses our current and future work. Plain text parallel corpora are relatively widely available and widely used in NLP, such as machine translation system development (Koehn, 2005, e.g., ). In contrast, there are very few parallel sense tagged corpora due to the expense of tagging the corpora and creating the sense inventories in multiple languages. The one exception is the translations of English SemCor (Landes et al., 1998) for Italian (Bentivogli and Pianta, 2005), Romanian (Lupu et al., 2005) and Japanese (Bond et al., 2012). Even for this corpus, not all of the original English texts have been translated and tagged, 2 Related Work In this section we introduce the corpus (NTU-MC), the sense inventory (OMW), and a brief overview of currently available tools. 7 Proce"
P15-4002,koeva-etal-2008-chooser,0,0.0298484,"possible tags to chose from: even constrained by the lemma, there may be over 40 tags and the set of tags will very from lemma to lemma. There are only a few annotation tools designed specifically for sense annotation. We were able to find the following: the tools to tag the Hinoki Corpus (Bond et al., 2008), for Japanese, and the Sense Annotation Tool for the American National Corpus (SATANiC: Passonneau et al., 2009), for English. Both of these tools were developed to be used in a monolingual environment, and have not been released. The only open source tool that we could find was Chooser (Koeva et al., 2008), a multi-task annotation tool that was used to tag the Bulgarian Sense Tagged Corpus (Koeva et al., 2006). This tool is open source, language independent and is capable of integrating a wordnet as a sense inventory. Unfortunately, it was not designed to be a web-service which means it is difficult to coordinate the work of multiple users. The NTU-MC (Tan and Bond, 2012) has data available for eight languages from seven language families (Arabic, Chinese, English, Indonesian, Japanese, Korean, Vietnamese and Thai), distributed across four domains (story, essay, news, and tourism). The corpus s"
P15-4002,W04-2710,0,0.111597,"Missing"
P15-4002,baccianella-etal-2010-sentiwordnet,0,0.0180008,"easier to maintain both consistency and quality of the corpus. In the near future we intend to: concept lemma, word, lemma, sentence id and POS, as well as any combination of these fields. Mousing over a word shows its lemma, pos, sense and annotators’ comments (if any), clicking on a word pops up more information about the lemma, pos and sense (such as definitions) that can be clicked for even more information. Further, it is possible to see aligned sentences (for as many languages as selected), and color coded sentiment scores using two freely available sentiment lexicons, the SentiWordNet (Baccianella et al., 2010) and the ML-SentiCon (Cruz et al., 2014) (individually or intersected). Further improvements will allow highlighting cross-lingual word and concept alignments (inspired by Nara: Song and Bond, 2009). 4 • refine the cross-lingual word and concept alignment tool (not shown here) • develop a reporting interface, where the project coordinators can easily review the history of changes committed to the corpus database • add a simple corpus import tool for adding new texts in different languages Summary and Future Work • further develop the corpus search interface, to allow highlighting cross-lingual"
P15-4002,Y11-1027,1,0.911661,"Missing"
P15-4002,W09-2402,0,0.126364,"particular, the number of tags, and the information associated with each tag is very large. Sense tagging for English using the PWN, for example, when unrestricted, defaults at over a hundred thousand possible tags to chose from: even constrained by the lemma, there may be over 40 tags and the set of tags will very from lemma to lemma. There are only a few annotation tools designed specifically for sense annotation. We were able to find the following: the tools to tag the Hinoki Corpus (Bond et al., 2008), for Japanese, and the Sense Annotation Tool for the American National Corpus (SATANiC: Passonneau et al., 2009), for English. Both of these tools were developed to be used in a monolingual environment, and have not been released. The only open source tool that we could find was Chooser (Koeva et al., 2008), a multi-task annotation tool that was used to tag the Bulgarian Sense Tagged Corpus (Koeva et al., 2006). This tool is open source, language independent and is capable of integrating a wordnet as a sense inventory. Unfortunately, it was not designed to be a web-service which means it is difficult to coordinate the work of multiple users. The NTU-MC (Tan and Bond, 2012) has data available for eight l"
P15-4002,W09-3026,1,0.822217,"word shows its lemma, pos, sense and annotators’ comments (if any), clicking on a word pops up more information about the lemma, pos and sense (such as definitions) that can be clicked for even more information. Further, it is possible to see aligned sentences (for as many languages as selected), and color coded sentiment scores using two freely available sentiment lexicons, the SentiWordNet (Baccianella et al., 2010) and the ML-SentiCon (Cruz et al., 2014) (individually or intersected). Further improvements will allow highlighting cross-lingual word and concept alignments (inspired by Nara: Song and Bond, 2009). 4 • refine the cross-lingual word and concept alignment tool (not shown here) • develop a reporting interface, where the project coordinators can easily review the history of changes committed to the corpus database • add a simple corpus import tool for adding new texts in different languages Summary and Future Work • further develop the corpus search interface, to allow highlighting cross-lingual word and concept links We have described the main interfaces and functionality of IMI. It has undergone almost six years of development, and is now a mature annotation platform. The improvement of"
P15-4002,P13-1133,1,0.955981,"l.com, tuananh.ke@gmail.com} Abstract and not all words are tagged in the translated text (typically only those with a corresponding English sense). Semantic annotated parallel corpora, though rare, play an increasingly important role in natural language processing. These corpora provide valuable data for computational tasks like sense-based machine translation and word sense disambiguation, but also to contrastive linguistics and translation studies. In this paper we present the ongoing development of a web-based corpus semantic annotation environment that uses the Open Multilingual Wordnet (Bond and Foster, 2013) as a sense inventory. The system includes interfaces to help coordinating the annotation project and a corpus browsing interface designed specifically to meet the needs of a semantically annotated corpus. The tool was designed to build the NTU-Multilingual Corpus (Tan and Bond, 2012). For the past six years, our tools have been tested and developed in parallel with the semantic annotation of a portion of this corpus in Chinese, English, Japanese and Indonesian. The annotation system is released under an open source license (MIT). In this paper we present IMI, a web-based multilingual semantic"
P15-4002,E12-2021,0,0.0406361,"or Italian (Bentivogli and Pianta, 2005), Romanian (Lupu et al., 2005) and Japanese (Bond et al., 2012). Even for this corpus, not all of the original English texts have been translated and tagged, 2 Related Work In this section we introduce the corpus (NTU-MC), the sense inventory (OMW), and a brief overview of currently available tools. 7 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 7–12, c Beijing, China, July 26-31, 2015. 2015 ACL and AFNLP 2.1 2.3 Other Available Systems The NTU-Multilingual Corpus (NTU-MC) There are many text annotation tools available for research (e.g., Stenetorp et al., 2012). However, sense annotation has some features that differ from most common annotation tasks (such as NE or POS annotation). In particular, the number of tags, and the information associated with each tag is very large. Sense tagging for English using the PWN, for example, when unrestricted, defaults at over a hundred thousand possible tags to chose from: even constrained by the lemma, there may be over 40 tags and the set of tags will very from lemma to lemma. There are only a few annotation tools designed specifically for sense annotation. We were able to find the following: the tools to tag"
P15-4002,W13-4302,1,0.878165,"onolingual part-of-speech (POS) annotation and crosslingual linking of sentences. We are extending it to include monolingual sense annotation and crosslingual word and concept alignments (Bond et al., 2013). Out of the available languages, Chinese, English, Japanese and Indonesian were chosen for further processing and annotation (due to the availability of lexical and human resources). As part of the annotation, we are also expanding the sense and concept inventory of the wordnets: Princeton Wordnet (PWN: Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril Hirfana et al. 2011) through the Open Multingual Wordnet (Bond and Foster, 2013). 2.2 The Open Multilingual Wordnet The task of semantic annotating a corpus involves the manual (and often automated) disambiguation of words using lexical semantic resources – selecting, for each word, the best match in a pool of available concepts. Among this type of resources, the PWN has, perhaps, attained the greatest visibility. As a resource, a wordnet is simply a huge net of concepts, senses and definitions linked through many different types of relations. Because of popular"
P15-4002,W13-2319,1,0.847069,"inventory. Unfortunately, it was not designed to be a web-service which means it is difficult to coordinate the work of multiple users. The NTU-MC (Tan and Bond, 2012) has data available for eight languages from seven language families (Arabic, Chinese, English, Indonesian, Japanese, Korean, Vietnamese and Thai), distributed across four domains (story, essay, news, and tourism). The corpus started off with monolingual part-of-speech (POS) annotation and crosslingual linking of sentences. We are extending it to include monolingual sense annotation and crosslingual word and concept alignments (Bond et al., 2013). Out of the available languages, Chinese, English, Japanese and Indonesian were chosen for further processing and annotation (due to the availability of lexical and human resources). As part of the annotation, we are also expanding the sense and concept inventory of the wordnets: Princeton Wordnet (PWN: Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Chinese Open Wordnet (Wang and Bond, 2013) and the Wordnet Bahasa (Nurril Hirfana et al. 2011) through the Open Multingual Wordnet (Bond and Foster, 2013). 2.2 The Open Multilingual Wordnet The task of semantic annotating a corp"
P15-4002,P15-4013,1,\N,Missing
P15-4013,henrich-hinrichs-2010-gernedit,0,0.0157273,"themselves by translating the PWN. However, as individual projects grow, they tend to move away from the inherited English concept hierarchy. This is the moment when systems to support easy manipulation and expansion of their WNs are needed. Among the available systems we can find VisDic (Horák et al., 2004) (later developed into DEBVisDic, Horák et al., 2006), used for the development of BalkaNet (Tufis et al., 2004), plWordNetApp (succeeded by WordNetLoom (Piasecki et al., 2013)) used for the construction of the Polish Wordnet (Derwojedowa et al., 2008), GernEdiT, the GermaNet editing tool (Henrich and Hinrichs, 2010), KUI (Sornlertlamvanich et al., 2008, used in the Asian Wordnet) and Polaris (Louw, 1998) used in the development of EuroWordnet (Vossen, 1998b). Out of the above mentioned, we excluded Polaris as not being released. Even though GernEdiT seemed well designed, it was mainly developed for a monolingual environment and a restrictive license (i.e. it does not allow redistribution or commercial use). WordNetLoom, the successor of plWordNetApp, develops an interesting editing mode based directly on the WN hierarchy graph, but the fact that it was not offered as a web-service limited our interest. V"
P15-4013,W13-4302,1,0.886089,"s their backbone. Though the hierarchical relations are still currently imposed by the PWN, we have abolished the limitation to a fixed concept inventory by allowing the creation of new concepts. Although the tool is far from perfect, we encourage existing and new projects to use the OMW and OMWEdit as a platform to for their WN development. Furthermore, we intend to feedback the changes committed to the individual wordnet projects: the Princeton Wordnet (Fellbaum, 1998), the Japanese Wordnet (Isahara et al., 2008), the Wordnet Bahasa (Nurril Hirfana et al. 2011) and the Chinese Open Wordnet (Wang and Bond, 2013), respectively, so that changes committed to the OMW can be incorporated to the original WN projects. Figure 3: Reporting Interface (extract of list) 4 Summary and Future Work We have described the architecture and main functionality of the OMWEdit. Considering its short development history, our system has proved itself an increasingly stable and useful tool for the expansion of a few major Wordnet projects. Our web-based system architecture has proved itself ideal for a medium to large scale lexicographic team, regardless of the location of each member. During the development of this system,"
P15-4013,Y11-1027,1,0.918157,"Missing"
P15-4013,isahara-etal-2008-development,1,\N,Missing
P15-4013,P13-1133,1,\N,Missing
P15-4013,P15-4002,1,\N,Missing
P16-1143,W04-3204,0,0.117847,"Missing"
P16-1143,N15-1132,0,0.200608,"the target word across its token usages. Boyd-Graber and Blei (2007) formalise the method of McCarthy et al. (2004b) with a probabilistic model, while others take different approaches, such as adapting existing sense frequency data to specific domains (Chan and Ng, 2005; Chan and Ng, 2006), using coarse grained thesaurus-like sense inventories (Mohammad and Hirst, 2006), adapting information retrieval-based methods (Lapata and Keller, 2007), using ensemble learning (Brody et al., 2006), utilising the network structure of W ORD N ET (Boyd-Graber et al., 2007), or making use of word embeddings (Bhingardive et al., 2015). Alternatively, Jin et al. (2009) focus on how best to use the MFS heuristic, by identifying when best to apply it, based on sense distribution entropy. Perhaps the most promising approach is that of Lau et al. (2014), due to its state-of-the art performance, and the fact that it can easily by applied to any language and any sense repository containing sense glosses. The task we are interested in — namely, sense distribution learning — is in principle very similar to identifying the MFS. Indeed, of these methods for identifying the MFS, some of them are 1514 explicitly described in terms of s"
P16-1143,P11-2087,0,0.0263279,"Missing"
P16-1143,S07-1060,0,0.165989,"nt sense (MFS) heuristic (McCarthy et al., 2007), which assigns each usage of a given word-type to its most frequent sense. Given the popularity of the MFS heuristic, much of the past work on unsupervised techniques has focused on identifying the most frequent sense. The original method of this kind was proposed by McCarthy et al. (2004b), which relied on finding distributionally similar words to the target word, and comparing these to the candidate senses. Most subsequent approaches have followed a similar approach, based on the words appearing nearby the target word across its token usages. Boyd-Graber and Blei (2007) formalise the method of McCarthy et al. (2004b) with a probabilistic model, while others take different approaches, such as adapting existing sense frequency data to specific domains (Chan and Ng, 2005; Chan and Ng, 2006), using coarse grained thesaurus-like sense inventories (Mohammad and Hirst, 2006), adapting information retrieval-based methods (Lapata and Keller, 2007), using ensemble learning (Brody et al., 2006), utilising the network structure of W ORD N ET (Boyd-Graber et al., 2007), or making use of word embeddings (Bhingardive et al., 2015). Alternatively, Jin et al. (2009) focus on"
P16-1143,D07-1109,0,0.185536,"o the most frequent sense heuristic has been particularly strong when used with domain-specific data (Koeling et al., 2005; Chan and Ng, 2006; Lau et al., 2014). Introduction Word sense disambiguation (WSD), as well as more general problems involving word senses, have been of great interest to the NLP community for many years (for a detailed overview, see Agirre and Edmonds (2007) and Navigli (2009)). In particular, there has recently been a lot of work on unsupervised techniques for these problems. This includes unsupervised methods for performing WSD (Postma et al., 2015; Chen et al., 2014; Boyd-Graber et al., 2007; Brody et al., 2006), In addition, there is great scope to use these techniques to improve existing sense frequency resources, which are currently limited by the bottleneck of requiring manual sense annotation. The most prominent example of such a resource is W ORD N ET (Fellbaum, 1998), where the sense 1513 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1513–1524, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics frequency data is based on S EM C OR (Miller et al., 1993), a 220,000 word corpus that has been ma"
P16-1143,P06-1013,0,0.127078,"heuristic has been particularly strong when used with domain-specific data (Koeling et al., 2005; Chan and Ng, 2006; Lau et al., 2014). Introduction Word sense disambiguation (WSD), as well as more general problems involving word senses, have been of great interest to the NLP community for many years (for a detailed overview, see Agirre and Edmonds (2007) and Navigli (2009)). In particular, there has recently been a lot of work on unsupervised techniques for these problems. This includes unsupervised methods for performing WSD (Postma et al., 2015; Chen et al., 2014; Boyd-Graber et al., 2007; Brody et al., 2006), In addition, there is great scope to use these techniques to improve existing sense frequency resources, which are currently limited by the bottleneck of requiring manual sense annotation. The most prominent example of such a resource is W ORD N ET (Fellbaum, 1998), where the sense 1513 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1513–1524, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics frequency data is based on S EM C OR (Miller et al., 1993), a 220,000 word corpus that has been manually tagged with W"
P16-1143,W10-0701,0,0.0326124,"our English Wikipedia corpus. The remaining lemmas were then split into 5 groups of approximately equal size based on S EM C OR frequency. The S EM C OR frequencies contained in each group are summarised in Table 1. From each of the S EM C OR frequency groups, we randomly sampled 10 lemmas, giving 50 lemmas in total. Then for each lemma, we randomly sampled 100 usages to be annotated from English Wikipedia. This was done in the same way as the sampling of lemma usages for L EX S EM TM (see Section 6). We obtained crowdsourced sense annotations for each lemma using Amazon Mechanical Turk (AMT: Callison-Burch and Dredze (2010)). The sentences for each lemma were split into 4 batches (25 sentences per batch). In addition, two control sentences18 were created for each lemma, and added to each corresponding batch. Each batch of 27 items was annotated separately by 10 annotators. For each item to be annotated, annotators were provided with the sentence containing the lemma, the gloss for each sense as listed in W ORD N ET 3.019 and a list of hypernyms and synonyms for each sense. Annotators were asked to assign each item to exactly one sense. From these crowdsourced annotations, our gold-standard sense distributions we"
P16-1143,P06-1012,0,0.19513,", 2014), semi-automatic dictionary construction (Cook et al., 2013), lexical simplification (Biran et al., 2011), and textual entailment (Shnarch et al., 2011). Automatically acquired sense distributions themselves are also used to improve unsupervised WSD, for example by providing a most frequent sense heuristic (McCarthy et al., 2004b; Jin et al., 2009) or by improving unsupervised usage sampling strategies (Agirre and Martinez, 2004). Furthermore, the improvement due to the most frequent sense heuristic has been particularly strong when used with domain-specific data (Koeling et al., 2005; Chan and Ng, 2006; Lau et al., 2014). Introduction Word sense disambiguation (WSD), as well as more general problems involving word senses, have been of great interest to the NLP community for many years (for a detailed overview, see Agirre and Edmonds (2007) and Navigli (2009)). In particular, there has recently been a lot of work on unsupervised techniques for these problems. This includes unsupervised methods for performing WSD (Postma et al., 2015; Chen et al., 2014; Boyd-Graber et al., 2007; Brody et al., 2006), In addition, there is great scope to use these techniques to improve existing sense frequency"
P16-1143,C14-1035,0,0.0254343,"others implicitly learn sense distributions by calculating some kind of scores used to rank senses. The state-of-the-art technique of Lau et al. (2014) that we are building upon involves performing unsupervised word sense induction (WSI), which itself is implemented using nonparametric HDP (Teh et al., 2006) topic models, as detailed in Section 3. The WSI component, HDP-WSI, is based on the work of Lau et al. (2012), which at the time was state-of-the-art. Since then, however, other competitive WSI approaches have been developed, involving complex structures such as multi-layer topic models (Chang et al., 2014), or complex word embedding based approaches (Neelakantan et al., 2014). We have not used these approaches in this work on account of their complexity and likely computational cost, however we believe they are worth future exploration. On the other hand, because HDP-WSI is implemented using topic models, it can be customised by replacing HDP with newer, more efficient topic modelling algorithms. Recent work has produced more advanced topic modelling approaches, some of which are extensions of existing approaches using more advanced learning algorithms or expanded models (Buntine and Mishra, 20"
P16-1143,D14-1110,0,0.186671,"e improvement due to the most frequent sense heuristic has been particularly strong when used with domain-specific data (Koeling et al., 2005; Chan and Ng, 2006; Lau et al., 2014). Introduction Word sense disambiguation (WSD), as well as more general problems involving word senses, have been of great interest to the NLP community for many years (for a detailed overview, see Agirre and Edmonds (2007) and Navigli (2009)). In particular, there has recently been a lot of work on unsupervised techniques for these problems. This includes unsupervised methods for performing WSD (Postma et al., 2015; Chen et al., 2014; Boyd-Graber et al., 2007; Brody et al., 2006), In addition, there is great scope to use these techniques to improve existing sense frequency resources, which are currently limited by the bottleneck of requiring manual sense annotation. The most prominent example of such a resource is W ORD N ET (Fellbaum, 1998), where the sense 1513 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1513–1524, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics frequency data is based on S EM C OR (Miller et al., 1993), a 220,000 wo"
P16-1143,C00-1027,0,0.202938,"Missing"
P16-1143,N13-1132,0,0.0174577,"ch lemma were split into 4 batches (25 sentences per batch). In addition, two control sentences18 were created for each lemma, and added to each corresponding batch. Each batch of 27 items was annotated separately by 10 annotators. For each item to be annotated, annotators were provided with the sentence containing the lemma, the gloss for each sense as listed in W ORD N ET 3.019 and a list of hypernyms and synonyms for each sense. Annotators were asked to assign each item to exactly one sense. From these crowdsourced annotations, our gold-standard sense distributions were created using MACE (Hovy et al., 2013), which is a generalpurpose tool for inferring item labels from multiannotator, multi-item tasks. It provides a Bayesian framework for modelling item annotations, modelling the individual biases of each annotator, and 17 We chose to restrict our scope in this evaluation to nouns because much of the prior work has also focussed on nouns, and these are the words we would expect others to care the most about disambiguating, since they are more often context bearing. Also, introducing other POS would require a greater quantity of expensive annotated data. 18 These were created manually, to be as c"
P16-1143,N09-2059,1,0.917589,"oyd-Graber and Blei (2007) formalise the method of McCarthy et al. (2004b) with a probabilistic model, while others take different approaches, such as adapting existing sense frequency data to specific domains (Chan and Ng, 2005; Chan and Ng, 2006), using coarse grained thesaurus-like sense inventories (Mohammad and Hirst, 2006), adapting information retrieval-based methods (Lapata and Keller, 2007), using ensemble learning (Brody et al., 2006), utilising the network structure of W ORD N ET (Boyd-Graber et al., 2007), or making use of word embeddings (Bhingardive et al., 2015). Alternatively, Jin et al. (2009) focus on how best to use the MFS heuristic, by identifying when best to apply it, based on sense distribution entropy. Perhaps the most promising approach is that of Lau et al. (2014), due to its state-of-the art performance, and the fact that it can easily by applied to any language and any sense repository containing sense glosses. The task we are interested in — namely, sense distribution learning — is in principle very similar to identifying the MFS. Indeed, of these methods for identifying the MFS, some of them are 1514 explicitly described in terms of sense distribution learning (Chan a"
P16-1143,H05-1053,1,0.832069,"ew/527 8 For simplicity we use HCA to refer to both the topic modelling algorithm implemented by Buntine and Mishra (2014) as well as the corresponding software suite, whereas elsewhere HCA often only refers to the software. 1516 HCA Topic Model Convergence 104 log2 (perplexity) Topic Model Training Time (s) Training Time for HDP-WSI vs. HCA-WSI 103 102 HDP-WSI HCA-WSI 0 20 40 Number of Lemma Usages (1000’s) 14 12 10 0 Figure 1: Comparison of the time taken to train the topic models of HDP-WSI and HCA-WSI for each lemma in the BNC dataset. For each method, one data point is plotted per lemma. Koeling et al. (2005),9 which was also used by Lau et al. (2014). This dataset consists of 40 English lemmas, and for each lemma it contains a set of usages of varying size from the BNC and a gold-standard sense distribution that was created by hand-annotating a subset of the usages with W ORD N ET 1.7 senses. Using this dataset, we can calculate the quality of a candidate sense distribution by calculating its Jensen Shannon divergence (JSD) with respect to the corresponding gold-standard distribution. JSD is a measure of dissimilarity between two probability distributions, so a lower JSD score means the distribut"
P16-1143,J04-1003,0,0.0262866,"iments is available via: https://github.com/awbennett/LexSemTm 2 Background and Related Work Given the difficulty and expense of obtaining large-scale and robust annotated data, unsupervised approaches to problems involving word learning and recognising word senses have long been studied in NLP. Perhaps the most famous such problem is word sense disambiguation (WSD), for which many unsupervised solutions have been proposed. Some methods are very complex, performing WSD separately for each word usage using information such as word embeddings of surrounding words (Chen et al., 2014) or POStags (Lapata and Brew, 2004). On the other hand, most approaches make use of the difficult-to-beat most frequent sense (MFS) heuristic (McCarthy et al., 2007), which assigns each usage of a given word-type to its most frequent sense. Given the popularity of the MFS heuristic, much of the past work on unsupervised techniques has focused on identifying the most frequent sense. The original method of this kind was proposed by McCarthy et al. (2004b), which relied on finding distributionally similar words to the target word, and comparing these to the candidate senses. Most subsequent approaches have followed a similar appro"
P16-1143,N07-1044,0,0.0165171,"lly similar words to the target word, and comparing these to the candidate senses. Most subsequent approaches have followed a similar approach, based on the words appearing nearby the target word across its token usages. Boyd-Graber and Blei (2007) formalise the method of McCarthy et al. (2004b) with a probabilistic model, while others take different approaches, such as adapting existing sense frequency data to specific domains (Chan and Ng, 2005; Chan and Ng, 2006), using coarse grained thesaurus-like sense inventories (Mohammad and Hirst, 2006), adapting information retrieval-based methods (Lapata and Keller, 2007), using ensemble learning (Brody et al., 2006), utilising the network structure of W ORD N ET (Boyd-Graber et al., 2007), or making use of word embeddings (Bhingardive et al., 2015). Alternatively, Jin et al. (2009) focus on how best to use the MFS heuristic, by identifying when best to apply it, based on sense distribution entropy. Perhaps the most promising approach is that of Lau et al. (2014), due to its state-of-the art performance, and the fact that it can easily by applied to any language and any sense repository containing sense glosses. The task we are interested in — namely, sense di"
P16-1143,P04-1036,1,0.835389,"posed. Some methods are very complex, performing WSD separately for each word usage using information such as word embeddings of surrounding words (Chen et al., 2014) or POStags (Lapata and Brew, 2004). On the other hand, most approaches make use of the difficult-to-beat most frequent sense (MFS) heuristic (McCarthy et al., 2007), which assigns each usage of a given word-type to its most frequent sense. Given the popularity of the MFS heuristic, much of the past work on unsupervised techniques has focused on identifying the most frequent sense. The original method of this kind was proposed by McCarthy et al. (2004b), which relied on finding distributionally similar words to the target word, and comparing these to the candidate senses. Most subsequent approaches have followed a similar approach, based on the words appearing nearby the target word across its token usages. Boyd-Graber and Blei (2007) formalise the method of McCarthy et al. (2004b) with a probabilistic model, while others take different approaches, such as adapting existing sense frequency data to specific domains (Chan and Ng, 2005; Chan and Ng, 2006), using coarse grained thesaurus-like sense inventories (Mohammad and Hirst, 2006), adapt"
P16-1143,J07-4005,1,0.0500043,"btaining large-scale and robust annotated data, unsupervised approaches to problems involving word learning and recognising word senses have long been studied in NLP. Perhaps the most famous such problem is word sense disambiguation (WSD), for which many unsupervised solutions have been proposed. Some methods are very complex, performing WSD separately for each word usage using information such as word embeddings of surrounding words (Chen et al., 2014) or POStags (Lapata and Brew, 2004). On the other hand, most approaches make use of the difficult-to-beat most frequent sense (MFS) heuristic (McCarthy et al., 2007), which assigns each usage of a given word-type to its most frequent sense. Given the popularity of the MFS heuristic, much of the past work on unsupervised techniques has focused on identifying the most frequent sense. The original method of this kind was proposed by McCarthy et al. (2004b), which relied on finding distributionally similar words to the target word, and comparing these to the candidate senses. Most subsequent approaches have followed a similar approach, based on the words appearing nearby the target word across its token usages. Boyd-Graber and Blei (2007) formalise the method"
P16-1143,H93-1061,0,0.858704,"Missing"
P16-1143,E06-1016,0,0.0192742,"roposed by McCarthy et al. (2004b), which relied on finding distributionally similar words to the target word, and comparing these to the candidate senses. Most subsequent approaches have followed a similar approach, based on the words appearing nearby the target word across its token usages. Boyd-Graber and Blei (2007) formalise the method of McCarthy et al. (2004b) with a probabilistic model, while others take different approaches, such as adapting existing sense frequency data to specific domains (Chan and Ng, 2005; Chan and Ng, 2006), using coarse grained thesaurus-like sense inventories (Mohammad and Hirst, 2006), adapting information retrieval-based methods (Lapata and Keller, 2007), using ensemble learning (Brody et al., 2006), utilising the network structure of W ORD N ET (Boyd-Graber et al., 2007), or making use of word embeddings (Bhingardive et al., 2015). Alternatively, Jin et al. (2009) focus on how best to use the MFS heuristic, by identifying when best to apply it, based on sense distribution entropy. Perhaps the most promising approach is that of Lau et al. (2014), due to its state-of-the art performance, and the fact that it can easily by applied to any language and any sense repository co"
P16-1143,D14-1113,0,0.02152,"kind of scores used to rank senses. The state-of-the-art technique of Lau et al. (2014) that we are building upon involves performing unsupervised word sense induction (WSI), which itself is implemented using nonparametric HDP (Teh et al., 2006) topic models, as detailed in Section 3. The WSI component, HDP-WSI, is based on the work of Lau et al. (2012), which at the time was state-of-the-art. Since then, however, other competitive WSI approaches have been developed, involving complex structures such as multi-layer topic models (Chang et al., 2014), or complex word embedding based approaches (Neelakantan et al., 2014). We have not used these approaches in this work on account of their complexity and likely computational cost, however we believe they are worth future exploration. On the other hand, because HDP-WSI is implemented using topic models, it can be customised by replacing HDP with newer, more efficient topic modelling algorithms. Recent work has produced more advanced topic modelling approaches, some of which are extensions of existing approaches using more advanced learning algorithms or expanded models (Buntine and Mishra, 2014), while others are more novel, involving variations such as neural n"
P16-1143,E12-1060,1,0.603835,"eed, of these methods for identifying the MFS, some of them are 1514 explicitly described in terms of sense distribution learning (Chan and Ng, 2005; Chan and Ng, 2006; Lau et al., 2014), while the others implicitly learn sense distributions by calculating some kind of scores used to rank senses. The state-of-the-art technique of Lau et al. (2014) that we are building upon involves performing unsupervised word sense induction (WSI), which itself is implemented using nonparametric HDP (Teh et al., 2006) topic models, as detailed in Section 3. The WSI component, HDP-WSI, is based on the work of Lau et al. (2012), which at the time was state-of-the-art. Since then, however, other competitive WSI approaches have been developed, involving complex structures such as multi-layer topic models (Chang et al., 2014), or complex word embedding based approaches (Neelakantan et al., 2014). We have not used these approaches in this work on account of their complexity and likely computational cost, however we believe they are worth future exploration. On the other hand, because HDP-WSI is implemented using topic models, it can be customised by replacing HDP with newer, more efficient topic modelling algorithms. Re"
P16-1143,S15-2058,0,0.0349866,"Missing"
P16-1143,P14-1025,1,0.218445,"f languages, which could be extremely computationally expensive. To make things worse, domain differences could require learning numerous distributions per word. Despite this, though, we would not want to make these techniques scalable at the expense of sense distribution quality. Therefore, we would like to understand the tradeoff between the accuracy and computation time of these techniques, and optimise this tradeoff. This could be particularly critical in applying them in an industrial setting. The current state-of-the-art technique for unsupervised sense distribution learning is HDP-WSI (Lau et al., 2014). In order to address the above concerns, we provide a series of investigations exploring how to best optimise HDP-WSI for largescale application. We then use our optimised technique to produce L EX S EM TM,1 a semantic and sense frequency dataset of unprecedented size, spanning the entire vocabulary of English. Finally, we use crowdsourced data to produce a new set of gold-standard sense distributions to accompany L EX S EM TM. We use these to investigate the quality of the sense frequency data in L EX S EM TM with respect to S EM C OR. 1 L EX S EM TM, as well as code for accessing L EX S EM"
P16-1143,P11-2098,0,0.0658532,"Missing"
P16-1143,N15-1074,0,0.0151679,"however we believe they are worth future exploration. On the other hand, because HDP-WSI is implemented using topic models, it can be customised by replacing HDP with newer, more efficient topic modelling algorithms. Recent work has produced more advanced topic modelling approaches, some of which are extensions of existing approaches using more advanced learning algorithms or expanded models (Buntine and Mishra, 2014), while others are more novel, involving variations such as neural networks (Larochelle and Murray, 2011; Cao et al., 2015), or incorporating distributional similarity of words (Xie et al., 2015). Of these approaches, we chose to experiment with that of Buntine and Mishra (2014) because a working implementation was readily available, it has previously shown very strong performance in terms of accuracy and speed, and it is similar to HDP and thus easy to incorporate into our work. 3 HDP-WSI Sense Learning HDP-WSI (Lau et al., 2014) is a state-of-theart unsupervised method for learning sense distributions, given a sense repository with per-sense glosses. It takes as input a collection of example usages of the target lemma2 and the glosses 2 Except where stated otherwise, a lemma usage i"
P98-1023,C96-1023,1,0.859275,"tifying the conditions under which a quantifier can appear in the adjunct position. The explanations range from configurational (Inoue, 1983; Miyagawa, 1989) to discourse based (Downing, 1996; Alam, 1997), we shall discuss these further below. There has been almost no discussion of other floating quantifiers, such as quantificational nouns. We call the process of identifying the noun phrase being quantified by a floating quantifier &apos;anchoring&apos; the quantifier. The necessity of anchoring floating quantifiers for many natural language processing tasks is widely recognized (Asahioka et al., 1990; Bond et al., 1996), and is important not only for machine translation but for the interpretation of Japanese in general. However, although there are several NLP systems that incorporate some solution to the problem of floating quantifiers, to the best of our knowledge, no algorithm for anchoring floating quantifiers has been given. We propose such an algorithm in this paper. The algorithm uses information about case-marking, sentence structure, part-of-speech, noun and verb meaning. The algorithm has been implemented and tested within the Japanese-to-English machine translation system A L T - J / E (Ikehara et"
P98-1023,1991.mtsummit-papers.16,1,0.795134,"al., 1996), and is important not only for machine translation but for the interpretation of Japanese in general. However, although there are several NLP systems that incorporate some solution to the problem of floating quantifiers, to the best of our knowledge, no algorithm for anchoring floating quantifiers has been given. We propose such an algorithm in this paper. The algorithm uses information about case-marking, sentence structure, part-of-speech, noun and verb meaning. The algorithm has been implemented and tested within the Japanese-to-English machine translation system A L T - J / E (Ikehara et al., 1991). The next section describes the phenomenon of quantifier float in more detail. We then propose our algorithm to identify and anchor floating quantifiers in Section 3. The results of implementing the algorithm in A L T - J / E are dis3The name &apos;float&apos; comes from early transformational accounts, where the quantifier was said to &apos;float&apos; out of the noun phrase. Although this analysis has largely been abandoned, and we disagree with it, we shall continue with accepted practice and call a quantifier in the adjunct position a floating quantifier. cussed in Section 4 and some remaining problems ident"
S13-2030,S07-1070,0,0.0446717,"Missing"
S13-2030,D07-1109,0,0.0249465,"Missing"
S13-2030,D07-1108,0,0.0593758,"Missing"
S13-2030,S13-2029,0,0.0362904,"e polysemous word in the query sentence should be equivalent to translation of word in the matched training sentence(s) from a parallel corpus. By pursuing this approach, we escape the traditional mode of disambiguating a sense using a sense inventory. 1 Introduction 4 System Description This paper describes the XLING system, an unsupervised Cross-Lingual Word Sense Disambiguation (CLWSD) system based on matching query sentence to parallel corpus using topic models. CLWSD is the task of disambiguating a word given a context by providing the most appropriate translation in different languages (Lefever and Hoste, 2013). 2 Background Topic models assume that latent topics exist in texts and each semantic topic can be represented with a multinomial distribution of words and each document can be classified into different semantic topics (Hofmann, 1999). Blei et al. (2003b) introduced a Bayesian version of topic modeling using Dirichlet hyper-parameters, Latent Dirichlet Allocation (LDA). Using LDA, a set of topics can be generated to classify documents within a corpus. Each topic will contain a list of all the words in the vocabulary of the corThe XLING_TnT system attempts the matching subtask in three steps ("
S13-2030,P10-1116,0,0.0778347,"of topics (#topics) as 50, and the alpha and beta 2 4.2.2 http://code.google.com/p/xlemma/ Using the Page and Article Analyzer stopwords from http://www.ranks.nl/resources/stopwords.html 168 Topic Allocation Each sentence was allocated the most probable topic induced by LDA. An induced topic contained a ranked list of tuples where the 2nd element in each tuple is a word that associated with the topic, the 1st element is the probability that the associated word will occur given the topic. The probabilities are generatively output using Variational Bayes algorithm as described in Hoffman et al. (2010). For example: [(0.0208, &apos;sport&apos;), (0.0172, &apos;however&apos;), (0.0170, &apos;quite&apos;), (0.0166, &apos;maritime&apos;), (0.0133, &apos;field&apos;), (0.0133, &apos;air-transport&apos;), (0.0130, &apos;appear&apos;), (0.0117, &apos;arrangement&apos;), (0.0117, &apos;pertain&apos;), (0.0111, &apos;supervision&apos;)] 4.2.3 4.2 Topicalize and Match 1 hyper-parameters were symmetrically set at 1.0/#topics. Blei et al. (2003) had shown that the perplexity plateaus when #topics ≥ 50; higher perplexity means more computing time needed to train the model. Topic Inference With the trained LDA model, we inferred the most probable topic of the query sentence. Then we extracted the top-"
S13-2030,J03-1002,0,0.00365126,"abulary of the corThe XLING_TnT system attempts the matching subtask in three steps (1) Topicalize: matching the query sentence to the training sentences by the most probable topic. (2) Rank: the matching sentences were ranked according to the cosine similarity between the query and matching sentences. (3) Translate: provides the translation of the polysemous word in the matched sentence(s) from the parallel corpus. 4.1 Preprocessing The Europarl version 7 corpus bitexts (EnglishGerman, English-Spanish, English-French, English-Italian and English-Dutch) were aligned at word-level with GIZA++ (Och and Ney, 2003). The translation tables from the word-alignments were used to provide the translation of the polysemous word in the Translate step. The English sentences from the bitexts were lemmatized using a dictionary-based lemmatiz167 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic c Evaluation (SemEval 2013), pages 167–170, Atlanta, Georgia, June 14-15, 2013. 2013 Association for Computational Linguistics er: xlemma1. After the lemmatization, English stopwords2 were removed from the sentences. The lemmatized and stop filtered s"
S14-2094,P13-1109,0,0.0128303,"ement (Mareˇcek et al., 2011). Untranslated fragments from machine translations are the result of out-of-vocabulary (OOV) words. Previous approaches to the handling of untranslated fragments include using a pivot language to translate the OOV word(s) into a third language and then back into to the source language, thereby extracting paraphrases to OOV (Callison-burch and Osborne, 2006), combining sub-lexical/constituent translations of the OOV word(s) to generate the translation (Huang et al., 2011) or finding paraphrases of the OOV words that have available translations (Marton et al., 2009; Razmara et al., 2013). 1 However the simplest approach to handle untranslated fragments is to increase the size of parallel data. The web is vast and infinite, a human translator would consult the web when encountering a word that he/she cannot translate easily. The most human-like approach to post-editing a foreign untranslated fragment is to do a search on the web or a translation memory and choose the most appropriate translation of the fragment from the search result given the context of the machine translated sentence. 4 5 System Description The PEZ system consists of three components, viz (i) a Web Translati"
S14-2094,S13-2031,0,0.015292,"e right morphology. Machine translation tasks focus on producing translations of whole sentences/documents while crosslingual word sense disambiguation targets a single lexical item. Previously, CLWSD systems have tried distributional semantics and string matching methods (Tan and Bond, 2013), unsupervised clustering of word alignment vectors (Apidianaki, 2013) and supervised classification-based approaches trained on local context features for a window of three words containing the focus word (van Gompel, 2010; van Gompel and van den Bosch, 2013; Rudnick et al., 2013). Interestingly, Carpuat (2013) approached the CLWSD task with a Statistical MT system . Short of concatenating outputs of CLWSD / CLS outputs and dealing with a reordering issue Introduction In this paper, we present a collaborative submission between Saarland University and Nanyang Technological University to the L2 Translation Assistant task in SemEval-2014. Our team name is Sensible and the participating system is PostEditor Z (PEZ). The L2 Translation Assistant task concerns the translation of an untranslated fragment from a partially translated sentence. For instance, given a sentence, “Ich konnte B¨arbel noch on the"
S14-2094,S13-2030,1,0.913179,"ual word sense disambiguation (CLWSD) or crosslingual lexical substitution (CLS) (Lefever and Hoste, 2013; Mihalcea et al. 2010). While CLWSD systems resolve the correct semantics of the translation by providing the correct lemma in the target language, CLS attempts to provide also the correct form of the translation with the right morphology. Machine translation tasks focus on producing translations of whole sentences/documents while crosslingual word sense disambiguation targets a single lexical item. Previously, CLWSD systems have tried distributional semantics and string matching methods (Tan and Bond, 2013), unsupervised clustering of word alignment vectors (Apidianaki, 2013) and supervised classification-based approaches trained on local context features for a window of three words containing the focus word (van Gompel, 2010; van Gompel and van den Bosch, 2013; Rudnick et al., 2013). Interestingly, Carpuat (2013) approached the CLWSD task with a Statistical MT system . Short of concatenating outputs of CLWSD / CLS outputs and dealing with a reordering issue Introduction In this paper, we present a collaborative submission between Saarland University and Nanyang Technological University to the L"
S14-2094,S13-2032,0,0.0244983,"on (CLS) (Lefever and Hoste, 2013; Mihalcea et al. 2010). While CLWSD systems resolve the correct semantics of the translation by providing the correct lemma in the target language, CLS attempts to provide also the correct form of the translation with the right morphology. Machine translation tasks focus on producing translations of whole sentences/documents while crosslingual word sense disambiguation targets a single lexical item. Previously, CLWSD systems have tried distributional semantics and string matching methods (Tan and Bond, 2013), unsupervised clustering of word alignment vectors (Apidianaki, 2013) and supervised classification-based approaches trained on local context features for a window of three words containing the focus word (van Gompel, 2010; van Gompel and van den Bosch, 2013; Rudnick et al., 2013). Interestingly, Carpuat (2013) approached the CLWSD task with a Statistical MT system . Short of concatenating outputs of CLWSD / CLS outputs and dealing with a reordering issue Introduction In this paper, we present a collaborative submission between Saarland University and Nanyang Technological University to the L2 Translation Assistant task in SemEval-2014. Our team name is Sensibl"
S14-2094,W14-3323,1,0.835877,"the reranker first removes all stopwords from the sentences and then ranks the sentences based on the number of overlapping stems. In situations where there are no overlapping content words from the sentences, XLING falls back on the most common translation of the untranslated fragment. 1 in MT, evaluation is normally performed using automatic metrics based on automatic evaluation metrics that compares scores based on string/word similarity between the machinegenerated translation and a reference output, simply removing OOV would have improved the metric “scores” of the system (Habash, 2008; Tan and Pal, 2014). 542 WebTM XLING PEZ acc 0.160 0.152 0.162 en-de wac 0.184 0.178 0.233 rec 0.647 0.647 0.878 acc 0.145 0.141 0.239 en-es wac 0.175 0.171 0.351 rec 0.470 0.470 0.819 fr-en wac 0.067 0.067 0.116 acc 0.055 0.055 0.081 rec 0.210 0.210 0.321 acc 0.092 0.088 0.115 nl-en wac 0.099 0.095 0.152 rec 0.214 0.214 0.335 Table 1: Results for Best Evaluation of the System Runs. 5.3 Longest Ngram/String Matches 1. WebTM: a baseline configuration which outputs the most frequent indexed translation of the untranslated fragment from the Web TM. 2. XLING: reranks the WebTM outputs based on cosine similarity. 3."
S14-2094,N06-1003,0,0.0398742,"exed by the translation memory and (iii) finally ranking them based on cosine similarity of the context words. Automatic Post-Editors APEs target various types of MT errors from determiner selection (Knight and Chander, 1994) to grammatical agreement (Mareˇcek et al., 2011). Untranslated fragments from machine translations are the result of out-of-vocabulary (OOV) words. Previous approaches to the handling of untranslated fragments include using a pivot language to translate the OOV word(s) into a third language and then back into to the source language, thereby extracting paraphrases to OOV (Callison-burch and Osborne, 2006), combining sub-lexical/constituent translations of the OOV word(s) to generate the translation (Huang et al., 2011) or finding paraphrases of the OOV words that have available translations (Marton et al., 2009; Razmara et al., 2013). 1 However the simplest approach to handle untranslated fragments is to increase the size of parallel data. The web is vast and infinite, a human translator would consult the web when encountering a word that he/she cannot translate easily. The most human-like approach to post-editing a foreign untranslated fragment is to do a search on the web or a translation me"
S14-2094,S13-2033,0,0.0171187,"e right morphology. Machine translation tasks focus on producing translations of whole sentences/documents while crosslingual word sense disambiguation targets a single lexical item. Previously, CLWSD systems have tried distributional semantics and string matching methods (Tan and Bond, 2013), unsupervised clustering of word alignment vectors (Apidianaki, 2013) and supervised classification-based approaches trained on local context features for a window of three words containing the focus word (van Gompel, 2010; van Gompel and van den Bosch, 2013; Rudnick et al., 2013). Interestingly, Carpuat (2013) approached the CLWSD task with a Statistical MT system . Short of concatenating outputs of CLWSD / CLS outputs and dealing with a reordering issue Introduction In this paper, we present a collaborative submission between Saarland University and Nanyang Technological University to the L2 Translation Assistant task in SemEval-2014. Our team name is Sensible and the participating system is PostEditor Z (PEZ). The L2 Translation Assistant task concerns the translation of an untranslated fragment from a partially translated sentence. For instance, given a sentence, “Ich konnte B¨arbel noch on the"
S14-2094,S13-2034,0,0.021765,"with the right morphology. Machine translation tasks focus on producing translations of whole sentences/documents while crosslingual word sense disambiguation targets a single lexical item. Previously, CLWSD systems have tried distributional semantics and string matching methods (Tan and Bond, 2013), unsupervised clustering of word alignment vectors (Apidianaki, 2013) and supervised classification-based approaches trained on local context features for a window of three words containing the focus word (van Gompel, 2010; van Gompel and van den Bosch, 2013; Rudnick et al., 2013). Interestingly, Carpuat (2013) approached the CLWSD task with a Statistical MT system . Short of concatenating outputs of CLWSD / CLS outputs and dealing with a reordering issue Introduction In this paper, we present a collaborative submission between Saarland University and Nanyang Technological University to the L2 Translation Assistant task in SemEval-2014. Our team name is Sensible and the participating system is PostEditor Z (PEZ). The L2 Translation Assistant task concerns the translation of an untranslated fragment from a partially translated sentence. For instance, given a sentence, “Ich konnte B¨arbel noch on the"
S14-2094,S10-1053,0,0.0572774,"Missing"
S14-2094,P08-2015,0,0.0284444,"WebTM crawler, the reranker first removes all stopwords from the sentences and then ranks the sentences based on the number of overlapping stems. In situations where there are no overlapping content words from the sentences, XLING falls back on the most common translation of the untranslated fragment. 1 in MT, evaluation is normally performed using automatic metrics based on automatic evaluation metrics that compares scores based on string/word similarity between the machinegenerated translation and a reference output, simply removing OOV would have improved the metric “scores” of the system (Habash, 2008; Tan and Pal, 2014). 542 WebTM XLING PEZ acc 0.160 0.152 0.162 en-de wac 0.184 0.178 0.233 rec 0.647 0.647 0.878 acc 0.145 0.141 0.239 en-es wac 0.175 0.171 0.351 rec 0.470 0.470 0.819 fr-en wac 0.067 0.067 0.116 acc 0.055 0.055 0.081 rec 0.210 0.210 0.321 acc 0.092 0.088 0.115 nl-en wac 0.099 0.095 0.152 rec 0.214 0.214 0.335 Table 1: Results for Best Evaluation of the System Runs. 5.3 Longest Ngram/String Matches 1. WebTM: a baseline configuration which outputs the most frequent indexed translation of the untranslated fragment from the Web TM. 2. XLING: reranks the WebTM outputs based on co"
S14-2094,D09-1040,0,0.0267417,") to grammatical agreement (Mareˇcek et al., 2011). Untranslated fragments from machine translations are the result of out-of-vocabulary (OOV) words. Previous approaches to the handling of untranslated fragments include using a pivot language to translate the OOV word(s) into a third language and then back into to the source language, thereby extracting paraphrases to OOV (Callison-burch and Osborne, 2006), combining sub-lexical/constituent translations of the OOV word(s) to generate the translation (Huang et al., 2011) or finding paraphrases of the OOV words that have available translations (Marton et al., 2009; Razmara et al., 2013). 1 However the simplest approach to handle untranslated fragments is to increase the size of parallel data. The web is vast and infinite, a human translator would consult the web when encountering a word that he/she cannot translate easily. The most human-like approach to post-editing a foreign untranslated fragment is to do a search on the web or a translation memory and choose the most appropriate translation of the fragment from the search result given the context of the machine translated sentence. 4 5 System Description The PEZ system consists of three components,"
S14-2094,W11-2152,0,\N,Missing
S16-1203,S15-2151,0,0.196441,"ge taxonomies such as CYC (Lenat, 1995), SUMO (Pease et al., 2002; Miller, 1995), YAGO (Suchanek et al., 2007) and Freebase (Bollacker et al., 2008) have been manually created or curated with much effort. With the rapid technological evolution, it is more feasible to construct a domain-specific taxonomy that caters to domain or company specific terminology (Lefever, 2015). This motivated the move towards unsupervised approaches to taxonomy extraction (Berland and Charniak, 1999; Lin and Pantel, 2001; Snow et al., 2006) and specifically focused towards particular domains (Velardi et al., 2013; Bordea et al., 2015). The aim of the Taxonomy Extraction Evaluation (TExEval) task is to automatically find lexical relations between pairs of terms within several specified domains. Previously, we have developed a hypernym extraction system using word embeddings by exploiting the frequent occurrence of the ‘X is a Y’ pattern in encyclopedic text (Tan et al., 2015). We have achieved competitive results in SemEval-2015 and as a follow up to our study, we would like to explore the endocentric nature of hyponyms that contributed substantially to the system performance in the previous TExEval task. Below, we will bri"
S16-1203,S16-1168,0,0.320784,"Missing"
S16-1203,S15-2156,0,0.0179609,"evious TExEval task. Below, we will briefly (i) describe related work on different approaches to taxonomy induction, (ii) explain the linguistic phenomenon of endocentricity, (iii) present our endocentric hypo-hypernym identification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der P"
S16-1203,S16-1205,0,0.239954,"ned low precision (Pocostales, 2016). Similar to our endocentric-based approach, the TAXI team extended the substring-based approach by filtering the hypernym candidates based on corpora statistics of lexico-syntactic patterns. Additionally, they applied pruning methods to improve the ontological structure which resulted in high Fowlkes and Mallows (F&M) Measure (Panchenko and Biemann, 2016). QASSIT used lexical patterns to extract hypernym candidates and applied the pretopological space graph optimization technique that is based on genetic algorithm to achieve the desired taxonomy structure (Cleuziou and Moreno, 2016). TAXI and QASSIT ranked first and second in the taxonomy construction criterion of the TExEval task. Both teams used graph pruning techniques to improve the taxonomy structure and implicitly improve the F&M scores5 of their taxonomy. Although our endocentricity based hypo-hypernym extraction system ranked first in hypernym identification of TExEval task, we ranked third in taxonomy construction with an overall F&M score of 0.0013. 7 Conclusion In this paper, we have described our submission to the Taxonomy Extraction Evaluation (TExEval2) Task for SemEval-2016. We have empirically shown that"
S16-1203,S15-2159,0,0.221084,"Missing"
S16-1203,S15-2158,0,0.0143016,"ification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a"
S16-1203,N12-1051,0,0.0156503,"oposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that similar meanings tend to be found close to each other"
S16-1203,P14-1113,0,0.0342695,"e where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that similar meanings tend to be found close to each other within the vector space (Mitchell and Lapata, 2010). With the present advancement in neural nets and word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy et al., 2014; Shazeer et al., 2016), neural space models are gaining popularity in taxonomy induction and relation extraction tasks (Saxe et al., 2013; Fu et al., 2014; Tan et al., 2015). for information retrieval, Jones (1979) observed that compound nouns often follow the head-modifier principle where the meaning of the term can be conveyed by part(s) of the compound. Approaching endocentricity from a different angle, Nichols et al. (2005) identified the semantic head(s) of a term as its hypernym using the lowest scoping element of the Robust Minimal Recursion Semantics (RMRS) (Copestake et al., 2005) structure of the dictionary definition of the term. In the first TExEval task in SemEval-2015, both Lefever (2015) and Tan et al. (2015)1 independently devel"
S16-1203,W03-1210,0,0.0757481,"to the system performance in the previous TExEval task. Below, we will briefly (i) describe related work on different approaches to taxonomy induction, (ii) explain the linguistic phenomenon of endocentricity, (iii) present our endocentric hypo-hypernym identification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector"
S16-1203,S15-2152,0,0.146206,"in the linguistic phenomenon of endocentricity, (iii) present our endocentric hypo-hypernym identification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural net"
S16-1203,C92-2082,0,0.669419,"substantially to the system performance in the previous TExEval task. Below, we will briefly (i) describe related work on different approaches to taxonomy induction, (ii) explain the linguistic phenomenon of endocentricity, (iii) present our endocentric hypo-hypernym identification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurge"
S16-1203,D10-1108,0,0.0669032,"etween terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that simil"
S16-1203,P08-1119,0,0.0707082,"Missing"
S16-1203,S15-2157,0,0.678751,"on of novel relations not covered by the gold standard taxonomies. 1 Introduction Semantic taxonomies provide structured world knowledge to Artificial Intelligence (AI) and Natural Language Processing (NLP) systems. Traditional broad-coverage taxonomies such as CYC (Lenat, 1995), SUMO (Pease et al., 2002; Miller, 1995), YAGO (Suchanek et al., 2007) and Freebase (Bollacker et al., 2008) have been manually created or curated with much effort. With the rapid technological evolution, it is more feasible to construct a domain-specific taxonomy that caters to domain or company specific terminology (Lefever, 2015). This motivated the move towards unsupervised approaches to taxonomy extraction (Berland and Charniak, 1999; Lin and Pantel, 2001; Snow et al., 2006) and specifically focused towards particular domains (Velardi et al., 2013; Bordea et al., 2015). The aim of the Taxonomy Extraction Evaluation (TExEval) task is to automatically find lexical relations between pairs of terms within several specified domains. Previously, we have developed a hypernym extraction system using word embeddings by exploiting the frequent occurrence of the ‘X is a Y’ pattern in encyclopedic text (Tan et al., 2015). We ha"
S16-1203,S12-1012,0,0.0187638,"ing and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that similar meanings tend to be found close to each other within the vector space (Mitchell and Lapata, 2010). With the present advancement in neural nets and word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy e"
S16-1203,W14-1618,0,0.0495305,", 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that similar meanings tend to be found close to each other within the vector space (Mitchell and Lapata, 2010). With the present advancement in neural nets and word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy et al., 2014; Shazeer et al., 2016), neural space models are gaining popularity in taxonomy induction and relation extraction tasks (Saxe et al., 2013; Fu et al., 2014; Tan et al., 2015). for information retrieval, Jones (1979) observed that compound nouns often follow the head-modifier principle where the meaning of the term can be conveyed by part(s) of the compound. Approaching endocentricity from a different angle, Nichols et al. (2005) identified the semantic head(s) of a term as its hypernym using the lowest scoping element of the Robust Minimal Recursion Semantics (RMRS) (Copestake et al., 2005) st"
S16-1203,P98-2127,0,0.504088,"k on different approaches to taxonomy induction, (ii) explain the linguistic phenomenon of endocentricity, (iii) present our endocentric hypo-hypernym identification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014)"
S16-1203,N04-1041,0,0.0592528,"taxonomy induction, (ii) explain the linguistic phenomenon of endocentricity, (iii) present our endocentric hypo-hypernym identification system and the results of our submission to the TExEval-2 task in SemEval-2016. 2 Related Work The hierarchical structure of domain concepts is made of hypo-hypernymy relations between terms. Different approaches have been proposed to induce these relations automatically ranging from pattern/rule-based approaches (Hearst, 1992; Girju, 2003; Kozareva et al., 2008; Ceesay and Hou, 2015) to clustering and frequency based approaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep le"
S16-1203,D14-1162,0,0.0919512,", 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that similar meanings tend to be found close to each other within the vector space (Mitchell and Lapata, 2010). With the present advancement in neural nets and word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy et al., 2014; Shazeer et al., 2016), neural space models are gaining popularity in taxonomy induction and relation extraction tasks (Saxe et al., 2013; Fu et al., 2014; Tan et al., 2015). for information retrieval, Jones (1979) observed that compound nouns often follow the head-modifier principle where the meaning of the term can be conveyed by part(s) of the compound. Approaching endocentricity from a different angle, Nichols et al. (2005) identified the semantic head(s) of a term as its hypernym using the lowest scoping element of the Robust Minimal Recursion Semantics (RMRS) (Copesta"
S16-1203,S16-1202,0,0.22248,"s presented in Bordea et al. (2016). JUNLP relied on substrings and relations extracted from BabelNet (Navigli and Ponzetto, 2012) to identify hyper-hyponym pairs. Although it is sensible to approach the task using an existing ontology, their system achieved relatively low precision on the manual evaluation of novel hyper-hyponym pairs. The NUIG-UNLP team extended previous work on vector space approaches to taxonomy induction by comparing the similarity between the dense word embeddings of the hyponyms and their candidate hypernyms. They system achieved high recall but attained low precision (Pocostales, 2016). Similar to our endocentric-based approach, the TAXI team extended the substring-based approach by filtering the hypernym candidates based on corpora statistics of lexico-syntactic patterns. Additionally, they applied pruning methods to improve the ontological structure which resulted in high Fowlkes and Mallows (F&M) Measure (Panchenko and Biemann, 2016). QASSIT used lexical patterns to extract hypernym candidates and applied the pretopological space graph optimization technique that is based on genetic algorithm to achieve the desired taxonomy structure (Cleuziou and Moreno, 2016). TAXI and"
S16-1203,E14-4008,0,0.0340838,"pproaches (Lin, 1998; Caraballo, 2001; Pantel and Ravichandran, 2004; Grefenstette, 2015), classification approaches (Snow et al., 2004; Ritter et al., 2009; Espinosa Anke et al., 2015) and graph-based ap1303 Proceedings of SemEval-2016, pages 1303–1309, c San Diego, California, June 16-17, 2016. 2016 Association for Computational Linguistics proaches (Kozareva and Hovy, 2010; Navigli et al., 2011; Fountain and Lapata, 2012; Tuan et al., 2014; Cleuziou et al., 2015). More recently, there is a resurgence of vector space or distributional approaches (Van Der Plas, 2005; Lenci and Benotto, 2012; Santus et al., 2014) primarily because of the renaissance of deep learning and neural networks. Semantic knowledge can be thought of as a vector space where each word is presented by a point and the proximity between words in this space quantifies their semantic association. The vector space is usually constructed from the distribution of words across contexts such that similar meanings tend to be found close to each other within the vector space (Mitchell and Lapata, 2010). With the present advancement in neural nets and word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy et al., 2014; Shazeer e"
S16-1203,P06-1101,0,0.113825,"cial Intelligence (AI) and Natural Language Processing (NLP) systems. Traditional broad-coverage taxonomies such as CYC (Lenat, 1995), SUMO (Pease et al., 2002; Miller, 1995), YAGO (Suchanek et al., 2007) and Freebase (Bollacker et al., 2008) have been manually created or curated with much effort. With the rapid technological evolution, it is more feasible to construct a domain-specific taxonomy that caters to domain or company specific terminology (Lefever, 2015). This motivated the move towards unsupervised approaches to taxonomy extraction (Berland and Charniak, 1999; Lin and Pantel, 2001; Snow et al., 2006) and specifically focused towards particular domains (Velardi et al., 2013; Bordea et al., 2015). The aim of the Taxonomy Extraction Evaluation (TExEval) task is to automatically find lexical relations between pairs of terms within several specified domains. Previously, we have developed a hypernym extraction system using word embeddings by exploiting the frequent occurrence of the ‘X is a Y’ pattern in encyclopedic text (Tan et al., 2015). We have achieved competitive results in SemEval-2015 and as a follow up to our study, we would like to explore the endocentric nature of hyponyms that cont"
S16-1203,S15-2143,1,0.840747,"k17-USAAR-WLV 2 https://en.wikipedia.org/wiki/List of lists of lists 3 Our open-source implementation can be found at https://github.com/alvations/Endrocentricity captured by this swap rule are (elixir of life, elixir), (sociology of education, sociology). To improve the precision of the identifier, we set a threshold of a minimum character length of three when identifying a term as a hypernym. 5 Extending a Taxonomy with Wikipedia List of Lists of Lists The Wikipedia List of Lists of Lists (LOLOL) is a crowdsourced list of lists of terms. We adapted the customized crawler4 (Tan et al., 2014; Tan and Ordan, 2015) to crawl for tables or bullet points in the Wikipedia subpages of the LOLOL for the food domain. We started the crawl from these seed pages under the bullet point of https://en.wikipedia.org/wiki/ List of lists of lists#Food and drink. When the crawler lands on each List of Lists (LOL) page, it will treat the URL suffix as the hypernym and find words in the bullet points or tables that contain endocentric hyponyms. If an endocentric hyponym exists, it will extract either (i) all the terms in bold font if the LOL page is bulleted or (ii) all terms in the first column if the LOL page is in tabl"
S16-1203,S14-2094,1,0.827597,"15/tree/master/task17-USAAR-WLV 2 https://en.wikipedia.org/wiki/List of lists of lists 3 Our open-source implementation can be found at https://github.com/alvations/Endrocentricity captured by this swap rule are (elixir of life, elixir), (sociology of education, sociology). To improve the precision of the identifier, we set a threshold of a minimum character length of three when identifying a term as a hypernym. 5 Extending a Taxonomy with Wikipedia List of Lists of Lists The Wikipedia List of Lists of Lists (LOLOL) is a crowdsourced list of lists of terms. We adapted the customized crawler4 (Tan et al., 2014; Tan and Ordan, 2015) to crawl for tables or bullet points in the Wikipedia subpages of the LOLOL for the food domain. We started the crawl from these seed pages under the bullet point of https://en.wikipedia.org/wiki/ List of lists of lists#Food and drink. When the crawler lands on each List of Lists (LOL) page, it will treat the URL suffix as the hypernym and find words in the bullet points or tables that contain endocentric hyponyms. If an endocentric hyponym exists, it will extract either (i) all the terms in bold font if the LOL page is bulleted or (ii) all terms in the first column if t"
S16-1203,S15-2155,1,0.874214,"raction tasks (Saxe et al., 2013; Fu et al., 2014; Tan et al., 2015). for information retrieval, Jones (1979) observed that compound nouns often follow the head-modifier principle where the meaning of the term can be conveyed by part(s) of the compound. Approaching endocentricity from a different angle, Nichols et al. (2005) identified the semantic head(s) of a term as its hypernym using the lowest scoping element of the Robust Minimal Recursion Semantics (RMRS) (Copestake et al., 2005) structure of the dictionary definition of the term. In the first TExEval task in SemEval-2015, both Lefever (2015) and Tan et al. (2015)1 independently developed string-based systems that exploit the endocentric nature of hyponyms. In our submission to the TExEval-2 task (Bordea et al., 2016), we seek to answer the question of exactly “how many hyponyms within a taxonomy are endocentric?”. Additionally, we exploit the endocentric nature of the hyponyms to extend the taxonomy by crawling and cleaning Wikipedia’s List of Lists of Lists.2 Often these lists of terms are found in Wikipedia marked up as tables or in bullet forms. 3 4 Endocentricity Early research in theoretical linguistics discussed the idea of"
S16-1203,D14-1088,0,0.0323931,"Missing"
S16-1203,I05-7011,0,0.0892162,"Missing"
S16-1203,J13-3007,0,0.136173,"aditional broad-coverage taxonomies such as CYC (Lenat, 1995), SUMO (Pease et al., 2002; Miller, 1995), YAGO (Suchanek et al., 2007) and Freebase (Bollacker et al., 2008) have been manually created or curated with much effort. With the rapid technological evolution, it is more feasible to construct a domain-specific taxonomy that caters to domain or company specific terminology (Lefever, 2015). This motivated the move towards unsupervised approaches to taxonomy extraction (Berland and Charniak, 1999; Lin and Pantel, 2001; Snow et al., 2006) and specifically focused towards particular domains (Velardi et al., 2013; Bordea et al., 2015). The aim of the Taxonomy Extraction Evaluation (TExEval) task is to automatically find lexical relations between pairs of terms within several specified domains. Previously, we have developed a hypernym extraction system using word embeddings by exploiting the frequent occurrence of the ‘X is a Y’ pattern in encyclopedic text (Tan et al., 2015). We have achieved competitive results in SemEval-2015 and as a follow up to our study, we would like to explore the endocentric nature of hyponyms that contributed substantially to the system performance in the previous TExEval ta"
S16-1203,P99-1016,0,\N,Missing
S16-1203,P99-1008,0,\N,Missing
S16-1203,C98-2122,0,\N,Missing
shirai-etal-2002-towards,1999.tmi-1.21,1,\N,Missing
shirai-etal-2002-towards,2001.mtsummit-road.1,0,\N,Missing
U12-1009,P01-1005,0,0.0314841,"Missing"
U12-1009,C04-1086,0,0.197049,"apanese loanword MWEs and construct likely English translations, with the ultimate aim of being part of a toolkit to aid the lexicographer. The system builds on the availability of large collections of translated loanwords and a large English n-gram corpus, and in testing is performing with high levels of precision and recall. 2 Prior Work There has not been a large amount of work published on the automatic and semiautomatic extraction and translation of Japanese loanwords. Much that has been reported has been in areas such as backtransliteration (Matsuo et al., 1996; Knight and Graehl, 1998; Bilac and Tanaka, 2004), or on extraction from parallel bilingual corpora (Brill et al., 2001). More recently work has been carried out exploring combinations of dictionaries and corpora (Nakazawa et al., 2005), although this lead does not seem to have been followed further. Both Bilac and Tanaka (2004) and Nakazawa et al. (2005) address the issue of segmentation of MWEs. This is discussed in 3.1 below. 1 In addition to katakana, loanwords use the ー (chōoN) character for indicating lengthened vowels, and on rare occasions the ヽ and ヾ syllable repetition characters. 3 Role and Nature of Katakana Words in Japanese As"
U12-1009,W04-2209,0,0.0863188,"Missing"
U12-1009,W04-3230,0,0.141664,"aka (2004) report a precision and recall of approximately 0.65 on the segmentation, with a tendency to undersegment being the main problem. Nakazawa et al. (2005) report a similar tendency with the JUMAN morphological analyzer (Kurohashi and Nagao, 1998). The problem was most likely due to the relatively poor representation of loanwords in the morpheme lexicons used by these systems. For example the IPADIC lexicon (Asahara and Matsumoto, 2003) used at that time only had about 20,000 words in katakana, and many of those were proper nouns. In this study, we use the MeCab morphological analyzer (Kudo et al., 2004) with the recently-developed UniDic lexicon (Den et al., 2007), as discussed below. As they were largely dealing with nonlexicalized words, Bilac and Tanaka (2004) used a dynamic programming model trained on a relatively small (13,000) list of katakana words, and reported a high precision in their segmentation. Nakazawa et al. (2005) used a larger lexicon in combination with the JUMAN analyzer and reported a similar high precision. 3.2 and Satō, 2003) indicates a similar proportion. (In both dictionaries loanwords from languages other than English are marked with their source language.) This r"
U12-1009,N04-1016,0,0.019131,"Missing"
U12-1009,I05-1060,0,0.292118,"ollections of translated loanwords and a large English n-gram corpus, and in testing is performing with high levels of precision and recall. 2 Prior Work There has not been a large amount of work published on the automatic and semiautomatic extraction and translation of Japanese loanwords. Much that has been reported has been in areas such as backtransliteration (Matsuo et al., 1996; Knight and Graehl, 1998; Bilac and Tanaka, 2004), or on extraction from parallel bilingual corpora (Brill et al., 2001). More recently work has been carried out exploring combinations of dictionaries and corpora (Nakazawa et al., 2005), although this lead does not seem to have been followed further. Both Bilac and Tanaka (2004) and Nakazawa et al. (2005) address the issue of segmentation of MWEs. This is discussed in 3.1 below. 1 In addition to katakana, loanwords use the ー (chōoN) character for indicating lengthened vowels, and on rare occasions the ヽ and ヾ syllable repetition characters. 3 Role and Nature of Katakana Words in Japanese As mentioned above, loan words in Japanese are currently written in the katakana script. This is an orthographical convention that has been applied relatively strictly since the late 1940s,"
U12-1009,W09-2900,0,\N,Missing
U12-1009,J98-4003,0,\N,Missing
W00-0708,P98-1085,0,0.40635,"Missing"
W00-0708,1991.mtsummit-papers.16,0,0.0574635,"Missing"
W00-0708,W00-1427,1,0.528054,"In this paper we investigate the use of corpus data to collect statistical generalizations about article use in English so as to be able to generate them automatically. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) that is used to predict whether to generate the or alan or no article. 1 We discuss a variety of lexical, syntactic and semantic features that * Visiting CSLI, Stanford University (2000). t Visiting CSLI, Stanford University (1999-2000). 1We assume a postprocessor to determine whether to generate a or a n a s described in Minnen et al. (2000). Abstract Article choice can pose difficult problems in applications such as machine translation and automated summarization. In this paper, we investigate the use of corpus data to collect statistical generalizations about article use in English in order to be able to generate articles automatically to supplement a symbolic generator. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) which predicts whether to generate an article with respect to an English base noun phrase. We discuss competitive results obtained using a variety of lexic"
W00-0708,1993.tmi-1.18,0,0.473714,"Missing"
W00-0708,P97-1056,0,0.0490389,"Missing"
W00-0708,C94-1002,1,0.918681,"Missing"
W00-0708,W97-0506,1,0.601846,"even if they are able to use a keyboard. Many have to rely on a slower physical interface (headstick, head-pointer, eye-tracker etc). We are attempting to use a range of NLP technology to improve text input speed for such users. Article choice is particularly important for this application: many AAC users drop articles and resort to a sort of telegraphese, but this causes degradation in comprehension of synthetic speech and contributes to its perception as unnatural and robot-like. Our particular goal is to be able to use an article generator in conjunction with a symbolic generator for AAC (Copestake, 1997; Carroll et al., 1999). In this paper we investigate the use of corpus data to collect statistical generalizations about article use in English so as to be able to generate them automatically. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) that is used to predict whether to generate the or alan or no article. 1 We discuss a variety of lexical, syntactic and semantic features that * Visiting CSLI, Stanford University (2000). t Visiting CSLI, Stanford University (1999-2000). 1We assume a postprocessor to determine whether to generate a"
W00-0708,C90-2023,0,\N,Missing
W00-0708,C98-1082,0,\N,Missing
W00-1701,1995.tmi-1.16,0,0.0243804,"y, Section 4 describes our browser-based annotation application. 2 Goi-Taikei As a base for our tags, we are using the GoiTaikei (GT) Japanese lexicon (Ikehara et al., 1997), a 400,000-word lexicon and ontology developed by NTT for machine translation (MT) applications. We decided that GT is an appropriate resource for our semantic annotation task for three reasons. First, semantic information from GT has already proved valuable in a variety of NLP applications in Japan, including parsing, morphological analysis, text-to-speech, proofreading, and MT (Ikehara et al., 1994; Shirai et al., 1995; Akiba et al., 1995; Oku, 1996; Nakaiwa and Seki, 1999; Baldwin et al., 1999; Baldwin and Tanaka, 1999; Yokoyama and Ochiai, 1999). Secondly, the GT lexicon and ontology, at 400,000 words, is significantly larger than earlier dictionaries, such as the 260,000-word EDR Dictionary (EDR, 1996) and the 2,000-word IPAL lexicon (IPA, 1987; IPA, 1990; IPA, 1996). GT also contains detailed valency information for 16,000 predicate senses, which makes it more suited to our task than the Kadokawa thesaurus (Hamanishi and Ono, 1990). Finally, GT is available in book and CD-ROM format at a price (around US $750) that is seve"
W00-1701,1999.tmi-1.21,1,0.81259,"lication. 2 Goi-Taikei As a base for our tags, we are using the GoiTaikei (GT) Japanese lexicon (Ikehara et al., 1997), a 400,000-word lexicon and ontology developed by NTT for machine translation (MT) applications. We decided that GT is an appropriate resource for our semantic annotation task for three reasons. First, semantic information from GT has already proved valuable in a variety of NLP applications in Japan, including parsing, morphological analysis, text-to-speech, proofreading, and MT (Ikehara et al., 1994; Shirai et al., 1995; Akiba et al., 1995; Oku, 1996; Nakaiwa and Seki, 1999; Baldwin et al., 1999; Baldwin and Tanaka, 1999; Yokoyama and Ochiai, 1999). Secondly, the GT lexicon and ontology, at 400,000 words, is significantly larger than earlier dictionaries, such as the 260,000-word EDR Dictionary (EDR, 1996) and the 2,000-word IPAL lexicon (IPA, 1987; IPA, 1990; IPA, 1996). GT also contains detailed valency information for 16,000 predicate senses, which makes it more suited to our task than the Kadokawa thesaurus (Hamanishi and Ono, 1990). Finally, GT is available in book and CD-ROM format at a price (around US $750) that is several times lower than EDR. GT consists of three main compo"
W00-1701,J96-2004,0,0.0123084,"Missing"
W00-1701,W98-1102,0,0.0268232,"the right conditions. 1 Introduction Semantic annotations have proved valuable for a variety of NLP tasks, including parsing, word sense disambiguation, coreference resolution, summarization, and information retrieval and extraction. The most challenging domain for all these tasks is spontaneous spoken language, which tends to be more terse, less grammatical, less structured, and more ambiguous than planned or written text. For this reason, the annotation of spoken language corpora with accurate, high-quality linguistic tags has become a topic of great interest recently (Dybkjær et al., 1998; Ide, 1998; Core et al., 1999). The target of our semantic annotations is the CallHome Japanese (CHJ) corpus (LDC, 1996). The CHJ corpus consists of digitized speech data and text transcriptions of 120 spontaneous, unscripted telephone conversations in Japanese. Each transcript is en⇤ Visiting CSLI, Stanford University (1999-2000). Francis Bond⇤ Machine Translation Research Group NTT Communication Science Laboratories 2-4 Hikari-dai, Kyoto 619-0237 JAPAN bond@cslab.kecl.ntt.co.jp coded in EUC-format Japanese characters and covers a contiguous 5 or 10 minute segment taken from a recorded conversation las"
W00-1701,1999.tmi-1.19,0,0.0174343,"ser-based annotation application. 2 Goi-Taikei As a base for our tags, we are using the GoiTaikei (GT) Japanese lexicon (Ikehara et al., 1997), a 400,000-word lexicon and ontology developed by NTT for machine translation (MT) applications. We decided that GT is an appropriate resource for our semantic annotation task for three reasons. First, semantic information from GT has already proved valuable in a variety of NLP applications in Japan, including parsing, morphological analysis, text-to-speech, proofreading, and MT (Ikehara et al., 1994; Shirai et al., 1995; Akiba et al., 1995; Oku, 1996; Nakaiwa and Seki, 1999; Baldwin et al., 1999; Baldwin and Tanaka, 1999; Yokoyama and Ochiai, 1999). Secondly, the GT lexicon and ontology, at 400,000 words, is significantly larger than earlier dictionaries, such as the 260,000-word EDR Dictionary (EDR, 1996) and the 2,000-word IPAL lexicon (IPA, 1987; IPA, 1990; IPA, 1996). GT also contains detailed valency information for 16,000 predicate senses, which makes it more suited to our task than the Kadokawa thesaurus (Hamanishi and Ono, 1990). Finally, GT is available in book and CD-ROM format at a price (around US $750) that is several times lower than EDR. GT consis"
W00-1701,C96-2146,0,0.0149572,"es our browser-based annotation application. 2 Goi-Taikei As a base for our tags, we are using the GoiTaikei (GT) Japanese lexicon (Ikehara et al., 1997), a 400,000-word lexicon and ontology developed by NTT for machine translation (MT) applications. We decided that GT is an appropriate resource for our semantic annotation task for three reasons. First, semantic information from GT has already proved valuable in a variety of NLP applications in Japan, including parsing, morphological analysis, text-to-speech, proofreading, and MT (Ikehara et al., 1994; Shirai et al., 1995; Akiba et al., 1995; Oku, 1996; Nakaiwa and Seki, 1999; Baldwin et al., 1999; Baldwin and Tanaka, 1999; Yokoyama and Ochiai, 1999). Secondly, the GT lexicon and ontology, at 400,000 words, is significantly larger than earlier dictionaries, such as the 260,000-word EDR Dictionary (EDR, 1996) and the 2,000-word IPAL lexicon (IPA, 1987; IPA, 1990; IPA, 1996). GT also contains detailed valency information for 16,000 predicate senses, which makes it more suited to our task than the Kadokawa thesaurus (Hamanishi and Ono, 1990). Finally, GT is available in book and CD-ROM format at a price (around US $750) that is several times l"
W00-1701,W00-1003,0,\N,Missing
W02-1608,2002.tmi-papers.6,1,0.635346,"nation consists of JU , an Unknown word for which we have no valency information; E, its English translation (or translations); which is linked to one or more valency patterns JV in the valency dictionary. Figure 1 shows the overall flow of creating candidate patterns. For each entry in the plain J-E dictionary • If no entries with the same Japanese (J U ) exist in the valency dictionary – For each valency entry (JV ) with the same English (E) ∗ Create a candidate pattern consisting of JV replaced by JU Figure 1: Creating Candidate Patterns Experimental Method The approach is based on that of Fujita and Bond (2002). For the explanation we assume 1 We use the following abbreviations: top: topic postposition; acc: accusative postposition; dat: dative postposition; quot: quotative postposition; NP: noun phrase: Cl: clause; V: verb. 2 The subordinate clause is incorrectly translated as a that-clause. This is a bug in the English generation; the Japanese parse and semantic structure are correct. The definition of “similar meaning” used to generate new patterns is that they have the same English translation. We had to make this quite loose: any entry with the same En3 We call an entry in the valency dictionar"
W02-1608,1991.mtsummit-papers.16,0,0.0367023,"rth.” with: The king ordered a follower that sallied forth. without: * ordered to a follower that the king, sallied forth. In general, translation tends to simplify text, because the target language will not be able to represent exactly the same shades of meaning as the source text, so there is some semantic loss. Therefore, in many cases, a single target language entry is the translation of many similar source patterns. For example, there are 23 Japanese predicates linked to the English entry report in the valency dictionary used by the Japanese-to-English machine translation system ALT-J/E (Ikehara et al., 1991). 2 that the source language is Japanese, and the target language is English, although nothing depends on this. 2.1 Method of Making New Patterns Our method is based on two facts: (1) verbs with similar meanings typically have similar valency structures; (2) verbs with identical translations typically have similar meanings. We use three resources: (1) a seed valency dictionary (in this case the verbs from ALT-J/E’s valency dictionary, ignoring all idiomatic and adjectival entries — this gave 5,062 verbs and 11,214 valency patterns3 ) ; (2) a plain bilingual dictionary which contains word pairs"
W02-1608,H01-1043,0,0.832196,"Missing"
W02-1608,W97-0123,0,0.0289452,"Missing"
W02-1608,P93-1032,0,\N,Missing
W03-1010,P03-1059,1,0.881675,"which simply looks at the distribution of features in the corpus data, and agreement-based representation which analyses the level of tokenwise agreement between multiple preprocessor systems. We additionally compare a single multiclass classifier architecture with a suite of binary classifiers, and combine analyses from multiple preprocessors. Finally, we present and evaluate a feature selection method. with differences in meaning: I submitted two papers “documents” (countable) vs. Please use white paper “substance to be written on” (uncountable). This research complements that described in Baldwin and Bond (2003), where we present the linguistic foundations and features drawn upon in the countability classification task, and motivate the claim that countability preferences can be learned from corpus evidence. In this paper, we focus on the methods used to tackle the task of countability classification based on this fixed feature set. The remainder of this paper is structured as follows. Section 2 outlines the countability classes, resources and pre-processors. Section 3 presents two methods of representing the feature space. Section 4 details the different classifier designs and the dataset, which are"
W03-1010,C02-1052,1,0.32975,"Missing"
W03-1010,C02-1013,0,0.019961,"ates to extract out the features from the processed data. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjong Kim Sang and Buchholz, 2000) chunkconverted versions of the full Brown and WSJ corpora. For the NP-internal features (e.g. determiners, head number), we used the noun chunks directly, or applied POS-based templates locally within noun chunks. For inter-chunk features (e.g. subject–verb agreement), we looked at only adjacent chunk pairs so as to maintain a high level of precision. We read dependency tuples directly off the output of RASP (Briscoe and Carroll, 2002b) in grammatical relation mode.1 RASP has the advantage that recall is high, although precision is potentially lower 1 We used the first parse in the experiments reported here. An alternative method would be to use weighted dependency tuples, as described in Briscoe and Carroll (2002a). than chunking or tagging as the parser is forced into resolving phrase attachment ambiguities and committing to a single phrase structure analysis. After generating the different feature vectors for each noun based on the above configurations, we filtered out all nouns which did not occur at least 10 times in"
W03-1010,briscoe-carroll-2002-robust,0,0.0389787,"ates to extract out the features from the processed data. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjong Kim Sang and Buchholz, 2000) chunkconverted versions of the full Brown and WSJ corpora. For the NP-internal features (e.g. determiners, head number), we used the noun chunks directly, or applied POS-based templates locally within noun chunks. For inter-chunk features (e.g. subject–verb agreement), we looked at only adjacent chunk pairs so as to maintain a high level of precision. We read dependency tuples directly off the output of RASP (Briscoe and Carroll, 2002b) in grammatical relation mode.1 RASP has the advantage that recall is high, although precision is potentially lower 1 We used the first parse in the experiments reported here. An alternative method would be to use weighted dependency tuples, as described in Briscoe and Carroll (2002a). than chunking or tagging as the parser is forced into resolving phrase attachment ambiguities and committing to a single phrase structure analysis. After generating the different feature vectors for each noun based on the above configurations, we filtered out all nouns which did not occur at least 10 times in"
W03-1010,J96-2004,0,0.0162335,"te 3n independent feature values. In the case of a two-dimensional feature matrix (e.g. subject-position noun number vs. verb number agreement), each unit feature f s,t for target noun w is translated into corpfreq(f s,t , w ), wordfreq(f s,t , w ) and featfreq(f s,t , w ) as above, and 2 additional feature values: featdimfreq  (f s,t , w ) featdimfreq  (f s,t , w ) agr (f s ,w ) (sys  , sys  ) = |tok (f s ,w ) (sys  ) ∩ tok (f s ,w ) (sys  )| |tok (f s ,w ) (sys  ) ∪ tok (f s ,w ) (sys  )| where tok (f s ,w ) (sys i ) returns the set of token instances of (f s , w ). The κ statistic (Carletta, 1996) is recast as: P κ(f s ,w ) (sys  , sys  ) = agr (f s ,w ) (sys  , sys  ) − P − agr (f ,∗) (sys  ,sys  ) s N agr (f ,∗) (sys  ,sys  ) s N In this modified form, κ(f s ,w ) represents the divergence in relative agreement wrt f s for target noun w , relative to the mean relative agreement wrt f s over all words. Correlated frequency is defined to be: cfreq (f s ,w ) (sys  , sys  ) = |tok (f s ,w ) (sys  ) ∩ tok (f s ,w ) (sys  )| freq(w ) It describes the occurrence of tokens in agreement for (f s , w ) relative to the total occurrence of the target word. The metrics are used to der"
W03-1010,1991.mtsummit-papers.16,0,0.0583768,"y have a plural form, such as goods, and cannot be either denumerated or modified by much; many plural only nouns, such as clothes, use the plural form even as modifiers: a clothes horse. Bipartite nouns are plural when they head a noun phrase (trousers), but generally singular when used as a modifier (trouser leg); they can be denumerated with the classifier pair: a pair of scissors. 2.2 Gold standard data Information about noun countability was obtained from two sources: COMLEX 3.0 (Grishman et al., 1998) and the common noun part of ALTJ/E’s Japanese-to-English semantic transfer dictionary (Ikehara et al., 1991). Of the approximately 22,000 noun entries in COMLEX, 13,622 are marked as countable, 710 as uncountable and the remainder are unmarked for countability. ALT-J/E has 56,245 English noun types with distinct countability. 2.3 Feature space Features used in this research are divided up into feature clusters, each of which is conditioned on the occurrence of a target noun in a given construction. Feature clusters are either one-dimensional (describing a single multivariate feature) or twodimensional (describing the interaction between two multivariate features), with each dimension describing a le"
W03-1010,N01-1006,0,0.134442,"is the number of the target noun for each 2.4 Feature extraction The values for the features described above were extracted from the written component of the British National Corpus (BNC, Burnard (2000)) using three different pre-processors: (a) a POS tagger, (b) a fulltext chunker and (c) a dependency parser. These are used independently to test the efficacy of the different systems at capturing features used in the classification process, and in tandem to consolidate the strengths of the individual methods. With the POS extraction method, we first tagged the BNC using an fnTBL-based tagger (Ngai and Florian, 2001) trained over the Brown and WSJ corpora and based on the Penn POS tagset. We then lemmatised this data using a Penn tagset-customised version of morph (Minnen et al., 2001). Finally, we implemented a range of high-precision, low-recall POS-based templates to extract out the features from the processed data. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjong Kim Sang and Buchholz, 2000) chunkconverted versions of the full Brown and WSJ corpora. For the NP-internal features (e.g. determiners, head number), we used the noun chunks directly, or appl"
W03-1010,W00-0726,0,0.0450574,"process, and in tandem to consolidate the strengths of the individual methods. With the POS extraction method, we first tagged the BNC using an fnTBL-based tagger (Ngai and Florian, 2001) trained over the Brown and WSJ corpora and based on the Penn POS tagset. We then lemmatised this data using a Penn tagset-customised version of morph (Minnen et al., 2001). Finally, we implemented a range of high-precision, low-recall POS-based templates to extract out the features from the processed data. For the chunker, we ran fnTBL over the lemmatised tagged data, training over CoNLL 2000style (Tjong Kim Sang and Buchholz, 2000) chunkconverted versions of the full Brown and WSJ corpora. For the NP-internal features (e.g. determiners, head number), we used the noun chunks directly, or applied POS-based templates locally within noun chunks. For inter-chunk features (e.g. subject–verb agreement), we looked at only adjacent chunk pairs so as to maintain a high level of precision. We read dependency tuples directly off the output of RASP (Briscoe and Carroll, 2002b) in grammatical relation mode.1 RASP has the advantage that recall is high, although precision is potentially lower 1 We used the first parse in the experiment"
W04-1901,C04-1193,1,0.769385,"Missing"
W04-1901,C02-2025,0,0.0635792,"Missing"
W04-1901,W02-1210,0,0.14637,"e who drives a car .” ) 1 hito “person” h292:driveri (⊂ 4:person)       removing screws .”          Figure 1: Entry for the Word doraib¯ a “driver” (with English glosses) put of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. By using a Japanese grammar (JACY: Siegel and Bender (2002)) based on a monostratal theory of grammar (HPSG: Pollard and Sag (1994)) we could simultaneously annotate syntactic and semantic structure without overburdening the annotator. The treebank records the complete syntacto-semantic analysis provided by the HPSG grammar, along with an annotator’s choice of the most appropriate parse. From this record, all kinds of information can be extracted at various levels of granularity. In particular, traditional syntactic structure (e.g., in the form of labeled trees), dependency relations between words and full meaning representations using minimal recursi"
W04-1901,P00-1023,0,\N,Missing
W04-1901,E03-1054,0,\N,Missing
W04-1901,W00-1905,0,\N,Missing
W04-2206,P98-1013,0,0.022942,"Missing"
W04-2206,1999.tmi-1.21,1,0.75369,"also be used directly, either as lexical/translation rules or to generate transitive and intransitive entries from a common underlying representation. For example, Shirai et al. (1999) uses the existing entries and lexical rules deploying them to translate causatives and passives (including adversative passives) from Japanese to English. Trujillo (1995) showed a method to apply lexical rules for word translation. That is, they expand the vocabulary using prepared lexical rules for each language, and create links for translation between the lexical rules of a pair of languages. Dorr (1997) and Baldwin et al. (1999) generate both alternates from a single underlying representation. Our proposed method could partially be implemented as a lexical or a translation rule. But not all the word senses alternate (§ 4.2), and not all the target language entries are regularly translated by the same head (§ 3). Further many of the 4 5 My friend passed away ↔ I lost my friend . http://www.papillon-dictionary.org/ rules mix lexical and syntactic information, making them quite complicated. Because of that, it is easier to expand out the rules beforehand and enter them into the system. 6.4 Further Work In this paper, we"
W04-2206,2002.tmi-papers.6,1,0.82951,"Missing"
W04-2206,1991.mtsummit-papers.16,0,0.117168,"Missing"
W04-2206,E93-1026,0,0.0210113,"se roles and translation of the linked valency pairs. 3 3.1 The Nature of the S=O Alternation Comparing Selectional Restrictions of A, O and S In alternations, a given semantic role typically appears in two different syntactic positions: for example, the dissolved role is the subject of intransitive dissolve and the object of the transitive. Baldwin et al. (1999) hypothesized that selectional restrictions (SRs) stay constant in the different syntactic positions. Dorr (1997), who generates both alternations from a single underlying representation, implicitly makes this assumption. In addition, Kilgarriff (1993) specifically makes the A h+sentient, +volitioni, while the O is h+changes-state, +causally affectedi. However, we know of no quantitative studies of the similarities of alternating verbs. Exploiting the machine translation lexicon for linguistic research, we compare the SRs of S with both A and O for verbs that take the S=O alternation. The SRs take the form of a list of semantic classes, strings or *. Strings only match specific words, while * matches anything, even non-nouns. The semantic classes are from the GoiTaikei ontology of 2,710 categories (Ikehara et al., 1997). It is an unbalanced"
W04-2206,W02-0907,0,0.0532335,"Missing"
W04-2206,A00-2034,0,0.0324807,"ata) creating valency entries is as follows. (1) • If the alternation requires a dependent not in the source Add the default argument We use the most frequent argument in existing valency entries as a default. Specific examples of creating S = O alternations are given in the next section. Although we only discuss the selectional restrictions and subcat information here, we also map the verb classes (given as verbal semantic attributes (Nakaiwa and Ikehara, 1997)). The mapping for the dependents in the alternation can be taken from existing lexical resources (Dorr, 1997), learned from corpora (McCarthy, 2000) or learned from existing lexicons (Bond et al., 2002). 4.1 Target In this experiment, we look at one family of alternations, the S = O alternation. The candidate words are thus intransitive verbs with no transitive alternate, or transitive entries with no intransitive alternate. Alternations should be between senses, but the alternation list is only of words. Many of the candidate words (those that have a entry for only one alternate) have several entries. Only some of these are suitable as seeds. We don’t use entries which are intransitive lemmas but have an accusative argument, which are in"
W04-2206,1995.tmi-1.4,0,0.0317389,"tion of the English translations by using richer English information, especially about past-participles or verb senses. 6.3 Usage as a Lexical/Translation Rule Although we have investigated the use of alternations in lexicon construction, the algorithms could also be used directly, either as lexical/translation rules or to generate transitive and intransitive entries from a common underlying representation. For example, Shirai et al. (1999) uses the existing entries and lexical rules deploying them to translate causatives and passives (including adversative passives) from Japanese to English. Trujillo (1995) showed a method to apply lexical rules for word translation. That is, they expand the vocabulary using prepared lexical rules for each language, and create links for translation between the lexical rules of a pair of languages. Dorr (1997) and Baldwin et al. (1999) generate both alternates from a single underlying representation. Our proposed method could partially be implemented as a lexical or a translation rule. But not all the word senses alternate (§ 4.2), and not all the target language entries are regularly translated by the same head (§ 3). Further many of the 4 5 My friend passed awa"
W04-2206,C98-1013,0,\N,Missing
W06-0502,C04-1185,0,0.0423415,"Missing"
W06-0502,1991.mtsummit-papers.16,0,0.0610952,"Missing"
W06-0502,W02-2016,0,0.013304,"part-of-speech tagger, ChaSen (Matsumoto et al., 2000) was used for shallow processing of Japanese. Predicate names were produced by transliterating the pronunciation field and mapping the part-of-speech codes to the RMRS super types. The part-of-speech codes were also used to judge whether predicates were real or grammatical. Since Japanese is a head-final language, the hook value was set to be the handle of the right-most real predicate. This is easy to do for Japanese, but difficult for English. Medium Parser (CaboCha-RMRS) For Japanese, we produce RMRS from the dependency parser Cabocha (Kudo and Matsumoto, 2002). The method is similar to that of Spreyer and Frank (2005), who produce RMRS from detailed German dependencies. CaboCha provides fairly minimal dependencies: there are three links (dependent, parallel, apposition) and they link base phrases (Japanese bunsetsu), marked with the syntactic and semantic head. The CaboChaRMRS parser uses this information, along with heuristics based on the parts-of-speech, to produce underspecified RMRSs. CaboCha-RMRS is capable of making use of HPSG resources, including verbal case frames, to further enrich its output. This allows it to produce RMRS that approach"
W06-0502,P98-2180,0,0.0441011,"yet to be seen how the rules will scale when deeper semantic relations are extracted. In comparison, as we will demonstrate, our system produces comparable results while the framework is immediately applicable to any language with the resources to produce RMRS. Advances in the state-of-the-art in parsing have made it practical to use deep processing systems that produce rich syntactic and semantic analyses to parse lexicons. This high level of semantic information makes it easy to identify the relations between words that make up an ontology. Such an approach was taken by the MindNet project (Richardson et al., 1998). However, deep parsing systems often suffer from small lexicons and large amounts of parse ambiguity, making it difficult to apply this knowledge broadly. Our ontology extraction system uses Robust Minimal Recursion Semantics (RMRS), a formalism that provides a high level of detail while, at the same time, allowing for the flexibility of underspecification. RMRS encodes syntactic information in a general enough manner to make processing of and extraction from syntactic phenomena including coordination, relative clause analyIn this paper, we outline the development of a system that automatical"
W06-0502,I05-6001,0,0.0259576,"used for shallow processing of Japanese. Predicate names were produced by transliterating the pronunciation field and mapping the part-of-speech codes to the RMRS super types. The part-of-speech codes were also used to judge whether predicates were real or grammatical. Since Japanese is a head-final language, the hook value was set to be the handle of the right-most real predicate. This is easy to do for Japanese, but difficult for English. Medium Parser (CaboCha-RMRS) For Japanese, we produce RMRS from the dependency parser Cabocha (Kudo and Matsumoto, 2002). The method is similar to that of Spreyer and Frank (2005), who produce RMRS from detailed German dependencies. CaboCha provides fairly minimal dependencies: there are three links (dependent, parallel, apposition) and they link base phrases (Japanese bunsetsu), marked with the syntactic and semantic head. The CaboChaRMRS parser uses this information, along with heuristics based on the parts-of-speech, to produce underspecified RMRSs. CaboCha-RMRS is capable of making use of HPSG resources, including verbal case frames, to further enrich its output. This allows it to produce RMRS that approaches the granularity of the analyses given by 3 Ontology Cons"
W06-0502,W04-2209,0,0.0703215,"Missing"
W06-0502,callmeier-etal-2004-deepthought,0,0.0344792,"Missing"
W06-0502,C98-2175,0,\N,Missing
W06-0608,C02-2025,0,0.0707571,"th structural annotation (such as the Penn Treebank (Taylor et al., 2003) or the Kyoto Corpus (Kurohashi and Nagao, 2003)) and semantic annotation (e.g. Senseval: Kilgariff and Rosenzweig, 2000; Shirai, 2002), there are almost no corpora that combine both. This makes it difficult to carry out research on the interaction between syntax and semantics. Projects such as the Penn Propbank are adding structural semantics (i.e. predicate argument structure) to syntactically annotated corpora, but not lexical semantic information (i.e. word senses). Other corpora, such as the English Redwoods Corpus (Oepen et al., 2002), combine both syntactic and structural semantics in a monostratal representation, but still have no lexical semantics. In this paper we discuss the (lexical) semantic annotation for the Hinoki Corpus, which is À{§ 62 Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006, pages 62–69, c Sydney, July 2006. 2006 Association for Computational Linguistics  I NDEX POS   FAMILIARITY      S ENSE 1     (0.11)              S ENSE 2    (0.84)               S ENSE 3     (0.05)       À{§  doraiba noun Lexical-Type nou"
W06-0608,shirai-2002-construction,0,0.505473,"An example doraib¯a “driver” entry for the word is given in Figure 1, with English glosses added. This figure includes the sense annotation and information derived from it that is described in this paper. Table 1 shows the relation between polysemy and familiarity. The #WS column indicates the average number of word senses that polysemous 1 Introduction While there has been considerable research on both structural annotation (such as the Penn Treebank (Taylor et al., 2003) or the Kyoto Corpus (Kurohashi and Nagao, 2003)) and semantic annotation (e.g. Senseval: Kilgariff and Rosenzweig, 2000; Shirai, 2002), there are almost no corpora that combine both. This makes it difficult to carry out research on the interaction between syntax and semantics. Projects such as the Penn Propbank are adding structural semantics (i.e. predicate argument structure) to syntactically annotated corpora, but not lexical semantic information (i.e. word senses). Other corpora, such as the English Redwoods Corpus (Oepen et al., 2002), combine both syntactic and structural semantics in a monostratal representation, but still have no lexical semantics. In this paper we discuss the (lexical) semantic annotation for the Hi"
W06-0608,W04-0811,0,0.0538813,"Missing"
W06-0608,P05-1041,1,0.843727,"uous in the contexts. When they cannot choose a sense in some reasons, they choose one or more of the following special tags. o other sense: an appropriate sense is not found in a lexicon. Relatively novel concepts (e.g. doraib¯a “driver” for “software driver”) are given this tag. À{§ c multiword expressions (compound / idiom): the target word is a part of a non-compositional compound or idiom. 4 Inter-Annotator Agreement p proper noun: the word is a proper noun. We employ inter-annotator agreement as our core measure of annotation consistency, in the same way we did for treebank evaluation (Tanaka et al., 2005). This agreement is calculated as the average of pairwise agreement. Let wi be a word in a set of content words W and wi, j be the jth occurrence of a word wi . Average pairwise agreement between the sense tags of wi, j each pair of annotators marked up a(wi, j ) is: x homonym: an appropriate entry is not found in a lexicon, because a target is different from head words in a lexicon (e.g. only a bass “bus” is present in a headword lexicon for basu “bass”). § § e analysis error: the word segmentation or partof-speech is incorrect due to errors in preannotation of the corpus. 3.3 Feedback a(wi"
W06-1106,W02-2016,0,0.0220472,"he match, otherwise it becomes part of a non-matching EP group. Any group of grammatical EPs that shares an arg0 but does not contain a content predicate is matched against any similar groupings 38 Best score is 0.799 for the match set: MATCHES: hito_n-sha_n: HYPERNYM:2.1 jidousha_n-jidousha_n:EXACT:0 unten_s_2-unten_s_2:EXACT:0.05 proposition_m_rel-proposition_m_rel:EXACT:0 UNMATCHED1: UNMATCHED2: u11: h10001:nado_n When parsing with Jacy failed, comparisons could still be made with RMRS produced from shallow tools such as ChaSen (Matsumoto et al., 2000), a morphological analyser or CaboCha (Kudo and Matsumoto, 2002), a Japanese dependency parser. Tools have been built to produced RMRS from the standard output of both those tools. The CaboCha output supplies similar dependency information to that of the Basic Elements (BE) tool used by Hovy et al. (2005b) for multi-document summarization. Even this intermediate level of parsing gives better comparisons than either word or sequence overlap, since it is easier to compare meaningful elements (Hovy et al., 2005a). Figure 8: Verbose comparison output in the other RMRS. This type of match can only be exact or no match and will make only a small di erence in the"
W06-1106,shirai-2002-construction,0,0.017957,"he de ned term yarou . 4 Evaluation We evaluated the performance of the RMRS comparison method in two tasks. First it was used to indicate whether two sentences were possible paraphrases. In the second task, we used the comparison scores to select the most likely sentence to contain the answer to a question. 4.1 Paraphrasing In this task we compared de nitions sentences for the same head word from two di erent Japanese dictionaries - the Lexeed dictionary (x3.2.1) and the Iwanami Kokugo Jiten (Iwanami: Nishio et al., 1994), the Japanese dictionary used in the SENSEVAL-2 Japanese lexical task (Shirai, 2002). There are 60,321 headwords and 85,870 word senses in Iwanami. Each sense in the dictionary consists of a sense ID and morphological information (word segmentation, POS tag, base form and reading, all manually postedited). The de nitions in Lexeed and Iwanami were linked by headword and three Japanese native speakers assessed each potential pair of sense de nitions for the same head word to judge which de nitions were describing the same sense. This annotation not only described which sense from each dictionary matched, but also whether the de nitions were equal, equivalent, or subsuming. The"
W06-1106,W02-1210,0,0.0180684,"lysis tools that produce the RMRSs, and lexical resources such as ontologies, dictionaries and gazetteers for evaluating matches. 3.1 Lexical Resources 3.2.2 Ontology The lexicon has been sense-tagged and parsed to give an ontology linking senses with various relations, principally hypernym and synonym (Nichols et al., 2005). For example, hhypernym, doraib a driver"", kurabu club""i. The ontology entries for nouns have been hand checked and corrected, including adding hypernyms for words where Parsing Japanese language processing tools are freely available. We used the Japanese grammar Jacy (Siegel and Bender, 2002), a deep parsing HPSG grammar that produces RMRSs for our primary input source. ,+ 39 ),&apos;* ( set being equally split between matching and non-matching pairs. This gives data that is to some extent semantically equivalent (the same word sense is being de ned), but with no guarantee of syntactic equivalence. Comparisons were made between the rst sentence of each de nition with both a Bagof-Words comparison method and our RMRS based method. If RMRS output was not available from Jacy (due to a failed parse), RMRS from CaboCha was used as a fall back shallow parse result. Scores were output and the"
W06-1106,C04-1185,0,0.0180147,"and any structure designated by such, so that the cat snored and the dog slept is equivalent to the dog snored and the cat slept. Sequence matching on the other hand requires exact word order matching and hence the game began quietly and the game quietly began are not considered a match. Neither method allows for synonym matching. 1.1 Robust Minimal Recursion Semantics Robust Minimal Recursion Semantics (RMRS) is a form of at semantics which is designed to allow deep and shallow processing to use a compatible semantic representation, while being rich enough to support generalized quanti ers (Frank, 2004). The main component of an RMRS representation is a bag of elementary predicates and their arguments. An elementary predicate always has a unique label, a relation type, a relation name and an ARG0 feature. The example in Figure 1 has a label of h5 which uniquely identi es this predicate. Relation types can either be realpred for a predicate that relates directly to a content word from the input text, or gpred for grammatical predicates which may not have a direct referent in the text. For examples in this paper, a realpred is distinguished by an underscore ( ) before the relation name. The gp"
W06-1106,C04-1064,0,0.0413722,"Missing"
W07-1204,W00-1320,0,0.129455,"SEM-L2 + SP). The definitions sentences are harder syntactically, and thus get more of a boost from the semantics. The semantics still improve performance for the example sentences. The semantic class based sense features used here are based on manual annotation, and thus show an upper bound on the effects of these features. This is not an absolute upper bound on the use of sense information — it may be possible to improve further through feature engineering. The learning curves (Fig 7) have not yet flattened out. We can still improve by increasing the size of the training data. 5 Discussion Bikel (2000) combined sense information and parse information using a subset of SemCor (with WordNet senses and Penn-II treebanks) to produce a combined model. This model did not use semantic dependency relations, but only syntactic dependencies augmented with heads, which suggests that the deeper structural semantics provided by the HPSG parser is important. Xiong et al. (2005) achieved only a very minor improvement over a plain syntactic model, using features based on both the correlation between predicates and their arguments, and between predicates and the hypernyms of their arguments (using HowNet)."
W07-1204,W04-2206,1,0.833629,"ypernym class for h988:land vehiclei is h706:inanimatei, h2003:motioni is h1236:human activityi and h4:humani is unchanged. So we used h706:inanimatei and h1236:human activityi to make features in the same way as Table 3. An advantage of these underspecified semantic classes is that they are more robust to errors in word sense disambiguation — fine grained sense distinctions can be ignored. 3.2.4 Valency Dictionary Compatability The last kind of semantic information we use is valency information, taken from the Japanese side of the Goi-Taikei Japanese-English valency dictionary as extended by Fujita and Bond (2004).This valency dictionary has detailed information about the argument properties of verbs and adjectives, including subcategorization and selectional restrictions. A simplified entry of the Japanese side for unten-suru “drive” is shown in Figure 6. Each entry has a predicate and several case-slots. Each case-slot has information such as grammatical function, case-marker, case-role (N1, N2, . . . ) and semantic restrictions. The semantic restrictions are defined by the Goi-Taikei’s semantic classes. On the Japanese side of Goi-Taikei’s valency dictionary, there are 10,146 types of verbs giving 1"
W07-1204,N06-2015,0,0.0183902,"move upward (⊃ sky rocket) frequently appear together, which suggests that using word senses and their hypernyms as features may be useful However, to date, there have been few combinations of sense information together with symbolic grammars and statistical models. We hypothesize that one of the reasons for the lack of success is that there has been no resource annotated with both 2 The Hinoki Corpus There are now some corpora being built with the syntactic and semantic information necessary to investigate the use of semantic information in parse selection. In English, the OntoNotes project (Hovy et al., 2006) is combining sense tags with the Penn treebank. We are using Japanese data from the Hinoki Corpus consisting of around 95,000 dictionary definition and example sentences (Bond et al., 2007) annotated with both syntactic parses and senses from the same dictionary. 2.1 Syntactic Annotation Syntactic annotation in Hinoki is grammar based corpus annotation done by selecting the best parse (or parses) from the full analyses derived by a broadcoverage precision grammar. The grammar is an HPSG implementation (JACY: Siegel and Bender, 2002), which provides a high level of detail, marking not only dep"
W07-1204,P03-1054,0,0.00508812,"antic features. Results are given for syntactic features, dependency relations and the use of semantic classes. 1 Introduction In this paper we investigate the use of semantic information in parse selection. Recently, significant improvements have been made in combining symbolic and statistical approaches to various natural language processing tasks. In parsing, for example, symbolic grammars are combined with stochastic models (Oepen et al., 2004; Malouf and van Noord, 2004). Much of the gain in statistical parsing using lexicalized models comes from the use of a small set of function words (Klein and Manning, 2003). Features based on general relations provide little improvement, presumably because the data is too sparse: in the Penn treebank standardly used to train and test statistical parsers stocks and skyrocket never appear together. However, the superordinate concepts capital (⊃ stocks) and move upward (⊃ sky rocket) frequently appear together, which suggests that using word senses and their hypernyms as features may be useful However, to date, there have been few combinations of sense information together with symbolic grammars and statistical models. We hypothesize that one of the reasons for the"
W07-1204,W02-2018,0,0.310709,"Missing"
W07-1204,oepen-lonning-2006-discriminant,1,0.824955,"le in each semantic relation. For most types of relations, the distinguished variable corresponds to the main index (ARG0 in the examples above), e.g. an event variable for verbal relations and a referential index for nominals. Assuming further that, by and large, there is a unique relation for each semantic variable for which it serves as the main index (thus assuming, for example, that adjectives and adverbs have event variables of their own, which can be motivated in predicative usages at least), an MRS can be broken down into a set of basic dependency tuples of the form shown in Figure 4 (Oepen and Lønning, 2006). All predicates are indexed to the position of the word or words that introduced them in the input sentence (<start:end>). This allows us to link them to the sense annotations in the corpus. 3.2.1 Basic Semantic Dependencies The basic semantic model, SEM-Dep, consists of features based on a predicate and its arguments taken from the elementary dependencies. For example, consider the dependencies for densha ya jidoushawo unten suru hito “a person who drives a train or car” given in Figure 4. The predicate unten “drive” has two arguments: ARG 1 hito “person” and ARG 2 jidousha “car”. From these"
W07-1204,W02-1210,0,0.0338149,"information in parse selection. In English, the OntoNotes project (Hovy et al., 2006) is combining sense tags with the Penn treebank. We are using Japanese data from the Hinoki Corpus consisting of around 95,000 dictionary definition and example sentences (Bond et al., 2007) annotated with both syntactic parses and senses from the same dictionary. 2.1 Syntactic Annotation Syntactic annotation in Hinoki is grammar based corpus annotation done by selecting the best parse (or parses) from the full analyses derived by a broadcoverage precision grammar. The grammar is an HPSG implementation (JACY: Siegel and Bender, 2002), which provides a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. As the grammar is based on a monostratal theory of grammar (HPSG: Pollard and Sag, 1994), annotation by manual disambiguation determines syntactic and semantic structure at the same time. Using a grammar 25 Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, pages 25–32, c Prague, Czech Republic, June, 2007. 2007 Association for Computational Linguistics helps treebank consistency — all sentences annotated are guaranteed to have well-formed parses"
W07-1204,I05-1007,0,\N,Missing
W07-1204,J97-4005,0,\N,Missing
W07-1204,J08-1002,0,\N,Missing
W07-1204,W06-1670,0,\N,Missing
W07-1204,P08-1037,0,\N,Missing
W07-1204,P02-1035,0,\N,Missing
W07-1204,P99-1069,0,\N,Missing
W09-3026,P07-2045,0,0.0364426,"alignment? (iii) which environments should be prepared for users? This paper covers these matters related to bilingual resources and their use. The language resource that this paper handles is the Sejong Korean-Japanese Bilingual Corpus (henceforth SKJBC). 1 The original version of the SKJBC, constructed in a XML format, aligns sentence by Francis Bond NICT Language Infrastructure Group 2-2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan bond@ieee.org sentence or paragraph by paragraph. This research re-organizes and re-aligns the original version using GIZA++ (Och and Ney, 2003) and Moses (Koehn et al. 2007), and interpolates the aligning information into each original file automatically. Turning to the interface, this research converts the whole data into a database system (MySQL) to guarantee data integrity. Building on the database, this research implements an online search system accessible without any restrictions; dubbed NARA2. 2 The SKJBC The SKJBC had been constructed as a subset of the Sejong project 3 which had been carried out from 1998 to 2007, sponsored by the Korean government. The SKJBC is divided into two parts; one is the raw corpus annotated only with sentence aligning indices,"
W09-3026,P02-1040,0,\N,Missing
W09-3026,J03-1002,0,\N,Missing
W09-3401,vossen-etal-2008-kyoto,1,\N,Missing
W09-3401,C04-1053,0,\N,Missing
W09-3401,W04-2209,0,\N,Missing
W09-3401,W04-2208,1,\N,Missing
W09-3401,W07-1522,0,\N,Missing
W09-3401,I08-2108,1,\N,Missing
W09-3401,bond-etal-2008-boot,1,\N,Missing
W09-3401,francopoulo-etal-2006-lexical,0,\N,Missing
W09-3401,1991.mtsummit-papers.16,0,\N,Missing
W10-3219,W02-1502,0,0.312271,"on linguistic data with theory-oriented approaches, is unable to yield efficient parsing or generation. The additional limit of the KRG1 is its unattested parsing efficiency with a large scale of naturally occurring data, which is a prerequisite to the practical uses of the developed grammar in the area of MT. Such weak points have motivated us to move the development of KRG to a data-driven approach from a theory-based one upon which the KRG1 is couched. In particular, this second phase of the KRG (henceforth, KRG2) also starts with two methods: shared grammar libraries (the Grammar Matrix (Bender et al., 2002; Bender et al., 2010)) and data-driven expansion (using the Korean portions of multilingual texts). Next, we introduce the resources we used (§ 2). this is followed by more detailed motivation for our extensions (§ 3). We then detail how we use the grammar libraries from the Grammar Matrix to enable generation (§ 2) and then expand the coverage based on a corpus study (§ 5). 2 2.1 Background Open Source NLP with HPSG The Deep Linguistic Processing with HPSG Initiative (DELPH-IN: www.delph-in.net) provides an open-source collection of tools and grammars for deep linguistic processing of human"
W10-3219,P10-4001,0,0.0880127,"ith theory-oriented approaches, is unable to yield efficient parsing or generation. The additional limit of the KRG1 is its unattested parsing efficiency with a large scale of naturally occurring data, which is a prerequisite to the practical uses of the developed grammar in the area of MT. Such weak points have motivated us to move the development of KRG to a data-driven approach from a theory-based one upon which the KRG1 is couched. In particular, this second phase of the KRG (henceforth, KRG2) also starts with two methods: shared grammar libraries (the Grammar Matrix (Bender et al., 2002; Bender et al., 2010)) and data-driven expansion (using the Korean portions of multilingual texts). Next, we introduce the resources we used (§ 2). this is followed by more detailed motivation for our extensions (§ 3). We then detail how we use the grammar libraries from the Grammar Matrix to enable generation (§ 2) and then expand the coverage based on a corpus study (§ 5). 2 2.1 Background Open Source NLP with HPSG The Deep Linguistic Processing with HPSG Initiative (DELPH-IN: www.delph-in.net) provides an open-source collection of tools and grammars for deep linguistic processing of human language within the HP"
W10-3219,2005.mtsummit-osmtw.3,1,0.895558,"Missing"
W10-3219,2008.iwslt-papers.2,1,0.819273,"ue in the KRG1 is that some of the defined types and rules in the grammar are inefficient in generation. Because the declared types and rules are defined with theoretical motivations, the run-time for generating any parsing units within the system takes more than expected and further causes memory overflow errors to crop up almost invariably, even though the input is quite simple. This problem is partially due to the complex morphological inflection system in the KRG1. Section 4.2 discusses how KRG2, solves this problem. Third it is better “to be robust for parsing and strict for generation” (Bond et al., 2008). That means robust rules will apply in parsing, though the input sentence does not sound perfect, but not in generation. For example, the sentence (1b), the colloquial form of the formal, standard sentence (1a), is used more frequently in colloquial context: (1) a. ney-ka cham yeppu-ney. you-NOM really pretty-DECL ‘You are really pretty.’ b. ni-ka cham ippu-ney The grammar needs to parse both (1a) and (1b) and needs to yield the same MRS because both sentences convey the same truthconditional meaning. However, the KRG1 handles only the legitimate sentence (1a), excluding (1b). The KRG1 is thu"
W10-3219,W02-1210,0,0.0282575,"s for deep linguistic processing of human language within the HPSG and MRS (Minimal Recursion Semantics (Copestake et al., 2005)) framework. The resources include software packages, such as the LKB for parsing and generation, PET (Callmeier, 2000) for parsing, and a profiling tool [incr tsdb()] (Oepen, 2001). There are also several grammars: e.g. ERG; the 144 Proceedings of the 8th Workshop on Asian Language Resources, pages 144–152, c Beijing, China, 21-22 August 2010. 2010 Asian Federation for Natural Language Processing English Resource Grammar (Flickinger, 2000), Jacy; a Japanese Grammar (Siegel and Bender, 2002), the Spanish grammar, and so forth. These along with some pre-compiled versions of preprocessing or experimental tools are packaged in the LOGON distribution.1 Most resources are under the MIT license, with some parts under other open licenses such as the LGPL.2 The KRG has been constructed within this open-source infrastructure, and is released under the MIT license3 . 2.2 The Grammar Matrix The Grammar Matrix (Bender et al., 2002; Bender et al., 2010) offers a well-structured environment for the development of precision-based grammars. This framework plays a role in building a HPSG/MRS-base"
W10-3219,Y03-1010,1,0.813698,"hyang@kangnam.ac.kr Abstract The Korean Resource Grammar (KRG) is a computational open-source grammar of Korean (Kim and Yang, 2003) that has been constructed within the DELPH-IN consortium since 2003. This paper reports the second phase of the KRG development that moves from a phenomenabased approach to grammar customization using the LinGO Grammar Matrix. This new phase of development not only improves the parsing efficiency but also adds generation capacity, which is necessary for many NLP applications. 1 Introduction The Korean Resource Grammar (KRG) has been under development since 2003 (Kim and Yang, 2003) with the aim of building an open source grammar of Korean. The grammatical framework for the KRG is Head-driven Phrase Structure Grammar (HPSG: (Pollard and Sag, 1994; Sag et al., 2003)), a non-derivational, constraintbased, and surface-oriented grammatical architecture. The grammar models human languages as systems of constraints on typed feature structures. This enables the extension of grammar in a systematic and efficient way, resulting in linguistically precise and theoretically motivated descriptions of languages. The initial stage of the KRG (hereafter, KRG1) has covered a large part o"
W11-0814,P05-1032,0,0.0113233,"re for extracting transfer rules for multiword expressions from parallel corpora for use in a rule based Japanese-English MT system. We show that adding the multi-word rules improves translation quality and sketch ideas for learning more such rules. 1 Introduction Because of the great ambiguity of natural language, it is hard to translate from one language to another. To deal with this ambiguity it is common to try to add more context to a word, either in the form of multi-word translation patterns (Ikehara et al., 1991) or by adding more context to the translations in statistical MT systems (Callison-Burch et al., 2005). In this paper, we present a way to learn large numbers of multi-word translation rules from either dictionaries or parallel text, and show their effectiveness in a semantic–transfer-based Japanese-toEnglish machine translation system. This research is similar to work such as Nichols et al. (2007). The novelty lies in (i) the fact that we are learning rules from parallel text and (ii) that we are learning much more complex rules. In Section 2, we outline the semantic transfer machinery and we introduce the DELPH - IN machine translation initiative that provided the resources used in its const"
W11-0814,copestake-etal-2002-multiword,1,0.862589,"ig a whole would have been translated using existing rules. In this case the advantage of the MWE rule is that it reduces the search space, so the system does not have to consider less likely translations such as carve the shortages. More interestingly, many of the rules find non-compositional translations, or those where the structure cannot be translated word for word. Some of these are also idiomatic in the source and target language. One of our long term goals is to move these expressions into the source and target grammars. Currently, both Jacy and the ERG have idiom processing (based on Copestake et al., 2002), but there are few idiomatic entries in their lexicons. Bilingual data can be a good source for identifying these monolingual idioms, as it makes the non-compositionality explicit. An example of a rule that uses the current idiom machinery is the (hand-built) rule N-ga chie-wo shiboru “N squeezes knowledge” → N racks N’s brains, where the subject is co-indexed with a possessive pronoun modifying the object: I/You rack my/your brains. Adding such expressions to the monolingual grammars simplifies the transfer rules and makes the grammars more useful for other tasks. In this paper we only prese"
W11-0814,W04-2209,0,0.034611,"T|RELS LBL h0 , ARG0 e0 , ARG1 ext Procedure We are using GIZA++ (Och and Ney, 2003) and Anymalign (Lardilleux and Lepage, 2009) to generate phrase tables from a collection of four Japanese English parallel corpora and one bilingual dictionary. The corpora are the Tanaka Corpus (2,930,132 words: Tanaka (2001)), the Japanese Wordnet Corpus (3,355,984 words: Bond et al. (2010)), the Japanese Wikipedia corpus (7,949,605),3 and the Kyoto University Text Corpus with NICT translations (1,976,071 words: Uchimoto et al. (2004)). The dictionary is Edict, a Japanese English dictionary (3,822,642 words: Breen (2004)). The word totals include both English and Japanese words. We divided the corpora into development, test, and training data, and extracted the transfer rules from the training data. The training data of the four corpora together with the Edict dictionary form a parallel corpus of 20 million words (9.6 million English words and 10.4 million Japanese words). The Japanese text is tokenized and lemmatized with the MeCab morphological analyzer (Kudo et al., 2004), and the English text is tokenized and lemmatized with the Freeling analyzer (Padró et al., 2010), with MWE, quantities, dates and sente"
W11-0814,1991.mtsummit-papers.16,0,0.170727,"niversity, Singapore petterha@ntu.edu.sg,bond@ieee.org Abstract 2 This paper presents a procedure for extracting transfer rules for multiword expressions from parallel corpora for use in a rule based Japanese-English MT system. We show that adding the multi-word rules improves translation quality and sketch ideas for learning more such rules. 1 Introduction Because of the great ambiguity of natural language, it is hard to translate from one language to another. To deal with this ambiguity it is common to try to add more context to a word, either in the form of multi-word translation patterns (Ikehara et al., 1991) or by adding more context to the translations in statistical MT systems (Callison-Burch et al., 2005). In this paper, we present a way to learn large numbers of multi-word translation rules from either dictionaries or parallel text, and show their effectiveness in a semantic–transfer-based Japanese-toEnglish machine translation system. This research is similar to work such as Nichols et al. (2007). The novelty lies in (i) the fact that we are learning rules from parallel text and (ii) that we are learning much more complex rules. In Section 2, we outline the semantic transfer machinery and we"
W11-0814,P03-1057,0,0.0199594,"formation between the templates. We therefore estimate that we can greatly reduce the sparseness of rule-types with four weeks work. To improve the coverage of rule instances, we need to look at more data, such as that aligned by Utiyama and Takahashi (2003). Neither absolute frequency nor estimated translation probability give reliable thresholds for determining whether rules are good or not. Currently we are investigating two solutions. One is feedback cleaning, where we investigate the impact of each new rule and discard those that degrade translation quality, following the general idea of Imamura et al. (2003). The second is the more traditional humanin-the loop: presenting each rule and a series of relevant translation pairs to a human and asking them to judge if it is good or not. Ultimately, we would like 98 to extend this approach to crowd source the decisions. There are currently two very successful online collaborative Japanese-English projects (Edict and Tatoeba, producing lexical entries and multilingual examples respectively) which indicates that there is a large pool of interested knowledgeable people. Finally, we are working in parallel to qualitatively improve the MWE rules in two ways."
W11-0814,W04-3230,0,0.0245787,"pus with NICT translations (1,976,071 words: Uchimoto et al. (2004)). The dictionary is Edict, a Japanese English dictionary (3,822,642 words: Breen (2004)). The word totals include both English and Japanese words. We divided the corpora into development, test, and training data, and extracted the transfer rules from the training data. The training data of the four corpora together with the Edict dictionary form a parallel corpus of 20 million words (9.6 million English words and 10.4 million Japanese words). The Japanese text is tokenized and lemmatized with the MeCab morphological analyzer (Kudo et al., 2004), and the English text is tokenized and lemmatized with the Freeling analyzer (Padró et al., 2010), with MWE, quantities, dates and sentence segmentation turned off. When applying GIZA++ and Anymalign to the lemmatized parallel corpus they produced phrase tables with 10,812,423 and 5,765,262 entries, respectively, running GIZA++ with the default MOSES settings and Anymalign for approximately 16 hours. 3 The Japanese-English Bilingual Corpus of Wikipedia’s Kyoto Articles: http://alaginrc.nict.go.jp/WikiCorpus/ index_E.html We filtered out the entries with an absolute frequency of 1,4 and which"
W11-0814,2007.tmi-papers.17,1,0.841141,"language, it is hard to translate from one language to another. To deal with this ambiguity it is common to try to add more context to a word, either in the form of multi-word translation patterns (Ikehara et al., 1991) or by adding more context to the translations in statistical MT systems (Callison-Burch et al., 2005). In this paper, we present a way to learn large numbers of multi-word translation rules from either dictionaries or parallel text, and show their effectiveness in a semantic–transfer-based Japanese-toEnglish machine translation system. This research is similar to work such as Nichols et al. (2007). The novelty lies in (i) the fact that we are learning rules from parallel text and (ii) that we are learning much more complex rules. In Section 2, we outline the semantic transfer machinery and we introduce the DELPH - IN machine translation initiative that provided the resources used in its construction. We describe in more detail how we learn new rules in Section 3, and show their effect in Section 4. We briefly discuss the results and outline future work in Section 5 and, finally, we conclude this paper in Section 6. Semantic transfer All experiments are carried out using Jaen, a semanti"
W11-0814,J03-1002,0,0.0039134,"have event indices (written with an e). 2 The HCONS feature has as value a list of qeq constraints (equality modulo quantifiers), which function is to express that the label of a relation is equal to a handle in an argument position (without unifying them). 93 3   pp-adj_mtr    i h   h1 x1 LBL , ARG0      #+  *""      h0 e0   RELS LBL , ARG0 ,    ARG1 ext , ARG2 x1  IN     i h     ARG0 x1 , RSTR hr           h i       HCONS HARG hr , LARG h1    *"" #+       OUT|RELS LBL h0 , ARG0 e0 , ARG1 ext Procedure We are using GIZA++ (Och and Ney, 2003) and Anymalign (Lardilleux and Lepage, 2009) to generate phrase tables from a collection of four Japanese English parallel corpora and one bilingual dictionary. The corpora are the Tanaka Corpus (2,930,132 words: Tanaka (2001)), the Japanese Wordnet Corpus (3,355,984 words: Bond et al. (2010)), the Japanese Wikipedia corpus (7,949,605),3 and the Kyoto University Text Corpus with NICT translations (1,976,071 words: Uchimoto et al. (2004)). The dictionary is Edict, a Japanese English dictionary (3,822,642 words: Breen (2004)). The word totals include both English and Japanese words. We divided t"
W11-0814,2007.tmi-papers.18,0,0.010086,"c representation (Copestake et al., 2005). The transfer process takes place in three steps. First, a Japanese string is parsed with the Japanese HPSG grammar, JACY. The grammar produces an MRS with Japanese predicates. Second, the Japanese MRS is transferred into an English MRS. And finally, the English HPSG grammar ERG generates an English string from the English MRS. At each step of the translation process, stochastic models are used to rank the output. There is a cutoff at 5, so the maximal amount of generated sentences is 125 (5x5x5). The final results are reranked using a combined model (Oepen et al., 2007). While JACY and the ERG have been developed over many years, less effort has been put into the transfer grammar, and this component is currently the bottleneck of the system. In general, transfer rules are the bottleneck for any system, and there is a long history of trying to expand the number of transfer rules types (Matsuo et al., 1997) and tokens (Yamada et al., 2002). In order to increase the coverage of the system (the number of words that we can translate) we build rules automatically. We look at strings that have a high probability of being a translation (identified from parallel corp"
W11-0814,padro-etal-2010-freeling,0,0.0177907,"Japanese English dictionary (3,822,642 words: Breen (2004)). The word totals include both English and Japanese words. We divided the corpora into development, test, and training data, and extracted the transfer rules from the training data. The training data of the four corpora together with the Edict dictionary form a parallel corpus of 20 million words (9.6 million English words and 10.4 million Japanese words). The Japanese text is tokenized and lemmatized with the MeCab morphological analyzer (Kudo et al., 2004), and the English text is tokenized and lemmatized with the Freeling analyzer (Padró et al., 2010), with MWE, quantities, dates and sentence segmentation turned off. When applying GIZA++ and Anymalign to the lemmatized parallel corpus they produced phrase tables with 10,812,423 and 5,765,262 entries, respectively, running GIZA++ with the default MOSES settings and Anymalign for approximately 16 hours. 3 The Japanese-English Bilingual Corpus of Wikipedia’s Kyoto Articles: http://alaginrc.nict.go.jp/WikiCorpus/ index_E.html We filtered out the entries with an absolute frequency of 1,4 and which had more than 4 words on the Japanese side or more than 3 words on the English side. This left us"
W11-0814,W04-2208,0,0.0293349,"RSTR hr           h i       HCONS HARG hr , LARG h1    *"" #+       OUT|RELS LBL h0 , ARG0 e0 , ARG1 ext Procedure We are using GIZA++ (Och and Ney, 2003) and Anymalign (Lardilleux and Lepage, 2009) to generate phrase tables from a collection of four Japanese English parallel corpora and one bilingual dictionary. The corpora are the Tanaka Corpus (2,930,132 words: Tanaka (2001)), the Japanese Wordnet Corpus (3,355,984 words: Bond et al. (2010)), the Japanese Wikipedia corpus (7,949,605),3 and the Kyoto University Text Corpus with NICT translations (1,976,071 words: Uchimoto et al. (2004)). The dictionary is Edict, a Japanese English dictionary (3,822,642 words: Breen (2004)). The word totals include both English and Japanese words. We divided the corpora into development, test, and training data, and extracted the transfer rules from the training data. The training data of the four corpora together with the Edict dictionary form a parallel corpus of 20 million words (9.6 million English words and 10.4 million Japanese words). The Japanese text is tokenized and lemmatized with the MeCab morphological analyzer (Kudo et al., 2004), and the English text is tokenized and lemmatize"
W11-0814,2002.tmi-papers.21,0,0.0145387,"each step of the translation process, stochastic models are used to rank the output. There is a cutoff at 5, so the maximal amount of generated sentences is 125 (5x5x5). The final results are reranked using a combined model (Oepen et al., 2007). While JACY and the ERG have been developed over many years, less effort has been put into the transfer grammar, and this component is currently the bottleneck of the system. In general, transfer rules are the bottleneck for any system, and there is a long history of trying to expand the number of transfer rules types (Matsuo et al., 1997) and tokens (Yamada et al., 2002). In order to increase the coverage of the system (the number of words that we can translate) we build rules automatically. We look at strings that have a high probability of being a translation (identified from parallel corpora), and see if they fit a pattern defined in the transfer grammar. A very simple pattern would be that of a noun predicate being transferred as another noun predicate. The transfer rule type for this pattern is given in (1). The type makes 92 Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 92–100, c Po"
W11-0814,R09-1040,0,\N,Missing
W12-4203,W02-1502,0,0.0779103,"Missing"
W12-4203,P11-2051,0,0.0155532,"e probabilities. Both are obtained from additional parallel corpora, where the translations of the same foreign language phrase are considered paraphrases. He et al. (2011) use a statistical framework for paraphrase generation of the source language. A log-linear model similar to the one used in phrasebased SMT provides paraphrases which are ranked based on novelty and fluency. The training corpus is then expanded by either adding the first best paraphrase, or n-best paraphrases. The target language is just copied to provide the required target side of the paraphrase. Marton et al. (2009) and Gao and Vogel (2011) create new information by means of shallow semantic methods. The former present an approach to overcome the problem of unknown words in a low resource experiment. They base their monolingual paraphrasing on semantic similarity measures. In their setting they achieve significantly better translations. Gao and Vogel (2011) expand the parallel corpus by creating new information from existing data. With the use of a monolingual semantic role labeller one side of the parallel corpus is labelled. Role-to-word rules are extracted. In sentences containing the frames and semantic roles for which repla"
W12-4203,P09-2028,1,0.851151,"Missing"
W12-4203,I11-1090,0,0.0125998,"ly large or underrepresented phenomena in par1 www.delph-in.net 20 Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 20–29, c Jeju, Republic of Korea, 12 July 2012. 2012 Association for Computational Linguistics allel corpora impose on SMT. Callison-Burch et al. (2006) tackle the problem of unseen phrases in SMT by adding source language paraphrases to the phrase table with appropriate probabilities. Both are obtained from additional parallel corpora, where the translations of the same foreign language phrase are considered paraphrases. He et al. (2011) use a statistical framework for paraphrase generation of the source language. A log-linear model similar to the one used in phrasebased SMT provides paraphrases which are ranked based on novelty and fluency. The training corpus is then expanded by either adding the first best paraphrase, or n-best paraphrases. The target language is just copied to provide the required target side of the paraphrase. Marton et al. (2009) and Gao and Vogel (2011) create new information by means of shallow semantic methods. The former present an approach to overcome the problem of unknown words in a low resource"
W12-4203,N06-1003,0,0.0330361,"different methods for corpus expansion. The experimental setup and the results are in Section 5. A discussion and our conclusion are given in Section 6 and Section 7, respectively. 2 Related Work There has been plenty of work on paraphrasing data in order to overcome the limitations that insufficiently large or underrepresented phenomena in par1 www.delph-in.net 20 Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 20–29, c Jeju, Republic of Korea, 12 July 2012. 2012 Association for Computational Linguistics allel corpora impose on SMT. Callison-Burch et al. (2006) tackle the problem of unseen phrases in SMT by adding source language paraphrases to the phrase table with appropriate probabilities. Both are obtained from additional parallel corpora, where the translations of the same foreign language phrase are considered paraphrases. He et al. (2011) use a statistical framework for paraphrase generation of the source language. A log-linear model similar to the one used in phrasebased SMT provides paraphrases which are ranked based on novelty and fluency. The training corpus is then expanded by either adding the first best paraphrase, or n-best paraphrase"
W12-4203,W04-3250,0,0.0530475,". The language model is trained as a 5-order model with Kneser-Ney discounting. The Giza++ alignment heuristic grow-diag-final-and is used. All systems are tuned with MERT (Och, 2003). Several tunings for each system are run, the best performing ones are reported here. 5.4 Results The results of our experiments can be seen in Table 4. The baseline is outperformed by our two best variations Append and Append + neg LM with respect to the entire test set. The differences in BLEU points are 0.14 and 0.16, which are not statistically significant according to the paired bootstrap resampling method (Koehn, 2004). When looking at the test set neg-strict that only contains negated sentences, our improvement is much more apparent. The gain of our best performing model Append + neg LM compared to the baseline is at 1.63 BLEU points, which is statistically significant (p &lt; 0.05). On the other hand there is a statistically insignificant drop of 0.30 with posstrict. The model with the expanded language model training data (Append + neg LM) always performs Tokens Sentences train dev train dev Baseline 1,300,821 / 1,641,591 42,248 / 52,822 141,147 4,500 Append 1,469,569 / 1,841,139 47,905 / 59,400 159,874 5,1"
W12-4203,P05-1066,0,0.131806,"used for filtering the generated paraphrases. An approach where paraphrases are obtained via generation from semantic structures is presented in Nichols et al. (2010). It exploits the fact that the generator produces multiple surface realizations. The basic set up is similar to our work, however our approach additionally manipulates, i.e. rephrases the semantics before generation. Furthermore, we implement parallel rephrasing, changing the meaning of both source and target text simultaneously. There is, on the other hand, little work in phrasebased SMT especially targeting negated sentences. Collins et al. (2005) approach the problem of properly translating negation in their general reordering setting. Transformation rules are applied to syntactic trees, so that the source language word order has a closer resemblance to the target language word or21 der. In particular, the German negation is moved towards the same position as the English one. This however presumes the existence of at least some negated training data. 3 Analysis of the Semantic Structure The linguistic analysis is performed based on the Head-Driven Phrase Structure Grammar (HPSG) formalism established in the DELPH-IN project. In partic"
W12-4203,D09-1040,0,0.016182,"ase table with appropriate probabilities. Both are obtained from additional parallel corpora, where the translations of the same foreign language phrase are considered paraphrases. He et al. (2011) use a statistical framework for paraphrase generation of the source language. A log-linear model similar to the one used in phrasebased SMT provides paraphrases which are ranked based on novelty and fluency. The training corpus is then expanded by either adding the first best paraphrase, or n-best paraphrases. The target language is just copied to provide the required target side of the paraphrase. Marton et al. (2009) and Gao and Vogel (2011) create new information by means of shallow semantic methods. The former present an approach to overcome the problem of unknown words in a low resource experiment. They base their monolingual paraphrasing on semantic similarity measures. In their setting they achieve significantly better translations. Gao and Vogel (2011) expand the parallel corpus by creating new information from existing data. With the use of a monolingual semantic role labeller one side of the parallel corpus is labelled. Role-to-word rules are extracted. In sentences containing the frames and seman"
W12-4203,P03-1021,0,0.00428841,"rd test subset biparse, which contains all the parsable sentence pairs. This set re24 veals the big jump of BLEU score compared to the fourth test set all, which is the regular test set of the Tanaka corpus. A combined dataset with pos-strictneg-strict is provided, which is the union of the first two sets. 5.3 Setup We use Moses (SVN revision 4293) with Giza++ (Och and Ney, 2003) and the SRILM toolkit 1.5.12 (Stolcke, 2002). The language model is trained as a 5-order model with Kneser-Ney discounting. The Giza++ alignment heuristic grow-diag-final-and is used. All systems are tuned with MERT (Och, 2003). Several tunings for each system are run, the best performing ones are reported here. 5.4 Results The results of our experiments can be seen in Table 4. The baseline is outperformed by our two best variations Append and Append + neg LM with respect to the entire test set. The differences in BLEU points are 0.14 and 0.16, which are not statistically significant according to the paired bootstrap resampling method (Koehn, 2004). When looking at the test set neg-strict that only contains negated sentences, our improvement is much more apparent. The gain of our best performing model Append + neg L"
W12-4203,J03-1002,0,0.00325062,"semantics of the sentence. In order to obtain the semantic structure, the sentence pairs have to be parsed successfully. This also means, we will have some sentence pairs for which we cannot make a decision. Therefore, we provide a third test subset biparse, which contains all the parsable sentence pairs. This set re24 veals the big jump of BLEU score compared to the fourth test set all, which is the regular test set of the Tanaka corpus. A combined dataset with pos-strictneg-strict is provided, which is the union of the first two sets. 5.3 Setup We use Moses (SVN revision 4293) with Giza++ (Och and Ney, 2003) and the SRILM toolkit 1.5.12 (Stolcke, 2002). The language model is trained as a 5-order model with Kneser-Ney discounting. The Giza++ alignment heuristic grow-diag-final-and is used. All systems are tuned with MERT (Och, 2003). Several tunings for each system are run, the best performing ones are reported here. 5.4 Results The results of our experiments can be seen in Table 4. The baseline is outperformed by our two best variations Append and Append + neg LM with respect to the entire test set. The differences in BLEU points are 0.14 and 0.16, which are not statistically significant accordin"
W12-4203,P07-2045,0,\N,Missing
W12-4208,adolphs-etal-2008-fine,0,0.0203844,"using 23 templates, and by adding new templates for multi-word expressions, we can increase the precision. The predicate alignments produced from the parallel corpus of predicates are relatively precise since the predicates are assigned by the grammars. This allows us to extract transfer rules from alignments 13 The pre-selection program speeds up the system by a factor of three. 74 the aligner. We would also like to get more from the data we have, by making the parser more robust. Two approaches that have been shown to work with other grammars is making more use of morphological information (Adolphs et al., 2008) or adding robustness rules (Cramer and Zhang, 2010). 6 Conclusion We have shown how semantic transfer rules can be learned from parallel corpora that have been aligned in SMT phrase tables. We employed two strategies. The first strategy was to lemmatize the parallel corpus and use SMT aligners to create phrase tables of lemmas. We then looked up the relations associated with the lemmas using the lexicons of the parser and generator. This gave us a phrase table of aligned relations. We were able to extract 127,000 rules by matching the aligned relations with 16 semantic transfer rule templates"
W12-4208,W04-2209,0,0.0146455,"been successfully integrated with the semantic extraction method. 68 Two methods of rule extraction The parallel corpus we use for rule extraction is a collection of four Japanese English parallel corpora and one bilingual dictionary. The corpora are the Tanaka Corpus (2,930,132 words: Tanaka, 2001), the Japanese Wordnet Corpus (3,355,984 words: Bond, Isahara, Uchimoto, Kuribayashi, and Kanzaki, 2010), the Japanese Wikipedia corpus (7,949,605 words),2 and the Kyoto University Text Corpus with NICT translations (1,976,071 words: Uchimoto et al., 2004). The dictionary is Edict (3,822,642 words: Breen, 2004). The word totals include both English and Japanese words. The corpora were divided into into development, test, and training data. The training data from the four corpora plus the bilingual dictionary was used for rule extraction. The combined corpus used for rule extraction consists of 9.6 million English words and 10.4 million Japanese words (20 million words in total). 3.1 Extraction from a lemmatized parallel corpus In the first rule extraction procedure we extracted transfer rules directly from the surface lemmas of the parallel text. The four parallel corpora were tokenized and lemmatiz"
W12-4208,C10-1026,0,0.0258141,"r multi-word expressions, we can increase the precision. The predicate alignments produced from the parallel corpus of predicates are relatively precise since the predicates are assigned by the grammars. This allows us to extract transfer rules from alignments 13 The pre-selection program speeds up the system by a factor of three. 74 the aligner. We would also like to get more from the data we have, by making the parser more robust. Two approaches that have been shown to work with other grammars is making more use of morphological information (Adolphs et al., 2008) or adding robustness rules (Cramer and Zhang, 2010). 6 Conclusion We have shown how semantic transfer rules can be learned from parallel corpora that have been aligned in SMT phrase tables. We employed two strategies. The first strategy was to lemmatize the parallel corpus and use SMT aligners to create phrase tables of lemmas. We then looked up the relations associated with the lemmas using the lexicons of the parser and generator. This gave us a phrase table of aligned relations. We were able to extract 127,000 rules by matching the aligned relations with 16 semantic transfer rule templates. The second strategy was to parse the parallel corp"
W12-4208,W04-3230,0,0.02088,"s. The corpora were divided into into development, test, and training data. The training data from the four corpora plus the bilingual dictionary was used for rule extraction. The combined corpus used for rule extraction consists of 9.6 million English words and 10.4 million Japanese words (20 million words in total). 3.1 Extraction from a lemmatized parallel corpus In the first rule extraction procedure we extracted transfer rules directly from the surface lemmas of the parallel text. The four parallel corpora were tokenized and lemmatized, for Japanese with the MeCab morphological analyzer (Kudo et al., 2004), and for English with the Freeling analyzer (Padró et al., 2010), with MWE, quantities, dates and sentence segmentation turned off. (The bilingual dictionary was not tokenized and lemmatized, since the entries in the dictionary are lemmas). 2 The Japanese-English Bilingual Corpus of Wikipedia’s Kyoto Articles: http://alaginrc.nict.go.jp/ WikiCorpus/index_E.html. Rule type noun_mtr n+n_n+n_mtr n+n_adj+n_mtr arg12+np_arg12+np_mtr arg1_v_mtr pp_pp_mtr adjective_mtr arg12_v_mtr n_adj+n_mtr n+n_n_mtr n+n+n_n+n_mtr n+adj-adj-mtr n_n+n_mtr pp-adj_mtr p+n+arg12_arg12_mtr pp+np_np+pp_mtr pp+arg12_arg1"
W12-4208,2007.tmi-papers.18,0,0.00996899,"ns, spatial expressions, and the most common open class items. The rest of the transfer rules (190,356 unique rules) are automatically extracted from parallel corpora. The full system is available from http: //moin.delph-in.net/LogonTop (different components have different licenses, all are open source, mainly LGPL and MIT). 3 Figure 1: Architecture of the Jaen MT system. is ranked by stochastic models. In the default configuration, only the 5 top ranked outputs at each step are kept, so the maximum number of translations is 125 (5x5x5). There is also a final reranking using a combined model (Oepen et al., 2007). The architecture of the MT system is illustrated in Figure 1, where the contribution of the transfer rule extraction from parallel corpora is depicted by the arrow going from Bitext to Semantic Transfer. Most of the rules in the transfer grammar are simple predicate changing rules, like the rule for mapping the predicate “_hon_n_rel” onto the predicate “_book_v_1_rel”. Other rules are more complex, and transfers many Japanese relations into many English relations. In all, there are 61 types of transfer rules, the most frequent being the rules for nouns translated into nouns (44,572), noun no"
W12-4208,padro-etal-2010-freeling,0,0.0134109,"ining data. The training data from the four corpora plus the bilingual dictionary was used for rule extraction. The combined corpus used for rule extraction consists of 9.6 million English words and 10.4 million Japanese words (20 million words in total). 3.1 Extraction from a lemmatized parallel corpus In the first rule extraction procedure we extracted transfer rules directly from the surface lemmas of the parallel text. The four parallel corpora were tokenized and lemmatized, for Japanese with the MeCab morphological analyzer (Kudo et al., 2004), and for English with the Freeling analyzer (Padró et al., 2010), with MWE, quantities, dates and sentence segmentation turned off. (The bilingual dictionary was not tokenized and lemmatized, since the entries in the dictionary are lemmas). 2 The Japanese-English Bilingual Corpus of Wikipedia’s Kyoto Articles: http://alaginrc.nict.go.jp/ WikiCorpus/index_E.html. Rule type noun_mtr n+n_n+n_mtr n+n_adj+n_mtr arg12+np_arg12+np_mtr arg1_v_mtr pp_pp_mtr adjective_mtr arg12_v_mtr n_adj+n_mtr n+n_n_mtr n+n+n_n+n_mtr n+adj-adj-mtr n_n+n_mtr pp-adj_mtr p+n+arg12_arg12_mtr pp+np_np+pp_mtr pp+arg12_arg12_mtr arg1+pp_arg1+pp_mtr monotonic_mtr adj_pp_mtr preposition_mt"
W12-4208,W02-1210,0,0.0447627,"r creating the alignments. In the first procedure the parallel corpus is lemmatized before it is aligned with two SMT phrase aligners. Then the aligned lemmas are mapped to predicates with the help of the lexicons of the parsing grammar and the generating grammar. Finally, the transfer rules 2 Semantic Transfer Jaen is a rule-based machine translation system employing semantic transfer rules. The medium for the semantic transfer is Minimal Recursion Semantics, MRS (Copestake et al., 2005). The system consists of the two HPSG grammars: JACY, which is used for the parsing of the Japanese input (Siegel and Bender, 2002) and the ERG, used for the generation of the English output (Flickinger, 2000). The third component of the system is the transfer grammar, which transfers the MRS representation produced by the Japanese grammar into an MRS representation that the English grammar can generate from: Jaen (Bond et al., 2011). At each step of the translation process, the output 67 Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 67–75, c Jeju, Republic of Korea, 12 July 2012. 2012 Association for Computational Linguistics  Bitext    ?  Treebank"
W12-4208,W04-2208,0,0.0162513,"ed). The rest of the templates are new, and they have so far only been successfully integrated with the semantic extraction method. 68 Two methods of rule extraction The parallel corpus we use for rule extraction is a collection of four Japanese English parallel corpora and one bilingual dictionary. The corpora are the Tanaka Corpus (2,930,132 words: Tanaka, 2001), the Japanese Wordnet Corpus (3,355,984 words: Bond, Isahara, Uchimoto, Kuribayashi, and Kanzaki, 2010), the Japanese Wikipedia corpus (7,949,605 words),2 and the Kyoto University Text Corpus with NICT translations (1,976,071 words: Uchimoto et al., 2004). The dictionary is Edict (3,822,642 words: Breen, 2004). The word totals include both English and Japanese words. The corpora were divided into into development, test, and training data. The training data from the four corpora plus the bilingual dictionary was used for rule extraction. The combined corpus used for rule extraction consists of 9.6 million English words and 10.4 million Japanese words (20 million words in total). 3.1 Extraction from a lemmatized parallel corpus In the first rule extraction procedure we extracted transfer rules directly from the surface lemmas of the parallel tex"
W12-4208,P07-2045,0,\N,Missing
W12-4208,R09-1040,0,\N,Missing
W13-2319,isahara-etal-2008-development,1,\N,Missing
W13-2319,Y11-1027,1,\N,Missing
W13-2319,C04-1053,0,\N,Missing
W13-2319,W03-1712,0,\N,Missing
W13-2319,P12-2025,1,\N,Missing
W13-2319,P96-1006,0,\N,Missing
W13-2319,cyrus-2006-building,0,\N,Missing
W13-2319,2005.mtsummit-papers.11,0,\N,Missing
W13-2319,P13-1133,1,\N,Missing
W13-2319,basile-etal-2012-developing,0,\N,Missing
W13-2319,tiedemann-2012-parallel,0,\N,Missing
W13-2319,tiedemann-nygaard-2004-opus,0,\N,Missing
W13-4302,W02-1106,0,0.104203,"Missing"
W13-4302,P13-1133,1,0.589826,"outheast University Chinese WordNet (SEW) was automatically constructed by implementing three approaches, including Minimum Distance, Intersection and Words Cooccurrence (Xu, Gao, Pan, Qu, & Huang, 2008); Taiwan University and Academia Sinica also developed a Chinese WordNet (CWN)(Huang et al 2010). We used SEW to sense-tag NTU corpus data (Bond, Wang, Gao, Mok, & Tan, 2013; Tan & Bond, 2012). However, its mistakes and its coverage hinder the progress of the sense-tagged corpus. Moreover, the open multilingual wordnet project (OMW) 1 created wordnet data for many languages, including Chinese (Bond & Foster, 2013). Based on OMW, we created a small scale Chinese wordnet from Wiktionary (WIKT). All of these wordnets have some flaws and, when we started our project, none of them were available under an open license. A high-quality and freely available wordnet would be an important resource for the community. Therefore, we have started work on yet another Chinese wordnet in Nanyang Technological University (NTU COW), aiming to produce one with even better accuracy and coverage. Core synsets2 are the most common ones ranked according to word frequency in British National Corpus (Fellbaum & Vossen, 2007). Th"
W13-4302,W13-2319,1,0.791383,"yang Drive, Singapore 637332 wangshanstar@gmail.com, bond@ieee.org Chinese wordnets have been developed. Sinica Bilingual Ontological Wordnet (BOW) was created through a bootstrapping method (Huang, Chang, & Lee, 2004; Huang, Tseng, Tsai, & Murphy, 2003). Southeast University Chinese WordNet (SEW) was automatically constructed by implementing three approaches, including Minimum Distance, Intersection and Words Cooccurrence (Xu, Gao, Pan, Qu, & Huang, 2008); Taiwan University and Academia Sinica also developed a Chinese WordNet (CWN)(Huang et al 2010). We used SEW to sense-tag NTU corpus data (Bond, Wang, Gao, Mok, & Tan, 2013; Tan & Bond, 2012). However, its mistakes and its coverage hinder the progress of the sense-tagged corpus. Moreover, the open multilingual wordnet project (OMW) 1 created wordnet data for many languages, including Chinese (Bond & Foster, 2013). Based on OMW, we created a small scale Chinese wordnet from Wiktionary (WIKT). All of these wordnets have some flaws and, when we started our project, none of them were available under an open license. A high-quality and freely available wordnet would be an important resource for the community. Therefore, we have started work on yet another Chinese wor"
W13-4302,isahara-etal-2008-development,1,\N,Missing
W13-4302,huang-etal-2004-sinica,0,\N,Missing
W14-0106,P98-1013,0,0.0960578,"7 7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8 8.1 8.2 8.3 8.4 8.5 8.6 9 9.1 9.2 9.3 9.4 9.5 9.6 9.7 Domain Physical actions Posture Move Move something Have, be with Arrange Hide Physical impact Divide into pieces Break, wear out States Quantity Big Quality Time Location Parts of things Grammar General words Part of speech Very Semantic constituents related to verbs Case Connected with, related Name Figure 2: Top two levels of the Semantic Domains many other useful resources, including corpora (Landes et al., 1998), images (Bond et al., 2008; Deng et al., 2009), geographical locations, verb frames (Baker et al., 1998), Wiktionary and Wikipedia (de Melo and Weikum, 2010; Bond and Foster, 2013), many NLP tools (Bird et al., 2009) and ontologies (Niles and Pease, 2001; Gangemi et al., 2003). Allowing under-resourced languages to access these is an important goal for this project. 2.3 Comparison As can be seen from Figures 1 and 2, the relations between domains are not as strongly typed as in WordNet, or at all uniform: for example bodily functions are related to person, but not as synonyms, hyponyms or meronyms. These somewhat looser relations are not captured well by WordNet: the so-called tennis problem (Wo"
W14-0106,P13-1133,1,0.937047,"ly equivalent to concepts. A combination of a word and synset defines a sense. Synsets are linked together by semantic relations, predominantly hyperonymy and meronymy, but including many others. Relations can also link senses to senses or synsets. Wordnets have been built for many languages, in this research we use the Princeton WordNet and the Wordnet Bahasa: a wordnet with Malay and Indonesian words linked to the Princeton WordNet structure (Nurril Hirfana at al., 2011). Over twenty wordnets have been linked together as the Open Multilingual Wordnet11 and there is data for many, many more (Bond and Foster, 2013). Almost all wordnets have been built for established languages: building a wordnet from scratch is a considerable undertaking. The Princeton WordNet is released under an open source license that allows reuse with attribution , and most new wordnets (including the Wordnet Bahasa we use here) are released under a similar license. The Princeton WordNet has been linked to 8 See http://webonary.org/ http://e-kamus2.org/ 10 More properly, lemmas, which may be multiword expressions. 11 See http://compling.hss.ntu.edu.sg/omw/ 9 See No. 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 2 2.1 2.2 2.3 2.4 2.5 2.6 3 3.1 3.2"
W14-0106,bond-etal-2008-boot,1,0.716226,"sh Working with buildings Occupation Tool Finance Business organization No. 7 7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8 8.1 8.2 8.3 8.4 8.5 8.6 9 9.1 9.2 9.3 9.4 9.5 9.6 9.7 Domain Physical actions Posture Move Move something Have, be with Arrange Hide Physical impact Divide into pieces Break, wear out States Quantity Big Quality Time Location Parts of things Grammar General words Part of speech Very Semantic constituents related to verbs Case Connected with, related Name Figure 2: Top two levels of the Semantic Domains many other useful resources, including corpora (Landes et al., 1998), images (Bond et al., 2008; Deng et al., 2009), geographical locations, verb frames (Baker et al., 1998), Wiktionary and Wikipedia (de Melo and Weikum, 2010; Bond and Foster, 2013), many NLP tools (Bird et al., 2009) and ontologies (Niles and Pease, 2001; Gangemi et al., 2003). Allowing under-resourced languages to access these is an important goal for this project. 2.3 Comparison As can be seen from Figures 1 and 2, the relations between domains are not as strongly typed as in WordNet, or at all uniform: for example bodily functions are related to person, but not as synonyms, hyponyms or meronyms. These somewhat loose"
W14-0106,Y11-1027,1,0.876252,"Missing"
W14-0106,W13-4302,1,0.899858,"Missing"
W14-0106,C98-1013,0,\N,Missing
W14-0125,P08-1037,0,0.126068,"features and approaches. Fujita et al. (2010) worked with the Japanese Hinoki Corpus (Bond et al., 2008) data and used hypernym chains from the Goi-Taikei Japanese ontology (Ikehara et al., 1997) for variable-level semantic backoff. This is in contrast to the uniform WordNet semantic file backoff performed here. In addition, this work only focuses on MRS ranking, whereas Fujita et al. (2010) combined MRS features with syntactic features to improve syntactic parse ranking accuracy. Our use of WordNet Semantic Files (SF) to reduce lexical feature sparseness is inspired by several recent papers. Agirre et al. (2008, 2011) have experimented with replacing open-class words with their SFs. Agirre et al. (2008) have shown an improvement in full parse and PP attachment scores with statistical constituency parsers using SFs. Agirre et al. (2011) have followed up on those results and re-trained a dependency parser on the data where words were replaced with their SFs. This resulted in a very modest labeled attachment score improvement, but with a significantly reduced feature set. In a recent HPSG work, MacKinlay et al. (2012) attempted to integrate lexical semantic features, including SF backoff, into a discri"
W14-0125,P11-2123,0,0.0187098,"off. This is in contrast to the uniform WordNet semantic file backoff performed here. In addition, this work only focuses on MRS ranking, whereas Fujita et al. (2010) combined MRS features with syntactic features to improve syntactic parse ranking accuracy. Our use of WordNet Semantic Files (SF) to reduce lexical feature sparseness is inspired by several recent papers. Agirre et al. (2008, 2011) have experimented with replacing open-class words with their SFs. Agirre et al. (2008) have shown an improvement in full parse and PP attachment scores with statistical constituency parsers using SFs. Agirre et al. (2011) have followed up on those results and re-trained a dependency parser on the data where words were replaced with their SFs. This resulted in a very modest labeled attachment score improvement, but with a significantly reduced feature set. In a recent HPSG work, MacKinlay et al. (2012) attempted to integrate lexical semantic features, including SF backoff, into a discriminative parse ranking model. However, this was not shown to help, presumably because the lexical semantic features were built from syntactic constituents rather than MRS predicates. The ancestor features found to be helpful here"
W14-0125,W00-1320,0,0.0495918,"ctly to higher accuracy. Other avenues we would like to explore is backing off not to the semantic files, but rather to WordNet hypernyms at various levels. These results show that generalizing to semantic supertypes allows us to build semantic ranking models that are not only smaller, but more accurate. In general, learning time was roughly proportional to the number of features, so a smaller model can be learned faster. We hypothesize that it is the combination of dependencies and supertypes that makes the difference: approaches that used semantic features on phrase structure trees (such as Bikel (2000) and MacKinlay et al. (2012)) have in general failed to get much improvement. Figure 3: Learning curve for SF+AF. The overall accuracy is still quite low, due principally to the lack of training data. We show the learning curves for the SF+AF configuration in Figure 3 (the other configurations are similar). The curve is still clearly rising: the accuracy of parse selection on our corpus is far from saturated. This observation gives us confidence that with a larger corpus the accuracy of parse selection will improve considerably. The learning curve in Fujita et al. (2010) showed similar results"
W14-0125,P13-1133,1,0.81251,"ly with more (they had a larger corpus for Japanese). As there are so far still very few corpora with both structural and lexical semantic annotation, we are currently investigating the use of automatic word sense disambiguation to create the features, in a similar way to Agirre et al. (2008). Finally, we would like to investigate even more features, such as the dependency chains of Le Roux et al. (2012). One exciting possibility is projecting ranking features across languages: wordnet semantic files are the supertypes for all wordnets linked to the Princeton Wordnet, of which there are many (Bond and Foster, 2013). The predicates that are not in the wordnets are generally either named entities or from smallish closed sets of function words such as conjunctions, prepositions and pronouns. We are currently investigating mapping these between Japanese and English using transfer rules from an existing machine translation system (Bond et al., 2011). In principal, a small set of mappings for closed class words could allow us to quickly boot-strap a semantic ranking model for any language with a wordnet. 6 Conclusion In summary, we showed some features that help parse selection. In the SD group, LR features t"
W14-0125,1983.tc-1.13,0,0.0500464,"Missing"
W14-0125,E09-1001,0,0.0196298,"tactic trees, using a Maximum Entropy Ranker. They experimented with Japanese data, using the Hinoki Treebank (Bond et al., 2008), using primarily elementary dependencies: single arcs between predicates and their arguments. These can miss some important connections between predicates. An example parse tree for I treat dogs and cats with worms is shown in Figure 1.1 , for the interpretation “I treat both dogs and cats that have worms” (not “I treat, using worms, dogs and cats” or any of the other possibilities) The semantic representation we use is Dependency Minimal Recursion Semantics (DRMS: Copestake, 2009). The Minimal Recursion Semantics (MRS: Copestake et al., 2005) is a computationally tractable flat semantics that underspecifies quantifier scope. The Dependency MRS is an MRS representation format that keeps all the information from the MRS but is simpler to manipulate. DMRSs differ from syntactic dependency graphs in that the relations are defined between slightly abstract predicates, not between ♣ Currently at PointInside, Inc. 1 Simplified by omission of non-branching nodes. surface forms. Some semantically empty surface tokens (such as infinitive to) are not included, while some predicat"
W14-0125,W12-3412,0,0.0688521,"Missing"
W14-0125,S12-1031,0,0.0765162,"tic Files (SF) to reduce lexical feature sparseness is inspired by several recent papers. Agirre et al. (2008, 2011) have experimented with replacing open-class words with their SFs. Agirre et al. (2008) have shown an improvement in full parse and PP attachment scores with statistical constituency parsers using SFs. Agirre et al. (2011) have followed up on those results and re-trained a dependency parser on the data where words were replaced with their SFs. This resulted in a very modest labeled attachment score improvement, but with a significantly reduced feature set. In a recent HPSG work, MacKinlay et al. (2012) attempted to integrate lexical semantic features, including SF backoff, into a discriminative parse ranking model. However, this was not shown to help, presumably because the lexical semantic features were built from syntactic constituents rather than MRS predicates. The ancestor features found to be helpful here are inspired by the use of grand-parenting in syntactic parse ranking (Toutanova et al., 2005) and chains in dependency parsing ranking (Le Roux et al., 2012). 3 Resources and Methodology In this section we introduce the corpus we work on, and the features we extract from it. 3.1 Cor"
W14-0125,W02-2018,0,0.0745041,"Missing"
W14-0125,P06-1043,0,0.0443792,"otated with both Dependency Minimal Recursion Semantic representations and WordNet senses. Using both types of features gives a significant improvement in whole sentence parse selection accuracy over the baseline model. NP N I VP V treat NP N N dogs PP N CONJ and with worms N cats 1 Introduction Figure 1: Syntactic view of sentence “I treat dogs and cats with worms”. In this paper we investigate various features to improve the accuracy of semantic parse ranking. There has been considerable successful work on syntactic parse ranking and reranking (Toutanova et al., 2005; Collins and Koo, 2006; McClosky et al., 2006), but very little that uses pure semantic representations. With recent work on building semantic representations (from deep grammars such as LFG (Butt et al., 1999) and HPSG (Sag et al., 1999), directly through lambda calculus, or as in intermediate step in machine translation) the question of ranking them has become more important. The closest related work is Fujita et al. (2010) who ranked parses using semantic features from Minimal Recursion Semantics (MRS) and syntactic trees, using a Maximum Entropy Ranker. They experimented with Japanese data, using the Hinoki Treebank (Bond et al., 2008"
W14-0125,J05-1003,0,\N,Missing
W14-0125,W07-1204,1,\N,Missing
W14-0132,P08-1037,0,0.02454,"Missing"
W14-0132,I08-2108,1,0.792209,"wordnet definitions have been translated into many languages, including Albanian (Ruci, 2008), Japanese (Bond et al., 2010), Korean (Yoon et al., 2009) and Spanish (FernándezMontraveta et al., 2008). Further, the glosses are useful for unsupervised sense disambiguation techniques such 18 http://www.inf.u-szeged.hu/rgai/HuWN 19 http://creativecommons.org/licences/by/3. 0/legalcode 20 plwordnet.pwr.wroc.pl/wordnet 21 wordnet.princeton.edu/glosstag.shtml as LESK (Lesk, 1986): and it has been shown for another resource that having the glosses disambiguated improves the accuracy of extended LESK (Baldwin et al., 2008). 2.3.2 Groningen Meaning Bank The Groningen Meaning Bank (GMB), is a free corpus of English (1,020,367 tokens) developed at the University of Groningen, comprises thousands of texts in raw and tokenised format, tags for part of speech, named entities and lexical categories (word senses from WordNet, among other things), and discourse representation structures compatible with first-order logic (Basile et al., 2012). The senses are mostly automatically annotated, though part of them are manually corrected through the GMB wiki-like interface: gmb.let.rug.nl/explorer. The current (development) ve"
W14-0132,basile-etal-2012-developing,0,0.0171493,"wordnet.princeton.edu/glosstag.shtml as LESK (Lesk, 1986): and it has been shown for another resource that having the glosses disambiguated improves the accuracy of extended LESK (Baldwin et al., 2008). 2.3.2 Groningen Meaning Bank The Groningen Meaning Bank (GMB), is a free corpus of English (1,020,367 tokens) developed at the University of Groningen, comprises thousands of texts in raw and tokenised format, tags for part of speech, named entities and lexical categories (word senses from WordNet, among other things), and discourse representation structures compatible with first-order logic (Basile et al., 2012). The senses are mostly automatically annotated, though part of them are manually corrected through the GMB wiki-like interface: gmb.let.rug.nl/explorer. The current (development) version of the GMB is accessible via the GMB Explorer: everbody is explicitly invited to contribute to the GMB by providing corrections to existing linguistic annotations with the simplicity made possible by such a wiki-like environment. Anyone can register via the GMB Explorer and check, improve, or discuss linguistic annotations. Stable releases are made available periodically and are freely available from the down"
W14-0132,W00-1320,0,0.0445595,"at 32k. f Only the 100 most frequent nouns are annotated. g The corpus is multilingual, in fact the same articles are available in other four languages:french, spanish, german and italian, respectively containing 3k tokens each, Frech, Spanish and German and 4k Italian) Kima gotb slowlyc upb , the childrend weree already f ong theirg feetg . ID a b c d e f g Lemma Kim get_up slowly child be already on_one’s_feet Sense org get_up4 slowly1 child1 be3 already1 notag Figure 1: SemCor Example 2011). The combination of syntactic and semantic information has been used in various parsing experiments (Bikel, 2000; Agirre et al., 2008). The corpus is divided into two parts: semcor-all in which 186 texts have all open-class words (such as nouns, verbs, adjectives and adverbs) semantically annotated. The SemCor component of all word types consists of 359,732 (Lupu et al., 2005) tokens of which 192,639 are semantically annotated. The second part, semcor-verbs, only has verbs senses annotated: 41,497 verbal occurrences from 316,814 tokens (Lupu et al., 2005). 2.1.2 MultiSemCor MultiSemCor is an English/Italian parallel corpus created by translating the English SemCor corpus into Italian (Bentivogli and Pia"
W14-0132,P13-1133,1,0.359021,"mpatible with MultiSemCor, align through English and refine. This will make it easier to add other languages: the Sherlock Holmes short stories and the Cathedral and the Bazaar have many translations. The third is to do this with the Wordnet Gloss Corpus: linking definitions in other languages to make a multilingual gloss corpus. It would also be interesting to use definitions from other sources (such as Wiktionary) to make an aligned sense-tagged paraphrase corpus. Finally (or in parallel) we would like to make these corpora all searchable, and linked to the Wordnet Grid (Pease et al., 2008; Bond and Foster, 2013). 5 Conclusions All these observations about the compatibility troubles in the construction process of multilingual wordnet annotated corpora point at a clear fact: the more we standardize our data formats, and the more we open and share freely our resources and tools the easier and the faster will be the development of new resources all over the world. Acknowledgments This research was supported in part by the Erasmus Mundus Action 2 program MULTI of the European Union, grant agreement number 2009-5259-5. We would like to thank Anja Weisscher and Piek Vossen for their help in adding the infor"
W14-0132,W13-2319,1,0.850439,"vailable for research purposes in 2010 (Dei Rossi et al., 2011). 2.2.8 NTU-MC The NTU-Multilingual Corpus is a corpus designed to be multilingual from the start. It contains parallel text in eight languages: English (eng), Mandarin Chinese (cmn), Japanese (cpn), Indonesian (ind), Korean (kor), Arabic (arb), Vietnamese (vie) and Thai (tha) (Tan and Bond, 2012). Text is in three genres: short stories, essays and tourism. All the text is translated from English. The text is being sense annotated (Open Multilingual Wordnet11 senses) in Chinese, English, Japanese and Indonesian (tourist data only; Bond et al., 2013). Tagging is still underway, snapshots are available from compling.hss.ntu.edu.sg/ntumc. The sizes of the different subcorpora are given in Table 1. There is more data for Chinese and English, with less for Indonesian and Japanese. 2.2.9 AQMAR Arabic SST This is a 65,000-token corpus12 of 28 Arabic Wikipedia articles (selected from the topical domains of history, sports, science, and technology) hand-annotated for nominal supersenses (40 coarse lexical semantic classes, 25 for nouns, 15 for verbs, originating in WordNet). It extends the Named Entity Corpus13 and was developed by Nathan Schneid"
W14-0132,broda-etal-2012-kpwr,0,0.0645544,"Missing"
W14-0132,P94-1020,0,0.116718,"Missing"
W14-0132,E12-1039,0,0.0505884,"t least one annotator and millions have been automatically tagged). The examples mainly come from existing corpora collected in the projects CGN (9 millions words: Van Eerten, 2007), D-Coi, and SoNaR (500 millions words: Oostdijk, 2008), but also additional examples from the Dutch websites have been added. DutchSemCor is not available, but excerpts and statistics are freely downloadable. 7 Read Civit and Martí (2004) for 3LB-ESP and Civit et al. (2004) for 3LB-CAT WebCaGe WebCaGe is a web-harvested corpus annotated with GermaNet senses, the largest sense-annotated corpus available for German (Henrich et al., 2012). WebCaGe includes example sentences from the German Wiktionary (46,457 German words) and additional material collected by following the links to Wikipedia, the Gutenberg archive, and other web-based materials. Wiktionary (7,644 tagged word tokens) and Wikipedia (1,732) contribute by far the largest subsets of the total number of tagged word tokens (10,750) compared with the external webpages (589) and the Gutenberg texts (785). These tokens belong to 2,607 distinct polysemous words contained in GermaNet, among which there are 211 adjectives, 1,499 nouns, and 897 verbs. On average, these words"
W14-0132,isahara-etal-2008-development,1,0.848839,"Missing"
W14-0132,S13-2049,0,0.0173668,"Missing"
W14-0132,W04-2710,0,0.0359565,"ce) (Ishida, 2006). In this paper we do the same for sense-annotated corpora. We restrict ourselves to those that use a wordnet as the sense inventory. Sense annotated corpora can be classified according to several criteria. Some obvious ones are the language used; the lexicon used to determine the senses; the size; the license. In addition, another useful distinction is that between those that annotate all words and those that only annotate some words, typically either a sample of a few frequent words, or of a single partof-speech. We will also distinguish those corpora that align to SemCor (Langone et al., 2004) the first wordnet annotated corpus. We will first describe it in some detail, as it is the most typical corpus, and then note where other corpora differ from it. We have found more than 20 WordNet Annotated Corpora in more than 10 different languages. We describe them in the following Section 2, discuss some of the issues they raise in Section 3 and then plans for future work in 4. 1 http://globalwordnet.org/?page_id=38 2 WordNet Annotated Corpora We have tried to list all known corpora annotated with wordnet senses, in any language.2 In most cases, information on size comes from the latest p"
W14-0132,H93-1051,0,0.728249,"Missing"
W14-0132,J93-2004,0,0.0641752,"Missing"
W14-0132,H94-1046,0,0.390173,"Missing"
W14-0132,S13-2040,0,0.0532242,"Missing"
W14-0132,P96-1006,0,0.125774,"n by the WordNet and FrameNet teams (100,000 annotated occurrences), described in (Ide, 2012). The sense-tagged data are distributed as a separate sentence corpus with links to the original documents in which 22 gmb.let.rug.nl/wordrobe.php they appear. Where MASC does not contain 1000 occurrences of a given word, additional sentences were drawn from the OANC. All annotations have either been manually produced or automatically produced and hand-validated. MASC is distributed without license or other restrictions. 2.3.4 DSO Corpus of Sense-Tagged English This sense tagged corpus was provided by Ng and Lee (1996) of the Defence Science Organisation (DSO) of Singapore and has been hand tagged by 12 undergraduates from the Linguistics Program of the National University of Singapore. It contains sense-tagged word occurrences for 121 nouns and 70 verbs which are among the most frequently occurring and ambiguous words in English. These sentences are taken from the Brown corpus and the Wall Street Journal corpus. About 192,800 word occurrences have been hand tagged with WordNet 1.5 senses. It is distributed on the Linguistic Data Consortium Catalogue23 (LDC) under different licences for LDC Members (free fo"
W14-0132,P12-2050,0,0.0451799,"le from compling.hss.ntu.edu.sg/ntumc. The sizes of the different subcorpora are given in Table 1. There is more data for Chinese and English, with less for Indonesian and Japanese. 2.2.9 AQMAR Arabic SST This is a 65,000-token corpus12 of 28 Arabic Wikipedia articles (selected from the topical domains of history, sports, science, and technology) hand-annotated for nominal supersenses (40 coarse lexical semantic classes, 25 for nouns, 15 for verbs, originating in WordNet). It extends the Named Entity Corpus13 and was developed by Nathan Schneider, Behrang Mohit, Kemal Oflazer, and Noah Smith (Schneider et al., 2012) as part of the AQMAR project.14 This dataset is released under the Creative Commons Attribution-ShareAlike 3.0 Unported license (CC BY-SA 3.0). 2.2.10 Jos100k The Jos100k corpus of Slovene contains 100,000 words of sampled paragraphs from the FidaPLUS corpus.15 It is meant to serve as a reference annotated corpus of Slovene: its manually-validated annotations cover three level of linguistic description (morphosyntactic, syntactic and semantic). All the occurences of 100 most frequent nouns are annotated with their concept (synset id) from the Slovene WordNet sloWNet. The corpus is now at the"
W14-0132,W13-0215,0,0.017801,"corrections to existing linguistic annotations with the simplicity made possible by such a wiki-like environment. Anyone can register via the GMB Explorer and check, improve, or discuss linguistic annotations. Stable releases are made available periodically and are freely available from the downloads webpage. Data from the Wordrobe22 platform is also used to correct word senses in the GMB, applying the very innovative crowdsourcing technique “Game with a Purpose” (GWAP): rewarding contributors with entertainment rather than money. The design and the first results of Wordrobe are presented in Venhuizen et al. (2013). 2.3.3 MASC MASC (Manually Annotated Sub-Corpus) is a part of the American National Corpus (Ide, 2012) with multiple layers of annotations in a common format that can be used either individually or together, and (unlike, for example, OntoNotes) to which others can add annotations. MASC currently contains nineteen genres of spoken and written language data in roughly equal amounts, covers a wide range of written genres, including emerging social media genres (tweets, blogs). The entire MASC is annotated for logical structure, token and sentence boundaries, part of speech and lemma, shallow par"
W14-0132,W04-0811,0,\N,Missing
W14-0132,vincze-etal-2008-hungarian,0,\N,Missing
W14-0154,W13-2319,1,0.649798,"It was developed from 1985 at Princeton University. Nouns, verbs, adjective and adverbs were grouped into synsets and linked through semantic relation (Fellbaum, 1998). We used Southeast University’s Chinese Wordnet to tag the Chinese part (SEW: Xu et al., 2008),1 and are now in the process of switching to the Chinese Open Wordnet (COW: Wang and Bond, 2013).2 3 Pre-processing the Corpus In this paper we talk only about the Chinese and English text from the short story, essay and tourism genres of the NTU-MC, although we are also cooperating with other work on tagging Indonesian and Japanese (Bond et al., 2013). The short stories are two Sherlock Holmes’ Adventures (The Adventure of the Dancing Men and The Adventure of the Speckled Band), the essay is The Cathedral and the Bazaar (Raymond, 1999) and the tourism data is from the Singapore tourist board’s web pages (Singapore Tourist Board, 2012). The corpus sizes are shown in Table 1. We show the number of sentences, words and concepts (open class words taggable with synsets). 3.1 Pre-processing with NLP Tools For English, Freeling (Padr´o et al., 2010) was run with number processing, name recognition, multi-words, dates and quantities all turned off"
W14-0154,Y04-1030,0,0.0381073,"Italian tokens and 258,499 English tokens (Pianta et al., 2002). This was followed by the Romanian SemCor with 175,603 tokens in Romanian matched with 178,499 English tokens (Lupu et al., 2005). Finally, the Japanese SemCor has senses projected across from English. Of the 150,555 content words, 58,265 are sense tagged either as monosemous words or by projecting from the English annotation (Bond et al., 2012). Some universities have devoted efforts to construct Chinese-English parallel corpora, such as Peking University, Tsinghua University and Chinese Academy of Sciences (Chang et al., 2003; Chang, 2004), Xiamen University (Chen et al., 2005, 2006), Beijing Foreign Studies University (Wang, 2012). However, none of them are sensed tagged or aligned at word level. Chinese-English word aligned corpora are available as part of many statistical machine translation projects, but we wanted to work with a multilingual corpus, not just two languages. 2 Related Research Rather than translate new data, we took advantage of an existing multilingual corpus containing eight languages: English (eng), Mandarin Chinese (cmn), Japanese (jpn), Indonesian (ind), Korean, Arabic, Vietnamese and Thai (Tan and Bond,"
W14-0154,W08-0336,0,0.0392769,"antities all turned off. Turning them on gave quite aggressive lemmatization: for example a bit in a bit of honest money was lemmatized to IF bit:1 “one bit of information”. We did very minimal preprocessing: for example rewriting three hyphens - - - to mdash —. We had some problems with lemmatization of hyphenated expressions and mdashes: whitecounterpaned which we would like to treat as two lemmas (white and counterpane) and not— because which should be treated as not and because. We ended up correcting many of these by hand. For Chinese, we segmented and tagged with the Stanford NLP tools (Chang et al., 2008).3 We did some post-processing: many punctuation marks R were not recognized (such as: [〔&quot;()-- {&quot;’), these we corrected with a script after the initial POS tagging. We also lemmatized pluralmarked nouns, such as 学生+们 xu´esh¯eng+men “student+s” to 学 生 xu´esh¯eng “student”. This 1 At the beginning of our project we tested a small sample of Chinese words by looking them up in both SEW and the Sinica Bilingual Ontological Wordnet (Huang et al., 2004) and found SEW had slightly better coverage. 2 COW is available at http://compling.hss.ntu. edu.sg/cow/. 3 We compared several free Chinese morphologi"
W14-0154,P12-2074,0,0.016219,") and hope our guidelines can help other people. With this in mind, we are trying to keep separate, as far as possible, tool-specific procedures and general tagging guidelines. Many of the unknown words, especially for our first attempt, were in fact words that are in wordnet with minor typographical variations: for example tool kit in wordnet as toolkit.7 We have added various heuristics to improve the look up within wordnet. We also started to work on improving the tokenization, but decided this was too large a task. Instead, we are looking at exploiting a more semantically aware tokenizer (Dridan and Oepen, 2012). Similarly for Chinese, we are comparing a wider variety of tokenizers. One reviewer suggested that there are more accurate proprietary pos taggers and segmenters available for Chinese. Unfortunately, the fact that they are not freely available means that we cannot test them to see if they are better. Our experience with English, 6 The corpus and guidelines are available at http:// compling.hss.ntu.edu.sg/ntumc/. 7 Although not with the desired sense. where we have more experience with state-of-theart systems is that (i) they do not do well with out-of-domain data (a well-known failing) and ("
W14-0154,padro-etal-2010-freeling,0,0.0776805,"Missing"
W14-0154,W14-0132,1,0.802277,"ourism web pages, in both Chinese and English. 1 Introduction Since the first release of the Princeton WordNet (PWN) (Fellbaum, 1998) there has been a great increase in the size and number of wordnets created (Bond and Paik, 2012). Further, there has been an empirical revolution in natural language processing (Vanderwende and Menezes, 2005), with machine learning based on annotated corpora dominating the field. Given this, we would expect to see a flowering of sense annotated corpora. However, they are still relatively rare and small in size compared to part-of-speech and tree banked corpora (Petrolito and Bond, 2014). In this paper we describe ongoing work to sense annotate data in two languages (English and Chinese), using texts provided by the Nanyang Technological University Multilingual Corpus (NTUMC: Tan and Bond, 2012). We discuss some of the problems involved with pre-processing (Section 3), monolingual sense tagging (Section 4) and multi-lingually linking the data (Section 5). We then discuss some ideas to improve the annotation process (Section 6) and conclude. translations have been made. The leading project was the Italian SemCor with 268,905 Italian tokens and 258,499 English tokens (Pianta et"
W14-0154,W13-4302,1,0.858772,"on is the MultiSemCor (Pianta et al., 2002). Taking the English SemCor (Landes et al., 1998) as a source, first Italian, then Romanian and Japanese The Princeton Wordnet is an important resource in natural language processing, psychology, and language studies. It was developed from 1985 at Princeton University. Nouns, verbs, adjective and adverbs were grouped into synsets and linked through semantic relation (Fellbaum, 1998). We used Southeast University’s Chinese Wordnet to tag the Chinese part (SEW: Xu et al., 2008),1 and are now in the process of switching to the Chinese Open Wordnet (COW: Wang and Bond, 2013).2 3 Pre-processing the Corpus In this paper we talk only about the Chinese and English text from the short story, essay and tourism genres of the NTU-MC, although we are also cooperating with other work on tagging Indonesian and Japanese (Bond et al., 2013). The short stories are two Sherlock Holmes’ Adventures (The Adventure of the Dancing Men and The Adventure of the Speckled Band), the essay is The Cathedral and the Bazaar (Raymond, 1999) and the tourism data is from the Singapore tourist board’s web pages (Singapore Tourist Board, 2012). The corpus sizes are shown in Table 1. We show the"
W15-3302,Y12-1002,0,0.0239595,"and generation. The semantic structures in MRS are underspecified for scope and thus suitable for representing ambiguous scoping. 9 Proceedings of the Grammar Engineering Across Frameworks (GEAF) Workshop, 53rd Annual Meeting of the ACL and 7th IJCNLP, pages 9–16, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics There is no previous work done on Indonesian HPSG but much has been done using Lexical Functional Grammar (LFG) (Kaplan and Bresnan, 1982), e.g. Arka and Manning (2008) on active and passive voice and Arka (2000) on control constructions. In addition, Arka (2012) and Mistica (2013) have worked on the computational grammar ”IndoGram” which is a part of the ParGram (Sulger et al., 2013).1 However, it is not open-source or very broad in its coverage. Further, it does not produce MRS, so cannot be easily incorporated into our machine translation system. Thus, there is a need to build and develop a broadcoverage open-source HPSG of Indonesian. 2.2 and LOGON (Oepen et al., 2007), a collection of software, grammars, and other linguistic resources for transfer-based machine translation. 3 This section describes some preliminary work as well as the methodology"
W15-3302,Y11-1027,1,0.923032,"d applicative constructions. This paper presents the creation and the initial stage development of a broadcoverage Indonesian Resource Grammar (INDRA) within the framework of Head Driven Phrase Structure Grammar (HPSG) (Pollard and Sag, 1994) and Minimal Recursion Semantics (MRS) (Copestake et al., 2005). At the present stage, INDRA focuses on verbal constructions and subcategorization since they are fundamental for argument and event structure. Verbs in INDRA were semi-automatically acquired from the English Resource Grammar (ERG) (Flickinger, 2000) via Wordnet Bahasa (Nurril Hirfana Mohamed Noor et al., 2011; Bond et al., 2014). In the future, INDRA will be used in the development process of machine translation. A preliminary evaluation of INDRA on the MRS test-suite shows promising coverage. 1 2 Background This section introduces the background theory, as well as an overview of the Deep Linguistic Processing with HPSG Initiative (DELPH-IN) and the tools to build and develop INDRA. Introduction to Indonesian Indonesian (ISO 639-3: ind) is a Western MalayoPolynesian language of the Austronesian language family. Within this subgroup, it belongs to the Malayic branch with Standard Malay in Malaysia"
W15-3302,2007.tmi-papers.18,0,0.049844,"Missing"
W15-3302,copestake-flickinger-2000-open,0,0.137547,"is process goes repetitively. If problems are not found or the debugging process has finished with a good result, the grammar will be updated in GitHub (https://github.com/davidmoeljadi/INDRA). DELPH-IN The DELPH-IN consortium (Deep Linguistic Processing with HPSG Initiative, http://www. delph-in.net) is a research collaboration between linguists and computer scientists which builds and develops open source grammar, tools for grammar development and applications using HPSG and MRS. More than fifteen grammars have been created and developed within DELPH-IN, e.g. English Resource Grammar (ERG) (Copestake and Flickinger, 2000) and Japanese grammar Jacy (Siegel and Bender, 2002). DELPH-IN grammars define typed feature structures using Type Description Language (TDL) (Copestake, 2002). We make extensive use of several open-source tools for grammar development provided by DELPH-IN: Linguistic Knowledge Builder (LKB) (Copestake, 2002), a grammar and lexicon development environment for typed feature structure grammars; The LinGO Grammar Matrix (Bender et al., 2010), a web-based questionnaire for writing new DELPH-IN grammars, providing a wide range of phenomena and basic files to make the grammars compatible with DELPH-"
W15-3302,W02-1210,0,0.05159,"the debugging process has finished with a good result, the grammar will be updated in GitHub (https://github.com/davidmoeljadi/INDRA). DELPH-IN The DELPH-IN consortium (Deep Linguistic Processing with HPSG Initiative, http://www. delph-in.net) is a research collaboration between linguists and computer scientists which builds and develops open source grammar, tools for grammar development and applications using HPSG and MRS. More than fifteen grammars have been created and developed within DELPH-IN, e.g. English Resource Grammar (ERG) (Copestake and Flickinger, 2000) and Japanese grammar Jacy (Siegel and Bender, 2002). DELPH-IN grammars define typed feature structures using Type Description Language (TDL) (Copestake, 2002). We make extensive use of several open-source tools for grammar development provided by DELPH-IN: Linguistic Knowledge Builder (LKB) (Copestake, 2002), a grammar and lexicon development environment for typed feature structure grammars; The LinGO Grammar Matrix (Bender et al., 2010), a web-based questionnaire for writing new DELPH-IN grammars, providing a wide range of phenomena and basic files to make the grammars compatible with DELPH-IN parsers and generators; Answer Constraint Engine"
W15-3302,P13-1054,0,0.0689086,"Missing"
W15-3303,adolphs-etal-2008-fine,0,0.0296465,"Missing"
W15-3303,fokkens-etal-2012-climb,0,0.0237895,"e development of 18 complex grammars through grammar customization by providing a static core grammar that handles basic phrase types, semantic compositionality and general infrastructure. It also provides libraries for cross-linguistically variable phenomena, so that analyses of these can be dynamically generated as code based on user-configured parameters. The generated grammar is then extended usually manually by a grammar engineer. CoreGram (M¨uller, 2013) is motivated by a similar assumption that grammars sharing certain properties can be grouped into classes and thus share common files. Fokkens et al. (2012) proposes CLIMB (Comparative Libraries of Implementations with Matrix Basis), a methodology closely related to the LinGO Grammar Matrix. While still sharing implementation across different languages, the emphasis of CLIMB is facilitating the exploration and comparison of implementations of different analyses for the same phenomenon. tional characters. These two further inherit from zhs.tdl and zht.tdl, respectively. The offi cial webpage of ZHONG [ ], with demo and test results, is http://moin.delph-in.net/ZhongTop, and the entire data set can be freely downloaded from https://github.com/delph"
W15-3303,P06-4018,0,0.183643,"Missing"
W15-3303,W00-1205,0,0.086865,"groups of test suites. First, we use three linguistic phenomena-based testsuites: the testsuite constructed at Free University of Berlin (fu-berlin, M¨uller and Lipenkova (2013)), the testsuite of the Mandarin Chinese Grammar (mcg-wxl, Zhang et al. (2011)), and the JEC basic sentences (jec, Kawahara and Kurohashi (2006)). Second, we use naturally occurring texts in order to check the computational feasibility of the current implementation. The corpora we used include the NTU-MC (ntumc, Tan and Bond (2012)), the Penn Chinese Treebank (pctb, Xue et al. (2005)), and the Sinica Treebank (sinica, Huang et al. (2000)). We used the entire NTU-MC (7,460 sentences) and extracted the first 5,000 sentences from the other two corpora. The tools for running tests are pyDelphin (https: //github.com/goodmami/pydelphin) and gTest (https://github.com/goodmami/gtest). The result of coverage testing is provided in Table 3. The numbers in parenthesis stand for the coverage of ungrammatical sentences. Note that only the first two include ungrammatical items. Since ungrammatical sentences had better be rejected, the smaller number means the better performance for those items. All the numbers in parenthesis are smaller th"
W15-3303,2008.iwslt-papers.2,1,0.726606,"delimited and converted to simplified Chinese script. It was further preprocessed using the Stanford Segmentor and POS tagger. Using very restrictive POS patterns, CL-noun pairs are extracted and filtered against a list of 204 sortal-CLs provided by Huang (Huang et al., 1997). They are then added into a lemma-based dictionary together with their frequency information. This lemma-based dictionary is further expanded into concept-based dictionary by mapping the lemmas to the concepts 4.3 Configuration ZHONG [ ] has been built up following the premise “parsing robustly and generating strictly” (Bond et al., 2008). This means that even a rather infelicitous sentence should be parsed, but the infelicitous sentence should be filtered out in generation. This different approach to parsing and generation can be facilitated using different configurations for compiling grammars. First, ZHONG [ ] includes a flag feature [STYLE style] for marking the felicity of particular lexical items and constructions, whose subtypes are strict, robust, unproductive, etc. Second, there are different types of roots: namely, roots.tdl, roots-robust.tdl, and roots-strict.tdl. The first one works for ordinary parsing and generat"
W15-3303,kawahara-kurohashi-2006-case,0,0.0410997,"Missing"
W15-3303,W13-4304,0,0.0139505,"quantifier scopes and others, which allows flexibility in representation. 17 Proceedings of the Grammar Engineering Across Frameworks (GEAF) Workshop, 53rd Annual Meeting of the ACL and 7th IJCNLP, pages 17–24, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics 2.2 2.3.2 DELPH-IN In more recent work, in-depth analysis continues to be conducted on specific phenomena in Chinese HPSG, like the detailed account of Serial Verb Constructions (SVC) (M¨uller and Lipenkova, 2009), reanalysis of BA structure (Lipenkova, 2011), valence alternations and marking structures (Lipenkova, 2013), etc. However, the trend is to extend pure linguistic analysis to implementation of the grammar as a more general computational resource. This has led to a few independently developed HPSG grammars on Mandarin Chinese with MRS as the semantic representation format: ManGO (Yang, 2007), MCG (Zhang et al., 2011), and ChinGram (M¨uller and Lipenkova, 2013). ChinGram was implemented in the grammar development system TRALE (Meurers et al., 2002), whereas ManGO and MCG were developed using LKB and the LinGO Grammar Matrix customization system (Bender et al., 2010). These grammars cover a wide variet"
W15-3303,W02-0103,0,0.0433057,"unt of Serial Verb Constructions (SVC) (M¨uller and Lipenkova, 2009), reanalysis of BA structure (Lipenkova, 2011), valence alternations and marking structures (Lipenkova, 2013), etc. However, the trend is to extend pure linguistic analysis to implementation of the grammar as a more general computational resource. This has led to a few independently developed HPSG grammars on Mandarin Chinese with MRS as the semantic representation format: ManGO (Yang, 2007), MCG (Zhang et al., 2011), and ChinGram (M¨uller and Lipenkova, 2013). ChinGram was implemented in the grammar development system TRALE (Meurers et al., 2002), whereas ManGO and MCG were developed using LKB and the LinGO Grammar Matrix customization system (Bender et al., 2010). These grammars cover a wide variety of core linguistic phenomena in Mandarin Chinese, but have limited lexical coverage as they typically only provide lexical entries for the words appearing in focused testsuites. Yu et al. (2010), on the other hand, has explored a semi-automatic approach to developing a Chinese HPSG parser by proposing a skeleton design of the grammar and then learning a lexicon from an HPSG Treebank manually converted from the Penn Chinese Treebank 6.0 (X"
W15-3303,tian-etal-2014-um,0,0.0469495,"Missing"
W15-3303,N03-1033,0,0.0701157,"Missing"
W15-3303,Y13-1023,0,0.026382,"Missing"
W15-3303,W13-4302,1,0.845781,"Missing"
W15-3303,W02-1210,0,0.043547,"en-source tools, computational grammars, and language resources. The tools include grammar development environment (LKB (Copestake, 2002)), efficient parsers/generators for language processing (PET (Callmeier, 2000), ACE (http://sweaglesw. org/linguistics/ace), agree (Slayden, 2012)), dynamic treebanking tools ([incr tsdb()] (Oepen, 2001), ACE), machine translation engine (LOGON, ACE, agree), and stochastic models to select the most plausible interpretation. The collection of DELPH-IN grammars described in Type Definition Language include ERG for English (Flickinger, 2000), Jacy for Japanese (Siegel and Bender, 2002), GG for German (Crysmann, 2003), SRG for Spanish (Marimon, 2012), KRG for Korean (Kim et al., 2011), and others. The language resources contain test sets parsed with DELPH-IN grammars, such as the Redwoods Treebank in English (Oepen et al., 2004) and the Hinoki Treebank in Japanese (Bond et al., 2006), and a set of transfer rules (e.g. JaEn, (Bond et al., 2011)). 2.3 2.3.1 Computational Grammars Previous Work on Chinese HPSG Early Work Early work on Chinese HPSG can be traced back to the 1990s, typically focusing on pure linguistic analysis of specific phenomena in Mandarin Chinese, such as t"
W15-3303,C10-2162,0,0.0304636,"oped HPSG grammars on Mandarin Chinese with MRS as the semantic representation format: ManGO (Yang, 2007), MCG (Zhang et al., 2011), and ChinGram (M¨uller and Lipenkova, 2013). ChinGram was implemented in the grammar development system TRALE (Meurers et al., 2002), whereas ManGO and MCG were developed using LKB and the LinGO Grammar Matrix customization system (Bender et al., 2010). These grammars cover a wide variety of core linguistic phenomena in Mandarin Chinese, but have limited lexical coverage as they typically only provide lexical entries for the words appearing in focused testsuites. Yu et al. (2010), on the other hand, has explored a semi-automatic approach to developing a Chinese HPSG parser by proposing a skeleton design of the grammar and then learning a lexicon from an HPSG Treebank manually converted from the Penn Chinese Treebank 6.0 (Xue et al., 2005). The foundation of our work is ManGO. Its testsuite is a Mandarin Chinese version of the MRS testsuite used by the ERG, with short example sentences covering a wide range of phenomena such as intransitive, transitive, and ditransitive verbs, BA and BEI structures, clausal subjects/objects, aspect markers, prepositional and adverbial"
W15-3303,W11-3404,0,0.0180012,"H-IN In more recent work, in-depth analysis continues to be conducted on specific phenomena in Chinese HPSG, like the detailed account of Serial Verb Constructions (SVC) (M¨uller and Lipenkova, 2009), reanalysis of BA structure (Lipenkova, 2011), valence alternations and marking structures (Lipenkova, 2013), etc. However, the trend is to extend pure linguistic analysis to implementation of the grammar as a more general computational resource. This has led to a few independently developed HPSG grammars on Mandarin Chinese with MRS as the semantic representation format: ManGO (Yang, 2007), MCG (Zhang et al., 2011), and ChinGram (M¨uller and Lipenkova, 2013). ChinGram was implemented in the grammar development system TRALE (Meurers et al., 2002), whereas ManGO and MCG were developed using LKB and the LinGO Grammar Matrix customization system (Bender et al., 2010). These grammars cover a wide variety of core linguistic phenomena in Mandarin Chinese, but have limited lexical coverage as they typically only provide lexical entries for the words appearing in focused testsuites. Yu et al. (2010), on the other hand, has explored a semi-automatic approach to developing a Chinese HPSG parser by proposing a skel"
W15-3303,I05-3027,0,\N,Missing
W15-4105,D08-1089,0,0.351286,"Missing"
W15-4105,W08-0509,0,0.172715,"T system on the WAT test set. The leftmost columns indicate the number of times a dictionary is appended to the parallel training data (Baseline = 0 times, Passive x1 = 1 time). The rightmost columns present the results from both the passive and pervasive use of dictionary translations, with exception to the top-right cell which shows the baseline result of the pervasive dictionary usage without appending any dictionary. • MGIZA++ implementation of IBM word alignment model 4 with grow-diagonalfinal-and heuristics for word alignment and phrase-extraction (Och and Ney, 2003; Koehn et al., 2003; Gao and Vogel, 2008) • Bi-directional lexicalized reordering model that considers monotone, swap and discontinuous orientations (Koehn et al., 2005 and Galley and Manning, 2008) Baseline Passive x1 Passive x2 Passive x3 Passive x4 Passive x5 • Language modeling is trained using KenLM with maximum phrase length of 5 with Kneser-Ney smoothing (Heafield, 2011; Kneser and Ney, 1995) • Minimum Error Rate Training (MERT) (Och, 2003) to tune the decoding parameters. + Pervasive 16.87 17.30∗∗ 16.87 17.06 17.38∗∗ 17.29∗∗ Table 2: BLEU Scores for Passive and Pervasive Use of the Dictionary in SMT (Japanese to English) • Fo"
W15-4105,W07-0733,0,0.0411937,"e given the source sentence, p(f|e), and the a priori probability of the translation, pLM (e) (Brown, 1993). ebest = argmax p(e|f ) e = argmax p(f |e) e pLM (e) State-of-art SMT systems rely on (i) large bilingual corpora to train the translation model p(f|e) and (ii) monolingual corpora to build the language model, pLM (e). One approach to improve the translation model is to extend the parallel data with a bilingual dictionary prior to training the model. The primary motivation to use additional lexical information for domain adaptation to overcome the out-ofvocabulary words during decoding (Koehn and Schroeder, 2007; Meng et al. 2014; Wu et al. 2008). Alternatively, adding in-domain lexicon to 30 Proceedings of the ACL 2015 Fourth Workshop on Hybrid Approaches to Translation (HyTra), pages 30–34, c Beijing, China, July 31, 2015. 2015 Association for Computational Linguistics translation. 2 In such a situation, where the dictionary does not provide a translation for the complete multiword string, we set the preference for the dictionary entry with the longest length in the direction from left to right and select “magnetic sensor” + “system” entries for forced translation.1 Finally, we investigate the effe"
W15-4105,N03-1017,0,0.0563605,"the phrase-based SMT system on the WAT test set. The leftmost columns indicate the number of times a dictionary is appended to the parallel training data (Baseline = 0 times, Passive x1 = 1 time). The rightmost columns present the results from both the passive and pervasive use of dictionary translations, with exception to the top-right cell which shows the baseline result of the pervasive dictionary usage without appending any dictionary. • MGIZA++ implementation of IBM word alignment model 4 with grow-diagonalfinal-and heuristics for word alignment and phrase-extraction (Och and Ney, 2003; Koehn et al., 2003; Gao and Vogel, 2008) • Bi-directional lexicalized reordering model that considers monotone, swap and discontinuous orientations (Koehn et al., 2005 and Galley and Manning, 2008) Baseline Passive x1 Passive x2 Passive x3 Passive x4 Passive x5 • Language modeling is trained using KenLM with maximum phrase length of 5 with Kneser-Ney smoothing (Heafield, 2011; Kneser and Ney, 1995) • Minimum Error Rate Training (MERT) (Och, 2003) to tune the decoding parameters. + Pervasive 16.87 17.30∗∗ 16.87 17.06 17.38∗∗ 17.29∗∗ Table 2: BLEU Scores for Passive and Pervasive Use of the Dictionary in SMT (Jap"
W15-4105,2005.mtsummit-papers.11,0,0.334378,"Missing"
W15-4105,C08-1125,0,0.0710785,"Missing"
W15-4105,D14-1060,0,0.0166551,", p(f|e), and the a priori probability of the translation, pLM (e) (Brown, 1993). ebest = argmax p(e|f ) e = argmax p(f |e) e pLM (e) State-of-art SMT systems rely on (i) large bilingual corpora to train the translation model p(f|e) and (ii) monolingual corpora to build the language model, pLM (e). One approach to improve the translation model is to extend the parallel data with a bilingual dictionary prior to training the model. The primary motivation to use additional lexical information for domain adaptation to overcome the out-ofvocabulary words during decoding (Koehn and Schroeder, 2007; Meng et al. 2014; Wu et al. 2008). Alternatively, adding in-domain lexicon to 30 Proceedings of the ACL 2015 Fourth Workshop on Hybrid Approaches to Translation (HyTra), pages 30–34, c Beijing, China, July 31, 2015. 2015 Association for Computational Linguistics translation. 2 In such a situation, where the dictionary does not provide a translation for the complete multiword string, we set the preference for the dictionary entry with the longest length in the direction from left to right and select “magnetic sensor” + “system” entries for forced translation.1 Finally, we investigate the effects of using the b"
W15-4105,W14-7001,0,0.214297,"Missing"
W15-4105,J03-1002,0,0.0213841,"lation outputs from the phrase-based SMT system on the WAT test set. The leftmost columns indicate the number of times a dictionary is appended to the parallel training data (Baseline = 0 times, Passive x1 = 1 time). The rightmost columns present the results from both the passive and pervasive use of dictionary translations, with exception to the top-right cell which shows the baseline result of the pervasive dictionary usage without appending any dictionary. • MGIZA++ implementation of IBM word alignment model 4 with grow-diagonalfinal-and heuristics for word alignment and phrase-extraction (Och and Ney, 2003; Koehn et al., 2003; Gao and Vogel, 2008) • Bi-directional lexicalized reordering model that considers monotone, swap and discontinuous orientations (Koehn et al., 2005 and Galley and Manning, 2008) Baseline Passive x1 Passive x2 Passive x3 Passive x4 Passive x5 • Language modeling is trained using KenLM with maximum phrase length of 5 with Kneser-Ney smoothing (Heafield, 2011; Kneser and Ney, 1995) • Minimum Error Rate Training (MERT) (Och, 2003) to tune the decoding parameters. + Pervasive 16.87 17.30∗∗ 16.87 17.06 17.38∗∗ 17.29∗∗ Table 2: BLEU Scores for Passive and Pervasive Use of the Di"
W15-4105,W14-3323,1,0.891614,"Missing"
W15-4105,2011.eamt-1.10,0,0.0193629,".de, josef.van genabith@dfki.de, bond@ieee.org Abstract parallel data has also shown to improve SMT. The intuition is that by adding extra counts of bilingual lexical entries, the word alignment accuracy improves, resulting in a better translation model (Skadins et al. 2013; Tan and Pal, 2014; Tan and Bond, 2014). Another approach to use a bilingual dictionary is to hijack the decoding process and force word/phrase translations as per the dictionary entries. Previous researches used this approach to explore various improvements in industrial and academic translation experiments. For instance, Tezcan and Vandeghinste (2011) injected a bilingual dictionary in the SMT decoding process and integrated it with Computer Assisted Translation (CAT) environment to translate documents in the technical domain. They showed that using a dictionary in decoding improves machine translation output and reduces post-editing time of human translators. Carpuat (2009) experimented with translating sentences in discourse context by using a discourse specific dictionary annotations to resolve lexical ambiguities and showed that this can potentially improve translation quality. In this paper, we investigate the improvements made by bot"
W15-4105,vogel-monson-2004-augmenting,0,0.0535445,"Missing"
W15-4105,N06-1001,0,0.0346588,"nd Galley and Manning, 2008) Baseline Passive x1 Passive x2 Passive x3 Passive x4 Passive x5 • Language modeling is trained using KenLM with maximum phrase length of 5 with Kneser-Ney smoothing (Heafield, 2011; Kneser and Ney, 1995) • Minimum Error Rate Training (MERT) (Och, 2003) to tune the decoding parameters. + Pervasive 16.87 17.30∗∗ 16.87 17.06 17.38∗∗ 17.29∗∗ Table 2: BLEU Scores for Passive and Pervasive Use of the Dictionary in SMT (Japanese to English) • For English translations, we trained a truecasing model to keep/reduce tokens’ capitalization to their statistical canonical form (Wang et al., 2006; Lita et al., 2003) and we recased the translation output after the decoding process By repeatedly appending the dictionary to the parallel data, the BLEU scores significantly4 improves from 16.75 to 17.31. Although the system’s performance degrades when adding the dictionary passively thrice, the score remains significantly better than baseline. The pervasive use of the dictionary improves the baseline without the passive of the dictionary. The best performance is achieved when the dictionary is passively added four times with the pervasive use of the dictionary during decoding. The fluctuat"
W15-4105,W09-2404,0,\N,Missing
W15-4105,P03-1020,0,\N,Missing
W15-4105,W11-2123,0,\N,Missing
W15-4105,P13-2121,0,\N,Missing
wang-bond-2014-building,isahara-etal-2008-development,1,\N,Missing
wang-bond-2014-building,Y11-1027,1,\N,Missing
wang-bond-2014-building,W13-2319,1,\N,Missing
wang-bond-2014-building,W03-1712,0,\N,Missing
wang-bond-2014-building,W00-0802,0,\N,Missing
wang-bond-2014-building,P98-2206,0,\N,Missing
wang-bond-2014-building,C98-2201,0,\N,Missing
wang-bond-2014-building,P96-1006,0,\N,Missing
wang-bond-2014-building,cyrus-2006-building,0,\N,Missing
wang-bond-2014-building,O03-4002,0,\N,Missing
wang-bond-2014-building,2005.mtsummit-papers.11,0,\N,Missing
wang-bond-2014-building,W13-4302,1,\N,Missing
wang-bond-2014-building,W14-0132,1,\N,Missing
wang-bond-2014-building,R11-1032,0,\N,Missing
wang-bond-2014-building,I08-4015,0,\N,Missing
wang-bond-2014-building,W14-0154,1,\N,Missing
Y11-1027,bond-etal-2008-boot,1,0.84384,"he extend approach on the other hand is executed by obtaining a set of synsets from Princeton WordNet (PWN), and then translating it into the target language. This method allows the preservation of the original structure of the wordnet. We have opted for the extend approach both because of its simplicity and because the resulting wordnet is automatically aligned to all other wordnets. The idea of extending the synsets with reference from not just the PWN but at least one other wordnet in a different language provides a much stronger foundation laid before the construction of a new wordnet. In Bond et al. (2008), the authors pointed out that by using wordnets in multiple languages to disambiguate the target language (Japanese in their study), a more reliable prototype could be provided. This multiple-pivot technique was then adapted to suit the needs of the Wordnet Bahasa, as will be explained in the next section. There has already been some work on building wordnets for Malay and Indonesian. Lim and Hussein (2006) serves as a good head start for the building of a Malay wordnet. The paper suggests finding the prototype based on sense alignments with Kamus Inggeris Melayu Dewan (KIMD) and the English"
Y11-1027,W10-3202,0,0.0634487,"rough gage of the minimum possible range of words in a Malay wordnet. In the final discussion of the paper, Lim and Hussein (2006) point out that the bottleneck for their prototype “is in the dictionary used”. Unfortunately, we do not have access to the same Malay lexicon, so we cannot directly implement their approach. There have been two approaches to building an Indonesian wordnet. The first was an expand approach, and created a small prototype (Putra et al., 2008). The second also used an expand approach, and then corrected entries using the infrastructure from the Asian Wordnet Project (Riza et al., 2010). The Indonesian Wordnet at the Asian Wordnet currently has 33,726 synsets; 38,394 words and 65,206 senses (word-synset pairs).2 The lexicons used to expand were bilingual English-Indonesian and thus did not enable the use of multiple pivots. 3 Resources We used two lexicons: FEM, which contains entries with French, English and Malay as well as hypernyms in French; and KAMI, which contains Malay, English and Chinese as well as semantic classes from the Goi-Taikei ontology. 1 2 http://www.ethnologue.com/show_language.asp?code=msa http://id.asianwordnet.org/ 256 We used four wordnets: one for En"
Y11-1038,W04-2209,0,0.0263754,"ifferent conditions: –dic – hunalign outputs without language pair dictionary, +dic – hunalign outputs with language pair dictionary, +human – manually aligned Gold Standard, +pivot – alignments generated by transitive relation using 2 +human alignments Only sentences from the textfiles that were available in all 6 languages were sentence-aligned. Two native Chinese and Japanese speakers were enlisted to correct the +dic alignments for the English-Chinese and English-Japanese data. The English-Chinese, English-Japanese and English-Korean were generated with the CC-CEDICT (MDBG, 2011), JMDICT (Breen, 2004) and enhanced engdic (Paik and Bond, 2003) respectively. By extending the idea of exploiting existing resources to building and extending valency dictionaries, we used the +human alignments to produce +pivot alignments. Using English as the pivot language, we aligned Chinese-English-Japanese. 3 Corpus Evaluation The corpus evaluation is based on the data availability, corpus outputs and its monolingual and cross-lingual annotations. The monolingual annotations were evaluated extrinsically by measuring Inter-annotator Agreement (IAA) between the POS-taggers and human annotators. The lack of in-"
Y11-1038,chiao-etal-2006-evaluation,0,0.0440589,"Missing"
Y11-1038,eisele-chen-2010-multiun,0,0.0615047,"Missing"
Y11-1038,erjavec-2004-multext,0,0.0354198,"ty in NLP application tasks such as word sense disambiguation (e.g. Sarrafzadeh et al. 2011; Saravanan et al. 2010; Mitamura et al. 2007), information retrieval and questionanswering. In addition, parallel corpora are valuable resources for advancing linguistic annotations morphologically, syntactically and semantically (e.g. Snyder and Barzilay; 2008, Hwa et al. 2005; Resnik, 2004). The essential knowledge resource in building these language technologies are grounded on parallel corpora. The present pool of resources holds a sizable amount of European parallel corpora (e.g. Ralf et al. 2006; Erjavec, 2004), an increasing interest in building Asian languages-English bitexts (e.g. Xiao, 2004) but only a handful of parallel Asian language corpora (e.g. Zhang, 2005). To fill the lack of parallel corpora of Asian languages, the NTU–Multilingual Corpus (NTUMC) taps on the array of multilingual texts available in Singapore; ranging from the multilingual sign boards with official languages of Singapore (English, Chinese, Malay, Tamil) to posters, signs and guides targeted towards migrants, expats and tourists (in Indonesian, Japanese, Korean, Vietnamese, Thai, Tagalog, etc.). Singapore‟s multicultural"
Y11-1038,P07-2053,0,0.0300783,"Missing"
Y11-1038,P93-1004,0,0.307798,"Missing"
Y11-1038,I05-3005,0,0.060906,"s two “words” separated by whitespace are supposed to mean a single thing. For example, the Vietnamese word „quốc tế‟ mean international but the individual “word” separated by the space does have its meaning („quốc‟ means country and „tế‟ means to run). Thus the JVnSegmenter module within JVnTextPro (Nguyen and Phan, 2007) was used to tokenize the Vietnamese data. For the Japanese and Korean word level segmentation, the segmenter is incorporated into the POS-taggers that this corpus project is using. The Stanford Chinese word segmenter was used to segment the Chinese sentences in this corpus (Tseng et al, 2005). Mis-segments generated from Stanford segmenter were local street names that were transliterated from English to Chinese. For example, the Stanford Chinese word segmenter wrongly tokenized 乌节路 wujielu “Orchard road” as 乌 节路 wu jielu “black joint-road”. These topological terms were re-segmented with a manually crafted dictionary built using Wikipedia‟s Chinese translations of English names of Singapore places and streets. 2.5 Monolingual Annotation – Part Of Speech (POS) Tagging Different programs were used to tag the individual languages with their respective POS tag sets. Due to the lack of"
Y11-1038,Y11-1027,1,\N,Missing
Y11-1038,steinberger-etal-2006-jrc,0,\N,Missing
Y11-1038,W04-3230,0,\N,Missing
Y11-1038,D08-1089,0,\N,Missing
Y11-1038,C10-1045,0,\N,Missing
Y11-1038,I05-2015,0,\N,Missing
Y11-1038,2005.mtsummit-papers.10,0,\N,Missing
Y12-1028,C00-1014,1,0.473855,"guages: Mandarin Chinese and Japanese. This paper presents a quantitative analysis of classifier translations between these two languages to better understand differences in classifier usage. Keywords – numeral classifier, sortal, translation, Mandarin Chinese, Japanese, contrastive linguistics 1 (1) (2) Introduction Mandarin Chinese (CMN) and Japanese (JPN) are numeral classifier languages. Numeral classifier languages express the quantity of referents by modifying a noun phrase (NP) with an obligatory numeral-classifier construction where the classifier denotes inherent referent attributes (Bond and Paik, 2000; Downing, 1996). Hence, for a numeralclassifier construction that is assigned to a noun, the numeral denotes the numerical quantity of the noun referent while the numeral classifier denotes the quality of the noun referent. Bond and Paik (2000) identified five main types of classifiers. Event classifiers classify events (Japanese: -kai 回 ‘time’; Mandarin Chinese: -cì 次‘time’). Mensural classifiers are employed for the measurement of physical properties (Japanese: -sun 寸 ‘inches’; Mandarin Chinese: cùn 寸 ‘inches’). Group classifiers classify groupings of referents (Japanese: -kumi 組 ‘pair, set"
Y12-1028,Y11-1038,1,0.766508,"g point of the development of a definite article (known as Stage I). Further development then sees it offering both definite and indefinite uses (Stage II). Our findings on how demonstratives and indefinite use in classifier phrases act as determiners seem to suggest that Mandarin Chinese is in the process of evolving articles. Finally, for future research, translation comparison for less impersonal domains (e.g. editorials) might shed light on whether certain classifier usage differences may be due to pragmatic factors. With regards to cross-linguistic interests, the NTU multilingual Corpus (Tan and Bond, 2011) contains more corpora linked to other classifier languages such as Thai, Vietnamese, Indonesian and Korean. These resources may be exploited in future studies to observe classifier usage patterns and a comparison may be done later between the studied languages to determine if similar (or dissimilar) phenomena and patterns exist. 7 Conclusion In this paper, we identified categories of classifier translations from Japanese to Mandarin Chinese and looked at notable translations that have implications for understanding lexical, syntactic and pragmatic differences. The analysis of classifier trans"
