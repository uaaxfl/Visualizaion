2021.blackboxnlp-1.15,On the Language-specificity of Multilingual {BERT} and the Impact of Fine-tuning,2021,-1,-1,2,0.882353,12095,marc tanti,Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,0,"Recent work has shown evidence that the knowledge acquired by multilingual BERT (mBERT) has two components: a language-specific and a language-neutral one. This paper analyses the relationship between them, in the context of fine-tuning on two tasks {--} POS tagging and natural language inference {--} which require the model to bring to bear different degrees of language-specific knowledge. Visualisations reveal that mBERT loses the ability to cluster representations by language after fine-tuning, a result that is supported by evidence from language identification experiments. However, further experiments on {`}unlearning{'} language-specific representations using gradient reversal and iterative adversarial learning are shown not to add further improvement to the language-independent component over and above the effect of fine-tuning. The results presented here suggest that the process of fine-tuning causes a reorganisation of the model{'}s limited representational capacity, enhancing language-independent representations at the expense of language-specific ones."
2020.lt4hala-1.11,Word Probability Findings in the Voynich Manuscript,2020,-1,-1,2,0,16560,colin layfield,Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages,0,"The Voynich Manuscript has baffled scholars for centuries. Some believe the elaborate 15th century codex to be a hoax whilst others believe it is a real medieval manuscript whose contents are as yet unknown. In this paper, we provide additional evidence that the text of the manuscript displays the hallmarks of a proper natural language with respect to the relationship between word probabilities and (i) average information per subword segment and (ii) the relative positioning of consecutive subword segments necessary to uniquely identify words of different probabilities."
2020.lrec-1.626,Annotating for Hate Speech: The {M}a{N}e{C}o Corpus and Some Input from Critical Discourse Analysis,2020,-1,-1,3,0,17903,stavros assimakopoulos,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents a novel scheme for the annotation of hate speech in corpora of Web 2.0 commentary. The proposed scheme is motivated by the critical analysis of posts made in reaction to news reports on the Mediterranean migration crisis and LGBTIQ+ matters in Malta, which was conducted under the auspices of the EU-funded C.O.N.T.A.C.T. project. Based on the realisation that hate speech is not a clear-cut category to begin with, appears to belong to a continuum of discriminatory discourse and is often realised through the use of indirect linguistic means, it is argued that annotation schemes for its detection should refrain from directly including the label {`}hate speech,{'} as different annotators might have different thresholds as to what constitutes hate speech and what not. In view of this, we propose a multi-layer annotation scheme, which is pilot-tested against a binary {\mbox{$\pm$}}hate speech classification and appears to yield higher inter-annotator agreement. Motivating the postulation of our scheme, we then present the MaNeCo corpus on which it will eventually be used; a substantial corpus of on-line newspaper comments spanning 10 years."
2020.lrec-1.784,{MASRI}-{HEADSET}: A {M}altese Corpus for Speech Recognition,2020,-1,-1,5,0,18163,carlos mena,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Maltese, the national language of Malta, is spoken by approximately 500,000 people. Speech processing for Maltese is still in its early stages of development. In this paper, we present the first spoken Maltese corpus designed purposely for Automatic Speech Recognition (ASR). The MASRI-HEADSET corpus was developed by the MASRI project at the University of Malta. It consists of 8 hours of speech paired with text, recorded by using short text snippets in a laboratory environment. The speakers were recruited from different geographical locations all over the Maltese islands, and were roughly evenly distributed by gender. This paper also presents some initial results achieved in baseline experiments for Maltese ASR using Sphinx and Kaldi. The MASRI HEADSET Corpus is publicly available for research/academic purposes."
W19-5105,Learning to Predict Novel Noun-Noun Compounds,2019,23,0,2,0,368,prajit dhar,Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019),0,"We introduce temporally and contextually-aware models for the novel task of predicting unseen but plausible concepts, as conveyed by noun-noun compounds in a time-stamped corpus. We train compositional models on observed compounds, more specifically the composed distributed representations of their constituents across a time-stamped corpus, while giving it corrupted instances (where head or modifier are replaced by a random constituent) as negative evidence. The model captures generalisations over this data and learns what combinations give rise to plausible compounds and which ones do not. After training, we query the model for the plausibility of automatically generated novel combinations and verify whether the classifications are accurate. For our best model, we find that in around 85{\%} of the cases, the novel compounds generated are attested in previously unseen data. An additional estimated 5{\%} are plausible despite not being attested in the recent corpus, based on judgments from independent human raters."
W19-4729,Measuring the Compositionality of Noun-Noun Compounds over Time,2019,11,0,3,0,368,prajit dhar,Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change,0,"We present work in progress on the temporal progression of compositionality in noun-noun compounds. Previous work has proposed computational methods for determining the compositionality of compounds. These methods try to automatically determine how transparent the meaning of the compound as a whole is with respect to the meaning of its parts. We hypothesize that such a property might change over time. We use the time-stamped Google Books corpus for our diachronic investigations, and first examine whether the vector-based semantic spaces extracted from this corpus are able to predict compositionality ratings, despite their inherent limitations. We find that using temporal information helps predicting the ratings, although correlation with the ratings is lower than reported for other corpora. Finally, we show changes in compositionality over time for a selection of compounds."
L18-1525,{F}ace2{T}ext: Collecting an Annotated Image Description Corpus for the Generation of Rich Face Descriptions,2018,21,3,9,0,6764,albert gatt,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"The past few years have witnessed renewed interest in NLP tasks at the interface between vision and language. One intensively-studied problem is that of automatically generating text from images. In this paper, we extend this problem to the more specific domain of face description. Unlike scene descriptions, face descriptions are more fine-grained and rely on attributes extracted from the image, rather than objects and relations. Given that no data exists for this task, we present an ongoing crowdsourcing study to collect a corpus of descriptions of face images taken `in the wild'. To gain a better understanding of the variation we find in face description and the possible issues that this may raise, we also conducted an annotation study on a subset of the corpus. Primarily, we found descriptions to refer to a mixture of attributes, not only physical, but also emotional and inferential, which is bound to create further challenges for current image-to-text methods."
W17-5311,{LCT}-{MALTA}{'}s Submission to {R}ep{E}val 2017 Shared Task,2017,8,5,5,0,30853,hoa vu,Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for {NLP},0,"System using BiLSTM and max pooling. Embedding is enhanced by POS, character and dependency info."
P17-2010,Evaluating Compound Splitters Extrinsically with Textual Entailment,2017,20,0,3,1,11557,glorianna jagfeld,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Traditionally, compound splitters are evaluated intrinsically on gold-standard data or extrinsically on the task of statistical machine translation. We explore a novel way for the extrinsic evaluation of compound splitters, namely recognizing textual entailment. Compound splitting has great potential for this novel task that is both transparent and well-defined. Moreover, we show that it addresses certain aspects that are either ignored in intrinsic evaluations or compensated for by taskinternal mechanisms in statistical machine translation. We show significant improvements using different compound splitting methods on a German textual entailment dataset."
J17-4005,{S}urvey: Multiword Expression Processing: A {S}urvey,2017,208,24,4,0,5618,mathieu constant,Computational Linguistics,0,"Multiword expressions (MWEs) are a class of linguistic forms spanning conventional word boundaries that are both idiosyncratic and pervasive across different languages. The structure of linguistic processing that depends on the clear distinction between words and phrases has to be re-thought to accommodate MWEs. The issue of MWE handling is crucial for NLP applications, where it raises a number of challenges. The emergence of solutions in the absence of guiding principles motivates this survey, whose aim is not only to provide a focused review of MWE processing, but also to clarify the nature of interactions between MWE processing and downstream applications. We propose a conceptual framework within which challenges and research contributions can be positioned. It offers a shared understanding of what is meant by {``}MWE processing,{''} distinguishing the subtasks of MWE discovery and identification. It also elucidates the interactions between MWE processing and two use cases: Parsing and machine translation. Many of the approaches in the literature can be differentiated according to how MWE processing is timed with respect to underlying use cases. We discuss how such orchestration choices affect the scope of MWE-aware systems. For each of the two MWE processing subtasks and for each of the two use cases, we conclude on open issues and research perspectives."
W16-3811,The Grammar of {E}nglish Deverbal Compounds and their Meaning,2016,0,0,2,0,33678,gianina iorduachioaia,Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces ({G}ram{L}ex),0,"We present an interdisciplinary study on the interaction between the interpretation of noun-noun deverbal compounds (DCs; e.g., task assignment) and the morphosyntactic properties of their deverbal heads in English. Underlying hypotheses from theoretical linguistics are tested with tools and resources from computational linguistics. We start with Grimshaw{'}s (1990) insight that deverbal nouns are ambiguous between argument-supporting nominal (ASN) readings, which inherit verbal arguments (e.g., the assignment of the tasks), and the less verbal and more lexicalized Result Nominal and Simple Event readings (e.g., a two-page assignment). Following Grimshaw, our hypothesis is that the former will realize object arguments in DCs, while the latter will receive a wider range of interpretations like root compounds headed by non-derived nouns (e.g., chocolate box). Evidence from a large corpus assisted by machine learning techniques confirms this hypothesis, by showing that, besides other features, the realization of internal arguments by deverbal heads outside compounds (i.e., the most distinctive ASN-property in Grimshaw 1990) is a good predictor for an object interpretation of non-heads in DCs."
W16-1807,Top a Splitter: Using Distributional Semantics for Improving Compound Splitting,2016,10,1,3,1,32558,patrick ziering,Proceedings of the 12th Workshop on Multiword Expressions,0,None
N16-1078,Towards Unsupervised and Language-independent Compound Splitting using Inflectional Morphological Transformations,2016,8,5,2,1,32558,patrick ziering,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W15-2514,Predicting Pronouns across Languages with Continuous Word Spaces,2015,17,4,2,0,5766,ngocquan pham,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"Predicting pronouns across languages from a language with less variation to one with much more is a hard task that requires many different types of information, such as morpho-syntactic information as well as lexical semantics and coreference. We assumed that continuous word spaces fed into a multi-layer perceptron enriched with morphological tags and coreference resolution would be able to capture many of the linguistic regularities we found. Our results show that the model captures most of the linguistic generalisations. Its macro-averaged F-score is among the top-3 systems submitted to the DiscoMT shared task reaching 56.5%."
W15-0112,From a Distance: Using Cross-lingual Word Alignments for Noun Compound Bracketing,2015,21,1,2,1,32558,patrick ziering,Proceedings of the 11th International Conference on Computational Semantics,0,"We present a cross-lingual method for determining NP structures. More specifically, we try to determine whether the semantics of tripartite noun compounds in context requires a left or right branching interpretation. The system exploits the difference in word position between languages as found in parallel corpora. We achieve a bracketing accuracy of 94.6%, significantly outperforming all systems in comparison and comparable to human performance. Our system generates large amounts of high-quality bracketed NPs in a multilingual context that can be used to train supervised learners."
R15-1094,One Tree is not Enough: Cross-lingual Accumulative Structure Transfer for Semantic Indeterminacy,2015,21,0,2,1,32558,patrick ziering,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"We address the task of parsing semantically indeterminate expressions, for which several correct structures exist that do not lead to differences in meaning. We present a novel non-deterministic structure transfer method that accumulates all structural information based on cross-lingual word distance derived from parallel corpora. Our systemxe2x80x99s output is a ranked list of trees. To evaluate our system, we adopted common IR metrics. We show that our system outperforms previous cross-lingual structure transfer methods significantly. In addition, we illustrate that tree accumulation can be used to combine partial evidence across languages to form a single structure, thereby making use of sparse parallel data in an optimal way."
N15-2005,Towards a Better Semantic Role Labeling of Complex Predicates,2015,18,1,2,1,11557,glorianna jagfeld,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,0,"We propose a way to automatically improve the annotation of verbal complex predicates in PropBank which until now has been treating language mostly in a compositional manner. In order to minimize the manual re-annotation effort, we build on the recently introduced concept of aliasing complex predicates to existing PropBank rolesets which encompass the same meaning and argument structure. We suggest to find aliases automatically by applying a multilingual distributional model that uses the translations of simple and complex predicates as features. Furthermore, we set up an annotation effort to obtain a frequency balanced, realistic test set for this task. Our method reaches an accuracy of 44% on this test set and 72% for the more frequent test items in a lenient evaluation, which is not far from the upper bounds from human annotation."
F14-1005,Cross-lingual Word Sense Disambiguation for Predicate Labelling of {F}rench,2014,26,2,1,1,12096,lonneke plas,Proceedings of TALN 2014 (Volume 1: Long Papers),0,"We address the problem of transferring semantic annotations, more specifically predicate labellings, from one language to another using parallel corpora. Previous work has transferred these annotations directly at the token level, leading to low recall. We present a global approach to annotation transfer that aggregates information across the whole parallel corpus. We show that this global method outperforms previous results in terms of recall without sacrificing precision too much. Mots-cles : transfert inter-langue, annotation semantique automatique, predicats, desambiguisation lexicale, cor- pus paralleles."
C14-1099,What good are {`}Nominalkomposita{'} for {`}noun compounds{'}: Multilingual Extraction and Structure Analysis of Nominal Compositions using Linguistic Restrictors,2014,33,4,2,1,32558,patrick ziering,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Finding a definition of compoundhood that is cross-lingually valid is a non-trivial task as shown by linguistic literature. We present an iterative method for defining and extracting English noun compounds in a multilingual setting. We show how linguistic criteria can be used to extract compounds automatically and vice versa how the results of this extraction can shed new lights on linguistic theories about compounding. The extracted compound nouns and their multilingual contexts are a rich source that serves several purposes. In an additional case study we show how the database serves to predict the internal structure of tripartite noun compounds using spelling variations across languages, which leads to a precision of over 91%."
C14-1121,Global Methods for Cross-lingual Semantic Role and Predicate Labelling,2014,29,10,1,1,12096,lonneke plas,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We address the problem of transferring semantic annotations to new languages using parallel corpora. Previous work has transferred these annotations on a token-to-token basis, an approach that is sensitive to alignment errors and translation shifts. We present a global approach to transfer that aggregates information across the whole parallel corpus and leads to more robust labellers. We build two global models, one for predicate labelling and one for role labelling, each tailored to the task at hand. We show that the combination of direct and global methods outperforms previous results."
I13-1104,Multilingual Lexicon Bootstrapping - Improving a Lexicon Induction System Using a Parallel Corpus,2013,15,4,2,1,32558,patrick ziering,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We address the task of improving the quality of lexicon bootstrapping, i.e., of expanding a semantic lexicon on a given corpus. A main problem of iterative bootstrapping techniques is the fact that lexicon quality degrades gradually as more and more false terms are added. We propose to exploit linguistic variation between languages to reduce this problem of semantic drift with a knowledge-lean and language-independent ensemble method. Our results on English and German show that lexicon bootstrapping benefits significantly from the multilingual symbiosis."
I13-1188,Bootstrapping Semantic Lexicons for Technical Domains,2013,32,7,2,1,32558,patrick ziering,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We address the task of bootstrapping a semantic lexicon from a list of seed terms and a large corpus. By restricting to a small subset of semantically strong patterns, i.e., coordinations, we improve results significantly. We show that the restriction to coordinations has several additional benefits, such as improved extraction of multiword expressions, and the possibility to scale up previous efforts."
P11-2052,Scaling up Automatic Cross-Lingual Semantic Role Annotation,2011,26,43,1,1,12096,lonneke plas,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntactic-semantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations."
W10-3304,Finding Medical Term Variations using Parallel Corpora and Distributional Similarity,2010,28,9,1,1,12096,lonneke plas,Proceedings of the 6th Workshop on {O}ntologies and {L}exical {R}esources,0,We describe a method for the identification of medical term variations using parallel corpora and measures of distributional similarity. Our approach is based on automatic word alignment and standard phrase extraction techniques commonly used in statistical machine translation. Combined with pattern-based filters we obtain encouraging results compared to related approaches using similar datadriven techniques.
W10-1814,Cross-Lingual Validity of {P}rop{B}ank in the Manual Annotation of {F}rench,2010,14,22,1,1,12096,lonneke plas,Proceedings of the Fourth Linguistic Annotation Workshop,0,Methods that re-use existing mono-lingual semantic annotation resources to annotate a new language rely on the hypothesis that the semantic annotation scheme used is cross-lingually valid. We test this hypothesis in an annotation agreement study. We show that the annotation scheme can be applied cross-lingually.
W09-1706,Combining Syntactic Co-occurrences and Nearest Neighbours in Distributional Methods to Remedy Data Sparseness.,2009,27,0,1,1,12096,lonneke plas,Proceedings of the Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics,0,The task of automatically acquiring semantically related words have led people to study distributional similarity. The distributional hypothesis states that words that are similar share similar contexts. In this paper we present a technique that aims at improving the performance of a syntax-based distributional method by augmenting the original input of the system (syntactic co-occurrences) with the output of the system (nearest neighbours). This technique is based on the idea of the transitivity of similarity.
P09-1033,"Abstraction and Generalisation in Semantic Role Labels: {P}rop{B}ank, {V}erb{N}et or both?",2009,19,28,2,0,3347,paola merlo,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Semantic role labels are the representation of the grammatically relevant aspects of a sentence meaning. Capturing the nature and the number of semantic roles in a sentence is therefore fundamental to correctly describing the interface between grammar and meaning. In this paper, we compare two annotation schemes, Prop-Bank and VerbNet, in a task-independent, general way, analysing how well they fare in capturing the linguistic generalisations that are known to hold for semantic role labels, and consequently how well they grammaticalise aspects of meaning. We show that VerbNet is more verb-specific and better able to generalise to new semantic role instances, while PropBank better captures some of the structural constraints among roles. We conclude that these two resources should be used together, as they are complementary."
N09-2032,Domain Adaptation with Artificial Data for Semantic Parsing of Speech,2009,13,8,1,1,12096,lonneke plas,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,We adapt a semantic role parser to the domain of goal-directed speech by creating an artificial treebank from an existing text tree-bank. We use a three-component model that includes distributional models from both target and source domains. We show that we improve the parser's performance on utterances collected from human-machine dialogues by training on the artificially created data without loss of performance on the text treebank.
W08-1807,Using Lexico-Semantic Information for Query Expansion in Passage Retrieval for Question Answering,2008,20,11,1,1,12096,lonneke plas,Coling 2008: Proceedings of the 2nd workshop on Information Retrieval for Question Answering,0,"In this paper we investigate the use of several types of lexico-semantic information for query expansion in the passage retrieval component of our QA system. We have used four corpus-based methods to acquire semantically related words, and we have used one hand-built resource. We evaluate our techniques on the Dutch CLEF QA track. In our experiments expansions that try to bridge the terminological gap between question and document collection do not result in any improvements. However, expansions bridging the knowledge gap show modest improvements."
P06-2111,Finding Synonyms Using Automatic Word Alignment and Measures of Distributional Similarity,2006,19,81,1,1,12096,lonneke plas,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"There have been many proposals to extract semantically related words using measures of distributional similarity, but these typically are not able to distinguish between synonyms and other types of semantically related words such as antonyms, (co)hyponyms and hypernyms. We present a method based on automatic word alignment of parallel corpora consisting of documents translated into multiple languages and compare our method with a monolingual syntax-based method. The approach that uses aligned multilingual data to extract synonyms shows much higher precision and recall scores for the task of synonym extraction than the monolingual syntax-based approach."
I05-7011,Automatic Acquisition of Lexico-semantic Knowledge for {QA},2005,20,15,1,1,12096,lonneke plas,Proceedings of {O}nto{L}ex 2005 - Ontologies and Lexical Resources,0,"We present an experiment for finding semantically similar words on the basis of a parsed corpus of Dutch text and show that the acquired information correlates with relations found in Dutch EuroWordNet. Next, we demonstrate how the acquired knowledge can be used to boost the performance of an open-domain question answering system for Dutch. Automatically acquired lexico-semantic information is used to improve the recall of a method for extracting function relations (such as Wim Kok is the prime minister of the Netherlands) from corpora, and to improve the precision of our QA system on general WH-questions and definition questions."
van-der-plas-etal-2004-automatic,Automatic Keyword Extraction from Spoken Text. A Comparison of Two Lexical Resources: {EDR} and {W}ord{N}et,2004,8,21,1,1,12096,lonneke plas,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Lexical resources such as WordNet and the EDR electronic dictionary (EDR) have been used in several NLP tasks. Probably partly due to the fact that the EDR is not freely available, WordNet has been used far more often than the EDR. We have used both resources on the same task in order to make a comparison possible. The task is automatic assignment of keywords to multi-party dialogue episodes (i.e. thematically coherent stretches of spoken text). We show that the use of lexical resources in such a task results in slightly higher performances than the use of a purely statistically based method."
