2021.naacl-demos.8,{COVID}-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation,2021,-1,-1,24,0,4844,qingyun wang,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations,0,"To combat COVID-19, both clinicians and scientists need to digest the vast amount of relevant biomedical knowledge in literature to understand the disease mechanism and the related biological functions. We have developed a novel and comprehensive knowledge discovery framework, COVID-KG to extract fine-grained multimedia knowledge elements (entities, relations and events) from scientific literature. We then exploit the constructed multimedia knowledge graphs (KGs) for question answering and report generation, using drug repurposing as a case study. Our framework also provides detailed contextual sentences, subfigures, and knowledge subgraphs as evidence. All of the data, KGs, reports."
2021.naacl-demos.16,{RESIN}: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System,2021,-1,-1,20,0,3228,haoyang wen,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations,0,"We present a new information extraction system that can automatically construct temporal event graphs from a collection of news documents from multiple sources, multiple languages (English and Spanish for our experiment), and multiple data modalities (speech, text, image and video). The system advances state-of-the-art from two aspects: (1) extending from sentence-level event extraction to cross-document cross-lingual cross-media event extraction, coreference resolution and temporal event tracking; (2) using human curated event schema library to match and enhance the extraction output. We have made the dockerlized system publicly available for research purpose at GitHub, with a demo video."
2021.law-1.4,{A}uto{A}spect: Automatic Annotation of Tense and Aspect for Uniform Meaning Representations,2021,-1,-1,2,0,5432,daniel chen,Proceedings of The Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop,0,"We present AutoAspect, a novel, rule-based annotation tool for labeling tense and aspect. The pilot version annotates English data. The aspect labels are designed specifically for Uniform Meaning Representations (UMR), an annotation schema that aims to encode crosslingual semantic information. The annotation tool combines syntactic and semantic cues to assign aspects on a sentence-by-sentence basis, following a sequence of rules that each output a UMR aspect. Identified events proceed through the sequence until they are assigned an aspect. We achieve a recall of 76.17{\%} for identifying UMR events and an accuracy of 62.57{\%} on all identified events, with high precision values for 2 of the aspect labels."
2021.law-1.13,Automatic Entity State Annotation using the {V}erb{N}et Semantic Parser,2021,-1,-1,2,1,5452,ghazaleh kazeminejad,Proceedings of The Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop,0,"Tracking entity states is a natural language processing task assumed to require human annotation. In order to reduce the time and expenses associated with annotation, we introduce a new method to automatically extract entity states, including location and existence state of entities, following Dalvi et al. (2018) and Tandon et al. (2020). For this purpose, we rely primarily on the semantic representations generated by the state of the art VerbNet parser (Gung, 2020), and extract the entities (event participants) and their states, based on the semantic predicates of the generated VerbNet semantic representation, which is in propositional logic format. For evaluation, we used ProPara (Dalvi et al., 2018), a reading comprehension dataset which is annotated with entity states in each sentence, and tracks those states in paragraphs of natural human-authored procedural texts. Given the presented limitations of the method, the peculiarities of the ProPara dataset annotations, and that our system, Lexis, makes no use of task-specific training data and relies solely on VerbNet, the results are promising, showcasing the value of lexical resources."
2021.findings-acl.418,What Would a Teacher Do? {P}redicting Future Talk Moves,2021,-1,-1,2,0,8467,ananya ganesh,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.dash-1.14,{T}op{G}u{NN}: Fast {NLP} Training Data Augmentation using Large Corpora,2021,-1,-1,6,0,11297,rebecca iglesiasflores,Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances,0,"Acquiring training data for natural language processing systems can be expensive and time-consuming. Given a few training examples crafted by experts, large corpora can be mined for thousands of semantically similar examples that provide useful variability to improve model generalization. We present TopGuNN, a fast contextualized k-NN retrieval system that can efficiently index and search over contextual embeddings generated from large corpora. TopGuNN is demonstrated for a training data augmentation use case over the Gigaword corpus. Using approximate k-NN and an efficient architecture, TopGuNN performs queries over an embedding space of 4.63TB (approximately 1.5B embeddings) in less than a day."
2021.acl-long.489,Fine-grained Information Extraction from Biomedical Literature based on Knowledge-enriched {A}bstract {M}eaning {R}epresentation,2021,-1,-1,6,0,3225,zixuan zhang,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Biomedical Information Extraction from scientific literature presents two unique and non-trivial challenges. First, compared with general natural language texts, sentences from scientific papers usually possess wider contexts between knowledge elements. Moreover, comprehending the fine-grained scientific entities and events urgently requires domain-specific background knowledge. In this paper, we propose a novel biomedical Information Extraction (IE) model to tackle these two challenges and extract scientific entities and events from English research papers. We perform Abstract Meaning Representation (AMR) to compress the wide context to uncover a clear semantic structure for each complex sentence. Besides, we construct the sentence-level knowledge graph from an external knowledge base and use it to enrich the AMR graph to improve the model{'}s understanding of complex scientific concepts. We use an edge-conditioned graph attention network to encode the knowledge-enriched AMR graph for biomedical IE tasks. Experiments on the GENIA 2011 dataset show that the AMR and external knowledge have contributed 1.8{\%} and 3.0{\%} absolute F-score gains respectively. In order to evaluate the impact of our approach on real-world problems that involve topic-specific fine-grained knowledge elements, we have also created a new ontology and annotated corpus for entity and event extraction for the COVID-19 scientific literature, which can serve as a new benchmark for the biomedical IE community."
2021.acl-demo.19,A Graphical Interface for Curating Schemas,2021,-1,-1,4,0,4911,piyush mishra,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations,0,"Much past work has focused on extracting information like events, entities, and relations from documents. Very little work has focused on analyzing these results for better model understanding. In this paper, we introduce a curation interface that takes an Information Extraction (IE) system{'}s output in a pre-defined format and generates a graphical representation of its elements. The interface supports editing while curating schemas for complex events like Improvised Explosive Device (IED) based scenarios. We identify various schemas that either have linear event chains or contain parallel events with complicated temporal ordering. We iteratively update an induced schema to uniquely identify events specific to it, add optional events around them, and prune unnecessary events. The resulting schemas are improved and enriched versions of the machine-induced versions."
2020.lrec-1.601,Spatial {AMR}: Expanded Spatial Annotation in the Context of a Grounded {M}inecraft Corpus,2020,-1,-1,2,1,17862,julia bonn,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents an expansion to the Abstract Meaning Representation (AMR) annotation schema that captures fine-grained semantically and pragmatically derived spatial information in grounded corpora. We describe a new lexical category conceptualization and set of spatial annotation tools built in the context of a multimodal corpus consisting of 170 3D structure-building dialogues between a human architect and human builder in Minecraft. Minecraft provides a particularly beneficial spatial relation-elicitation environment because it automatically tracks locations and orientations of objects and avatars in the space according to an absolute Cartesian coordinate system. Through a two-step process of sentence-level and document-level annotation designed to capture implicit information, we leverage these coordinates and bearings in the AMRs in combination with spatial framework annotation to ground the spatial language in the dialogues to absolute space."
2020.lrec-1.717,From Spatial Relations to Spatial Configurations,2020,-1,-1,6,0,3462,soham dan,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Spatial Reasoning from language is essential for natural language understanding. Supporting it requires a representation scheme that can capture spatial phenomena encountered in language as well as in images and videos.Existing spatial representations are not sufficient for describing spatial configurations used in complex tasks. This paper extends the capabilities of existing spatial representation languages and increases coverage of the semantic aspects that are needed to ground spatial meaning of natural language text in the world. Our spatial relation language is able to represent a large, comprehensive set of spatial concepts crucial for reasoning and is designed to support composition of static and dynamic spatial configurations. We integrate this language with the Abstract Meaning Representation (AMR) annotation schema and present a corpus annotated by this extended AMR. To exhibit the applicability of our representation scheme, we annotate text taken from diverse datasets and show how we extend the capabilities of existing spatial representation languages with fine-grained decomposition of semantics and blend it seamlessly with AMRs of sentences and discourse representations as a whole."
2020.lrec-1.734,The {R}ussian {P}rop{B}ank,2020,-1,-1,3,0.714286,11445,sarah moeller,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents a proposition bank for Russian (RuPB), a resource for semantic role labeling (SRL). The motivating goal for this resource is to automatically project semantic role labels from English to Russian. This paper describes frame creation strategies, coverage, and the process of sense disambiguation. It discusses language-specific issues that complicated the process of building the PropBank and how these challenges were exploited as language-internal guidance for consistency and coherence."
2020.louhi-1.12,Defining and Learning Refined Temporal Relations in the Clinical Narrative,2020,-1,-1,6,1,17864,kristin wrightbettner,Proceedings of the 11th International Workshop on Health Text Mining and Information Analysis,0,"We present refinements over existing temporal relation annotations in the Electronic Medical Record clinical narrative. We refined the THYME corpus annotations to more faithfully represent nuanced temporality and nuanced temporal-coreferential relations. The main contributions are in re-defining CONTAINS and OVERLAP relations into CONTAINS, CONTAINS-SUBEVENT, OVERLAP and NOTED-ON. We demonstrate that these refinements lead to substantial gains in learnability for state-of-the-art transformer models as compared to previously reported results on the original THYME corpus. We thus establish a baseline for the automatic extraction of these refined temporal relations. Although our study is done on clinical narrative, we believe it addresses far-reaching challenges that are corpus- and domain- agnostic."
2020.cllrd-1.5,Leveraging Non-Specialists for Accurate and Time Efficient {AMR} Annotation,2020,-1,-1,3,0,21866,mary martin,Proceedings of the LREC 2020 Workshop on ``Citizen Linguistics in Language Resource Development'',0,"Abstract Meaning Representations (AMRs), a syntax-free representation of phrase semantics are useful for capturing the meaning of a phrase and reflecting the relationship between concepts that are referred to. However, annotating AMRs are time consuming and expensive. The existing annotation process requires expertly trained workers who have knowledge of an extensive set of guidelines for parsing phrases. In this paper, we propose a cost-saving two-step process for the creation of a corpus of AMR-phrase pairs for spatial referring expressions. The first step uses non-specialists to perform simple annotations that can be leveraged in the second step to accelerate the annotation performed by the experts. We hypothesize that our process will decrease the cost per annotation and improve consistency across annotators. Few corpora of spatial referring expressions exist and the resulting language resource will be valuable for referring expression comprehension and generation modeling."
2020.acl-main.744,Structured Tuning for Semantic Role Labeling,2020,38,0,3,0,5453,tao li,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of structure to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve models using softened constraints only at training time. Our framework leverages the expressiveness of neural networks and provides supervision with structured loss components. We start with a strong baseline (RoBERTa) to validate the impact of our approach, and show that our framework outperforms the baseline by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios."
W19-5014,Enhancing biomedical word embeddings by retrofitting to verb clusters,2019,0,0,3,0,22857,billy chiu,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"Verbs play a fundamental role in many biomed-ical tasks and applications such as relation and event extraction. We hypothesize that performance on many downstream tasks can be improved by aligning the input pretrained embeddings according to semantic verb classes.In this work, we show that by using semantic clusters for verbs, a large lexicon of verbclasses derived from biomedical literature, weare able to improve the performance of common pretrained embeddings in downstream tasks by retrofitting them to verb classes. We present a simple and computationally efficient approach using a widely-available {``}off-the-shelf{''} retrofitting algorithm to align pretrained embeddings according to semantic verb clusters. We achieve state-of-the-art results on text classification and relation extraction tasks."
W19-4016,Explaining Simple Natural Language Inference,2019,0,1,4,0,11533,aikaterinilida kalouli,Proceedings of the 13th Linguistic Annotation Workshop,0,"The vast amount of research introducing new corpora and techniques for semi-automatically annotating corpora shows the important role that datasets play in today{'}s research, especially in the machine learning community. This rapid development raises concerns about the quality of the datasets created and consequently of the models trained, as recently discussed with respect to the Natural Language Inference (NLI) task. In this work we conduct an annotation experiment based on a small subset of the SICK corpus. The experiment reveals several problems in the annotation guidelines, and various challenges of the NLI task itself. Our quantitative evaluation of the experiment allows us to assign our empirical observations to specific linguistic phenomena and leads us to recommendations for future annotation tasks, for NLI and possibly for other tasks."
W19-3315,"{C}lear{TAC}: Verb Tense, Aspect, and Form Classification Using Neural Nets",2019,0,0,2,0,13408,skatje myers,Proceedings of the First International Workshop on Designing Meaning Representations,0,"This paper proposes using a Bidirectional LSTM-CRF model in order to identify the tense and aspect of verbs. The information that this classifier outputs can be useful for ordering events and can provide a pre-processing step to improve efficiency of annotating this type of information. This neural network architecture has been successfully employed for other sequential labeling tasks, and we show that it significantly outperforms the rule-based tool TMV-annotator on the Propbank I dataset."
W19-3318,{V}erb{N}et Representations: Subevent Semantics for Transfer Verbs,2019,0,1,6,1,4915,susan brown,Proceedings of the First International Workshop on Designing Meaning Representations,0,"This paper announces the release of a new version of the English lexical resource VerbNet with substantially revised semantic representations designed to facilitate computer planning and reasoning based on human language. We use the transfer of possession and transfer of information event representations to illustrate both the general framework of the representations and the types of nuances the new representations can capture. These representations use a Generative Lexicon-inspired subevent structure to track attributes of event participants across time, highlighting oppositions and temporal and causal relations among the subevents."
K19-1034,Linguistic Analysis Improves Neural Metaphor Detection,2019,0,0,4,1,11362,kevin stowe,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"In the field of metaphor detection, deep learning systems are the ubiquitous and achieve strong performance on many tasks. However, due to the complicated procedures for manually identifying metaphors, the datasets available are relatively small and fraught with complications. We show that using syntactic features and lexical resources can automatically provide additional high-quality training data for metaphoric language, and this data can cover gaps and inconsistencies in metaphor annotation, improving state-of-the-art word-level metaphor identification. This novel application of automatically improving training data improves classification across numerous tasks, and reconfirms the necessity of high-quality data for deep learning frameworks."
D19-6201,Cross-document coreference: An approach to capturing coreference without context,2019,0,0,2,1,17864,kristin wrightbettner,Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019),0,"This paper discusses a cross-document coreference annotation schema that was developed to further automatic extraction of timelines in the clinical domain. Lexical senses and coreference choices are determined largely by context, but cross-document work requires reasoning across contexts that are not necessarily coherent. We found that an annotation approach that relies less on context-guided annotator intuitions and more on schematic rules was most effective in creating meaningful and consistent cross-document relations."
2019.lilt-17.1,Syntactic composition and selectional preferences in {H}indi Light Verb Constructions,2019,0,0,2,1,640,ashwini vaidya,"Linguistic Issues in Language Technology, Volume 17, 2019",0,"Previous work on light verb constructions (e.g. chorii kar {`}theft do; steal{'}) in Hindi describes their syntactic formation via co-predication (Ahmed et al., 2012, Butt, 2014). This implies that both noun and light verb contribute their arguments, and these overlapping argument structures must be composed in the syntax. In this paper, we present a co-predication analysis using Tree-Adjoining Grammar, which models syntactic composition and semantic selectional preferences without transformations (deletion or argument identification). The analysis has two key components (i) an underspecified category for the nominal and (ii) combinatorial constraints on the noun and light verb to specify selectional preferences. The former has the advantage of syntactic composition without argument identification and the latter prevents over-generalization, while recognizing the semantic contribution of both predicates. This work additionally accounts for the agreement facts for the Hindi LVC."
W18-4915,Developing and Evaluating Annotation Procedures for {T}witter Data during Hazard Events,2018,0,3,2,1,11362,kevin stowe,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"When a hazard such as a hurricane threatens, people are forced to make a wide variety of decisions, and the information they receive and produce can influence their own and others{'} actions. As social media grows more popular, an increasing number of people are using social media platforms to obtain and share information about approaching threats and discuss their interpretations of the threat and their protective decisions. This work aims to improve understanding of natural disasters through social media and provide an annotation scheme to identify themes in user{'}s social media behavior and facilitate efforts in supervised machine learning. To that end, this work has three contributions: (1) the creation of an annotation scheme to consistently identify hazard-related themes in Twitter, (2) an overview of agreement rates and difficulties in identifying annotation categories, and (3) a public release of both the dataset and guidelines developed from this scheme."
W18-3512,Improving Classification of {T}witter Behavior During Hurricane Events,2018,0,4,3,1,11362,kevin stowe,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,0,"A large amount of social media data is generated during natural disasters, and identifying the relevant portions of this data is critical for researchers attempting to understand human behavior, the effects of information sources, and preparatory actions undertaken during these events. In order to classify human behavior during hazard events, we employ machine learning for two tasks: identifying hurricane related tweets and classifying user evacuation behavior during hurricanes. We show that feature-based and deep learning methods provide different benefits for tweet classification, and ensemble-based methods using linguistic, temporal, and geospatial features can effectively classify user behavior."
W18-0903,Leveraging Syntactic Constructions for Metaphor Identification,2018,0,0,2,1,11362,kevin stowe,Proceedings of the Workshop on Figurative Language Processing,0,"Identification of metaphoric language in text is critical for generating effective semantic representations for natural language understanding. Computational approaches to metaphor identification have largely relied on heuristic based models or feature-based machine learning, using hand-crafted lexical resources coupled with basic syntactic information. However, recent work has shown the predictive power of syntactic constructions in determining metaphoric source and target domains (Sullivan 2013). Our work intends to explore syntactic constructions and their relation to metaphoric language. We undertake a corpus-based analysis of predicate-argument constructions and their metaphoric properties, and attempt to effectively represent syntactic constructions as features for metaphor processing, both in identifying source and target domains and in distinguishing metaphoric words from non-metaphoric."
S18-1011,{S}em{E}val 2018 Task 6: Parsing Time Normalizations,2018,0,1,5,0,1744,egoitz laparra,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper presents the outcomes of the Parsing Time Normalization shared task held within SemEval-2018. The aim of the task is to parse time expressions into the compositional semantic graphs of the Semantically Compositional Annotation of Time Expressions (SCATE) schema, which allows the representation of a wider variety of time expressions than previous approaches. Two tracks were included, one to evaluate the parsing of individual components of the produced graphs, in a classic information extraction way, and another one to evaluate the quality of the time intervals resulting from the interpretation of those graphs. Though 40 participants registered for the task, only one team submitted output, achieving 0.55 F1 in Track 1 (parsing) and 0.70 F1 in Track 2 (intervals)."
L18-1009,Integrating {G}enerative {L}exicon Event Structures into {V}erb{N}et,2018,0,0,4,1,4915,susan brown,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1231,The New {P}ropbank: Aligning {P}ropbank with {AMR} through {POS} Unification,2018,0,0,3,1,5428,tim ogorman,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1266,"{A}bstract {M}eaning {R}epresentation of Constructions: The More We Include, the Better the Representation",2018,0,1,7,1,5184,claire bonial,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1224,Automatically Extracting Qualia Relations for the Rich Event Ontology,2018,0,1,4,1,5452,ghazaleh kazeminejad,Proceedings of the 27th International Conference on Computational Linguistics,0,"Commonsense, real-world knowledge about the events that entities or {``}things in the world{''} are typically involved in, as well as part-whole relationships, is valuable for allowing computational systems to draw everyday inferences about the world. Here, we focus on automatically extracting information about (1) the events that typically bring about certain entities (origins), (2) the events that are the typical functions of entities, and (3) part-whole relationships in entities. These correspond to the agentive, telic and constitutive qualia central to the Generative Lexicon. We describe our motivations and methods for extracting these qualia relations from the Suggested Upper Merged Ontology (SUMO) and show that human annotators overwhelmingly find the information extracted to be reasonable. Because ontologies provide a way of structuring this information and making it accessible to agents and computational systems generally, efforts are underway to incorporate the extracted information to an ontology hub of Natural Language Processing semantic role labeling resources, the Rich Event Ontology."
C18-1313,{AMR} Beyond the Sentence: the Multi-sentence {AMR} corpus,2018,0,2,6,1,5428,tim ogorman,Proceedings of the 27th International Conference on Computational Linguistics,0,"There are few corpora that endeavor to represent the semantic content of entire documents. We present a corpus that accomplishes one way of capturing document level semantics, by annotating coreference and similar phenomena (bridging and implicit roles) on top of gold Abstract Meaning Representations of sentence-level semantics. We present a new corpus of this annotation, with analysis of its quality, alongside a plausible baseline for comparison. It is hoped that this Multi-Sentence AMR corpus (MS-AMR) may become a feasible method for developing rich representations of document meaning, useful for tasks such as information extraction and question answering."
W17-2812,Towards Problem Solving Agents that Communicate and Learn,2017,11,1,9,0,2982,anjali narayanchen,Proceedings of the First Workshop on Language Grounding for Robotics,0,Agents that communicate back and forth with humans to help them execute non-linguistic tasks are a long sought goal of AI. These agents need to translate between utterances and actionable meaning representations that can be interpreted by task-specific problem solvers in a context-dependent manner. They should also be able to learn such actionable interpretations for new predicates on the fly. We define an agent architecture for this scenario and present a series of experiments in the Blocks World domain that illustrate how our architecture supports language learning and problem solving in this domain.
W17-2712,The Rich Event Ontology,2017,0,2,4,1,4915,susan brown,Proceedings of the Events and Stories in the News Workshop,0,"In this paper we describe a new lexical semantic resource, The Rich Event On-tology, which provides an independent conceptual backbone to unify existing semantic role labeling (SRL) schemas and augment them with event-to-event causal and temporal relations. By unifying the FrameNet, VerbNet, Automatic Content Extraction, and Rich Entities, Relations and Events resources, the ontology serves as a shared hub for the disparate annotation schemas and therefore enables the combination of SRL training data into a larger, more diverse corpus. By adding temporal and causal relational information not found in any of the independent resources, the ontology facilitates reasoning on and across documents, revealing relationships between events that come together in temporal and causal chains to build more complex scenarios. We envision the open resource serving as a valuable tool for both moving from the ontology to text to query for event types and scenarios of interest, and for moving from text to the ontology to access interpretations of events using the combined semantic information housed there."
S17-2093,{S}em{E}val-2017 Task 12: Clinical {T}emp{E}val,2017,6,23,3,0,224,steven bethard,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"Clinical TempEval 2017 aimed to answer the question: how well do systems trained on annotated timelines for one medical condition (colon cancer) perform in predicting timelines on another medical condition (brain cancer)? Nine sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification. Participant systems were evaluated on clinical and pathology notes from Mayo Clinic cancer patients, annotated with an extension of TimeML for the clinical domain. 11 teams participated in the tasks, with the best systems achieving F1 scores above 0.55 for time expressions, above 0.70 for event expressions, and above 0.40 for temporal relations. Most tasks observed about a 20 point drop over Clinical TempEval 2016, where systems were trained and evaluated on the same domain (colon cancer)."
E17-1053,Unsupervised {AMR}-Dependency Parse Alignment,2017,22,3,2,0,33035,weite chen,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"In this paper, we introduce an Abstract Meaning Representation (AMR) to Dependency Parse aligner. Alignment is a preliminary step for AMR parsing, and our aligner improves current AMR parser performance. Our aligner involves several different features, including named entity tags and semantic role labels, and uses Expectation-Maximization training. Results show that our aligner reaches an 87.1{\%} F-Score score with the experimental data, and enhances AMR parsing."
W16-6201,Identifying and Categorizing Disaster-Related Tweets,2016,13,26,3,1,11362,kevin stowe,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,None
W16-5706,"Richer Event Description: Integrating event coreference with temporal, causal and bridging annotation",2016,0,17,3,1,5428,tim ogorman,Proceedings of the 2nd Workshop on Computing News Storylines ({CNS} 2016),0,None
W16-1701,Building a Cross-document Event-Event Relation Corpus,2016,26,4,6,0,6661,yu hong,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,None
W16-1712,A Corpus of Preposition Supersenses,2016,47,11,8,0.283875,794,nathan schneider,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,"We present the first corpus annotated with preposition supersenses, unlexicalized categories for semantic functions that can be marked by English prepositions (Schneider et al., 2015). The preposition supersenses are organized hierarchically and designed to facilitate comprehensive manual annotation. Our dataset is publicly released on the web. 1"
W16-1003,Multimodal Use of an Upper-Level Event Ontology,2016,33,1,4,1,5184,claire bonial,Proceedings of the Fourth Workshop on Events,0,"We describe the ongoing development of a lexically-informed, upper-level event ontology and explore use cases of the ontology. This ontology draws its lexical sense distinctions from VerbNet, FrameNet and the Rich Entities, Relations and Events Project. As a result, the ontology facilitates interoperability and the combination of annotations done for each independent resource. While this ontology is intended to be practical for a variety of applications, here we take the initial steps in determining whether or not the event ontology could be utilized in multimodal applications, specifically to recognize and reason about events in both text and video. We find that the ontology facilitates the generalization of potentially noisy or sparse individual realizations of events into larger categories of events and enables reasoning about event relations and participants, both of which are useful in event recognition and interpretation regardless of modality."
W16-1004,A Comparison of Event Representations in {DEFT},2016,0,3,7,0,17656,ann bies,Proceedings of the Fourth Workshop on Events,0,None
S16-2012,Leveraging {V}erb{N}et to build Corpus-Specific Verb Clusters,2016,13,0,3,1,34180,daniel peterson,Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics,0,"In this paper, we aim to close the gap from extensive, human-built semantic resources and corpus-driven unsupervised models. The particular resource explored here is VerbNet, whose organizing principle is that semantics and syntax are linked. To capture patterns of usage that can augment knowledge resources like VerbNet, we expand a Dirichlet process mixture model to predict a VerbNet class for each sense of each verb, allowing us to incorporate annotated VerbNet data to guide the clustering process. The resulting clusters align more closely to hand-curated syntactic/semantic groupings than any previous models, and can be adapted to new domains since they require only corpus counts."
L16-1145,"Large Multi-lingual, Multi-level and Multi-genre Annotation Corpus",2016,9,1,2,0,30118,xuansong li,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"High accuracy for automated translation and information retrieval calls for linguistic annotations at various language levels. The plethora of informal internet content sparked the demand for porting state-of-art natural language processing (NLP) applications to new social media as well as diverse language adaptation. Effort launched by the BOLT (Broad Operational Language Translation) program at DARPA (Defense Advanced Research Projects Agency) successfully addressed the internet information with enhanced NLP systems. BOLT aims for automated translation and linguistic analysis for informal genres of text and speech in online and in-person communication. As a part of this program, the Linguistic Data Consortium (LDC) developed valuable linguistic resources in support of the training and evaluation of such new technologies. This paper focuses on methodologies, infrastructure, and procedure for developing linguistic annotation at various language levels, including Treebank (TB), word alignment (WA), PropBank (PB), and co-reference (CoRef). Inspired by the OntoNotes approach with adaptations to the tasks to reflect the goals and scope of the BOLT project, this effort has introduced more annotation types of informal and free-style genres in English, Chinese and Egyptian Arabic. The corpus produced is by far the largest multi-lingual, multi-level and multi-genre annotation corpus of informal text and speech."
L16-1377,A {P}roposition {B}ank of {U}rdu,2016,16,0,5,0,35107,maaz anwar,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper describes our efforts for the development of a Proposition Bank for Urdu, an Indo-Aryan language. Our primary goal is the labeling of syntactic nodes in the existing Urdu dependency Treebank with specific argument labels. In essence, it involves annotation of predicate argument structures of both simple and complex predicates in the Treebank corpus. We describe the overall process of building the PropBank of Urdu. We discuss various statistics pertaining to the Urdu PropBank and the issues which the annotators encountered while developing the PropBank. We also discuss how these challenges were addressed to successfully expand the PropBank corpus. While reporting the Inter-annotator agreement between the two annotators, we show that the annotators share similar understanding of the annotation guidelines and of the linguistic phenomena present in the language. The present size of this Propbank is around 180,000 tokens which is double-propbanked by the two annotators for simple predicates. Another 100,000 tokens have been annotated for complex predicates of Urdu."
L16-1628,Comprehensive and Consistent {P}rop{B}ank Light Verb Annotation,2016,0,0,2,1,5184,claire bonial,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Recent efforts have focused on expanding the annotation coverage of PropBank from verb relations to adjective and noun relations, as well as light verb constructions (e.g., make an offer, take a bath). While each new relation type has presented unique annotation challenges, ensuring consistent and comprehensive annotation of light verb constructions has proved particularly challenging, given that light verb constructions are semi-productive, difficult to define, and there are often borderline cases. This research describes the iterative process of developing PropBank annotation guidelines for light verb constructions, the current guidelines, and a comparison to related resources."
C16-1125,Linguistic features for {H}indi light verb construction identification,2016,9,0,3,1,640,ashwini vaidya,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Light verb constructions (LVC) in Hindi are highly productive. If we can distinguish a case such as nirnay lenaa {`}decision take; decide{'} from an ordinary verb-argument combination kaagaz lenaa {`}paper take; take (a) paper{'},it has been shown to aid NLP applications such as parsing (Begum et al., 2011) and machine translation (Pal et al., 2011). In this paper, we propose an LVC identification system using language specific features for Hindi which shows an improvement over previous work(Begum et al., 2011). To build our system, we carry out a linguistic analysis of Hindi LVCs using Hindi Treebank annotations and propose two new features that are aimed at capturing the diversity of Hindi LVCs in the corpus. We find that our model performs robustly across a diverse range of LVCs and our results underscore the importance of semantic features, which is in keeping with the findings for English. Our error analysis also demonstrates that our classifier can be used to further refine LVC annotations in the Hindi Treebank and make them more consistent across the board."
W15-1612,"A Hierarchy with, of, and for Preposition Supersenses",2015,52,22,4,0.283875,794,nathan schneider,Proceedings of The 9th Linguistic Annotation Workshop,0,"English prepositions are extremely frequent and extraordinarily polysemous. In some usages they contribute information about spatial, temporal, or causal roles/relations; in other cases they are institutionalized, somewhat arbitrarily, as case markers licensed by a particular governing verb, verb class, or syntactic construction. To facilitate automatic disambiguation, we propose a general-purpose, broadcoverage taxonomy of preposition functions that we call supersenses: these are coarse and unlexicalized so as to be tractable for efficient manual annotation, yet capture crucial semantic distinctions. Our resource, including extensive documentation of the supersenses, many example sentences, and mappings to other lexical resources, will be publicly released. Prepositions are perhaps the most beguiling yet pervasive lexicosyntactic class in English. They are everywhere; their functional versatility is dizzying and largely idiosyncratic (1). They are nearly invisible, yet indispensable for situating the where, when, why, and how of events. In a way, prepositions are the bastard children of lexicon and grammar, rising to the occasion almost whenever a noun-noun or verbnoun relation is needed and neither subject nor object is appropriate. Consider the many uses of the word to, just a few of which are illustrated in (1):1 (1) a. My cake is to die for. b. If you want I can treat you to some. c. How about this: you go to the store d. to buy ingredients. e. Then if you give the recipe to me f. Ixe2x80x99m happy to make the batter g. and put it in the oven for 30 to 40 minutes h. so youxe2x80x99ll arrive to the sweet smell of chocolate. i. That sounds good to me. j. Thatxe2x80x99s all there is to it. 1Though infinitival to is traditionally not considered a preposition, we allow it to be labeled with a supersense if the infinitival clause serves as a PURPOSE (as in (1d)) or FUNCTION. See xc2xa72. Sometimes a preposition specifies a relationship between two entities or quantities, as in (1g). In other scenarios it serves a case-marking sort of function, marking a complement or adjunctxe2x80x94principally to a verb (1bxe2x80x931e, 1h, 1i), but also to an argument-taking noun or adjective (1f). Further, it is not always possible to separate the semantic contribution of the preposition from that of other words in the sentence. As amply demonstrated in the literature, prepositions play a key role in multiword expressions (Baldwin and Kim, 2010), as in (1a, 1b, 1j). An adequate descriptive annotation scheme for prepositions must deal with these messy facts. Following a brief discussion of existing approaches to preposition semantics (xc2xa71), this paper offers a new approach to characterizing their functions at a coarsegrained level. Our scheme is intended to apply to almost all preposition tokens, though some are excluded on the grounds that they belong to a larger multiword expression or are purely syntactic (xc2xa72). The rest of the paper is devoted to our coarse semantic categories, supersenses (xc2xa73).2 Many of these categories are based on previous proposalsxe2x80x94primarily, Srikumar and Roth (2013a) (so-called preposition relations) and VerbNet (thematic roles; Bonial et al., 2011; Hwang, 2014, appendix C)xe2x80x94but we organize them into a hierarchy and motivate a number of new or altered categories that make the scheme more robust. Because prepositions are so frequent, so polysemous, and so crucial in establishing relations, we believe that a wide variety of NLP applications (including knowledge base construction, reasoning about events, summarization, paraphrasing, and translation) stand to benefit from automatic disambiguation of preposition supersenses. 2Supersense inventories have also been described for nouns and verbs (Ciaramita and Altun, 2006; Schneider et al., 2012; Schneider and Smith, 2015) and adjectives (Tsvetkov et al., 2014). Other inventories characterize semantic functions expressed via morphosyntax: e.g., tense/aspect (Reichart and Rappoport, 2010), definiteness (Bhatia et al., 2014, also hierarchical). A wiki documenting our scheme in detail can be accessed at http://tiny.cc/prepwiki. It maps finegrained preposition senses to our supersenses, along with numerous examples. The wiki is conducive to browsing and to exporting the structure and examples for use elsewhere (e.g., in an annotation tool). From our experience with pilot annotations, we believe that the scheme is fairly stable and broadly applicable."
W15-1012,Improving {C}hinese-{E}nglish {P}rop{B}ank Alignment,2015,22,1,2,1,37082,shumin wu,"Proceedings of the Ninth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"We describe 2 improvements to ChineseEnglish PropBank predicate-argument structure alignment. Taking advantage of the recently expanded PropBank English nominal and adjective predicate annotation (Bonial et al., 2014), we performed predicateargument alignments between both verb and nominal/adjective predicates in Chinese and English. Using our alignment system, this increased the number of aligned predicateargument structures by 24.5% on the parallel Xinhua News corpus. We also improved the PropBank alignment system using expectation-maximization (EM) techniques. By collecting Chinese-English predicate-topredicate and argument type-to-argument type alignment probabilities and iteratively improving the alignment output using these probabilities on a large unannotated parallel corpora, we improved the predicate alignment performance by 1 F point when using all automatic SRL and word alignment inputs."
S15-1006,Identification of Caused Motion Construction,2015,12,2,2,1,7749,jena hwang,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"This research describes the development of a supervised classifier of English Caused Motion Constructions (CMCs) (e.g. The goalie kicked the ball into the field). Consistent identification of CMCs is a necessary step to a correct interpretation of semantics for sentences where the verb does not conform to the expected semantics of the verb (e.g. The crowd laughed the clown off the stage). We expand on a previous study on the classification CMCs (Hwang et al., 2010) to show that CMCs can be successfully identified in the corpus data. In this paper, we present the classifier and the series of experiments carried out to improve its performance."
S15-1027,Can Selectional Preferences Help Automatic Semantic Role Labeling?,2015,20,3,2,1,37082,shumin wu,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"We describe a topic model based approach for selectional preference. Using the topic features generated by an LDA model on the extracted predicate-arguments over the Chinese Gigaword corpus, we show improvement to our state-of-the-art Chinese SRL system by 2.34 F1 points on arguments of nominal predicates, 0.40 F1 point on arguments of verb predicates, and 0.66 F1 point overall. More over, similar gains were achieved on out-ofgenre test data, as well as on English SRL using the same technique."
W14-5816,Light verb constructions with {`}do{'} and {`}be{'} in {H}indi: A {TAG} analysis,2014,16,2,3,1,640,ashwini vaidya,Proceedings of Workshop on Lexical and Grammatical Resources for Language Processing,0,"In this paper we present a Lexicalized Feature-based Tree-Adjoining Grammar analysis for a type of nominal predicate that occurs in combination with the light verbs xe2x80x9cdoxe2x80x9d and xe2x80x9cbexe2x80x9d (Hindi kar and ho respectively). Light verb constructions are a challenge for computational grammars because they are a highly productive predicational strategy in Hindi. Such nominals have been discussed in the literature (Mohanan, 1997; Ahmed and Butt, 2011; Bhatt et al., 2013), but this work is a first attempt at a Tree-Adjoining Grammar (TAG) representation. We look at three possibilities for the design of elementary trees in TAG and explore one option in depth using Hindi data. In this analysis, the nominal is represented with all the arguments of the light verb construction, while the light verb adjoins into its elementary tree."
W14-4206,Adapting Predicate Frames for {U}rdu {P}rop{B}anking,2014,20,1,4,0.576923,29432,riyaz bhat,Proceedings of the {EMNLP}{'}2014 Workshop on Language Technology for Closely Related Languages and Language Variants,0,"Hindi and Urdu are two standardized registers of what has been called the Hindustani language, which belongs to the IndoAryan language family. Although, both the varieties share a common grammar, they differ significantly in their vocabulary to an extent where both become mutually incomprehensible (Masica, 1993). Hindi draws its vocabulary from Sanskrit while Urdu draws its vocabulary from Persian, Arabic and even Turkish. In this paper, we present our efforts to adopt frames of nominal and verbal predicates that Urdu shares with either Hindi or Arabic for Urdu PropBanking. We discuss the feasibility of porting such frames from either of the sources (Arabic or Hindi) and also present a simple and reasonably accurate method to automatically identify the origin of Urdu words which is a necessary step in the process of porting such frames."
W14-3004,"{S}em{L}ink+: {F}rame{N}et, {V}erb{N}et and Event Ontologies",2014,14,0,1,1,4859,martha palmer,Proceedings of Frame Semantics in {NLP}: A Workshop in Honor of Chuck {F}illmore (1929-2014),0,"This paper reviews the significant contributions FrameNet has made to our understanding of lexical resources, semantic roles and event relations."
W14-2903,Challenges of Adding Causation to Richer Event Descriptions,2014,17,13,5,0,38612,rei ikuta,"Proceedings of the Second Workshop on {EVENTS}: Definition, Detection, Coreference, and Representation",0,"The goal of this study is to create guidelines for annotating cause-effect relations as part of the Richer Event Description schema. We present the challenges faced using the definition of causation in terms of counterfactual dependence and propose new guidelines for cause-effect annotation using an alternative definition which treats causation as an intrinsic relation between events. To support the use of such an intrinsic definition, we examine the theoretical problems that the counterfactual definition faces, show how the intrinsic definition solves those problems, and explain how the intrinsic definition adheres to psychological reality, at least for our annotation purposes, better than the counterfactual definition. We then evaluate the new guidelines by presenting results obtained from pilot annotations of ten documents, showing that an inter-annotator agreement (F1-score) of 0.5753 was achieved. The results provide a benchmark for future studies concerning cause-effect annotation in the RED schema."
W14-0816,An Approach to Take Multi-Word Expressions,2014,7,2,4,1,5184,claire bonial,Proceedings of the 10th Workshop on Multiword Expressions ({MWE}),0,"This research discusses preliminary efforts to expand the coverage of the PropBank lexicon to multi-word and idiomatic expressions, such as take one for the team. Given overwhelming numbers of such expressions, an efficient way for increasing coverage is needed. This research discusses an approach to adding multiword expressions to the PropBank lexicon in an effective yet semantically rich fashion. The pilot discussed here uses double annotation of take multi-word expressions, where annotations provide information on the best strategy for adding the multi-word expression to the lexicon. This work represents an important step for enriching the semantic information included in the PropBank corpus, which is a valuable and comprehensive resource for the field of Natural Language Processing."
Q14-1012,Temporal Annotation in the Clinical Domain,2014,32,79,4,0,39080,william iv,Transactions of the Association for Computational Linguistics,0,"This article discusses the requirements of a formal specification for the annotation of temporal information in clinical narratives. We discuss the implementation and extension of ISO-TimeML for annotating a corpus of clinical notes, known as the THYME corpus. To reflect the information task and the heavily inference-based reasoning demands in the domain, a new annotation guideline has been developed, {``}the THYME Guidelines to ISO-TimeML (THYME-TimeML){''}. To clarify what relations merit annotation, we distinguish between linguistically-derived and inferentially-derived temporal orderings in the text. We also apply a top performing TempEval 2013 system against this new resource to measure the difficulty of adapting systems to the clinical domain. The corpus is available to the community and has been proposed for use in a SemEval 2015 task."
P14-2065,The {V}erb{C}orner Project: Findings from Phase 1 of crowd-sourcing a semantic decomposition of verbs,2014,19,7,3,1,33119,joshua hartshorne,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Any given verb can appear in some syntactic frames (Sally broke the vase, The vase broke) but not others (*Sally broke at the vase, *Sally broke the vase to John). There is now considerable evidence that the syntactic behaviors of some verbs can be predicted by their meanings, and many current theories posit that this is true for most if not all verbs. If true, this fact would have striking implications for theories and models of language acquisition, as well as numerous applications in natural language processing. However, empirical investigations to date have focused on a small number of verbs. We report on early results from VerbCorner, a crowd-sourced project extending this work to a large, representative sample of English verbs."
P14-1097,A Step-wise Usage-based Method for Inducing Polysemy-aware Verb Classes,2014,43,7,3,0,3202,daisuke kawahara,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present an unsupervised method for inducing verb classes from verb uses in gigaword corpora. Our method consists of two clustering steps: verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames. By taking this step-wise approach, we can not only generate verb classes based on a massive amount of verb uses in a scalable manner, but also deal with verb polysemy, which is bypassed by most of the previous studies on verb clustering. In our experiments, we acquire semantic frames and verb classes from two giga-word corpora, the larger comprising 20 billion words. The effectiveness of our approach is verified through quantitative evaluations based on polysemy-aware gold-standard data."
bonial-etal-2014-propbank,{P}rop{B}ank: Semantics of New Predicate Types,2014,14,21,5,1,5184,claire bonial,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This research focuses on expanding PropBank, a corpus annotated with predicate argument structures, with new predicate types; namely, noun, adjective and complex predicates, such as Light Verb Constructions. This effort is in part inspired by a sister project to PropBank, the Abstract Meaning Representation project, which also attempts to capture Âwho is doing what to whomÂ in a sentence, but does so in a way that abstracts away from syntactic structures. For example, alternate realizations of a {`}destroying{'} event in the form of either the verb {`}destroy{'} or the noun {`}destruction{'} would receive the same Abstract Meaning Representation. In order for PropBank to reach the same level of coverage and continue to serve as the bedrock for Abstract Meaning Representation, predicate types other than verbs, which have previously gone without annotation, must be annotated. This research describes the challenges therein, including the development of new annotation practices that walk the line between abstracting away from language-particular syntactic facts to explore deeper semantics, and maintaining the connection between semantics and syntactic structures that has proven to be very valuable for PropBank as a corpus of training data for Natural Language Processing applications."
xue-etal-2014-interlingua,"Not an Interlingua, But Close: Comparison of {E}nglish {AMR}s to {C}hinese and {C}zech",2014,18,10,4,0,10294,nianwen xue,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Abstract Meaning Representations (AMRs) are rooted, directional and labeled graphs that abstract away from morpho-syntactic idiosyncrasies such as word category (verbs and nouns), word order, and function words (determiners, some prepositions). Because these syntactic idiosyncrasies account for many of the cross-lingual differences, it would be interesting to see if this representation can serve, e.g., as a useful, minimally divergent transfer layer in machine translation. To answer this question, we have translated 100 English sentences that have existing AMRs into Chinese and Czech to create AMRs for them. A cross-linguistic comparison of English to Chinese and Czech AMRs reveals both cases where the AMRs for the language pairs align well structurally and cases of linguistic divergence. We found that the level of compatibility of AMR between English and Chinese is higher than between English and Czech. We believe this kind of comparison is beneficial to further refining the annotation standards for each of the three languages and will lead to more compatible annotation guidelines between the languages."
hwang-etal-2014-criteria,Criteria for Identifying and Annotating Caused Motion Constructions in Corpus Data,2014,12,5,3,1,7749,jena hwang,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"While natural language processing performance has been improved through the recognition that there is a relationship between the semantics of the verb and the syntactic context in which the verb is realized, sentences where the verb does not conform to the expected syntax-semantic patterning behavior remain problematic. For example, in the sentence ÂThe crowed laughed the clown off the stageÂ, a verb of non-verbal communication laugh is used in a caused motion construction and gains a motion entailment that is atypical given its inherent lexical semantics. This paper focuses on our efforts at defining the semantic types and varieties of caused motion constructions (CMCs) through an iterative annotation process and establishing annotation guidelines based on these criteria to aid in the production of a consistent and reliable annotation. The annotation will serve as training and test data for classifiers for CMCs, and the CMC definitions developed throughout this study will be used in extending VerbNet to handle representations of sentences in which a verb is used in a syntactic context that is atypical for its lexical semantics."
popescu-etal-2014-mapping,Mapping {CPA} Patterns onto {O}nto{N}otes Senses,2014,31,4,2,0,21558,octavian popescu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper we present an alignment experiment between patterns of verb use discovered by Corpus Pattern Analysis (CPA; Hanks 2004, 2008, 2012) and verb senses in OntoNotes (ON; Hovy et al. 2006, Weischedel et al. 2011). We present a probabilistic approach for mapping one resource into the other. Firstly we introduce a basic model, based on conditional probabilities, which determines for any given sentence the best CPA pattern match. On the basis of this model, we propose a joint source channel model (JSCM) that computes the probability of compatibility of semantic types between a verb phrase and a pattern, irrespective of whether the verb phrase is a norm or an exploitation. We evaluate the accuracy of the proposed mapping using cluster similarity metrics based on entropy."
kawahara-palmer-2014-single,Single Classifier Approach for Verb Sense Disambiguation based on Generalized Features,2014,19,3,2,0,3202,daisuke kawahara,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present a supervised method for verb sense disambiguation based on VerbNet. Most previous supervised approaches to verb sense disambiguation create a classifier for each verb that reaches a frequency threshold. These methods, however, have a significant practical problem that they cannot be applied to rare or unseen verbs. In order to overcome this problem, we create a single classifier to be applied to rare or unseen verbs in a new text. This single classifier also exploits generalized semantic features of a verb and its modifiers in order to better deal with rare or unseen verbs. Our experimental results show that the proposed method achieves equivalent performance to per-verb classifiers, which cannot be applied to unseen verbs. Our classifier could be utilized to improve the classifications in lexical resources of verbs, such as VerbNet, in a semi-automatic manner and to possibly extend the coverage of these resources to new verbs."
peterson-etal-2014-focusing,Focusing Annotation for Semantic Role Labeling,2014,8,0,2,1,34180,daniel peterson,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Annotation of data is a time-consuming process, but necessary for many state-of-the-art solutions to NLP tasks, including semantic role labeling (SRL). In this paper, we show that language models may be used to select sentences that are more useful to annotate. We simulate a situation where only a portion of the available data can be annotated, and compare language model based selection against a more typical baseline of randomly selected data. The data is ordered using an off-the-shelf language modeling toolkit. We show that the least probable sentences provide dramatic improved system performance over the baseline, especially when only a small portion of the data is annotated. In fact, the lion{'}s share of the performance can be attained by annotating only 10-20{\%} of the data. This result holds for training a model based on new annotation, as well as when adding domain-specific annotation to a general corpus for domain adaptation."
E14-1007,Inducing Example-based Semantic Frames from a Massive Amount of Verb Uses,2014,40,16,4,0,3202,daisuke kawahara,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present an unsupervised method for inducing semantic frames from verb uses in giga-word corpora. Our semantic frames are verb-specific example-based frames that are distinguished according to their senses. We use the Chinese Restaurant Process to automatically induce these frames from a massive amount of verb instances. In our experiments, we acquire broad-coverage semantic frames from two giga-word corpora, the larger comprising 20 billion words. Our experimental results indicate the effectiveness of our approach."
W13-5503,Renewing and Revising {S}em{L}ink,2013,22,15,3,1,5184,claire bonial,"Proceedings of the 2nd Workshop on Linked Data in Linguistics ({LDL}-2013): Representing and linking lexicons, terminologies and other language data",0,"This research describes SemLink, a comprehensive resource for Natural Language Processing that maps and unifies several highquality lexical resources: PropBank, VerbNet, FrameNet, and the recently added OntoNotes sense groupings. Each of these resources was created for slightly different purposes, and therefore each carries unique strengths and limitations. SemLink allows users to leverage the strengths of each resource and provides the groundwork for incorporating these lexical resources effectively into linked data resources. SemLink and the resources included therein are discussed with a focus on the value of using lexical resources in a complementary fashion. Recent improvements to SemLink, including the addition of a new resource, the OntoNotes sense groupings, are described. Work to address future goals, including further expansion of SemLink, is also discussed."
W13-5407,Expanding {V}erb{N}et with {S}ketch {E}ngine,2013,23,3,3,1,5184,claire bonial,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
W13-2322,{A}bstract {M}eaning {R}epresentation for Sembanking,2013,23,386,9,0,40939,laura banarescu,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"We describe Abstract Meaning Representation (AMR), a semantic representation language in which we are writing down the meanings of thousands of English sentences. We hope that a sembank of simple, whole-sentence semantic structures will spur new work in statistical natural language understanding and generation, like the Penn Treebank encouraged work on statistical parsing. This paper gives an overview of AMR and tools associated with it."
W13-1004,Complex Predicates are Multi-Word Expressions,2013,0,2,1,1,4859,martha palmer,Proceedings of the 9th Workshop on Multiword Expressions,0,"Practitioners of English Natural Language Processing often feel fortunate because their tokens are clearly marked by spaces on either side. However, the spaces can be quite deceptive, since they ignore the boundaries of multi-word expressions, such as noun-noun compounds, verb particle constructions, light verb constructions and constructions from Construction Grammar, e.g., caused-motion constructions and resultatives. Correctly identifying and handling these types of expressions can be quite challenging, even from the viewpoint of manual annotation. This talk will review the pervasive nature of these constructions, touching on Arabic and Hindi as well as English. Using several illustrative examples from newswire and medical informatics, current best practices for annotation and automatic identification will be described, with an emphasis on contributions from predicate argument structures."
W13-1018,Semantic Roles for Nominal Predicates: Building a Lexical Resource,2013,15,6,2,1,640,ashwini vaidya,Proceedings of the 9th Workshop on Multiword Expressions,0,"The linguistic annotation of noun-verb complex predicates (also termed as light verb constructions) is challenging as these predicates are highly productive in Hindi. For semantic role labelling, each argument of the noun-verb complex predicate must be given a role label. For complex predicates, frame files need to be created specifying the role labels for each noun-verb complex predicate. The creation of frame files is usually done manually, but we propose an automatic method to expedite this process. We use two resources for this method: Hindi PropBank frame files for simple verbs and the annotated Hindi Treebank. Our method perfectly predicts 65% of the roles in 3015 unique noun-verb combinations, with an additional 22% partial predictions, giving us 87% useful predictions to build our annotation resource."
N13-4004,Semantic Role Labeling,2013,-1,-1,1,1,4859,martha palmer,NAACL HLT 2013 Tutorial Abstracts,0,None
D13-1149,The {V}erb{C}orner Project: Toward an Empirically-Based Semantic Decomposition of Verbs,2013,21,9,3,1,33119,joshua hartshorne,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"This research describes efforts to use crowdsourcing to improve the validity of the semantic predicates in VerbNet, a lexicon of about 6300 English verbs. The current semantic predicates can be thought of semantic primitives, into which the concepts denoted by a verb can be decomposed. For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location. Although VerbNetxe2x80x99s predicates are theoretically well-motivated, systematic empirical data is scarce. This paper describes a recently-launched attempt to address this issue with a series of human judgment tasks, posed to subjects in the form of games."
W12-2001,Question Ranking and Selection in Tutorial Dialogues,2012,29,3,2,1,22282,lee becker,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"A key challenge for dialogue-based intelligent tutoring systems lies in selecting follow-up questions that are not only context relevant but also encourage self-expression and stimulate learning. This paper presents an approach to ranking candidate questions for a given dialogue context and introduces an evaluation framework for this task. We learn to rank using judgments collected from expert human tutors, and we show that adding features derived from a rich, multi-layer dialogue act representation improves system performance over baseline lexical and syntactic features to a level in agreement with the judges. The experimental results highlight the important factors in modeling the questioning process. This work provides a framework for future work in automatic question generation and it represents a step toward the larger goal of directly learning tutorial dialogue policies directly from human examples."
P12-2071,Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection,2012,8,23,2,1,1137,jinho choi,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, left-to-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. We believe that this model selection approach can be applied to more sophisticated tagging algorithms and improve their robustness even further."
P12-1028,Verb Classification using Distributional Similarity in Syntactic and Semantic Structures,2012,49,11,4,0,12619,danilo croce,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper, we propose innovative representations for automatic classification of verbs according to mainstream linguistic theories, namely VerbNet and FrameNet. First, syntactic and semantic structures capturing essential lexical and syntactic properties of verbs are defined. Then, we design advanced similarity functions between such structures, i.e., semantic tree kernel functions, for exploiting distributional and grammatical information in Support Vector Machines. The extensive empirical analysis on VerbNet class and frame detection shows that our models capture meaningful syntactic/semantic structures, which allows for improving the state-of-the-art."
vaidya-etal-2012-empty,Empty Argument Insertion in the {H}indi {P}rop{B}ank,2012,9,4,3,1,640,ashwini vaidya,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper examines both linguistic behavior and practical implication of empty argument insertion in the Hindi PropBank. The Hindi PropBank is annotated on the Hindi Dependency Treebank, which contains some empty categories but not the empty arguments of verbs. In this paper, we analyze four kinds of empty arguments, *PRO*, *REL*, *GAP*, *pro*, and suggest effective ways of annotating these arguments. Empty arguments such as *PRO* and *REL* can be inserted deterministically; we present linguistically motivated rules that automatically insert these arguments with high accuracy. On the other hand, it is difficult to find deterministic rules to insert *GAP* and *pro*; for these arguments, we introduce a new annotation scheme that concurrently handles both semantic role labeling and empty category insertion, producing fast and high quality annotation. In addition, we present algorithms for finding antecedents of *REL* and *PRO*, and discuss why finding antecedents for some types of *PRO* is difficult."
corvey-etal-2012-foundations,Foundations of a Multilayer Annotation Framework for {T}witter Communications During Crisis Events,2012,12,18,4,1,43313,william corvey,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In times of mass emergency, vast amounts of data are generated via computer-mediated communication (CMC) that are difficult to manually collect and organize into a coherent picture. Yet valuable information is broadcast, and can provide useful insight into time- and safety-critical situations if captured and analyzed efficiently and effectively. We describe a natural language processing component of the EPIC (Empowering the Public with Information in Crisis) Project infrastructure, designed to extract linguistic and behavioral information from tweet text to aid in the task of information integration. The system incorporates linguistic annotation, in the form of Named Entity Tagging, as well as behavioral annotations to capture tweets contributing to situational awareness and analyze the information type of the tweet content. We show classification results and describe future integration of these classifiers in the larger EPIC infrastructure."
W11-3801,Statistical Dependency Parsing in {K}orean: From Corpus Generation To Automatic Parsing,2011,19,9,2,1,1137,jinho choi,Proceedings of the Second Workshop on Statistical Parsing of Morphologically Rich Languages,0,"This paper gives two contributions to dependency parsing in Korean. First, we build a Korean dependency Treebank from an existing constituent Treebank. For a morphologically rich language like Korean, dependency parsing shows some advantages over constituent parsing. Since there is not much training data available, we automatically generate dependency trees by applying head-percolation rules and heuristics to the constituent trees. Second, we show how to extract useful features for dependency parsing from rich morphology in Korean. Once we build the dependency Treebank, any statistical parsing approach can be applied. The challenging part is how to extract features from tokens consisting of multiple morphemes. We suggest a way of selecting important morphemes and use only these as features to avoid sparsity. Our parsing approach is evaluated on three different genres using both gold-standard and automatic morphological analysis. We also test the impact of fine vs. coarse-grained morphologies on dependency parsing. With automatic morphological analysis, we achieve labeled attachment scores of 80%. To the best of our knowledge, this is the first time that Korean dependency parsing has been evaluated on labeled edges with such a large variety of data."
W11-1901,{C}o{NLL}-2011 Shared Task: Modeling Unrestricted Coreference in {O}nto{N}otes,2011,44,200,4,0.5979,11322,sameer pradhan,Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,0,"The CoNLL-2011 shared task involved predicting coreference using OntoNotes data. Resources in this field have tended to be limited to noun phrase coreference, often on a restricted set of entities, such as ace entities. OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types. OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure. This paper briefly describes the OntoNotes annotation (coreference and other layers) and then describes the parameters of the shared task including the format, pre-processing information, and evaluation criteria, and presents and discusses the results achieved by the participating systems. Having a standard test set and evaluation parameters, all based on a new resource that provides multiple integrated annotation layers (parses, semantic roles, word senses, named entities and coreference) that could support joint models, should help to energize ongoing research in the task of entity and event coreference."
W11-1003,Semantic Mapping Using Automatic Word Alignment and Semantic Role Labeling,2011,26,17,2,1,37082,shumin wu,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"To facilitate the application of semantics in statistical machine translation, we propose a broad-coverage predicate-argument structure mapping technique using automated resources. Our approach utilizes automatic syntactic and semantic parsers to generate Chinese-English predicate-argument structures. The system produced a many-to-many argument mapping for all PropBank argument types by computing argument similarity based on automatic word alignment, achieving 80.5% F-score on numbered argument mapping and 64.6% F-score on all arguments. By measuring predicate-argument structure similarity based on the argument mapping, and formulating the predicate-argument structure mapping problem as a linear-assignment problem, the system achieved 84.9% F-score using automatic SRL, only 3.7% F-score lower than using gold standard SRL. The mapping output covered 49.6% of the annotated Chinese predicates (which contains predicate-adjectives that often have no parallel annotations in English) and 80.7% of annotated English predicates, suggesting its potential as a valuable resource for improving word alignment and reranking MT output."
W11-0901,Going Beyond Shallow Semantics,2011,0,1,1,1,4859,martha palmer,Proceedings of the {ACL} 2011 Workshop on Relational Models of Semantics,0,"Shallow semantic analyzers, such as semantic role labeling and sense tagging, are increasing in accuracy and becoming commonplace. However, they only provide limited and local representations of local words and individual predicate-argument structures. This talk will address some of the current challenges in producing deeper, connected representations of eventualities. Available resources, such as VerbNet, FrameNet and TimeBank, that can assist in this process will also be discussed, as well as some of their limitations."
W11-0906,Transition-based Semantic Role Labeling Using Predicate Argument Clustering,2011,25,18,2,1,1137,jinho choi,Proceedings of the {ACL} 2011 Workshop on Relational Models of Semantics,0,"This paper suggests two ways of improving semantic role labeling (SRL). First, we introduce a novel transition-based SRL algorithm that gives a quite different approach to SRL. Our algorithm is inspired by shift-reduce parsing and brings the advantages of the transition-based approach to SRL. Second, we present a self-learning clustering technique that effectively improves labeling accuracy in the test domain. For better generalization of the statistical models, we cluster verb predicates by comparing their predicate argument structures and apply the clustering information to the final labeling decisions. All approaches are evaluated on the CoNLL'09 English data. The new algorithm shows comparable results to another state-of-the-art system. The clustering technique improves labeling accuracy for both in-domain and out-of-domain tasks."
W11-0910,Incorporating Coercive Constructions into a Verb Lexicon,2011,22,5,5,1,5184,claire bonial,Proceedings of the {ACL} 2011 Workshop on Relational Models of Semantics,0,"We take the first steps towards augmenting a lexical resource, VerbNet, with probabilistic information about coercive constructions. We focus on Causedmotion as an example construction occurring with verbs for which it is a typical usage or for which it must be interpreted as extending the event semantics through coercion, which occurs productively and adds substantially to the relational semantics of a verb. However, through annotation we find that VerbNet fails to accurately capture all usages of the construction. We use unsupervised methods to estimate probabilistic measures from corpus data for predicting usage of the construction across verb classes in the lexicon and evaluate against VerbNet. We discuss how these methods will form the basis for enhancements for VerbNet supporting more accurate analysis of the relational semantics of a verb across productive usages."
W11-0403,Analysis of the {H}indi {P}roposition {B}ank using Dependency Structure,2011,17,14,3,1,640,ashwini vaidya,Proceedings of the 5th Linguistic Annotation Workshop,0,"This paper makes two contributions. First, we describe the Hindi Proposition Bank that contains annotations of predicate argument structures of verb predicates. Unlike PropBanks in most other languages, the Hind PropBank is annotated on top of dependency structure, the Hindi Dependency Treebank. We explore the similarities between dependency and predicate argument structures, so the PropBank annotation can be faster and more accurate. Second, we present a probabilistic rule-based system that maps syntactic dependents to semantic arguments. With simple rules, we classify about 47% of the entire PropBank arguments with over 90% confidence. These preliminary results are promising; they show how well these two frameworks are correlated. This can also be used to speed up our annotations."
W11-0408,Reducing the Need for Double Annotation,2011,24,9,2,1,12174,dmitriy dligach,Proceedings of the 5th Linguistic Annotation Workshop,0,"The quality of annotated data is crucial for supervised learning. To eliminate errors in single annotated data, a second round of annotation is often used. However, is it absolutely necessary to double annotate every example? We show that it is possible to reduce the amount of the second round of annotation by more than half without sacrificing the performance."
W11-0410,A scaleable automated quality assurance technique for semantic representations and proposition banks,2011,27,0,3,0,29526,bretonnel cohen,Proceedings of the 5th Linguistic Annotation Workshop,0,"This paper presents an evaluation of an automated quality assurance technique for a type of semantic representation known as a predicate argument structure. These representations are crucial to the development of an important class of corpus known as a proposition bank. Previous work (Cohen and Hunter, 2006) proposed and tested an analytical technique based on a simple discovery procedure inspired by classic structural linguistic methodology. Cohen and Hunter applied the technique manually to a small set of representations. Here we test the feasibility of automating the technique, as well as the ability of the technique to scale to a set of semantic representations and to a corpus many times larger than that used by Cohen and Hunter. We conclude that the technique is completely automatable, uncovers missing sense distinctions and other bad semantic representations, and does scale well, performing at an accuracy of 69% for identifying bad representations. We also report on the implications of our findings for the correctness of the semantic representations in PropBank."
W11-0110,{V}erb{N}et Class Assignment as a {WSD} Task,2011,29,25,3,1,4915,susan brown,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"The VerbNet lexical resource classifies English verbs based on semantic and syntactic regularities and has been used for numerous NLP tasks, most notably, semantic role labeling. Since, in addition to thematic roles, it also provides semantic predicates, it can serve as a foundation for further inferencing. Many verbs belong to multiple VerbNet classes, with each class membership corresponding roughly to a different sense of the verb. A VerbNet token classifier is essential for current applications using the resource and could provide the basis for a deep semantic parsing system, one that made full use of VerbNet's extensive syntactic and semantic information. We describe our VerbNet classifier, which uses rich syntactic and semantic features to label verb instances with their appropriate VerbNet class. It achieves an accuracy of 88.67% with multiclass verbs, which is a 49% error reduction over the most frequent class baseline."
W11-0133,{DISCUSS}: A dialogue move taxonomy layered over semantic representations,2011,8,9,4,1,22282,lee becker,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"In this paper we describe DISCUSS, a dialogue move taxonomy layered over semantic representations. We designed this scheme to enable development of computational models of tutorial dialogues and to provide an intermediate representation suitable for question and tutorial act generation. As such, DISCUSS captures semantic and pragmatic elements across four dimensions: Dialogue Act, Rhetorical Form, Predicate Type, Semantic Roles. Together these dimensions provide a summary of an utterance's propositional content and how it may change the underlying information state of the conversation. This taxonomy builds on previous work in both general dialogue act taxonomies as well as work in tutorial act and tutorial question categorization. The types and values found within our taxonomy are based on preliminary observations and on-going annotation from our corpus of multimodal tutorial dialogues for elementary school science education."
P11-2002,Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling,2011,14,13,2,1,12174,dmitriy dligach,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Active Learning (AL) is typically initialized with a small seed of examples selected randomly. However, when the distribution of classes in the data is skewed, some classes may be missed, resulting in a slow learning progress. Our contribution is twofold: (1) we show that an unsupervised language modeling based technique is effective in selecting rare class examples, and (2) we use this technique for seeding AL and demonstrate that it leads to a higher learning rate. The evaluation is conducted in the context of word sense disambiguation."
P11-2121,Getting the Most out of Transition-based Dependency Parsing,2011,22,51,2,1,1137,jinho choi,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-the-art performance with respect to other parsing approaches evaluated on the same data set."
W10-1808,To Annotate More Accurately or to Annotate More,2010,11,11,3,1,12174,dmitriy dligach,Proceedings of the Fourth Linguistic Annotation Workshop,0,"The common accepted wisdom is that blind double annotation followed by adjudication of disagreements is necessary to create training and test corpora that result in the best possible performance. We provide evidence that this is unlikely to be the case. Rather, the greatest value for your annotation dollar lies in single annotating more data."
W10-1810,{P}rop{B}ank Annotation of Multilingual Light Verb Constructions,2010,15,24,7,1,7749,jena hwang,Proceedings of the Fourth Linguistic Annotation Workshop,0,"In this paper, we have addressed the task of PropBank annotation of light verb constructions, which like multi-word expressions pose special problems. To arrive at a solution, we have evaluated 3 different possible methods of annotation. The final method involves three passes: (1) manual identification of a light verb construction, (2) annotation based on the light verb construction's Frame File, and (3) a deterministic merging of the first two passes. We also discuss how in various languages the light verb constructions are identified and can be distinguished from the non-light verb word groupings."
W10-1811,Retrieving Correct Semantic Boundaries in Dependency Structure,2010,10,4,2,1,1137,jinho choi,Proceedings of the Fourth Linguistic Annotation Workshop,0,"This paper describes the retrieval of correct semantic boundaries for predicate-argument structures annotated by dependency structure. Unlike phrase structure, in which arguments are annotated at the phrase level, dependency structure does not have phrases so the argument labels are associated with head words instead: the subtree of each head word is assumed to include the same set of words as the annotated phrase does in phrase structure. However, at least in English, retrieving such subtrees does not always guarantee retrieval of the correct phrase boundaries. In this paper, we present heuristics that retrieve correct phrase boundaries for semantic arguments, called semantic boundaries, from dependency trees. By applying heuristics, we achieved an F1-score of 99.54% for correct representation of semantic boundaries. Furthermore, error analysis showed that some of the errors could also be considered correct, depending on the interpretation of the annotation."
W10-1833,An Overview of the {CRAFT} Concept Annotation Guidelines,2010,6,18,3,0,26534,michael bada,Proceedings of the Fourth Linguistic Annotation Workshop,0,"We present our concept-annotation guidelines for an large multi-institutional effort to create a gold-standard manually annotated corpus of full-text biomedical journal articles. We are semantically annotating these documents with the full term sets of eight large biomedical ontologies and controlled terminologies ranging from approximately 1,000 to millions of terms, and, using these guidelines, we have been able to perform this extremely challenging task with a high degree of interannotator agreement. The guidelines have been designed to be able to be used with any terminology employed to semantically annotate concept mentions in text and are available for external use."
W10-1836,The Revised {A}rabic {P}rop{B}ank,2010,26,23,5,0,579,wajdi zaghouani,Proceedings of the Fourth Linguistic Annotation Workshop,0,The revised Arabic PropBank (APB) reflects a number of changes to the data and the process of PropBanking. Several changes stem from Treebank revisions. An automatic process was put in place to map existing annotation to the new trees. We have revised the original 493 Frame Files from the Pilot APB and added 1462 new files for a total of 1955 Frame Files with 2446 framesets. In addition to a heightened attention to sense distinctions this cycle includes a greater attempt to address complicated predicates such as light verb constructions and multi-word expressions. New tools facilitate the data tagging and also simplify frame creation.
W10-0801,Towards a Domain Independent Semantics: Enhancing Semantic Representation with Construction Grammar,2010,23,8,3,1,7749,jena hwang,Proceedings of the {NAACL} {HLT} Workshop on Extracting and Using Constructions in Computational Linguistics,0,"In Construction Grammar, structurally patterned units called constructions are assigned meaning in the same way that words are -- via convention rather than composition. That is, rather than piecing semantics together from individual lexical items, Construction Grammar proposes that semantics can be assigned at the construction level. In this paper, we investigate whether a classifier can be taught to identify these constructions and consider the hypothesis that identifying construction types can improve the semantic interpretation of previously unseen predicate uses. Our results show that not only can the constructions be automatically identified with high accuracy, but the classifier also performs just as well with out-of-vocabulary predicates."
W10-0512,{T}witter in Mass Emergency: What {NLP} Can Contribute,2010,1,2,4,1,43313,william corvey,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Linguistics in a World of Social Media,0,"We detail methods for entity span identification and entity class annotation of Twitter communications that take place during times of mass emergency. We present our motivation, method and preliminary results."
S10-1008,{S}em{E}val-2010 Task 10: Linking Events and Their Participants in Discourse,2010,6,67,5,0.606061,3382,josef ruppenhofer,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"We describe the SemEval-2010 shared task on Linking Events and Their Participants in Discourse. This task is an extension to the classical semantic role labeling task. While semantic role labeling is traditionally viewed as a sentence-internal task, local semantic argument structures clearly interact with each other in a larger context, e.g., by sharing references to specific discourse entities or events. In the shared task we looked at one particular aspect of cross-sentence links between argument structures, namely linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist). This task is potentially beneficial for a number of NLP applications, such as information extraction, question answering or text summarization."
N10-2004,Multilingual {P}ropbank Annotation Tools: Cornerstone and Jubilee,2010,6,5,3,1,1137,jinho choi,Proceedings of the {NAACL} {HLT} 2010 Demonstration Session,0,"This paper demonstrates two annotation tools related to Propbank: Cornerstone and Jubilee. Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles. Propbank annotation also requires the choice of a sense ID for each predicate, defined in the corresponding frameset file. Jubilee expedites the annotation process by displaying several resources of syntactic and semantic information simultaneously; easy access to each of these resources allows the annotator to quickly absorb and apply the necessary syntactic and semantic information pertinent to each predicate for consistent and efficient annotation. Cornerstone is a user-friendly XML editor, customized to allow frame authors to create and edit frameset files. Both tools have been successfully adapted to many Prop-bank projects; they run platform independently, are light enough to run as X11 applications and support multiple languages such as Arabic, Chinese, English, Hindi and Korean."
choi-etal-2010-propbank,"{P}ropbank Frameset Annotation Guidelines Using a Dedicated Editor, Cornerstone",2010,7,13,3,1,1137,jinho choi,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper gives guidelines of how to create and update Propbank frameset files using a dedicated editor, Cornerstone. Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles in relation to the predicate. Propbank annotation also requires the choice of a sense ID for each predicate. Thus, for each predicate in Propbank, there exists a corresponding frameset file showing the expected predicate argument structure of each sense related to the predicate. Since most Propbank annotations are based on the predicate argument structure defined in the frameset files, it is important to keep the files consistent, simple to read as well as easy to update. The frameset files are written in XML, which can be difficult to edit when using a simple text editor. Therefore, it is helpful to develop a user-friendly editor such as Cornerstone, specifically customized to create and edit frameset files. Cornerstone runs platform independently, is light enough to run as an X11 application and supports multiple languages such as Arabic, Chinese, English, Hindi and Korean."
bhatia-etal-2010-empty,Empty Categories in a {H}indi Treebank,2010,8,9,4,0,11651,archna bhatia,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We are in the process of creating a multi-representational and multi-layered treebank for Hindi/Urdu (Palmer et al., 2009), which has three main layers: dependency structure, predicate-argument structure (PropBank), and phrase structure. This paper discusses an important issue in treebank design which is often neglected: the use of empty categories (ECs). All three levels of representation make use of ECs. We make a high-level distinction between two types of ECs, trace and silent, on the basis of whether they are postulated to mark displacement or not. Each type is further refined into several subtypes based on the underlying linguistic phenomena which the ECs are introduced to handle. This paper discusses the stages at which we add ECs to the Hindi/Urdu treebank and why. We investigate methodically the different types of ECs and their role in our syntactic and semantic representations. We also examine our decisions whether or not to coindex each type of ECs with other elements in the representation."
choi-etal-2010-propbank-instance,"{P}ropbank Instance Annotation Guidelines Using a Dedicated Editor, Jubilee",2010,5,15,3,1,1137,jinho choi,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper gives guidelines of how to annotate Propbank instances using a dedicated editor, Jubilee. Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles in relation to the predicate. Propbank annotation also requires the choice of a sense ID for each predicate. Jubilee facilitates this annotation process by displaying several resources of syntactic and semantic information simultaneously: the syntactic structure of a sentence is displayed in the main frame, the available senses with their corresponding argument structures are displayed in another frame, all available Propbank arguments are displayed for the annotators choice, and example annotations of each sense of the predicate are available to the annotator for viewing. Easy access to each of these resources allows the annotator to quickly absorb and apply the necessary syntactic and semantic information pertinent to each predicate for consistent and efficient annotation. Jubilee has been successfully adapted to many Propbank projects in several universities. The tool runs platform independently, is light enough to run as an X11 application and supports multiple languages such as Arabic, Chinese, English, Hindi and Korean."
brown-etal-2010-number,Number or Nuance: Which Factors Restrict Reliable Word Sense Annotation?,2010,16,10,3,1,4915,susan brown,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This study attempts to pinpoint the factors that restrict reliable word sense annotation, focusing on the influence of the number of senses annotators use and the semantic granularity of those senses. Both of these factors may be possible causes of low interannotator agreement (ITA) when tagging with fine-grained word senses, and, consequently, low WSD system performance (Ng et al., 1999; Snyder {\&} Palmer, 2004; Chklovski {\&} Mihalcea, 2002). If number of senses is the culprit, modifying the task to show fewer senses at a time could improve annotator reliability. However, if overly nuanced distinctions are the problem, then more general, coarse-grained distinctions may be necessary for annotator success and may be all that is needed to supply systems with the types of distinctions that people make. We describe three experiments that explore the role of these factors in annotation performance. Our results indicate that of these two factors, only the granularity of the senses restricts interannotator agreement, with broader senses resulting in higher annotation reliability."
cieri-etal-2010-road,A Road Map for Interoperable Language Resource Metadata,2010,0,5,6,0,17560,christopher cieri,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"LRs remain expensive to create and thus rare relative to demand across languages and technology types. The accidental re-creation of an LR that already exists is a nearly unforgivable waste of scarce resources that is unfortunately not so easy to avoid. The number of catalogs the HLT researcher must search, with their different formats, make it possible to overlook an existing resource. This paper sketches the sources of this problem and outlines a proposal to rectify along with a new vision of LR cataloging that will to facilitates the documentation and exploitation of a much wider range of LRs than previously considered."
2010.amta-papers.15,Detecting Cross-lingual Semantic Similarity Using Parallel {P}rop{B}anks,2010,16,6,3,1,37082,shumin wu,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper suggests a method for detecting cross-lingual semantic similarity using parallel PropBanks. We begin by improving word alignments for verb predicates generated by GIZA++ by using information available in parallel PropBanks. We applied the Kuhn-Munkres method to measure predicate-argument matching and improved verb predicate alignments by an F-score of 12.6{\%}. Using the enhanced word alignments we checked the set of target verbs aligned to a specific source verb for semantic consistency. For a set of English verbs aligned to a Chinese verb, we checked if the English verbs belong to the same semantic class using an existing lexical database, WordNet. For a set of Chinese verbs aligned to an English verb we manually checked semantic similarity between the Chinese verbs within a set. Our results show that the verb sets we generated have a high correlation with semantic classes. This could potentially lead to an automatic technique for generating semantic classes for verbs."
W09-3702,Knowing a word (sense) by its company,2009,0,0,1,1,4859,martha palmer,Proceedings of the Eight International Conference on Computational Semantics,0,"Supervised word sense disambiguation requires training corpora that have been tagged with word senses, and these word senses typically come from a pre-existing sense inventory. Space limitations imposed by dictionary publishers have biased the field towards lists of discrete senses for an individual lexeme. This approach does not capture information about relatedness of individual senses. How important is this information to knowing which sense distinctions are critical for particular types of NLP applications? How much does sense relatedness affect automatic word sense disambiguation performance? Recent psycholinguistic evidence seems to indicate that closely related word senses may be represented in the mental lexicon much like a single sense, whereas distantly related senses may be represented more like discrete entities. These results suggest that, for the purposes of WSD, closely related word senses can be clustered together into a more general sense with little meaning loss. This talk will describe the relatedness of verb senses and its impact on NLP applications and WSD components as well as recent psycholinguistic research results."
W09-3020,Using Parallel Propbanks to enhance Word-alignments,2009,5,7,2,1,1137,jinho choi,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"This short paper describes the use of the linguistic annotation available in parallel PropBanks (Chinese and English) for the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type."
W09-3036,A Multi-Representational and Multi-Layered Treebank for {H}indi/{U}rdu,2009,11,89,3,1,40828,rajesh bhatt,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"This paper describes the simultaneous development of dependency structure and phrase structure treebanks for Hindi and Urdu, as well as a PropBank. The dependency structure and the PropBank are manually annotated, and then the phrase structure treebank is produced automatically. To ensure successful conversion the development of the guidelines for all three representations are carefully coordinated."
W09-2417,{S}em{E}val-2010 Task 10: Linking Events and Their Participants in Discourse,2009,18,19,5,0.606061,3382,josef ruppenhofer,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"In this paper, we describe the SemEval-2010 shared task on Linking Events and Their Participants in Discourse. This task is a variant of the classical semantic role labelling task. The novel aspect is that we focus on linking local semantic argument structures across sentence boundaries. Specifically, the task aims at linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist). This task is potentially beneficial for a number of NLP applications and we hope that it will not only attract researchers from the semantic role labelling community but also from co-reference resolution and information extraction."
N09-3005,Using Language Modeling to Select Useful Annotation Data,2009,19,5,2,1,12174,dmitriy dligach,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Student Research Workshop and Doctoral Consortium",0,"An annotation project typically has an abundant supply of unlabeled data that can be drawn from some corpus, but because the labeling process is expensive, it is helpful to pre-screen the pool of the candidate instances based on some criterion of future usefulness. In many cases, that criterion is to improve the presence of the rare classes in the data to be annotated. We propose a novel method for solving this problem and show that it compares favorably to a random sampling baseline and a clustering algorithm."
W08-1201,Invited Talk: The Relevance of a Cognitive Model of the Mental Lexicon to Automatic Word Sense Disambiguation,2008,0,0,1,1,4859,martha palmer,Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics,0,"Supervised word sense disambiguation requires training corpora that have been tagged with word senses, and these word senses typically come from a pre-existing sense inventory. Space limitations imposed by dictionary publishers have biased the field towards lists of discrete senses for an individual lexeme. Although some dictionaries use hierarchical entries to emphasize relations between senses, many do not. WordNet, which has been the default choice of NLP researchers for sense tagging because of its broad coverage and easy accibility, does not have hierarchical entries. Could the relations between senses that are captured by a hierarchy be useful to NLP systems? Concerns have also been raised about whether or not WordNet's word senses are unnecessarily fine-grained. WSD systems are obviously more successful in distinguishing coarse-grained senses than fine-grained ones (Navigli, 2006), but important information could be lost if fine-grained distinctions are ignored. Recent psycholinguistic evidence seems to indicate that closely related word senses may be represented in the mental lexicon much like a single sense, whereas distantly related senses may be represented more like discrete entities (Brown, 2008). These results suggest that, for the purposes of WSD, closely related word senses can be clustered together into a more general sense with little meaning loss. This talk will describe this psycholinguistic research and its current implications for automatic word sense disambiguation, as well as plans for future research and its possible impact."
P08-2008,Novel Semantic Features for Verb Sense Disambiguation,2008,10,28,2,1,12174,dmitriy dligach,"Proceedings of ACL-08: HLT, Short Papers",0,We propose a novel method for extracting semantic information about a verb's arguments and apply it to Verb Sense Disambiguation (VSD). We contrast this method with two popular approaches to retrieving this information and show that it improves the performance of our VSD system and outperforms the other two approaches
P08-2061,Extracting a Representation from Text for Semantic Analysis,2008,11,7,4,1,24264,rodney nielsen,"Proceedings of ACL-08: HLT, Short Papers",0,"We present a novel fine-grained semantic representation of text and an approach to constructing it. This representation is largely extractable by today's technologies and facilitates more detailed semantic analysis. We discuss the requirements driving the representation, suggest how it might be of value in the automated tutoring domain, and provide evidence of its validity."
nielsen-etal-2008-annotating,Annotating Students{'} Understanding of Science Concepts,2008,18,28,4,1,24264,rodney nielsen,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper summarizes the annotation of fine-grained entailment relationships in the context of student answers to science assessment questions. We annotated a corpus of 15,357 answer pairs with 145,911 fine-grained entailment relationships. We provide the rationale for such fine-grained analysis and discuss its perceived benefits to an Intelligent Tutoring System. The corpus also has potential applications in other areas, such as question answering and multi-document summarization. Annotators achieved 86.2{\%} inter-annotator agreement (Kappa=0.728, corresponding to substantial agreement) annotating the fine-grained facets of reference answers with regard to understanding expressed in student answers and labeling from one of five possible detailed relationship categories. The corpus described in this paper, which is the only one providing such detailed entailment annotations, is available as a public resource for the research community. The corpus is expected to enable application development, not only for intelligent tutoring systems, but also for general textual entailment applications, that is currently not practical."
palmer-etal-2008-pilot,A Pilot {A}rabic {P}ropbank,2008,13,37,1,1,4859,martha palmer,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, we present the details of creating a pilot Arabic proposition bank (Propbank). Propbanks exist for both English and Chinese. However the morphological and syntactic expression of linguistic phenomena in Arabic yields a very different type of process in creating an Arabic propbank. Hence, we highlight those characteristics of Arabic that make creating a propbank for the language a different challenge compared to the creation of an English Propbank.We believe that many of the lessons learned in dealing with Arabic could generalise to other languages that exhibit equally rich morphology and relatively free word order."
W07-1508,Criteria for the Manual Grouping of Verb Senses,2007,7,23,7,0,45506,cecily duffield,Proceedings of the Linguistic Annotation Workshop,0,"In this paper, we argue that clustering WordNet senses into more coarse-grained groupings results in higher inter-annotator agreement and increased system performance. Clustering of verb senses involves examining syntactic and semantic features of verbs and arguments on a case-by-case basis rather than applying a strict methodology. Determining appropriate criteria for clustering is based primarily on the needs of annotators."
S07-1016,"{S}em{E}val-2007 Task-17: {E}nglish Lexical Sample, {SRL} and All Words",2007,10,207,4,0.5979,11322,sameer pradhan,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes our experience in preparing the data and evaluating the results for three subtasks of SemEval-2007 Task-17 - Lexical Sample, Semantic Role Labeling (SRL) and All-Words respectively. We tabulate and analyze the results of participating systems."
S07-1017,{S}em{E}val-2007 Task 18: {A}rabic Semantic Labeling,2007,8,17,6,0.153281,7377,mona diab,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper, we present the details of the Arabic Semantic Labeling task. We describe some of the features of Arabic that are relevant for the task. The task comprises two subtasks: Arabic word sense disambiguation and Arabic semantic role labeling. The task focuses on modern standard Arabic."
N07-1069,Can Semantic Roles Generalize Across Genres?,2007,14,45,3,0,49340,szuting yi,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"PropBank has been widely used as training data for Semantic Role Labeling. However, because this training data is taken from the WSJ, the resulting machine learning models tend to overfit on idiosyncrasies of that textxe2x80x99s style, and do not port well to other genres. In addition, since PropBank was designed on a verb-by-verb basis, the argument labels Arg2 - Arg5 get used for very diverse argument roles with inconsistent training instances. For example, the verb xe2x80x9cmakexe2x80x9d uses Arg2 for the xe2x80x9cMaterialxe2x80x9d argument; but the verb xe2x80x9cmultiplyxe2x80x9d uses Arg2 for the xe2x80x9cExtentxe2x80x9d argument. As a result, it can be difficult for automatic classifiers to learn to distinguish arguments Arg2-Arg5. We have created a mapping between PropBank and VerbNet that provides a VerbNet thematic role label for each verb-specific PropBank label. Since VerbNet uses argument labels that are more consistent across verbs, we are able to demonstrate that these new labels are easier to learn."
W06-0609,Issues in Synchronizing the {E}nglish Treebank and {P}rop{B}ank,2006,9,24,5,0.540541,43023,olga babkomalaya,Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006,0,"The PropBank primarily adds semantic role labels to the syntactic constituents in the parsed trees of the Treebank. The goal is for automatic semantic role labeling to be able to use the domain of locality of a predicate in order to find its arguments. In principle, this is exactly what is wanted, but in practice the PropBank annotators often make choices that do not actually conform to the Treebank parses. As a result, the syntactic features extracted by automatic semantic role labeling systems are often inconsistent and contradictory. This paper discusses in detail the types of mismatches between the syntactic bracketing and the semantic role labeling that can be found, and our plans for reconciling them."
P06-2118,Aligning Features with Sense Distinction Dimensions,2006,20,10,3,0.571429,10294,nianwen xue,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"In this paper we present word sense disambiguation (WSD) experiments on ten highly polysemous verbs in Chinese, where significant performance improvements are achieved using rich linguistic features. Our system performs significantly better, and in some cases substantially better, than the baseline on all ten verbs. Our results also demonstrate that features extracted from the output of an automatic Chinese semantic role labeling system in general benefited the WSD system, even though the amount of improvement was not consistent across the verbs. For a few verbs, semantic role information actually hurt WSD performance. The inconsistency of feature performance is a general characteristic of the WSD task, as has been observed by others. We argue that this result can be explained by the fact that word senses are partitioned along different dimensions for different verbs and the features therefore need to be tailored to particular verbs in order to achieve adequate accuracy on verb sense disambiguation."
N06-2015,{O}nto{N}otes: The 90{\\%} Solution,2006,13,537,3,0,1043,eduard hovy,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement. An initial portion (300K words of English newswire and 250K words of Chinese newswire) will be made available to the community during 2007."
N06-1016,An Empirical Study of the Behavior of Active Learning for Word Sense Disambiguation,2006,13,67,4,1,36926,jinying chen,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"This paper shows that two uncertainty-based active learning methods, combined with a maximum entropy model, work well on learning English verb senses. Data analysis on the learning process, based on both instance and feature levels, suggests that a careful treatment of feature extraction is important for the active learning to be useful for WSD. The overfitting phenomena that occurred during the active learning process are identified as classic overfitting in machine learning based on the data analysis."
kipper-etal-2006-extending,Extending {V}erb{N}et with Novel Verb Classes,2006,21,114,4,1,50347,karin kipper,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Lexical classifications have proved useful in supporting various natural language processing (NLP) tasks. The largest verb classification for English is Levin's (1993) work which defined groupings of verbs based on syntactic properties. VerbNet - the largest computational verb lexicon currently available for English - provides detailed syntactic-semantic descriptions of Levin classes. While the classes included are extensive enough for some NLP use, they are not comprehensive. Korhonen and Briscoe (2004) have proposed a significant extension of Levin's classification which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin. This paper describes the integration of these classes into VerbNet. The result is the most extensive Levin-style classification for English verbs which can be highly useful for practical applications."
2006.amta-papers.5,Better Learning and Decoding for Syntax Based {SMT} Using {PSDIG},2006,26,3,2,1,50712,yuan ding,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"As an approach to syntax based statistical machine translation (SMT), Probabilistic Synchronous Dependency Insertion Grammars (PSDIG), introduced in (Ding and Palmer, 2005), are a version of synchronous grammars defined on dependency trees. In this paper we discuss better learning and decoding algorithms for a PSDIG MT system. We introduce two new grammar learners: (1) an exhaustive learner combining different heuristics, (2) an n-gram based grammar learner. Combining the grammar rules learned from the two learners improved the performance. We introduce a better decoding algorithm which incorporates a tri-gram language model. According to the Bleu metric, the PSDIG MT system performance is significantly better than IBM Model 4, while on par with the state-of-the-art phrase based system Pharaoh (Koehn, 2004). The improved integration of syntax on both source and target languages opens door to more sophisticated SMT processes."
W05-0639,The Integration of Syntactic Parsing and Semantic Role Labeling,2005,9,26,2,0,49340,szuting yi,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"This paper describes a system for the CoNLL-2005 Shared Task on Semantic Role Labeling. We trained two parsers with the training corpus in which the semantic argument information is attached to the constituent labels, we then used the resulting parse trees as the input of the pipelined SRL system. We present our results of combining the output of various SRL systems using different parsers."
W05-0302,"Merging {P}rop{B}ank, {N}om{B}ank, {T}ime{B}ank, {P}enn {D}iscourse {T}reebank and Coreference",2005,21,21,3,0,993,james pustejovsky,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"Many recent annotation efforts for English have focused on pieces of the larger problem of semantic annotation, rather than initially producing a single unified representation. This paper discusses the issues involved in merging four of these efforts into a unified linguistic structure: PropBank, NomBank, the Discourse Treebank and Coreference Annotation undertaken at the University of Essex. We discuss resolving overlapping and conflicting annotation as well as how the various annotation schemes can reinforce each other to produce a representation that is greater than the sum of its parts."
W05-0309,A Parallel {P}roposition {B}ank {II} for {C}hinese and {E}nglish,2005,14,15,1,1,4859,martha palmer,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"The Proposition Bank (PropBank) project is aimed at creating a corpus of text annotated with information about semantic propositions. The second phase of the project, PropBank II adds additional levels of semantic annotation which include eventuality variables, co-reference, coarse-grained sense tags, and discourse connectives. This paper presents the results of the parallel PropBank II project, which adds these richer layers of semantic annotation to the first 100K of the Chinese Treebank and its English translation. Our preliminary analysis supports the hypothesis that this additional annotation reconciles many of the surface differences between the two languages."
P05-1006,The Role of Semantic Roles in Disambiguating Verb Senses,2005,11,38,2,1,34044,hoa dang,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"We describe an automatic Word Sense Disambiguation (WSD) system that disambiguates verb senses using syntactic and semantic features that encode information about predicate arguments and semantic classes. Our system performs at the best published accuracy on the English verbs of Senseval-2. We also experiment with using the gold-standard predicate-argument labels from PropBank for disambiguating fine-grained WordNet senses and course-grained PropBank framesets, and show that disambiguation of verb senses can be further improved with better extraction of semantic roles."
P05-1067,Machine Translation Using Probabilistic Synchronous Dependency Insertion Grammars,2005,26,170,2,1,50712,yuan ding,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data. In this paper, we present a syntax-based statistical machine translation system based on a probabilistic synchronous dependency insertion grammar. Synchronous dependency insertion grammars are a version of synchronous grammars defined on dependency trees. We first introduce our approach to inducing such a grammar from parallel corpora. Second, we describe the graphical model for the machine translation task, which can also be viewed as a stochastic tree-to-tree transducer. We introduce a polynomial time decoding algorithm for the model. We evaluate the outputs of our MT system using the NIST and Bleu automatic MT evaluation software. The result shows that our system outperforms the baseline system based on the IBM models in both translation speed and quality."
J05-1004,The {P}roposition {B}ank: An Annotated Corpus of Semantic Roles,2005,54,1559,1,1,4859,martha palmer,Computational Linguistics,0,"The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated.We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus.n n We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty ''trace'' categories of the treebank."
I05-1081,Towards Robust High Performance Word Sense Disambiguation of {E}nglish Verbs Using Rich Linguistic Features,2005,21,25,2,1,36926,jinying chen,Second International Joint Conference on Natural Language Processing: Full Papers,0,This paper shows that our WSD system using rich linguistic features achieved high accuracy in the classification of English SENSEVAL2 verbs for both fine-grained (64.6%) and coarse-grained (73.7%) senses. We describe three specific enhancements to our treatment of rich linguistic features and present their separate and combined contributions to our system's performance. Further experiments showed that our system had robust performance on test data without high quality rich features.
W04-3212,Calibrating Features for Semantic Role Labeling,2004,16,277,2,0.681818,10294,nianwen xue,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"This paper takes a critical look at the features used in the semantic role tagging literature and show that the information in the input, generally a syntactic parse tree, has yet to be fully exploited. We propose an additional set of features and our experiments show that these features lead to fairly significant improvements in the tasks we performed. We further show that different features are needed for different subtasks. Finally, we show that by using a Maximum Entropy classifier and fewer features, we achieved results comparable with the best previously reported results obtained with SVM models. We believe this is a clear indication that developing features that capture the right kind of information is crucial to advancing the stateof-the-art in semantic analysis."
W04-3111,Integrated Annotation for Biomedical Information Extraction,2004,19,156,6,0,23568,seth kulick,"{HLT}-{NAACL} 2004 Workshop: Linking Biological Literature, Ontologies and Databases",0,"We describe an approach to two areas of biomedical information extraction, drug development and cancer genomics. We have developed a framework which includes corpus annotation integrated at multiple levels: a Treebank containing syntactic structure, a Propbank containing predicate-argument structure, and annotation of entities and relations among the entities. Crucial to this approach is the proper characterization of entities as relation components, which allows the integration of the entity annotation with the syntactic structure while retaining the capacity to annotate and extract more complex events. We are training statistical taggers using this annotation for such extraction as well as using them for improving the annotation process."
W04-2807,Different Sense Granularities for Different Applications,2004,10,44,1,1,4859,martha palmer,Proceedings of the 2nd International Workshop on Scalable Natural Language Understanding ({S}ca{N}a{LU} 2004) at {HLT}-{NAACL} 2004,0,"This paper describes an hierarchical approach to WordNet sense distinctions that provides different types of automatic Word Sense Disambiguation (WSD) systems, which perform at varying levels of accuracy. For tasks where fine-grained sense distinctions may not be essential, an accurate coarse-grained WSD system may be sufficient. The paper discusses the criteria behind the three different levels of sense granularity, as well as the machine learning approach used by the WSD system."
W04-2704,{P}roposition {B}ank {II}: Delving Deeper,2004,19,13,2,0.540541,43023,olga babkomalaya,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,"The PropBank project is creating a corpus of text annotated with information about basic semantic propositions. PropBank I (Kingsbury & Palmer, 2002) added a layer of predicateargument information, or semantic roles, to the syntactic structures of the English Penn Treebank. This paper presents an overview of the second phase of PropBank Annotation, PropBank II, which is being applied to English and Chinese, and includes (Neodavidsonian) eventuality variables, nominal references, sense tagging, and connections to the Penn Discourse Treebank (PDTB), a project for annotating discourse connectives and their arguments."
W04-2604,Using prepositions to extend a verb lexicon,2004,12,8,3,1,50347,karin kipper,Proceedings of the Computational Lexical Semantics Workshop at {HLT}-{NAACL} 2004,0,This paper presents a detailed account of prepositional mismatch between our handcrafted verb lexicon and a semantically annotated corpus. The analysis of these mismatches allows us to refine the lexicon and to create a more robust resource capable of better semantic predictions based on the verb-preposition relations.
W04-2424,Putting Meaning into Your Trees,2004,4,0,1,1,4859,martha palmer,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,"The meaning of a sentence is an essential aspect of natural language understanding, yet an elusive one, since there is no accepted methodology for determining it. There is not even a consensus on criteria for distinguishing word senses. Clearly a more robust technology is needed that uses data-driven techniques. These techniques typically rely on supervised machine learning, so a critical goal is the definition of a level of semantic representation (sense tags and semantic role labels) that could be consistently annotated on a large scale. We have been training automatic WSD systems on the English sense-tagged training data based on WordNet that we supplied to SENSEVAL2 (Dang & Palmer, 2002). A pervasive problem with sense tagging is finding a sense inventory with clear criteria for sense distinctions. WordNet is often criticized for its subtle and fine-grained sense distinctions. Perhaps more consistent and coarse-grained sense distinctions would be more suitable for natural language processing applications. Grouping the highly polysemous verb senses in WordNet (on average reducing the >16 senses per verb to 8) provides an important first step a more flexible granularity for WordNet senses that improves both inter-annotator agreement (71% to 82%) and system performance (60.2% to 69%) (Dang & Palmer, 2002). The Frameset sense tags associated with the PropBank, as discussed below, provide an even more coarse-grained and easily replicable level of sense distinctions."
W04-1513,Synchronous Dependency Insertion Grammars: A Grammar Formalism for Syntax Based Statistical {MT},2004,16,23,2,1,50712,yuan ding,Proceedings of the Workshop on Recent Advances in Dependency Grammar,0,None
W04-0811,The {E}nglish all-words task,2004,2,227,2,0,37815,benjamin snyder,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
P04-1038,{C}hinese Verb Sense Discrimination Using an {EM} Clustering Model with Rich Linguistic Features,2004,11,9,2,1,36926,jinying chen,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"This paper discusses the application of the Expectation-Maximization (EM) clustering algorithm to the task of Chinese verb sense discrimination. The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs. A semantic taxonomy for Chinese nouns, which was built semi-automatically based on two electronic Chinese semantic dictionaries, was used to provide semantic features for the model. Purity and normalized mutual information were used to evaluate the clustering performance on 12 Chinese verbs. The experimental results show that the EM clustering model can learn sense or sense group distinctions for most of the verbs successfully. We further enhanced the model with certain fine-grained semantic categories called lexical sets. Our results indicate that these lexical sets improve the model's performance for the three most challenging verbs chosen from the first set of experiments."
kipper-etal-2004-extending,Extending a Verb-lexicon Using a Semantically Annotated Corpus,2004,10,18,3,1,50347,karin kipper,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,None
W03-1707,Annotating the Propositions in the {P}enn {C}hinese Treebank,2003,9,65,2,0.681818,10294,nianwen xue,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,"In this paper, we describe an approach to annotate the propositions in the Penn Chinese Treebank. We describe how diathesis alternation patterns can be used to make coarse sense distinctions for Chinese verbs as a necessary step in annotating the predicate-structure of Chinese verbs. We then discuss the representation scheme we use to label the semantic arguments and adjuncts of the predicates. We discuss several complications for this type of annotation and describe our solutions. We then discuss how a lexical database with predicate-argument structure information can be used to ensure consistent annotation. Finally, we discuss possible applications for this resource."
2003.mtsummit-papers.13,An algorithm for word-level alignment of parallel dependency trees,2003,13,23,3,1,50712,yuan ding,Proceedings of Machine Translation Summit IX: Papers,0,"Structural divergence presents a challenge to the use of syntax in statistical machine translation. We address this problem with a new algorithm for alignment of loosely matched non-isomorphic dependency trees. The algorithm selectively relaxes the constraints of the two tree structures while keeping computational complexity polynomial in the length of the sentences. Experimentation with a large Chinese-English corpus shows an improvement in alignment results over the unstructured models of (Brown et al., 1993)."
Y02-1007,{P}enn {K}orean Treebank : Development and Evaluation,2001,-1,-1,4,0.885417,31427,chunghye han,"Proceedings of the 16th Pacific Asia Conference on Language, Information and Computation",0,None
W02-0813,Combining Contextual Features for Word Sense Disambiguation,2002,15,27,2,1,34044,hoa dang,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"In this paper we present a maximum entropy Word Sense Disambiguation system we developed which performs competitively on SENSEVAL-2 test data for English verbs. We demonstrate that using richer linguistic contextual features significantly improves tagging accuracy, and compare the system's performance with human annotator performance in light of both fine-grained and coarse-grained sense distinctions made by the sense inventory."
P02-1031,The Necessity of Parsing for Predicate Argument Recognition,2002,14,180,2,0.454545,3945,daniel gildea,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"Broad-coverage corpora annotated with semantic role, or argument structure, information are becoming available for the first time. Statistical systems have been trained to automatically label semantic roles from the output of statistical parsers on unannotated text. In this paper, we quantify the effect of parser accuracy on these systems' performance, and examine the question of whether a flatter chunked representation of the input can be as effective for the purposes of semantic role identification."
han-etal-2002-development,Development and Evaluation of a {K}orean Treebank and its Application to {NLP},2002,14,25,4,0.766667,31427,chunghye han,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,Abstract : This paper discusses issues involved in building a 54-thousand-word Korean Treebank using a phrase structure annotation and the development of annotation guidelines based on the morpho-syntactic phenomena represented in the corpus. The various methods that were employed for quality control are described. An evaluation of the quality of the Treebank and some of the Natural Language Processing (NLP) applications under development using the Treebank also are described.
calzolari-etal-2002-standards,Standards {\\&} best practice for multilingual computational lexicons: {ISLE} {MILE} and more{''},2002,1,5,3,0,18003,nicoletta calzolari,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
atkins-etal-2002-resources,From Resources to Applications. Designing the Multilingual {ISLE} Lexical Entry,2002,4,10,10,0,53506,sue atkins,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
kingsbury-palmer-2002-treebank,From {T}ree{B}ank to {P}rop{B}ank,2002,12,442,2,0,50978,paul kingsbury,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
C02-1143,Simple Features for {C}hinese Word Sense Disambiguation,2002,17,26,3,1,34044,hoa dang,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"In this paper we report on our experiments on automatic Word Sense Disambiguation using a maximum entropy approach for both English and Chinese verbs. We compare the difficulty of the sense-tagging tasks in the two languages and investigate the types of contextual features that are useful for each language. Our experimental results suggest that while richer linguistic features are useful for English WSD, they may not be as beneficial for Chinese."
C02-1145,Building a Large-Scale Annotated {C}hinese Corpus,2002,7,126,3,0.681818,10294,nianwen xue,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"In this paper we address issues related to building a large-scale Chinese corpus. We try to answer four questions: (i) how to speed up annotation, (ii) how to maintain high annotation quality, (iii) for what purposes is the corpus applicable, and finally (iv) what future work we anticipate."
S01-1005,{E}nglish Tasks: All-Words and Verb Lexical Sample,2001,2,95,1,1,4859,martha palmer,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,We describe our experience in preparing the lexicon and sense-tagged corpora used in the English all-words and lexical sample tasks of Senseval-2.
H01-1010,Automatic Predicate Argument Analysis of the {P}enn {T}ree{B}ank,2001,7,15,1,1,4859,martha palmer,Proceedings of the First International Conference on Human Language Technology Research,0,"One of the primary tasks of Information Extraction is recognizing all of the different guises in which a particular type of event can appear. For instance, a meeting between two dignitaries can be referred to as A meets B or A and B meet, or a meeting between A and B took place/was held/opened/convened/finished/dragged on or A had/presided over a meeting/conference with B"
H01-1014,Converting Dependency Structures to Phrase Structures,2001,9,97,2,1,16067,fei xia,Proceedings of the First International Conference on Human Language Technology Research,0,"Treebanks are of two types according to their annotation schemata: phrase-structure Treebanks such as the English Penn Treebank [8] and dependency Treebanks such as the Czech dependency Treebank [6]. Long before Treebanks were developed and widely used for natural language processing, there had been much discussion of comparison between dependency grammars and context-free phrase-structure grammars [5]. In this paper, we address the relationship between dependency structures and phrase structures from a practical perspective; namely, the exploration of different algorithms that convert dependency structures to phrase structures and the evaluation of their performance against an existing Treebank. This work not only provides ways to convert Treebanks from one type of representation to the other, but also clarifies the differences in representational coverage of the two approaches."
H01-1026,Facilitating Treebank Annotation Using a Statistical Parser,2001,15,26,3,0,53648,fudong chiou,Proceedings of the First International Conference on Human Language Technology Research,0,"Corpora of phrase-structure-annotated text, or treebanks, are useful for supervised training of statistical models for natural language processing, as well as for corpus linguistics. Their primary drawback, however, is that they are very time-consuming to produce. To alleviate this problem, the standard approach is to make two passes over the text: first, parse the text automatically, then correct the parser output by hand."
W00-2021,Building a class-based verb lexicon using {TAG}s,2000,10,16,4,1,50347,karin kipper,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,"We present a class-based approach to building a verb lexicon that makes explicit the close relation between syntax and semantics for Levin classes. We have used a Lexicalized Tree Adjoining Grammar to capture the syntax associated with each verb class and have added semantic predicates to each tree, which allow for a compositional interpretation."
W00-2028,Lexicalized grammar and the description of motion events,2000,21,8,4,0,7129,matthew stone,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,"In natural language generation, the use of a lexicalized grammar formalism and incremental syntactic and semantic processing places strong and specific constraints on the form and meaning of grammatical entries. These principles restrict which grammatical representations are possible and suggest examples an analyst can consult to decide among possibilities. We discuss and justify a number of such constraints, and describe how they inform the design of lexical entries for motion verbs. Our entries allow a generator to match the lexical choices found in a target corpus of action descriptions by assessing how the interpretation of a verb in context contributes towards the hearerxe2x80x99s identification of the intended action."
W00-2041,Comparing and integrating {T}ree {A}djoining {G}rammars,2000,1,2,2,1,16067,fei xia,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,None
W00-1307,A Uniform Method of Grammar Extraction and Its Applications,2000,26,44,2,1,16067,fei xia,2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"Grammars are core elements of many NLP applications. In this paper, we present a system that automatically extracts lexicalized grammars from annotated corpora. The data produced by this system have been used in several tasks, such as training NLP tools (such as Supertaggers) and estimating the coverage of hand-crafted grammars. We report experimental results on two of those tasks and compare our approaches with related work."
W00-1208,"Comparing Lexicalized Treebank Grammars Extracted from {C}hinese, {K}orean, and {E}nglish Corpora",2000,9,9,3,1,16067,fei xia,Second {C}hinese Language Processing Workshop,0,"In this paper, we present a method for comparing Lexicalized Tree Adjoining Grammars extracted from annotated corpora for three languages: English, Chinese and Korean. This method makes it possible to do a quantitative comparison between the syntactic structures of each language, thereby providing a way of testing the Universal Grammar Hypothesis, the foundation of modern linguistic theories."
W00-0505,Towards Translingual Information Access using Portable Information Extraction,2000,10,1,6,0,1437,michael white,{ANLP}-{NAACL} 2000 Workshop: Embedded Machine Translation Systems,0,"We report on a small study undertaken to demonstrate the feasibility of combining portable information extraction with MT in order to support translingual information access. After describing the proposed system's usage scenario and system design, we describe our investigation of transferring information extraction techniques developed for English to Korean. We conclude with a brief discussion of related MT issues we plan to investigate in future work."
W00-0202,Representations of Actions as an Interlingua,2000,12,11,2,1,50347,karin kipper,{NAACL}-{ANLP} 2000 Workshop: Applied Interlinguas: Practical Applications of Interlingual Approaches to {NLP},0,"We present a Parameterized Action Representation (PAR) that provides a conceptual representation of different types of actions used to animate virtual human agents in a simulated 3D environment. These actions involve changes of state, changes of location (kinematic) and exertion of force (dynamic). PARs are hierarchical, parameterized structures that facilitate both visual and verbal expressions. In order to support the animation of the actions, PARs have tomake explicit many details that are often underspecified in the language. This detailed level of representation also provides a suitable pivot representation for generation in other natural languages, i.e., a form of interlingua. We show examples of how certain divergences in machine translation can be solved by our approach focusing specifically on how verb-framed and satellite-framed languages can use our representation."
palmer-etal-2000-semantic,Semantic Tagging for the {P}enn {T}reebank,2000,10,6,1,1,4859,martha palmer,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"This paper describes the methodology that is being used to augment the Penn Treebank annotation with sense tags and other types of semantic information. Inspired by the results of SENSEVAL, and the high inter-annotator agreement that was achieved there, similar methods were used for a pilot study of 5000 words of running text from the Penn Treebank. Using the same techniques of allowing the annotators to discuss difficult tagging cases and to revise WordNet entries if necessary, comparable inter-annotator rates have been achieved. The criteria for determining appropriate revisions and ensuring clear sense distinctions are described. We are also using hand correction of automatic predicate argument structure information to provide additional thematic role labeling."
xia-etal-2000-developing,Developing Guidelines and Ensuring Consistency for {C}hinese Text Annotation,2000,-1,-1,2,1,16067,fei xia,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,None
C00-2148,Integrating compositional semantics into a verb lexicon,2000,14,27,3,1,34044,hoa dang,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"We present a class-based approach to building a verb lexicon that makes explicit the close association between syntax and semantics for Levin classes. We have used Lexicalized Tree Adjoining Grammars to capture the syntax associated with each verb class and have augmented the trees to include selectional restrictions. In addition, semantic predicates are associated with each tree, which allow for a compositional interpretation."
han-etal-2000-handling,Handling structural divergences and recovering dropped arguments in a {K}orean/{E}nglish machine translation system,2000,10,34,3,0.885417,31427,chunghye han,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper describes an approach for handling structural divergences and recovering dropped arguments in an implemented Korean to English machine translation system. The approach relies on canonical predicate-argument structures (or dependency structures), which provide a suitable pivot representation for the handling of structural divergences and the recovery of dropped arguments. It can also be converted to and from the interface representations of many off-the-shelf parsers and generators."
zhao-etal-2000-machine,A machine translation system from {E}nglish to {A}merican {S}ign {L}anguage,2000,24,107,6,0,54802,liwei zhao,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"Research in computational linguistics, computer graphics and autonomous agents has led to the development of increasingly sophisticated communicative agents over the past few years, bringing new perspective to machine translation research. The engineering of language- based smooth, expressive, natural-looking human gestures can give us useful insights into the design principles that have evolved in natural communication between people. In this paper we prototype a machine translation system from English to American Sign Language (ASL), taking into account not only linguistic but also visual and spatial information associated with ASL signs."
W98-0104,Motion verbs and semantic features in {TAG},1998,0,0,2,1,42142,tonia bleam,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
W98-0143,Consistent grammar development using partial-tree descriptions for {L}exicalized {T}ree-{A}djoining {G}rammars,1998,3,14,2,1,16067,fei xia,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
P98-1046,Investigating Regular Sense Extensions based on Intersective {L}evin Classes,1998,7,86,3,1,34044,hoa dang,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"In this paper we specifically address questions of polysemy with respect to verbs, and how regular extensions of meaning can be achieved through the adjunction of particular syntactic phrases. We see verb classes as the key to making generalizations about regular extensions of meaning. Current approaches to English classification, Levin classes and WordNet, have limitations in their applicability that impede their utility as general classification schemes. We present a refinement of Levin classes, intersective sets, which are a more fine-grained classification and have more coherent sets of syntactic frames and associated semantic components. We have preliminary indications that the membership of our intersective sets will be more compatible with WordNet than the original Levin classes. We also have begun to examine related classes in Portuguese, and find that these verbs demonstrate similarly coherent syntactic and semantic properties."
C98-1046,Investigating regular sense extensions based on intersective Levin classes,1998,7,86,3,1,34044,hoa dang,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"In this paper we specifically address questions of polysemy with respect to verbs, and how regular extensions of meaning can be achieved through the adjunction of particular syntactic phrases. We see verb classes as the key to making generalizations about regular extensions of meaning. Current approaches to English classification, Levin classes and WordNet, have limitations in their applicability that impede their utility as general classification schemes. We present a refinement of Levin classes, intersective sets, which are a more fine-grained classification and have more coherent sets of syntactic frames and associated semantic components. We have preliminary indications that the membership of our intersective sets will be more compatible with WordNet than the original Levin classes. We also have begun to examine related classes in Portuguese, and find that these verbs demonstrate similarly coherent syntactic and semantic properties."
palmer-etal-1998-rapid,Rapid prototyping of domain-apecific machine translation systems,1998,9,14,1,1,4859,martha palmer,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper reports on an experiment in assembling a domain-specific machine translation prototype system from off-the-shelf components. The design goals of this experiment were to reuse existing components, to use machine-learning techniques for parser specialization and for transfer lexicon extraction, and to use an expressive, lexicalized formalism for the transfer component."
A97-2014,An {E}nglish Grammar Checker as a Writing Aid for Students of {E}nglish as a Second Language,1997,0,21,2,0,2116,jong park,Fifth Conference on Applied Natural Language Processing: Descriptions of System Demonstrations and Videos,0,None
1997.mtsummit-workshop.2,Associating semantic components with intersective Levin classes,1997,6,3,3,1,34044,hoa dang,AMTA/SIG-IL First Workshop on Interlinguas,0,None
1997.mtsummit-workshop.12,Enriching lexical transfer with cross-linguistic semantic features or how to do interlingua without interlingua,1997,7,12,3,0,5812,alexis nasr,AMTA/SIG-IL First Workshop on Interlinguas,0,"In this paper, we propose an alternative to interlingua which can capture the analyses and generalizations that interlinguas can express, but which uses cross-linguistic semantic features rather than a separate level of representation. This alternative we call lexico-structural transfer. Lexico-structural transfer relies on the expressive power of a lexicalized syntactic representation (or xe2x80x9clexicalized grammarxe2x80x9d for short). In a lexicalized grammar, lexemes are associated with syntactic structure; in the transfer lexicon, we do not simply relate words (or context-free rewrite rules) from one language to words (or context-free rewrite rules) from another language. Instead, we relate lexemes along with relevant syntactic structure (essentially, their syntactic projection along with syntactic and lexical-semantic features). Several different lexicalized grammar formalisms have been proposed in the past, including notably Tree Adjoining Grammar (Joshi, 1987), Lexical-Functional Grammar (Kaplan and Bresnan, 1982) and various dependency grammars. We will present our work using a transfer formalism based on a dependency grammar, namely Melxe2x80x99cukxe2x80x99s Meaning Text Theory (MTT) (Melxe2x80x99cuk, 1988), specifically the xe2x80x9cDeep Syntactic Levelxe2x80x9d. This level of representation is similar in crucial respects to the derivation structures of TAG (Rambow and Joshi, 1996) and to the f-structure of LFG. There are two main reasons why we may want to investigate an alternative to the use of an interlingua:"
J96-4004,A Statistically Emergent Approach for Language Processing: Application to Modeling Context Effects in Ambiguous {C}hinese Word Boundary Perception,1996,17,24,2,0,55934,kokwee gan,Computational Linguistics,0,"This paper proposes that the process of language understanding can be modeled as a collective phenomenon that emerges from a myriad of microscopic and diverse activities. The process is analogous to the crystallization process in chemistry. The essential features of this model are: asynchronous parallelism; temperature-controlled randomness; and statistically emergent active symbols. A computer program that tests this model on the task of capturing the effect of context on the perception of ambiguous word boundaries in Chinese sentences is presented. The program adopts a holistic approach in which word identification forms an integral component of sentence analysis. Various types of knowledge, from statistics to linguistics, are seamlessly integrated for the tasks of word boundary disambiguation as well as sentential analysis. Our experimental results showed that the model is able to address the word boundary ambiguity problems effectively."
1996.amta-1.8,Capturing motion verb generalizations in synchronous tree adjoining grammars,1996,-1,-1,1,1,4859,martha palmer,Conference of the Association for Machine Translation in the Americas,0,None
P94-1019,Verb Semantics and Lexical Selection,1994,9,2255,2,0,54504,zhibiao wu,32nd Annual Meeting of the Association for Computational Linguistics,1,"This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentences as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection."
O93-2003,Developing a {C}hinese Module in {UNITRAN},1993,0,0,3,0,54504,zhibiao wu,{ROCLING} 1993 Short Papers,0,None
W91-0218,General Lexical Representation for an Effect Predicate,1991,6,0,1,1,4859,martha palmer,Lexical Semantics and Knowledge Representation,0,"This paper argues that there is no reason to distinguish between lexical information and real-world information on the basis of the formalisms used; that both types of knowledge can be expressed in the same formalism. However, it also argues that there is information that is uniquely lexical in content, and this information consists of verb-independent definitions for thematic relations such as cause and effect that alter the representation of a verb depending on the presence or absence of certain verb arguments."
J90-3005,Workshop on the Evaluation of Natural Language Processing Systems,1990,5,35,1,1,4859,martha palmer,Computational Linguistics,0,None
H89-1048,"Natural Language Understanding: Integrating Syntax, Semantics, and Discourse.",1989,0,0,2,0,45475,lynette hirschman,"Speech and Natural Language: Proceedings of a Workshop Held at Philadelphia, {P}ennsylvania, {F}ebruary 21-23, 1989",0,"Technical Summary: The focus of the UNISYS research is on integrating multiple knowledge sources, including syntax, semantics, pragmatics, a domain model, and both domain-specific and domain-independent knowledge sources, to produce a system capable of understanding messages in a restricted domain."
P87-1019,Nominalizations in {PUNDIT},1987,10,34,2,0,55257,deborah dahl,25th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes the treatment of nominalizations in the PUNDIT text processing system. A single semantic definition is used for both nominalizations and the verbs to which they are related, with the same semantic roles, decompositions, and selectional restrictions on the semantic roles. However, because syntactically nominalizations are noun phrases, the processing which produces the semantic representation is different in several respects from that used for clauses. (1) The rules relating the syntactic positions of the constituents to the roles that they can fill are different. (2) The fact that nominalizations are untensed while clauses normally are tensed means that an alternative treatment of time is required for nominalizations. (3) Because none of the arguments of a nominalization is syntactically obligatory, some differences in the control of the filling of roles are required, in particular, roles can be filled as part of reference resolution for the nominalization. The differences in processing are captured by allowing the semantic interpreter to operate in two different modes, one for clauses, and one for nominalizations. Because many nominalizations are noun-noun compounds, this approach also addresses this problem, by suggesting a way of dealing with one relatively tractable subset of noun-noun compounds."
P86-1004,Recovering Implicit Information,1986,12,62,1,1,4859,martha palmer,24th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes the SDC PUNDIT, (Prolog UNDerstands Integrated Text), system for processing natural language messages. PUNDIT, written in Prolog, is a highly modular system consisting of distinct syntactic, semantic and pragmatics components. Each component draws on one or more sets of data, including a lexicon, a broad-coverage grammar of English, semantic verb decompositions, rules mapping between syntactic and semantic constituents, and a domain model.This paper discusses the communication between the syntactic, semantic and pragmatic modules that is necessary for making implicit linguistic information explicit. The key is letting syntax and semantics recognize missing linguistic entities as implicit entities, so that they can be labelled as such, and reference resolution can be directed to find specific referents for the entities. In this way the task of making implicit linguistic information explicit becomes a subset of the tasks performed by reference resolution. The success of this approach is dependent on marking missing syntactic constituents as elided and missing semantic roles as ESSENTIAL so that reference resolution can know when to look for referents."
H86-1011,Recovering Implicit Information,1986,12,62,1,1,4859,martha palmer,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"This paper describes the SDC PUNDIT, (Prolog UNDerstands Integrated Text), system for processing natural language messages. PUNDIT, written in Prolog, is a highly modular system consisting of distinct syntactic, semantic and pragmatics components. Each component draws on one or more sets of data, including a lexicon, a broad-coverage grammar of English, semantic verb decompositions, rules mapping between syntactic and semantic constituents, and a domain model.This paper discusses the communication between the syntactic, semantic and pragmatic modules that is necessary for making implicit linguistic information explicit. The key is letting syntax and semantics recognize missing linguistic entities as implicit entities, so that they can be labelled as such, and reference resolution can be directed to find specific referents for the entities. In this way the task of making implicit linguistic information explicit becomes a subset of the tasks performed by reference resolution. The success of this approach is dependent on marking missing syntactic constituents as elided and missing semantic roles as ESSENTIAL so that reference resolution can know when to look for referents."
A83-1010,Parsing With Logical Variables,1983,8,3,2,0,58498,timothy finin,First Conference on Applied Natural Language Processing,0,"Logic based programming systems have enjoyed an increasing popularity in applied AI work in the last few years. One of the contributions to Computational Linguistics made by the Logic Programming Paradigm has been the Definite Clause Grammar. In comparing DCG's with previous parsing mechanisms such as ATN's, certain clear advantages are seen. We feel that the most important of these advantages are due to the use of Logical Variables with Unification as the fundamental operation on them. To illustrate the power of the Logical Variable, we have implemented an experimental ATN system which treats ATN registers as Logical Variables and provides a unification operation over them. We would like to simultaneously encourage the use of the powerful mechanisms available in DCG's, and demonstrate that some of these techniques can be captured without reference to a resolution theorem prover."
P81-1029,A Case for Rule-Driven Semantic Processing,1981,5,6,1,1,4859,martha palmer,19th Annual Meeting of the Association for Computational Linguistics,1,None
