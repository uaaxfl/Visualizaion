2020.alw-1.6,Abusive Language Detection using Syntactic Dependency Graphs,2020,-1,-1,2,0,22389,kanika narang,Proceedings of the Fourth Workshop on Online Abuse and Harms,0,"Automated detection of abusive language online has become imperative. Current sequential models (LSTM) do not work well for long and complex sentences while bi-transformer models (BERT) are not computationally efficient for the task. We show that classifiers based on syntactic structure of the text, dependency graphical convolutional networks (DepGCNs) can achieve state-of-the-art performance on abusive language datasets. The overall performance is at par with of strong baselines such as fine-tuned BERT. Further, our GCN-based approach is much more efficient than BERT at inference time making it suitable for real-time detection."
S18-1145,Digital Operatives at {S}em{E}val-2018 Task 8: Using dependency features for malware {NLP},2018,0,1,1,1,22390,chris brew,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"The four sub-tasks of SecureNLP build towards a capability for quickly highlighting critical information from malware reports, such as the specific actions taken by a malware sample. Digital Operatives (DO) submitted to sub-tasks 1 and 2, using standard text analysis technology (text classification for sub-task 1, and a CRF for sub-task 2). Performance is broadly competitive with other submitted systems on sub-task 1 and weak on sub-task 2. The annotation guidelines for the intermediate sub-tasks create a linkage to the final task, which is both an annotation challenge and a potentially useful feature of the task. The methods that DO chose do not attempt to make use of this linkage, which may be a missed opportunity. This motivates a post-hoc error analysis. It appears that the annotation task is very hard, and that in some cases both deep conceptual knowledge and substantial surrounding context are needed in order to correctly classify sentences."
W16-0315,Classifying {R}each{O}ut posts with a radial basis function {SVM},2016,6,10,1,1,22390,chris brew,Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology,0,"The ReachOut clinical psychology shared task challenge addresses the problem of providing an automatic triage for posts to a support forum for people with a history of mental health issues. Posts are classified into green, amber, red and crisis. The non-green categories correspond to increasing levels of urgency for some form of intervention. The Thomson Reuters submissions arose from an idea about self-training and ensemble learning. The available labeled training set is small (947 examples) and the class distribution unbalanced. It was therefore hoped to develop a method that would make use of the larger dataset of unlabeled posts provided by the organisers. This did not work, but the performance of a radial basis function SVM intended as a baseline was relatively good. Therefore, the report focuses on the latter, aiming to understand the reasons for its performance."
N15-3021,Natural Language Question Answering and Analytics for Diverse and Interlinked Datasets,2015,22,9,4,0,24711,dezhao song,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"Previous systems for natural language questions over complex linked datasets require the user to enter a complete and well-formed question, and present the answers as raw lists of entities. Using a feature-based grammar with a full formal semantics, we have developed a system that is able to support rich autosuggest, and to deliver dynamically generated analytics for each result that it returns."
S13-2045,{S}em{E}val-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge,2013,26,71,3,0.296596,41055,myroslava dzikovska,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"We present the results of the Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge, aiming to bring together researchers in educational NLP technology and textual entailment. The task of giving feedback on student answers requires semantic inference and therefore is related to recognizing textual entailment. Thus, we offered to the community a 5-way student response labeling task, as well as 3-way and 2way RTE-style tasks on educational data. In addition, a partial entailment task was piloted. We present and compare results from 9 participating teams, and discuss future directions."
N12-1021,Towards Effective Tutorial Feedback for Explanation Questions: A Dataset and Baselines,2012,28,48,3,0.296596,41055,myroslava dzikovska,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We propose a new shared task on grading student answers with the goal of enabling well-targeted and flexible feedback in a tutorial dialogue setting. We provide an annotated corpus designed for the purpose, a precise specification for a prediction task and an associated evaluation methodology. The task is feasible but non-trivial, which is demonstrated by creating and comparing three alternative baseline systems. We believe that this corpus will be of interest to the researchers working in textual entailment and will stimulate new developments both in natural language processing in tutorial dialogue systems and textual entailment, contradiction detection and other techniques of interest for a variety of computational linguistics tasks."
I11-1022,Semantic Role Labeling Without Treebanks?,2011,16,3,2,1,44758,stephen boxwell,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We describe a method for training a semantic role labeler for CCG in the absence of gold-standard syntax derivations. Traditionally, semantic role labeling is performed by placing human-annotated semantic roles on gold-standard syntactic parses, identifying patterns in the syntaxsemantics relationship, and then predicting roles on novel syntactic analyses. The gold standard syntactic training data can be eliminated from the process by extracting training instances from semantic roles projected onto a packed parse chart. This process can be used to rapidly develop NLP tools for resource-poor languages of interest."
boxwell-brew-2010-pilot,A Pilot {A}rabic {CCG}bank,2010,10,4,2,1,44758,stephen boxwell,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We describe a process for converting the Penn Arabic Treebank into the CCG formalism. Previous efforts have yielded CCGbanks in English, German, and Turkish, thus opening these languages to the sophisticated computational tools developed for CCG and enabling further cross-linguistic development. Conversion from a context free grammar treebank to a CCGbank is a four stage process: head finding, argument classification, binarization, and category conversion. In the process of implementing a basic CCGbank conversion algorithm, we reveal properties of Arabic grammar that interfere with conversion, such as subject topicalization, genitive constructions, relative clauses, and optional pronominal subjects. All of these problematic phenomena can be resolved in a variety of ways - we discuss advantages and disadvantages of each in their respective sections. We detail these and describe our categorial analysis of each of these Arabic grammatical phenomena in depth, as well as technical details on their integration into the conversion algorithm."
D10-1072,What a Parser Can Learn from a Semantic Role Labeler and Vice Versa,2010,12,4,3,1,44758,stephen boxwell,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser's packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles."
W09-3304,Using the {W}iktionary Graph Structure for Synonym Detection,2009,12,19,2,0,46904,timothy weale,Proceedings of the 2009 Workshop on The People{'}s Web Meets {NLP}: Collaboratively Constructed Semantic Resources (People{'}s Web),0,"This paper presents our work on using the graph structure of Wiktionary for synonym detection. We implement semantic relatedness metrics using both a direct measure of information flow on the graph and a comparison of the list of vertices found to be close to a given vertex. Our algorithms, evaluated on ESL 50, TOEFL 80 and RDWP 300 data sets, perform better than or comparable to existing semantic relatedness measures."
P09-1005,"{B}rutus: A Semantic Role Labeling System Incorporating {CCG}, {CFG}, and Dependency Features",2009,20,14,3,1,44758,stephen boxwell,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"We describe a semantic role labeling system that makes primary use of CCG-based features. Most previously developed systems are CFG-based and make extensive use of a treepath feature, which suffers from data sparsity due to its use of explicit tree configurations. CCG affords ways to augment treepath-based features to overcome these data sparsity issues. By adding features over CCG word-word dependencies and lexicalized verbal subcategorization frames (supertags), we can obtain an F-score that is substantially better than a previous CCG-based SRL system and competitive with the current state of the art. A manual error analysis reveals that parser errors account for many of the errors of our system. This analysis also suggests that simultaneous incremental parsing and semantic role labeling may lead to performance gains in both tasks."
P08-1050,Which Are the Best Features for Automatic Verb Classification,2008,22,21,2,1,47912,jianguo li,Proceedings of ACL-08: HLT,1,"In this work, we develop and evaluate a wide range of feature spaces for deriving Levinstyle verb classifications (Levin, 1993). We perform the classification experiments using Bayesian Multinomial Regression (an efficient log-linear modeling framework which we found to outperform SVMs for this task) with the proposed feature spaces. Our experiments suggest that subcategorization frames are not the most effective features for automatic verb classification. A mixture of syntactic information and lexical information works best for this task."
baker-brew-2008-statistical,Statistical Identification of {E}nglish Loanwords in {K}orean Using Automatically Generated Training Data,2008,0,4,2,0,48053,kirk baker,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper describes an accurate, extensible method for automatically classifying unknown foreign words that requires minimal monolingual resources and no bilingual training data (which is often difficult to obtain for an arbitrary language pair). We use a small set of phonologically-based transliteration rules to generate a potentially unlimited amount of pseudo-data that can be used to train a classifier to distinguish etymological classes of actual words. We ran a series of experiments on identifying English loanwords in Korean, in order to explore the consequences of using pseudo-data in place of the original training data. Results show that a sufficient quantity of automatically generated training data, even produced by fairly low precision transliteration rules, can be used to train a classifier that performs within 0.3{\%} of one trained on actual English loanwords (96{\%} accuracy)."
W07-1013,A shared task involving multi-label classification of clinical free text,2007,14,240,2,0,33830,john pestian,"Biological, translational, and clinical language processing",0,"This paper reports on a shared task involving the assignment of ICD-9-CM codes to radiology reports. Two features distinguished this task from previous shared tasks in the biomedical domain. One is that it resulted in the first freely distributable corpus of fully anonymized clinical text. This resource is permanently available and will (we hope) facilitate future research. The other key feature of the task is that it required categorization with respect to a large and commercially significant set of labels. The number of participants was larger than in any previous biomedical challenge task. We describe the data production process and the evaluation measures, and give a preliminary analysis of the results. Many systems performed at levels approaching the inter-coder agreement, suggesting that human-like performance on this task is within the reach of currently available technologies."
2007.tmi-papers.15,{BLEU{\\^A}TRE}: flattening syntactic dependencies for {MT} evaluation,2007,-1,-1,2,1,40043,dennis mehay,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
W06-2005,Tagging {P}ortuguese with a {S}panish Tagger,2006,21,22,4,0,31440,jirka hana,Proceedings of the Cross-Language Knowledge Induction Workshop,0,"We describe a knowledge and resource light system for an automatic morphological analysis and tagging of Brazilian Portuguese. We avoid the use of labor intensive resources; particularly, large annotated corpora and lexicons. Instead, we use (i) an annotated corpus of Peninsular Spanish, a language related to Portuguese, (ii) an unannotated corpus of Portuguese, (iii) a description of Portuguese morphology on the level of a basic grammar book. We extend the similar work that we have done (Hana et al., 2004; Feldman et al., 2006) by proposing an alternative algorithm for cognate transfer that effectively projects the Spanish emission probabilities into Portuguese. Our experiments use minimal new human effort and show 21% error reduction over even emissions on a fine-grained tagset."
P06-2067,Parsing and Subcategorization Data,2006,21,4,2,1,47912,jianguo li,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"In this paper, we compare the performance of a state-of-the-art statistical parser (Bikel, 2004) in parsing written and spoken language and in generating subcategorization cues from written and spoken language. Although Bikel's parser achieves a higher accuracy for parsing written language, it achieves a higher accuracy when extracting subcategorization cues from spoken language. Our experiments also show that current technology for extracting subcategorization frames initially designed for written texts works equally well for spoken language. Additionally, we explore the utility of punctuation in helping parsing and extraction of subcategorization cues. Our experiments show that punctuation is of little help in parsing spoken language and extracting subcategorization cues from spoken language. This indicates that there is no need to add punctuation in transcribing spoken corpora simply in order to help parsers."
P06-1007,A Finite-State Model of Human Sentence Processing,2006,22,4,2,0,49900,jihyun park,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"It has previously been assumed in the psycholinguistic literature that finite-state models of language are crucially limited in their explanatory power by the locality of the probability distribution and the narrow scope of information used by the model. We show that a simple computational model (a bigram part-of-speech tagger based on the design used by Corley and Crocker (2000)) makes correct predictions on processing difficulty observed in a wide range of empirical sentence processing data. We use two modes of evaluation: one that relies on comparison with a control sentence, paralleling practice in human studies; another that measures probability drop in the disambiguating region of the sentence. Both are surprisingly good indicators of the processing difficulty of garden-path sentences. The sentences tested are drawn from published sources and systematically explore five different types of ambiguity: previous studies have been narrower in scope and smaller in scale, We do not deny the limitations of finite-state models, but argue that our results show that their usefulness has been underestimated."
feldman-etal-2006-cross,A Cross-language Approach to Rapid Creation of New Morpho-syntactically Annotated Resources,2006,9,27,3,1,2888,anna feldman,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We take a novel approach to rapid, low-cost development of morpho-syntactically annotated resources without using parallel corpora or bilingual lexicons. The overall research question is how to exploit language resources and properties to facilitate and automate the creation of morphologically annotated corpora for new languages. This portability issue is especially relevant to minority languages, for which such resources are likely to remain unavailable in the foreseeable future. We compare the performance of our system on languages that belong to different language families (Romance vs. Slavic), as well as different language pairs within the same language family (Portuguese via Spanish vs. Catalan via Spanish). We show that across language families, the most difficult category is the category of nominals (the noun homonymy is challenging for morphological analysis and the order variation of adjectives within a sentence makes it challenging to create a realiable model), whereas different language families present different challenges with respect to their morpho-syntactic descriptions: for the Slavic languages, case is the most challenging category; for the Romance languages, gender is more challenging than case. In addition, we present an alternative evaluation metric for our system, where we measure how much human labor will be needed to convert the result of our tagging to a high precision annotated resource."
W05-1529,Robust Extraction of Subcategorization Data from Spoken Language,2005,8,1,2,1,47912,jianguo li,Proceedings of the Ninth International Workshop on Parsing Technology,0,"Subcategorization data has been crucial for various NLP tasks. Current method for automatic SCF acquisition usually proceeds in two steps: first, generate all SCF cues from a corpus using a parser, and then filter out spurious SCF cues with statistical tests. Previous studies on SCF acquisition have worked mainly with written texts; spoken corpora have received little attention. Transcripts of spoken language pose two challenges absent in written texts: uncertainty about utterance segmentation and disfluency."
W05-0103,{``}Language and {C}omputers{''}: Creating an Introduction for a General Undergraduate Audience,2005,3,1,1,1,22390,chris brew,Proceedings of the Second {ACL} Workshop on Effective Tools and Methodologies for Teaching {NLP} and {CL},0,"This paper describes the creation of Language and Computers, a new course at the Ohio State University designed to be a broad overview of topics in computational linguistics, focusing on applications which have the most immediate relevance to students. This course satisfies the mathematical and logical analysis requirement at Ohio State by using natural language systems to motivate students to exercise and develop a range of basic skills in formal and computational analysis. In this paper we discuss the design of the course, focusing on the success we have had in offering it, as well as some of the difficulties we have faced."
W04-3229,A Resource-light Approach to {R}ussian Morphology: Tagging {R}ussian using {C}zech resources,2004,13,38,3,0,51334,jiri hana,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we describe a resource-light system for the automatic morphological analysis and tagging of Russian. We eschew the use of extensive resources (particularly, large annotated corpora and lexicons), exploiting instead (i) pre-existing annotated corpora of Czech; (ii) an unannotated corpus of Russian. We show that our approach has benefits, and present what we believe to be one of the first full evaluations of a Russian tagger in the openly available literature."
P04-1003,A Distributional Model of Semantic Context Effects in Lexical Processing,2004,56,21,2,0,51746,scott mcdonald,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"One of the most robust findings of experimental psycholinguistics is that the context in which a word is presented influences the effort involved in processing that word. We present a computational model of contextual facilitation based on word co-occurrence vectors, and empirically validate the model through simulation of three representative types of context manipulation: single word priming, multiple-priming and contextual constraint. The aim of our study is to find out whether special-purpose mechanisms are necessary in order to capture the pattern of the experimental results."
J04-1003,Verb Class Disambiguation Using Informative Priors,2004,53,60,2,0,3314,mirella lapata,Computational Linguistics,0,"Levin's (1993) study of verb classes is a widely used resource for lexical semantics. In her framework, some verbs, such as give, exhibit no class ambiguity. But other verbs, such as write, have several alternative classes. We extend Levin's inventory to a simple statistical model of verb class ambiguity. Using this model we are able to generate preferences for ambiguous verbs without the use of a disambiguated corpus. We additionally show that these preferences are useful as priors for a verb sense disambiguator."
J03-1007,Book Review: The {C}ambridge Grammar of the {E}nglish Language by Rodney Huddleston and Geoffrey {K}. Pullum,2003,0,0,1,1,22390,chris brew,Computational Linguistics,0,None
W02-1813,Using the Segmentation Corpus to Define an Inventory of Concatenative Units for {C}antonese Speech Synthesis,2002,1,4,2,0,53156,wai wong,{COLING}-02: The First {SIGHAN} Workshop on {C}hinese Language Processing,0,"The problem of word segmentation affects all aspects of Chinese language processing, including the development of text-to-speech synthesis systems. In synthesizing a Hong Kong Cantonese text, for example, words must be identified in order to model fusion of coda [p] with initial [h], and other similar effects that differentiate word-internal syllable boundaries from syllable edges that begin or end words. Accurate segmentation is necessary also for developing any list of words large enough to identify the word-internal cross-syllable sequences that must be recorded to model such effects using concatenated synthesis units. This paper describes our use of the Segmentation Corpus to constrain such units."
W02-1016,Spectral Clustering for {G}erman Verbs,2002,20,61,1,1,22390,chris brew,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"We describe and evaluate the application of a spectral clustering technique (Ng et al., 2002) to the unsupervised clustering of German verbs. Our previous work has shown that standard clustering techniques succeed in inducing Levin-style semantic classes from verb subcategorisation information. But clustering in the very high dimensional spaces that we use is fraught with technical and conceptual difficulties. Spectral clustering performs a dimensionality reduction on the verb frame patterns, and provides a robustness and efficiency that standard clustering methods do not display in direct use. The clustering results are evaluated according to the alignment (Christianini et al., 2002) between the Gram matrix defined by the cluster output and the corresponding matrix defined by a gold standard."
P02-1029,Inducing {G}erman Semantic Verb Classes from Purely Syntactic Subcategorisation Information,2002,15,72,2,0,631,sabine walde,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"The paper describes the application of k-Means, a standard clustering technique, to the task of inducing semantic classes for German verbs. Using probability distributions over verb subcategorisation frames, we obtained an intuitively plausible clustering of 57 verbs into 14 classes. The automatic clustering was evaluated against independently motivated, hand-constructed semantic verb classes. A series of post-hoc cluster analyses explored the influence of specific frames and frame groups on the coherence of the verb classes, and supported the tight connection between the syntactic behaviour of the verbs and their lexical meaning components."
2002.tmi-papers.5,Stone soup translation,2002,-1,-1,2,0,49418,paul davis,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
J01-3007,Book Reviews: Advances in Probabilistic and Other Parsing Technologies,2001,6,0,1,1,22390,chris brew,Computational Linguistics,0,None
W99-0632,Using Subcategorization to Resolve Verb Class Ambiguity,1999,14,43,2,0,52903,maria lapata,1999 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"Levin's (1993) taxonomy of verbs and their classes is a widely used resource for lexical semantics. In her framework, some verbs, such as give exhibit no class ambiguity. But other verbs, such as write, can inhabit more than one class. In some of these ambiguous cases the appropriate class for a particular token of a verb is immediately obvious from inspection of the surrounding context. In others it is not, and an application which wants to recover this information will be forced to rely on some more or less elaborate process of inference. We present a simple statistical model of verb class ambiguity and show how it can be used to carry out such inference."
Y98-1021,Error-Driven Learning of {C}hinese Word Segmentation,1998,6,25,2,0,8351,julia hockenmaier,"Proceedings of the 12th Pacific Asia Conference on Language, Information and Computation",0,"Palmer ([4]) demonstrated how Brill's Transformation-based Error-Driven Learning can be applied to word segmentation in various languages. We present experimental results which show that such algorithms can achieve satisfactory performance even with a a very dimple initial state annotator We also present two preliminary studies, which suggest that even higher performance might be achieved if simple morphological information is available to the system, and that segmentation performance might actually be improved by combining segmentation with rudimentary part-of-speech tagging."
A97-1034,Using {SGML} as a Basis for Data-Intensive {NLP},1997,7,27,2,0,54493,david mckelvie,Fifth Conference on Applied Natural Language Processing,0,"This paper describes the LT NSL system (McKelvie et al, 1996), an architecture for writing corpus processing tools. This system is then compared with two other systems which address similar issues, the GATE system (Cunningham et al, 1995) and the IMS Corpus Workbench (Christ, 1994). In particular we address the advantages and disadvantages of an SGML approach compared with a non-SGML database approach."
E95-1012,Stochastic {HPSG},1995,6,43,1,1,22390,chris brew,Seventh Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper we provide a probabilistic interpretation for typed feature structures very similar to those used by Pollard and Sag. We begin with a version of the interpretation which lacks a treatment of re-entrant feature structures, then provide an extended interpretation which allows them. We sketch algorithms allowing the numerical parameters of our probabilistic interpretations of HPSG to be estimated from corpora."
P94-1003,Priority Union and Generalization in Discourse Grammars,1994,11,25,2,0,18408,claire grover,32nd Annual Meeting of the Association for Computational Linguistics,1,"We describe an implementation in Carpenter's typed feature formalism, ALE, of a discourse grammar of the kind proposed by Scha, Polanyi, et al. We examine their method for resolving parallelism-dependent anaphora and show that there is a coherent feature-structural rendition of this type of grammar which uses the operations of priority union and generalization. We describe an augmentation of the ALE system to encompass these operations and we show that an appropriate choice of definition for priority union gives the desired multiple output for examples of VP-ellipsis which exhibit a strict/sloppy ambiguity."
H94-1019,Automatic Evaluation of Computer Generated Text: A Progress Report on the {T}ext{E}val Project,1994,6,15,1,1,22390,chris brew,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"We present results of experiments designed to assess the usefulness of a new technique for the evaluation of translation quality, comparing human rankings with automatic measures. The basis of our approach is the use of a standard set and the adoption of a statistical view of translation quality. This approach has the ability to provide evaluations which avoid dependence on any particular theory of translation, which are therefore potentially more objective than previous techniques. The work presented here was supported by the Science and Engineering and the Social and Economic Research Councils of Great Britain, and would not have been possible without the gracious assistance of Ian Mason of Heriot Watt University, Edinburgh."
C92-2092,Letting the Cat Out of the Bag: Generation for Shake-and-Bake {MT},1992,3,49,1,1,22390,chris brew,{COLING} 1992 Volume 2: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
J91-4002,Systematic Classification and its Efficiency,1991,-1,-1,1,1,22390,chris brew,Computational Linguistics,0,None
C90-3007,Partial Descriptions and Systemic Grammar,1990,9,3,1,1,22390,chris brew,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,"This paper examines the properties of featurebased partial descriptions built on top of Halliday's systemic networks. We show that the crucial operation of consistency checking for such descriptions is NP-complete, and therefore probably intractable, but proceed to develop algorithms which can sometimes alleviate the unpleasant consequences of this intractability."
