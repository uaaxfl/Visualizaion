2002.jeptalnrecital-long.10,2001.jeptalnrecital-long.21,1,0.606767,"Missing"
2002.jeptalnrecital-long.10,1995.mtsummit-1.1,0,0.234594,"Missing"
2003.jeptalnrecital-long.22,2001.jeptalnrecital-long.21,1,0.834084,"Missing"
2003.jeptalnrecital-long.22,2002.jeptalnrecital-long.10,1,0.799177,"Missing"
2004.jeptalnrecital-poster.12,P84-1004,0,0.472677,"Missing"
2005.jeptalnrecital-long.8,2002.jeptalnrecital-long.10,1,0.773132,"Missing"
2006.jeptalnrecital-poster.15,P84-1004,0,0.59594,"Missing"
2006.jeptalnrecital-poster.15,C92-2070,0,0.0330132,"Missing"
2007.jeptalnrecital-long.27,P06-1036,0,0.0676454,"Missing"
2007.jeptalnrecital-long.27,lafourcade-2006-conceptual,1,0.877035,"Missing"
2007.jeptalnrecital-long.27,1995.mtsummit-1.1,0,0.0607237,"Missing"
2007.jeptalnrecital-long.27,2002.jeptalnrecital-long.10,1,0.881296,"Missing"
2007.jeptalnrecital-long.27,C02-1038,0,0.0737216,"Missing"
2008.jeptalnrecital-long.19,W06-1007,0,0.024177,"ponses communes aux joueurs (A) et (B). Nous ne mémorisons pas les réponses proposées uniquement par l’un des deux joueurs. Cela permet la construction d’un réseau lexical reliant les termes par des relations typées et pondérées, validées par paires de joueurs. Ces relations sont typées par la consigne imposée aux joueurs ; elles sont pondérées en fonction du nombre de paires de joueurs qui les ont proposées, comme explicité en section 2.2. La structure du réseau lexical que nous cherchons ainsi à obtenir s’appuie sur les notions de nœuds et de relations entre nœuds, telles que rappelées par (Polguère, 2006). Chaque nœud du réseau est constitué d’une unité lexicale (terme ou expression) regroupant toutes ses lexies et les relations entre nœuds traduisent des fonctions lexicales, telles que présentées par (Mel’čuk et al., 1995). Initialement, les nœuds sont constitués des termes de notre base de départ, mais celle-ci peut s’accroître ; effectivement, si les deux joueurs (A) et (B) d’une même partie proposent un terme initialement inconnu, alors ce terme est ajouté à notre base. La figure 1 présente les relations acquises pour le terme aile. relations ==&gt; aile ---r_associated:360--&gt; voler aile ---r"
2011.jeptalnrecital-long.20,2003.mtsummit-papers.26,0,0.0783052,"Missing"
2011.jeptalnrecital-long.20,1995.mtsummit-1.1,0,0.0237433,"Missing"
2011.jeptalnrecital-long.20,W02-1118,1,0.843749,"Missing"
2016.jeptalnrecital-long.4,esuli-sebastiani-2006-sentiwordnet,0,0.10395,"Missing"
2016.jeptalnrecital-long.4,kamps-etal-2004-using,0,0.037042,"Missing"
2016.jeptalnrecital-long.4,C04-1200,0,0.294634,"Missing"
2016.jeptalnrecital-long.4,W06-0301,0,0.124879,"Missing"
2016.jeptalnrecital-long.4,R15-1044,1,0.869075,"Missing"
2016.jeptalnrecital-long.4,P10-1023,0,0.093295,"Missing"
2016.jeptalnrecital-long.4,W10-0204,0,0.100385,"Missing"
2016.jeptalnrecital-long.4,J11-2001,0,0.128129,"Missing"
2016.jeptalnrecital-poster.26,embarek-ferret-2008-learning,0,0.0457018,"Missing"
2016.jeptalnrecital-poster.26,D11-1142,0,0.0801793,"Missing"
2016.jeptalnrecital-poster.26,N03-1011,0,0.133108,"Missing"
2016.jeptalnrecital-poster.26,C92-2082,0,0.532986,"Missing"
2016.jeptalnrecital-poster.26,P90-1034,0,0.867917,"Missing"
2016.jeptalnrecital-poster.26,P06-1101,0,0.0443471,"Missing"
2016.jeptalnrecital-poster.26,E14-1019,1,0.809353,"Missing"
2017.jeptalnrecital-court.19,N03-1011,0,0.144605,"Missing"
2017.jeptalnrecital-court.19,C92-2082,0,0.381151,"Missing"
2017.jeptalnrecital-court.19,P10-1023,0,0.0384954,"Missing"
2017.jeptalnrecital-court.19,I08-2126,0,0.0397553,"Missing"
2017.jeptalnrecital-court.19,E14-1019,1,0.876869,"Missing"
2018.jeptalnrecital-court.28,claveau-kijak-2014-generating,0,0.056192,"Missing"
2018.jeptalnrecital-court.28,W07-1007,0,0.105168,"Missing"
2018.jeptalnrecital-court.28,2015.jeptalnrecital-long.16,0,0.0654591,"Missing"
2018.jeptalnrecital-court.37,gravier-etal-2012-etape,0,0.0346695,"Missing"
2018.jeptalnrecital-court.37,P14-2076,0,0.0709506,"Missing"
2018.jeptalnrecital-court.37,Q14-1019,0,0.0993739,"Missing"
2018.jeptalnrecital-court.37,W12-0508,0,0.0751872,"Missing"
2019.jeptalnrecital-court.18,C10-3014,0,0.109224,"Missing"
2019.jeptalnrecital-court.18,W17-2403,0,0.0622976,"Missing"
2019.jeptalnrecital-court.18,W02-1106,0,0.25773,"Missing"
2019.jeptalnrecital-court.18,D15-1090,0,0.0255507,"Missing"
2019.jeptalnrecital-court.18,serasset-2012-dbnary,0,0.0445156,"Missing"
2019.jeptalnrecital-court.18,speer-havasi-2012-representing,0,0.0486341,"Missing"
2020.crac-1.17,P19-1409,0,0.0244489,"structural level : Due to the segmented form of the communication (message/thread), emails redefine the binding scope of an anaphoric mention (Reinhart, 1983). An expression can refer to antecedents mentioned within the same message or not. Antecedents may be located in different emails in the thread, or even in different threads. This particular aspect impels us, from an annotation point of view, to design a scheme that handles these extended scopes, and deals with internal and external antecedents. It also affects the resolution task, which becomes analogous to a CrossDocument (CD) problem (Barhom et al., 2019) in which every email thread represents a document. As opposed to Within-Document (WD) anaphora resolution that has been extensively studied during the last decades, the CD task, that aims to locate coreferent entities across multiple documents, remains, as far as we are aware, totally unexplored for French. In addition to that, the writings in emails obey to a certain number of stylistic and functional rules making their content singular. One example is the mentions of entities in the metadata of each mail (Sender, recipients, signatures..) that can be antecedents to anaphoric expressions use"
2020.crac-1.17,J08-4004,0,0.0630604,"4. Agreement study: In order to assess the operability of the resulting typology, agreement studies have been undertook on the threads selected in step 2. Unlike for other NLP tasks (typically classification ones), annotators are expected to mark words from the text as antecedents, this makes it difficult to establish a priori the set of all possible annotations for a given anaphor. Provided that the Kappa measure relies on the set of possible class labels, implementing it to capture agreements on anaphora annotation is challenging. Several methods were used to address this particular aspect (Artstein and Poesio, 2008). In our experiments, we chose to isolate the identification and delimitation of antecedents from the classification task. The formal experiments concerned the task of classification of annotated anaphoric mentions into the set of types defined. It was designed to determine in what proportion the annotators agree that an anaphoric markable belongs to a given type, then analyse the reasons for eventual disagreements. Two agreement scores were calculated to assess the consistency of both the typology and the guidelines : A first pairwise (annotatori , gold) agreement score (Cohen’s Kappa), and a"
2020.crac-1.17,L16-1404,0,0.0276653,"3.5) in a collection of anonymized professional French emails. Our work leads to the following contributions: Making available the first free French email corpus for scientific exploitation; Providing annotations for the anaphora discourse phenomenon in French emails; Giving a first quantitative overview of anaphora and coreference in emails. In this paper, we describe the dataset and its anonymization process (cf. section 2), then, we focus on anaphora and coreference annotation (cf. section 3). Finally, we describe the annotated corpus and our future works (cf. section 5). 2 Dataset As for (Krieg-Holz et al., 2016), our dataset is made of French professional emails which were requested from individual email authors on the basis of a volunteer act. In our case, authors are employees of a company that wished to remain anonymous. The corpus consists of 100 threads made of 314 emails (7163 words), out of mailing lists, exchanged between June and September 2017. 2.1 Data collection Technically, the threads were collected through two email inboxes. This implies that the recipients of the threads are always the two same individuals, but emails are from 53 authors. Given the user-centered applications that we c"
2020.crac-1.17,muzerelle-etal-2014-ancor,0,0.132062,"core components of the NLP field. These tasks aim to detect and resolve repeated mentions of the same entities in a given document. Many NLP tasks rely on the ability to resolve entities efficiently and could be prominently improved by using robust automatic strategies of anaphora and coreference resolution. In order to design suitable strategies dealing with a natural language phenomenon, one would require to analyse a sufficient number of occurrences of the said phenomenon. Several studies on annotating French texts with anaphoric links have been conducted (Landragin, 2019; Landragin, 2018; Muzerelle et al., 2014; Tutin et al., 2000), resulting in a few available corpora. The texts covered in these corpora are of various genres and natures, nonetheless, emails are part of none of these datasets. This work is licensed under a Creative Commons Attribution 4.0 International License. http://creativecommons.org/licenses/by/4.0/. License details: 165 Proceedings of the 3rd Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2020), pages 165–175, Barcelona, Spain (online), December 12, 2020. In order to capture the characteristics of referring expressions in this particular kind of"
2020.crac-1.17,poesio-artstein-2008-anaphoric,0,0.0576164,"ken French transcriptions taken from sociolinguistic interviews. DEMOCRAT’s corpus is the most recent resource, annotated with coreferential information (Landragin, 2019). Interestingly, the authors took into account coreference chains in the annotation process. In DEMOCRAT, the selection of texts was done in a way that helps capture the variations of the coreference phenomenon across text genres and eras. Nonetheless, emails are not considered in these corpora. In Section 4, a set of methodological choices is compared to those of larger-scale projects ; ANCOR (Muzerelle et al., 2014), ARRAU (Poesio and Artstein, 2008) and OntoNotes corpora (Pradhan et al., 2007). In the following section, we discuss the specificity of annotating anaphoric links in the context of emails (cf. section 3.1), then describe our annotation protocol and the typology used (cf. section 3.3)). 3.1 Emails singularities Email writings show some singularities that make the tasks of anaphora annotation and resolution difficult. The two main challenges encountered when dealing with emails are: • The structural level : Due to the segmented form of the communication (message/thread), emails redefine the binding scope of an anaphoric mention"
2020.crac-1.17,2017.jeptalnrecital-court.15,1,0.837554,"tions of entities in the metadata of each mail (Sender, recipients, signatures..) that can be antecedents to anaphoric expressions used in the email body. • The morphological aspects : Similarly to every other kind of user-generated texts, the morphological level affects both the tasks of manual annotation of anaphora and its automatic resolution. For example, gender and number traits being some of the most decisive features in anaphora resolution, rely on meticulous spelling and require a high level of morphological accuracy. However, considering the ”non standard” nature of emails writings (Tarrade et al., 2017), morphological errors can produce ambiguous phrasings. 3.2 Annotation protocol The task was performed by a group of 3 MSc/PhD annotators with Linguistics background, and of different French language proficiency levels. Including one expert annotator whose annotations were considered as gold standard in the agreement study. The process consisted of six stages (including three iterative steps): 1. Initialization of the guideline: The first strategy emerged from discussions about the general purposes and requirements of the resulting corpus. The initial draft was defined in such a way that allow"
2020.gamnlp-1.4,W16-1316,0,0.0216954,"Missing"
2020.gamnlp-1.4,W16-2522,0,0.0283717,"d on the popular game Taboo and just asks players to provide words in relation to a target word (stimulus or seed, in the psycholinguistics jargon). There is a taboo list of forbidden words which comes from SemCor and Google unigram data. The game Verbosity (Ahn et al., 2006) also aims to collect linguistic data and semantic facts. The principle of the game is to propose riddles (a term that a user must make another user guess through the proposal of semantic relations.) In Grác and Nevěřilová (2010), a game similar to Verbosity is presented, but with a strong time constraint of 3 minutes. In Parasca et al. (2016), an interesting analysis shows how a game can produce data that go beyond automatic extraction based on the distributional hypothesis. The presented game, Word Sheriff, handles word associations as well as more precise semantic relations. All in all, there are quite no recent GWAPs in NLP to collect word associations. In this context, there are no studies on the effect of game design on data collection. For instance one might ask what effect does the time constraint have on the quality and quantity of data collected? What would be the bias if players could control the proposed target terms ?"
2020.gamnlp-1.4,D08-1056,0,0.048914,". 2.2. JeuxDeMots - A Sophisticated Environment The relevant game design elements of the main game of the JeuxDeMots project are as follows: • The term to be played with (the target term) is randomly selected; • the relation (game instruction) is given at the beginning of the game; • The answers given are compared with those of another player, on the same term with the same instruction. Answers common to both players are added to the lexical network, or strengthen the relation if it already exists. Related Work and Research Questions Other GWAPs are available to collect word associations. In (Vickrey et al., 2008) three online games are mentioned (Categorilla and Categodzilla and Free Association) that were designed to collect semantic associations in the form of structured data. Users are asked to supply words to fulfill specific categories, for example, ""Types of bird"", ""A thing • Points are computed according to the number of associations common to both players, and the point amount is notified to the user at the end of the game; 27 Figure 1: in-going play of JDM. The target word is épée. The player has already proposed a number of terms (list on the right). • a game lasts one minute by default; a t"
2020.gamnlp-1.4,W19-2908,0,0.060659,"Missing"
2020.jeptalnrecital-taln.12,W17-2403,0,0.0593285,"Missing"
2020.jeptalnrecital-taln.12,speer-havasi-2012-representing,0,0.106493,"Missing"
2020.jeptalnrecital-taln.25,P18-1218,0,0.0627471,"Missing"
2020.jeptalnrecital-taln.25,K16-1006,0,0.0207384,"Missing"
2020.jeptalnrecital-taln.25,P19-1570,0,0.03071,"Missing"
2020.jeptalnrecital-taln.25,P18-1226,0,0.0306771,"Missing"
2020.jeptalnrecital-taln.25,P19-1268,0,0.0421838,"Missing"
2020.jeptalnrecital-taln.25,N18-1202,0,0.0484017,"Missing"
2020.jeptalnrecital-taln.25,P19-2057,0,0.0437528,"Missing"
2020.lrec-1.280,W17-2403,0,0.0527939,"Missing"
2020.lrec-1.280,speer-havasi-2012-representing,0,0.0187083,"l, use of the Accusative case as opposed to the Locative case) in order to extract supplementary sets of semantic information i.e. part-of (composition), state-of, and type-place. These pieces of semantic knowledge are used for the relation annotation (attaching meta-information to the relations of the (M)LSN). We notice that, compared to the extraction, the inference processes yield numerous candidate relations. This is due to the presence of sense refinements in the MLSN (i.e. sense refinements obtained from the pre-existing resources (such as WordNet (Fellbaum, 1998), RezoJDM, ConceptNet ((Speer and Havasi, 2012). When a term in the source language (inference entry point) is unrefined (not disambiguated), it is linked to the potential senses possibly present in the pivot in the target sub-graph. Term disambiguation is crucial for the lexical semantic resource building. When automatically validated, inferences allow disambiguation of the polysemous terms present in the MLSN. 4.4. #true rel 815 35 74 49 64 44 1081 #true inf 2 454 2 419 453 3 181 283 264 9 054 #undec 37 493 6 475 2 442 2 777 2 636 132 51 955 Table 2: Evaluation of the inferred relations. For simplicity, only the relations accepted by loo"
2021.jeptalnrecital-taln.15,Q17-1010,0,0.0109829,"Missing"
2021.jeptalnrecital-taln.15,S15-2151,0,0.0580068,"Missing"
2021.jeptalnrecital-taln.15,H05-1091,0,0.500101,"Missing"
2021.jeptalnrecital-taln.15,2015.jeptalnrecital-long.12,0,0.0603549,"Missing"
2021.jeptalnrecital-taln.15,N19-1423,0,0.00892761,"Missing"
2021.jeptalnrecital-taln.15,K15-1027,0,0.0531195,"Missing"
2021.jeptalnrecital-taln.15,C92-2082,0,0.651167,"Missing"
2021.jeptalnrecital-taln.15,P09-1113,0,0.34618,"Missing"
2021.jeptalnrecital-taln.15,S16-1206,0,0.0509502,"Missing"
2021.jeptalnrecital-taln.15,P06-1015,0,0.391159,"Missing"
2021.jeptalnrecital-taln.15,D17-1123,0,0.0494995,"Missing"
2021.jeptalnrecital-taln.5,D13-1178,0,0.0414649,"Missing"
2021.jeptalnrecital-taln.5,D19-1651,0,0.0228077,"Missing"
2021.jeptalnrecital-taln.5,W10-0907,0,0.0888142,"Missing"
2021.jeptalnrecital-taln.5,N19-1423,0,0.0150283,"Missing"
2021.jeptalnrecital-taln.5,D11-1142,0,0.193572,"Missing"
2021.jeptalnrecital-taln.5,D19-1428,0,0.026209,"Missing"
2021.jeptalnrecital-taln.5,2020.lrec-1.279,0,0.0205497,"Missing"
2021.jeptalnrecital-taln.5,2020.emnlp-main.306,0,0.0296425,"Missing"
2021.jeptalnrecital-taln.5,W19-4002,0,0.0315762,"Missing"
2021.jeptalnrecital-taln.5,L16-1262,0,0.0804756,"Missing"
2021.jeptalnrecital-taln.5,W16-1307,0,0.0538199,"Missing"
2021.jeptalnrecital-taln.5,2020.acl-demos.14,0,0.0539881,"Missing"
2021.jeptalnrecital-taln.5,2020.findings-emnlp.99,0,0.0534999,"Missing"
2021.jeptalnrecital-taln.5,P15-2050,0,0.0605221,"Missing"
2021.jeptalnrecital-taln.5,N18-1081,0,0.0349546,"Missing"
2021.jeptalnrecital-taln.5,D16-1177,0,0.0642745,"Missing"
2021.jeptalnrecital-taln.5,D14-1038,0,0.0618471,"Missing"
2021.jeptalnrecital-taln.5,N07-4013,0,0.142725,"Missing"
C02-1061,2001.jeptalnrecital-long.21,1,0.758298,"Missing"
C02-1061,1995.mtsummit-1.1,0,0.015342,"Missing"
C14-1036,W12-5102,1,0.881435,"Missing"
C14-1036,W03-2408,0,0.105066,"Missing"
C14-1036,P10-1023,0,0.090199,"Missing"
C14-1036,P06-1101,0,0.124521,"Missing"
C14-1036,R13-1096,1,0.796302,"Missing"
C14-1036,E14-1019,1,0.24882,"Missing"
C14-1036,zarrouk-lafourcade-2014-relation,1,0.168013,"Missing"
C14-1036,P12-2031,0,0.0687531,"Missing"
C94-1045,J87-3003,0,\N,Missing
C96-2199,C94-1045,1,\N,Missing
E14-1019,P06-1101,0,0.412398,"Missing"
E14-1019,W12-5102,1,0.881543,"Missing"
E14-1019,P12-2031,0,0.195898,"Missing"
E14-1019,W03-2408,0,0.751027,"Missing"
E14-1019,P10-1023,0,0.351941,"Missing"
F13-1025,W11-0106,0,0.0424481,"Missing"
F13-1025,W09-3308,0,0.0748167,"Missing"
F13-1025,W12-5102,1,0.896974,"Missing"
F13-1025,W03-2408,0,0.0966729,"Missing"
F13-1025,2008.jeptalnrecital-long.18,0,0.126989,"Missing"
F14-1010,R13-1096,1,0.893438,"Missing"
F14-2034,joubert-lafourcade-2012-new,1,0.856165,"Missing"
F14-2034,W12-5102,1,0.838027,"Missing"
F14-2034,W11-0611,0,0.0389982,"Missing"
F14-2034,W10-3405,0,0.0604968,"Missing"
joubert-lafourcade-2008-evolutionary,P84-1004,0,\N,Missing
joubert-lafourcade-2012-new,W06-1007,0,\N,Missing
joubert-lafourcade-2012-new,W03-2408,0,\N,Missing
L16-1725,E12-1043,0,0.0481133,"Missing"
L16-1725,W04-3205,0,0.0870447,"Missing"
L16-1725,2006.jeptalnrecital-long.9,0,0.175123,"Missing"
L16-1725,D11-1142,0,0.151155,"Missing"
L16-1725,J06-1005,0,0.121811,"Missing"
L16-1725,C92-2082,0,0.649191,"Missing"
L16-1725,P90-1034,0,0.638723,"Missing"
L16-1725,P06-1101,0,0.0826276,"Missing"
lafourcade-2006-conceptual,C92-2070,0,\N,Missing
lafourcade-2006-conceptual,C02-1061,1,\N,Missing
lafourcade-boitet-2002-unl,C90-2045,0,\N,Missing
lafourcade-boitet-2002-unl,C92-3168,0,\N,Missing
lafourcade-boitet-2002-unl,C92-3129,0,\N,Missing
lafourcade-boitet-2002-unl,C00-2111,1,\N,Missing
lafourcade-boitet-2002-unl,C94-1017,0,\N,Missing
lafourcade-boitet-2002-unl,C80-1064,0,\N,Missing
lafourcade-fort-2014-propa,J11-2010,1,\N,Missing
R13-1096,W03-2408,0,0.653557,"Missing"
R13-1096,P10-1023,0,0.166236,"Missing"
R13-1096,W12-5102,1,0.8631,"Missing"
R15-1044,R11-1054,0,0.0139973,"a term, and thus obtain a resulting polarity for most of the terms of the freely available lexical network of the JeuxDeMots project. We present a quantitative analysis of data obtained through our approach, together with the comparison method we developed to validate them qualitatively. 1 Introduction Being able to evaluate feelings is essential in natural language processing, whether to analyze political speeches or opinion of the general public on the provision of services, tourist, cultural, or about consumer goods. Whatever type of approach, statistics supervised or more linguistic one (Brun, 2011), such ability requires referring to a polarity lexical resource, in wich terms are endowed with positive, negative and neutral values. The polarity can be expressed using a single numerical value (Taboada et al., 2011), or more: two values (positive/negative) are used in Emolex (Saif and Turney, 2013), a lexical polarity / feelings resource in English, produced by crowdsourcing (using Amazon Mechanical Turk, which can be problematic, see Fort et al. (2014)). SentiWordNet (Esuli and Sebastiani, 2006), as well as WordNet Affect (Strapparava and Valitutti, 2004) are extensions of WorldNet in whi"
R15-1044,lafourcade-fort-2014-propa,1,0.824129,"1), or more: two values (positive/negative) are used in Emolex (Saif and Turney, 2013), a lexical polarity / feelings resource in English, produced by crowdsourcing (using Amazon Mechanical Turk, which can be problematic, see Fort et al. (2014)). SentiWordNet (Esuli and Sebastiani, 2006), as well as WordNet Affect (Strapparava and Valitutti, 2004) are extensions of WorldNet in which terms are polarized along three values (positive, negative, objective) of which the last one is opposed to the first two. Approaches through propagation by starting from a manual core (see Gala and Brun (2012) and Lafourcade and Fort (2014)) have also been performed, but such approaches may not exactly reflect the views of speakers. Learning algorithms 329 Proceedings of Recent Advances in Natural Language Processing, pages 329–337, Hissar, Bulgaria, Sep 7–9 2015. • diversity of vocabulary and topics and variability of response: a number of words elicit mixed feelings, even opposing (e.g., the term operating room, theoretically seen as positive, but negative if we are personally concerned), and the feelings of a player can evolve over time and according to circumstances. Thus the word bachelor or school exam creates a negative f"
R15-1044,D08-1027,0,0.0222377,"Missing"
R15-1044,esuli-sebastiani-2006-sentiwordnet,0,0.387922,"t, cultural, or about consumer goods. Whatever type of approach, statistics supervised or more linguistic one (Brun, 2011), such ability requires referring to a polarity lexical resource, in wich terms are endowed with positive, negative and neutral values. The polarity can be expressed using a single numerical value (Taboada et al., 2011), or more: two values (positive/negative) are used in Emolex (Saif and Turney, 2013), a lexical polarity / feelings resource in English, produced by crowdsourcing (using Amazon Mechanical Turk, which can be problematic, see Fort et al. (2014)). SentiWordNet (Esuli and Sebastiani, 2006), as well as WordNet Affect (Strapparava and Valitutti, 2004) are extensions of WorldNet in which terms are polarized along three values (positive, negative, objective) of which the last one is opposed to the first two. Approaches through propagation by starting from a manual core (see Gala and Brun (2012) and Lafourcade and Fort (2014)) have also been performed, but such approaches may not exactly reflect the views of speakers. Learning algorithms 329 Proceedings of Recent Advances in Natural Language Processing, pages 329–337, Hissar, Bulgaria, Sep 7–9 2015. • diversity of vocabulary and top"
R15-1044,strapparava-valitutti-2004-wordnet,0,0.0814554,"pproach, statistics supervised or more linguistic one (Brun, 2011), such ability requires referring to a polarity lexical resource, in wich terms are endowed with positive, negative and neutral values. The polarity can be expressed using a single numerical value (Taboada et al., 2011), or more: two values (positive/negative) are used in Emolex (Saif and Turney, 2013), a lexical polarity / feelings resource in English, produced by crowdsourcing (using Amazon Mechanical Turk, which can be problematic, see Fort et al. (2014)). SentiWordNet (Esuli and Sebastiani, 2006), as well as WordNet Affect (Strapparava and Valitutti, 2004) are extensions of WorldNet in which terms are polarized along three values (positive, negative, objective) of which the last one is opposed to the first two. Approaches through propagation by starting from a manual core (see Gala and Brun (2012) and Lafourcade and Fort (2014)) have also been performed, but such approaches may not exactly reflect the views of speakers. Learning algorithms 329 Proceedings of Recent Advances in Natural Language Processing, pages 329–337, Hissar, Bulgaria, Sep 7–9 2015. • diversity of vocabulary and topics and variability of response: a number of words elicit mix"
R15-1044,J11-2001,0,0.225689,"together with the comparison method we developed to validate them qualitatively. 1 Introduction Being able to evaluate feelings is essential in natural language processing, whether to analyze political speeches or opinion of the general public on the provision of services, tourist, cultural, or about consumer goods. Whatever type of approach, statistics supervised or more linguistic one (Brun, 2011), such ability requires referring to a polarity lexical resource, in wich terms are endowed with positive, negative and neutral values. The polarity can be expressed using a single numerical value (Taboada et al., 2011), or more: two values (positive/negative) are used in Emolex (Saif and Turney, 2013), a lexical polarity / feelings resource in English, produced by crowdsourcing (using Amazon Mechanical Turk, which can be problematic, see Fort et al. (2014)). SentiWordNet (Esuli and Sebastiani, 2006), as well as WordNet Affect (Strapparava and Valitutti, 2004) are extensions of WorldNet in which terms are polarized along three values (positive, negative, objective) of which the last one is opposed to the first two. Approaches through propagation by starting from a manual core (see Gala and Brun (2012) and La"
R15-1044,C04-1200,0,0.811616,"Missing"
R15-1044,P02-1053,0,0.0138434,"Missing"
R19-1012,speer-havasi-2012-representing,0,0.102794,"Missing"
R19-1012,W14-0148,0,0.0176701,"n and ontology building process. Such process relies on an intermediary structure, a termino-ontology (for instance, the Terminae suite, (Szulman, 2012)). Undifferentiated tools use some statistical information to suggest the canhttp://neon-project.org/nw/About_NeOn.html 92 Proceedings of Recent Advances in Natural Language Processing, pages 92–101, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_012 didate concepts. They exploit such methods as formal concept analysis (Mondary, 2011) or knowledge based methods (for instance, TextToOnto2 ). ”Lexical ontologies” (Abu Helou et al., 2014) are successfully used for ontology building. Numerous approaches targeted at high level ontology or information retrieval ontology based on general knowledge (such as (Marciniak, 2013)) rely on PWN. Others use PWN and domain specific semantic lexicons for forming the concepts (Turcato et al., 2000). Many other ontology learning techniques use distributional semantics to learn lightweight ontologies, for example, (Wong, 2009). sourcing methods and, in particular, games with a purpose (GWAPS) such as JeuxDeMots3 and additional games . This commons sense network has been built since 2007. It is"
R19-1012,clairet-2017-dish,0,0.0257273,"the results listed in the table 3. Fully automated structure-based evaluation such as described in (Fern´andez et al., 2009) may be chosen to compare to other resources available on the Web such as (Dooley et al., 2018). To address the ontology accuracy, completeness, conciseness, efficiency, consistency, and other features (Raad and Cruz, 2015), a combination of methods is needed. In particular, gold standard ontology, specific tasks and corpora may be used for evaluation. A task-based evaluation such as semantic analysis (BebeshinaClairet, 2019), dietary conflict detection from dish titles (Clairet, 2017) have been used for the MLSN. To evaluate the output of the immersion- projection method, we need to organize our triples into a fully structured ontology. This will be one of the priorities of our future work. We automatically suggested and semi-automatically validated 342 RPKs(desc). We explored the possibility of suggesting relevant RPKs to human experts. We defined 3 pseudo-properties for testing: aPourComposantFlaveur (”hasFlavourComponent”), aPourComposantToucher (”hasTouchComponent”), and aPourComposantAspect (”hasAspectComponent”). To populate them, we explored the RezoJDM relations ty"
R19-1012,C10-3014,0,0.043504,"Missing"
R19-1012,W00-1101,0,0.133095,"dvances in Natural Language Processing, pages 92–101, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_012 didate concepts. They exploit such methods as formal concept analysis (Mondary, 2011) or knowledge based methods (for instance, TextToOnto2 ). ”Lexical ontologies” (Abu Helou et al., 2014) are successfully used for ontology building. Numerous approaches targeted at high level ontology or information retrieval ontology based on general knowledge (such as (Marciniak, 2013)) rely on PWN. Others use PWN and domain specific semantic lexicons for forming the concepts (Turcato et al., 2000). Many other ontology learning techniques use distributional semantics to learn lightweight ontologies, for example, (Wong, 2009). sourcing methods and, in particular, games with a purpose (GWAPS) such as JeuxDeMots3 and additional games . This commons sense network has been built since 2007. It is a directed, typed and weighted graph. At the time of our writing, RezoJDM contains 2.7 millions of terms that are modeled as nodes of the graph and 240 millions of relations (arcs). The MLSN (Bebeshina-Clairet, 2019) is a multilingual LSN (it covers French, English, Spanish, and Russian) with an int"
W12-5102,W03-2408,0,0.343948,"get term 1 T and a same instruction (synonyms, domains, free associations …), the answers common to both players are recorded. Validations are thus made by concordance of the propositions between pairs of players. This validating process is similar to the one used by (von Ahn and Dabbish, 2004) to index images and by (Liberman et al., 2007) to collect common sense knowledge. As far as we know, this is the first time it is done for lexical/semantic networks. However, using games for collecting resources of use in NLP is nowhere new, as (Chamberlain et al.) used it for anaphora annotations and (Mihalcea and Chklovski, 2003) for annotating corpora, to name a few. The structure of the lexical network built in JDM relies on the nodes and relations between nodes, as it was initially introduced by (Collins and Quillian, 1969) and more recently explicited by (Polguère, 2006). More precisely, JDM game leads to the construction of a lexical network connecting terms by typed and weighted relations 2, some of them being quite non-classical. These relations are labelled by the instruction given to the players and they are weighted according to the number of pairs of players who proposed them. Also similar at first sight, t"
W12-5102,W04-2607,0,0.0190151,"found in clue. For example, :loc garden, :loc desert The target word is a location for clue. For example, :locfor money The target word has clue as a property. For example, :carac cold The target word has clue as part. For example, :part wheel The target word is a part of clue. For example, :partof car The target word can do clue. For example, :do roar The target word can be an patient of clue. For example, : patientof paint The target word can cause clue. For example, :cause disease. The target word is a consequence of clue. For example, : hascause virus The reader can refer for example to (Morris and Hirst, 2004) for a discussion of nonclassical semantic relations and their relevance for NLP. 11 2.1 Principle and General Algorithm When viewing AKI as a game, the user tries consciously to make the computer guess a term, supplying, one by one, a succession of typed clues. After each clue, AKI makes the most probable proposition. If it corresponds to the searched term, the user confirms the proposition as the proper one; otherwise he introduces a new clue. This dialogue goes on, until either AKI finds the target term, or gives up asking the user to supply the solution. The algorithm relies both on the in"
W12-5102,P10-1023,0,0.136573,"Missing"
W12-5102,W06-1007,0,0.0232499,"by (von Ahn and Dabbish, 2004) to index images and by (Liberman et al., 2007) to collect common sense knowledge. As far as we know, this is the first time it is done for lexical/semantic networks. However, using games for collecting resources of use in NLP is nowhere new, as (Chamberlain et al.) used it for anaphora annotations and (Mihalcea and Chklovski, 2003) for annotating corpora, to name a few. The structure of the lexical network built in JDM relies on the nodes and relations between nodes, as it was initially introduced by (Collins and Quillian, 1969) and more recently explicited by (Polguère, 2006). More precisely, JDM game leads to the construction of a lexical network connecting terms by typed and weighted relations 2, some of them being quite non-classical. These relations are labelled by the instruction given to the players and they are weighted according to the number of pairs of players who proposed them. Also similar at first sight, this a strong departure from collecting concurrences (typed or not) form corpora. Indeed, there is less guarantee, if any, that term associations extracted from corpora faithfully reflect what people have in their mind than asking them directly. In a"
W12-5102,C90-2067,0,0.186869,"Missing"
W17-6920,basile-etal-2012-developing,0,0.0488148,"Missing"
W17-6920,ide-etal-2008-masc,0,0.0534981,"Missing"
W17-6920,S15-2049,0,0.0611423,"Missing"
W17-6920,P10-1023,0,0.0506045,"Missing"
W17-6920,E17-1010,0,0.0236812,"Missing"
W17-6920,W13-0215,0,0.0408888,"Missing"
W17-6920,J11-2010,0,\N,Missing
W17-7206,E03-1020,0,0.0854412,"a list of all incompatible hypernyms (which will be referred as incompatibility rules later in this paper), one could easily detect polysemous words. Is it possible to create such a list ? Can it be done automatically ? To answer these questions we experimented on the French lexical-semantic network JeuxDeMots, Lafourcade (2007), which a free and open resource. Identifying polysemous words is crucial in order to understand a text. It is usually done by detecting high density components in co-occurrence graphs created from large corpora, as in Véronis (2003). Similar methods have been used by Dorow and Widdows (2003) and Ferret (2004) to discover word senses also in corpora. To detect the different dense areas of their graphs, Dorow and Widdows (2003) used the Markov Cluster Algorithm, van Dongen (2000). These methods are very effective, but they highly depend on the corpora used to create the graphs which might induce many biases. To choose the proper glosses for naming the different word senses, Dorow and Widdows (2003) used the hypernyms present in the lexical network WordNet, Fellbaum (1998). WordNet is also used by Ferret (2004) to evaluate his results. We experimented our approach on the French lexi"
W17-7206,2004.jeptalnrecital-long.5,0,0.0866909,"ypernyms (which will be referred as incompatibility rules later in this paper), one could easily detect polysemous words. Is it possible to create such a list ? Can it be done automatically ? To answer these questions we experimented on the French lexical-semantic network JeuxDeMots, Lafourcade (2007), which a free and open resource. Identifying polysemous words is crucial in order to understand a text. It is usually done by detecting high density components in co-occurrence graphs created from large corpora, as in Véronis (2003). Similar methods have been used by Dorow and Widdows (2003) and Ferret (2004) to discover word senses also in corpora. To detect the different dense areas of their graphs, Dorow and Widdows (2003) used the Markov Cluster Algorithm, van Dongen (2000). These methods are very effective, but they highly depend on the corpora used to create the graphs which might induce many biases. To choose the proper glosses for naming the different word senses, Dorow and Widdows (2003) used the hypernyms present in the lexical network WordNet, Fellbaum (1998). WordNet is also used by Ferret (2004) to evaluate his results. We experimented our approach on the French lexical-semantic netwo"
W17-7206,2003.jeptalnrecital-long.25,0,0.119824,"those two hypernyms are &quot;incompatible&quot;. If one had a list of all incompatible hypernyms (which will be referred as incompatibility rules later in this paper), one could easily detect polysemous words. Is it possible to create such a list ? Can it be done automatically ? To answer these questions we experimented on the French lexical-semantic network JeuxDeMots, Lafourcade (2007), which a free and open resource. Identifying polysemous words is crucial in order to understand a text. It is usually done by detecting high density components in co-occurrence graphs created from large corpora, as in Véronis (2003). Similar methods have been used by Dorow and Widdows (2003) and Ferret (2004) to discover word senses also in corpora. To detect the different dense areas of their graphs, Dorow and Widdows (2003) used the Markov Cluster Algorithm, van Dongen (2000). These methods are very effective, but they highly depend on the corpora used to create the graphs which might induce many biases. To choose the proper glosses for naming the different word senses, Dorow and Widdows (2003) used the hypernyms present in the lexical network WordNet, Fellbaum (1998). WordNet is also used by Ferret (2004) to evaluate"
zarrouk-lafourcade-2014-relation,P06-1101,0,\N,Missing
zarrouk-lafourcade-2014-relation,W12-5102,1,\N,Missing
zarrouk-lafourcade-2014-relation,E14-1019,1,\N,Missing
zarrouk-lafourcade-2014-relation,R13-1096,1,\N,Missing
zarrouk-lafourcade-2014-relation,W03-2408,0,\N,Missing
zarrouk-lafourcade-2014-relation,P12-2031,0,\N,Missing
