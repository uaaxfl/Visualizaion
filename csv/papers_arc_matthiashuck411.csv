2021.mtsummit-research.15,A Comparison of Sentence-Weighting Techniques for {NMT},2021,-1,-1,2,0,5060,simon riess,Proceedings of Machine Translation Summit XVIII: Research Track,0,Sentence weighting is a simple and powerful domain adaptation technique. We carry out domain classification for computing sentence weights with 1) language model cross entropy difference 2) a convolutional neural network 3) a Recursive Neural Tensor Network. We compare these approaches with regard to domain classification accuracy and and study the posterior probability distributions. Then we carry out NMT experiments in the scenario where we have no in-domain parallel corpora and and only very limited in-domain monolingual corpora. Here and we use the domain classifier to reweight the sentences of our out-of-domain training corpus. This leads to improvements of up to 2.1 BLEU for German to English translation.
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,9,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,8,0,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
W19-5344,The {LMU} {M}unich Unsupervised Machine Translation System for {WMT}19,2019,0,1,3,0.606061,3264,dario stojanovski,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,We describe LMU Munich{'}s machine translation system for GermanâCzech translation which was used to participate in the WMT19 shared task on unsupervised news translation. We train our model using monolingual data only from both languages. The final model is an unsupervised neural model using established techniques for unsupervised translation such as denoising autoencoding and online back-translation. We bootstrap the model with masked language model pretraining and enhance it with back-translations from an unsupervised phrase-based system which is itself bootstrapped using unsupervised bilingual word embeddings.
W19-1425,Cross-lingual Annotation Projection Is Effective for Neural Part-of-Speech Tagging,2019,0,0,1,1,5061,matthias huck,"Proceedings of the Sixth Workshop on {NLP} for Similar Languages, Varieties and Dialects",0,"We tackle the important task of part-of-speech tagging using a neural model in the zero-resource scenario, where we have no access to gold-standard POS training data. We compare this scenario with the low-resource scenario, where we have access to a small amount of gold-standard POS training data. Our experiments focus on Ukrainian as a representative of under-resourced languages. Russian is highly related to Ukrainian, so we exploit gold-standard Russian POS tags. We consider four techniques to perform Ukrainian POS tagging: zero-shot tagging and cross-lingual annotation projection (for the zero-resource scenario), and compare these with self-training and multilingual learning (for the low-resource scenario). We find that cross-lingual annotation projection works particularly well in the zero-resource scenario."
P19-1581,Better {OOV} Translation with Bilingual Terminology Mining,2019,0,0,1,1,5061,matthias huck,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Unseen words, also called out-of-vocabulary words (OOVs), are difficult for machine translation. In neural machine translation, byte-pair encoding can be used to represent OOVs, but they are still often incorrectly translated. We improve the translation of OOVs in NMT using easy-to-obtain monolingual data. We look for OOVs in the text to be translated and translate them using simple-to-construct bilingual word embeddings (BWEs). In our MT experiments we take the 5-best candidates, which is motivated by intrinsic mining experiments. Using all five of the proposed target language words as queries we mine target-language sentences. We then back-translate, forcing the back-translation of each of the five proposed target-language OOV-translation-candidates to be the original source-language OOV. We show that by using this synthetic data to fine-tune our system the translation of OOVs can be dramatically improved. In our experiments we use a system trained on Europarl and mine sentences containing medical terms from monolingual data."
W18-6428,The {LMU} {M}unich Unsupervised Machine Translation Systems,2018,0,0,3,0.606061,3264,dario stojanovski,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We describe LMU Munich{'}s unsupervised machine translation systems for EnglishâGerman translation. These systems were used to participate in the WMT18 news translation shared task and more specifically, for the unsupervised learning sub-track. The systems are trained on English and German monolingual data only and exploit and combine previously proposed techniques such as using word-by-word translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation."
W18-6446,{LMU} {M}unich{'}s Neural Machine Translation Systems at {WMT} 2018,2018,0,0,1,1,5061,matthias huck,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We present the LMU Munich machine translation systems for the English{--}German language pair. We have built neural machine translation systems for both translation directions (EnglishâGerman and GermanâEnglish) and for two different domains (the biomedical domain and the news domain). The systems were used for our participation in the WMT18 biomedical translation task and in the shared task on machine translation of news. The main focus of our recent system development efforts has been on achieving improvements in the biomedical domain over last year{'}s strong biomedical translation engine for EnglishâGerman (Huck et al., 2017a). Considerable progress has been made in the latter task, which we report on in this paper."
W18-1805,Neural Morphological Tagging of Lemma Sequences for Machine Translation,2018,0,0,2,0,215,costanza conforti,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,None
W17-4706,Target-side Word Segmentation Strategies for Neural Machine Translation,2017,28,12,1,1,5061,matthias huck,Proceedings of the Second Conference on Machine Translation,0,None
W17-4717,Findings of the 2017 Conference on Machine Translation ({WMT}17),2017,0,109,7,0,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,"This paper presents the results of the WMT17 shared tasks, which includedn three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task."
W17-4730,{LMU} {M}unich{'}s Neural Machine Translation Systems for News Articles and Health Information Texts,2017,21,3,1,1,5061,matthias huck,Proceedings of the Second Conference on Machine Translation,0,None
E17-2059,Producing Unseen Morphological Variants in Statistical Machine Translation,2017,0,6,1,1,5061,matthias huck,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Translating into morphologically rich languages is difficult. Although the coverage of lemmas may be reasonable, many morphological variants cannot be learned from the training data. We present a statistical translation system that is able to produce these inflected word forms. Different from most previous work, we do not separate morphological prediction from lexical choice into two consecutive steps. Our approach is novel in that it is integrated in decoding and takes advantage of context information from both the source language and the target language sides."
W16-2301,Findings of the 2016 Conference on Machine Translation,2016,113,137,6,0,292,ondvrej bojar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 shared tasks, which included five machine translation (MT) tasks (standard news, IT-domain, biomedical, multimodal, pronoun), three evaluation tasks (metrics, tuning, run-time estimation of MT quality), and an automatic post-editing task and bilingual document alignment task. This year, 102 MT systems from 24 institutions (plus 36 anonymized online systems) were submitted to the 12 translation directions in the news translation task. The IT-domain task received 31 submissions from 12 institutions in 7 directions and the Biomedical task received 15 submissions systems from 5 institutions. Evaluation was both automatic and manual (relative ranking and 100-point scale assessments). The quality estimation task had three subtasks, with a total of 14 teams, submitting 39 entries. The automatic post-editing task had a total of 6 teams, submitting 11 entries."
W16-2315,The {E}dinburgh/{LMU} Hierarchical Machine Translation System for {WMT} 2016,2016,39,2,1,1,5061,matthias huck,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine translation of news under xe2x80x9cconstrainedxe2x80x9d conditions, i.e. using the provided training data only."
W16-2320,The {QT}21/{H}im{L} Combined Machine Translation System,2016,5,6,4,0.432099,30412,janthorsten peter,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the joint submission of the QT21 and HimL projects for the Englishxe2x86x92Romanian translation task of the ACL 2016 First Conference on Machine Translation (WMT 2016). The submission is a system combination which combines twelve different statistical machine translation systems provided by the different groups (RWTH Aachen University, LMU Munich, Charles University in Prague, University of Edinburgh, University of Sheffield, Karlsruhe Institute of Technology, LIMSI, University of Amsterdam, Tilde). The systems are combined using RWTHxe2x80x99s system combination approach. The final submission shows an improvement of 1.0 BLEU compared to the best single system on newstest2016."
W16-2327,{E}dinburgh{'}s Statistical Machine Translation Systems for {WMT}16,2016,52,7,4,1,11121,philip williams,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the University of Edinburghxe2x80x99s phrase-based and syntax-based submissions to the shared translation tasks of the ACL 2016 First Conference on Machine Translation (WMT16). We submitted five phrase-based and five syntaxbased systems for the news task, plus one phrase-based system for the biomedical task."
L16-1003,Enhancing Access to Online Education: Quality Machine Translation of {MOOC} Content,2016,19,1,7,0,12066,valia kordoni,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The present work is an overview of the TraMOOC (Translation for Massive Open Online Courses) research and innovation project, a machine translation approach for online educational content. More specifically, videolectures, assignments, and MOOC forum text is automatically translated from English into eleven European and BRIC languages. Unlike previous approaches to machine translation, the output quality in TraMOOC relies on a multimodal evaluation schema that involves crowdsourcing, error type markup, an error taxonomy for translation model comparison, and implicit evaluation via text mining, i.e. entity recognition and its performance comparison between the source and the translated text, and sentiment analysis on the students{'} forum posts. Finally, the evaluation output will result in more and better quality in-domain parallel data that will be fed back to the translation engine for higher quality output. The translation service will be incorporated into the Iversity MOOC platform and into the VideoLectures.net digital library portal."
W15-3001,Findings of the 2015 Workshop on Statistical Machine Translation,2015,78,107,5,0,292,ondvrej bojar,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT15 shared tasks, which included a standard news translation task, a metrics task, a tuning task, a task for run-time estimation of machine translation quality, and an automatic post-editing task. This year, 68 machine translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries."
W15-3013,The {E}dinburgh/{JHU} Phrase-based Machine Translation Systems for {WMT} 2015,2015,30,13,2,0,5032,barry haddow,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper describes the submission of the University of Edinburgh and the Johns Hopkins University for the shared translation task of the EMNLP 2015 Tenth Workshop on Statistical Machine Translation (WMT 2015). We set up phrase-based statistical machine translation systems for all ten language pairs of this yearxe2x80x99s evaluation campaign, which are English paired with Czech, Finnish, French, German, and Russian in both translation directions. Novel research directions we investigated include: neural network language models and bilingual neural network language models, a comprehensive use of word classes, and sparse lexicalized reordering features."
W15-3024,{E}dinburgh{'}s Syntax-Based Systems at {WMT} 2015,2015,-1,-1,4,1,11121,philip williams,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,None
2015.mtsummit-papers.19,Mixed domain vs. multi-domain statistical machine translation,2015,45,6,1,1,5061,matthias huck,Proceedings of Machine Translation Summit XV: Papers,0,"Domain adaptation boosts translation quality on in-domain data, but translation quality for domain adapted systems on out-of-domain data tends to suffer. Users of web-based translation services expect high quality translation across a wide range of diverse domains, and what makes the task even more difficult is that no domain label is provided with the translation request. In this paper we present an approach to domain adaptation which results in large-scale, general purpose machine translation systems. First, we tune our translation models to multiple individual domains. Then, by means of source-side domain classification, we are able to predict the domain of individual input sentences and thereby select the appropriate domain-specific model parameters. We call this approach multi-domain translation. We develop state-of-the-art, domain-adapted translation engines for three broadly-defined domains: TED talks, Europarl, and News. Our results suggest that multi-domain translation performs better than a mixed-domain approach, which deploys a system that has been tuned on a development set composed of samples from many domains."
2015.iwslt-evaluation.4,The {E}dinburgh machine translation systems for {IWSLT} 2015,2015,55,3,1,1,5061,matthias huck,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the University of Edinburghxe2x80x99s machine translation (MT) systems for the IWSLT 2015 evaluation campaign. Our submissions are based on preliminary systems which are under development for the purpose of lecture translation in the TraMOOC project, 1 funded by the European Union. We participated in the English!Chinese and the English!German translation tasks in the MT track, utilizing only data supplied by the organizers or listed as permissible. We built phrase-based translation systems for both tasks. For English!German, we furthermore made use of syntax-based translation and system combination."
W14-4018,Preference Grammars and Soft Syntactic Constraints for {GHKM} Syntax-based Statistical Machine Translation,2014,31,8,1,1,5061,matthias huck,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"In this work, we investigate the effectiveness of two techniques for a featurebased integration of syntactic information into GHKM string-to-tree statistical machine translation (Galley et al., 2004): (1.) Preference grammars on the target language side promote syntactic wellformedness during decoding while also allowing for derivations that are not linguistically motivated (as in hierarchical translation). (2.) Soft syntactic constraints augment the system with additional sourceside syntax features while not modifying the set of string-to-tree translation rules or the baseline feature scores. We conduct experiments with a stateof-the-art setup on an English!German translation task. Our results suggest that preference grammars for GHKM translation are inferior to the plain targetsyntactified model, whereas the enhancement with soft source syntactic constraints provides consistent gains. By employing soft source syntactic constraints with sparse features, we are able to achieve improvements of up to 0.7 points BLEU and 1.0 points TER."
W14-3310,{EU-BRIDGE} {MT}: Combined Machine Translation,2014,59,18,5,1,3519,markus freitag,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes one of the collaborative efforts within EU-BRIDGE to further advance the state of the art in machine translation between two European language pairs, Germanxe2x86x92English and Englishxe2x86x92German. Three research institutes involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the shared translation task of the evaluation campaign at the ACL 2014 Eighth Workshop on Statistical Machine Translation (WMT 2014). We combined up to nine different machine translation engines via system combination. RWTH Aachen University, the University of Edinburgh, and Karlsruhe Institute of Technology developed several individual systems which serve as system combination input. We devoted special attention to building syntax-based systems and combining them with the phrasebased ones. The joint setups yield empirical gains of up to 1.6 points in BLEU and 1.0 points in TER on the WMT newstest2013 test set compared to the best single systems."
W14-3324,{E}dinburgh{'}s Syntax-Based Systems at {WMT} 2014,2014,49,19,4,0.931234,11121,philip williams,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the string-to-tree systems built at the University of Edinburgh for the WMT 2014 shared translation task. We developed systems for English-German, Czech-English, FrenchEnglish, German-English, Hindi-English, and Russian-English. This year we improved our English-German system through target-side compound splitting, morphosyntactic constraints, and refinements to parse tree annotation; we addressed the out-of-vocabulary problem using transliteration for Hindi and Russian and using morphological reduction for Russian; we improved our GermanEnglish system through tree binarization; and we reduced system development time by filtering the tuning sets."
W14-3362,Augmenting String-to-Tree and Tree-to-String Translation with Non-Syntactic Phrases,2014,47,8,1,1,5061,matthias huck,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We present an effective technique to easily augment GHKM-style syntax-based machine translation systems (Galley et al., 2006) with phrase pairs that do not comply with any syntactic well-formedness constraints. Non-syntactic phrase pairs are distinguished from syntactic ones in order to avoid harming effects. We apply our technique in state-of-the-art string-totree and tree-to-string setups. For tree-tostring translation, we furthermore investigate novel approaches for translating with source-syntax GHKM rules in association with input tree constraints and input tree features."
E14-2008,{J}ane: Open Source Machine Translation System Combination,2014,14,17,2,1,3519,markus freitag,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Different machine translation engines can be remarkably dissimilar not only with respect to their technical paradigm, but also with respect to the translation output they yield. System combination is a method for combining the output of multiple machine translation engines in order to take benefit of the strengths of each of the individual engines. In this work we introduce a novel system combination implementation which is integrated into Jane, RWTHxe2x80x99s open source statistical machine translation toolkit. On the most recent Workshop on Statistical Machine Translation system combination shared task, we achieve improvements of up to 0.7 points in BLEU over the best system combination hypotheses which were submitted for the official evaluation. Moreover, we enhance our system combination pipeline with additional n-gram language models and lexical translation models."
2014.iwslt-evaluation.6,{E}dinburgh {SLT} and {MT} system description for the {IWSLT} 2014 evaluation,2014,48,14,2,0,5031,alexandra birch,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the University of Edinburgh{'}s spoken language translation (SLT) and machine translation (MT) systems for the IWSLT 2014 evaluation campaign. In the SLT track, we participated in the GermanâEnglish and EnglishâFrench tasks. In the MT track, we participated in the GermanâEnglish, EnglishâFrench, ArabicâEnglish, FarsiâEnglish, HebrewâEnglish, SpanishâEnglish, and Portuguese-BrazilâEnglish tasks. For our SLT submissions, we experimented with comparing operation sequence models with bilingual neural network language models. For our MT submissions, we explored using unsupervised transliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination."
2014.iwslt-evaluation.7,Combined spoken language translation,2014,55,6,5,1,3519,markus freitag,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE is a European research project which is aimed at developing innovative speech translation technology. One of the collaborative efforts within EU-BRIDGE is to produce joint submissions of up to four different partners to the evaluation campaign at the 2014 International Workshop on Spoken Language Translation (IWSLT). We submitted combined translations to the GermanâEnglish spoken language translation (SLT) track as well as to the GermanâEnglish, EnglishâGerman and EnglishâFrench machine translation (MT) tracks. In this paper, we present the techniques which were applied by the different individual translation systems of RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show the combination approach developed at RWTH Aachen University which combined the individual systems. The consensus translations yield empirical gains of up to 2.3 points in BLEU and 1.2 points in TER compared to the best individual system."
2014.amta-tutorials.5,Statistical machine translation with the {M}oses toolkit,2014,-1,-1,2,0,22899,hieu hoang,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: Tutorials,0,None
W13-2223,Joint {WMT} 2013 Submission of the {QUAERO} Project,2013,34,4,3,0.769231,27027,stephan peitz,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes the joint submission of the QUAERO project for the German!English translation task of the ACL 2013 Eighth Workshop on Statistical Machine Translation (WMT 2013). The submission was a system combination of the output of four different translation systems provided by RWTH Aachen University, Karlsruhe Institute of Technology (KIT), LIMSI-CNRS and SYSTRAN Software, Inc. The translations were joined using the RWTHxe2x80x99s system combination approach. Experimental results show improvements of up to 1.2 points in BLEU and 1.2 points in TER compared to the best single translation."
W13-2224,The {RWTH} {A}achen Machine Translation System for {WMT} 2013,2013,-1,-1,6,0.769231,27027,stephan peitz,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,None
W13-2258,A Phrase Orientation Model for Hierarchical Machine Translation,2013,31,17,1,1,5061,matthias huck,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We introduce a lexicalized reordering model for hierarchical phrase-based machine translation. The model scores monotone, swap, and discontinuous phrase orientations in the manner of the one presented by Tillmann (2004). While this type of lexicalized reordering model is a valuable and widely-used component of standard phrase-based statistical machine translation systems (Koehn et al., 2007), it is however commonly not employed in hierarchical decoders. We describe how phrase orientation probabilities can be extracted from wordaligned training data for use with hierarchical phrase inventories, and show how orientations can be scored in hierarchical decoding. The model is empirically evaluated on the NIST Chinese!English translation task. We achieve a significant improvement of 1.2 %BLEU over a typical hierarchical baseline setup and an improvement of 0.7 %BLEU over a syntax-augmented hierarchical setup. On a French!German translation task, we obtain a gain of up to 0.4 %BLEU."
W13-0804,A Performance Study of Cube Pruning for Large-Scale Hierarchical Machine Translation,2013,36,3,1,1,5061,matthias huck,"Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"In this paper, we empirically investigate the impact of critical configuration parameters in the popular cube pruning algorithm for decoding in hierarchical statistical machine translation. Specifically, we study how the choice of the k-best generation size affects translation quality and resource requirements in hierarchical search. We furthermore examine the influence of two different granularities of hypothesis recombination. Our experiments are conducted on the large-scale Chinese!English and Arabic!English NIST translation tasks. Besides standard hierarchical grammars, we also explore search with restricted recursion depth of hierarchical rules based on shallow-1 grammars."
2013.mtsummit-papers.20,Reverse Word Order Model,2013,-1,-1,3,1,3519,markus freitag,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.iwslt-evaluation.16,{EU}-{BRIDGE} {MT}: text translation of talks in the {EU}-{BRIDGE} project,2013,52,8,6,1,3519,markus freitag,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes one of the collaborative efforts within EUBRIDGE to further advance the state of the art in machine translation between two European language pairs, EnglishâFrench and GermanâEnglish. Four research institutions involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the machine translation track of the evaluation campaign at the 2013 International Workshop on Spoken Language Translation (IWSLT). We present the methods and techniques to achieve high translation quality for text translation of talks which are applied at RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show how we have been able to considerably boost translation performance (as measured in terms of the metrics BLEU and TER) by means of system combination. The joint setups yield empirical gains of up to 1.4 points in BLEU and 2.8 points in TER on the IWSLT test sets compared to the best single systems."
W12-3137,The {RWTH} {A}achen Machine Translation System for {WMT} 2012,2012,-1,-1,1,1,5061,matthias huck,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,None
W12-3140,Joint {WMT} 2012 Submission of the {QUAERO} Project,2012,37,5,3,1,3519,markus freitag,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the joint QUAERO submission to the WMT 2012 machine translation evaluation. Four groups (RWTH Aachen University, Karlsruhe Institute of Technology, LIMSI-CNRS, and SYSTRAN) of the QUAERO project submitted a joint translation for the WMT Germanxe2x86x92English task. Each group translated the data sets with their own systems and finally the RWTH system combination combined these translations in our final submission. Experimental results show improvements of up to 1.7 points in Bleu and 3.4 points in Ter compared to the best single system."
N12-1035,Insertion and Deletion Models for Statistical Machine Translation,2012,17,6,1,1,5061,matthias huck,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We investigate insertion and deletion models for hierarchical phrase-based statistical machine translation. Insertion and deletion models are designed as a means to avoid the omission of content words in the hypotheses. In our case, they are implemented as phrase-level feature functions which count the number of inserted or deleted words. An English word is considered inserted or deleted based on lexical probabilities with the words on the foreign language side of the phrase. Related techniques have been employed before by Och et al. (2003) in an n-best reranking framework and by Mauser et al. (2006) and Zens (2008) in a standard phrase-based translation system. We propose novel thresholding methods in this work and study insertion and deletion features which are based on two different types of lexicon models. We give an extensive experimental evaluation of all these variants on the NIST Chinesexe2x86x92English translation task."
C12-3061,{J}ane 2: Open Source Phrase-based and Hierarchical Statistical Machine Translation,2012,36,34,2,0.5,7150,joern wuebker,Proceedings of {COLING} 2012: Demonstration Papers,0,"We present Jane 2, an open source toolkit supporting both the phrase-based and the hierarchical phrase-based paradigm for statistical machine translation. It is implemented in C and provides efficient decoding algorithms and data structures. This work focuses on the description of its phrase-based functionality. In addition to the standard pipeline, including phrase extraction and parameter optimization, Jane 2 contains several state-of-the-art extensions and tools. Forced alignment phrase training can considerably reduce rule table size while learning the translation scores in a more principled manner. Word class language models can be used to integrate longer context with a reduced vocabulary size. Rule table interpolation is applicable for different tasks, e.g. domain adaptation. The decoder distinguishes between lexical and coverage pruning and applies reordering constraints for efficiency."
2012.iwslt-evaluation.7,The {RWTH} {A}achen speech recognition and machine translation system for {IWSLT} 2012,2012,36,2,5,0.769231,27027,stephan peitz,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, the automatic speech recognition (ASR) and statistical machine translation (SMT) systems of RWTH Aachen University developed for the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2012 are presented. We participated in the ASR (English), MT (English-French, Arabic-English, Chinese-English, German-English) and SLT (English-French) tracks. For the MT track both hierarchical and phrase-based SMT decoders are applied. A number of different techniques are evaluated in the MT and SLT tracks, including domain adaptation via data selection, translation model interpolation, phrase training for hierarchical and phrase-based systems, additional reordering model, word class language model, various Arabic and Chinese segmentation methods, postprocessing of speech recognition output with an SMT system, and system combination. By application of these methods we can show considerable improvements over the respective baseline systems."
2012.eamt-1.66,Discriminative Reordering Extensions for Hierarchical Phrase-Based Machine Translation,2012,17,12,1,1,5061,matthias huck,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"In this paper, we propose novel extensions of hierarchical phrase-based systems with a discriminative lexicalized reordering model. We compare different feature sets for the discriminative reordering model and investigate combinations with three types of non-lexicalized reordering rules which are added to the hierarchical grammar in order to allow for more reordering flexibility during decoding. All extensions are evaluated in standard hierarchical setups as well as in setups where the hierarchical recursion depth is restricted. We achieve improvements of up to 1.2 %BLEU on a large-scale Chinese!English translation task."
2012.amta-papers.8,Pivot Lightly-Supervised Training for Statistical Machine Translation,2012,-1,-1,1,1,5061,matthias huck,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In this paper, we investigate large-scale lightly-supervised training with a pivot language: We augment a baseline statistical machine translation (SMT) system that has been trained on human-generated parallel training corpora with large amounts of additional unsupervised parallel data; but instead of creating this synthetic data from monolingual source language data with the baseline system itself, or from target language data with a reverse system, we employ a parallel corpus of target language data and data in a pivot language. The pivot language data is automatically translated into the source language, resulting in a trilingual corpus with unsupervised source language side. We augment our baseline system with the unsupervised source-target parallel data. Experiments are conducted for the German-French language pair using the standard WMT newstest sets for development and testing. We obtain the unsupervised data by translating the English side of the English-French 109 corpus to German. With careful system design, we are able to achieve improvements of up to +0.4 points BLEU / -0.7 points TER over the baseline."
W11-2211,Lightly-Supervised Training for Hierarchical Phrase-Based Machine Translation,2011,23,7,1,1,5061,matthias huck,Proceedings of the First workshop on Unsupervised Learning in {NLP},0,In this paper we apply lightly-supervised training to a hierarchical phrase-based statistical machine translation system. We employ bitexts that have been built by automatically translating large amounts of monolingual data as additional parallel training corpora. We explore different ways of using this additional data to improve our system.n n Our results show that integrating a second translation model with only non-hierarchical phrases extracted from the automatically generated bitexts is a reasonable approach. The translation performance matches the result we achieve with a joint extraction on all training bitexts while the system is kept smaller due to a considerably lower overall number of phrases.
W11-2149,The {RWTH} {A}achen Machine Translation System for {WMT} 2011,2011,13,3,1,1,5061,matthias huck,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"We describe our system for the news commentary translation task of WMT 2011. The submitted run for the French-English direction is a combination of two MOSES-based systems developed at LIG and LIA laboratories. We report experiments to improve over the standard phrase-based model using statistical post-edition, information retrieval methods to subsample out-of-domain parallel corpora and Rover to combine n-best list of hypotheses output by different systems."
2011.iwslt-papers.1,Lexicon models for hierarchical phrase-based machine translation,2011,26,7,1,1,5061,matthias huck,Proceedings of the 8th International Workshop on Spoken Language Translation: Papers,0,"In this paper, we investigate lexicon models for hierarchical phrase-based statistical machine translation. We study five types of lexicon models: a model which is extracted from word-aligned training data and{---}given the word alignment matrix{---}relies on pure relative frequencies [1]; the IBM model 1 lexicon [2]; a regularized version of IBM model 1; a triplet lexicon model variant [3]; and a discriminatively trained word lexicon model [4]. We explore sourceto-target models with phrase-level as well as sentence-level scoring and target-to-source models with scoring on phrase level only. For the first two types of lexicon models, we compare several scoring variants. All models are used during search, i.e. they are incorporated directly into the log-linear model combination of the decoder. Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions. We also propose a new regularization technique for IBM model 1 by means of the Kullback-Leibler divergence with the empirical unigram distribution as regularization term. Experiments are carried out on the large-scale NIST ChineseâEnglish translation task and on the EnglishâFrench and ArabicâEnglish IWSLT TED tasks. For ChineseâEnglish and EnglishâFrench, we obtain the best results by using the discriminative word lexicon to smooth our phrase tables."
2011.iwslt-papers.8,Soft string-to-dependency hierarchical machine translation,2011,0,7,2,0.952381,30412,janthorsten peter,Proceedings of the 8th International Workshop on Spoken Language Translation: Papers,0,"In this paper, we dissect the influence of several target-side dependency-based extensions to hierarchical machine translation, including a dependency language model (LM). We pursue a non-restrictive approach that does not prohibit the production of hypotheses with malformed dependency structures. Since many questions remained open from previous and related work, we offer in-depth analysis of the influence of the language model order, the impact of dependency-based restrictions on the search space, and the information to be gained from dependency tree building during decoding. The application of a non-restrictive approach together with an integrated dependency LM scoring is a novel contribution which yields significant improvements for two large-scale translation tasks for the language pairs Chinese{--}English and German{--}French."
2011.iwslt-evaluation.14,The {RWTH} {A}achen machine translation system for {IWSLT} 2011,2011,-1,-1,2,0.576923,7150,joern wuebker,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper the statistical machine translation (SMT) systems of RWTH Aachen University developed for the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2011 is presented. We participated in the MT (English-French, Arabic-English, ChineseEnglish) and SLT (English-French) tracks. Both hierarchical and phrase-based SMT decoders are applied. A number of different techniques are evaluated, including domain adaptation via monolingual and bilingual data selection, phrase training, different lexical smoothing methods, additional reordering models for the hierarchical system, various Arabic and Chinese segmentation methods, punctuation prediction for speech recognition output, and system combination. By application of these methods we can show considerable improvements over the respective baseline systems."
2011.eamt-1.37,Advancements in {A}rabic-to-{E}nglish Hierarchical Machine Translation,2011,20,4,1,1,5061,matthias huck,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"In this paper we study several advanced techniques and models for Arabic-toEnglish statistical machine translation. We examine how the challenges imposed by this particular language pair and translation direction can be successfully tackled within the framework of hierarchical phrase-based translation. We extend the state-of-the-art with a novel cross-system and cross-paradigm lightlysupervised training approach. In addition, for following recently developed techniques we provide a concise review, an empirical evaluation, and an in-depth analysis: soft syntactic labels, a discriminative word lexicon model, additional reorderings, and shallow rules. We thus bring together complementary methods that previously have only been investigated in isolation and mostly on different language pairs. Combinations of the methods yield significant improvements over a baseline using a usual set of models. The resulting hierarchical systems perform competitive on the large-scale NIST Arabic-to-English translation task."
W10-1711,The {RWTH} {A}achen Machine Translation System for {WMT} 2010,2010,61,32,3,0,37774,carmen heger,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the statistical machine translation (SMT) systems developed at RWTH Aachen University for the translation task of the NAACL 2012 Seventh Workshop on Statistical Machine Translation (WMT 2012). We participated in the evaluation campaign for the French-English and German-English language pairs in both translation directions. Both hierarchical and phrase-based SMT systems are applied. A number of different techniques are evaluated, including an insertion model, different lexical smoothing methods, a discriminative reordering extension for the hierarchical system, reverse translation, and system combination. By application of these methods we achieve considerable improvements over the respective baseline systems."
W10-1738,"{J}ane: Open Source Hierarchical Translation, Extended with Reordering and Lexicon Models",2010,29,67,3,0,5800,david vilar,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"We present Jane, RWTH's hierarchical phrase-based translation system, which has been open sourced for the scientific community. This system has been in development at RWTH for the last two years and has been successfully applied in different machine translation evaluations. It includes extensions to the hierarchical approach developed by RWTH as well as other research institutions. In this paper we give an overview of its main features.n n We also introduce a novel reordering model for the hierarchical phrase-based approach which further enhances translation performance, and analyze the effect some recent extended lexicon models have on the performance of the system."
2010.amta-papers.32,A Comparison of Various Types of Extended Lexicon Models for Statistical Machine Translation,2010,-1,-1,1,1,5061,matthias huck,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In this work we give a detailed comparison of the impact of the integration of discriminative and trigger-based lexicon models in state-of-the-art hierarchical and conventional phrase-based statistical machine translation systems. As both types of extended lexicon models can grow very large, we apply certain restrictions to discard some of the less useful information. We show how these restrictions facilitate the training of the extended lexicon models. We finally evaluate systems that incorporate both types of models with different restrictions on a large-scale translation task for the Arabic-English language pair. Our results suggest that extended lexicon models can be substantially reduced in size while still giving clear improvements in translation performance."
