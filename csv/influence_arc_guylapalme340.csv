2001.mtsummit-papers.36,J93-2003,0,0.0436816,"we clean up the resulting model by filtering out dubious associations. The motivation behind this process is essentially practical. We do not believe that separating the identification of salient units from their bilingual mapping is a promising approach. It would be much better to look for a translation model which allows ;=<?&gt; associations. Of course, the problem for such an approach is to find a way to cope with the well known malediction of multidimensionality (any group of source words being potentially associated to any target group one). More advanced models such as IBM models 3 to 5 (Brown et al., 1993) which permit * <@; associations may be seen as a step in this direction. More recently, the 2-stage model described by Och (Och and Weber, 98; Och et al., 99) seems to be another alternative — at least in a task comparable to the Verbmobil one — as it allows certain hidden structural information to be captured. best results. An exemple of the output of this process is reported in Table 1 for a pair of sentences from the Hansard corpus. H K L O MNN 9QKRSKTU9 NNP VXW Y[ZV^] Gb c bdfee g[h E_a` ` _Xi jk c qr AaB  D & cl E H Km,nIo,p*&apos; (2) Identifying monolingual salient sequences"
2001.mtsummit-papers.36,langlais-etal-2000-evaluation,1,0.898765,"rtion point. Evaluation An implementation of T RANS T YPE which allows the completion of words was evaluated in two ways. In a theoretical evaluation, a simulated user generates character by character the target part of a test corpus, accepting as soon as it is helpful the first completion provided by T RANS T YPE. It was shown that under this scenario, a user could save about two thirds of the keystrokes needed to produce a translation (Foster et al., 1997). An in-situ evaluation involving ten translators who were asked to translate the same text using T RANS T YPE has also been carried out (Langlais et al., 2000b). Some interesting observations emerged which motivate the present study. Only one translator actually managed to translate faster using T RANS T YPE; this suggests that even in a very simple scenario, target-text mediated interactive translation is at least viable. Lack of training time is probably one reason for these otherwise disappointing results. The fact that real users do not systematically watch the screen when typing may also account for part of the problem. A qualitative survey revealed that most users (actually nine out of ten) liked T RANS T YPE and would be eager to try it in t"
2001.mtsummit-papers.36,W97-0311,0,0.0227295,"nslation (e.g. bill/facture vs bill/projet de loi), lexicons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units"
2001.mtsummit-papers.36,1999.tmi-1.9,0,0.0455546,"bill/facture vs bill/projet de loi), lexicons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units hereafter) are linked across"
2001.mtsummit-papers.36,P99-1067,0,0.0120337,"e loi), lexicons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units hereafter) are linked across languages."
2001.mtsummit-papers.36,P97-1061,0,0.0170624,"emple of the output of this process is reported in Table 1 for a pair of sentences from the Hansard corpus. H K L O MNN 9QKRSKTU9 NNP VXW Y[ZV^] Gb c bdfee g[h E_a` ` _Xi jk c qr AaB  D & cl E H Km,nIo,p*&apos; (2) Identifying monolingual salient sequences Distributional filters The literature abounds in measures that help to decide whether words that happen to co-occur are linguistically significant or not. In this study, we rated the coherence of any sequence of words seen in a training corpus by means of two measures: a likelihood-based one (Dunning, 93) and an entropy-based one (Shimohata et al., 1997). Observing the output produced by these methods, it is immediatly apparent that neither metric guarantees that the best ranked units are those that we would ourselves manually select as salient. In particular, it is clear that many sequences overlap; which further complicating the selection process. For this reason, we applied a cascade filter to remove well-rated but non-salient units. Below, we report on the results of a filtering process (called DIST) which removes any sequence seen only once or having a likelihood ratio lower than 5.0; DIST also removes some sequences that overlap with ot"
2001.mtsummit-papers.36,1999.tmi-1.11,0,0.021485,"cons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units hereafter) are linked across languages. Last but not least, we cl"
2001.mtsummit-papers.36,W99-0604,0,\N,Missing
2001.mtsummit-papers.36,A00-1019,1,\N,Missing
2001.mtsummit-papers.36,P98-2162,0,\N,Missing
2001.mtsummit-papers.36,C98-2157,0,\N,Missing
2003.jeptalnrecital-poster.14,W00-1404,1,0.892008,"Missing"
2003.jeptalnrecital-poster.14,C02-1128,1,0.835828,"Missing"
2003.jeptalnrecital-poster.14,P98-2173,0,0.0482442,"Missing"
2004.jeptalnrecital-long.26,P03-2002,1,0.864935,"Missing"
2004.jeptalnrecital-long.26,P94-1002,0,0.0817227,"Missing"
2005.eamt-1.23,2004.iwslt-evaluation.1,0,0.0542013,"hine Translation is a field nowadays strongly anchored in a paradigm of performance. Evaluation exercises such as those conducted within the TIDES project are pushing system designers to constantly improve their systems. The shared task usually consists in translating news articles excerpts from a foreign language into English. While this is certainly a challenging issue, real life applications of machine translation in a production setting (i.e. without human revision) will likely be more targeted than newspaper articles. More focused evaluation exercises do exist. Within the IWSLT workshop (Akiba et al., 2004), the main objective was to provide an evaluation framework for spoken language translation technologies. The shared task consisted in translating sentences from the Basic Travel Expression Corpus (BTEC) which gathers sentences believed to be useful for a tourist in a foreign country. In the Verbmobil project (Wahlster, 2000), transcriptions of spontaneous speech from several narrow domains such as ap166 pointment scheduling were translated from German into English. In this study, we focus on an even more concrete task and one of the greatest successes of machine translation: the English to Fr"
2005.eamt-1.23,C02-1134,0,0.222759,"Missing"
2005.eamt-1.23,C04-1046,1,0.822277,"of Figure 2. The weights on the arcs are the frequency of a given transition. A non-smoothed local bigram language model is obtained by simply normalizing each node by the sum of the weights of the arcs leaving this node. provement. memory + consensus WER SER NIST BLEU 18.69 18.97 94.82 85.53 9.7853 9.9314 66.56 68.86 Table 4: Results of the consensus approach on the output of the memory, for the 13 010 sentences of BLANC not seen verbatim in the TRAIN corpus. 6 The rescoring approach Several papers recently described rescoring approaches for improving the accuracy of a base MT system (e.g. (Blatz et al., 2004)). Rescoring is based on the hope that with the help of additional information (or different ways of using it), we can change the ranks of translations in a nbest list. One motivation for such an approach is that the best translation among alternatives is often not the first one proposed by the base system. P HARAOH, used in section 4, can output its search graph for which the C ARMEL package (Knight and Al-Onaizan, 1999) used in the preceding section, can produce n-best lists. For each source sentence s we built a n-best list of up to 10 different translation alternatives {tj }j∈[1,n≤10] usin"
2005.eamt-1.23,J93-2003,0,0.00649038,"C TEST WER SER NIST BLEU 8.17 7.46 32.46 32.01 10.4081 10.8725 83.52 84.03 Table 3: Results of the phrase-based statistical engine on the BLANC and TEST corpora. longest sequence in a pair was at most twice the length of its counterpart5 . Doing so, we acquired a model of 3 199 163 parameters. We considered two ways of scoring each parameter. The first one is by relative frequency, that is, simply by counting the number of times a given pair (f, e) was seen aligned in the bitext, normalized by the number of times f was seen. The second score we used is the IBM model 1 conditional probability (Brown et al., 1993): p(eji |fab ) −j+i−1 = (b − a) j  b  y=i x=a p(ey |fx ) (1) Since we had only a few parameters to tune, we sought the best setting by uniformly sampling each parameter range with a small enough step size (0.1 for weighting coefficients, and 0.2 for the word penalty). Indeed, we did not find the tuning to bring much gain. In particular, a contrario to the observation we made on other translation tasks, we did not observe a huge difference in performance between the relative frequency score and the IBM one. This might be due to the fact that each parameter is seen often enough that relative f"
2005.eamt-1.23,W98-1435,0,0.230837,"this task. Some alternatives to Machine Translation (MT) have been proposed for weather reports, namely multilingual text generation directly from raw weather data: temperatures, winds, pressures etc. In these generation systems, humans still make selections on templates in order to organize the report. Generating text in many languages from one source is quite appealing from a conceptual point of view and has been cited as one of the potential applications for natural language generation (Reiter and Dale, 2000); some systems have been developed (Kittredge et al., 1986; Goldberg et al., 1994; Coch, 1998) and tested in operational contexts. A recent experiment (Reiter, 2005) even suggests that in some ways automatically generated reports are judged better by humans than human written forecasts! But to our knowledge, no automatic generation has yet been put to daily use on the same level as the one attained by MT, one of the reasons being that meteorologists prefer to write their reports in natural language rather than selecting text structure templates. So we are confident that there is still a need (and a market ?) for a the automatic translation of manually written weather reports. 9 Acknowl"
2005.eamt-1.23,C86-1132,0,0.206006,"Missing"
2005.eamt-1.23,2005.eamt-1.23,1,0.124992,"n the very short life of a weather report. Weather reports are issued every 6 hours. We specifically chose this task because there already exists a fully operational rule-based translation system designed for it, who’s performance was carefully measured (Macklovitch (1985)), and because a very large bitext corpus of previously published weather forcasts is available. Thus, we were able to build a variety of corpus-based MT systems targeted on this specific task and compare their respective performances. 1 The current reports are available at http://meteo. ec.gc.ca/forecast/textforecast_f.html EAMT 2005 Conference Proceedings From the real world to real Words: the METEO case Langlais, Leplus, Grandrabur, Lapalme In the mid seventies, a group of linguists and computer scientists of Universit´e de Montr´eal (TAUM group) developed an English to French weather report machine translation system which became known as the TAUM -M ETEO system. Spin-offs of that research system, namely METEO-1 and METEO-2 (Grimaila and Chandioux, 1992), have been in continuous use since 1984 translating up to 45,000 words a day. A description of the system is presented in (Hutchins and Somers, 1992, chap12). Roughly,"
2005.eamt-1.23,N03-1017,0,0.00999102,"sing the SRILM package (Stolcke, 2002). The perplexity of this model on BLANC and TEST is respectively 4.94 and 3.83, which is very low compared to standard benchmarks (Zens and Ney, 2004). To build our translation table, we first aligned our bitext at the word level. Following a common practice, we used the GIZA++ package (Och and Ney, 2000) to word-align our bitext in both directions (English-to-French and FrenchTo-English)4 . We extended the set of word links that were present in both alignments by some links belonging to only one alignment direction, following the heuristics described in (Koehn et al., 2003). From the resulting alignment A, we collected the set of pairs of source and target sequences (fab , eji ) from all regions (a, b) × (i, j) in the alignment matrix where none of the source words in fab is aligned to a word not belonging to eji and vice-versa: ∀x ∈ [a, b], ∀y : (x, y) ∈ A, y ∈ [i, j] ∀y ∈ [i, j], ∀x : (x, y) ∈ A, x ∈ [a, b] We did apply a few length-based heuristics to filter the parameters acquired in this way: (source or target) sequences of at most 8 words were considered and we imposed that the length of the 4 We used the alignments produced by IBM model 2. EAMT 2005 Confe"
2005.eamt-1.23,leplus-etal-2004-weather,1,0.749326,"d seventies, a group of linguists and computer scientists of Universit´e de Montr´eal (TAUM group) developed an English to French weather report machine translation system which became known as the TAUM -M ETEO system. Spin-offs of that research system, namely METEO-1 and METEO-2 (Grimaila and Chandioux, 1992), have been in continuous use since 1984 translating up to 45,000 words a day. A description of the system is presented in (Hutchins and Somers, 1992, chap12). Roughly, it involves three major steps: dictionary look-up, syntactic analysis and light syntactic and morphological generation. Leplus et al. (2004) described experiments they conducted on a bitext of forecasts in both French and English produced during 2002 and 2003 by Environment Canada. They report fairly good translation results by applying a straightforward memory-based approach to the task. The authors mentioned that this approach is warranted by the particularly high rate of sentence repetitions. Indeed, Grimaila and Chandioux (1992) argued that the repetitiveness of the task was one of the reasons for the success of the METEO system. In the current work, we explore how well stateof-the-art corpus-based approaches can do for the sa"
2005.eamt-1.23,P00-1056,0,0.0227071,"We split the TRAIN corpus in two subparts, TRAIN - T (4 180 000 pairs of sentences) for training the translation and the language models, and TRAIN - H (8 100 pairs) for tuning the different parameters of the engine. We trained a KneserNey smoothed trigram language model using the SRILM package (Stolcke, 2002). The perplexity of this model on BLANC and TEST is respectively 4.94 and 3.83, which is very low compared to standard benchmarks (Zens and Ney, 2004). To build our translation table, we first aligned our bitext at the word level. Following a common practice, we used the GIZA++ package (Och and Ney, 2000) to word-align our bitext in both directions (English-to-French and FrenchTo-English)4 . We extended the set of word links that were present in both alignments by some links belonging to only one alignment direction, following the heuristics described in (Koehn et al., 2003). From the resulting alignment A, we collected the set of pairs of source and target sequences (fab , eji ) from all regions (a, b) × (i, j) in the alignment matrix where none of the source words in fab is aligned to a word not belonging to eji and vice-versa: ∀x ∈ [a, b], ∀y : (x, y) ∈ A, y ∈ [i, j] ∀y ∈ [i, j], ∀x : (x, y"
2005.eamt-1.23,N04-1021,0,0.177775,"group of linguists and computer scientists of Universit´e de Montr´eal (TAUM group) developed an English to French weather report machine translation system which became known as the TAUM -M ETEO system. Spin-offs of that research system, namely METEO-1 and METEO-2 (Grimaila and Chandioux, 1992), have been in continuous use since 1984 translating up to 45,000 words a day. A description of the system is presented in (Hutchins and Somers, 1992, chap12). Roughly, it involves three major steps: dictionary look-up, syntactic analysis and light syntactic and morphological generation. Leplus et al. (2004) described experiments they conducted on a bitext of forecasts in both French and English produced during 2002 and 2003 by Environment Canada. They report fairly good translation results by applying a straightforward memory-based approach to the task. The authors mentioned that this approach is warranted by the particularly high rate of sentence repetitions. Indeed, Grimaila and Chandioux (1992) argued that the repetitiveness of the task was one of the reasons for the success of the METEO system. In the current work, we explore how well stateof-the-art corpus-based approaches can do for the sa"
2005.eamt-1.23,N04-1033,0,0.0892427,"quiring a language model and a translation table; if desired, weighting coefficients as well as a few pruning options can control the behavior of the engine. We split the TRAIN corpus in two subparts, TRAIN - T (4 180 000 pairs of sentences) for training the translation and the language models, and TRAIN - H (8 100 pairs) for tuning the different parameters of the engine. We trained a KneserNey smoothed trigram language model using the SRILM package (Stolcke, 2002). The perplexity of this model on BLANC and TEST is respectively 4.94 and 3.83, which is very low compared to standard benchmarks (Zens and Ney, 2004). To build our translation table, we first aligned our bitext at the word level. Following a common practice, we used the GIZA++ package (Och and Ney, 2000) to word-align our bitext in both directions (English-to-French and FrenchTo-English)4 . We extended the set of word links that were present in both alignments by some links belonging to only one alignment direction, following the heuristics described in (Koehn et al., 2003). From the resulting alignment A, we collected the set of pairs of source and target sequences (fab , eji ) from all regions (a, b) × (i, j) in the alignment matrix wher"
2005.eamt-1.23,koen-2004-pharaoh,0,\N,Missing
2005.jeptalnrecital-court.14,2004.iwslt-evaluation.1,0,0.0399483,"Missing"
2005.jeptalnrecital-court.14,C02-1134,0,0.0434285,"Missing"
2005.jeptalnrecital-court.14,C04-1046,1,0.887609,"Missing"
2005.jeptalnrecital-court.14,J93-2003,0,0.005862,"Missing"
2005.jeptalnrecital-court.14,N03-1017,0,0.0127935,"Missing"
2005.jeptalnrecital-court.14,2005.eamt-1.23,1,0.800055,"Missing"
2005.jeptalnrecital-court.14,leplus-etal-2004-weather,1,0.891043,"Missing"
2005.jeptalnrecital-court.14,N04-1033,0,0.0276551,"Missing"
2005.jeptalnrecital-court.14,koen-2004-pharaoh,0,\N,Missing
2005.jeptalnrecital-court.14,P00-1056,0,\N,Missing
2005.jeptalnrecital-court.3,P02-1031,0,0.0557699,"Missing"
2005.jeptalnrecital-court.3,J95-2003,0,0.0799333,"Missing"
2005.jeptalnrecital-court.3,P03-1002,0,0.0554917,"Missing"
2005.jeptalnrecital-long.19,N03-1020,0,0.0919187,"Missing"
2005.mtsummit-posters.1,1997.mtsummit-papers.1,0,0.0969056,"ed naturally. Instead, it unobtrusively records the expert’s every action as she works with the system, as well as the system’s response to each such action, and discreetly stores them in an electronic ﬁle that can later be analyzed in detail. Just as with the ﬁlming of a sports event, careful analysis of this trace ﬁle can often prove very revealing; or at least this has been our experience. We have designed such a tracing facility as part of our contribution to a research project called TransType, the goal of which is to explore the feasibility of a new type interactive machine translation (Foster et al., 1997; Langlais et al., 2002a; Langlais et al., 2001). Our automatic tracing program, christened TTPlayer, analyses the trace ﬁle of a translator’s working session using TransType and generates detailed statistics on a host of interesting questions. Furthermore, TTPlayer can also read the trace ﬁle and visually replay the translation session, much like a video cassette recorder. In eﬀect, it’s almost as though we were actually present and able to peer over the translator’s shoulder, except that we can stop, slow down, accelerate and rewind the action at will. This too facilitates our eﬀorts to bett"
2005.mtsummit-posters.1,W02-1020,1,0.832069,"nt Interface (MDI). In order to guarantee a faithful rendition of the actions of the trace, TTPlayer disables all user events sent to the GUI except for scroll-bar manipulations. On the other hand, the user can control the manner in which the trace is played via the forward, rewind, fast forward and pause buttons. Using the same framework of sending events to a common interface, we have also implemented a non-graphical mode to compute global statistics over the whole trace ﬁle without displaying the user actions. 3.2 Role in usability studies An earlier version of TTPlayer was used by Foster (Foster, 2002) for developing a user Figure 3: Screenshot of a TTPlayer session. The content of the trace appears on the right; the bottom panels show the controls of the player on the left and the statistics of the translator that are updated on the right. The center is taken by the trace ﬁle that is being played back. Characters that were suggested by TransType and accepted by the translator appear in red (or in shaded grey on a black and white printed copy) model that takes into account such parameters as the time needed to read a suggestion, the probability of rejecting or accepting it, the probability"
2005.mtsummit-posters.1,langlais-etal-2002-translators,1,0.925471,", it unobtrusively records the expert’s every action as she works with the system, as well as the system’s response to each such action, and discreetly stores them in an electronic ﬁle that can later be analyzed in detail. Just as with the ﬁlming of a sports event, careful analysis of this trace ﬁle can often prove very revealing; or at least this has been our experience. We have designed such a tracing facility as part of our contribution to a research project called TransType, the goal of which is to explore the feasibility of a new type interactive machine translation (Foster et al., 1997; Langlais et al., 2002a; Langlais et al., 2001). Our automatic tracing program, christened TTPlayer, analyses the trace ﬁle of a translator’s working session using TransType and generates detailed statistics on a host of interesting questions. Furthermore, TTPlayer can also read the trace ﬁle and visually replay the translation session, much like a video cassette recorder. In eﬀect, it’s almost as though we were actually present and able to peer over the translator’s shoulder, except that we can stop, slow down, accelerate and rewind the action at will. This too facilitates our eﬀorts to better understand the behav"
2005.mtsummit-posters.1,macklovitch-2004-contribution,1,0.784441,"e required to produce her translation. With the system’s predictor turned on, the same participant required an average of only 3.48 actions per word to produce her target texts. In other words, TransType was allowing this participant to produce her translations with about half the (physical) eﬀort she required to translate on her own. And, of course, translation quality can also beneﬁt from the system’s predictions, by reducing the time that users have to devote to terminological research. A more detailed analysis of the results obtained with TransType in our usability trials can be found in (Macklovitch, 2004). 4 Conclusion This paper has shown the interest of tracing as a tool for obtaining knowledge about potential users in the context of developing applications that embed advanced AI components. Given the fact that the medium of interaction in our application is a text editor, instrumenting it through a trace ﬁle was a natural and unobtrusive way of keeping track of users’ actions. This general approach can certainly be extended to other interactive applications, particularly those that involve text. 5 Acknowledgment We want to thank all members of the TT2 consortium, especially the translators"
2006.jeptalnrecital-long.10,A00-2004,0,0.0412164,"Missing"
2006.jeptalnrecital-long.10,J97-1003,0,0.226282,"Missing"
2006.jeptalnrecital-long.10,W04-1013,0,0.00507667,"Missing"
2007.jeptalnrecital-demonstration.3,A00-1018,0,0.0459065,"Missing"
2007.jeptalnrecital-demonstration.3,1995.mtsummit-1.36,1,0.718196,"Missing"
2007.jeptalnrecital-demonstration.3,2005.tc-1.7,0,0.0513547,"Missing"
2008.amta-govandcom.11,P07-2045,0,0.00584144,"l use within NLP Technologies in order to produce DecisionExpress™ fact sheets and summaries. We extract the source text from these structured XML files in which sentence boundaries have already been identified. This is essential, since the translation engine works sentence by sentence. The second phase translates the source sentences into the target language using SMT. The SMT module makes use of open source modules GIZA++3 for creating the translation models and SRILM4 for the language models. We considered a few phrase-based translation engines such as Phramer (Olteanu et al, 2006), Moses (Koehn et al., 2007), Pharaoh (Koehn, 2004), Ramses (Patry et al., 2006) and Portage5. Moses was selected because we found it to be a state-of-the-art package with a convenient open source license for our testing purposes. The last phase is devoted to the rendering of the translated decisions in HTML. Because appropriate bookkeeping information has been maintained, it is possible to merge the translation with the original XML file in order to yield a second XML file containing a bilingual version of each segment of text. This bilingual file can then be used to produce an HTML version of the translation, or for ot"
2008.amta-govandcom.11,W07-0733,0,0.0788253,"Missing"
2008.amta-govandcom.11,koen-2004-pharaoh,0,0.0759724,"in order to produce DecisionExpress™ fact sheets and summaries. We extract the source text from these structured XML files in which sentence boundaries have already been identified. This is essential, since the translation engine works sentence by sentence. The second phase translates the source sentences into the target language using SMT. The SMT module makes use of open source modules GIZA++3 for creating the translation models and SRILM4 for the language models. We considered a few phrase-based translation engines such as Phramer (Olteanu et al, 2006), Moses (Koehn et al., 2007), Pharaoh (Koehn, 2004), Ramses (Patry et al., 2006) and Portage5. Moses was selected because we found it to be a state-of-the-art package with a convenient open source license for our testing purposes. The last phase is devoted to the rendering of the translated decisions in HTML. Because appropriate bookkeeping information has been maintained, it is possible to merge the translation with the original XML file in order to yield a second XML file containing a bilingual version of each segment of text. This bilingual file can then be used to produce an HTML version of the translation, or for other types of processing"
2008.amta-govandcom.11,W06-3121,0,0.202053,"nsformed into XML for internal use within NLP Technologies in order to produce DecisionExpress™ fact sheets and summaries. We extract the source text from these structured XML files in which sentence boundaries have already been identified. This is essential, since the translation engine works sentence by sentence. The second phase translates the source sentences into the target language using SMT. The SMT module makes use of open source modules GIZA++3 for creating the translation models and SRILM4 for the language models. We considered a few phrase-based translation engines such as Phramer (Olteanu et al, 2006), Moses (Koehn et al., 2007), Pharaoh (Koehn, 2004), Ramses (Patry et al., 2006) and Portage5. Moses was selected because we found it to be a state-of-the-art package with a convenient open source license for our testing purposes. The last phase is devoted to the rendering of the translated decisions in HTML. Because appropriate bookkeeping information has been maintained, it is possible to merge the translation with the original XML file in order to yield a second XML file containing a bilingual version of each segment of text. This bilingual file can then be used to produce an HTML version o"
2008.amta-govandcom.11,W06-3116,1,0.550288,"cisionExpress™ fact sheets and summaries. We extract the source text from these structured XML files in which sentence boundaries have already been identified. This is essential, since the translation engine works sentence by sentence. The second phase translates the source sentences into the target language using SMT. The SMT module makes use of open source modules GIZA++3 for creating the translation models and SRILM4 for the language models. We considered a few phrase-based translation engines such as Phramer (Olteanu et al, 2006), Moses (Koehn et al., 2007), Pharaoh (Koehn, 2004), Ramses (Patry et al., 2006) and Portage5. Moses was selected because we found it to be a state-of-the-art package with a convenient open source license for our testing purposes. The last phase is devoted to the rendering of the translated decisions in HTML. Because appropriate bookkeeping information has been maintained, it is possible to merge the translation with the original XML file in order to yield a second XML file containing a bilingual version of each segment of text. This bilingual file can then be used to produce an HTML version of the translation, or for other types of processing, like summarization. Figure"
2008.amta-govandcom.11,2001.mtsummit-papers.68,0,0.0618641,"Missing"
2008.amta-govandcom.11,2006.jeptalnrecital-poster.23,0,0.0516086,"Missing"
2008.amta-govandcom.11,W07-0725,0,0.0264979,"Missing"
2008.amta-govandcom.17,macklovitch-etal-2000-transsearch,1,0.839151,"Missing"
2008.amta-govandcom.17,macklovitch-russell-2000-whats,1,0.732221,"es. Moreover, once this target sentence has been assembled, the translator also has to relate it, both logically and in terms of the larger discourse of the text, to the sentences that precede and follow it. In languages like English and French, the 7 Counterbalancing TS’ richness, on the other hand, is the fact that users have to sift through and evaluate all the examples it makes available; whereas a printed bilingual dictionary, which needs to be concise for reasons of publishing costs, attempts to condense and synthesize this information. 8 And one which we ourselves have worked on; c.f. (Macklovitch and Russell, 2000). 418 [8th AMTA conference, Hawaii, 21-25 October 2008] mortar with which the bricks of a translation are assembled into a final translation – or, if you prefer, the hinges9 linking the blocks together – are largely made up of function words, typically prepositional phrases and other types of adverbials. Now as we have seen, these are just the kinds of queries that users appear to submit most frequently to TS. In sharp contrast to technical terms, an important property of these prepositional and adverbial phrases is that they generally admit multiple, often numerous translations, with the most"
2009.mtsummit-posters.9,J93-2003,0,0.00920608,"n Figure 1(b), conforme ` a and respecte are 2 of the 103 transpots displayed to the user for the query in keeping with. 2.1 Word Alignment Word alignment is a key component of the transpotting task. Given a source sentence S = s1 ...sn and a target sentence T = t1 ...tm in translation relation, an IBM-style alignment a = a1 ...am connects each target token to a source one (aj ∈ {1, ..., n}) or to the so-called NULL token which accounts for untranslated target tokens, and which is arbitrarily set to the source position 0 (aj = 0). Several word-alignment models are introduced and discussed in (Brown et al., 1993). They differ by the expression of the joint probability of a target sentence and its alignment, given the source sentence. As we do not want to keep the precomputed alignments of each sentence pairs, we decided to use the IBM model 2 which allows our system to quickly manage on-line hundreds of pairs of sentences retrieved for a given query. This model is expressed by: m n p(tm 1 , a1 |s1 ) = m Y Figure 2: Example of word alignment generated by an IBM model 2 that leads to an erroneous transpot for the query in keeping with. 2.2 Transpotting Algorithm In this work, we implemented a variant o"
2009.mtsummit-posters.9,2009.eamt-1.4,1,0.789456,"the French sentence is much harder to identify. Professional translators are quick to locate the matches but they must often go through many sentences to find different translations. Currently, the system displays the sentences in reverse chronological order of dates of the documents. Identifying the matching substring in the other language enables a better display of the results by grouping them as shown in Figure 1(b). To do so, we collect all these substrings for a given query and merge close variants, such as the inflected forms of the same lemmas, according to the procedure described in (Huet et al., 2009). In the displayed example, the user can easily browse the 103 different French translations identified for in keeping with among 371 sentence pairs. The most frequent translations are conforme ` a, conform´ ement ` a, respecte, correspondant ` a, etc. Clicking on a translation shows the two most recent occurrences and clicking on the number below the second translation displays all of them. (a) Current system. (b) Development version. Figure 1: Results to the query in keeping with with the current version (a) and the future version (b) of T RANS S EARCH. This last version groups the translati"
2009.mtsummit-posters.9,2008.amta-govandcom.17,1,0.720278,"ory (TM) systems and bilingual concordancers. Both tools exploit a TM composed of a bitext: a set of pairs of units (typically sentences) that are in translation relation. Whereas a TM system is a translation device, a bilingual concordancer is conceptually simpler, since its main purpose is to retrieve from a bitext, the pairs of units that contain a query (typically a phrase) that a user manually submits. It is then left to the user to locate the relevant material in the retrieved target units. As simple as it may appear, a bilingual concordancer is nevertheless a very popular CAT tool. In (Macklovitch et al., 2008), the authors report that T RANS S EARCH,1 the commercial 1 www.tsrali.com web-based concordancer we focus on in this study, received an average of 177 000 queries a month over a one-year period (2006–2007). Figure 1(a) shows the first three search results found by the current version of T RANS S EARCH for the English phrase in keeping with in a bitext composed of sentences from the Canadian Hansards. Once the system has identified English sentences containing the query, it displays them with the corresponding French sentence. Although the substring of the English sentence can be highlighted e"
2009.mtsummit-posters.9,W03-0313,0,0.815193,"the number below the second translation displays all of them. (a) Current system. (b) Development version. Figure 1: Results to the query in keeping with with the current version (a) and the future version (b) of T RANS S EARCH. This last version groups the translations before the display; the user can thus know right away the whole gamut of translations that were found in the bitext. For the first suggested translation, the two substrings highlighted in the targer parts were considered as variants of conforme ` a, according to the merging process described in (Huet et al., 2009). Following (Simard, 2003), we call translation spotting or transpotting the process of identifying the different translations of a user query in a bitext. The first idea that comes to mind is using word alignment, a common task in Statistical Machine Translation (SMT). Unfortunately, merely relying on maximal word alignment scores does not give satisfactory results. While in SMT, word alignment is one component of a complete pipeline, in our application, its results are directly visible by the user. In many cases, they are a a bit off : the spotted translation may be incomplete, too long or completely miss the right t"
2009.mtsummit-posters.9,P03-1041,0,0.0181874,"eep the precomputed alignments of each sentence pairs, we decided to use the IBM model 2 which allows our system to quickly manage on-line hundreds of pairs of sentences retrieved for a given query. This model is expressed by: m n p(tm 1 , a1 |s1 ) = m Y Figure 2: Example of word alignment generated by an IBM model 2 that leads to an erroneous transpot for the query in keeping with. 2.2 Transpotting Algorithm In this work, we implemented a variant of the transpotting algorithm initially proposed by Simard (2003), which shares some similarity with the phrase extraction technique described in (Venugopal et al., 2003). For each pair hj1 , j2 i ∈ [1, m] × [1, m], two Viterbi alignments are computed: one between the phrase tjj21 and the query sii21 , and one between the remaining material in the sentences s¯ii21 ≡ si11 −1 sni2 +1 and t¯jj21 ≡ t1j1 −1 tm j2 +1 . This method finds the translation of the query according to:   maxaj2 p(ajj21 |sii21 , tjj21 )   j1 ˆ × tˆˆjj2 = argmax 1 (j1 ,j2 )    max j2 p(¯ ajj21 |¯ sii21 , t¯jj21 ) a ¯ j1 p(tj |saj ) × p(aj |j, m, n) j=1 where  is the length distribution, the first term inside the product is the transfer or lexical distribution and the second one is th"
2009.mtsummit-posters.9,C96-2141,0,0.121935,"rly improves precision scores for the transpotting and the translation tasks, two metrics we consider as important in our application. More specifically, the SRF method has a better ability to spot a translation in a given pair of sentences, while the PRF method tends to reduce the number of suggested translations to a query. Albeit these results are encouraging, we are facing an evaluation problem inherent to interactive applications. Ultimately, this will involve the development of test cases with real users of the application. We are currently experimenting the use of HMM alignment models (Vogel et al., 1996) in our transpotting algorithms as alternative to the IBM model 2. Finally, our approach might be applied to the more general task of acquiring a phrase table in SMT. As a matter of fact, a phrase in such a system plays a similar role to a query in our setting. Therefore, apλ 0 0.01 0.06 0.5 1 score rec prec rec prec rec prec rec prec rec prec transpotting 72.6 85.6 77.6 85.7 80.5 84.8 83.9 81.3 83.7 78.7 translation 61.9 18.0 74.9 18.5 79.9 18.2 82.6 16.2 82.6 14.7 Table 1: Scores of the SRF method for the transpotting and translation tasks according to the parameter λ on the TEST corpus. λ ="
2010.jeptalnrecital-demonstration.14,2008.amta-govandcom.17,1,0.800507,"Missing"
2010.jeptalnrecital-long.17,J02-3001,0,0.0876116,"Missing"
2010.jeptalnrecital-long.17,P03-1002,0,0.0859236,"Missing"
2010.jeptalnrecital-long.17,W09-1207,0,0.0648788,"Missing"
2010.jeptalnrecital-long.17,W09-1216,0,0.0378054,"Missing"
2010.jeptalnrecital-long.17,messiant-etal-2008-lexschem,0,0.0657235,"Missing"
2010.jeptalnrecital-long.26,J05-3002,0,0.079434,"Missing"
2010.jeptalnrecital-long.26,W04-1013,0,0.016149,"Missing"
2010.jeptalnrecital-long.31,1997.mtsummit-papers.6,0,0.0949857,"Missing"
2011.jeptalnrecital-court.25,D09-1002,0,0.0218432,"Missing"
2011.jeptalnrecital-court.25,J02-3001,0,0.084803,"Missing"
2011.jeptalnrecital-long.1,C96-2167,1,0.681086,"Missing"
2020.webnlg-1.16,2020.webnlg-1.7,0,0.264547,"Missing"
2020.webnlg-1.16,W03-1016,0,0.313814,"Missing"
2020.webnlg-1.16,W13-0108,0,0.0244033,"rse HTML pages and databases to find a large set of biographies. For W EB NLG C HALLENGE 2020, this essential but difficult step has already been done by the organizers of the competition (Gardent et al., 2017a). Sun and Mellish (2006) take advantage of the fact that RDF representations are not only logical representations, but that they also contain rich linguistic information useful for generating text. After studying many published ontologies, they found systematic patterns in class and relation names that can be exploited for lexicalization without developing special purpose dictionaries. Duma and Klein (2013) propose a system that can automatically learn sentence templates and document planning from parallel RDF data and text from the Simple English Wikipedia. They first match named entities in the sentence with a graph related to a specific entity in order to extract a template in which named entities are replaced by a variable. To prune entities and their dependents in the sentence not appearing in the graph, the sentences are first parsed and a few hand-written rules operating on the syntactic tree are applied as suggested by Gagnon and Da Sylva (2006) for summarization purposes. The content se"
2020.webnlg-1.16,W14-4405,0,0.0233737,"the sentences are first parsed and a few hand-written rules operating on the syntactic tree are applied as suggested by Gagnon and Da Sylva (2006) for summarization purposes. The content selection uses the method originally suggested by Duboue and McKeown. To determine relevant predicates, they determine a prototypical class by looking at the most frequent subwords in the class names which often use camelCase. Given the URI of an entity to be described, they determine the relevant class and its associated templates that are used for creating many sentences from which the best ones are chosen. Ell and Harth (2014) show how to extract verbalization templates for RDF graphs from DBPedia and the corresponding Wikipedia documents about specific types of entities. Sentences that mention the entities are aligned with a data graph using language-independent transformations. The connected entities in the graph are then iteratively explored to find commonalities that allow some abstraction of the entities using variables. They thus obtain a set of abstracted sentences from which templates are created. They applied their technique on English and German with promising results. Dong and Holder (2014) present Natur"
2020.webnlg-1.16,E09-2005,0,0.0395461,", 1995) approach with the KPML (Bateman, 1997) text realizer. Wilcock and Jokinen (2003) use the information in the ontology as background information for a dialogue system that provides information about a public transportation system. The ontology serves both as a source of information and for identifying misconceptions and suggesting alternative reasonable questions. Bontcheva and Wilks (2004) show how to generate reports from domain ontologies; they present a use case in the area of breast cancer in which the concepts of the ontology were manually mapped to words of a specialized lexicon. Galanis et al. (2009) describe NATURAL OWL2 , a plug-in for the P ROT E´ G E´ 3 ontology editor that produces template-based descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling information expressed in RDF. Given that it is opensource and embedded in a widely used ontology editor, it has been used as a baseline in many subsequent works. 2.2 Verbalizing RDF statements The first step in generating texts from RDF is finding an appropriate subset of RDF statements. 2 https://protegewiki.stanford.edu/ wiki/NaturalOWL 3 https://protege.stanford.edu 145 Dubo"
2020.webnlg-1.16,P17-1017,0,0.522206,"ng some representative natural language generation works dealing with Semantic Web information, we describe our approach and analyze the scores of the automatic evaluation on W EB NLG C HALLENGE 2020 test data. We then give a personal appraisal on the data for W EB NLG C HALLENGE 2020 and how it is representative of real Semantic Web data and conclude by giving ideas for future development. 2 This paper describes our system developed for participating to the RDF-to-text generation for English subtask of the W EB NLG C HALLENGE 2020 (Castro-Ferreira et al., 2020) as a followup to 2017 edition (Gardent et al., 2017b). The W EB NLG C HALLENGE 2020 data was developed for pushing the development of Resource Description Framework (RDF) verbalizers for realizing short texts while dealing with micro-planning problems such as sentence segmentation and ordering, referring expression generation and aggregation. The first edition of the data featuring 15 DBpedia categories was created in 2017 (Gardent et al., 2017a). The 2020 challenge covers more categories and an additional language, Russian and a new task: Text-to-RDF semantic parsing for converting a text into the corresponding set of RDF triples. Related wor"
2020.webnlg-1.16,W17-3518,0,0.500776,"ng some representative natural language generation works dealing with Semantic Web information, we describe our approach and analyze the scores of the automatic evaluation on W EB NLG C HALLENGE 2020 test data. We then give a personal appraisal on the data for W EB NLG C HALLENGE 2020 and how it is representative of real Semantic Web data and conclude by giving ideas for future development. 2 This paper describes our system developed for participating to the RDF-to-text generation for English subtask of the W EB NLG C HALLENGE 2020 (Castro-Ferreira et al., 2020) as a followup to 2017 edition (Gardent et al., 2017b). The W EB NLG C HALLENGE 2020 data was developed for pushing the development of Resource Description Framework (RDF) verbalizers for realizing short texts while dealing with micro-planning problems such as sentence segmentation and ordering, referring expression generation and aggregation. The first edition of the data featuring 15 DBpedia categories was created in 2017 (Gardent et al., 2017a). The 2020 challenge covers more categories and an additional language, Russian and a new task: Text-to-RDF semantic parsing for converting a text into the corresponding set of RDF triples. Related wor"
2020.webnlg-1.16,W09-0613,0,0.208448,"determination, document structuring, and lexicalization, aggregation and realization to create English text. It uses templates that code linguistic information about each class such as its English label both singular and plural; the relations are also coded with templates that indicate the type of its subject and object and priority to drive the text organization. Model preparation uses an RDF reasoner to infer new triples and remove redundant ones. Document structuring consists in deciding the order of output: first classes, then attributes and finally relationship information. S IMPLE NLG (Gatt and Reiter, 2009) is used for creating the English text. Our system follows a similar approach. Alan_Shepard |mission |Apollo_14 Alan_Shepard |deathPlace |California Alan_Shepard |birthPlace |New_Hampshire Alan_Shepard |dateOfRetirement |""1974-08-01"" Apollo_14 |operator |NASA Alan_Shepard |birthDate |""1923-11-18"" Alan Shepard was born on November 18, 1923 in New Hampshire and he was a crew member of Apollo 14 that is operated by NASA. He went into retirement on August 1, 1974 and passed away in California. Table 1: The top part shows a triple set from /dev/en/6triples/Astronaut.xml. The bottom part shows the r"
2020.webnlg-1.16,W15-4719,1,0.843301,"ups of more than 3 triples are split into two sentences. In order to avoid very short sentences, groups with only one triple are combined using a subordinate when its subject is the object of another triple in a bigger group. Table 2 shows the result of the sorting and grouping process on the example of Table 1. The five triples having Alan_Shepard as subject are grouped and sorted to form a coherent biography. This input will be used for realizing the two sentences shown in the bottom part of Table 1 using JS R EAL B. 3.2 Surface realization For the final realization step, we use JS R EAL B (Molins and Lapalme, 2015), a surface realizer written in Javascript similar in principle to S IMPLE NLG (Gatt and Reiter, 2009) in which programming language instructions create data structures corresponding to the constituents of the sentence to be produced. Once the data structure is built, it is traversed to produce the list of words in the sentence, dealing with conjugation, agreement, capitalization, all the small details that are important for easing the reading by the users and evaluators. Unfortunately, a large part of this hard work is not taken into account by the automatic evaluation process which often wor"
A00-1019,J96-1002,0,0.00664237,"ere a(t', s) E [0, 1] are context-dependent interpolation coefficients. For example, the translation model could have a higher weight at the start of a sentence but the contribution of the language model might become more important in the middle or the end of the sentence• A study of the weightings for these two models is described elsewhere• In the work described here we did not use the contribution of the language model (that is, a(t', s) = O, V t', s). Techniques for weakening the independence assumptions made by the IBM models 1 and 2 have been proposed in recent work (Brown et al., 1993; Berger et al., 1996; Och and Weber, 98; Wang and Waibel, 98; Wu and Wong, 98). These studies report improvements on some specific tasks (task-oriented limited vocabulary) which by nature are very different from the task TRANSTYPE is devoted to. Furthermore, the underlying decoding strategies are too time consuming for our application• We therefore use a translation model based on the simple linear interpolation given in equation 2 which combines predictions of two translation models - - Ms and M~ - both based on IBM-like model 2(Brown et al., 1993). Ms was trained on single words and Mu, described 136 in section"
A00-1019,1997.mtsummit-papers.1,0,0.096049,"Missing"
A00-1019,P95-1032,0,0.0543477,"Missing"
A00-1019,P93-1003,0,0.027342,"Missing"
A00-1019,W97-0311,0,0.0428982,"Missing"
A00-1019,P97-1061,0,0.0366885,"ord model, A u the 10 best units according to the unit model. Modeling = et • a • premier disait 3 p(w~) Finding Monolingual Units Finding relevant units in a text has been explored in many areas of natural language processing. Our approach relies on distributional and frequency statistics computed on each sequence of words found in a training corpus. For sake of efficiency, we used the suffix array technique to get a compact representation of our training corpus. This method allows the efficient retrieval of arbitrary length n-grams (Nagao and Mori, 94; Haruno et al., 96; Ikehara et al., 96; Shimohata et al., 1997; Russell, 1998). The literature abounds in measures that can help to decide whether words that co-occur are linguistically significant or not. In this work, the strength of association of a sequence of words w [ = w l , . . . , w n is computed by two measures: a likelihood-based one p(w'~) (where g is the likelihood ratio given in (Dunning, 93)) and an entropy-based one e(w'~) (Shimohata et al., 1997). Letting T stand for the training text and m a token: 137 Intuitively, the first measurement accounts for the fact that parts of a sequence of words that should be considered as a whole should n"
A00-1019,P94-1033,0,0.046262,"Missing"
A00-1019,P98-2221,0,0.048473,"Missing"
A00-1019,P98-2230,0,0.027694,"Missing"
A00-1019,W99-0604,0,\N,Missing
A00-1019,C90-2045,0,\N,Missing
A00-1019,C96-1006,0,\N,Missing
A00-1019,J93-2003,0,\N,Missing
A00-1019,C94-1101,0,\N,Missing
A00-1019,C96-1070,0,\N,Missing
A00-1019,C90-3008,0,\N,Missing
A00-1019,C96-2098,0,\N,Missing
A00-1019,P99-1067,0,\N,Missing
A00-1019,P98-2158,0,\N,Missing
A00-1019,C98-2153,0,\N,Missing
A00-1019,P97-1037,0,\N,Missing
A00-1019,P96-1003,0,\N,Missing
A00-1019,P94-1032,0,\N,Missing
A00-1019,C86-1077,0,\N,Missing
A00-1019,C96-1089,0,\N,Missing
A00-1019,C98-2225,0,\N,Missing
A00-1019,P98-2162,0,\N,Missing
A00-1019,C98-2157,0,\N,Missing
A00-1019,C98-2216,0,\N,Missing
A00-1019,langlais-etal-2000-evaluation,1,\N,Missing
A00-1019,P99-1041,0,\N,Missing
A00-1019,C96-1097,0,\N,Missing
A00-1019,P97-1047,0,\N,Missing
D19-6305,W09-0613,0,0.0402865,"n., a negative passive sentence with a modal verb for possibility. Row 5 of Table 1 is the JS R EAL B structure that is realized as the bottom part of the table. The structure of constituents written as an active sentence has been realized as a passive one, the original complement becoming the subject. The verb was also conjugated to the past tense. This was made possible by the options given to JS R EAL B. 2.3 Surface Syntactic Representation (SSR) The SSR is the input form for JS R EAL B(Molins and Lapalme, 2015), a surface realizer written in JavaScript similar in principle to S IMPLE NLG (Gatt and Reiter, 2009) in which programming language instructions create data structures corresponding to the constituents of the sentence to be produced. Once the data structure (a tree) is built in memory, it is traversed to produce the list of tokens of the sentence. This data structure is built by function calls whose names are the same as the symbols usually used for classical syntax trees: for example, N to create a noun structure, NP for a noun phrase, V for a verb, D for a determiner, S for a sentence and so on. Options added to the structures using the dot notation can modify the values according to what i"
D19-6305,D19-6301,0,0.0212893,"alizer for Universal Dependencies (UD) structures. The system uses a symbolic approach to transform the dependency tree into a tree of constituents that is transformed into an English sentence by an existing realizer. This approach was then adapted for the two shared tasks of SR’19. The system is quite fast and showed competitive results for English sentences using automatic and manual evaluation measures. 1 Introduction This paper describe the system that we submitted to the Surface Realization Shared Task 2019 (SR’19)1 in conjunction with Second Workshop on Multilingual Surface Realization (Mille et al., 2019). The data used by this shared task was created by modifying original Universal Dependencies structures (Nivre et al., 2016) (UD) to create two tracks: Shallow Track (T1) in which word order is permuted and tokens have been lemmatized and some information about linear order about the governor has been added. The task consists in determining the word order and inflecting the words. Deep Track (T2) in which functional and surface-oriented morphological information has been removed from the T1 structures. The goal is to reintroduce the missing functional words and morphological features. 41 Proce"
D19-6305,W18-6527,0,0.0193906,"ation about linear order about the governor has been added. The task consists in determining the word order and inflecting the words. Deep Track (T2) in which functional and surface-oriented morphological information has been removed from the T1 structures. The goal is to reintroduce the missing functional words and morphological features. 41 Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019), pages 41–49 c Hong Kong, China, November 3rd, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 reversing the transformations described in (Mille et al., 2018). Section 4 gives the results of the evaluation obtained using the evaluation scripts provided with the task. We also compare our results with the automatic and manual scores obtained by other systems that participated in the task. We conclude with some lessons learned from this development. the output of UD-S URF R just to determine how far a symbolic approach can go. In a production setting, it would surely be better to combine statistical and symbolic systems. We did not find any text realizer that takes UD annotations as input except for Ranta and Kolachina (2017) who present an algorithm"
D19-6305,W15-4719,1,0.852871,"d:""poss""}) to the previous JS R EAL B structure will be realized as The red apple cannot be eaten by women., a negative passive sentence with a modal verb for possibility. Row 5 of Table 1 is the JS R EAL B structure that is realized as the bottom part of the table. The structure of constituents written as an active sentence has been realized as a passive one, the original complement becoming the subject. The verb was also conjugated to the past tense. This was made possible by the options given to JS R EAL B. 2.3 Surface Syntactic Representation (SSR) The SSR is the input form for JS R EAL B(Molins and Lapalme, 2015), a surface realizer written in JavaScript similar in principle to S IMPLE NLG (Gatt and Reiter, 2009) in which programming language instructions create data structures corresponding to the constituents of the sentence to be produced. Once the data structure (a tree) is built in memory, it is traversed to produce the list of tokens of the sentence. This data structure is built by function calls whose names are the same as the symbols usually used for classical syntax trees: for example, N to create a noun structure, NP for a noun phrase, V for a verb, D for a determiner, S for a sentence and s"
D19-6305,L16-1262,0,0.0470813,"Missing"
D19-6305,W17-0414,0,0.0165955,"he transformations described in (Mille et al., 2018). Section 4 gives the results of the evaluation obtained using the evaluation scripts provided with the task. We also compare our results with the automatic and manual scores obtained by other systems that participated in the task. We conclude with some lessons learned from this development. the output of UD-S URF R just to determine how far a symbolic approach can go. In a production setting, it would surely be better to combine statistical and symbolic systems. We did not find any text realizer that takes UD annotations as input except for Ranta and Kolachina (2017) who present an algorithm to transform many UDs into Grammatical Framework structures from with English sentences can be generated. A UD realizer might seem pointless, because UD annotations are created from realized sentences. As UDs contains all the tokens in their original form (except for elision in some cases), the realization can be obtained trivially by listing the FORM in the second column of each line. What we propose in this paper is a full realizer that uses only the lemmas and the syntactic information contained in the UD to create the final sentence from scratch which can be compa"
foster-etal-2002-text,J99-4005,0,\N,Missing
foster-etal-2002-text,J93-2003,0,\N,Missing
foster-etal-2002-text,C00-2123,0,\N,Missing
foster-etal-2002-text,P98-2158,0,\N,Missing
foster-etal-2002-text,C98-2153,0,\N,Missing
foster-etal-2002-text,W00-0707,1,\N,Missing
foster-etal-2002-text,W02-1020,1,\N,Missing
foster-etal-2002-text,P00-1006,1,\N,Missing
J02-4005,W97-0703,0,0.308081,"l work of Luhn (1958). Since then several methods and theories have been applied, including the use of term frequency ∗ inverse document frequency (TF ∗ IDF) measures, sentence position, and cue and title words (Luhn 1958; Edmundson 1969; Kupiec, Pedersen, and Chen 1995; Brandow, Mitze, and Rau 1995); partial understanding using conceptual structures (DeJong 1982; Tait 1982); bottom-up understanding, top-down parsing, and automatic linguistic acquisition (Rau, Jacobs, and Zernik 1989); recognition of thematic text structures (Hahn 1990); cohesive properties of texts (Benbrahim and Ahmad 1995; Barzilay and Elhadad 1997); and rhetorical structure theory (Ono, Sumita, and Miike 1994; Marcu 1997). In the context of the scientific article, Rino and Scott (1996) have addressed the problem of coherent selection for text summarization, but they depend on the availability of a complex meaning representation, which in practice is difficult to obtain from the raw text. Instead, superficial analysis in scientific text summarization using lexical information was applied by Lehmam (1997) for the French language. Liddy (1991) produced one of the most complete descriptions of conceptual information for abstracts of empiric"
J02-4005,A00-2024,0,0.104599,"Missing"
J02-4005,P99-1072,0,0.037478,"Missing"
J02-4005,W97-0713,0,0.620733,"een the two automatic systems (SumUM and Autosummarize) and differences with the author abstract at 0.05. In the third experiment, the ANOVA for text quality did not allow us to draw any conclusions about differences in text quality (F(2, 42) = 0.83). 5.2 Evaluation of Content in a Coselection Experiment Our objective in the evaluation of content in a coselection experiment is to measure coselection between sentences selected by our system and a set of “correct” extracted sentences. This method of evaluation has already been used in other summarization evaluations such as Edmundson (1969) and Marcu (1997). The idea is that if we find a high degree of overlap between the sentences selected by an automatic method and the sentences selected by a human, the method can be regarded as effective. Nevertheless, this method of evaluation has been criticized not only because of the low rate of agreement between human subjects in this task (Jing et al. 1998), but also because there is no unique ideal or target abstract for a given document. Instead, there is a set of main ideas that a good abstract should contain (Johnson 1995). In our coselection experiment, we were also interested in comparing our syst"
J02-4005,C94-1056,0,0.0240794,"Missing"
J02-4005,J98-3005,0,0.0727489,"nd generates coordinate structures, avoiding verb repetition. Whereas our algorithm is genre dependent, requiring only shallow parsing, Jing’s algorithm is genre and domain independent and requires full syntactic parsing and disambiguation and extensive linguistic resources. Regarding the fusion of information, we have concentrated only on the fusion of explicit topical information (document topic, section topic, and signaling structural and conceptual elements). Jing and McKeown (2000) have proposed a rule-based algorithm for sentence combination, but no results have been reported. Radev and McKeown (1998) have already addressed the issue of information fusion in the context of multidocument summarization in one specific domain (i.e., terrorism): The fusion of information is achieved through the implementation of summary operators that integrate the information of different templates from different documents referring to the same event. Although those operators are dependent on the specific task of multidocument summarization, and to some extent on the particular domain they deal with, it is interesting to observe that some of Radev and McKeown’s ideas could be applied in order to improve our t"
J02-4005,W00-0401,1,0.709135,"the reader to determine the topics to expand. 3.1 Implementing SumUM The architecture of SumUM is depicted in Figure 3. Our approach to text summarization is based on a superficial analysis of the source document to extract appropriate types of information and on the implementation of some text regeneration techniques. SumUM has been implemented in SICStus Prolog (release 3.7.1) (SICStus 1998) and Perl (Wall, Christiansen, and Schwartz 1996) running on Sun workstations (5.6) and Linux machines (RH 6.0). For a complete description of the system and its implementation, the reader is referred to Saggion (2000). The sources of information we use for implementing our system are a POS tagger (Foster 1991); linguistic and conceptual patterns specified by regular expressions combining POS tags, our syntactic categories, domain concepts, and words; and a conceptual dictionary that implements our conceptual model (241 domain verbs, 163 domain nouns, and 129 adjectives); see Table 5. 3.1.1 Preprocessing and Interpretation. The input article (plain ASCII text in English without markup) is segmented in main units (title, author information, main sections and references) using typographic information (i.e., n"
J02-4005,W98-0307,0,0.0596896,"Missing"
J02-4005,A00-1043,0,\N,Missing
J02-4005,J02-4001,0,\N,Missing
J02-4005,E99-1011,0,\N,Missing
J90-3002,J87-3006,0,0.231744,"Missing"
J96-1004,P83-1012,0,0.0338127,"ust be fulfilled. The term ""function,"" in this context, refers to the role played by a constituent of a phrase in achieving a communicative goal (Halliday 1985). For example, a sentence can often be decomposed into three constituents fulfilling the following functions: Subject, Predicate, and Object. 4 Once the functional structure of the sentence is established, its network is traversed again to determine the syntactic structure, which is then further refined until each function is realized by a single word. Figure 8 illustrates the organization of the modules in Pr6texte, inspired by Nigel (Mann 1983; Mann 1985; Matthiessen 1985; Matthiessen and Bateman 1991). To produce a sentence, Pr6texte uses three information components: the environment, containing the information about the message and a knowledge base describing how to achieve lexicalization; the grammar, represented as a systemic network; and the blackboard, used to determine the syntactic structure. The engine controls the surface generation process and accesses the three information components through three interface modules: semantic interface, interpreter and realizer. The solver determines the final structure of the constituen"
J96-1004,J83-1005,0,0.240855,"Missing"
J96-1004,P84-1076,0,\N,Missing
langlais-etal-2000-evaluation,C90-2045,0,\N,Missing
langlais-etal-2000-evaluation,J93-2003,0,\N,Missing
langlais-etal-2000-evaluation,C90-3008,0,\N,Missing
langlais-etal-2000-evaluation,P98-2158,0,\N,Missing
langlais-etal-2000-evaluation,C98-2153,0,\N,Missing
langlais-etal-2000-evaluation,A00-1019,1,\N,Missing
langlais-etal-2000-evaluation,P97-1037,0,\N,Missing
langlais-etal-2000-evaluation,C86-1077,0,\N,Missing
langlais-etal-2000-evaluation,P97-1047,0,\N,Missing
langlais-etal-2002-translators,J93-2003,0,\N,Missing
langlais-etal-2002-translators,P01-1067,0,\N,Missing
langlais-etal-2002-translators,langlais-etal-2000-evaluation,1,\N,Missing
langlais-etal-2002-translators,2001.mtsummit-papers.36,1,\N,Missing
langlais-etal-2002-translators,P00-1006,0,\N,Missing
leplus-etal-2004-weather,J93-2003,0,\N,Missing
leplus-etal-2004-weather,C86-1132,0,\N,Missing
leplus-etal-2004-weather,P98-2158,0,\N,Missing
leplus-etal-2004-weather,C98-2153,0,\N,Missing
leplus-etal-2004-weather,N03-1017,0,\N,Missing
leplus-etal-2004-weather,P98-1117,1,\N,Missing
leplus-etal-2004-weather,C98-1113,1,\N,Missing
P04-3001,1997.mtsummit-papers.1,0,0.696374,"Missing"
P04-3001,2003.mtsummit-systems.16,1,0.830486,"Missing"
P04-3001,2003.eamt-1.6,0,\N,Missing
P04-3001,E03-1032,0,\N,Missing
P04-3001,P00-1006,0,\N,Missing
P12-2069,N04-1015,0,0.00940846,"ies and aspects define an information need, and using Information Extraction (IE) seems appropriate to address it. The idea to use an IE system for summarization can be traced back to the FRUMP system (DeJong, 1982), which generates brief summaries about various kinds of stories; (White et al., 2001) also wrote abstractive summaries using the output of an IE system applied to events such as natural disasters. In both cases, the end result is a generated summary from the information available. A lot of other work has instead used IE to improve the performance of extraction-based systems, like (Barzilay and Lee, 2004) and (Ji et al., 2010). What is common to all these approaches is that the IE system is designed for a specific purpose, separate from summarization. However, to properly address each aspect requires a system designed specifically for that task. To our knowledge, tailoring IE to the needs of abstractive summarization has not been done before. Our methodology uses a rule-based, custom-designed IE module, integrated with Content Selection and Generation in order to write short, well-written abstractive summaries. Before tackling these, we perform some preprocessing on the cluster of documents. I"
P12-2069,J05-3002,0,0.0859346,"field is also getting saturated near what appears to be a ceiling in performance. Systems that claim to be very different from one another have all become statistically indistinguishable in evaluation results. An experiment (Genest et al., 2009) found a performance ceiling to pure sentence extraction that is very low compared to regular (abstractive) human summaries, but not that much better than the current best automatic systems. Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al., 2009), and a generationbased approach that could be called sentence splitting (Genest and Lapalme, 2011). They are all 1 www.nist.gov/tac rewriting techniques based on syntactical analysis, offering little improvement over extractive methods in the content selection process. We believe that a fully abstractive approach with a separate process for the analysis of the text, the content selection, and the generation of the summary has the most potential for generating summaries at a level comparable to human. For the foreseeable future, we think that such a process fo"
P12-2069,de-marneffe-etal-2006-generating,0,0.0356065,"Missing"
P12-2069,P05-1045,0,0.0185237,"done before. Our methodology uses a rule-based, custom-designed IE module, integrated with Content Selection and Generation in order to write short, well-written abstractive summaries. Before tackling these, we perform some preprocessing on the cluster of documents. It includes: cleaning up and normalization of the input using regular expressions, sentence segmentation, tokenization and lemmatization using GATE (Cunningham et al., 2002), syntactical parsing and dependency parsing (collapsed) using the Stanford Parser (de Marneffe et al., 2006), and Named Entity Recognition using Stanford NER (Finkel et al., 2005). We have also developed a date resolution engine that focuses on days of the week and relative terms. 355 Information Extraction Our architecture is based on Abstraction Schemes. An abstraction scheme consists of IE rules, content selection heuristics and one or more generation patterns, all created by hand. Each abstraction scheme is designed to address a theme or subcategory. Thus, rules that extract information for the same aspect within the same scheme will share a similar meaning. An abstraction scheme aims to answer one or more aspects of its category, and more than one scheme can be li"
P12-2069,W09-0613,0,0.0398805,"nces that might appear in the same cluster of documents, we rely on dates. The ancestors of a date in the dependency tree are associated with that date, and excluded from the summary if the main event occurs on a different date. The text of a summary must be fluid and feel natural, while being straightforward and concise. From our observation of human-written summaries, it also does not require a great deal of originality to be considered excellent by human standards. Thus, we have designed straightforward generation patterns for each scheme. They are implemented using the SimpleNLG realizer (Gatt and Reiter, 2009), which takes a sentence structure and words in their root form as input and gives a sentence with resolved agreements and sentence markers as output. The greatest difficulty in the structure is in realizing noun phrases. The content selection module selects a lemma that should serve as noun phrase head, and its number, modifiers and specifier must be determined during generation. Frequencies and heuristics are again used to identify appropriate modifiers, this time from all those used with that head within the source documents. We apply the constraint that the 356 On April 20, 1999, a massacr"
P12-2069,W11-1608,1,0.573184,"her have all become statistically indistinguishable in evaluation results. An experiment (Genest et al., 2009) found a performance ceiling to pure sentence extraction that is very low compared to regular (abstractive) human summaries, but not that much better than the current best automatic systems. Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al., 2009), and a generationbased approach that could be called sentence splitting (Genest and Lapalme, 2011). They are all 1 www.nist.gov/tac rewriting techniques based on syntactical analysis, offering little improvement over extractive methods in the content selection process. We believe that a fully abstractive approach with a separate process for the analysis of the text, the content selection, and the generation of the summary has the most potential for generating summaries at a level comparable to human. For the foreseeable future, we think that such a process for full abstraction is impossible in the general case, since it is almost equivalent to perfect text understanding. In specific domain"
P12-2069,P88-1020,0,0.591148,"Amsterdam. A gunman stabbed and shot Dutch filmmaker Theo van Gogh. A policeman and the suspect were wounded. On February 14, 2005, a suicide car bombing occurred in Beirut. Former Lebanese Prime Minister Rafik Hariri and 14 others were killed. Figure 3: Brief fully abstractive summaries on clusters D1001A-A, D1039G-A and D1043H-A, respectively on the Columbine massacre, the murder of Theo van Gogh and the assassination of Rafik Hariri. combination of number and modifiers chosen must appear at least once as an IE rule match. As for any generated text, a good summary also requires a text plan (Hovy, 1988) (McKeown, 1985). Ours consists of an ordering of the schemes. For example, an Attack summary begins with the scheme event. This ordering also determines which scheme to favor in the case of redundancy, e.g. given that a building was both damaged and destroyed, only the fact that is was destroyed will be mentioned. 4 Results and Discussion We have implemented this fully abstractive summarization methodology. The abstraction schemes and text plan for the Attack category are written in an XML document, designed to easily allow the addition of more schemes and the design of new categories. The la"
P12-2069,kipper-etal-2006-extending,0,0.00821677,"ted. For the scheme killing, the IE rules would match X as the perpetrator and Y as a victim for all of the following phrases: X killed Y, Y was assassinated by X, and the murder of X by Y. Other schemes have similar structure and purpose, such as wounding, abducting, damaging and destroying. To create extraction rules for a scheme, we must find several verbs and nouns sharing a similar meaning and identify the syntactical position of the roles we are interested in. Three resources have helped us in designing extraction rules: a thesaurus to find semantically related nouns and verbs; VerbNet (Kipper et al., 2006), which provides amongst other things the semantic roles of the syntactical dependents of verbs; and a hand-crafted list of aspect-relevant word stems provided by the team that made CLASSY (Conroy et al., 2010). Schemes and their extraction rules can also be quite different from this first example, as shown with the scheme event. This scheme gathers the basic information about the attack event: WHAT category of attack, WHEN and WHERE it occurred. A list of key words is used to identify words that imply an attack event, while a list of EVENT NOUNs is used to identify specifically words that ref"
P12-2069,W09-2808,0,0.0187437,"appears to be a ceiling in performance. Systems that claim to be very different from one another have all become statistically indistinguishable in evaluation results. An experiment (Genest et al., 2009) found a performance ceiling to pure sentence extraction that is very low compared to regular (abstractive) human summaries, but not that much better than the current best automatic systems. Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al., 2009), and a generationbased approach that could be called sentence splitting (Genest and Lapalme, 2011). They are all 1 www.nist.gov/tac rewriting techniques based on syntactical analysis, offering little improvement over extractive methods in the content selection process. We believe that a fully abstractive approach with a separate process for the analysis of the text, the content selection, and the generation of the summary has the most potential for generating summaries at a level comparable to human. For the foreseeable future, we think that such a process for full abstraction is impossible i"
P12-2069,H01-1054,0,0.0161927,"th, injury), or individuals otherwise negatively affected DAMAGES: damages caused by the attack COUNTERMEASURES: countermeasures, rescue efforts, prevention efforts, other reactions Figure 1: Aspects for TAC’s guided summarization task, category 2: Attacks 3 Fully Abstractive Approach 3.1 Guided summarization categories and aspects define an information need, and using Information Extraction (IE) seems appropriate to address it. The idea to use an IE system for summarization can be traced back to the FRUMP system (DeJong, 1982), which generates brief summaries about various kinds of stories; (White et al., 2001) also wrote abstractive summaries using the output of an IE system applied to events such as natural disasters. In both cases, the end result is a generated summary from the information available. A lot of other work has instead used IE to improve the performance of extraction-based systems, like (Barzilay and Lee, 2004) and (Ji et al., 2010). What is common to all these approaches is that the IE system is designed for a specific purpose, separate from summarization. However, to properly address each aspect requires a system designed specifically for that task. To our knowledge, tailoring IE t"
R09-1076,P07-1056,0,0.571688,"ted words, we construct three feature sets for text representation: I terminals of direct Details rules enhanced by personal pronouns; h was determined by frequencies of personal pronouns; II terminals of all the hierarchy rules enhanced by the most frequent extracted extracted words; h was determined by frequencies of personal pronouns; III the terminals and all the words extracted by the procedure presented in Figure 2; the cut-off threshold h = 5 was determined by using Katz smoothing to ensure reliability of data representation. 5 Empirical results We ran experiments on data introduced in [5]. There are four sets of reviews of different consumer goods: books, DVD, electronics, kitchen and houseware. Each data set has 2000 labelled examples, all evenly split on 1000 positive and 1000 negative examples. Blitzer et al. deleted reviews they considered as having ambiguous opinions. A typical review contained abundance of information assigned to several fields: (i) product name, (ii) product type, (iii) unique id which often summarized the review contents, (iv) product rating, 424 (v) review helpfulness rating, (vi) the review title, (vii) the date, (viii) the review text, etc. For this"
R09-1076,D07-1113,0,0.0191836,"does not allow us to directly compare the obtained results. Syntactic and semantic features that express the intensity of terms are used to classify the text opinion intensity [23]. Benamara et al. studies the impact of combining adverbs of degree with adjectives for the purpose of opinion evaluation [3]. Our approach deals instead with opinion analysis which is broader than the analysis of sentiments. We focus on the formalization and utilization of non-emotional lexical features. Except sentiment analysis, machine learning is used to study opinions from the point of view of predictive power [12], strength [23], and also in summarization and feature extraction studies [8]. Although Kim and Hovy (2007) generalized bi- and trigrams found 426 Acc 80.20 80.50 82.40 85.20 III tp 81.05 84.10 76.85 88.20 tn 79.35 76.80 87.85 82.20 in texts (e.g. NDP will win and Liberals will win became Party will win), they did it bottom-up, without providing theoretical background. We, instead, used a top-down hierarchical approach based on pragmatic and lexical rules. Wilson et al (2006) concentrated on learning subjective vs objective sentences and sentence clauses. Their initial manual clues included ve"
R09-1076,P06-2079,0,0.189038,"ective. We present a method which uses non-affective adjectives and adverbs (future, full, perhaps), supplemented by degree pronouns and mental and modal verbs, to determine whether a text bears a positive or a negative opinion label. The method engineers features by using the intrinsic characteristics of a language and avoids extensive and elaborate computational mechanism. Methods used to Guy Lapalme RALI, Universit´e de Montr´eal Montr´eal, Qu´ebec, Canada lapalme@iro.umontreal.ca classify complete texts according to opinions and sentiments usually employ automated feature selection, e.g., [17, 15]. Although such methods can be applied to different domains, they sometimes involve complex optimization problems, e.g., N P -hard approximation problems [2]. We concentrate on expressions of stance (maybe, necessary), degree (extremely, any), time (ago, now), frequency (rare, again), size (short, high), quantity (many, few), and extent (big). We show that these indicators reliably represent texts in opinion learning. We organize the corresponding word categories – stance/degree/time/frequency adverbs, frequency/size/quantity adjectives, degree pronouns – into a semantic hierarchy. Its lowest"
R09-1076,P05-1015,0,0.0682316,"ective. We present a method which uses non-affective adjectives and adverbs (future, full, perhaps), supplemented by degree pronouns and mental and modal verbs, to determine whether a text bears a positive or a negative opinion label. The method engineers features by using the intrinsic characteristics of a language and avoids extensive and elaborate computational mechanism. Methods used to Guy Lapalme RALI, Universit´e de Montr´eal Montr´eal, Qu´ebec, Canada lapalme@iro.umontreal.ca classify complete texts according to opinions and sentiments usually employ automated feature selection, e.g., [17, 15]. Although such methods can be applied to different domains, they sometimes involve complex optimization problems, e.g., N P -hard approximation problems [2]. We concentrate on expressions of stance (maybe, necessary), degree (extremely, any), time (ago, now), frequency (rare, again), size (short, high), quantity (many, few), and extent (big). We show that these indicators reliably represent texts in opinion learning. We organize the corresponding word categories – stance/degree/time/frequency adverbs, frequency/size/quantity adjectives, degree pronouns – into a semantic hierarchy. Its lowest"
R09-1076,H05-1043,0,0.0289518,"is work extends preliminary studies presented in [22]. The rest of the presentation is organized as follows: we introduce word categories used in the test representation, then the hierarchy is presented, followed by description of the information extraction procedure and empirical results; discussion of related work, results and future work conclude the paper. 2 Text representation Studies of sentiment and subjectivity analysis mostly concentrate on the use of the affective words in expression of sentiments and opinions. Some opinion studies use topic and domain words and affect-neutral verbs [18, 21]. We propose that words which emphasize quantitative properties (high, some), time (old, yesterday) and confidence in happening (can, necessary, probably) can be used in learning opinions. Such words constitute detailed, specific, description of an object or action [4, 9]. We organize them in the 421 International Conference RANLP 2009 - Borovets, Bulgaria, pages 421–427 semantic groups. The highest, the most general, level is concerned with text pragmatics. We determined the list of terminals by finding seed words for these word categories in [4, 6] and added their synonyms from an electronic"
R09-1076,W06-1652,0,0.0213642,"mentioned only once or few times. In contrast, we opted for a domain-independent method that does not involve the use of the domain’s content words. Popescu and Etzioni (2005) extracted product characteristics from noun phases in the data and matched them with known product features. In contrast, we opted for a domain-independent method that does not involve the use of the domain’s content words. For automating recognition and the evaluation of the expressed opinion, complete texts are represented through N -grams or patterns and then classified as opinion/non-opinion, positive/negative, etc. [19]. In [5], the authors combine supervised and semisupervised structural correspondence learning to classify the four data sets. They use fully automated feature selection based on frequency and the mutual information of words. However, the difference in evaluation technique does not allow us to directly compare the obtained results. Syntactic and semantic features that express the intensity of terms are used to classify the text opinion intensity [23]. Benamara et al. studies the impact of combining adverbs of degree with adjectives for the purpose of opinion evaluation [3]. Our approach deals"
R09-1076,H05-2017,0,\N,Missing
vasilescu-etal-2004-evaluating,W02-0807,0,\N,Missing
W00-0401,W97-0713,0,0.439339,"to de ComputaciSn, Facultad de CienciasExactas y Naturales, UBA, Argentina. Text Summarization The process of producing a summary from a source text consists of the following steps: (i) the interpretation of the text; (ii) the extraction of the relevant information which ideally includes the ""topics"" of the source; (iii) the condensation of the extracted information and construction of a summary representation; and (iv) the presentation of the summary representation to the reader in natural language. While some techniques exist for producing summaries for domain independent texts (Luhn, 1958; Marcu, 1997) it seems that domain specific texts require domain specific techniques (DeJong, 1982; Paice and Jones, 1993). In our case, we are dealing with technical articles which are the result of the complex process of scientific inquiry that starts with the. identification of a knowledge problem and eventually culminates with the discovery of an answer to it. Even if authors of technical articles write about several concepts in their articles, not all of them are topics. In order to address the issue of topic identification, content selection and presentation, we have studied alignments (manually prod"
W00-0401,W97-0703,0,0.133721,"the following criteria taken from (Rowley, 1982) (they were only suggestions to the evaluators and were not enforced): good spelling and grammar; clear indication of the topic of Experiment We compared abstrac£s produced by o u r m e t h o d with abstracts produced by Microsoft&apos;97 Summarizer and with others published with source documents (usually author abstracts). We have chosen Microsoft&apos;97 Summarizer because, even if it only produces extracts, it was the only summarizer available in order to carry out this evaluation and because it has already been used in other evaluations (Marcu, 1997; Barzilay and Elhadad, 1997). 7 I different page. It included 5 lists of keywords, a field to be completed with the quality score associated to the abstract and a field to be f i l l e d with comments about the abstract. One of the lists of keywords was the one published with the source document, the other four were randomly selected from the set of 11 remaining keyword lists, they were printed in the form in random order. One page was also available to be completed with comments about the task, in particular with the time it took to the judges to complete the evaluation. We produced three copies of each form for a total"
W00-0401,J98-3005,0,\N,Missing
W00-0401,E99-1011,0,\N,Missing
W00-0507,C90-3008,0,0.247146,"Missing"
W00-0507,J93-2003,0,0.00567536,"xpensive to compute than p(t[s) when using IBM-style translation models. Since speed is crucial for our application, we chose to forego it in the work described here. Our linear combination model is fully described in (Langlais and Foster, 2000) but can be seen as follows: 2.2.1 T h e e v a l u a t o r The evaluator is a function p(t[t&apos;, s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t&apos; which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al., 1993), but it diflhrs in one significant aspect: whereas the IBM model involves a &quot;noisy channel&quot; decomposition, we 48 p(tlt&apos;,s ) = p(tlt&apos; ) A(O(t&apos;,s)), (1) language + p(tls)[1-~(O(t&apos;,s))! translation where .~(O(t&apos;,s)) e [0,1] are contextdependent interpolation coefficients. O(t~,s) stands for any function which maps t~,s into a set of equivalence classes. Intuitively, ),(O(t r, s)) should be high when s is more informative than t r and low otherwise. For example, the translation model could have a higher weight at the start of sentence but the contribution of the language model can become more imp"
W00-0507,langlais-etal-2000-evaluation,1,0.713413,"Missing"
W00-0507,A00-1018,0,0.0195985,"Missing"
W00-0507,A00-1019,1,0.86616,"Missing"
W00-0507,C90-2045,0,0.0899252,"eract with the user and how to find appropriate multi-word units for suggestions that can be computed in real time. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled trans][ators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from the meaning of the source text to the form of the target"
W00-0507,C86-1077,0,0.503703,"o find appropriate multi-word units for suggestions that can be computed in real time. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled trans][ators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from the meaning of the source text to the form of the target text. This would relieve"
W00-1419,C96-1034,0,0.03949,"Missing"
W00-1419,W98-1431,1,0.871509,"Missing"
W02-1020,J93-2003,0,0.00791075,"Missing"
W02-1020,W97-0504,0,0.109042,"Missing"
W02-1020,1997.mtsummit-papers.1,0,0.685544,"Missing"
W02-1020,W00-0707,1,0.889221,"Missing"
W02-1020,J99-4005,0,0.0733578,"Missing"
W02-1020,A00-1019,1,0.904482,"Missing"
W02-1020,P98-2158,0,0.0401272,"Missing"
W02-1020,C00-2123,0,0.0311209,"Missing"
W02-1020,C98-2153,0,\N,Missing
W02-1020,langlais-etal-2002-translators,1,\N,Missing
W02-1020,P00-1006,1,\N,Missing
W04-1006,A00-2004,0,0.0163789,"alled LetSum (Legal text Summarizer), which has been developed in Java and Perl. Input to the system is a legal judgment in English. To determine the Part-of-Speech tags, the tagger described by (Hepple, 2000) is used. The semantic grammars and rules are developed in JAPE language (Java Annotations Pattern Engine) and executed by a GATE transducer (Cunningham et al., 2002). 4.1 Components of LetSum Thematic segmentation for which we performed some experiments with two statistic segmenters: one described by Hearst for the TexTiling system (Hearst, 1994) and the C99 segmenter described by Choi (Choi, 2000), both of which apply a clustering function on a document to find classes divided by theme. But because the results of these numerical segmenters were not satisfactory enough to find the thematic structures of the legal judgments, we decided to develop a segmentation process based on the specific knowledge of the legal field. Category of section title Begin of the judgment I NTRODUCTION C ONTEXT Linguistic markers decision, judgment, reason, order introduction, summary facts, background J URIDICAL A NALYSIS C ONCLUSION analysis, decision, discussion conclusion, disposiotion, cost Examples of s"
W04-1006,2004.jeptalnrecital-recitalposter.4,1,0.758503,"tic summarization has continued to grow in recent years. In this paper, we present our method for producing a very short text from a long legal document (a record of the proceedings of federal courts in Canada) and present it as a table style summary. The goal of this project is to develop a system to create a summary for the needs of lawyers, judges and experts in the legal domain. Our approach investigates the extraction of the most important units based on the identification of thematic structures of the document and the determination of semantic roles of the textual units in the judgment (Farzindar, 2004). The remainder of the paper is organized as follows. Section 2 introduces the motivation of the research and the context of the work. Section 3 reports on the results of our analysis of a corpus of legal abstracts written by professional abstractors. Section 4 describes our method for the exploration of document architecture and the components of the system that we have developed to produce a summary. Section 5 presents some related work in this domain. Section 6 concludes the paper and presents some preliminary evaluation results for the components of our system. 2 Context of the Work In Can"
W04-1006,W03-0505,0,0.0200415,"similar to our corpus. SALOMON (Moens et al., 1999) automatically extracts informative paragraphs of text from Belgian legal cases. In this project a double methodology was used. First, the case category, the case structure and irrelevant text units are identified based on a knowledge base represented as a text grammar. Consequently, general data and legal foundations concerning the essence of the case are extracted. Secondly, the system extracts informative text units of the alleged offences and of the opinion of the court based on the selection of representative objects. More recently, SUM (Grover et al., 2003) examined the use of rhetorical and discourse structure in level of the sentence of legal cases for finding the main verbes. The methodology is based on (Teufel and Moens, 2002) where sentences are classified according to their argumentative role. These studies have shown the interest of summarization in a specialized domain such as legal texts but none of these systems was implemented in an environment such as CANLII which has to deal with thousands of texts and produce summaries for each. 6 Conclusion In this paper, we have presented our approach for dealing with automatic summarization tech"
W04-1006,P00-1036,0,0.0141966,"is needed about this topic, the complete thematic segment containing the selected sentence could be presented. The summary is built in four phases (Figure 1): thematic segmentation, filtering of less important units such as citations of law articles, selection of relevant textual units and production of the summary within the size limit of the abstract. The implementation of our approach is a system called LetSum (Legal text Summarizer), which has been developed in Java and Perl. Input to the system is a legal judgment in English. To determine the Part-of-Speech tags, the tagger described by (Hepple, 2000) is used. The semantic grammars and rules are developed in JAPE language (Java Annotations Pattern Engine) and executed by a GATE transducer (Cunningham et al., 2002). 4.1 Components of LetSum Thematic segmentation for which we performed some experiments with two statistic segmenters: one described by Hearst for the TexTiling system (Hearst, 1994) and the C99 segmenter described by Choi (Choi, 2000), both of which apply a clustering function on a document to find classes divided by theme. But because the results of these numerical segmenters were not satisfactory enough to find the thematic st"
W04-1006,J02-4005,1,0.829482,"egal domain and legal interpretations of expressions produce many ambiguities. For example, the word sentence can have two very different meanings: one is a sequence of words and the other is a more particular meaning in law, the decision as to what punishment is to be imposed. Similarly disposition which means nature, effort, mental attitude or property but in legal terms it means the final part of a judgement indicating the nature of a decision: acceptation of a inquiry or dismission. Most previous systems of automatic summarization are limited to newspaper articles and scientific articles (Saggion and Lapalme, 2002). There are important differences between news style and the legal language: statistics of words, probability of selection of textual units, position of paragraphs and sentences, words of title and lexical chains relations between words of the title and the key ideas of the text, relations between sentences and paragraphs and structures of the text. For judgments, we show that we can identify discursive structures for the different parts of the decision and assign some argumentative roles to them. Newspapers articles often repeat the most important message but, in law, important information ma"
W04-1006,J02-4002,0,0.0426526,"sed. First, the case category, the case structure and irrelevant text units are identified based on a knowledge base represented as a text grammar. Consequently, general data and legal foundations concerning the essence of the case are extracted. Secondly, the system extracts informative text units of the alleged offences and of the opinion of the court based on the selection of representative objects. More recently, SUM (Grover et al., 2003) examined the use of rhetorical and discourse structure in level of the sentence of legal cases for finding the main verbes. The methodology is based on (Teufel and Moens, 2002) where sentences are classified according to their argumentative role. These studies have shown the interest of summarization in a specialized domain such as legal texts but none of these systems was implemented in an environment such as CANLII which has to deal with thousands of texts and produce summaries for each. 6 Conclusion In this paper, we have presented our approach for dealing with automatic summarization techniques. This work refers to the problem of processing of a huge volume of electronic documents in the legal field which becomes more and more difficult to access. Our method is"
W04-1006,P94-1002,0,\N,Missing
W04-3225,J96-1002,0,0.0140255,"ed within our IMT prototype. Section 3 describes the cache-based adaptation we performed on the target language model. In section 4, we present the different types of adaptations we performed on the translation model. Section 5 then puts the results in the context of our IMT application. Section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system. 2 Current IMT models The word-based translation model embedded within the IMT system has been designed by Foster (2000). It is a Maximum Entropy/Minimum Divergence (MEMD) translation model (Berger et al., 1996), which mimics the parameters of the IBM model 2 (Brown et al., 1993) within a log-linear setting. The resulting model (named MDI2B) is of the following form, where h is the current target text, s the source sentence being translated, s a particular word in s and w the next word to be predicted: P q(w|h) exp( s∈s αsw + βAB ) p(w|h, s) = (1) Z(h, s) The q distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study. The α coefficients are the familiar transfer or lexical parameters, and the β ones can be understood"
W04-3225,C88-1016,0,0.0304285,"as their position dependent correction. Z is a normalizing factor, the sum of the numerator for every w in the target vocabulary. Our baseline model used an interpolated trigram of the following form as the q distribution: p(w|h) = + + + λ1 (wi−2 wi−1 ) × ptri (wi |wi−2 wi−1 ) λ2 (wi−2 wi−1 ) × pbi (wi |wi−1 ) λ3 (wi−2 wi−1 ) × puni (wi ) λ4 (wi−2 wi−1 ) × |V 1|+1 where λ1 (wi−2 wi−1 ) + λ2 (wi−2 wi−1 ) + λ3 (wi−2 wi−1 ) + λ4 (wi−2 wi−1 ) = 1 and |V |+ 1 is the size of the event space (including a special unknown word). As mentioned above, the MDI2B model is closely related to the IBM2 model (Brown et al., 1988). It contains two classes of features: word pair features and positional features. The word pair feature functions are defined as follows:  1 if s ∈ s and t = w fst (w, h, s) = 0 otherwise This function is on if the predicted word is t and s is in the current source sentence. Each feature fst has a corresponding weight αst (for brevity, this is defined to be 0 in equation 1 if the pair s, t is not included in the model). The positional feature functions are defined as follows: fA,B (w, i, s) = J X δ[(i, j, J) ∈ A ∧ (sj , w) ∈ B ∧ j = ˆsj ] j=1 where δ[X] is 1 if X is true, otherwise 0; and"
W04-3225,J93-2003,0,0.00945756,"ation we performed on the target language model. In section 4, we present the different types of adaptations we performed on the translation model. Section 5 then puts the results in the context of our IMT application. Section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system. 2 Current IMT models The word-based translation model embedded within the IMT system has been designed by Foster (2000). It is a Maximum Entropy/Minimum Divergence (MEMD) translation model (Berger et al., 1996), which mimics the parameters of the IBM model 2 (Brown et al., 1993) within a log-linear setting. The resulting model (named MDI2B) is of the following form, where h is the current target text, s the source sentence being translated, s a particular word in s and w the next word to be predicted: P q(w|h) exp( s∈s αsw + βAB ) p(w|h, s) = (1) Z(h, s) The q distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study. The α coefficients are the familiar transfer or lexical parameters, and the β ones can be understood as their position dependent correction. Z is a normalizing factor, th"
W04-3225,W02-1020,1,0.903063,"Missing"
W04-3225,W03-0302,0,0.0102562,"ith documents such as the sniper corpus, we believe that this could be a key improvement for a dynamic adaptive model. Better alignment As mentioned before, the ultimate goal for our cache is that it contains only the pairs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done for positional alignment"
W04-3225,W03-0301,0,0.0457849,"Missing"
W04-3225,W01-1411,0,0.0113039,"the sniper corpus, we believe that this could be a key improvement for a dynamic adaptive model. Better alignment As mentioned before, the ultimate goal for our cache is that it contains only the pairs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done for positional alignment features, wou"
W04-3225,P00-1056,0,0.0456813,"ition. Especially with documents such as the sniper corpus, we believe that this could be a key improvement for a dynamic adaptive model. Better alignment As mentioned before, the ultimate goal for our cache is that it contains only the pairs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done fo"
W04-3225,E03-1032,0,0.0244729,"Missing"
W04-3225,W03-0304,1,0.806705,"irs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done for positional alignment features, would lead to better results. It would enable the model to take into account the tendency that a pair has to repeat itself in a document. Relative weighting Another key improvement is that changes to word-pair weigh"
W04-3225,P00-1006,1,\N,Missing
W11-1608,J05-3002,0,0.727931,"and the ability to generate new sentences, which provide an obvious advantage in improving the focus of a summary, reducing its redundancy and keeping a good compression rate. According to a recent study (Genest et al., 2009b), there is an empirical limit intrinsic to pure extraction, as compared to abstraction. For these reasons, as well as for the technical and theoretical challenges involved, we were motivated to come up with an abstractive summarization model. Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al., 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection. We believe that a “fully abstractive” approach requires a separate process for the analysis of the text that serves as an intermediate step before the generation of sentences. This way, content selection can be applied to an abstract representation rather than to original sentences or generated sentences. We propose the concept of Information Items (INIT) to help define the abstract representati"
W11-1608,C96-2183,0,0.0490964,"Missing"
W11-1608,W09-0613,0,0.0253953,"f course, even though about half the candidates are rejected. Examples of rejected Inits include those with verbs in infinitive form and those that are part of a conditional clause. Discarding a lot of available information is a significant limitation of this first attempt, which we will address as the first priority in the future. 3.2 Generation From each INIT retrieved, we directly generate a new sentence, instead of first selecting INITs and planning the summary. This is accomplished using the original parse tree of the sentence from which the INIT is taken, and the NLG realizer SimpleNLG (Gatt and Reiter, 2009) to generate an actual sentence. Sample generated sentences are illustrated in Figure 2. This process – a type of text-to-text generation – can be described as translating the parts that we want to keep from the dependency tree provided by the parser, into a format that the realizer understands. This way we keep track of what words play what role in the generated sentence and we select directly which parts of a sentence appear in a generated sentence for the summary. All of this is driven by the previous identification of INITs. We do not include any words identified as a date or a location in"
W11-1608,W01-0100,0,0.322169,"ract representation relies on the concept of Information Items (INIT), which we define as the smallest element of coherent information in a text or a sentence. Our framework differs from previous abstractive summarization models in requiring a semantic analysis of the text. We present a first attempt made at developing a system from this framework, along with evaluation results for it from TAC 2010. We also present related work, both from within and outside of the automatic summarization domain. 1 Introduction Summarization approaches can generally be categorized as extractive or abstractive (Mani, 2001). Most systems developped for the main international conference on text summarization, the Text Analysis Conference (TAC) (Owczarzak and Dang, 2010), predominantly use sentence extraction, including all the top-ranked systems, which make only minor post-editing of extracted sentences (Conroy et al., 2010) (Gillick et al., 2009) (Genest et al., 2008) (Chen et al., 2008). Abstractive methods require a deeper analysis of the text and the ability to generate new sentences, which provide an obvious advantage in improving the focus of a summary, reducing its redundancy and keeping a good compression"
W11-1608,C04-1129,0,0.00808663,"field of text simplification. Text simplification has been associated with techniques that deal not only with helping readers with reading disabilities, but also to help NLP systems (Chandrasekar et al., 1996). The work of (Beigman Klebanov et al., 2004) simplifies sentences by using MINIPAR parses as a starting point, in a process similar to ours, for the purpose of helping information-seeking applications in their own task. (Vickrey and Koller, 2008) applies similar techniques, using a sequence of rule-based simplifications of sentences, to preprocess documents for Semantic Role Labeling. (Siddharthan et al., 2004) uses shallow techniques for syntactical simplification of text by removing relative clauses and apposi71 tives, before running a sentence clustering algorithm for multi-document summarization. The kind of text-to-text generation involved in our work is related to approaches in paraphrasing (Androutsopoulos and Malakasiotis, 2010). Paraphrase generation produces sentences with similar meanings, but paraphrase extraction from texts requires a certain level of analysis. In our case, we are interested both in reformulating specific aspects of a sentence, but also in identifying parts of sentences"
W11-1608,W09-2808,0,0.230929,"s, which provide an obvious advantage in improving the focus of a summary, reducing its redundancy and keeping a good compression rate. According to a recent study (Genest et al., 2009b), there is an empirical limit intrinsic to pure extraction, as compared to abstraction. For these reasons, as well as for the technical and theoretical challenges involved, we were motivated to come up with an abstractive summarization model. Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al., 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection. We believe that a “fully abstractive” approach requires a separate process for the analysis of the text that serves as an intermediate step before the generation of sentences. This way, content selection can be applied to an abstract representation rather than to original sentences or generated sentences. We propose the concept of Information Items (INIT) to help define the abstract representation. An INIT is the smallest elemen"
W11-1608,P08-1040,0,0.0417415,"ereas we used several rules to clean up the SVOs that would serve as INITs. Rewriting sentences one idea at a time, as we have done in this work, is also related to the field of text simplification. Text simplification has been associated with techniques that deal not only with helping readers with reading disabilities, but also to help NLP systems (Chandrasekar et al., 1996). The work of (Beigman Klebanov et al., 2004) simplifies sentences by using MINIPAR parses as a starting point, in a process similar to ours, for the purpose of helping information-seeking applications in their own task. (Vickrey and Koller, 2008) applies similar techniques, using a sequence of rule-based simplifications of sentences, to preprocess documents for Semantic Role Labeling. (Siddharthan et al., 2004) uses shallow techniques for syntactical simplification of text by removing relative clauses and apposi71 tives, before running a sentence clustering algorithm for multi-document summarization. The kind of text-to-text generation involved in our work is related to approaches in paraphrasing (Androutsopoulos and Malakasiotis, 2010). Paraphrase generation produces sentences with similar meanings, but paraphrase extraction from tex"
W13-2110,J96-1004,1,0.406229,"Missing"
W13-2110,J02-4005,1,0.793241,"g the selection of the most important sentences from the original documents. In much the same way as NLG has suffered from the fact that it is often possible to trick the readers with canned text or formatted templates, abstractive summarization had to compete with acceptable results produced by scorers of sentences, the ones with the best scores being then concatenated to produce a summary. In our group, we tried to stay away from such approaches that in our view did not give any new insights even though it did not always allow us to win the summarization competitions at DUC or TAC. S UM UM (Saggion and Lapalme, 2002) explored the idea of dynamic summarization by taking a raw technical text as input and produced an indicative-informative summary. The indicative part of the summary identifies the topics of the document, and the informative part elaborates on some of these topics according to the reader’s interest. SumUM motivates the topics, describes entities, and defines concepts. This is accomplished through a process of shallow syntactic and semantic analysis, concept identification, and text regeneration. L ET SUM (Farzindar and Lapalme, 2004) developed an approach for the summarization of legal docume"
W13-2110,W13-2125,1,0.751327,"Missing"
W13-2110,W04-1006,1,\N,Missing
W13-2125,W11-2817,0,0.533017,"igher complexity of French morphology. 3.2 Syntax Verb phrase and clause: First, English and French have the same basic clause constituent order: Subject-Verb-Object (SVO). Even more importantly for SimpleNLG-EnFr, this constituent order is relatively stable (compared with other languages like German or Russian), at least for the purpose of practical NLG applications. This frees us in most cases from having to choose between different syntactically correct word orders. We thus did not have to make such big changes to the syntactic representation as were needed in adapting SimpleNLG to German (Bollmann, 2011). Indeed, in German the subject has the same syntactic status in the clause than the object(s) and they can all occupy the same varying positions relative to the verb. However, Bollmann (2011) had more leeway because he had decided not to keep the English grammar alongside the German one in his implementation. In contrast, in SimpleNLG-EnFr we wanted to be able to change freely between English and French grammars during the generation of a single text. English and French also have a very similar passive construction. In French, it is used less frequently because other options exist to avoid me"
W13-2125,W09-0613,0,0.328558,"palme}@iro.umontreal.ca Abstract This paper describes SimpleNLG-EnFr, an adaption of the English realisation engine SimpleNLG (Gatt and Reiter, 2009) for bilingual English-French realisation. Grammatical similarities between English and French that could be exploited and specifics of French that needed adaptation are discussed. 1 Introduction Surface realisation is the last step in natural language generation. It takes as input an abstract representation where lexical units and syntactic structures have been determined. Its output is formatted natural language text. SimpleNLG, as described in Gatt and Reiter (2009), is a realisation engine for English in the form of a Java library. It handles inflection, derivation, word order, auxiliaries, agreement, pronominalisation, punctuation, spacing, etc. This paper describes SimpleNLG-EnFr 1.1 1 , a bilingual realisation engine for English and French derived from SimpleNLG 4.2, and explains the design choices and the challenges encountered. Grammatical similarities and differences between English and French that influenced the design are discussed. The current version of SimpleNLG is 4.4, but all mentions of SimpleNLG in this paper refer to version 4.2. 2 Subse"
W14-6402,van-assem-etal-2006-conversion,0,0.0878874,"Missing"
W14-6704,C10-1052,0,0.062975,"Missing"
W14-6704,2008.jeptalnrecital-long.18,0,0.130759,"Missing"
W15-4719,W09-0613,0,0.260956,"ations. The realization engine is mainly rule-based. Table driven rules are defined for inflection and algorithmic propagation rules, for agreements. It allows its user to build a variety of French and English expressions and sentences from a single specification to produce dynamic output depending on the content of a web page. Natural language generation can automate a significant part of textual production, only requiring a human to supply some important aspects and thus saving considerable time for producing consistent grammatically correct output. In recent years, tools such as SimpleNLG (Gatt and Reiter, 2009) facilitated text realization by a programmer provided they program their application in Java. This system was then extended with SimpleNLG-EnFr (Vaudry and Lapalme, 2013), a English-French version of SimpleNLG. Another approach to text realization is JSreal (Daoust and Lapalme, 2014), a French Web realizer written in JavaScript. This paper describes an attempt at combining the ideas of SimpleNLGEnFr and JSreal to produce a bilingual realizer for French and English from a single specification. JSrealB generates well-formed expressions and sentences. It can be used standalone for linguistic dem"
W15-4719,W13-2125,1,0.882087,"to build a variety of French and English expressions and sentences from a single specification to produce dynamic output depending on the content of a web page. Natural language generation can automate a significant part of textual production, only requiring a human to supply some important aspects and thus saving considerable time for producing consistent grammatically correct output. In recent years, tools such as SimpleNLG (Gatt and Reiter, 2009) facilitated text realization by a programmer provided they program their application in Java. This system was then extended with SimpleNLG-EnFr (Vaudry and Lapalme, 2013), a English-French version of SimpleNLG. Another approach to text realization is JSreal (Daoust and Lapalme, 2014), a French Web realizer written in JavaScript. This paper describes an attempt at combining the ideas of SimpleNLGEnFr and JSreal to produce a bilingual realizer for French and English from a single specification. JSrealB generates well-formed expressions and sentences. It can be used standalone for linguistic demonstrations or be integrated into complex text generation projects. But like JSreal, it is aimed at web developers, from taking care of morphology, declension and conjugat"
W15-4724,J86-2003,0,0.224272,"for user B on 24 November 2012. 137 3 the last activity on the choice of the current activity. Type 2 does the same for the penultimate activity and type 3 for the last two activities. Type 4 takes into account the influence of the current hour of the day on the choice of activity. Lastly, type 5 combines the current hour and the last activity to try to predict the current activity. Each rule is accompanied by an example with the first Toileting activity of Table 1. To be able to describe the algorithm in more general terms, events and states will in this paper be called eventualities (after Bach, 1986). This includes activities and hours of the day. For selecting significant association rules, we computed three properties for each candidate (Hamalainen and Nykanen, 2008): Data mining for association rules For finding significant association rules in the ADL data, we used the data mining techniques presented by Hamalainen and Nykanen (2008). This approach was selected because it has been successfully applied for the construction of a causal network from a video (Kwon and Lee, 2012). The video was first segmented spatially and temporally using only pixel information to form the nodes of the n"
W15-4724,W07-2315,0,0.0507451,"Missing"
W15-4724,W07-2317,0,0.381204,"rent automatically generated narratives fail to achieve the same level of performance (Portet et al., 2009). Experts in discourse analysis have concluded that the problem may lay in the narrative structure: deficiencies in narrative flow and narrative details impacted negatively on coherence (McKinlay et al., 2009). How can the coherence of generated narratives be improved? Causal networks have been successfully used to explain the process of narrative comprehension in humans (Trabasso et al., 1989). This motivated their use in the automatic creation of fairy tales (Swartjes and Theune, 2006; Theune et al., 2007). Those causal networks are essentially composed of physical and mental events and states (of which goals and actions) connected by causal relations. Restrictions apply on which types of causal relation can connect which types of event or state. Some have suggested that causal relations also play an important role in improving narrative generation from real-life data (Hunter et al., 2012; Gervás, 2014). Several narrative generation systems already identify and make use of some causal relations (Hallett, 2008; Hunter et al., 2012; Bouayad-Agha et al., 2012; Wanner et al., 2010). Going one step"
W15-4724,W13-2125,1,0.708187,"the rhetorical relations holding between the promoted leaves of the two children nodes are taken into account. When there are none, in the future we plan to take other relations between the two children nodes into account. Our hypothesis is that it could lead to more coherent texts provided that anaphora is used judiciously to avoid adding ambiguity. Sentence and paragraph segmentation are a function of clustering distance. The latter reflects adjacency preferences, which are defined in terms of sentences and paragraphs. Surface realization was performed using the SimpleNLG-EnFr Java library (Vaudry and Lapalme, 2013). During surface realization, the syntactic and lexical specifications are combined with the output language grammar and lexicon to generate formatted natural language text. Because SimpleNLG-EnFr can realise text in both English and French, we were able to generate a report in both languages. For that a version of the lexico-syntactic templates used in microplanning had to be written for each language. 9 Results Table 5 presents some statistics on the performance of the data mining, data interpretation and document planning stages. Data interpretation and document planning were tested by gene"
W16-1517,W13-2116,0,0.328579,"hat link to the facet of the scientific discourse. Using that information, histograms are built over the training data to infer a facet for each sentence of the paper (result, method, aim, implication and hypothesis). This helps us identify the sentences best representing a citation of the same facet. We use this information to build a structured summary of the paper as an HTML page. 1 Introduction One’s task in research is to read scientific papers to be able to compare them, to identify new problems, to position a work within the current literature and to elaborate new research propositions [8]. This implies reading many papers before finding the ones we are looking for. With the growing amount of publications, this task is getting harder. It is becoming important to have a fast way of determining the utility of a paper for our needs. A first solution is to use web sites such as CiteSeer, arXiv, Google Scholar and Microsoft Academic Search that provide cross reference citations to papers. Another approach is automatic summarization of a group of scientific papers dealing with the subject. This year’s CL-SciSumm competition for summarization of computational linguistics papers propos"
W16-1517,J02-4001,0,0.119519,"Missing"
W16-1517,J02-4002,0,0.620786,"rst works of Luhn [11] and Edmundson [5] many researchers have developed methods for finding the most relevant sentences of papers to produce abstracts and summaries. Many metrics have been introduced to measure the relevance of parts of text, either using special purpose formulas [21] or using learned weights [10]. The hypothesis for CL-SciSumm task is that important sentences can be pointed out by other papers : a citation indicates a paper considered important by the author of the citing paper. Another domain for study over scientific papers is the classification of their sentences. Teufel [19] identified the rhetorical status of sentences using Bayes classifier. To find citations inside a paper, we need to analyse the references section. Dominique Besagni et al. [1] developed a method using pattern recognition to extract fields from the references while Brett Powley and Robert Dale [15] looked citations and references simultaneously using informations from one task to help complete the second task. 3 Task Description For this year competition we were given 30 topics, 10 for training, 10 for tuning and 10 for testing [9]. Each topic is composed of a Reference Paper (RP) and some Cit"
W16-1517,P94-1019,0,\N,Missing
W16-5501,P08-1090,0,0.0853713,"Missing"
W16-5501,W15-4707,0,0.0197562,"e that every event must be directly or indirectly a precondition to the last event of the story. Although this may make sense for a fictional story, it could involve selecting out important information when starting from real-life data. In the context of generating a narrative from data with multiple actors, Gerv´as (2014) associates actions having the same actor. This makes sense, because actions by the same actor can certainly be directly or indirectly causally related. However, our prototype having been tested only on data with a single actor, this tactic would not have been adequate here. Farrell et al. (2015) use regular expressions to define explanation specifications for error trace data. Regular expressions could also be used to manually define association rules in the context of our model. Baez Miranda et al. (2014) use a task model to provide top-down constraints on the sequence of scenes that can be identified in the data to form the structure of the narrative. In contrast, our model can be said to be more bottom-up in the importance it gives to automatically extracted associations. In Vaudry and Lapalme (2015), we tried to structure the narrative using hierarchical clustering. This did not"
W16-5501,W07-2317,0,0.0305782,"ritten association rules can be used to build the structure of a narrative from real-life temporal data. The generated text’s communicative goal is to help the reader construct a causal representation of the events. A connecting associative thread allows the reader to follow associations from the beginning to the end of the text. It is created using a spanning tree over a selected associative sub-network. The results of a text quality evaluation show that the texts were understandable, but that flow between sentences, although not bad, could still be improved. 1 Swartjes and Theune (2006) and Theune et al. (2007) applied causal networks to the automatic creation of fairy tales. Several narrative data-totext systems already identify and make use of some causal relations (Hallett, 2008; Hunter et al., 2012; Wanner et al., 2010; Bouayad-Agha et al., 2012). Going further, in Vaudry and Lapalme (2015) we have tried to extract a form of causal network from temporal data and use it to build the structure of the generated narrative. We used data mining techniques to extract sequential association rules and interpreted them as indicating potential, approximate causal relations. The resulting causal network was"
W16-5501,W13-2125,1,0.846852,"s Breakfast 10:04. It is located in another paragraph. Consequently, the marker becomes beside his 10:04 PM breakfast. 2.6 OrdonezB got up at 10:02 AM and then he ate his breakfast. As usual at 10:17 AM he went to the toilet but then he unexpectedly spent 1 hour in the living room instead of grooming. In addition to having gone to the toilet at 10:17 AM, he took a shower at 11:30 AM. Also at 12:01 PM he went to the toilet. Beside his 10:04 AM breakfast, he had a snack at 12:09 PM. Surface Realization Surface realization (step 6 of Figure 1) was performed using the SimpleNLG-EnFr Java library (Vaudry and Lapalme, 2013). During surface realization, the syntactic and lexical specifications are combined with the output language grammar and lexicon to generate formatted natural language text. The lexico-syntactic templates used in microplanning were written for both English and French output languages. In combination with SimpleNLGEnFr, this enabled bilingual generation. An example of English generated text corresponding to the preceding figures is given in Figure 5. 2.7 At 2:36 PM he left for 1 hour. In addition to his 12:09 PM snack, he had a snack at 11:21 PM. As usual at 1:50 AM he went to bed. Figure 5: Ge"
W16-5501,W15-4724,1,0.849171,"ions from the beginning to the end of the text. It is created using a spanning tree over a selected associative sub-network. The results of a text quality evaluation show that the texts were understandable, but that flow between sentences, although not bad, could still be improved. 1 Swartjes and Theune (2006) and Theune et al. (2007) applied causal networks to the automatic creation of fairy tales. Several narrative data-totext systems already identify and make use of some causal relations (Hallett, 2008; Hunter et al., 2012; Wanner et al., 2010; Bouayad-Agha et al., 2012). Going further, in Vaudry and Lapalme (2015) we have tried to extract a form of causal network from temporal data and use it to build the structure of the generated narrative. We used data mining techniques to extract sequential association rules and interpreted them as indicating potential, approximate causal relations. The resulting causal network was used to express locally some rhetorical relations in the sense of the Rhetorical Structure Theory (RST) (Mann and Thompson, 1987). However we did not succeed at exploiting it to build a complete rhetorical structure that would give the text a global coherence. Introduction A narrative is"
W93-0229,J86-3001,0,0.03572,"Missing"
W93-0229,P92-1025,0,0.0366403,"Missing"
W94-0307,J89-4002,0,0.0342313,"Missing"
W94-0307,C92-2114,0,\N,Missing
W96-0406,J96-1004,1,0.864601,"Missing"
W98-1407,1993.eamt-1.1,0,0.0690738,"simple binary Value (important vs. unimportant) 1. • All this reflects, of course, in the content and form of the final text. Relative importance is signaled by different means at the text level (headers, paragraphs, etc.) and at the sentence level (word choice, •syntactic structure: main clause versus subordinate clause, topic-comment •structures). •Concerning the prominence status (i.e. relative importance of a piece of information), semioticians and text linguists have reached a similar conclusion by distinguishing between the &apos;Yoreground/background&quot; or &quot;primary/secondary level&quot; of a text [Bar66, vD77, AP89, Com92]. According to Combettes [Com92], the &quot;primary level&quot; deals with the core meaning, i.e. events and facts that make the text progress, while th e &quot;secondary level&quot; deaIs •with descriptions, evaluations, comments, and:reformulati0ns. &quot; . - - ~: &quot; i ~. : : : The distinction of levels, with information Of varying shades (salience gradation), implies t h a t it should be possible to identify corresponding linguistic &quot;markers&quot; for each one of them. Yet, as Combettes has pointed out [Com92], the means used for marking the relative importance of information may vary •from one type of text to another."
