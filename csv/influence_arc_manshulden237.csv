2020.coling-main.257,K18-3001,1,0.859646,"icularly in low-resource settings. We also propose a method to combine the analogy-motivated approach with data hallucination or augmentation. We find that the two approaches are complementary to each other and combining the two approaches is especially helpful when the training data is extremely limited. 1 Introduction Morphological tasks such as the task of morphological inflection generation have attracted great research interest in recent years. SIGMORPHON has organized annual shared tasks on morphological inflection in the past five years (Cotterell et al., 2016; Cotterell et al., 2017a; Cotterell et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020). In the typical SIGMORPHON shared task of morphological inflection, a lemma (citation form) and a morphosyntactic description (MSD) consisting of a set of features are provided, and the task is to generate an inflected form for the lemma corresponding to the MSD. Neural network models have been very successful in handling natural language processing (NLP) problems, and have achieved new state of the arts in almost every area of NLP, including characterlevel sequence to sequence transformation tasks like morphological inflection, especially when t"
2020.coling-main.257,W16-2405,1,0.834587,"l inflection. However, when we inflect walis V;NFIN → nagwawalis V;IPFV;AGFOC by analogy to guhit V;NFIN → nagguguhit V;IPFV;AGFOC, analogy also happens between paradigms: we also compare between guhit and walis, and between nagguguhit and nagwawalis, where commonality is found in the affix part between pairs. We resort to both the intraparadigmatic analogy and the interparadigmatic analogy in order to inflect unknown words from our knowledge of other words. There exists previous work trying to catch both parts of analogical reasoning (Hulden, 2014; Ahlberg et al., 2014; Ahlberg et al., 2015; Forsberg and Hulden, 2016; Silfverberg et al., 2018), though neural network models for morphological inflection have been relying on the neural model itself to catch the interparadigmatic analogy implicitly and haven’t explicitly incorporated the cross-paradigm information. Neural models for morphological inflection are traditionally trained to inflect from the lemma form only. In our Tagalog example, then, every form of the verb walis would be predicted from the NFIN form walis. Since models trained in this fashion perform quite well, they must have implicitly learned to form the analogies described above, even thoug"
2020.coling-main.257,E17-1049,0,0.0709096,"Missing"
2020.coling-main.257,P17-1182,0,0.0903687,"Missing"
2020.coling-main.257,2020.sigmorphon-1.17,1,0.246524,"phological inflection task include engineering the neural network architecture to take better advantage of linguistic knowledge (Aharoni and Goldberg, 2017; Wu et al., 2018; Wu and Cotterell, 2019; Canby et al., 2020), designing data hallucination techniques to generate synthetic data based on existing labeled data (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Yu et al., 2020), augmenting the training data by making better use of labeled or unlabeled data (Kann and Sch¨utze, 2017; Kann et al., 2017a; Silfverberg et al., 2018; Silfverberg and Hulden, 2018; Liu and Hulden, 2020), and cross-lingual transfer learning, i.e. using labeled data in related languages to train models for the target language (McCarthy et al., 2019). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2861 Proceedings of the 28th International Conference on Computational Linguistics, pages 2861–2878 Barcelona, Spain (Online), December 8-13, 2020 ID MSD 1 2 3 4 5 6 7 V;NFIN V;AGFOC;LGSPEC1 V;IPFV;AGFOC V;PFV;AGFOC V;PFOC;LGSPEC1 V;IPFV;PFOC V;PFV;PFOC Lexeme1 “draw” Lexeme2 “sweep” Lexeme3 “carry ov"
2020.coling-main.257,W19-4201,0,0.0194716,"digm examples Model architecture engineering and data hallucination and augmentation techniques have seen consistent performance gains in current literature, but the effect of cross-lingual transfer for morphological inflection is less consistent. Some work has shown advances by conducting cross-lingual learning (Kann et al., 2017b; Anastasopoulos and Neubig, 2019; Murikinati and Anastasopoulos, 2020; Scherbakov, 2020; Peters and Martins, 2020), while some others have not found obvious improvements (Bergmanis et al., 2017; Rama and C ¸ o¨ ltekin, 2018; C ¸ o¨ ltekin, 2019; Hauer et al., 2019; Madsack and Weißgraeber, 2019). Wu et al. (2020) shows the success of the Transformer architecture (Vaswani et al., 2017) for characterlevel transduction tasks, as is also supported by the results of the SIGMORPHON 2020 shared task 0 on morphological inflection (Vylomova et al., 2020). One approach the SIGMORPHON 2020 shared task 0 participating teams adopted to tackle the low-resource languages is data augmentation. The winning system (Liu and Hulden, 2020) reorganized the shared task data into partial paradigms and augmented the training data by inflecting from multiple known source forms in a paradigm—as opposed to the"
2020.coling-main.257,W19-4226,1,0.908574,"settings. We also propose a method to combine the analogy-motivated approach with data hallucination or augmentation. We find that the two approaches are complementary to each other and combining the two approaches is especially helpful when the training data is extremely limited. 1 Introduction Morphological tasks such as the task of morphological inflection generation have attracted great research interest in recent years. SIGMORPHON has organized annual shared tasks on morphological inflection in the past five years (Cotterell et al., 2016; Cotterell et al., 2017a; Cotterell et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020). In the typical SIGMORPHON shared task of morphological inflection, a lemma (citation form) and a morphosyntactic description (MSD) consisting of a set of features are provided, and the task is to generate an inflected form for the lemma corresponding to the MSD. Neural network models have been very successful in handling natural language processing (NLP) problems, and have achieved new state of the arts in almost every area of NLP, including characterlevel sequence to sequence transformation tasks like morphological inflection, especially when there are abundant label"
2020.coling-main.257,2020.sigmorphon-1.6,0,0.0137654,"winalis sunong magsusunong nagsusunong nagsunong susunungin sinusunong sinunong suot magsusuot nagsusuot nagsuot susuutin sinusuot sinuot tanong magtatanong nagtatanong nagtanong tatanungin tinatanong tinanong Table 1: Tagalog paradigm examples Model architecture engineering and data hallucination and augmentation techniques have seen consistent performance gains in current literature, but the effect of cross-lingual transfer for morphological inflection is less consistent. Some work has shown advances by conducting cross-lingual learning (Kann et al., 2017b; Anastasopoulos and Neubig, 2019; Murikinati and Anastasopoulos, 2020; Scherbakov, 2020; Peters and Martins, 2020), while some others have not found obvious improvements (Bergmanis et al., 2017; Rama and C ¸ o¨ ltekin, 2018; C ¸ o¨ ltekin, 2019; Hauer et al., 2019; Madsack and Weißgraeber, 2019). Wu et al. (2020) shows the success of the Transformer architecture (Vaswani et al., 2017) for characterlevel transduction tasks, as is also supported by the results of the SIGMORPHON 2020 shared task 0 on morphological inflection (Vylomova et al., 2020). One approach the SIGMORPHON 2020 shared task 0 participating teams adopted to tackle the low-resource languages is d"
2020.coling-main.257,N19-4009,0,0.0246153,"ining one model for each language with and without data hallucination, or training one model per language group with and without data hallucination. This results in 8 baseline models: trm-single, trm-hal-single, trm-shared, trm-hal-shared, and mono-single, mono-hal-single, mono-shared, mono-hal-shared. All the baseline models are trained with only lemma as the source form. Since we adopt the Transformer architecture for morphological inflection, our work focuses on the comparison with the Transformer baselines. We use the implementation of the Transformer architecture in the Fairseq toolkit2 (Ott et al., 2019), and set the hyperparameters equal to the SIGMORPHON shared task Transformer baselines, except that we use beam search rather than greedy search for decoding. Details on the hyperparameters and training heuristics used in the current paper is provided in Appendix A. We train one model with the Fairseq 2 https://fairseq.readthedocs.io/en/latest/ 2865 Figure 2: Comparison of model performance. The white circle indicates the median accuracy, and the white triangle indicates the average accuracy. The models are displayed from left to right with decreasing average accuracy. Figures in green are ou"
2020.coling-main.257,2020.sigmorphon-1.4,0,0.0374263,"ungin sinusunong sinunong suot magsusuot nagsusuot nagsuot susuutin sinusuot sinuot tanong magtatanong nagtatanong nagtanong tatanungin tinatanong tinanong Table 1: Tagalog paradigm examples Model architecture engineering and data hallucination and augmentation techniques have seen consistent performance gains in current literature, but the effect of cross-lingual transfer for morphological inflection is less consistent. Some work has shown advances by conducting cross-lingual learning (Kann et al., 2017b; Anastasopoulos and Neubig, 2019; Murikinati and Anastasopoulos, 2020; Scherbakov, 2020; Peters and Martins, 2020), while some others have not found obvious improvements (Bergmanis et al., 2017; Rama and C ¸ o¨ ltekin, 2018; C ¸ o¨ ltekin, 2019; Hauer et al., 2019; Madsack and Weißgraeber, 2019). Wu et al. (2020) shows the success of the Transformer architecture (Vaswani et al., 2017) for characterlevel transduction tasks, as is also supported by the results of the SIGMORPHON 2020 shared task 0 on morphological inflection (Vylomova et al., 2020). One approach the SIGMORPHON 2020 shared task 0 participating teams adopted to tackle the low-resource languages is data augmentation. The winning system (Liu and"
2020.coling-main.257,K17-2010,1,0.782365,"lt to obtain for many languages. As interest has grown in low-resource NLP, several effective strategies to improve the performance of neural models have surfaced, and neural network models have become the dominant approach in low-resource settings as well. Such efforts for the morphological inflection task include engineering the neural network architecture to take better advantage of linguistic knowledge (Aharoni and Goldberg, 2017; Wu et al., 2018; Wu and Cotterell, 2019; Canby et al., 2020), designing data hallucination techniques to generate synthetic data based on existing labeled data (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Yu et al., 2020), augmenting the training data by making better use of labeled or unlabeled data (Kann and Sch¨utze, 2017; Kann et al., 2017a; Silfverberg et al., 2018; Silfverberg and Hulden, 2018; Liu and Hulden, 2020), and cross-lingual transfer learning, i.e. using labeled data in related languages to train models for the target language (McCarthy et al., 2019). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2861 Proceedings of the"
2020.coling-main.257,C18-1137,1,0.90307,"low-resource settings as well. Such efforts for the morphological inflection task include engineering the neural network architecture to take better advantage of linguistic knowledge (Aharoni and Goldberg, 2017; Wu et al., 2018; Wu and Cotterell, 2019; Canby et al., 2020), designing data hallucination techniques to generate synthetic data based on existing labeled data (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Yu et al., 2020), augmenting the training data by making better use of labeled or unlabeled data (Kann and Sch¨utze, 2017; Kann et al., 2017a; Silfverberg et al., 2018; Silfverberg and Hulden, 2018; Liu and Hulden, 2020), and cross-lingual transfer learning, i.e. using labeled data in related languages to train models for the target language (McCarthy et al., 2019). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2861 Proceedings of the 28th International Conference on Computational Linguistics, pages 2861–2878 Barcelona, Spain (Online), December 8-13, 2020 ID MSD 1 2 3 4 5 6 7 V;NFIN V;AGFOC;LGSPEC1 V;IPFV;AGFOC V;PFV;AGFOC V;PFOC;LGSPEC1 V;IPFV;PFOC V;PFV;"
2020.emnlp-main.424,P17-1183,0,0.0127464,"ncerned with generation (as opposed to analysis) has focused on morpholog5253 Text Segmented Glossed Translation Vecherom ya pobejala vecher-om ya pobeja-la evening-INS 1.SG.NOM run-PFV.PST.SG.FEM ‘In the evening I ran to the store.’ v v in magazin. magazin store.ACC Table 2: An example of typical interlinear glossed text (IGT) with a transliterated Russian sentence, including translation. This paper leverages the original text and gloss lines. ical inflection or reinflection. Approaches include Durrett and DeNero (2013); Nicolai et al. (2015); Faruqui et al. (2016); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017). Partially building on these, other research has developed models which are more suitable for low-resource languages and perform well with limited data (Kann et al., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on paradigm completion – or the paradigm cell filling problem (PCFP; Ackerman et al.,"
2020.emnlp-main.424,N13-1138,0,0.0527418,"sks described in Section 2.1. Most recent work in the area of computational morphology which was concerned with generation (as opposed to analysis) has focused on morpholog5253 Text Segmented Glossed Translation Vecherom ya pobejala vecher-om ya pobeja-la evening-INS 1.SG.NOM run-PFV.PST.SG.FEM ‘In the evening I ran to the store.’ v v in magazin. magazin store.ACC Table 2: An example of typical interlinear glossed text (IGT) with a transliterated Russian sentence, including translation. This paper leverages the original text and gloss lines. ical inflection or reinflection. Approaches include Durrett and DeNero (2013); Nicolai et al. (2015); Faruqui et al. (2016); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017). Partially building on these, other research has developed models which are more suitable for low-resource languages and perform well with limited data (Kann et al., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our exp"
2020.emnlp-main.424,D19-1091,0,0.340374,"Missing"
2020.emnlp-main.424,N16-1077,0,0.0139444,"the area of computational morphology which was concerned with generation (as opposed to analysis) has focused on morpholog5253 Text Segmented Glossed Translation Vecherom ya pobejala vecher-om ya pobeja-la evening-INS 1.SG.NOM run-PFV.PST.SG.FEM ‘In the evening I ran to the store.’ v v in magazin. magazin store.ACC Table 2: An example of typical interlinear glossed text (IGT) with a transliterated Russian sentence, including translation. This paper leverages the original text and gloss lines. ical inflection or reinflection. Approaches include Durrett and DeNero (2013); Nicolai et al. (2015); Faruqui et al. (2016); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017). Partially building on these, other research has developed models which are more suitable for low-resource languages and perform well with limited data (Kann et al., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on paradigm completion – or the"
2020.emnlp-main.424,bender-2014-language,0,0.0126653,"lemmas, an accompanying step in fieldwork is that of elicitation of inflectional paradigms for selected lemmas. Presenting candidate words to a native speaker for acceptance or rejection is often easier than asking the speaker to grasp the abstract concept of a paradigm and to generate the missing cells in a table. With the help of IGT2P, linguists could use the machine-generated word forms to support this elicitation process. IGT2P then becomes a tool for the discovery of morphological patterns in under-described and endangered languages. 3 Related Work IGT for NLP. The AGGREGATION project (Bender, 2014) has used IGT to automatically construct grammars for multiple languages. This includes inferring and visualizing systems of morphosyntax (Lepp et al., 2019; Wax, 2014). Much of their data comes from the Online Database of INterlinear Text (Lewis and Xia, 2010, ODIN) which is a collection of IGTs extracted from published linguistic documents on the web. Published IGT excerpts, such as those in ODIN, differ from IGTs produced by field linguists such as those used in our experiments. First, noise is generally removed from the published examples. Second, the amount of glossed information in publi"
2020.emnlp-main.424,K18-3001,1,0.86364,"Missing"
2020.emnlp-main.424,K17-2001,1,0.92412,"Missing"
2020.emnlp-main.424,E17-1049,1,0.901192,"Missing"
2020.emnlp-main.424,P17-1182,1,0.917577,"Missing"
2020.emnlp-main.424,E17-2120,0,0.0177591,"u and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on paradigm completion – or the paradigm cell filling problem (PCFP; Ackerman et al., 2009) – includes Malouf (2016), who trained recurrent neural networks for it, and applied them successfully to Irish, Maltese, and Khaling, among other languages. Silfverberg and Hulden (2018) also trained neural networks for the task. Kann et al. (2017a) differed from other approaches in that they encoded multiple inflected forms of a lemma to provide complementary information for the generation of unknown forms of the same lemma. Finally, Cotterell et al. (2017b) introduced neural graphical models which completed paradigms based on principal parts. The unsupervised version of the paradigm completion task (Jin et al., 2020) has been the subject of a recent shared task (Kann et al., 2020b), with the conclusion that it is exremely challenging for current state-of-the-art systems. Here, we propose to, instead of generating paradigms from raw text, generate them from IGT, a resource available for many under-studied languages. 4 To POS Tag or Not to POS Tag In addition to the lemma and the morphological features of the target form, part-of-speech (POS) ta"
2020.emnlp-main.424,P16-2090,1,0.910705,"Missing"
2020.emnlp-main.424,N19-4022,0,0.0210044,"speaker for acceptance or rejection is often easier than asking the speaker to grasp the abstract concept of a paradigm and to generate the missing cells in a table. With the help of IGT2P, linguists could use the machine-generated word forms to support this elicitation process. IGT2P then becomes a tool for the discovery of morphological patterns in under-described and endangered languages. 3 Related Work IGT for NLP. The AGGREGATION project (Bender, 2014) has used IGT to automatically construct grammars for multiple languages. This includes inferring and visualizing systems of morphosyntax (Lepp et al., 2019; Wax, 2014). Much of their data comes from the Online Database of INterlinear Text (Lewis and Xia, 2010, ODIN) which is a collection of IGTs extracted from published linguistic documents on the web. Published IGT excerpts, such as those in ODIN, differ from IGTs produced by field linguists such as those used in our experiments. First, noise is generally removed from the published examples. Second, the amount of glossed information in published IGT snippets can vary widely depending on the phenomenon that is the main focus of the publication. Computational morphology. Our work is further relat"
2020.emnlp-main.424,D18-1314,0,0.0119307,"the store.’ v v in magazin. magazin store.ACC Table 2: An example of typical interlinear glossed text (IGT) with a transliterated Russian sentence, including translation. This paper leverages the original text and gloss lines. ical inflection or reinflection. Approaches include Durrett and DeNero (2013); Nicolai et al. (2015); Faruqui et al. (2016); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017). Partially building on these, other research has developed models which are more suitable for low-resource languages and perform well with limited data (Kann et al., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on paradigm completion – or the paradigm cell filling problem (PCFP; Ackerman et al., 2009) – includes Malouf (2016), who trained recurrent neural networks for it, and applied them successfully to Irish, Maltese, and Khaling, among other languages. Silfverberg and Hulden (2018) also trained neural networks"
2020.emnlp-main.424,W19-4226,1,0.816571,"ng paradigm cells. Noisy paradigms are automatically constructed from IGT and a language expert creates “cleaned” paradigms. Both sets are tested on the same missing word forms and the results are compared. Introduction Over the last few years, multiple shared tasks have encouraged the development of systems for learning morphology, including generating inflected forms of the canonical form—the lemma—of a word. NLP systems that account for morphology can reduce data sparsity caused by an abundance of individual word forms in morphologically rich languages (Cotterell et al., 2016, 2017a, 2018; McCarthy et al., 2019; Vylomova et al., 2020) and help mitigate bias in training data for natural language processing (NLP) systems (Zmigrod et al., 2019). However, such systems have often been limited to languages with publicly available structured data, i.e. languages for which tables containing inflectional patterns can be found, for example, in online dictionaries like Wiktionary.1 This limits the development of NLP systems for morphology to languages for which morphological information can be easily extracted. Here, we propose to instead make use of a resource which is much more common, especially for low-res"
2020.emnlp-main.424,N15-1093,0,0.0695259,"1. Most recent work in the area of computational morphology which was concerned with generation (as opposed to analysis) has focused on morpholog5253 Text Segmented Glossed Translation Vecherom ya pobejala vecher-om ya pobeja-la evening-INS 1.SG.NOM run-PFV.PST.SG.FEM ‘In the evening I ran to the store.’ v v in magazin. magazin store.ACC Table 2: An example of typical interlinear glossed text (IGT) with a transliterated Russian sentence, including translation. This paper leverages the original text and gloss lines. ical inflection or reinflection. Approaches include Durrett and DeNero (2013); Nicolai et al. (2015); Faruqui et al. (2016); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017). Partially building on these, other research has developed models which are more suitable for low-resource languages and perform well with limited data (Kann et al., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on parad"
2020.emnlp-main.424,D18-1315,1,0.806599,"l., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on paradigm completion – or the paradigm cell filling problem (PCFP; Ackerman et al., 2009) – includes Malouf (2016), who trained recurrent neural networks for it, and applied them successfully to Irish, Maltese, and Khaling, among other languages. Silfverberg and Hulden (2018) also trained neural networks for the task. Kann et al. (2017a) differed from other approaches in that they encoded multiple inflected forms of a lemma to provide complementary information for the generation of unknown forms of the same lemma. Finally, Cotterell et al. (2017b) introduced neural graphical models which completed paradigms based on principal parts. The unsupervised version of the paradigm completion task (Jin et al., 2020) has been the subject of a recent shared task (Kann et al., 2020b), with the conclusion that it is exremely challenging for current state-of-the-art systems. He"
2020.emnlp-main.424,P19-1148,0,0.185939,"agazin store.ACC Table 2: An example of typical interlinear glossed text (IGT) with a transliterated Russian sentence, including translation. This paper leverages the original text and gloss lines. ical inflection or reinflection. Approaches include Durrett and DeNero (2013); Nicolai et al. (2015); Faruqui et al. (2016); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017). Partially building on these, other research has developed models which are more suitable for low-resource languages and perform well with limited data (Kann et al., 2017b; Sharma et al., 2018; Makarov and Clematide, 2018; Wu and Cotterell, 2019; Kann et al., 2020a; Wu et al., 2020). These are the most relevant approaches for our work, since we expect IGT2P to aid documentation of low-resource languages. Accordingly, we use the systems by Wu and Cotterell (2019) and Wu et al. (2020) in our experiments. Work on paradigm completion – or the paradigm cell filling problem (PCFP; Ackerman et al., 2009) – includes Malouf (2016), who trained recurrent neural networks for it, and applied them successfully to Irish, Maltese, and Khaling, among other languages. Silfverberg and Hulden (2018) also trained neural networks for the task. Kann et al"
2020.emnlp-main.424,2021.eacl-main.163,1,0.931506,"Missing"
2020.emnlp-main.424,P00-1027,0,0.519567,"Missing"
2020.emnlp-main.424,P19-1161,0,0.0284426,"s are tested on the same missing word forms and the results are compared. Introduction Over the last few years, multiple shared tasks have encouraged the development of systems for learning morphology, including generating inflected forms of the canonical form—the lemma—of a word. NLP systems that account for morphology can reduce data sparsity caused by an abundance of individual word forms in morphologically rich languages (Cotterell et al., 2016, 2017a, 2018; McCarthy et al., 2019; Vylomova et al., 2020) and help mitigate bias in training data for natural language processing (NLP) systems (Zmigrod et al., 2019). However, such systems have often been limited to languages with publicly available structured data, i.e. languages for which tables containing inflectional patterns can be found, for example, in online dictionaries like Wiktionary.1 This limits the development of NLP systems for morphology to languages for which morphological information can be easily extracted. Here, we propose to instead make use of a resource which is much more common, especially for low-resource languages: we explore how to leverage interlinear glossed text (IGT)—a common artifact of linguistic field research—to generate"
2020.lrec-1.483,P19-1310,0,0.0958144,"Missing"
2020.lrec-1.483,C12-2009,1,0.843263,"Missing"
2020.lrec-1.483,P19-1156,0,0.050149,"Missing"
2020.lrec-1.483,P16-1156,1,0.881371,"Missing"
2020.lrec-1.483,K17-2001,1,0.904106,"Missing"
2020.lrec-1.483,N07-1048,0,0.0363457,"Missing"
2020.lrec-1.483,P08-1115,0,0.0323664,"Missing"
2020.lrec-1.483,K19-1014,1,0.901227,"Missing"
2020.lrec-1.483,N12-1032,0,0.0791982,"Missing"
2020.lrec-1.483,D19-1328,0,0.0253837,"Missing"
2020.lrec-1.483,S19-1026,1,0.819906,"Missing"
2020.lrec-1.483,L16-1498,1,0.928068,"Missing"
2020.lrec-1.483,L18-1293,1,0.890225,"Missing"
2020.lrec-1.483,W18-6011,1,0.883111,"Missing"
2020.lrec-1.483,W19-4226,1,0.885665,"Missing"
2020.lrec-1.483,D14-1095,0,0.0393603,"Missing"
2020.lrec-1.483,2020.lrec-1.488,1,0.822461,"Missing"
2020.lrec-1.483,L16-1262,0,0.126329,"Missing"
2020.lrec-1.483,Q15-1026,0,0.0701072,"Missing"
2020.lrec-1.483,W18-1813,1,0.887977,"Missing"
2020.lrec-1.483,P15-2111,1,0.855194,"Missing"
2020.lrec-1.483,A94-1008,0,0.317255,"Missing"
2020.lrec-1.483,N01-1026,1,0.569711,"Missing"
2020.sigmorphon-1.1,K18-3001,1,0.899071,"logical reinflection, we specifically focus on typological diversity and aim to investigate systems’ ability to generalize across typologically distinct languages many of which are low-resource. For example, if a neural network architecture works well for a sample of IndoEuropean languages, should the same architecture also work well for Tupi–Guarani languages (where nouns are “declined” for tense) or Austronesian languages (where verbal morphology is frequently prefixing)? 2 Task Description The 2020 iteration of our task is similar to CoNLL-SIGMORPHON 2017 (Cotterell et al., 2017) and 2018 (Cotterell et al., 2018) in that participants are required to design a model that learns to generate inflected forms from a lemma and a set of morphosyntactic features that derive the desired target form. For each language we provide a separate training, development, and test set. More historically, all of these tasks resemble the classic “wug”-test that Berko (1958) developed to test child and human knowledge of English nominal morphology. Unlike the task from earlier years, this year’s task proceeds in three phases: a Development Phase, a Generalization Phase, and an Evaluation Phase, in which each phase introduces"
2020.sigmorphon-1.1,K17-2001,1,0.928876,"e SIGMORPHON shared task on morphological reinflection, we specifically focus on typological diversity and aim to investigate systems’ ability to generalize across typologically distinct languages many of which are low-resource. For example, if a neural network architecture works well for a sample of IndoEuropean languages, should the same architecture also work well for Tupi–Guarani languages (where nouns are “declined” for tense) or Austronesian languages (where verbal morphology is frequently prefixing)? 2 Task Description The 2020 iteration of our task is similar to CoNLL-SIGMORPHON 2017 (Cotterell et al., 2017) and 2018 (Cotterell et al., 2018) in that participants are required to design a model that learns to generate inflected forms from a lemma and a set of morphosyntactic features that derive the desired target form. For each language we provide a separate training, development, and test set. More historically, all of these tasks resemble the classic “wug”-test that Berko (1958) developed to test child and human knowledge of English nominal morphology. Unlike the task from earlier years, this year’s task proceeds in three phases: a Development Phase, a Generalization Phase, and an Evaluation Pha"
2020.sigmorphon-1.1,W09-0106,0,0.0385713,"n variably surface as prefixes, suffixes, infixes, or circumfixes (Dryer, 2013). Most Eurasian and Australian languages strongly favor suffixation, and the same holds true, but to a lesser extent, for South American and New Guinean languages (Dryer, 2013). In Mesoamerican languages and African languages spoken below the Sahara, prefixation is dominant instead. These are just three dimensions of variation in morphology, and the cross-linguistic variation is already considerable. Such cross-lingual variation makes the development of natural language processing (NLP) applications challenging. As Bender (2009, 2016) notes, many current architectures and training and tuning algorithms still present language-specific biases. The most commonly used language for developing NLP applications is English. Along the above dimensions, English is productively concatenative, a mixture of analytic and synthetic, and largely suffixing in its inflectional morphology. With respect to languages that exhibit inflectional morphology, English is relatively impoverished.1 Importantly, English is just one morphological system among many. A larger goal of natural language processing is that the system work for any prese"
2020.sigmorphon-1.1,2020.lrec-1.344,1,0.878264,"Missing"
2020.sigmorphon-1.1,2020.sigmorphon-1.15,0,0.0565092,"Missing"
2020.sigmorphon-1.1,2020.sigmorphon-1.14,0,0.0439232,"Missing"
2020.sigmorphon-1.1,L16-1379,0,0.0190826,"Missing"
2020.sigmorphon-1.1,K17-2010,1,0.837279,"l baselines were based on a neural transducer (Wu and Cotterell, 2019), which is essentially a hard monotonic attention model (mono-*). The second baseline is a transformer (Vaswani et al., 2017) adopted for character-level tasks that currently holds the state-of-the-art on the 2017 SIGMORPHON shared task data (Wu et al., 2020, trm-*). Both models take the lemma and morphological tags as input and output the target inflection. The baseline is further expanded to include the data augmentation technique used by Anastasopoulos and Neubig (2019, -aug-) (conceptually similar to the one proposed by Silfverberg et al. (2017)). Relying on a simple characterlevel alignment between lemma and form, this technique replaces shared substrings of length &gt; 3 with random characters from the language’s alphabet, producing hallucinated lemma–tag–form triples. Both neural baselines were trained in mono- (*-single) and multilingual (shared parameters among the same family, *-shared) settings. 6 Many teams based their models on the transformer architecture. NYU-CUBoulder experimented with a vanilla transformer model (NYU-CUBoulder-04-0), a pointer-generator transformer that allows for a copy mechanism (NYU-CUBoulder-02-0), and"
2020.sigmorphon-1.1,2020.sigmorphon-1.4,0,0.0612223,"Missing"
2020.sigmorphon-1.1,W19-4207,0,0.0125147,"c attention model with improved alignment strategy. This model is further improved (flexica-03-1) by introducing a data hallucination technique which is based on phonotactic modelling of extremely low-resource languages (Shcherbakov et al., 2016). LTI focused on their earlier model (Anastasopoulos and Neubig, 2019), a neural multi-source encoder–decoder with two-step attention architecture, training it with hallucinated data, cross-lingual transfer, and romanization of scripts to improve performance on low-resource languages. DeepSpin reimplemented gated sparse two-headed attention model from Peters and Martins (2019) and trained it on all languages at once (massively multilingual). The team experimented with two modifications of the softmax function: sparsemax (Martins and Astudillo, 2016, deepspin-02-1) and 1.5-entmax (Peters et al., 2019, deepspin-01-1). Neural Neural baselines were based on a neural transducer (Wu and Cotterell, 2019), which is essentially a hard monotonic attention model (mono-*). The second baseline is a transformer (Vaswani et al., 2017) adopted for character-level tasks that currently holds the state-of-the-art on the 2017 SIGMORPHON shared task data (Wu et al., 2020, trm-*). Both"
2020.sigmorphon-1.1,P19-1146,0,0.0351308,"Missing"
2020.sigmorphon-1.1,P19-1148,1,0.838088,"lti-source encoder–decoder with two-step attention architecture, training it with hallucinated data, cross-lingual transfer, and romanization of scripts to improve performance on low-resource languages. DeepSpin reimplemented gated sparse two-headed attention model from Peters and Martins (2019) and trained it on all languages at once (massively multilingual). The team experimented with two modifications of the softmax function: sparsemax (Martins and Astudillo, 2016, deepspin-02-1) and 1.5-entmax (Peters et al., 2019, deepspin-01-1). Neural Neural baselines were based on a neural transducer (Wu and Cotterell, 2019), which is essentially a hard monotonic attention model (mono-*). The second baseline is a transformer (Vaswani et al., 2017) adopted for character-level tasks that currently holds the state-of-the-art on the 2017 SIGMORPHON shared task data (Wu et al., 2020, trm-*). Both models take the lemma and morphological tags as input and output the target inflection. The baseline is further expanded to include the data augmentation technique used by Anastasopoulos and Neubig (2019, -aug-) (conceptually similar to the one proposed by Silfverberg et al. (2017)). Relying on a simple characterlevel alignme"
2020.sigmorphon-1.1,2020.sigmorphon-1.5,0,0.0487999,"Missing"
2020.sigmorphon-1.17,P17-1183,0,0.059372,"Missing"
2020.sigmorphon-1.17,W16-2007,0,0.0671482,"Missing"
2020.sigmorphon-1.17,D19-1091,0,0.144382,"Missing"
2020.sigmorphon-1.17,Q19-1021,1,0.889082,"Missing"
2020.sigmorphon-1.17,K18-3001,1,0.890918,"Missing"
2020.sigmorphon-1.17,K17-2001,1,0.915172,"Missing"
2020.sigmorphon-1.17,E17-2120,0,0.116688,". 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 guages (33 out of 45) when the model is trained per language. Therefore, we adopt the Transformer architecture (Vaswani et al., 2017) for all three of our models (see Figure 1) which are different from each other by the input and output to the Transformer model, as will be presented in section 3. Though not explicitly organized as a paradigm cell filling problem (PCFP) (Ackerman et al., 2009) task, the shared task is closely related to and can largely be seen as a computational instance of it (Malouf, 2016, 2017; Cotterell et al., 2017a; Silfverberg et al., 2018; Silfverberg and Hulden, 2018), where some slots are given in the paradigms as training data and others are to be inflected as development data or test data.1 The data format of the shared task privileges the lemma as the source form (henceforth srcform) which all tgtforms are inflected from. However, the lemma form may not be the only and the most informative srcform to inflect all other slots from in the same paradigm. Morphologists refer to a lexeme’s principal parts (Finkel and Stump, 2007) as the minimum subset of paradigm slots which, if known, provide all the"
2020.sigmorphon-1.17,E17-1049,0,0.244494,"Missing"
2020.sigmorphon-1.17,W16-2010,0,0.033548,"Missing"
2020.sigmorphon-1.17,D18-1314,0,0.0395941,"Missing"
2020.sigmorphon-1.17,W19-4226,1,0.937739,"ration of general model architectures. All three of our models use the Transformer architecture for inflection. They are different from each other by the input to the Transformer model. Introduction The task of morphological inflection is to generate a target inflected word form (henceforth tgtform) given a lemma form (henceforth lemma) and a target morphosyntactic description (henceforth tgtmsd). In the SIGMORPHON 2020 shared task 0 on morphological inflection (Vylomova et al., 2020) and previous years’ SIGMORPHON shared tasks on morphological inflection (Cotterell et al., 2016, 2017a, 2018; McCarthy et al., 2019), the training data is provided in the format of tabseparated lemma-tgtmsd-tgtform triples, and participating systems are expected to predict the missing target forms in the test data released shortly before prediction submission. The sequence-to-sequence (henceforth seq2seq) architecture has been very successful in dealing with morphological inflection, especially when there are abundant labeled data for training. The accuracies and Levenshtein distances on the development data inflected by 9 baseline models are provided for the 45 typologically and genealogically diversified development lang"
2020.sigmorphon-1.17,N19-4009,0,0.0301754,"ent and test data, corresponding to the reality of data availability for the language. Of the total 90 languages from 18 language families, 44 have 5,000 or more lemmatgtmsd-tgtform training triples and 46 have fewer than 5,000. Of the 45 development languages, 24 have fewer than 5,000 training examples. In this paper, we refer to languages with 5,000 or more training triples as high-resource and those with fewer than 5,000 training triples as low-resource. 3 System description All our models use the self-attention Transformer architecture (Vaswani et al., 2017) as implemented in the Fairseq (Ott et al., 2019) tool, a PyTorchbased sequence modeling toolkit. Both the encoder and decoder have 4 layers with 4 attention heads, an embedding size of 256 and hidden layer size of 1024. Models are trained with the Adam algorithm (Kingma and Ba, 2014) for optimization with an initial learning rate of 0.001, a batch size of 400, 0.1 label smoothing, the gradient clip threshold as 1.0, and 4,000 warmup updates. The models are trained for a maximum of 20,000 or 30,000 optimizer updates depending on the amount of input154 ID 1 2 3 4 5 6 7 8 MSD V;CANONICAL V;AGFOC;LGSPEC1 V;IPFV;AGFOC V;IPFV;PFOC V;NFIN V;PFOC;L"
2020.sigmorphon-1.17,D18-1315,1,0.839904,"tps://doi.org/10.18653/v1/P17 guages (33 out of 45) when the model is trained per language. Therefore, we adopt the Transformer architecture (Vaswani et al., 2017) for all three of our models (see Figure 1) which are different from each other by the input and output to the Transformer model, as will be presented in section 3. Though not explicitly organized as a paradigm cell filling problem (PCFP) (Ackerman et al., 2009) task, the shared task is closely related to and can largely be seen as a computational instance of it (Malouf, 2016, 2017; Cotterell et al., 2017a; Silfverberg et al., 2018; Silfverberg and Hulden, 2018), where some slots are given in the paradigms as training data and others are to be inflected as development data or test data.1 The data format of the shared task privileges the lemma as the source form (henceforth srcform) which all tgtforms are inflected from. However, the lemma form may not be the only and the most informative srcform to inflect all other slots from in the same paradigm. Morphologists refer to a lexeme’s principal parts (Finkel and Stump, 2007) as the minimum subset of paradigm slots which, if known, provide all the information needed to generate the other slots in its par"
2020.sigmorphon-1.17,C18-1137,1,0.45361,"Missing"
2020.sigmorphon-1.17,K17-2010,1,0.856033,"Missing"
2020.sigmorphon-1.17,P19-1148,0,0.0513832,"morphological inflection, especially when there are abundant labeled data for training. The accuracies and Levenshtein distances on the development data inflected by 9 baseline models are provided for the 45 typologically and genealogically diversified development languages: a non-neural model based on lemma-tgtform alignment and transformation, a per-language Transformer model, a per-language-family Transformer model, a perlanguage Transformer model with data augmentation, a per-language-family Transformer model with data augmentation, LSTM seq2seq models with exact hard monotonic attention (Wu and Cotterell, 2019) trained per language, per language family, per language with data augmentation, and per language family with data augmentation respectively. The data augmentation method used by the baseline models is from Anastasopoulos and Neubig (2019). The baseline numbers indicate that the Transformer model for character-level transduction (Wu et al., 2020) is very competitive, achieving the highest average accuracy and lowest average edit distance and best performance on most lan153 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, page"
2020.sigmorphon-1.17,2021.eacl-main.163,1,0.943837,"Missing"
2020.sigmorphon-1.17,D18-1473,0,0.0402444,"Missing"
2020.sigmorphon-1.18,N15-1107,1,0.834324,"itten morphological analyzer (Pirinen, 2015), with the seq2seq-based participant’s model yielding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon paradigm generalization work by Forsberg and Hulden (2016), which in turn is an extension of Hulden et al. (2014) and Ahlberg et al. (2015). An earlier non-neural model for paradigm generalization is found in Dreyer and Eisner (2011). 6.2 Human Resources We did not record the exact amounts of time spent on the project individually for each participant. However, we can estimate this based on previous years’ class surveys in the same course (LING 7565—Computational Phonology and Morphology) as regards the number of hours per week students spend working on course projects. Each student on average in the course spends 6.6 hours per week; as the project ran for 5 weeks with 19 participants, we roughly estimate a total of 627 personhou"
2020.sigmorphon-1.18,W12-6209,0,0.0198297,". 2 3 Approach All of the grammars were built with the foma finitestate tool (Hulden, 2009). Before grammar writing commenced, the participants were urged to spend roughly 1 hour in groups of 3 to quickly analyze all the languages in the development and surprise groups as follows: Finite-State Grammars Finite-state Transducer (FST) solutions have long been the foremost paradigm in which to develop linguistically informed large-scale morphological grammars (Koskenniemi, 1983; Beesley and Karttunen, 2003; Hulden, 2009). The availability of a variety of tools (Hulden (2009); Riley et al. (2009); Beesley (2012) inter alia) has also supported this mode of development, and by now hundreds of lan163 • Triage: the training sets for all languages in the shared task were rapidly analyzed for difficulty, and possible complex inflectional classes. Following this, a selection of languages were chosen by the participants to model. This was done once for the development languages, and through an additional round of triage for the surprise languages. • Each language was scored for difficulty based on familiarity with the writing system, paradigm size, complexity, and the apparent number of inflectional classes;"
2020.sigmorphon-1.18,K18-3001,1,0.833436,"Missing"
2020.sigmorphon-1.18,K17-2001,1,0.902563,"Missing"
2020.sigmorphon-1.18,D11-1057,0,0.0207472,"elding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon paradigm generalization work by Forsberg and Hulden (2016), which in turn is an extension of Hulden et al. (2014) and Ahlberg et al. (2015). An earlier non-neural model for paradigm generalization is found in Dreyer and Eisner (2011). 6.2 Human Resources We did not record the exact amounts of time spent on the project individually for each participant. However, we can estimate this based on previous years’ class surveys in the same course (LING 7565—Computational Phonology and Morphology) as regards the number of hours per week students spend working on course projects. Each student on average in the course spends 6.6 hours per week; as the project ran for 5 weeks with 19 participants, we roughly estimate a total of 627 personhours spent on the task of developing grammars. As reflected in the results, we considered 13–15"
2020.sigmorphon-1.18,W16-2405,1,0.840461,"t that compares an earlier SIGMORPHON shared task winner’s results to a Finnish handwritten morphological analyzer (Pirinen, 2015), with the seq2seq-based participant’s model yielding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon paradigm generalization work by Forsberg and Hulden (2016), which in turn is an extension of Hulden et al. (2014) and Ahlberg et al. (2015). An earlier non-neural model for paradigm generalization is found in Dreyer and Eisner (2011). 6.2 Human Resources We did not record the exact amounts of time spent on the project individually for each participant. However, we can estimate this based on previous years’ class surveys in the same course (LING 7565—Computational Phonology and Morphology) as regards the number of hours per week students spend working on course projects. Each student on average in the course spends 6.6 hours per week; as the project r"
2020.sigmorphon-1.18,E09-2008,1,0.614111,"project notes). The symbol R represents reduplication of the first CV(V) in the stem. student having training in either computer science or linguistics, and some previous training in writing finite-state morphological grammars. The languages were chosen from the 2020 SIGMORPHON shared task 0 (Vylomova et al., 2020), and the grammars were designed so as to be able to inflect unseen forms. The design was also such that the grammars were able to function as “guessers” and inflect lexemes never seen in the training data. 2 3 Approach All of the grammars were built with the foma finitestate tool (Hulden, 2009). Before grammar writing commenced, the participants were urged to spend roughly 1 hour in groups of 3 to quickly analyze all the languages in the development and surprise groups as follows: Finite-State Grammars Finite-state Transducer (FST) solutions have long been the foremost paradigm in which to develop linguistically informed large-scale morphological grammars (Koskenniemi, 1983; Beesley and Karttunen, 2003; Hulden, 2009). The availability of a variety of tools (Hulden (2009); Riley et al. (2009); Beesley (2012) inter alia) has also supported this mode of development, and by now hundreds"
2020.sigmorphon-1.18,E14-1060,1,0.838679,"sults to a Finnish handwritten morphological analyzer (Pirinen, 2015), with the seq2seq-based participant’s model yielding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon paradigm generalization work by Forsberg and Hulden (2016), which in turn is an extension of Hulden et al. (2014) and Ahlberg et al. (2015). An earlier non-neural model for paradigm generalization is found in Dreyer and Eisner (2011). 6.2 Human Resources We did not record the exact amounts of time spent on the project individually for each participant. However, we can estimate this based on previous years’ class surveys in the same course (LING 7565—Computational Phonology and Morphology) as regards the number of hours per week students spend working on course projects. Each student on average in the course spends 6.6 hours per week; as the project ran for 5 weeks with 19 participants, we roughly estimat"
2020.sigmorphon-1.18,W06-0605,0,0.0219463,"on aware component into NLP systems. However, the recent successes of sequence-to-sequence (seq2seq) models in learning morphological patterns, as seen in multiple shared tasks that address the topic (Cotterell et al., 2016, 2017, 2018; McCarthy et al., 2019), have raised the question whether there is any advantage in developing handwritten grammars for performance reasons. This question has special relevance with regard to lowresource languages when there is a desire to quickly develop fundamental NLP resources such as a morphological analyzer and generator with minimal resource expenditure (Maxwell and Hughes, 2006). It is clear that there is a need for hand-written morphological grammars, even if neural network models approach the performance of carefully hand-crafted morphologies. Normative and prescriptive language models, such as those needed by language academies in many countries—e.g. RAE in Spain, Acad´emie Franc¸aise in France, or the Council of the Cherokee Nation in the U.S.— would need to rely on explicitly designed models for providing guidance in word inflection, spelling rules, and orthography if they were to be implemented computationally. Currently, neural models trained on examples provi"
2020.sigmorphon-1.18,W19-4226,1,0.835555,"+s sheep blarg+s Morphophonological FST cascade buses sheep blargs Figure 1: Basic FST grammar design used in this project which combines a lexicon-based model with a guesser to handle unseen lemmas. Introduction Hand-written grammars for modeling derivational and inflectional morphology have long been seen as the gold standard for incorporating a word inflection aware component into NLP systems. However, the recent successes of sequence-to-sequence (seq2seq) models in learning morphological patterns, as seen in multiple shared tasks that address the topic (Cotterell et al., 2016, 2017, 2018; McCarthy et al., 2019), have raised the question whether there is any advantage in developing handwritten grammars for performance reasons. This question has special relevance with regard to lowresource languages when there is a desire to quickly develop fundamental NLP resources such as a morphological analyzer and generator with minimal resource expenditure (Maxwell and Hughes, 2006). It is clear that there is a need for hand-written morphological grammars, even if neural network models approach the performance of carefully hand-crafted morphologies. Normative and prescriptive language models, such as those neede"
2020.sigmorphon-1.18,W18-4802,1,0.73675,"en grammars (1 ) and our non-neural learner (2 ). The non-neural model also participated in additional languages not shown here. Languages with accuracies on par with or exceeding the best shared task participants are shown in boldface. 166 network models for morphology have been proposed. Pirinen (2019) reports on a small experiment that compares an earlier SIGMORPHON shared task winner’s results to a Finnish handwritten morphological analyzer (Pirinen, 2015), with the seq2seq-based participant’s model yielding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon paradigm generalization work by Forsberg and Hulden (2016), which in turn is an extension of Hulden et al. (2014) and Ahlberg et al. (2015). An earlier non-neural model for paradigm generalization is found in Dreyer and Eisner (2011). 6.2 Human Resources We did not record the exact amounts of time spent on the project"
2020.sigmorphon-1.18,W15-1844,0,0.0157255,".4 100.0 57.1 100.0 62.4 93.6 91.3 88.3 99.3 99.0 100.0 89.1 93.8 70.3 81.1 88.5 Table 1: Results for the train, dev, and test sets with our handwritten grammars (1 ) and our non-neural learner (2 ). The non-neural model also participated in additional languages not shown here. Languages with accuracies on par with or exceeding the best shared task participants are shown in boldface. 166 network models for morphology have been proposed. Pirinen (2019) reports on a small experiment that compares an earlier SIGMORPHON shared task winner’s results to a Finnish handwritten morphological analyzer (Pirinen, 2015), with the seq2seq-based participant’s model yielding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon paradigm generalization work by Forsberg and Hulden (2016), which in turn is an extension of Hulden et al. (2014) and Ahlberg et al. (2015). An earlier non-neural"
2020.sigmorphon-1.18,W19-0309,0,0.0214376,"4 72.5 100.0 100.0 92.9 98.7 100.0 66.7 100.0 100.0 71.0 99.0 90.9 89.0 100.0 100.0 100.0 88.3 93.8 77.8 81.7 78.9 83.3 89.8 84.7 97.7 76.1 100.0 100.0 77.2 97.4 100.0 57.1 100.0 62.4 93.6 91.3 88.3 99.3 99.0 100.0 89.1 93.8 70.3 81.1 88.5 Table 1: Results for the train, dev, and test sets with our handwritten grammars (1 ) and our non-neural learner (2 ). The non-neural model also participated in additional languages not shown here. Languages with accuracies on par with or exceeding the best shared task participants are shown in boldface. 166 network models for morphology have been proposed. Pirinen (2019) reports on a small experiment that compares an earlier SIGMORPHON shared task winner’s results to a Finnish handwritten morphological analyzer (Pirinen, 2015), with the seq2seq-based participant’s model yielding higher precision than the rule-based FST analyzer. In another related experiment, Moeller et al. (2018) train neural seq2seq models from an existing hand-designed transducer acting as an oracle and note that the seq2seq model begins to converge to the FST with around 30,000 examples in a very complex language, Arapaho (arp). The non-neural inflection model (CU-7565-02) builds upon par"
2020.sigmorphon-1.18,N09-4005,0,0.00953331,"in the training data. 2 3 Approach All of the grammars were built with the foma finitestate tool (Hulden, 2009). Before grammar writing commenced, the participants were urged to spend roughly 1 hour in groups of 3 to quickly analyze all the languages in the development and surprise groups as follows: Finite-State Grammars Finite-state Transducer (FST) solutions have long been the foremost paradigm in which to develop linguistically informed large-scale morphological grammars (Koskenniemi, 1983; Beesley and Karttunen, 2003; Hulden, 2009). The availability of a variety of tools (Hulden (2009); Riley et al. (2009); Beesley (2012) inter alia) has also supported this mode of development, and by now hundreds of lan163 • Triage: the training sets for all languages in the shared task were rapidly analyzed for difficulty, and possible complex inflectional classes. Following this, a selection of languages were chosen by the participants to model. This was done once for the development languages, and through an additional round of triage for the surprise languages. • Each language was scored for difficulty based on familiarity with the writing system, paradigm size, complexity, and the apparent number of infle"
2020.sigmorphon-1.18,2021.eacl-main.163,1,0.842593,"Missing"
2020.sigmorphon-1.21,D19-1091,0,0.0401052,"for both the SIGMORPHON 2020 shared tasks on graphemeto-phoneme conversion (Gorman et al., 2020) and low-resource morphological inflection (Vylomova et al., 2020), delivering substantially better performance than other models.1 A common thread in research with characterlevel seq2seq has been that, for situations where few training examples are available, alternative strategies to produce more robust performance must be taken. For morphology tasks, this has included strategies such as instructing the model to copy input symbols to the output (Makarov et al., 2017; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019), which may require alignment of the input and output in the training. Another strategy is data augmentation (Bergmanis et al., 2017; Silfverberg et al., 2017), whereby some mechanism is employed to generate additional training examples from the few available ones. Pointer-generator networks (Vinyals et al., 2015), which facilitate copying of the input, have also been employed (Sharma et al., 2018). Perhaps since no low-resource g2p task has previously been organized, the performance of standard models of seq2seq in settings with limited training data have not been explored as much as in morph"
2020.sigmorphon-1.21,K17-2002,0,0.0652239,"Missing"
2020.sigmorphon-1.21,P16-1038,0,0.0412217,"Missing"
2020.sigmorphon-1.21,2020.sigmorphon-1.2,0,0.442518,"re of splicing. For each language and each original-size data set (100, 500, 3600) we generate 50,000 additional training examples from the original training data. To create the low-resource data training sets from the shared task training sets, we randomly select 100 (min), or 500 (med) examples from the original training data consisting of 3,600 examples. To determine the cutoff where the data-augmentation strategy stops paying dividends, we also create an augmented data set of 50,000 examples from the original data (we call the original task data the full) data set. 2.3 Following Wu et al. (2020), we use a relatively small transformer model (the Fairseq implementation; Ott et al. (2019)) with 4 encoder-decoder layers, and 4 attention heads. The embedding size is 256 and hidden layer size 1024. We use dropout (0.3) during training and a batch size of 400, a learning rate of 0.001. We train the models until no improvement is seen on the dev-set for 5 epochs. 3 Consonants and Vowels After estimating p(o|i) for each seen subsequence in the training data the resulting “reliable” pieces can be spliced together to augment the data set, by combining word-initial and word-final pieces. Since p"
2020.sigmorphon-1.21,K17-1030,1,0.791619,"rge number of usable pieces for each language, even in the lowest-resource setting of 100 training examples.2 Note that the number of actual potential augmented input-output mappings corresponds to roughly the square of the number of discovered reliable beginning and ending pairings. We generate augmented words completely at random from all the pieces available to us, except we limit the output sequence length to 15 by excluding longer sequences, and put an additional restriction on the juncture where the splices come together regarding consonants and vowels, discussed below. 2.2 algorithm in Hulden (2017) to divide the set of phonemes seen in the training data for a language into consonants and vowels. Table 1 shows a selection of French “words” generated by this complete process of aligning, determining useful pieces, and splicing them together while avoiding CC or VV sequences at the juncture of splicing. For each language and each original-size data set (100, 500, 3600) we generate 50,000 additional training examples from the original training data. To create the low-resource data training sets from the shared task training sets, we randomly select 100 (min), or 500 (med) examples from the"
2020.sigmorphon-1.21,C18-1008,0,0.0266764,"served as the baseline system for both the SIGMORPHON 2020 shared tasks on graphemeto-phoneme conversion (Gorman et al., 2020) and low-resource morphological inflection (Vylomova et al., 2020), delivering substantially better performance than other models.1 A common thread in research with characterlevel seq2seq has been that, for situations where few training examples are available, alternative strategies to produce more robust performance must be taken. For morphology tasks, this has included strategies such as instructing the model to copy input symbols to the output (Makarov et al., 2017; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019), which may require alignment of the input and output in the training. Another strategy is data augmentation (Bergmanis et al., 2017; Silfverberg et al., 2017), whereby some mechanism is employed to generate additional training examples from the few available ones. Pointer-generator networks (Vinyals et al., 2015), which facilitate copying of the input, have also been employed (Sharma et al., 2018). Perhaps since no low-resource g2p task has previously been organized, the performance of standard models of seq2seq in settings with limited training data have not"
2020.sigmorphon-1.21,N19-4009,0,0.031612,") we generate 50,000 additional training examples from the original training data. To create the low-resource data training sets from the shared task training sets, we randomly select 100 (min), or 500 (med) examples from the original training data consisting of 3,600 examples. To determine the cutoff where the data-augmentation strategy stops paying dividends, we also create an augmented data set of 50,000 examples from the original data (we call the original task data the full) data set. 2.3 Following Wu et al. (2020), we use a relatively small transformer model (the Fairseq implementation; Ott et al. (2019)) with 4 encoder-decoder layers, and 4 attention heads. The embedding size is 256 and hidden layer size 1024. We use dropout (0.3) during training and a batch size of 400, a learning rate of 0.001. We train the models until no improvement is seen on the dev-set for 5 epochs. 3 Consonants and Vowels After estimating p(o|i) for each seen subsequence in the training data the resulting “reliable” pieces can be spliced together to augment the data set, by combining word-initial and word-final pieces. Since phonological assimilations and coarticulations are very common in vowel-vowel and consonant-c"
2020.sigmorphon-1.21,K18-3001,1,0.901664,"Missing"
2020.sigmorphon-1.21,K17-2010,0,0.0280998,"elivering substantially better performance than other models.1 A common thread in research with characterlevel seq2seq has been that, for situations where few training examples are available, alternative strategies to produce more robust performance must be taken. For morphology tasks, this has included strategies such as instructing the model to copy input symbols to the output (Makarov et al., 2017; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019), which may require alignment of the input and output in the training. Another strategy is data augmentation (Bergmanis et al., 2017; Silfverberg et al., 2017), whereby some mechanism is employed to generate additional training examples from the few available ones. Pointer-generator networks (Vinyals et al., 2015), which facilitate copying of the input, have also been employed (Sharma et al., 2018). Perhaps since no low-resource g2p task has previously been organized, the performance of standard models of seq2seq in settings with limited training data have not been explored as much as in morphological inflection, where data augmentation has proven to be a successful strategy. 1 Our code is available at https://github.com/ LonelyRider-cs/sig_shared_t"
2020.sigmorphon-1.21,2021.eacl-main.163,1,0.919815,"Missing"
2020.sigmorphon-1.3,P03-1036,0,0.427615,"Missing"
2020.sigmorphon-1.3,2020.sigmorphon-1.11,0,0.0613575,"Missing"
2020.sigmorphon-1.3,N15-1107,1,0.866875,"riori (MAP) estimations to determine segmentation points, or minimum description length (MDL)-based approaches. However, they tended to make assumptions regarding how morphemes are combined, and worked best for purely concatenative morphology. Furthermore, these methods had no productive method of handling allomorphy—morphemic variance was simply treated as separate morphemes. tently word embeddings change between related word forms, with the goal of providing useful word embeddings for unseen words. Our task further differs from traditional paradigm completion (e.g., Dreyer and Eisner, 2011; Ahlberg et al., 2015) in that no seed paradigms are observed. Thus, no information is being provided regarding the paradigm size, inflectional features, or relationships between lemmas and inflected forms. Other recent work (Nicolai and Yarowsky, 2019; Nicolai et al., 2020) learned fine-grained morphosyntactic tools from the Bible, though they leveraged supervision projected from higher-resource languages (Yarowsky et al., 2001; T¨ackstr¨om et al., 2013). The task of unsupervised morphological paradigm completion concerns more than just segmentation: besides capturing how morphology is reflected in the word form,"
2020.sigmorphon-1.3,D11-1057,0,0.0701913,"(MLE) or maximum a posteriori (MAP) estimations to determine segmentation points, or minimum description length (MDL)-based approaches. However, they tended to make assumptions regarding how morphemes are combined, and worked best for purely concatenative morphology. Furthermore, these methods had no productive method of handling allomorphy—morphemic variance was simply treated as separate morphemes. tently word embeddings change between related word forms, with the goal of providing useful word embeddings for unseen words. Our task further differs from traditional paradigm completion (e.g., Dreyer and Eisner, 2011; Ahlberg et al., 2015) in that no seed paradigms are observed. Thus, no information is being provided regarding the paradigm size, inflectional features, or relationships between lemmas and inflected forms. Other recent work (Nicolai and Yarowsky, 2019; Nicolai et al., 2020) learned fine-grained morphosyntactic tools from the Bible, though they leveraged supervision projected from higher-resource languages (Yarowsky et al., 2001; T¨ackstr¨om et al., 2013). The task of unsupervised morphological paradigm completion concerns more than just segmentation: besides capturing how morphology is refle"
2020.sigmorphon-1.3,J01-2001,0,0.785887,"Missing"
2020.sigmorphon-1.3,P82-1020,0,0.795212,"Missing"
2020.sigmorphon-1.3,2020.acl-main.598,1,0.850896,"ne of the submitted systems was able to improve over the baseline on average over all 9 test languages. Only on 3 languages did a submitted system obtain the best results. This shows that unsupervised morphological paradigm completion is still largely unsolved. We present an analysis here, so that this shared task will ground further research on the topic. 1 guess1 guess2 lemma2 lemma2 guess guess guess lemma 1 1 3 guess 2 4 guess guess 1 guess 5 guess 2 guess 3 guess 4 6 lemman guess guess guess 3 5 guess 4 6 guess5 guess6 Figure 1: The task of unsupervised morphological paradigm completion (Jin et al., 2020) consists of generating complete inflectional paradigms for given lemmas, with the only additional available information being a corpus without annotations. ing have not yet been developed. We anticipate that such systems will be extremely useful, as they will open the possibility of rapid development of first-pass inflectional paradigms in a large set of languages. These can be utilized both in se for generation and as a starting point for elicitation (Sylak-Glassman et al., 2016), thus aiding the development of low-resource human language technologies (Christianson et al., 2018). In this pap"
2020.sigmorphon-1.3,K18-3001,1,0.0792627,"Missing"
2020.sigmorphon-1.3,P16-2090,1,0.901708,"Missing"
2020.sigmorphon-1.3,K17-2001,1,0.925404,"Missing"
2020.sigmorphon-1.3,D18-1363,1,0.921705,"Missing"
2020.sigmorphon-1.3,L18-1293,1,0.871732,"Missing"
2020.sigmorphon-1.3,D18-2012,0,0.0402026,"Missing"
2020.sigmorphon-1.3,P19-1172,1,0.84237,"native morphology. Furthermore, these methods had no productive method of handling allomorphy—morphemic variance was simply treated as separate morphemes. tently word embeddings change between related word forms, with the goal of providing useful word embeddings for unseen words. Our task further differs from traditional paradigm completion (e.g., Dreyer and Eisner, 2011; Ahlberg et al., 2015) in that no seed paradigms are observed. Thus, no information is being provided regarding the paradigm size, inflectional features, or relationships between lemmas and inflected forms. Other recent work (Nicolai and Yarowsky, 2019; Nicolai et al., 2020) learned fine-grained morphosyntactic tools from the Bible, though they leveraged supervision projected from higher-resource languages (Yarowsky et al., 2001; T¨ackstr¨om et al., 2013). The task of unsupervised morphological paradigm completion concerns more than just segmentation: besides capturing how morphology is reflected in the word form, it also requires correctly clustering transformations into paradigm slots and, finally, generation of unobserved forms. Past shared tasks. This task extends a tradition of SIGMORPHON shared tasks concentrating on inflectional morp"
2020.sigmorphon-1.3,W10-2211,0,0.0931197,"Missing"
2020.sigmorphon-1.3,P17-1099,0,0.0243433,"stom inflection system. The IMS–CUBoulder team relied on LSTM (Hochreiter and Schmidhuber, 1997) sequence-tosequence models for inflection. In IMS-CUB-1, the generation component is based on the architecture by Bahdanau et al. (2015), but with fewer parameters, as suggested by Kann and Sch¨utze (2016). This model – as well as all other inflection components used for systems in this category – receives the sequence of the lemma’s characters and the paradigm slot number as input and produces a sequence of output characters. Their second system, IMS-CUB-2, uses an LSTM pointer-generator network (See et al., 2017) instead. This architecture has originally been proposed for low-resource morphological inflection by Sharma et al. (2018). The NYU–CUBoulder team also substituted the baseline’s generation component. Their morphological inflection models are ensembles of dif5 5.1 Results and Analysis Results on Development Languages To encourage reproducibility, we first report the performance of all systems on the development languages in the upper part of Table 4. Although participants were not evaluated on these languages, the results provide insight and enable future researchers to benchmark their progres"
2020.sigmorphon-1.3,2020.sigmorphon-1.9,1,0.755428,"Missing"
2020.sigmorphon-1.3,D18-1314,0,0.0742252,"ieval component is a list of inflected forms with their lemmas, annotated with a paradigm slot number. The generation component receives this output and prepares the data to train an inflectional generator. First, identified inflections are divided into a training and development split, and missing paradigm slots are identified. The generator is trained on the discovered inflections, and new forms are predicted for each missing slot. We used two morphological inflection systems for the two variants of our baseline: the non-neural baseline from Cotterell et al. (2017) and the model proposed by Makarov and Clematide (2018). Both are highly suitable for the low-resource setting. 4.2 ferent combinations of transformer sequence-tosequence models (Vaswani et al., 2017) and pointergenerator transformers, a model they introduced for the task. NYU-CUB-1 is an ensemble of 6 pointergenerator transformers, while NYU-CUB-2 is an ensemble of 6 vanilla transformers. Their last system, NYU-CUB-3, is an ensemble of all 12 models. 4.3 Submitted Systems: Segment+Conquer The KU–CST team did not modify the baseline directly, but, nevertheless, was heavily inspired by it. Their system first employs a charactersegmentation algorith"
2020.sigmorphon-1.3,W19-4226,1,0.657183,"tions, requiring participants to generate an inflection solely utilizing a provided lemma and sentential cues. This task further imitated language learners, but extended beyond morphological learning to morphosyntactic incorporation. Furthermore, removing the requirement of an inflectional feature vector more closely approximated the generation step in our task. However, it was still supervised in that participants were provided with lemma–inflection pairs in context during training. We, in contrast, made no assumption of the existence of such pairs. Finally, the fourth iteration of the task (McCarthy et al., 2019) again concentrated on lesssupervised inflection. Cross-lingual training allowed low-resource inflectors to leverage information from high-resource languages, while a contextual analysis task flipped the previous year’s contextual task on its head—tagging a sentence with inflectional information. This process is very similar to the retrieval portion of our task. We extended this effort to not only identify the paradigm slot of particular word, but to combine learned information from each class to extend and complete existing paradigms. Furthermore, we lifted the requirement of named inflection"
2020.sigmorphon-1.3,P08-1084,0,0.108806,"Missing"
2020.sigmorphon-1.3,N15-1186,0,0.0841628,"previously unencountered word forms, after having studied thousands of other types. The second task (Cotterell et al., 2017) extended While Xu et al. (2018) did discover something similar to paradigms, those paradigms were a means to a segmentation end and the shape or size of the paradigms was not a subject of their research. Moon et al. (2009) similarly uses segmentation and clustering of affixes to group words into conflation sets, groups of morphologically related words, in an unsupervised way. Their work assumes prefixing and suffixing morphology. In a more task-driven line of research, Soricut and Och (2015) develop an approach to learn morphological transformation rules from observing how consis58 6.2 the first task from 10 to 52 languages and started to encourage the development of tools for the lowresource setting. While the first shared task approximated an adult learner with experience with thousands of word forms, low-resource inflection was closer to the language learner that has only studied a small number of inflections—however, it was closer to L2 learning than L1, as it still required training sets with lemma–inflection–slot triplets. The 2017 edition of the shared task also introduced"
2020.sigmorphon-1.3,2020.lrec-1.352,1,0.595113,"rms for all lemmas in both the predictions and the ground truth before evaluating. Provided Resources We provided data for 5 development and 9 test languages. The development languages were available for system development and hyperparameter tuning, while the test languages were released shortly before the shared task deadline. For the test languages, no ground truth data was available before system submission. This setup emulated a realworld scenario with the goal to create a system for languages about which we have no information. For the raw text corpora, we leveraged the JHU Bible Corpus (McCarthy et al., 2020). This resource covers 1600 languages, which will enable future work to quickly produce systems for a large set of languages. Additionally, using the Bible allowed for a fair comparison of models across languages without potential confounds such as domain mismatch. 7 of the languages have only the New Testament available (approximately 8k sentences), and 7 have both the New and Old Testaments (approximately 31k sentences). All morphological information was taken from UniMorph (Sylak-Glassman et al., 2015; Kirov et al., 2018), a resource which contains paradigms for more than 100 languages. How"
2020.sigmorphon-1.3,L16-1497,0,0.0222648,"6 lemman guess guess guess 3 5 guess 4 6 guess5 guess6 Figure 1: The task of unsupervised morphological paradigm completion (Jin et al., 2020) consists of generating complete inflectional paradigms for given lemmas, with the only additional available information being a corpus without annotations. ing have not yet been developed. We anticipate that such systems will be extremely useful, as they will open the possibility of rapid development of first-pass inflectional paradigms in a large set of languages. These can be utilized both in se for generation and as a starting point for elicitation (Sylak-Glassman et al., 2016), thus aiding the development of low-resource human language technologies (Christianson et al., 2018). In this paper, we present the SIGMORPHON 2020 shared task on unsupervised morphological paradigm completion (SIGMORPHON 2020 Task 2). We asked participants to produce systems that can learn to inflect in an unsupervised fashion: given a small corpus (the Bible) together with a list of lemmas for each language, systems for the shared task should output all corresponding inflected forms. In their output, systems had to mark which forms expressed the same morphosyntactic features, e.g., demonstr"
2020.sigmorphon-1.3,D09-1070,0,0.0920434,"Missing"
2020.sigmorphon-1.3,P15-2111,0,0.0214204,"bout which we have no information. For the raw text corpora, we leveraged the JHU Bible Corpus (McCarthy et al., 2020). This resource covers 1600 languages, which will enable future work to quickly produce systems for a large set of languages. Additionally, using the Bible allowed for a fair comparison of models across languages without potential confounds such as domain mismatch. 7 of the languages have only the New Testament available (approximately 8k sentences), and 7 have both the New and Old Testaments (approximately 31k sentences). All morphological information was taken from UniMorph (Sylak-Glassman et al., 2015; Kirov et al., 2018), a resource which contains paradigms for more than 100 languages. However, this information was only accessible to the participants for the development languages. UniMorph paradigms were further used internally for evaluation on the test languages—this data was then released after the conclusion of the shared task. Example. Assume our gold standard is (1) (the complete, 5-slot English paradigms for the verbs walk and listen) and a system outputs the following, including an error in the fourth row: 3.2 Languages During the development phase of the shared task, we released"
2020.sigmorphon-1.3,Q13-1001,0,0.0712336,"Missing"
2020.sigmorphon-1.3,C18-1005,0,0.0169383,"rms. Past shared tasks. This task extends a tradition of SIGMORPHON shared tasks concentrating on inflectional morphology. The first such task (Cotterell et al., 2016) encouraged participants to create inflectional tools in a typologically diverse group of 10 languages. The task was fully-supervised, requiring systems to learn inflectional morphology from a large annotated database. This task is similar to human learners needing to generate inflections of previously unencountered word forms, after having studied thousands of other types. The second task (Cotterell et al., 2017) extended While Xu et al. (2018) did discover something similar to paradigms, those paradigms were a means to a segmentation end and the shape or size of the paradigms was not a subject of their research. Moon et al. (2009) similarly uses segmentation and clustering of affixes to group words into conflation sets, groups of morphologically related words, in an unsupervised way. Their work assumes prefixing and suffixing morphology. In a more task-driven line of research, Soricut and Och (2015) develop an approach to learn morphological transformation rules from observing how consis58 6.2 the first task from 10 to 52 languages"
2020.sigmorphon-1.3,H01-1035,0,0.0415472,"between related word forms, with the goal of providing useful word embeddings for unseen words. Our task further differs from traditional paradigm completion (e.g., Dreyer and Eisner, 2011; Ahlberg et al., 2015) in that no seed paradigms are observed. Thus, no information is being provided regarding the paradigm size, inflectional features, or relationships between lemmas and inflected forms. Other recent work (Nicolai and Yarowsky, 2019; Nicolai et al., 2020) learned fine-grained morphosyntactic tools from the Bible, though they leveraged supervision projected from higher-resource languages (Yarowsky et al., 2001; T¨ackstr¨om et al., 2013). The task of unsupervised morphological paradigm completion concerns more than just segmentation: besides capturing how morphology is reflected in the word form, it also requires correctly clustering transformations into paradigm slots and, finally, generation of unobserved forms. Past shared tasks. This task extends a tradition of SIGMORPHON shared tasks concentrating on inflectional morphology. The first such task (Cotterell et al., 2016) encouraged participants to create inflectional tools in a typologically diverse group of 10 languages. The task was fully-super"
2021.acl-long.78,D19-1091,0,0.23777,"Missing"
2021.acl-long.78,K18-3001,1,0.925788,"Missing"
2021.acl-long.78,W02-0603,0,0.237472,"mon lexical categories as can be seen by comparing to the Leipzig Glossing Rules (Institute, 2008) which also has recommended tags for less common categories. Many NLP models have been applied to segmentation and glossing of low-resource languages but they often tackle just one of the two tasks, e.g. segmentation only (Ruokolainen et al., 2014; Wang et al., 2016; Kann et al., 2018; Mager et al., 2020; Sorokin, 2019; Eskander et al., 2020a). Automatic morpheme segmentation was introduced by Harris (1970) and much earlier segmentation research implemented unsupervised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of"
2021.acl-long.78,N13-1138,0,0.0173521,"make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of interlinearized texts such as translation and POS tags. Computational approaches to morphological inflection or reinflection have been developed by Durrett and DeNero (2013); Nicolai et al. (2015); Liu and Mao (2016); Cotterell et al. (2017); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017), etc. Some of the work was developed as part of the SIGMORPHON Shared Tasks.1 Our work partly replicates the CoNLL-SIGMORPHON reinflection shared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov an"
2021.acl-long.78,2020.lrec-1.879,0,0.0636823,"Missing"
2021.acl-long.78,2020.emnlp-main.391,0,0.0552243,"ion has not been methodically tested. Introduction Parts of speech (POS), also known as word classes or lexical categories, communicate information about a word, its morphological structure and inflectional paradigm, and its potential grammatical role in a clause. POS tagging is a well-studied problem in NLP. It is one of the first tasks undertaken for a new data set and a POS tagger is often one of the first NLP resources built for lowresource languages (Yarowsky and Ngai, 2001; Cox, 2010; De Pauw, 2012; Baldridge and Garrette, 2013; Duong, 2017; Anastasopoulos, 2019; Millour and Fort, 2019; Eskander et al., 2020b). Although this priority on early POS tagging may be simply due to the relative ease of building a POS tagger, it seems to reflect an assumption that POS This paper examines the impact of POS tags on morphological learning, an important area for low-resource languages, many of which are more morphologically complex than English, Mandarin, or other large-resource languages. Morphological learning can help reduce the out-of-vocabulary problem in morphologically complex languages, especially in low-resource settings. Morphological learning also holds high priority in documentary and descriptive"
2021.acl-long.78,J01-2001,0,0.194067,"nventions for common lexical categories as can be seen by comparing to the Leipzig Glossing Rules (Institute, 2008) which also has recommended tags for less common categories. Many NLP models have been applied to segmentation and glossing of low-resource languages but they often tackle just one of the two tasks, e.g. segmentation only (Ruokolainen et al., 2014; Wang et al., 2016; Kann et al., 2018; Mager et al., 2020; Sorokin, 2019; Eskander et al., 2020a). Automatic morpheme segmentation was introduced by Harris (1970) and much earlier segmentation research implemented unsupervised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use in"
2021.acl-long.78,W17-0105,0,0.0188176,"cept for the presence/lack of POS tags. We chose morpheme segmentation and glossing because it is a high-priority and early step in documenting and describing new languages. Segmenting words into morphemes and glossing (strictly translating) them is usually the first task undertaken after new data has been transcribed. Therefore, it is important to study how to provide and improve automated assistance for field linguists. Automatic systems could greatly benefit the analysis of endangered languages and combat the “annotation bottleneck” caused by current manual methods (Simons and Lewis, 2013; Holton et al., 2017; Seifart et al., 2018). Although adding POS tagging as a high-priority task would add to that bottleneck, if the tags have a significant and positive impact on automating segmentation and glossing, then linguists may receive long-term benefits from the addition to their workflow. Therefore, we explore the impact of POS tags at very low-resource settings and the impact of POS tags when a new field project takes time to tag some, but not all, tokens. This is also why we chose noisy field corpora, rather than published, polished corpora which are not like the data that linguists typically work w"
2021.acl-long.78,N18-1005,0,0.0377886,"Missing"
2021.acl-long.78,P16-2090,0,0.0291507,"Missing"
2021.acl-long.78,W17-4009,1,0.82866,"the morphological re-inflection task because it is easy to reproduce and to compare with the original SIGMORPHON shared task. Eliciting and analyzing a language’s inflectional patterns is a recommended next step after morpheme segmentation and glossing (Bird and Chiang, 2012). The inflectional pattern of a lexeme or a lexical category is also known as a morphological paradigm. Learning morphological paradigms can be viewed in terms of filling in, or generating, the missing forms of a paradigm table by generalizing over inflectional patterns (Ackerman et al., 2009; Ahlberg et al., 2014, 2015; Liu and Hulden, 2017; Malouf, 2017; Silfverberg et al., 2018; Silfverberg and Hulden, 2018). The experiments in this section partly replicates the CoNLL-SIGMORPHON 2018 shared task 1 of morphological reinflection. Reinflection consists of generating unknown inflected forms, given a related inflected form f (`, ~tγ1 ) and a target morphological feature vector ~tγ2 . Thus, it corresponds to learning the mapping f : Σ∗ × T → Σ∗ . The goal is then to produce the inflected form f (`, ~tγ2 ). An inflected form is generated when the model is given a related inflected form and the target morphological features (which are"
2021.acl-long.78,2020.coling-main.257,1,0.661214,"hared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019; Wu and Cotterell, 2019; Liu, 2021). The Transformer (Vaswani et al., 2017a) is the model architecture which produces the current state-of-the-art performance on this task (Vylomova et al., 2020; Wu et al., 2020; Liu and Hulden, 2020b,a). Therefore, we use the Transformer for all the experiments in this paper. This paper is an expansion of a section in Moeller et al. (2020). The experimental setup and SIGMORPHON languages are the same as that work, but it does not look at what happens when POS tags are available in the field data. We expanded the re-inflection task to field corpora. we also ran the SIGMORPHON experiments 5 times instead of one time. The addition of the segmentation and glossing was inspired by Moeller and Hulden (2021). 3 Data We use published data in ten languages and unpublished data in five low-resourc"
2021.acl-long.78,2020.sigmorphon-1.17,1,0.741964,"hared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019; Wu and Cotterell, 2019; Liu, 2021). The Transformer (Vaswani et al., 2017a) is the model architecture which produces the current state-of-the-art performance on this task (Vylomova et al., 2020; Wu et al., 2020; Liu and Hulden, 2020b,a). Therefore, we use the Transformer for all the experiments in this paper. This paper is an expansion of a section in Moeller et al. (2020). The experimental setup and SIGMORPHON languages are the same as that work, but it does not look at what happens when POS tags are available in the field data. We expanded the re-inflection task to field corpora. we also ran the SIGMORPHON experiments 5 times instead of one time. The addition of the segmentation and glossing was inspired by Moeller and Hulden (2021). 3 Data We use published data in ten languages and unpublished data in five low-resourc"
2021.acl-long.78,P17-1182,0,0.0418455,"Missing"
2021.acl-long.78,W16-2006,1,0.821199,"d into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of interlinearized texts such as translation and POS tags. Computational approaches to morphological inflection or reinflection have been developed by Durrett and DeNero (2013); Nicolai et al. (2015); Liu and Mao (2016); Cotterell et al. (2017); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017), etc. Some of the work was developed as part of the SIGMORPHON Shared Tasks.1 Our work partly replicates the CoNLL-SIGMORPHON reinflection shared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anastasopoulos and Neubi"
2021.acl-long.78,2020.scil-1.42,0,0.0230456,"they often tackle just one of the two tasks, e.g. segmentation only (Ruokolainen et al., 2014; Wang et al., 2016; Kann et al., 2018; Mager et al., 2020; Sorokin, 2019; Eskander et al., 2020a). Automatic morpheme segmentation was introduced by Harris (1970) and much earlier segmentation research implemented unsupervised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of interlinearized texts such as translation and POS tags. Computational approaches to morphological inflection or reinflection have been developed by Durrett and DeNero (2013); Nicolai et al. (2015); Liu and Mao (2016); Cotterell et al. (2017); Kann an"
2021.acl-long.78,R19-1090,0,0.013422,"are aware, this assumption has not been methodically tested. Introduction Parts of speech (POS), also known as word classes or lexical categories, communicate information about a word, its morphological structure and inflectional paradigm, and its potential grammatical role in a clause. POS tagging is a well-studied problem in NLP. It is one of the first tasks undertaken for a new data set and a POS tagger is often one of the first NLP resources built for lowresource languages (Yarowsky and Ngai, 2001; Cox, 2010; De Pauw, 2012; Baldridge and Garrette, 2013; Duong, 2017; Anastasopoulos, 2019; Millour and Fort, 2019; Eskander et al., 2020b). Although this priority on early POS tagging may be simply due to the relative ease of building a POS tagger, it seems to reflect an assumption that POS This paper examines the impact of POS tags on morphological learning, an important area for low-resource languages, many of which are more morphologically complex than English, Mandarin, or other large-resource languages. Morphological learning can help reduce the out-of-vocabulary problem in morphologically complex languages, especially in low-resource settings. Morphological learning also holds high priority in docu"
2021.acl-long.78,petrov-etal-2012-universal,0,0.073525,"Missing"
2021.acl-long.78,N09-1024,0,0.0464355,"s can be seen by comparing to the Leipzig Glossing Rules (Institute, 2008) which also has recommended tags for less common categories. Many NLP models have been applied to segmentation and glossing of low-resource languages but they often tackle just one of the two tasks, e.g. segmentation only (Ruokolainen et al., 2014; Wang et al., 2016; Kann et al., 2018; Mager et al., 2020; Sorokin, 2019; Eskander et al., 2020a). Automatic morpheme segmentation was introduced by Harris (1970) and much earlier segmentation research implemented unsupervised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of interlinearized text"
2021.acl-long.78,2021.computel-1.11,1,0.704691,"e current state-of-the-art performance on this task (Vylomova et al., 2020; Wu et al., 2020; Liu and Hulden, 2020b,a). Therefore, we use the Transformer for all the experiments in this paper. This paper is an expansion of a section in Moeller et al. (2020). The experimental setup and SIGMORPHON languages are the same as that work, but it does not look at what happens when POS tags are available in the field data. We expanded the re-inflection task to field corpora. we also ran the SIGMORPHON experiments 5 times instead of one time. The addition of the segmentation and glossing was inspired by Moeller and Hulden (2021). 3 Data We use published data in ten languages and unpublished data in five low-resource languages. The published and unpublished data is used for the morLanguage Adyghe Arabic Basque Finnish German Persian Russian Spanish Swahili Turkish POS N, ADJ N, V, ADJ V N, V, ADJ N, ADJ V N, V, ADJ N, V N, V, ADJ N, V, ADJ Table 1: SIGMORPHON languages and the lexical categories found in the data. phological reinflection but only the unpublished data for segmentation and glossing. 3.1 SIGMORPHON Data For the morphological reinflection task we use datasets that were released for the CoNLLSIGMORPHON 201"
2021.acl-long.78,2020.emnlp-main.424,1,0.750796,"logical (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019; Wu and Cotterell, 2019; Liu, 2021). The Transformer (Vaswani et al., 2017a) is the model architecture which produces the current state-of-the-art performance on this task (Vylomova et al., 2020; Wu et al., 2020; Liu and Hulden, 2020b,a). Therefore, we use the Transformer for all the experiments in this paper. This paper is an expansion of a section in Moeller et al. (2020). The experimental setup and SIGMORPHON languages are the same as that work, but it does not look at what happens when POS tags are available in the field data. We expanded the re-inflection task to field corpora. we also ran the SIGMORPHON experiments 5 times instead of one time. The addition of the segmentation and glossing was inspired by Moeller and Hulden (2021). 3 Data We use published data in ten languages and unpublished data in five low-resource languages. The published and unpublished data is used for the morLanguage Adyghe Arabic Basque Finnish German Persian Russian Spanish Swahili"
2021.acl-long.78,N15-1093,0,0.0228262,"ata is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of interlinearized texts such as translation and POS tags. Computational approaches to morphological inflection or reinflection have been developed by Durrett and DeNero (2013); Nicolai et al. (2015); Liu and Mao (2016); Cotterell et al. (2017); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017), etc. Some of the work was developed as part of the SIGMORPHON Shared Tasks.1 Our work partly replicates the CoNLL-SIGMORPHON reinflection shared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anas"
2021.acl-long.78,E14-4017,0,0.0224592,"8)) as well as tag sets. The most popular tag set for English was developed by the Penn Treebank Project (Taylor et al., 2003). A universal POS tag set was proposed by Petrov et al. (2012) and has been widely adopted. It closely follows traditional linguistic conventions for common lexical categories as can be seen by comparing to the Leipzig Glossing Rules (Institute, 2008) which also has recommended tags for less common categories. Many NLP models have been applied to segmentation and glossing of low-resource languages but they often tackle just one of the two tasks, e.g. segmentation only (Ruokolainen et al., 2014; Wang et al., 2016; Kann et al., 2018; Mager et al., 2020; Sorokin, 2019; Eskander et al., 2020a). Automatic morpheme segmentation was introduced by Harris (1970) and much earlier segmentation research implemented unsupervised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line f"
2021.acl-long.78,W15-3710,0,0.0229038,"ised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The low-resource language data came from interlinearized data that was polished for publication. McMillan-Major (2020) and some other experiments such as Samardzic et al. (2015) use information from lines of interlinearized texts such as translation and POS tags. Computational approaches to morphological inflection or reinflection have been developed by Durrett and DeNero (2013); Nicolai et al. (2015); Liu and Mao (2016); Cotterell et al. (2017); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017), etc. Some of the work was developed as part of the SIGMORPHON Shared Tasks.1 Our work partly replicates the CoNLL-SIGMORPHON reinflection shared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling"
2021.acl-long.78,C18-1137,1,0.895449,"Missing"
2021.acl-long.78,K17-2010,1,0.872217,"flection have been developed by Durrett and DeNero (2013); Nicolai et al. (2015); Liu and Mao (2016); Cotterell et al. (2017); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017), etc. Some of the work was developed as part of the SIGMORPHON Shared Tasks.1 Our work partly replicates the CoNLL-SIGMORPHON reinflection shared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019; Wu and Cotterell, 2019; Liu, 2021). The Transformer (Vaswani et al., 2017a) is the model architecture which produces the current state-of-the-art performance on this task (Vylomova et al., 2020; Wu et al., 2020; Liu and Hulden, 2020b,a). Therefore, we use the Transformer for all the experiments in this paper. This paper is an expansion of a section in Moeller et al. (2020). The experimental setup and SIGMORPHON languages are the same as that work, but it does not look at what happens when POS tags are availabl"
2021.acl-long.78,W19-4218,0,0.0160627,"enn Treebank Project (Taylor et al., 2003). A universal POS tag set was proposed by Petrov et al. (2012) and has been widely adopted. It closely follows traditional linguistic conventions for common lexical categories as can be seen by comparing to the Leipzig Glossing Rules (Institute, 2008) which also has recommended tags for less common categories. Many NLP models have been applied to segmentation and glossing of low-resource languages but they often tackle just one of the two tasks, e.g. segmentation only (Ruokolainen et al., 2014; Wang et al., 2016; Kann et al., 2018; Mager et al., 2020; Sorokin, 2019; Eskander et al., 2020a). Automatic morpheme segmentation was introduced by Harris (1970) and much earlier segmentation research implemented unsupervised learning (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). Published linguistic descriptive data is used 967 as training data usually after some preprocessing. Glossing-only experiments make the assumption that data is already segmented into morphemes. For example, McMillan-Major (2020) trained a conditional random field (CRF) model to produce a gloss line for several high-resource languages and three low-resource languages. The"
2021.acl-long.78,P19-1148,0,0.0184582,"ll et al. (2017); Kann and Sch¨utze (2016); Aharoni and Goldberg (2017), etc. Some of the work was developed as part of the SIGMORPHON Shared Tasks.1 Our work partly replicates the CoNLL-SIGMORPHON reinflection shared tasks (Cotterell et al., 2016, 2017, 2018a). Sequence-to-sequence neural network models have been very successful at handling the morphological (re)inflection task, even in low-resource conditions with model improvement designed to tackle the situation (Kann et al., 2017; Silfverberg et al., 2017; Sharma et al., 2018; Makarov and Clematide, 2018; Anastasopoulos and Neubig, 2019; Wu and Cotterell, 2019; Liu, 2021). The Transformer (Vaswani et al., 2017a) is the model architecture which produces the current state-of-the-art performance on this task (Vylomova et al., 2020; Wu et al., 2020; Liu and Hulden, 2020b,a). Therefore, we use the Transformer for all the experiments in this paper. This paper is an expansion of a section in Moeller et al. (2020). The experimental setup and SIGMORPHON languages are the same as that work, but it does not look at what happens when POS tags are available in the field data. We expanded the re-inflection task to field corpora. we also ran the SIGMORPHON experi"
2021.acl-long.78,2021.eacl-main.163,1,0.84876,"Missing"
2021.acl-long.78,N01-1026,0,0.0172486,"at POS-tags have little and irregular impact. tags simplify or improve other NLP tasks (Krauwer, 2003). As far as we are aware, this assumption has not been methodically tested. Introduction Parts of speech (POS), also known as word classes or lexical categories, communicate information about a word, its morphological structure and inflectional paradigm, and its potential grammatical role in a clause. POS tagging is a well-studied problem in NLP. It is one of the first tasks undertaken for a new data set and a POS tagger is often one of the first NLP resources built for lowresource languages (Yarowsky and Ngai, 2001; Cox, 2010; De Pauw, 2012; Baldridge and Garrette, 2013; Duong, 2017; Anastasopoulos, 2019; Millour and Fort, 2019; Eskander et al., 2020b). Although this priority on early POS tagging may be simply due to the relative ease of building a POS tagger, it seems to reflect an assumption that POS This paper examines the impact of POS tags on morphological learning, an important area for low-resource languages, many of which are more morphologically complex than English, Mandarin, or other large-resource languages. Morphological learning can help reduce the out-of-vocabulary problem in morphologica"
2021.computel-1.11,R19-1007,0,0.0128893,"re described in § 4. The experiments are described in § 5 and results are presented in § 6 and analyzed in § 7. 2 Many NLP models have been applied to segmentation and glossing of low-resource languages. Automatic morpheme segmentation was introduced by Harris (1970) and much segmentation research since then has implemented this in an unsupervised fashion (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). This is probably motivated by the difficulty of finding high quality amounts of segmented data that is needed for supervised learning. A recent supervised segmentation experiment (Ansari et al., 2019) had to first manually segment a Persian corpus before being able to conduct the experiment. NLP experiments with low-resource languages often treat segmentation and glossing as separate tasks. Their approach seems to assume that the two tasks are performed sequentially and that it is reasonable to expect morpheme segments to be available before glosses. However, our field experiences indicates that it is not uncommon for linguists to segment a morpheme and gloss it immediately. Glossing-only experiments make the assumption that the data is already segmented into morphemes or that it does not"
2021.computel-1.11,auer-etal-2010-elan,0,0.0322539,"pheme breaks in the orthographic representation. The two segmentation strategies are compared in (1) where the first two surface letters of each word in (1a) are represented by identical canonical segments in (1b). Since NLP almost always deals with orthographic representations, its systems are trained to perform surface segmentation almost exclusively. In practice, both strategies are encountered during language documentation and description, the initial strategy depending in part on software tools. For example, the older, but still popular, Toolbox1 allows surface segmentation whereas ELAN (Auer et al., 2010) supports both but as separate tasks, while FLEx (Baines, 2018) requires surface segmentation but facilitates simultaneous canonical segmentation. It might seem reasonable that linguists who want to integrate automated assistance would adjust their strategy to match NLP expectations. But without testing, are we sure that NLP systems perform better at surface or at canonical segmentation? (1) a. il-legal in-capable im-mature b. in-legal in-capable in-mature c. compare those results between a joint and sequential approach to segmentation and glossing and between a surface and canonical strategy"
2021.computel-1.11,K15-1017,0,0.0176303,"pable NEG -mature This paper describes experiments that test results of Transformer models (Vaswani et al., 2017) trained on segmented and glossed data and then 1 Related Work https://software.sil.org/toolbox/ 87 Language Alas Lamkang Lezgi Manipuri Natügu training on different types of information and is based on the intuition that one type of linguistic knowledge (e.g. syntax) can improve results in another domain (e.g. morphology) (Goldsmith et al., 2017). Joint learning of segmentation and glossing, or labeled segmentation, is less common but has been successful in low-resource languages (Cotterell et al., 2015; Moeller and Hulden, 2018), usually with non-neural models. The authors’ previous work on Lezgi (Moeller and Hulden, 2018) used the same corpus as the current work and compared sequential vs. joint models as well as feature-based vs. deep learning models. The reported F1 -scores were nearly .9. However, a direct comparison between the two studies cannot be made because the previous work only segmented and glossed affixes while the current work includes root and affixes. The segmentation strategies that an NLP project implements may depend on available data or the type of learning model employ"
2021.computel-1.11,W02-0603,0,0.64483,"etween a joint and sequential approach to segmentation and glossing and between a surface and canonical strategy to segmentation. After a review of related literature in § 2, § 3 introduces the data used by the models that are described in § 4. The experiments are described in § 5 and results are presented in § 6 and analyzed in § 7. 2 Many NLP models have been applied to segmentation and glossing of low-resource languages. Automatic morpheme segmentation was introduced by Harris (1970) and much segmentation research since then has implemented this in an unsupervised fashion (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). This is probably motivated by the difficulty of finding high quality amounts of segmented data that is needed for supervised learning. A recent supervised segmentation experiment (Ansari et al., 2019) had to first manually segment a Persian corpus before being able to conduct the experiment. NLP experiments with low-resource languages often treat segmentation and glossing as separate tasks. Their approach seems to assume that the two tasks are performed sequentially and that it is reasonable to expect morpheme segments to be available before glosses. However, our field ex"
2021.computel-1.11,N09-1024,0,0.411151,"ntial approach to segmentation and glossing and between a surface and canonical strategy to segmentation. After a review of related literature in § 2, § 3 introduces the data used by the models that are described in § 4. The experiments are described in § 5 and results are presented in § 6 and analyzed in § 7. 2 Many NLP models have been applied to segmentation and glossing of low-resource languages. Automatic morpheme segmentation was introduced by Harris (1970) and much segmentation research since then has implemented this in an unsupervised fashion (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). This is probably motivated by the difficulty of finding high quality amounts of segmented data that is needed for supervised learning. A recent supervised segmentation experiment (Ansari et al., 2019) had to first manually segment a Persian corpus before being able to conduct the experiment. NLP experiments with low-resource languages often treat segmentation and glossing as separate tasks. Their approach seems to assume that the two tasks are performed sequentially and that it is reasonable to expect morpheme segments to be available before glosses. However, our field experiences indicates"
2021.computel-1.11,W15-3710,0,0.295072,"ssing-only experiments make the assumption that the data is already segmented into morphemes or that it does not need to be segmented. McMillan-Major (2020) trained conditional random field (CRF) systems to produce a gloss line for several high-resource languages and three lowresource languages. The systems incorporated predictions made directly from the segmented line and predictions made with information from the free translation line that was enriched with INTENT (Georgi, 2016). The low-resource language data came from field projects, as does the data in this paper. Both McMillan-Major and Samardzic et al. (2015) used information from other lines of interlinearized texts such as translation and partof-speech tags, whereas our work assumes the texts have not yet been annotated with any other information. In general, joint learning is characterized by NEG -legal NEG -capable NEG -mature This paper describes experiments that test results of Transformer models (Vaswani et al., 2017) trained on segmented and glossed data and then 1 Related Work https://software.sil.org/toolbox/ 87 Language Alas Lamkang Lezgi Manipuri Natügu training on different types of information and is based on the intuition that one t"
2021.computel-1.11,J01-2001,0,0.113947,"e those results between a joint and sequential approach to segmentation and glossing and between a surface and canonical strategy to segmentation. After a review of related literature in § 2, § 3 introduces the data used by the models that are described in § 4. The experiments are described in § 5 and results are presented in § 6 and analyzed in § 7. 2 Many NLP models have been applied to segmentation and glossing of low-resource languages. Automatic morpheme segmentation was introduced by Harris (1970) and much segmentation research since then has implemented this in an unsupervised fashion (Goldsmith, 2001; Creutz and Lagus, 2002; Poon et al., 2009). This is probably motivated by the difficulty of finding high quality amounts of segmented data that is needed for supervised learning. A recent supervised segmentation experiment (Ansari et al., 2019) had to first manually segment a Persian corpus before being able to conduct the experiment. NLP experiments with low-resource languages often treat segmentation and glossing as separate tasks. Their approach seems to assume that the two tasks are performed sequentially and that it is reasonable to expect morpheme segments to be available before glosse"
2021.computel-1.11,W18-1813,0,0.0547213,"Missing"
2021.computel-1.11,E14-2006,0,0.0239233,"joint or sequential segmentation and glossing is a better approach to interlinearization when integrating automated assistance. Joint segmentation assumes that segmented data without glosses is unlikely because identifying a morpheme usually means there has already been an identification of the morpheme’s meaning. Joint segmentation requires the model to learn the morpheme boundary and gloss simultaneously for each segment. The sequential system–glossing after segmenting the whole text—assumes that segmentation is easier to do by hand or that unsupervised segmentation tools such as Morfessor (Smit et al., 2014) are available for low-resource languages. For joint learning, the input is a character-level representation of a word, shown in (2a). Each character is treated as as separate symbol by the model. The output is a sequence of labels, one label per morpheme, shown in (2b). The label combines the morpheme’s shape and gloss. The combination allows the system to perform segmentation and glossing simultaneously. 5 (2) Segmentation and Glossing Experiments a. IN: b. OUT: The experiments assume access to field data that has only been segmented and glossed. Therefore, no other information was leveraged"
2021.computel-1.11,W16-2006,0,0.313838,"held-out data. For each experiment, a ten-fold cross validation was run. 5.1 4 Models Joint versus Sequential System All tasks are treated as a problem of converting an input sequence of characters x = (x1 , . . . , xn ) to an output sequence of labels y = (y1 , . . . , yn ). The output sequence of labels indicate the (canonical or surface) morpheme and/or the morpheme’s gloss. Since Conditional Random Fields (CRF) (Lafferty et al., 2001), the state-of-art non-neural sequence labeling model, has not performed as well as neural models on low-resource sequenceto-sequence tasks since about 2016 (Liu and Mao, 2016), we selected the Transformer (Vaswani et al., 2017) as our model. The Transformer is a supervised deep learning system that has achieved promising results for NLP in low-resource languages (Abbott and Martinus, 2018; Martinus and Abbott, 2019). It is a stateless encoderdecoder model that uses additional attention layers to boost speed and performance. We used the Fairseq (Ott et al., 2019) implementation with the modifications and code described by Wu et al. (2020) which have been successful in lowresource character-level morphological tasks.7 The first experiment tested whether joint or sequ"
2021.computel-1.11,2020.scil-1.42,0,0.103529,"segment a Persian corpus before being able to conduct the experiment. NLP experiments with low-resource languages often treat segmentation and glossing as separate tasks. Their approach seems to assume that the two tasks are performed sequentially and that it is reasonable to expect morpheme segments to be available before glosses. However, our field experiences indicates that it is not uncommon for linguists to segment a morpheme and gloss it immediately. Glossing-only experiments make the assumption that the data is already segmented into morphemes or that it does not need to be segmented. McMillan-Major (2020) trained conditional random field (CRF) systems to produce a gloss line for several high-resource languages and three lowresource languages. The systems incorporated predictions made directly from the segmented line and predictions made with information from the free translation line that was enriched with INTENT (Georgi, 2016). The low-resource language data came from field projects, as does the data in this paper. Both McMillan-Major and Samardzic et al. (2015) used information from other lines of interlinearized texts such as translation and partof-speech tags, whereas our work assumes the"
2021.computel-1.11,W18-4809,1,0.780612,"aper describes experiments that test results of Transformer models (Vaswani et al., 2017) trained on segmented and glossed data and then 1 Related Work https://software.sil.org/toolbox/ 87 Language Alas Lamkang Lezgi Manipuri Natügu training on different types of information and is based on the intuition that one type of linguistic knowledge (e.g. syntax) can improve results in another domain (e.g. morphology) (Goldsmith et al., 2017). Joint learning of segmentation and glossing, or labeled segmentation, is less common but has been successful in low-resource languages (Cotterell et al., 2015; Moeller and Hulden, 2018), usually with non-neural models. The authors’ previous work on Lezgi (Moeller and Hulden, 2018) used the same corpus as the current work and compared sequential vs. joint models as well as feature-based vs. deep learning models. The reported F1 -scores were nearly .9. However, a direct comparison between the two studies cannot be made because the previous work only segmented and glossed affixes while the current work includes root and affixes. The segmentation strategies that an NLP project implements may depend on available data or the type of learning model employed. Unsupervised learning o"
2021.computel-1.11,2021.eacl-main.163,1,0.76796,"Missing"
2021.computel-1.11,N19-4009,0,0.0242584,"onal Random Fields (CRF) (Lafferty et al., 2001), the state-of-art non-neural sequence labeling model, has not performed as well as neural models on low-resource sequenceto-sequence tasks since about 2016 (Liu and Mao, 2016), we selected the Transformer (Vaswani et al., 2017) as our model. The Transformer is a supervised deep learning system that has achieved promising results for NLP in low-resource languages (Abbott and Martinus, 2018; Martinus and Abbott, 2019). It is a stateless encoderdecoder model that uses additional attention layers to boost speed and performance. We used the Fairseq (Ott et al., 2019) implementation with the modifications and code described by Wu et al. (2020) which have been successful in lowresource character-level morphological tasks.7 The first experiment tested whether joint or sequential segmentation and glossing is a better approach to interlinearization when integrating automated assistance. Joint segmentation assumes that segmented data without glosses is unlikely because identifying a morpheme usually means there has already been an identification of the morpheme’s meaning. Joint segmentation requires the model to learn the morpheme boundary and gloss simultaneou"
2021.computel-1.6,W12-6206,1,0.75659,"eng 87.0k 80.6k word pairs Table 1: Data information glish is used as a baseline, which is referred to as tok. In addition to that, we experiment with segmenting Basque or Navajo words by syllables, for which we manually develop finite-state transducers, using foma (Hulden, 2009), to break up words into syllables for each language. We refer to this method as syl. We also experiment with the bytepair encoding (BPE) algorithm with a vocabulary size of 8,000 and 16,000 respectively, which are referred to as bpe-8k and bpe-16k. Experiments 2.2 Data and data preprocessing Syllabifier details As in Agirrezabal et al. (2012) we treat Basque syllabification as following the maximum onset principle and a standard sonority hierarchy. Such syllabifiers can be built with a finite-state transducer (FST) constructed with a single rewrite rule which inserts syllable boundaries after legal syllables following a leftmost-shortest strategy (Hulden, 2005). Leftmost-shortest rewrite rule compilation is implemented in many standard FST toolkits such as foma (Hulden, 2009), the Xerox tools (Beesley and Karttunen, 2003), or Kleene (Beesley, 2012). Navajo has a relatively simple syllable structure, disallowing onsetless syllables"
2021.computel-1.6,D18-1399,0,0.0473227,"Missing"
2021.computel-1.6,E09-2008,1,0.687783,"ible data in our experiments, though the word-to-word mapping data augmentation method is the best of all the additional data approaches we apply. 2 2.1 verse eus - eng 31.7k nvj - eng 31.8k eus - eng 14.9k nvj - eng 14.8k bible dict w2w dict eus - eng token eus 609.7k eng 836.8k nvj 716.1k eng 844.3k eus 55.1k eng 76.7k nvj 43.0k eng 87.0k 80.6k word pairs Table 1: Data information glish is used as a baseline, which is referred to as tok. In addition to that, we experiment with segmenting Basque or Navajo words by syllables, for which we manually develop finite-state transducers, using foma (Hulden, 2009), to break up words into syllables for each language. We refer to this method as syl. We also experiment with the bytepair encoding (BPE) algorithm with a vocabulary size of 8,000 and 16,000 respectively, which are referred to as bpe-8k and bpe-16k. Experiments 2.2 Data and data preprocessing Syllabifier details As in Agirrezabal et al. (2012) we treat Basque syllabification as following the maximum onset principle and a standard sonority hierarchy. Such syllabifiers can be built with a finite-state transducer (FST) constructed with a single rewrite rule which inserts syllable boundaries after"
2021.computel-1.6,N19-4009,0,0.0192133,"or an English word. In cases where an English word does not appear in the dictionary, we copy the English word as Basque translation. ba@ @tzu@ @e@ @tan o@ @rain@ @dik Do@ @nos@ @ti@ @a@ @ra@ @ko ko@ @txe@ @a@ @re@ @kin a@ @hiz@ @pa łéé@ @chąą@ @&apos;í shi&apos;@ @niił@ @hį ná@ @ni@ @ni@ @chaa@ @dísh na@ @hwiil@ @zhooh ch&apos;éé@ @nís@ @dzid Figure 1: Example outputs of FST syllabifiers for Basque and Navajo. The output (right) of the FST is in BPE-format with double @-signs for word-internal syllables, and single @-signs at the word edge. ture (Vaswani et al., 2017) as implemented in the Fairseq toolkit (Ott et al., 2019).2 The Transformer model we use has 4 encoding layers and 4 attention heads with an embedding dimension of 256 and hidden layer size of 1024. Its decoding layer, attention head and dimensions have the same setting. The model is trained with a batch size of 16 for 120k maximum number of updates. Beam search with a width of 5 is used for generation. More details on the hyperparameters and training heuristics are provided in Appendix A.1. The BLEU score (Papineni et al., 2002) is used as the metric to evaluate the NMT model generation output throughout. Note that in this paper the BLEU score is m"
2021.computel-1.6,W14-4012,0,0.177536,"Missing"
2021.computel-1.6,P02-1040,0,0.119963,"rd-internal syllables, and single @-signs at the word edge. ture (Vaswani et al., 2017) as implemented in the Fairseq toolkit (Ott et al., 2019).2 The Transformer model we use has 4 encoding layers and 4 attention heads with an embedding dimension of 256 and hidden layer size of 1024. Its decoding layer, attention head and dimensions have the same setting. The model is trained with a batch size of 16 for 120k maximum number of updates. Beam search with a width of 5 is used for generation. More details on the hyperparameters and training heuristics are provided in Appendix A.1. The BLEU score (Papineni et al., 2002) is used as the metric to evaluate the NMT model generation output throughout. Note that in this paper the BLEU score is measured over word overlap, not word-piece overlap. 2.4 Using dictionary data We experiment with incorporating dictionary data in three different ways. For Basque-English, we use the Elhuyar dictionary,3 whose phrase examples give us around 14.9k parallel sentences or phrases, and around 80.6k word pairs. For NavajoEnglish, we extract around 14.8k parallel sentences or phrases from the Young & Morgan dictionary (Young and Morgan, 1987). We omit the word-pair experiments for"
2021.computel-1.6,W17-4715,0,0.0303912,"Missing"
2021.computel-1.6,P16-1009,0,0.258017,"r phrases from the dictionary directly to the Bible training dataset. Second, in order to alleviate the cross-domain problem, we also experiment with only adding word pairs to the Bible data for training. Third, inspired by Nag et al. (2020), we experiment with the data augmentation approach of mapping additional English texts into Basque with the word-to-word dictionary data, which are then combined with the Bible data to train the Basque to English NMT model. This word-to-word translation data augmentation approach is compared with the commonly used backtranslation data augmentation method (Sennrich et al., 2016). However, neither the additional dictionary data nor any of the data augmentation method produces improvements in the BLEU score over using only the Bible data in our experiments, though the word-to-word mapping data augmentation method is the best of all the additional data approaches we apply. 2 2.1 verse eus - eng 31.7k nvj - eng 31.8k eus - eng 14.9k nvj - eng 14.8k bible dict w2w dict eus - eng token eus 609.7k eng 836.8k nvj 716.1k eng 844.3k eus 55.1k eng 76.7k nvj 43.0k eng 87.0k 80.6k word pairs Table 1: Data information glish is used as a baseline, which is referred to as tok. In ad"
2021.computel-1.6,P19-1021,0,0.0283877,"Missing"
2021.eacl-main.163,D19-1091,0,0.274868,"Missing"
2021.eacl-main.163,W19-5301,0,0.048882,"Missing"
2021.eacl-main.163,K17-2002,0,0.146749,"Missing"
2021.eacl-main.163,P17-1183,0,0.0427771,"Missing"
2021.eacl-main.163,K18-3001,1,0.94323,"Missing"
2021.eacl-main.163,K17-2001,1,0.951744,"Missing"
2021.eacl-main.163,N19-1423,0,0.0323939,"gure 1: Development set accuracy for 5 languages on morphological inflection with different batch sizes. We evince our two primary contributions: (1) we set the new state of the art morphological inflection using the transformer and (2) we demonstrate the transformer’s dependence on the batch size. Introduction The transformer (Vaswani et al., 2017) has become a popular architecture for sequence-to-sequence transduction in NLP. It has achieved state-of-theart performance on a range of common word-level transduction tasks: neural machine translation (Barrault et al., 2019), question answering (Devlin et al., 2019) and abstractive summarization (Dong et al., 2019). In addition, the transformer forms the backbone of the widely-used BERT (Devlin et al., 2019). Yet for character-level transduction tasks like morphological inflection, the dominant model has remained a recurrent neural network-based sequenceCode will be available at https://github.com/ shijie-wu/neural-transducer. to-sequence model with attention (Cotterell et al., 2018). This is not for lack of effort—but rather, it is the case that the transformer has consistently underperformed in experiments on average (Tang et al., 2018b).1 As anecdotal"
2021.eacl-main.163,P19-1157,0,0.0491436,"Missing"
2021.eacl-main.163,D15-1166,0,0.113722,"a dropout of 0.3 yields a slightly better CERi . G2P and Transliteration. Tab. 4 shows that the transformer outperforms previously published strong recurrent models on two tasks despite having fewer parameters. A dropout rate of 0.3 yields 1904 significantly better performance on the transliteration task while a dropout rate of 0.1 is stronger on the g2p task. This shows that transformers can and do outperform recurrent transducers on common character-level tasks when properly tuned. 4 Related Work Character-level transduction is largely dominated by attention-based LSTM sequence-to-sequence (Luong et al., 2015) models (Cotterell et al., 2018). Character-level transduction tasks usually involve input-output pairs that share large substrings and alignments between these are often monotonic. Models that address the task tend to focus on exploiting such structural bias. Instead of learning the alignments, Aharoni and Goldberg (2017) use external monotonic alignments from the SIGMORPHON 2016 shared task baseline Cotterell et al. (2016). Makarov et al. (2017) use this approach to win the CoNLL-SIGMORPHON 2017 shared task on morphological inflection (Cotterell et al., 2017). Wu et al. (2018) shows that exp"
2021.eacl-main.163,W19-4226,1,0.884602,"uction tasks like morphological inflection, the dominant model has remained a recurrent neural network-based sequenceCode will be available at https://github.com/ shijie-wu/neural-transducer. to-sequence model with attention (Cotterell et al., 2018). This is not for lack of effort—but rather, it is the case that the transformer has consistently underperformed in experiments on average (Tang et al., 2018b).1 As anecdotal evidence of this, we note that in the 2019 SIGMORPHON shared task on cross-lingual transfer for morphological inflection, no participating system was based on the transformer (McCarthy et al., 2019). Character-level transduction models are often trained with less data than their word-level counterparts: In contrast to machine translation, where millions of training samples are available, the 2018 SIGMORPHON shared task (Cotterell et al., 2018) high-resource setting only provides ≈ 10k training examples per language. It is also not obvious that non-recurrent architectures such as the transformer 1 This claim is also based on the authors’ personal communication with other researchers in morphology in the corridors of conferences and through email. 1901 Proceedings of the 16th Conference of"
2021.eacl-main.163,K19-1014,1,0.909908,"Missing"
2021.eacl-main.163,W13-2409,0,0.0320945,"et al., 2017) with 52 languages. The performance is evaluated by accuracy (ACC) and edit distance (Dist). For the g2p task, we use the unstressed CMUDict (Weide, 1998) and NETtalk (Sejnowski and Rosenberg, 1987) resources. We use the splits from Wu et al. (2018). We evaluate under word error rate (WER) and phoneme error rate (PER). For transliteration, we use the NEWS 2015 shared task data (Zhang et al., 2015).4 For historical text normalization, we follow Bollmann (2019) and use datasets for Spanish (S´anchez-Mart´ınez et al., 2013), Icelandic and Swedish (Pettersson et al., 2013), Slovene (Scherrer and Erjavec, 2013, 2016; Ljubeˇsic et al., 2016), Hungarian and German (Pettersson, 2016).5 We evaluate using accuracy (ACC) and character error rate of incorrect prediction (CERi ). Optimization. We use Adam (Kingma and Ba, 2014) with a learning rate of 0.001 and an inverse 3 While the features could be encoded with a binary vector followed by MLP, it introduces a representation bottleneck for encoding features. 4 We do not have access to the test set. 5 We do not include English due to licensing issues. Figure 3: Distribution of incorrectly inflected forms in the test set of the inflection task over all 52 l"
2021.eacl-main.163,K17-2010,0,0.324347,"Missing"
2021.eacl-main.163,C18-1112,0,0.0162749,"on answering (Devlin et al., 2019) and abstractive summarization (Dong et al., 2019). In addition, the transformer forms the backbone of the widely-used BERT (Devlin et al., 2019). Yet for character-level transduction tasks like morphological inflection, the dominant model has remained a recurrent neural network-based sequenceCode will be available at https://github.com/ shijie-wu/neural-transducer. to-sequence model with attention (Cotterell et al., 2018). This is not for lack of effort—but rather, it is the case that the transformer has consistently underperformed in experiments on average (Tang et al., 2018b).1 As anecdotal evidence of this, we note that in the 2019 SIGMORPHON shared task on cross-lingual transfer for morphological inflection, no participating system was based on the transformer (McCarthy et al., 2019). Character-level transduction models are often trained with less data than their word-level counterparts: In contrast to machine translation, where millions of training samples are available, the 2018 SIGMORPHON shared task (Cotterell et al., 2018) high-resource setting only provides ≈ 10k training examples per language. It is also not obvious that non-recurrent architectures such"
2021.eacl-main.163,D18-1458,0,0.0513814,"Missing"
2021.eacl-main.163,P19-1148,1,0.942093,"nce of the transformer on character-level tasks, and we show that with a large enough batch size, the transformer does indeed outperform recurrent models. We also introduce a simple technique to handle feature-guided character-level transduction that further improves performance. With these insights, we achieve state-of-the-art performance on morphological inflection and historical text normalization. We also show that the transformer outperforms a strong baseline on two other character-level transduction tasks: grapheme-to-phoneme conversion and transliteration. 1 86 ACC 84 82 80 78 76 16 32 Wu and Cotterell (2019) Wu and Cotterell (2019) (Our Eval) Wu and Cotterell (2019) + LR Warmup Vanilla Transformer Feature Invariant Transformer 64 128 256 512 Batch Size Figure 1: Development set accuracy for 5 languages on morphological inflection with different batch sizes. We evince our two primary contributions: (1) we set the new state of the art morphological inflection using the transformer and (2) we demonstrate the transformer’s dependence on the batch size. Introduction The transformer (Vaswani et al., 2017) has become a popular architecture for sequence-to-sequence transduction in NLP. It has achieved st"
2021.eacl-main.163,D18-1473,1,0.886594,"Missing"
2021.insights-1.13,D19-1091,0,0.0401634,"Missing"
2021.insights-1.13,D18-1045,0,0.0233263,"(or subwordlevel) string transduction while morphological inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six differe"
2021.insights-1.13,K17-2002,0,0.027807,"gical inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six different languages with unlabeled data from different resources indicates that backtranslation can only improve morphological inflection in low-resource scenarios when the unlabeled data set is very clean and has been filtered by the same annotation standards as the lab"
2021.insights-1.13,2020.acl-main.253,0,0.0203702,"on can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six different languages with unlabeled data from different resources indicates that backt"
2021.insights-1.13,W19-5206,0,0.0194042,"hared task words improves the inflection model, adding backtranslated UD words causes the model to deteriorate. This opposite tendency goes quite against our expectations, especially considering that the UD words were selected to ensure that they are of the same parts-of-speech covered in the original training data. In order to explain the opposite tendency and answer whether backtranslation could indeed be helpful for morphological generation, we conducted the following experiments on comparing different ways of adding backtranslated data. Morphological inflection with tagged backtranslation Caswell et al. (2019) show that tagging backtranslated source sentences with an extra distinguishing token can improve the contribution backtranslated data can provide to machine translation. This finding is supported in later work (Marie et al., 2020). Therefore, we hypothesize that adding a special tag to the lemma and MSD tag sequence predicted by the morphological analyzer may improve the performance of the inflection model trained with the combination of the original training data and the backtranslated data. In order to test the hypothesis, we start with experiments on the 500 training example setting. We tr"
2021.insights-1.13,P17-2090,0,0.017476,"treated as word-level (or subwordlevel) string transduction while morphological inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the"
2021.insights-1.13,2020.wmt-1.8,0,0.0294325,"inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six different languages with unlabeled data from different resources"
2021.insights-1.13,K17-2001,1,0.881959,"Missing"
2021.insights-1.13,2020.coling-main.257,1,0.751145,"hat the words available from Wikipedia often represent parts-ofspeech (e.g. determiners, adverbs, etc) not found in the labeled data and thus introduce excessive noise. Therefore, we changed the source of our unExperiments and Results We conduct several experiments to evaluate the performance of morphological inflection with the backtranslation data augmentation technique. The deep learning architecture we use is the Transformer model (Vaswani et al., 2017) as implemented in Fairseq (Ott et al., 2019). For our experiments, we use the same hyperparameter settings as the best-performing system (Liu and Hulden, 2020b,a) in the SIGMORPHON 2020 shared task on inflection (Vylomova et al., 2020). All models have been trained with a single NVIDIA Tesla P100 GPU. Data Our experiments cover six languages: Czech, Finnish, German, Russian, Spanish and Turkish. These languages are selected to include variety in morphological inflection complexity and difficulty. Finnish and Turkish are agglutinative languages, both of which have vowel harmony and extensive agglutination. Spanish has a rich inflec1 Thanks to one of the reviewers for pointing out that the amount of the development data makes the experiment not reall"
2021.insights-1.13,2020.sigmorphon-1.17,1,0.748168,"hat the words available from Wikipedia often represent parts-ofspeech (e.g. determiners, adverbs, etc) not found in the labeled data and thus introduce excessive noise. Therefore, we changed the source of our unExperiments and Results We conduct several experiments to evaluate the performance of morphological inflection with the backtranslation data augmentation technique. The deep learning architecture we use is the Transformer model (Vaswani et al., 2017) as implemented in Fairseq (Ott et al., 2019). For our experiments, we use the same hyperparameter settings as the best-performing system (Liu and Hulden, 2020b,a) in the SIGMORPHON 2020 shared task on inflection (Vylomova et al., 2020). All models have been trained with a single NVIDIA Tesla P100 GPU. Data Our experiments cover six languages: Czech, Finnish, German, Russian, Spanish and Turkish. These languages are selected to include variety in morphological inflection complexity and difficulty. Finnish and Turkish are agglutinative languages, both of which have vowel harmony and extensive agglutination. Spanish has a rich inflec1 Thanks to one of the reviewers for pointing out that the amount of the development data makes the experiment not reall"
2021.insights-1.13,W17-4715,0,0.0245589,"0.00 czech finnish german russian spanish turkish Figure 3: Basic Transformer inflection performance at different training data sizes: 500 or 1,000 training examples. 500 training Transformer inflection and analyzer performance We first evaluate the base performance of the inflection model trained with only the 500 or the 1,000 triplet set. The accuracy results are presented in Figure 3. As it has been noted that the quality of the backtranslation model (in our case, the morphological analyzer) is positively correlated to the ability of backtranslation data augmentation to yield improvements (Currey et al., 2017), we present the morphological analyzer accuracy in Figure 4. The development and test data for the morphological analyzer is created by simply reversing the input and output of the development and test set data for morphological inflection. The reported accuracy for each morphological inflection model and each morphological analysis model are the average of five runs with different random initializations to ensure a good representation of the model performance. 1000 training 100.00 75.00 50.00 25.00 0.00 czech finnish german russian spanish turkish Figure 4: Transformer morphological analyzer"
2021.insights-1.13,K17-2010,1,0.842576,"in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six different languages with unlabeled data from different resources indicates that backtranslation can only improve morphological inflection in low-resource scenarios when the unlabeled data set is very clean and has been filtered by the same annotat"
2021.insights-1.13,K18-3001,1,0.906128,"Missing"
2021.insights-1.13,2020.acl-main.532,0,0.136858,"character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six different languages with unlabeled data from different resources indicates that backtranslation can only"
2021.insights-1.13,W19-4226,1,0.844189,"V;V.PTCP;PRS enforcing meagre V;V.PTCP;PST meagred remarry V;PST Figure remarried 1: Data example for morphological inflection … … … Both and inflection generation are string transduction tasks: MT is typically treated as word-level (or subwordlevel) string transduction while morphological inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtransla"
2021.insights-1.13,2021.acl-long.78,1,0.806906,"Missing"
2021.insights-1.13,2021.eacl-main.163,1,0.765716,"Missing"
2021.insights-1.13,P19-1579,0,0.0199662,"ile morphological inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augmentation method in morphological inflection under low-resource circumstances. Our evaluation of the method on six different languages with unlabeled data from"
2021.insights-1.13,2020.emnlp-main.424,1,0.734235,"T Figure remarried 1: Data example for morphological inflection … … … Both and inflection generation are string transduction tasks: MT is typically treated as word-level (or subwordlevel) string transduction while morphological inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtransla"
2021.insights-1.13,N19-4009,0,0.0165938,"g different amount of backtranslated Wikipedia words. We hypothesized that the reason for the decrease may be that the words available from Wikipedia often represent parts-ofspeech (e.g. determiners, adverbs, etc) not found in the labeled data and thus introduce excessive noise. Therefore, we changed the source of our unExperiments and Results We conduct several experiments to evaluate the performance of morphological inflection with the backtranslation data augmentation technique. The deep learning architecture we use is the Transformer model (Vaswani et al., 2017) as implemented in Fairseq (Ott et al., 2019). For our experiments, we use the same hyperparameter settings as the best-performing system (Liu and Hulden, 2020b,a) in the SIGMORPHON 2020 shared task on inflection (Vylomova et al., 2020). All models have been trained with a single NVIDIA Tesla P100 GPU. Data Our experiments cover six languages: Czech, Finnish, German, Russian, Spanish and Turkish. These languages are selected to include variety in morphological inflection complexity and difficulty. Finnish and Turkish are agglutinative languages, both of which have vowel harmony and extensive agglutination. Spanish has a rich inflec1 Than"
2021.insights-1.13,P16-1009,0,0.0378474,"ogical inflection … … … Both and inflection generation are string transduction tasks: MT is typically treated as word-level (or subwordlevel) string transduction while morphological inflection generation can be treated as character-level string transduction. MT models and techniques can usually be naturally applied to morphological inflection, as is shown in recent work on morphological inflection (Liu, 2021; Kann and Schütze, 2016; Cotterell et al., 2016, 2017, 2018; Liu et al., 2018; McCarthy et al., 2019; Vylomova et al., 2020; Wu et al., 2020; Moeller et al., 2020, 2021). Backtranslation (Sennrich et al., 2016) has become a common practice in machine translation in low-resource scenarios (Fadaee et al., 2017; Edunov et al., 2018; Hoang et al., 2018; Xia et al., 2019; Chen et al., 2020; Edunov et al., 2020; Marie et al., 2020; Liu et al., 2021). There has been work on data augmentation for morphological generation in low-resource scenarios (Silfverberg et al., 2017; Bergmanis et al., 2017; Anastasopoulos and Neubig, 2019; Liu and Hulden, 2021), but no previous work has applied the backtranslation technique. In this paper, we propose to apply backtranslation as a and morphological analysis. data augme"
2021.naacl-main.435,P18-1198,0,0.0303327,"of the speech signal: specifically the presence or absence of the fricative [s] in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of n"
2021.naacl-main.435,D18-1269,0,0.0139971,"of the speech signal: specifically the presence or absence of the fricative [s] in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of n"
2021.naacl-main.435,K17-2001,1,0.890174,"Missing"
2021.naacl-main.435,2020.scil-1.5,0,0.0342658,"Missing"
2021.naacl-main.435,W19-4828,0,0.0254706,"cifically the presence or absence of the fricative [s] in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of neural representations in"
2021.naacl-main.435,2020.emnlp-main.15,0,0.0345602,"in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of neural representations in recurrent neural models has been an active area of resear"
2021.naacl-main.435,W16-2010,0,0.0450767,"Missing"
2021.naacl-main.435,W18-1817,0,0.0614385,"Missing"
2021.naacl-main.435,W19-4219,0,0.045635,"Missing"
2021.naacl-main.435,W97-1012,0,0.577375,"rticularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of neural representations in recurrent neural models has been an active area of research over a long period of time starting with Elman (1990). However, representations in models of phonology have received less attention than many other subfields of NLP. Rodd (1997) investigates learning of Turkish vowel harmony by a character-based RNN language model trained on Our approach was inspired by the now-classic word forms. The paper investigates hidden state ac- paper on visualization and interpretation of recurtivations of RNN models while varying the hidden rent networks by Karpathy et al. (2015) in that we state dimensionality between 1 and 4. It presents also seek individual interpretable dimensions. The evidence that RNN hidden states can capture Turk- work by Dalvi et al. (2019) on analyzing individish vowel harmony patterns when a sufficient num- ual n"
2021.naacl-main.435,W18-0314,1,0.84302,". The paper investigates hidden state ac- paper on visualization and interpretation of recurtivations of RNN models while varying the hidden rent networks by Karpathy et al. (2015) in that we state dimensionality between 1 and 4. It presents also seek individual interpretable dimensions. The evidence that RNN hidden states can capture Turk- work by Dalvi et al. (2019) on analyzing individish vowel harmony patterns when a sufficient num- ual neurons in networks trained for linguistic tasks ber of hidden dimensions are available. In a similar (POS tagging as well as semantic and morphologivein, Silfverberg et al. (2018) investigate phoneme cal tagging) is more closely related to the present representations for Finnish, Spanish and Turkish work. They present a general methodology for finding correlations between embedding represen- uncovering neurons which encode linguistic infortations and phonological distinctive features. Ko- mation by training a classifier to predict linguistic lachina and Magyar (2019) present an investiga- features of the input based on the representations tion of phone embeddings learned using word2vec generated by the network. They also show that it is (Mikolov et al., 2013) for simul"
2021.sigmorphon-1.25,K18-3001,1,0.679933,"l marker used for expressing case, familiarity, plurality, and (sometimes) gender within animate nouns. Pronouns are marked for different cases and honorificity levels. These paradigms are generated on the basis of a manually annotated corpus of Magahi folktales. We used a raw dataset from the literary domain. First, we annotated the dataset with the Universal Dependency morphological feature tags at token level using the CoNLL-U editor (Heinecke, 2019). We then converted the annotated dataset into the UniMorph schema using the script available for converting UD data into the UniMorph tagset (McCarthy et al., 2018). To finalize the data, we manually validated the dataset against the UniMorph schema (Sylak-Glassman et al., 2015a). Brajbhasha, or Braj is one of the Indo-Aryan languages spoken in the Western Indian states of Uttar Pradesh, Madhya Pradesh, and Rajasthan. Grierson (1908) groups Brajbhasha under Western Hindi of the Central Group in the Indo-Aryan family, along with other languages like Hindustani, Bangaru, Kannauji, and Bundeli. Braj is not generally used in education or for any official purposes in any Braj spoken state, but it has a very rich literary tradition. Also in order to preserve,"
2021.sigmorphon-1.25,K17-2001,1,0.858355,"Missing"
2021.sigmorphon-1.25,U19-1001,1,0.893844,"nje-ng ‘1/3PL-again-wrong-BENmeat-cook-PP’ (“I cooked the wrong meat for them again”). As shown, the form has several prefixes and suffixes attached to the stem. As in other Australian languages, long vowels are typically represented by double characters, and trills with “rr”.3 According to Evans’ (2003) analysis, the verb template contains 12 affix slots which include two incorporated noun classes, and derivational affixes such as the benefactive and comitative. The data included in this set are verbs extracted from the Kunwinjku translation of the Bible using the morphological analyzer from Lane and Bird (2019) and manually verified by human annotators. 3.2 Afro-Asiatic The Afro-Asiatic language family is represented by the Semitic subgroup. 3.2.1 Semitic: Classical Syriac Classical Syriac is a dialect of the Aramaic language and is attested as early as the 1st century CE. As with most Semitic languages, it displays non-concatenative morphology involving primarily tri-consonantal roots. Syriac nouns and adjectives are conventionally classified into three ‘states’— Emphatic, Absolute, Construct—which loosely correlate with the syntactic features of definiteness, indeterminacy and the genitive. There"
2021.sigmorphon-1.25,U19-1005,1,0.782664,"respect to morphology and realized in the UniMorph schema (Sylak-Glassman et al., 2015b). Morphosyntactic features (such as “the dative case” or “the past tense”) in the UniMorph occupy an intermediate position between the descriptive categories and comparative concepts. The set of features was initially established on the basis of analysis of typological literature, and refined with the addition of new languages to the UniMorph database (Kirov et al., 2018; McCarthy et al., 2020). Since 2016, SIGMORPHON organized shared tasks on morphological reinflection (Cotterell et al., 2016, 2017, 2018; McCarthy et al., 2019; Vylomova et al., 2020) that aimed at evaluating contemporary systems. Parallel to that, they also served as a platform for enriching the UniMorph database with new languages. For instance, the 2020 shared task (Vylomova et al., 2020) featured 90 typologically diverse languages derived from various linguistic resources. This year, we are bringing many under-resourced languages (languages of Peru, Russia, India, Australia, Papua New Guinea) and dialects (e.g., for Arabic and Kurdish). The sample is highly diverse: it contains languages with templatic, concatenative (fusional and agglutinative)"
2021.sigmorphon-1.25,W02-0604,0,0.0878472,"Missing"
2021.sigmorphon-1.25,U08-1018,0,0.0643919,"through affixation, compounding, or reduplication. The four types of Indonesian affixes are prefixes, suffixes, circumfixes (combination of prefixes and suffixes), and infixes (inside the base form). Indonesian uses both full and partial reduplication processes to form words. Full reduplication is often used to express the plural forms of nouns, while partial reduplication is typically used to derive forms that might have a different category than their base forms. Unlike English, the distinction between inflectional and derivational morphological processes in Indonesian is not always clear (Pisceldo et al., 2008). In this shared task, the Indonesian data is created by bootstrapping the data from an Indonesian Wikipedia dump. Using a list of possible Indonesian affixes, we collect unique word forms from Wikipedia and analyze them using MorphInd (Larasati et al., 2011), a morphological analyzer tool for Indonesian based on an FST. We manually create a mapping between the MorphInd tagset and the UniMorph schema. We then use this mapping and apply some additional rule-based formulas created by Indonesian linguists to build the final dataset (Table 9). 3.9.2 Malayo-Polynesian: Kodi/Kodhi Kodi or Kodhi [koâ"
2021.sigmorphon-1.25,N19-1119,0,0.0213266,"ugmentation technique presented by Anastasopoulos and Neubig (2019). More specifically, the team implemented an encoder–decoder model with an attention mechanism. The encoder processes a character sequence using an LSTM-based RNN with attention. Tags are encoded with a selfattention (Vaswani et al., 2017) position-invariant module. The decoder is an LSTM with separate attention mechanisms for the lemma and the tags. GUClasp focus their efforts on exploring strategies for training a multilingual model, in particular, they implement the following strategies: curriculum learning with competence (Platanios et al., 2019) based on character frequency and L BME GUClasp afb amh ara arz heb syc ame cni ind kod aym ckt itl gup bra bul ces ckb deu kmr mag nld pol por rus spa see ail evn sah tyv krl lud olo vep 92.39 98.16 99.76 95.27 97.46 21.71 82.46 99.5 81.31 94.62 99.98 44.74 32.4 14.75 58.52 98.9 98.03 99.46 97.98 98.21 70.2 98.28 99.54 99.85 98.07 99.82 78.28 6.84 51.9 99.95 99.97 99.88 59.46 99.72 99.72 81.71 93.81 94.86 87.12 89.93 10.57 55.94 93.36 55.68 87.1 99.97 52.63 31.28 21.31 56.91 96.46 94.00 96.60 91.94 98.09 72.24 94.91 98.52 99.11 94.32 97.65 40.97 6.46 51.5 99.69 99.78 98.50 59.46 98.2 97.05 sj"
2021.sigmorphon-1.25,2020.acl-main.597,1,0.915066,"arget inflected form—and removed all forms other than verbs, nouns, or adjectives. We then capped the dataset sizes to a maximum of 100,000 instances per language, subsampling when necessary. Finally, we create a 70–10–20 train–dev–test split per language, splitting the data across these sets at the instance level (as opposed to, e.g., the lemma one). As such, the information about a lemma’s declension or inflection class is spread out across these train, dev and test sets, making this task much simpler than if one had to predict the entire class from the lemma’s form alone, as done by, e.g., Williams et al. (2020) and Liu and Hulden (2021). 5 Baseline Systems The organizers provide four neural systems as baselines, a product of two models and optional data augmentation. The first model is a transformer (Vaswani et al., 2017, TRM), and the second model is an adaption of the transformer to character-level transduction tasks (Wu et al., 2021, CHR-TRM), which holds the state-of-the-art on the 2017 SIGMORPHON shared task data. Both models follow the hyperparameters of Wu et al. (2021). The optional data augmentation follows the technique proposed by Anastasopoulos and Neubig (2019). Rely14 The new languages"
2021.sigmorphon-1.8,K17-2001,1,0.900551,"Missing"
2021.sigmorphon-1.8,W16-2002,1,0.895884,"Missing"
2021.sigmorphon-1.8,N13-1138,0,0.0713896,"Missing"
2021.sigmorphon-1.8,2020.acl-main.695,1,0.883705,"Missing"
2021.sigmorphon-1.8,2021.sigmorphon-1.12,1,0.8311,"Missing"
2021.sigmorphon-1.8,Q17-1010,0,0.106213,"Missing"
2021.sigmorphon-1.8,2020.acl-main.598,1,0.881267,"Missing"
2021.sigmorphon-1.8,K18-3001,1,0.886365,"Missing"
2021.sigmorphon-1.8,2020.lrec-1.497,0,0.0616438,"Missing"
2021.sigmorphon-1.8,2020.sigmorphon-1.3,1,0.815511,"Missing"
2021.sigmorphon-1.8,2021.sigmorphon-1.10,0,0.061232,"Missing"
2021.sigmorphon-1.8,2020.acl-demos.14,0,0.0404485,"Missing"
2021.sigmorphon-1.8,W19-4226,1,0.902221,"Missing"
2021.sigmorphon-1.8,2021.sigmorphon-1.11,1,0.696729,"Missing"
2021.sigmorphon-1.8,2020.lrec-1.352,1,0.814695,"Missing"
2021.sigmorphon-1.8,2021.sigmorphon-1.9,0,0.0885046,"Missing"
adesam-etal-2014-computer,E14-1060,1,\N,Missing
agirrezabal-etal-2017-comparison,D10-1051,0,\N,Missing
agirrezabal-etal-2017-comparison,W16-0201,0,\N,Missing
C14-1073,drobac-etal-2014-heuristic,0,0.022074,"Missing"
C14-1073,E09-2008,1,0.881321,"by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 772 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 772–780, Dublin, Ireland, August 23-29 2014. We do not attempt here to add a new method to this list; instead, we concentrate on three practical aspects of FST-based CG. First, we report accurate measurements of the real-world performance of one of the methods above. Second, we endeavour to optimise the implementation of the selected method. All three works used foma, an open source FST library (Hulden, 2009b; Hulden, 2009a). We show that while foma is fast, relying on specialised FST application code instead of a generic library clearly benefits performance. We also demonstrate what further improvements can be achieved by exploiting the peculiarities of CG. Lastly, our research also aims to fill the niche left by the lack of openly accessible finite-state CG implementations. Section 2 briefly introduces the method we chose to evaluate. In the rest of the paper, we present our optimisations in a way that mirrors the actual development process. We start out with a simple rule engine based on foma,"
C14-1073,W11-4406,1,0.849866,"e free/open-source VISL CG-3 (Bick, 2000; Didriksen, 2011). Constraint grammar, however, has its drawbacks, one of which is speed. The Apertium machine translation project (Forcada et al., 2011) uses both CG (via VISL CG-3) and n-gram based models for morphological disambiguation, and while CG achieves higher accuracy, the n-gram model runs about ten times faster. In this paper, we investigate how using finite-state transducers (FST) for CG application can help to bridge the performance gap. In recent years, several methods have been proposed for compiling a CG to FST and applying it on text: Hulden (2011) compiles CG rules to transducers and runs them on the input sentences; Peltonen (2011) converts the sentences into ambiguous automata and attempts to eliminate branches by intersecting them with the rule FSTs; finally, Yli-Jyr¨a (2011) creates a single FST from the grammar and applies it on featurised input. Unfortunately, none of the authors report exact performance measurements of their systems. Yli-Jyr¨a published promising numbers for the preprocessing step, but nothing on the overall performance. Peltonen, on the other hand, observed that “VISL CG-3 was 1,500 times faster” than his imple"
C14-1073,C90-3030,0,0.293307,"ile these formalisms serve their purpose as proofs of the concept, the performance of the generated transducers lags behind other CG implementations and taggers. In this paper, we argue that the fault lies with using generic finite-state libraries, and not with the formalisms themselves. We present an open-source implementation that capitalises on the characteristics of CG rule application to improve execution time. On smaller grammars our implementation achieves performance comparable to the current open-source state of the art. 1 Introduction Constraint grammar (CG), described originally by Karlsson (1990), is a rule-based formalism for various linguistics tasks, including morphological analysis, clause boundary detection and surface syntactic parsing. It has been used in a wide range of application areas, such as morphological disambiguation, grammar checking and machine translation (Bick, 2011). CG owns its popularity to two reasons: first, it achieves high accuracy on free text. Second, it works for languages where the annotated corpora required by statistical parsing methods are not available, but a linguist willing to work on the rules is. The original CG has since been superseded by CG-2"
C14-1073,W05-1106,0,0.0341418,"Missing"
C14-1073,2010.eamt-1.13,1,0.843745,"development. Therefore, we have written a small Hungarian CG, aimed to fully disambiguate a short Hungarian story, which was used as the development corpus. Since Hungarian is not properly supported by Apertium yet, morphological analysis was carried out by Hunmorph (Tr´on et al., 2005), and the tags were translated to the Apertium tagset with a transducer in foma. The performance of fomacg-proc has been measured against that of VISL CG. The programs were benchmarked with three Apertium CG grammars: the toy Hungarian grammar mentioned earlier, the Breton grammar from the br-fr language pair (Tyers, 2010), and the version of the Finnish grammar originally written by Karlsson in the North S´ami–Finnish (sme-fin) pair. Seeing that in the early phases, only the Hungarian grammar was used for development, results for the other two languages are reported only for the later steps. Each grammar was run on a test corpus. For Breton, we used the corpus in the br-fr language pair, which consists of 1,161 sentences. There are no Finnish and Hungarian corpora in Apertium; for the former, we used a 1,620-sentence excerpt from the 2013-Nov-14 snapshot of the Finnish Wikipedia, while for the latter, the shor"
C16-1074,W16-0201,0,0.652133,"r this line which may all be accepted as correct, or at least reasonable. 2.1 State of the art Automatic scansion of poetry has attracted attention from numerous scholars in recent years and in the following section we discuss some of them. Some works rely on statistical analyses, like Hayward (1996) and Hayes et al. (2012). Others make use of linguistic knowledge obtained by generalizing observations found in different kinds of poetry and propose hand-written rules for the assignment of stress. Recently, as in other NLP tasks, data-driven approaches have emerged in automatic poetry analysis (Estes and Hench, 2016). Statistics about scansion Hayward (1996) has as its goal to investigate whether it would be possible to differentiate among the metrical patterns developed by individual writers and also the stylistic differences among periods. To this end, the authors collected a corpus of work by several poets from different time periods and built a neural network model (Rumelhart et al., 1988) to scan poems. Using this technique, Hayward analyzes the work of ten different poets and reports that the neural model of poetic meter was successful in determining “significant differences” among the analyzed poet"
C16-1074,D10-1051,0,0.656469,"Hench (2016) is a current work that makes use of supervised learning tools in order to metrically analyze poems written in Middle High German. Middle High German poetry is a hybrid between qualitative and quantitative verse, which means that both the length and the stress of syllables are taken into account for patterning in the lines. In order to perform supervised learning, they use a corpus of 825 manually annotated lines, which are annotated by the authors. They report an F-score of 0.894 on 10-fold cross-validated development data and 0.904 on held-out testing data. Unsupervised scansion Greene et al. (2010) uses statistical methods in the analysis of poetry. For the learning process, The Sonnets by Shakespeare was used, as well as a number of other works freely available online.7 They learn word-stress patterns from the corpus using unsupervised learning and with the incorporation of rhyme and discourse models, they use this system to generate English love poetry. In addition, they also apply their models for the automatic translation of poetry, testing them with Italian three-line stanzas as a source language and English iambic pentameter verse as the target language. We have not obtained an im"
C16-1074,P07-2053,0,0.0484179,"Missing"
C16-1074,W03-0430,0,0.0925635,"ion. From single prediction to structured prediction As single predictors do not optimize the resulting sequence labeling, they can make simple errors that propagate throughout the line—something that could be avoided by looking at the surrounding outputs. This is the main weakness of not using structured prediction systems. Hidden Markov Models are simple models that have been successfully used in tasks like POS-tagging, reaching reasonably good results. Conditional Random Fields are often used as an alternative model for POS-tagging and also for Named Entity Recognition and other NLP tasks (McCallum and Li, 2003). In our experiments, although the per-syllable accuracies do not vary too much, the per-line scores improve substantially by the use of structured predictors. In table 3 the per line and per syllable accuracy of structured prediction systems can be seen (HMM and linear-chain CRF). The HMM has been trained in the standard way, that is, using single syllables (emissions) and their corresponding classes (states). The CRF model is trained analogously, i.e. using only syllables as the features, and the previous label. As expected, training the CRFs using the richer feature configurations employed"
C16-1074,W15-0712,0,0.0211811,"les and two stressed syllables [xx//]. 6 http://oak.conncoll.edu/cohar/Programs.htm 5 774 One of the recent scansion implementations is ZeuScansion (Agirrezabal et al., 2016), a tool for scansion of English poetry, which performs poetry scansion using a simplified version of various stress assignment ‘rules-of-thumb’ developed by (Groves, 1998). We use this work as a baseline for our experiments. The rule-based systems mentioned above were designed to work only with poetry in English. There exist, however, several rule-based implementations for other languages, such as Spanish (Gerv´as, 2000; Navarro-Colorado, 2015). Supervised Learning & sequential modeling Estes and Hench (2016) is a current work that makes use of supervised learning tools in order to metrically analyze poems written in Middle High German. Middle High German poetry is a hybrid between qualitative and quantitative verse, which means that both the length and the stress of syllables are taken into account for patterning in the lines. In order to perform supervised learning, they use a corpus of 825 manually annotated lines, which are annotated by the authors. They report an F-score of 0.894 on 10-fold cross-validated development data and"
C16-1081,W98-1007,0,0.114591,"the corpus was deemed sufficient for the purpose of this study. 850 4 4.1 Implementation Finite-state phonology The loanword adaptation grammar is implemented as a sequence of phonological rewrite rules in the Xerox finite-state calculus (Beesley and Karttunen, 2003). This is the standard mode of implementing complex hand-written phonological grammars computationally, capturing phenomena such as phonological alternations (Karttunen and Beesley, 2005), syllabification processes (Hulden, 2006), optimalitytheoretic constraints (Karttunen, 1998), and nonconcatenative morphophonological processes (Beesley, 1998). The system relies on the ability to convert phonological replacement (or ‘rewrite’) rules into individual finite state transducers. A collection of such transducers can then be composed in a certain order, yielding one monolithic transducer, the end result essentially replicating the effect of applying multiple phonological rules in a sequence. This grammar transducer can also be applied in the inverse direction, mapping from a loanword phonological form to its possible sources. Although we don’t explore this possibility here, the invertibility of a transducer is useful for debugging our rul"
C16-1081,W04-2209,0,0.0250883,"loanword adaptation processes, and automatically calculating coverage and adjusting the rules to maximize coverage. The benefit of the computational approach is obvious: we can immediately obtain the accuracy of the system output during each round of the rule development and modification process, which is nearly impossible when resorting to paper-andpencil approaches. 3 Japanese loanword corpus compilation We manually compiled a word list of 250 tokens of Japanese loanwords from a Japanese-Multilingual Dictionary—essentially a multilingual lexical database with Japanese as the pivot language (Breen, 2004). The word list contains parallel phonetic transcriptions of both English (source) and Japanese (borrowing) entries, and we designed it carefully in the following ways: 1. The word list includes all the phonemes in English and Japanese. 2. The word list reflects as many different phonological interactions as possible collected from previous studies. 849 3. The word list intentionally includes ‘peculiar instances’ discussed in previous studies (e.g. /pIk.nIk/ 7→ [pi.kW.nik.kW] in which the word-final /k/ is geminated while the word-medial /k/ is not.) (Kubozono et al., 2008). 4. We only include"
C16-1081,W12-6202,1,0.806532,"in a certain order, yielding one monolithic transducer, the end result essentially replicating the effect of applying multiple phonological rules in a sequence. This grammar transducer can also be applied in the inverse direction, mapping from a loanword phonological form to its possible sources. Although we don’t explore this possibility here, the invertibility of a transducer is useful for debugging our rules. While finite-state tools have also been used to model other prominent approaches to describing loanword adaptation such as OT grammars (Karttunen, 1998; Gerdemann and van Noord, 2000; Gerdemann and Hulden, 2012), we restrict ourselves to the rewrite-rule model in this study. The grammar itself is developed using the foma-toolkit (Hulden, 2009). A summary of the core formalism is given in Table 2. Although the formalism offers a vast number of operations, we essentially only make use of a standard context-conditioned rewrite rule, which has the following appearance (2) LHS -> RHS ||LC RC which essentially reads as: replace all occurrences of the pattern LHS with the pattern RHS, whenever it occurs between the patterns LC and RC. The patterns in question can be expressed as regular expressions. Unlike"
C16-1081,W00-1804,0,0.18034,"Missing"
C16-1081,E09-2008,1,0.757048,"a sequence. This grammar transducer can also be applied in the inverse direction, mapping from a loanword phonological form to its possible sources. Although we don’t explore this possibility here, the invertibility of a transducer is useful for debugging our rules. While finite-state tools have also been used to model other prominent approaches to describing loanword adaptation such as OT grammars (Karttunen, 1998; Gerdemann and van Noord, 2000; Gerdemann and Hulden, 2012), we restrict ourselves to the rewrite-rule model in this study. The grammar itself is developed using the foma-toolkit (Hulden, 2009). A summary of the core formalism is given in Table 2. Although the formalism offers a vast number of operations, we essentially only make use of a standard context-conditioned rewrite rule, which has the following appearance (2) LHS -> RHS ||LC RC which essentially reads as: replace all occurrences of the pattern LHS with the pattern RHS, whenever it occurs between the patterns LC and RC. The patterns in question can be expressed as regular expressions. Unlike the rewrite rules found in the phonological literature (Hayes, 2011), such a replacement rule is taken to operate simultaneously (and"
C16-1081,W98-1301,0,0.0180834,"a relatively small number of rules, the number of tokens included in the corpus was deemed sufficient for the purpose of this study. 850 4 4.1 Implementation Finite-state phonology The loanword adaptation grammar is implemented as a sequence of phonological rewrite rules in the Xerox finite-state calculus (Beesley and Karttunen, 2003). This is the standard mode of implementing complex hand-written phonological grammars computationally, capturing phenomena such as phonological alternations (Karttunen and Beesley, 2005), syllabification processes (Hulden, 2006), optimalitytheoretic constraints (Karttunen, 1998), and nonconcatenative morphophonological processes (Beesley, 1998). The system relies on the ability to convert phonological replacement (or ‘rewrite’) rules into individual finite state transducers. A collection of such transducers can then be composed in a certain order, yielding one monolithic transducer, the end result essentially replicating the effect of applying multiple phonological rules in a sequence. This grammar transducer can also be applied in the inverse direction, mapping from a loanword phonological form to its possible sources. Although we don’t explore this possibility here"
C18-1137,L18-1293,1,0.898204,"Missing"
C18-1137,N15-2022,0,0.0272718,"h as ‘koiralla’ in Figure 1b) will be generalized into 3 Some authors call the generalization an inflectional class (Haspelmath and Sims, 2013). 1616 a form pattern, such as xi +lla. The features corresponding to a form, such as NOM;SG will be referred to as the morphosyntactic description (MSD). 2 Related Work As noted above, we build on the work of Ahlberg et al. (2014), Ahlberg et al. (2015), and Forsberg and Hulden (2016) which introduced the LCS as a core strategy in formal definitions of morphological paradigm and analogy. Further linguistic arguments favoring the LCS-model are given in Lee (2015). Learning to generalize from inflection tables to unseen forms has attracted much recent interest in natural language processing (Dreyer and Eisner, 2011; Durrett and DeNero, 2013). In addition, two recent shared tasks hosted by SIGMORPHON and CoNLL have contributed to the research by producing comparable large multilingual data sets (Cotterell et al., 2016; Cotterell et al., 2017) consistently annotated with the Unimorph scheme (Sylak-Glassman et al., 2015; Kirov et al., 2018). Overwhelmingly, most recent work in inflection generation has employed neural sequence-to-sequence models with atte"
C18-1137,W16-2003,0,0.0308496,"g (Dreyer and Eisner, 2011; Durrett and DeNero, 2013). In addition, two recent shared tasks hosted by SIGMORPHON and CoNLL have contributed to the research by producing comparable large multilingual data sets (Cotterell et al., 2016; Cotterell et al., 2017) consistently annotated with the Unimorph scheme (Sylak-Glassman et al., 2015; Kirov et al., 2018). Overwhelmingly, most recent work in inflection generation has employed neural sequence-to-sequence models with attention (Sutskever et al., 2014; Bahdanau et al., 2015) in supervised scenarios (Kann and Sch¨utze, 2016; Faruqui ¨ et al., 2016; Ostling, 2016; Makarov et al., 2017; Aharoni and Goldberg, 2017), often with data augmentation mechanisms in low-resource settings (Bergmanis et al., 2017; Silfverberg et al., 2017; Kann and Sch¨utze, 2017). The PCFP has been explicitly addressed by recurrent neural generators as well (Malouf, 2016; Malouf, 2017). While neural models perform quite well on such tasks—even in low-resource settings—their parameter opacity makes it difficult to extract concise linguistic generalizations that can be interpreted and compared with linguist analyses. Since morphological annotation is usually done at the word-level"
C18-1137,W17-0418,1,0.782897,"ic generalizations that can be interpreted and compared with linguist analyses. Since morphological annotation is usually done at the word-level (flowers ↔ l+PL),4 recent work has also attempted to learn the latent segmentation and recover the different allomorphs for stems and affixes (flower = l, s=PL). This is arguably similar to what an L1-learner does, and the kind of evidence L1 learners have—words with semantic (l) and grammatical (+PL) content deducible from context, but crucially missing information about how these correspond to some subsequence of phonemes in an inflected word form. Silfverberg and Hulden (2017a) and Silfverberg and Hulden (2017b) propose a datadriven method that searches the space of possible allomorph and grammatical tag associations, and favors a small model. Similar approaches are found in Hayes (2018) who similarly argues that allomorphs can be detected “even if we don’t yet understand the phonology”. Our work, apart from providing an explicit model for paradigms, also implicitly extracts the different allomorphs used, something that falls out as a byproduct of the paradigm generalizations in section 4 and inference from partial inflection tables in section 5. 3 Data We use two"
C18-1137,W17-4107,1,0.839424,"ic generalizations that can be interpreted and compared with linguist analyses. Since morphological annotation is usually done at the word-level (flowers ↔ l+PL),4 recent work has also attempted to learn the latent segmentation and recover the different allomorphs for stems and affixes (flower = l, s=PL). This is arguably similar to what an L1-learner does, and the kind of evidence L1 learners have—words with semantic (l) and grammatical (+PL) content deducible from context, but crucially missing information about how these correspond to some subsequence of phonemes in an inflected word form. Silfverberg and Hulden (2017a) and Silfverberg and Hulden (2017b) propose a datadriven method that searches the space of possible allomorph and grammatical tag associations, and favors a small model. Similar approaches are found in Hayes (2018) who similarly argues that allomorphs can be detected “even if we don’t yet understand the phonology”. Our work, apart from providing an explicit model for paradigms, also implicitly extracts the different allomorphs used, something that falls out as a byproduct of the paradigm generalizations in section 4 and inference from partial inflection tables in section 5. 3 Data We use two"
C18-1137,K17-2010,1,0.796272,"by producing comparable large multilingual data sets (Cotterell et al., 2016; Cotterell et al., 2017) consistently annotated with the Unimorph scheme (Sylak-Glassman et al., 2015; Kirov et al., 2018). Overwhelmingly, most recent work in inflection generation has employed neural sequence-to-sequence models with attention (Sutskever et al., 2014; Bahdanau et al., 2015) in supervised scenarios (Kann and Sch¨utze, 2016; Faruqui ¨ et al., 2016; Ostling, 2016; Makarov et al., 2017; Aharoni and Goldberg, 2017), often with data augmentation mechanisms in low-resource settings (Bergmanis et al., 2017; Silfverberg et al., 2017; Kann and Sch¨utze, 2017). The PCFP has been explicitly addressed by recurrent neural generators as well (Malouf, 2016; Malouf, 2017). While neural models perform quite well on such tasks—even in low-resource settings—their parameter opacity makes it difficult to extract concise linguistic generalizations that can be interpreted and compared with linguist analyses. Since morphological annotation is usually done at the word-level (flowers ↔ l+PL),4 recent work has also attempted to learn the latent segmentation and recover the different allomorphs for stems and affixes (flower = l, s=PL). This"
C18-1137,P15-2111,0,0.0312277,"d the LCS as a core strategy in formal definitions of morphological paradigm and analogy. Further linguistic arguments favoring the LCS-model are given in Lee (2015). Learning to generalize from inflection tables to unseen forms has attracted much recent interest in natural language processing (Dreyer and Eisner, 2011; Durrett and DeNero, 2013). In addition, two recent shared tasks hosted by SIGMORPHON and CoNLL have contributed to the research by producing comparable large multilingual data sets (Cotterell et al., 2016; Cotterell et al., 2017) consistently annotated with the Unimorph scheme (Sylak-Glassman et al., 2015; Kirov et al., 2018). Overwhelmingly, most recent work in inflection generation has employed neural sequence-to-sequence models with attention (Sutskever et al., 2014; Bahdanau et al., 2015) in supervised scenarios (Kann and Sch¨utze, 2016; Faruqui ¨ et al., 2016; Ostling, 2016; Makarov et al., 2017; Aharoni and Goldberg, 2017), often with data augmentation mechanisms in low-resource settings (Bergmanis et al., 2017; Silfverberg et al., 2017; Kann and Sch¨utze, 2017). The PCFP has been explicitly addressed by recurrent neural generators as well (Malouf, 2016; Malouf, 2017). While neural model"
D18-1315,P17-1183,0,0.0625453,";PRS;2;SG haga ponga SBJV;PRS;1;SG NFIN SBJV;PRS;3;PL NFIN SBJV;PRS;1;SG … pondrá IND;FUT;3;SG SBJV;PRS;2;SG IND;FUT;3;SG hiciera … SBJV;PST;3;SG SBJV;PST;1;SG … SBJV;PST;3;SG SBJV;PST;1;SG … SBJV;PST;3;SG SBJV;PST;1;SG Figure 1: Illustration of the PCFP using a fraction of Spanish verb tables: given such partially filled paradigms, the task is to fill in all the missing forms. Related Work Neural models have recently been shown to be highly competitive in many different tasks of learning supervised morphological inflection (Faruqui et al., 2016; Kann and Sch¨utze, 2016; Makarov et al., 2017; Aharoni and Goldberg, 2017) and derivation (Cotterell et al., 2017b). Most current architectures are based on encoderdecoder models (Sutskever et al., 2014), and usually contain an attention component (Bahdanau et al., 2015). The SIGMORPHON (Cotterell et al., 2016) and CoNLL-SIGMORPHON (Cotterell et al., 2017a, 2018) shared tasks in recent years have explored morphological inflection but not explicitly the PCFP. In the 2017 task, participants were given full paradigms—i.e. a listing of all forms—of 2883 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2883–2889 c Brussels, Be"
D18-1315,E14-1060,1,0.806534,"Missing"
D18-1315,N15-1107,1,0.900177,"Missing"
D18-1315,W13-3520,0,0.032896,"ed collections of morphological inflection tables based on Wiktionary. We conduct experiments on noun and verb paradigms from eight languages.6 Not all languages have 1,000 noun and verb tables. Hence, our selection is not complete as seen in Table 3. We conduct experiments on two different sets of tables: (1) we randomly sample 1,000 tables for each language and part-of-speech, and (2) we select Unimorph tables including some of the 10,000 most common word forms according to Wikipedia frequency. The Wikipedia word frequencies are based on plain Wikipedia text dumps from the Polyglot project (Al-Rfou et al., 2013). Georgian and Latin did not have a Polyglot Wikipedia so we excluded those. Moreover, we excluded Latvian verbs because there was very little overlap between the most frequent Wikipedia word forms and Unimorph table entries (< 200 forms occurred in both). Details for both types of data sets are given in Tables 3 and 2. F INNISH N OUNS F INNISH V ERBS F RENCH V ERBS G ERMAN V ERBS L ATVIAN N OUNS S PANISH V ERBS T URKISH N OUNS # Tables Table Size 1,335 513 1,131 657 802 1,067 884 27.3 38.9 47.8 24.9 12.8 62.8 78.5 Table 2: Details for inflection tables chosen according to Wikipedia word frequ"
D18-1315,K18-3001,1,0.840202,"Missing"
D18-1315,K17-2001,1,0.9136,"Missing"
D18-1315,D17-1074,0,0.0344831,"Missing"
D18-1315,N16-1077,0,0.054421,";PRS;3;SG SBJV;PRS;1;SG SBJV;PRS;3;SG SBJV;PRS;2;SG IND;FUT;3;SG SBJV;PRS;2;SG haga ponga SBJV;PRS;1;SG NFIN SBJV;PRS;3;PL NFIN SBJV;PRS;1;SG … pondrá IND;FUT;3;SG SBJV;PRS;2;SG IND;FUT;3;SG hiciera … SBJV;PST;3;SG SBJV;PST;1;SG … SBJV;PST;3;SG SBJV;PST;1;SG … SBJV;PST;3;SG SBJV;PST;1;SG Figure 1: Illustration of the PCFP using a fraction of Spanish verb tables: given such partially filled paradigms, the task is to fill in all the missing forms. Related Work Neural models have recently been shown to be highly competitive in many different tasks of learning supervised morphological inflection (Faruqui et al., 2016; Kann and Sch¨utze, 2016; Makarov et al., 2017; Aharoni and Goldberg, 2017) and derivation (Cotterell et al., 2017b). Most current architectures are based on encoderdecoder models (Sutskever et al., 2014), and usually contain an attention component (Bahdanau et al., 2015). The SIGMORPHON (Cotterell et al., 2016) and CoNLL-SIGMORPHON (Cotterell et al., 2017a, 2018) shared tasks in recent years have explored morphological inflection but not explicitly the PCFP. In the 2017 task, participants were given full paradigms—i.e. a listing of all forms—of 2883 Proceedings of the 2018 Conference on Empi"
D18-1315,W14-2804,1,0.754779,"Missing"
D18-1315,E17-1049,0,0.194971,"Missing"
D18-1315,P16-2090,0,0.0802553,"Missing"
D18-1315,L18-1293,1,0.841548,"chs without batching. We train 10 models for every language and part-of-speech and apply majority voting to get the final output forms. All models were implemented using DyNet (Neubig et al., 2017). 3 Table Size Unique Forms per Table 27.7 39.0 47.5 19.0 28.9 11.9 99.8 11.6 62.5 74.4 25.7 37.6 36.1 16.9 12.3 7.2 94.8 7.6 52.1 54.8 F IN N F IN V F RE V G EO N G ER V L AT N L AT V L AV N S PA V T UR N Table 3: Details for randomly sampled inflection tables. The data for each language and part-of-speech consist of 1,000 tables. Data We use UniMorph morphological paradigm data in our experiments (Kirov et al., 2018). Unimorph data sets are crowd-sourced collections of morphological inflection tables based on Wiktionary. We conduct experiments on noun and verb paradigms from eight languages.6 Not all languages have 1,000 noun and verb tables. Hence, our selection is not complete as seen in Table 3. We conduct experiments on two different sets of tables: (1) we randomly sample 1,000 tables for each language and part-of-speech, and (2) we select Unimorph tables including some of the 10,000 most common word forms according to Wikipedia frequency. The Wikipedia word frequencies are based on plain Wikipedia te"
D18-1315,C18-1137,1,0.834426,"Missing"
E14-1060,E09-2008,1,0.511733,"illustrated in figure 1. The first step, extracting the LCS from a collection of strings, is the well-known multiple longest common subsequence problem (MLCS). It is known to be NP-hard (Maier, 1978). Although the number of strings to find the LCS from may be rather large in real-world data, we find that a few sensible heuristic techniques allow us to solve this problem efficiently for practical linguistic material, i.e., inflection tables. We calculate the LCS by calculating intersections of finite-state machines that encode all subsequences of all words, using the foma finite-state toolkit (Hulden, 2009).3 While for most tables there is only one way to segment the LCS in the various forms, some ambiguous corner cases need to be resolved by imposing additional criteria for the segmentation, given in steps 2(a) and 2(b). As an example, consider a snippet of a small conjugation table for the Spanish verb comprar (to buy), comprar#compra#compro. Obviously the LCS is compr—however, this can be distributed in two different ways across the strings, as seen below. Maximally general paradigms In order to generalize as much as possible from an inflection table, we extract from it what we call the maxim"
E14-1060,W06-3209,0,0.237385,"resources presupposes a linguist who constructs a detailed morphological grammar that models inflection, compounding, and other morphological and phonolog1 Our programs and the datasets used, including the evaluation procedure for this paper, are freely available at https://svn.spraakbanken.gu.se/clt/ eacl/2014/extract 569 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013). Eskander et"
E14-1060,clement-etal-2004-morphology,0,0.138752,"Missing"
E14-1060,E12-1066,0,0.0641857,"Missing"
E14-1060,D11-1057,0,0.523068,"rence of the European Chapter of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013). Eskander et al. (2013) shares many of the goals in this paper, but is more supervised in that it focuses on learning inflectional classes from richer annotation. A major departure from much previous work is that we do not attempt to encode variation as string-changing operations, say by string edits (Dreyer and Eisner, 2011) or transformation rules (Lind´en, 2008; Durrett and"
E14-1060,W02-0604,0,0.115644,"lable at https://svn.spraakbanken.gu.se/clt/ eacl/2014/extract 569 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013). Eskander et al. (2013) shares many of the goals in this paper, but is more supervised in that it focuses on learning inflectional classes from richer annotation. A major departure from much previous work is that we do not attempt to encode variation as string-changing operations, s"
E14-1060,N13-1138,0,0.537708,"of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013). Eskander et al. (2013) shares many of the goals in this paper, but is more supervised in that it focuses on learning inflectional classes from richer annotation. A major departure from much previous work is that we do not attempt to encode variation as string-changing operations, say by string edits (Dreyer and Eisner, 2011) or transformation rules (Lind´en, 2008; Durrett and DeNero, 2013) that perform map"
E14-1060,D13-1105,0,0.320918,"Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013). Eskander et al. (2013) shares many of the goals in this paper, but is more supervised in that it focuses on learning inflectional classes from richer annotation. A major departure from much previous work is that we do not attempt to encode variation as string-changing operations, say by string edits (Dreyer and Eisner, 2011) or transformation rules (Lind´en, 2008; Durrett and DeNero, 2013) that perform mappings between forms. Rather, our goal is to encode all variation within paradigms by presenting them in a sufficiently generic fashion so as to allow affixation processes, phonological alternations as well as orth"
E14-1060,N01-1024,0,0.238244,"ion of large-scale lexical resources presupposes a linguist who constructs a detailed morphological grammar that models inflection, compounding, and other morphological and phonolog1 Our programs and the datasets used, including the evaluation procedure for this paper, are freely available at https://svn.spraakbanken.gu.se/clt/ eacl/2014/extract 569 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013)."
E14-1060,J01-2001,0,0.305368,"ly, the construction of large-scale lexical resources presupposes a linguist who constructs a detailed morphological grammar that models inflection, compounding, and other morphological and phonolog1 Our programs and the datasets used, including the evaluation procedure for this paper, are freely available at https://svn.spraakbanken.gu.se/clt/ eacl/2014/extract 569 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as"
E14-1060,J11-2002,0,0.149114,"Missing"
E14-1060,A97-1016,0,0.10945,"cond main type of error (210 out of 1000) is confusion with the unseen paradigm of parti (party), which inflects similarly to akademi, but with a difference in gender—difficult to predict from surface forms—that manifests itself in two out of eight word forms. 6 standard features to ascertain that word forms in hypothetical reconstructed inflection tables maintain similar shapes to ones seen during training. One can also investigate ways to collapse paradigms further by generalizing over phonological alternations and by learning alternation rules from the induced paradigms (Koskenniemi, 1991; Theron and Cloete, 1997; Koskenniemi, 2013). Finally, we are working on a separate interactive graphical morphological tool in which we plan to integrate the methods presented in this paper. 7 Conclusion We have presented a language-independent method for extracting paradigms from inflection tables and for representing and generalizing the resulting paradigms.7 Central to the process of paradigm extraction is the notion of maximally general paradigm, which we define as the inflection table, with all of the common string subsequences forms represented by variables. The method is quite uncomplicated and outputs human-"
E14-1060,P99-1037,0,0.208869,"Missing"
E14-1060,P00-1027,0,0.27012,"e for this paper, are freely available at https://svn.spraakbanken.gu.se/clt/ eacl/2014/extract 569 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569–578, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics 3.1 unlabeled data (Goldsmith, 2001; Schone and Jurafsky, 2001; Chan, 2006; Creutz and Lagus, 2007; Monson et al., 2008). Hammarstr¨om and Borin (2011) provides a current overview of unsupervised learning. Previous work with similar semi-supervised goals as the ones in this paper include Yarowsky and Wicentowski (2000), Neuvel and Fulop (2002), Cl´ement et al. (2004). Recent machine learning oriented work includes Dreyer and Eisner (2011) and Durrett and DeNero (2013), which documents a method to learn orthographic transformation rules to capture patterns across inflection tables. Part of our evaluation uses the same dataset as Durrett and DeNero (2013). Eskander et al. (2013) shares many of the goals in this paper, but is more supervised in that it focuses on learning inflectional classes from richer annotation. A major departure from much previous work is that we do not attempt to encode variation as stri"
francom-etal-2014-activ,francom-etal-2010-specialized,1,\N,Missing
francom-etal-2014-activ,E09-2008,1,\N,Missing
francom-etal-2014-activ,P94-1013,0,\N,Missing
francom-etal-2014-activ,taule-etal-2008-ancora,0,\N,Missing
francom-hulden-2008-parallel,J98-4004,0,\N,Missing
francom-hulden-2008-parallel,mengel-lezius-2000-xml,0,\N,Missing
francom-hulden-2008-parallel,J93-2004,0,\N,Missing
francom-hulden-2008-parallel,P03-1054,0,\N,Missing
francom-hulden-2008-parallel,J07-3004,0,\N,Missing
francom-hulden-2008-parallel,W07-1212,0,\N,Missing
francom-hulden-2008-parallel,A97-1011,0,\N,Missing
hulden-francom-2012-boosting,carreras-etal-2004-freeling,0,\N,Missing
hulden-francom-2012-boosting,C90-3030,0,\N,Missing
hulden-francom-2012-boosting,W07-1709,0,\N,Missing
hulden-francom-2012-boosting,P01-1035,0,\N,Missing
hulden-francom-2012-boosting,A00-1031,0,\N,Missing
hulden-francom-2012-boosting,P98-1062,0,\N,Missing
hulden-francom-2012-boosting,P98-1063,0,\N,Missing
hulden-francom-2012-boosting,C98-1060,0,\N,Missing
hulden-francom-2012-boosting,taule-etal-2008-ancora,0,\N,Missing
hulden-francom-2012-boosting,A94-1008,0,\N,Missing
K17-1030,N15-1107,1,0.830413,"of the OCP (see e.g. McCarthy (1986); Odden (1988)). Some languages (such as Finnish and Hawaiian) yield splits that almost always coincide with a single phonological feature, whereas other languages do not. Smaller inventories typically yield more robust results, although this may be partly due to chance factors—there are more ways to split a small set according to distinctive features than large sets. Of interest is the utility of the extracted clusters in various supervised and semi-supervised NLP applications. For example, in algorithms that learn to inflect words from annotated examples (Ahlberg et al., 2015; Cotterell et al., 2016), it is often useful to have a subdivision of the segments that alternate, since this allows one to generalize behavior of classes of segments or graphemes, similar to the way e.g. Brown clusters (Brown et al., 1992) generalize over classes of words. Labeling segments with the position in a clustering tree and using that as a feature, for instance, is a cheap and straightforward way to inject this kind of knowledge into supervised systems designed to operate over many languages. юмолануолиїнимижи ноулисѣханолиомобоу юмоласоудьнииохови (c) абвджилмносухьюїѣ бвджлмнсух в"
K17-1030,boruta-jastrzebska-2012-phonemic,0,0.0695139,"Missing"
K17-1030,J92-4003,0,0.515349,"d more robust results, although this may be partly due to chance factors—there are more ways to split a small set according to distinctive features than large sets. Of interest is the utility of the extracted clusters in various supervised and semi-supervised NLP applications. For example, in algorithms that learn to inflect words from annotated examples (Ahlberg et al., 2015; Cotterell et al., 2016), it is often useful to have a subdivision of the segments that alternate, since this allows one to generalize behavior of classes of segments or graphemes, similar to the way e.g. Brown clusters (Brown et al., 1992) generalize over classes of words. Labeling segments with the position in a clustering tree and using that as a feature, for instance, is a cheap and straightforward way to inject this kind of knowledge into supervised systems designed to operate over many languages. юмолануолиїнимижи ноулисѣханолиомобоу юмоласоудьнииохови (c) абвджилмносухьюїѣ бвджлмнсух вджлмнсх бу аиоьюїѣ июї аоьѣ (d) (e) C: б в ж л м н с у х ь V: ѣ ю а д ї и о C: б в ж л м н с у х V: ѣ ь ю а д ї и о (f) C: б в д ж л м н с у х V: ѣ ь ю а ї и о Figure 4: Clustering the graphemes in the 54symbol birch bark letter 292 manuscri"
K17-1030,P13-1150,0,0.217516,"consonants and vowels without labeled data, rather than identifying distinctive features. Following that, the general algorithm is developed in section 3, after which the experiments on both phonemic and graphemic representations in section 4 are reported. Four experiments are evaluated. The first uses phonemic data from 9 languages for clustering and evaluates clustering along distinctive feature lines. The second is a graphemic experiment that uses a data set of Bible translations in 503 languages where the task is to distinguish the vowels from the consonants; here, results are compared to Kim and Snyder (2013) on the same data set. That data is slightly noisy, motivating the third experiment, which is also graphemic and evaluates consonant-vowel distinctions on vetted word lists from data taken from the ACL SIG MORPHON shared task on morphological reinflection (Cotterell et al., 2016). The ability of a tierbased variant of the algorithm to separate coronals from non-coronals is evaluated in a fourth experiment where Universal Dependencies corpora (Nivre et al., 2017) are used. The main results are presented in section 5. Given the high accuracy of the algorithm in C/V distinction with very little d"
K17-1030,P06-2065,0,0.0463139,"s top-level objective function that we want to maximize can be expressed as as a proxy for phonology since textual data is easier to come by. A spectral method was introduced by Moler and Morrison (1983) with the explicit purpose of distinguishing consonants from vowels by a dimensionality reduction on a segment co-occurrence matrix through singular value decomposition (SVD). An almost identical SVD-based approach was later applied to phonological data by Goldsmith and Xanthos (2009). Hidden Markov Models coupled with the EM algorithm have also been used to learn consonant-vowel distinctions (Knight et al., 2006) as well as other latent structure, such as vowel harmony (Goldsmith and Xanthos, 2009). Kim and Snyder (2013) use Bayesian inference supported by simultaneous language clustering to infer C/V-distinctions in a large number of scripts simultaneously. We compare our results against a data set published in conjunction with that work. More directly related to the current work are Mayer et al. (2010) and Mayer and Rohrdantz (2013) who work with models for visualizing consonant co-occurrence in a corpus. 2.1 Sukhotin’s algorithm Sukhotin’s algorithm (Sukhotin, 1962, 1973) is a well-known algorithm"
K17-1030,P13-4013,0,0.0142231,"ter applied to phonological data by Goldsmith and Xanthos (2009). Hidden Markov Models coupled with the EM algorithm have also been used to learn consonant-vowel distinctions (Knight et al., 2006) as well as other latent structure, such as vowel harmony (Goldsmith and Xanthos, 2009). Kim and Snyder (2013) use Bayesian inference supported by simultaneous language clustering to infer C/V-distinctions in a large number of scripts simultaneously. We compare our results against a data set published in conjunction with that work. More directly related to the current work are Mayer et al. (2010) and Mayer and Rohrdantz (2013) who work with models for visualizing consonant co-occurrence in a corpus. 2.1 Sukhotin’s algorithm Sukhotin’s algorithm (Sukhotin, 1962, 1973) is a well-known algorithm for separating consonants from vowels in orthographic data; good descriptions of the algorithm are given in Guy (1991) and Sassoon (1992). The idea is to start with the assumption that all segments in a corpus are consonants, then repeatedly and greedily find the segment that co-occurs most with other segments, and declare that a vowel. This is performed until a stopping condition is reached. The algorithm is known to perform"
K17-1030,taule-etal-2008-ancora,0,0.039826,"Missing"
K17-1030,W10-2110,0,0.0799381,"Missing"
K17-2001,E14-1060,1,0.855884,"Missing"
K17-2001,P17-1136,0,0.0562959,"Missing"
K17-2001,N15-1107,1,0.861491,"Missing"
K17-2001,chrupala-etal-2008-learning,0,0.152497,"Missing"
K17-2001,W16-2004,0,0.0654088,"Missing"
K17-2001,P14-2102,1,0.910119,"Missing"
K17-2001,Q15-1031,1,0.919531,"Missing"
K17-2001,P16-1156,1,0.87299,"Missing"
K17-2001,K17-2002,0,0.132442,"Missing"
K17-2001,E17-2120,1,0.859022,"Missing"
K17-2001,E17-1049,1,0.894341,"Missing"
K17-2001,N07-1048,0,0.21796,"Missing"
K17-2001,P17-1182,1,0.876831,"Missing"
K17-2001,D09-1011,1,0.888474,"Missing"
K17-2001,D08-1113,1,0.874358,"Missing"
K17-2001,P16-2090,0,0.46072,"Missing"
K17-2001,N13-1138,0,0.147728,"Missing"
K17-2001,P08-1115,0,0.089787,"Missing"
K17-2001,L16-1498,1,0.792213,"Missing"
K17-2001,N16-1077,1,0.812854,"Missing"
K17-2001,W10-2211,0,0.123726,"Missing"
K17-2001,W16-2006,0,0.0673676,"Missing"
K17-2001,P82-1020,0,0.75423,"Missing"
K17-2001,P08-1103,0,0.0541683,"Missing"
K17-2001,D15-1272,1,0.92636,"Missing"
K17-2001,D14-1095,0,0.0938069,"Missing"
K17-2001,K17-2011,0,0.0350181,"Missing"
K17-2001,N15-1093,0,0.19098,"Missing"
K17-2001,K17-2008,0,0.055504,"Missing"
K17-2001,K17-2010,0,0.158704,"Missing"
K17-2001,W16-2007,0,\N,Missing
K17-2001,L16-1497,1,\N,Missing
K17-2001,K17-2012,0,\N,Missing
K17-2001,K17-2003,0,\N,Missing
K17-2001,P17-1029,0,\N,Missing
K18-3001,K18-3001,1,0.103672,"Missing"
K18-3001,P16-2090,1,0.838493,"Missing"
K18-3001,K17-2003,1,0.836665,"Missing"
K18-3001,K17-2010,1,0.734971,"Missing"
K18-3001,W18-6011,1,0.913422,"and a target UniMorph sentence is shown in Figure 3. Since the selection of languages in task 2 is small and we do not attempt to correct annotation errors in the UD source materials, conversion between UD and UniMorph morphosyntactic descriptions is generally straightforward.11 However, UD descriptions are more fine-grained than their UniMorph equivalents. For example, UD denotes lexical features such as noun gender which are inherent features of a lexeme possessed by all of its word forms. Such inherent features are missing from UniMorph which exclusively annotates inflectional morphology (McCarthy et al., 2018). Therefore, UD fea$ → sta$ ti$ → dista$ koti$ → kodista$ i$ → ista$ oti$ → odista$ Such rules are then extracted from each example inflection in the training data. At generation time, the longest matching left hand side of a rule is identified and applied to the citation form. For example, if the Finnish noun luoti ‘bullet’ were to be inflected in the elative (N;IN+ABL;SG) using only the extracted rules given above, the transformation oti$ → odista$ would be triggered, producing the output luodista. In case there are multiple candidate rules of equally long left hand sides that all match, tie"
K18-3001,K18-3012,0,0.30177,"Missing"
K18-3001,K18-3015,0,0.276525,"Missing"
K18-3001,P15-2111,1,\N,Missing
K18-3001,K17-2002,1,\N,Missing
K18-3001,K17-3001,0,\N,Missing
K18-3001,W17-4110,1,\N,Missing
K18-3001,N18-2087,1,\N,Missing
K18-3001,P18-1245,1,\N,Missing
K18-3001,L18-1293,1,\N,Missing
K18-3001,K18-3004,0,\N,Missing
K18-3001,K18-3010,0,\N,Missing
K18-3001,K18-3013,0,\N,Missing
K18-3001,K18-3003,0,\N,Missing
K18-3001,K18-3016,0,\N,Missing
K18-3001,K18-3005,0,\N,Missing
K18-3001,W16-2006,0,\N,Missing
K18-3001,K17-2008,1,\N,Missing
K18-3001,K17-2005,0,\N,Missing
K18-3001,K18-3008,0,\N,Missing
K18-3001,K18-3007,0,\N,Missing
L16-1169,almeida-etal-2010-bigorna,0,0.063694,"Missing"
L16-1169,carreras-etal-2004-freeling,0,0.0661537,"Missing"
L16-1169,E09-2008,1,0.824088,"Missing"
L16-1169,W11-2605,1,0.780727,"Missing"
L16-1169,N07-1047,0,0.017361,"e used for all word pairs. As discussd above, we apply the strongest method found in our previous work with dialect normalization (Etxeberria et al., 2014). This approach uses Phonetisaurus, a Weighted Finite State Transducer (WFST) driven phonology tool (Novak et al., 2012), based on OpenFST (Allauzen et al., 2007), which learns mapping of phonological changes using a noisy channel model. After data preparation, where we collect pairs into a dictionary, the application of the tool includes three major steps: 1. Sequence alignment. The alignment algorithm is based on the algorithm proposed in Jiampojamarn et al. (2007) and includes some minor modifications to it. 2. Model training. An n-gram language model is trained using the aligned data and then converted into a WFST. For producing the language model, we used the Language Model training toolkit NGramLibrary for our experiments, although several alternative similar tools exist that all cooperate with Phonetisaurus: mitlm, NGramLibrary, SRILM, SRILM MaxEnt extension, CMU-Cambridge SLM. 3. Decoding. The default decoder used in the WFSTbased approach finds the best hypothesis for the input words given the WFST obtained in the previous step. It is also possib"
L16-1169,W10-2209,0,0.311035,"cs are not shared by historical and dialectal text resources and, therefore, standard NLP tools can often not be directly applied to such corpora. Traditionally, some degree of lexical normalization is performed when working with historical and dialectal texts in order to link each variant to its corresponding standard form. Once the texts are normalized, standard NLP and IR (Information Retrieval) tools can be applied to the corpora with reasonably high performance. Canonicalization is the term used in this area, a term which referring to mapping each non-standard variant to a canonical one (Jurish, 2010). Accurate normalization can be very useful: by carrying out such normalization before indexing historical texts, for example, it is possible to perform queries against texts using standard words or lemmata and find their historical counterparts. Normalization has the potential to make ancient documents more accessible for non-expert users. NLP tools for standard languages also work better after normalization, which in turn allows for subsequent deeper processing to be carried out, e.g. information extraction for the purpose of identification of historical events and other applications. In thi"
L16-1169,N01-1020,0,0.390811,"Missing"
L16-1169,W12-6208,0,0.700593,"events and other applications. In this paper, we propose and evaluate an approach based on a model that is often used for similar tasks such as the induction of phonology and learning grapheme-to-phoneme conversion models. Our working hypothesis is that, as in the case of dialectal variants, the differences between ancient and current standard Basque seem to be mainly phonological, and therefore, we have reapplied the best method used in our previous work with dialects (Etxeberria et al., 2014). This method uses Phonetisaurus,1 a Weighted Finite State Transducer (WFST) driven phonology tool (Novak et al., 2012) which learns to map phonological changes using a noisy channel model. It is a solution that uses a limited amount of supervision in order to achieve adequate performance without the need of an unrealistic amount of manual effort. This technique has been also performed for normalization of non-standard texts in social media (Alegria et al., 2013). Experiments for Basque were carried out using a corpus of old Basque (Section 3 in this article). In order to compare our results with the systems used for Spanish (Porta et al., 2013) and for Slovene (Scherrer and Erjavec, 2015), we have also evalua"
L16-1169,P07-3010,0,0.0482343,"Missing"
L16-1169,E12-2021,0,0.072954,"Missing"
L16-1410,E14-1060,1,0.835481,"ed x1 ed (b) Generalized into paradigms (c) Paradigms collapsed Figure 1: Illustration of generalizing inflection tables into abstract paradigms: (a) a number of inflection tables are given; (b) the aligned longest common subsequence is extracted; (c) resulting identical paradigms are merged. If the resulting paradigm is interpreted as a function, f1 (shr, nk) produces shrink, shrank, shrunk. functions that model inflectional behavior are built by hand (Forsberg and Ranta, 2004; Forsberg et al., 2006; Détrez and Ranta, 2012). As a starting point to the current work, we assume the approach of Ahlberg et al. (2014) and Ahlberg et al. (2015), which provide a mechanism to learn a specific type of function automatically from labeled data given to the algorithm in the form of inflected word forms grouped into inflection tables. In that work, different inflections and derived forms of a lemma are generalized into so-called ‘abstract paradigms’. These paradigm functions essentially generalize concrete manifestations of word inflections for specific lemmas, allowing those inflections to be carried out for previously unseen words. This generalization is done by extracting the Longest Common Subsequence (LCS) fo"
L16-1410,N15-1107,1,0.812339,"Missing"
L16-1410,P08-1087,0,0.0378013,"e to map inflected forms of previously unseen words into lemmas and corresponding morphosyntactic descriptions. We evaluate the system when provided with inflection tables for several languages collected from the Wiktionary. Keywords: learning morphology, paradigm induction, finite-state morphology 1. Introduction Morphological analysis tools that provide detailed morphosyntactic descriptions (MSDs) and lemmatization of arbitrary word forms in some language are widely held to be fundamental for good performance of many higher-level NLP applications (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012), particularly for languages with rich inflectional and derivational morphology. Hand-built systems, often modeled as finite-state transducers, offer very reliable morphological parses, but are time-consuming to create, and require significant linguistic expertise from the developers (Maxwell, 2015). In many cases, however, finding collated example inflections on a large scale for some language through resources such as the Wiktionary or simply by consulting a speaker of the language is far less laborious than the elaborate linguistic modeling required t"
L16-1410,E12-1066,0,0.0288541,"1 a x2 x1 u x 2 x1 u x 2 x1 x1 ed x1 ed x 1 i x2 x 1 x1 a x2 x1 ed x1 u x2 x1 ed f1 f2 x1 x1 ed x1 ed (b) Generalized into paradigms (c) Paradigms collapsed Figure 1: Illustration of generalizing inflection tables into abstract paradigms: (a) a number of inflection tables are given; (b) the aligned longest common subsequence is extracted; (c) resulting identical paradigms are merged. If the resulting paradigm is interpreted as a function, f1 (shr, nk) produces shrink, shrank, shrunk. functions that model inflectional behavior are built by hand (Forsberg and Ranta, 2004; Forsberg et al., 2006; Détrez and Ranta, 2012). As a starting point to the current work, we assume the approach of Ahlberg et al. (2014) and Ahlberg et al. (2015), which provide a mechanism to learn a specific type of function automatically from labeled data given to the algorithm in the form of inflected word forms grouped into inflection tables. In that work, different inflections and derived forms of a lemma are generalized into so-called ‘abstract paradigms’. These paradigm functions essentially generalize concrete manifestations of word inflections for specific lemmas, allowing those inflections to be carried out for previously unsee"
L16-1410,N13-1138,0,0.0215058,"data and hence gets a parse from O, while the second word aceleran ‘accelerate’ is not, and only gets parses from C and U with increasing tolerance of variable instantiation. • Original: this is an analyzer where no variables are generalized; any xi must be exactly one of those seen in the training data. • Constrained: this is an analyzer where variables are constrained as described above in section 3. • Unconstrained: this is an analyzer where all variables are completely unconstrained, i.e. match the regular expression Σ+ . Evaluation To evaluate the system we used the data set published by Durrett and DeNero (2013) (D&DN13). This includes fully inflected forms for thousands of lemmas in three languages: German (nouns and verbs), Spanish (verbs), and Finnish (nouns+adjectives and verbs). These forms are organized into inflection tables. We used the same train/test splits as in the source, and set aside all the word forms from 200 inflection tables for testing. The task then consisted of providing analyses for each unseen form. We test on each part-of-speech separately, and also provide an evaluation on a combined test set where the part-of-speech is not known. The evaluation setup is the one described ab"
L16-1410,hulden-francom-2012-boosting,1,0.848986,"nseen words into lemmas and corresponding morphosyntactic descriptions. We evaluate the system when provided with inflection tables for several languages collected from the Wiktionary. Keywords: learning morphology, paradigm induction, finite-state morphology 1. Introduction Morphological analysis tools that provide detailed morphosyntactic descriptions (MSDs) and lemmatization of arbitrary word forms in some language are widely held to be fundamental for good performance of many higher-level NLP applications (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012), particularly for languages with rich inflectional and derivational morphology. Hand-built systems, often modeled as finite-state transducers, offer very reliable morphological parses, but are time-consuming to create, and require significant linguistic expertise from the developers (Maxwell, 2015). In many cases, however, finding collated example inflections on a large scale for some language through resources such as the Wiktionary or simply by consulting a speaker of the language is far less laborious than the elaborate linguistic modeling required to produce a robust morphological analyze"
L16-1410,E09-2008,1,0.799808,"cted in the classical finite-state paradigm (Beesley and Karttunen, 2003), are non-probabilistic, and are designed to be highrecall, and hence to return all linguistically plausible analyses and lemmas, much like a hand-built morphological analyzer would which is extended with a ‘guesser’ module. Our tool takes as input a set of words annotated with lemma and MSD, grouped into inflection tables, and produces as output a morphological analyzer using the Xerox regular expression formalism (Karttunen et al., 1996), which we compile into a transducer with the open-source finitestate toolkit foma (Hulden, 2009).1 2. Background In this paper, we work with the idea that inflections and derivations of related word forms can be formally expressed as functions. Such a view has been commonly seen as an alternative to the finite-state morphology approach where 1 Our code is freely available together with the training/test setup employed in this paper at github.com/marfors/ paradigmextract swim ring jump type swam rang jumped typed (a) Inflection tables swum rung jumped typed x 1 i x2 x 1 i x2 x1 a x2 x1 a x2 x1 u x 2 x1 u x 2 x1 x1 ed x1 ed x 1 i x2 x 1 x1 a x2 x1 ed x1 u x2 x1 ed f1 f2 x1 x1 ed x1 ed (b)"
L16-1410,W14-2804,1,0.803717,"m in the form of inflected word forms grouped into inflection tables. In that work, different inflections and derived forms of a lemma are generalized into so-called ‘abstract paradigms’. These paradigm functions essentially generalize concrete manifestations of word inflections for specific lemmas, allowing those inflections to be carried out for previously unseen words. This generalization is done by extracting the Longest Common Subsequence (LCS) for all related word forms and then declaring that the graphemes or phonemes that participate in the LCS are variables of the resulting function (Hulden, 2014). The new representation can be interpreted as a function which generates specific new inflection tables, given a specific set of variable values. We 2578 refer the reader to Figure 1, which illustrates this process where paradigm functions are built from the extracted LCS from a number of inflected forms. In general, the algorithm often produces much fewer unique functions compared with the number of inflection tables given as input. One of the advantages of the model is that it produces a human-readable structured output which can be inspected and also used as a starting point for other lear"
L16-1410,W07-1709,0,0.0615132,"Missing"
L16-1410,I05-3005,0,0.0351936,"s into a finite-state transducer that is able to map inflected forms of previously unseen words into lemmas and corresponding morphosyntactic descriptions. We evaluate the system when provided with inflection tables for several languages collected from the Wiktionary. Keywords: learning morphology, paradigm induction, finite-state morphology 1. Introduction Morphological analysis tools that provide detailed morphosyntactic descriptions (MSDs) and lemmatization of arbitrary word forms in some language are widely held to be fundamental for good performance of many higher-level NLP applications (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012), particularly for languages with rich inflectional and derivational morphology. Hand-built systems, often modeled as finite-state transducers, offer very reliable morphological parses, but are time-consuming to create, and require significant linguistic expertise from the developers (Maxwell, 2015). In many cases, however, finding collated example inflections on a large scale for some language through resources such as the Wiktionary or simply by consulting a speaker of the language is far less laboriou"
L16-1410,zeman-2008-reusable,0,0.024575,"previously unseen words into lemmas and corresponding morphosyntactic descriptions. We evaluate the system when provided with inflection tables for several languages collected from the Wiktionary. Keywords: learning morphology, paradigm induction, finite-state morphology 1. Introduction Morphological analysis tools that provide detailed morphosyntactic descriptions (MSDs) and lemmatization of arbitrary word forms in some language are widely held to be fundamental for good performance of many higher-level NLP applications (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012), particularly for languages with rich inflectional and derivational morphology. Hand-built systems, often modeled as finite-state transducers, offer very reliable morphological parses, but are time-consuming to create, and require significant linguistic expertise from the developers (Maxwell, 2015). In many cases, however, finding collated example inflections on a large scale for some language through resources such as the Wiktionary or simply by consulting a speaker of the language is far less laborious than the elaborate linguistic modeling required to produce a r"
L16-1411,W12-0804,0,0.0196517,"arker, negative marker, and so on. Furthermore, N can also surface as ne, M, and me creating even more possibilities for homophony. Alternations like this produce a large number of potential parses for some word forms. Any disambiguation—although usually obvious at a glance for an expert—must then be performed by the user. ... 2.3. LEXICON Verb Previous computational work The only computational effort we know of regarding Sahidic Coptic is that of Orlandi (2004), which is largely a implementationless sketch concerning the possibility of automatically analyzing Coptic word forms (POS tagging). Ashton (2012) also presents a formal analysis of the socalled ‘second position clitics’ in Coptic through monadic second-order transductions. No implementation is given. A ongoing larger-scale project is Zeldes and Schroeder (2015) who have developed a coarse-grained tagset for Sahidic Coptic and trained a statistical tagger on small amounts of labeled text, producing reasonable accuracy on held-out data. No morphological analysis module is included and the authors rely on pre-tokenized text. 3. Implementation The analyzer is implemented using the foma toolkit (Hulden, 2009a). We use the lexc (Beesley and"
L16-1411,W98-1007,0,0.116611,"d (b) different roots have difTable 3:Alternationpossibilities in the Singular and Plural ferent morphological for prefixes or forms suffixes. of nouns in the Sahidic Coptic (Lambdin Implementing root-and-pattern morphology as 1988:1). transducers is generally well understood and there are relatively simple mechanisms for doing so: multi-tape automata (Kay, 3 In Coptic, these behave very much like ablauting verbs in Indo-European languages where a single vowel alternates, as for tense in some English lexemes run ∼ ran. 2585 coptic.lexc 1987; Hulden, 2009b), intersection of roots and patterns (Beesley, 1998), perhaps by specialized regular expression operations (Beesley and Karttunen, 2003), or through composition of transducers that directly modify vowels (Jaber and Delmonte, 2008). In the case of Coptic, however, we have decided to simply hard-code all the different verbal grades in the lexicon, because of the unpredictability. Some of the alternations are illustrated below. The final hurdle presented by Coptic is the enormous number of homophonous forms. Just the simple form N has an exceptional number of possible meanings in the lexicon including: genitive, dative, object marker, negative mar"
L16-1411,E09-2008,1,0.91534,"our separate entries for each verb in the lexicon and (b) different roots have difTable 3:Alternationpossibilities in the Singular and Plural ferent morphological for prefixes or forms suffixes. of nouns in the Sahidic Coptic (Lambdin Implementing root-and-pattern morphology as 1988:1). transducers is generally well understood and there are relatively simple mechanisms for doing so: multi-tape automata (Kay, 3 In Coptic, these behave very much like ablauting verbs in Indo-European languages where a single vowel alternates, as for tense in some English lexemes run ∼ ran. 2585 coptic.lexc 1987; Hulden, 2009b), intersection of roots and patterns (Beesley, 1998), perhaps by specialized regular expression operations (Beesley and Karttunen, 2003), or through composition of transducers that directly modify vowels (Jaber and Delmonte, 2008). In the case of Coptic, however, we have decided to simply hard-code all the different verbal grades in the lexicon, because of the unpredictability. Some of the alternations are illustrated below. The final hurdle presented by Coptic is the enormous number of homophonous forms. Just the simple form N has an exceptional number of possible meanings in the lexicon in"
L16-1411,W09-0803,1,0.894637,"our separate entries for each verb in the lexicon and (b) different roots have difTable 3:Alternationpossibilities in the Singular and Plural ferent morphological for prefixes or forms suffixes. of nouns in the Sahidic Coptic (Lambdin Implementing root-and-pattern morphology as 1988:1). transducers is generally well understood and there are relatively simple mechanisms for doing so: multi-tape automata (Kay, 3 In Coptic, these behave very much like ablauting verbs in Indo-European languages where a single vowel alternates, as for tense in some English lexemes run ∼ ran. 2585 coptic.lexc 1987; Hulden, 2009b), intersection of roots and patterns (Beesley, 1998), perhaps by specialized regular expression operations (Beesley and Karttunen, 2003), or through composition of transducers that directly modify vowels (Jaber and Delmonte, 2008). In the case of Coptic, however, we have decided to simply hard-code all the different verbal grades in the lexicon, because of the unpredictability. Some of the alternations are illustrated below. The final hurdle presented by Coptic is the enormous number of homophonous forms. Just the simple form N has an exceptional number of possible meanings in the lexicon in"
L16-1411,C90-3030,0,0.124196,"lt tasks for students new to the language appears to be the segmentation of texts, especially in cases of homophony or large units. This system offers a tool whereby students struggling with a text can automatically produce all of the possible readings for a unit. Additionally, the analyzer provides the possibility of automatically spacing and glossing larger texts in Coptic. Some manual disambiguation remains to be done by the user. However, as future work, the analyzer could profit from being combined with a disambiguator. Such a tool could be coupled with a hand-written constraint grammar (Karlsson, 1990), such as is done in Bick (2000), and other developers in different domains (Forcada et al., 2011). As Zeldes and Schroeder (2015) reports encouraging POS-tagging accuracy results using two different less fine-grained annotation schemes than are assumed in this paper, we expect that a statistical disambiguator could also be trained as more labeled data becomes available. Increasing coverage of the analyzer can in most cases be done without major additions to the grammar as we expect to have captured the major morphophonological alternations and morphotactic constraints. The majority of work to"
L16-1411,E87-1002,0,0.795557,"Missing"
L18-1293,E14-1060,1,0.914644,"Missing"
L18-1293,P16-1156,1,0.911216,"Missing"
L18-1293,N07-1048,0,0.136877,"Missing"
L18-1293,N13-1138,0,0.235978,"Missing"
L18-1293,P08-1115,0,0.0456449,"Missing"
L18-1293,N16-1077,1,0.880807,"Missing"
L18-1293,L16-1498,1,0.945257,"The Universal Morphology (UniMorph) project, centered at the Center for Language and Speech Processing (CLSP) at Johns Hopkins University is a collaborative effort to improve how NLP systems handle complex morphology across the world’s languages. The project releases annotated morphological data using a universal tagset, the UniMorph schema. Each inflected form is associated with a lemma, which typically carries its underlying lexical meaning, and a bundle of morphological features from our schema. Additional supporting data and tools are also released on a per-language basis when available. Kirov et al. (2016) introduced version 1.0 of the UniMorph morphological database, created by extracting and normalizing the inflectional paradigms included in Wiktionary (www.wiktionary.org), a large, broadly multi-lingual crowd-sourced collection of lexical data. This paper describes UniMorph 2.0. It details improvements in Wiktionary extraction and annotation, as well as normalization of non-Wiktionary resources, leading to a much higher quality morphological database. The new dataset spans 52 languages representing a range of language families. As in UniMorph 1.0, we provide paradigms from highlyinflected op"
L18-1293,D14-1095,0,0.116143,"Missing"
L18-1293,N15-1093,0,0.150689,"Missing"
L18-1293,Q15-1026,0,0.0836395,"Missing"
L18-1293,P15-2111,1,0.852807,"rsing and normalization of Wiktionary. Wiktionary is a broadly multilingual resource with many crowd-sourced morphological paradigms in the form of custom HTML tables. Figure 1 illustrates the challenge associated with extracting this data. Wiktionary is designed for human, rather than machine readability, and authors have extensive freedom in formatting data. This leads to wildly differing table layouts across languages which need to be converted to a consistent tabular format. The extraction process developed for UniMorph 1.0 relied heavily on statistical, visual, and positional heuristics (Sylak-Glassman et al., 2015b) to: 1. Determine which entries in an HTML table are inflected forms and which are grammatical descriptors. 2. Link each inflected form with its appropriate descriptors. 3. Convert each set of linked descriptors into a universal feature annotation schema, described in detail in Sylak-Glassman (2016).1 This led to a large dataset of 952,530 unique noun, verb, and adjective lemmas across 350 languages. Unfortunately, 1 pdf unimorph.github.io/doc/unimorph-schema. Figure 1: Paradigm extraction and normalization. the UniMorph 1.0 dataset was very error-prone due to the inability of our heuristics"
L18-1293,zeman-2008-reusable,0,0.0233658,"Each group represents a different type of paradigm (e.g., regular verb). For each group, a sample table was selected, and an annotator replaced each inflected form in the table with the appropriate UniMorph features. All annotation was compliant with the UniMorph Schema, which was designed to represent the full range of semantic distinctions that can be captured by inflectional morphology in any language (SylakGlassman et al., 2015a). The schema is similar in form and spirit to other tagset universalization efforts, such as the Universal Dependencies Project (Choi et al., 2015) and Interset (Zeman, 2008), but is designed specifically for typological completeness for inflectional morphology, including a focus on the morphology of especially low-resource languages. It includes over 200 base features distributed among 23 dimensions of meaning (i.e., morphological categories), including both common dimensions like tense and aspect as well as rarer dimensions like evidentiality and switch-reference. Despite the high coverage of the UniMorph tagset, for UniMorph 2.0, annotators were allowed to employ additional ‘language specific’ LGSPEC(1, 2, 3, etc.) features to mark any missing distinctions, or"
L18-1293,W16-2002,1,\N,Missing
L18-1294,E09-2008,1,0.873366,"Verb themes fall into larger lexicalinflectional classes referred to in Dene linguistics as verb theme categories. These are characterized by shared conjugation markers in the Imperfective and Perfective, a shared primary aspect indicated by (historic) stem suffixation pattern, derivational potential, and semantic properties (durativity, telicity...). There are 10 verb theme categories, as shown in Table 4. Adverbial-derivational Table 3: aa-perfective of ch’+L+dzüh (op.) ‘dance’ are currently several open source implementations of FSM compilers, e.g. xfst (Beesley and Karttunen, 2003), foma (Hulden, 2009) and HFST (Lindén et al., 2011). The key advantages of FSMs are most crucially that they provide a calculus for powerful manipulations and are designed for rulebased definition of paradigms, which does not require large corpora from which to learn such rules, usually lacking for endangered languages. Furthermore, as well-established computational data structures, FSMs allow for easy integration with other software applications, for instance as spellchecking modules within word-processors, morphologically “intelligent” electronic dictionaries, and “intelligent” computer-aided language-learning"
N15-1107,E14-1060,1,0.777496,"1 Introduction Use of detailed and sophisticated morphological features has been found to be crucial for many downstream NLP tasks, including part-of-speech tagging and parsing (Tseng et al., 2005; Spoustov´a et al., 2007). However, creating an accurate widecoverage morphological analyzer for a new language that can be used in tandem with other higherlevel analyses is an arduous task. Learning word inflection patterns by organizing related word-forms into morphological paradigms based on the longest common subsequence (LCS) found in an inflection table has recently been We used this idea in (Ahlberg et al., 2014) to create a relatively simple-to-implement system that learns paradigms from example inflection tables and is then able to reconstruct inflection tables for unseen words by comparing suffixes of new base forms to base forms seen during training. The system performs well on available datasets and results in human-readable and editable output. The longest common subsequence strategy itself shows little bias toward any specific morphological process such as prefixation, suffixation, or infixation. Using the model, we argued, a selection of ready-inflected tables could be quickly provided by a li"
N15-1107,E12-1053,0,0.0600889,"Missing"
N15-1107,D11-1057,0,0.0348682,"paradigm learning. In the second, we use a more comprehensive and complex dataset we have developed for 8 additional languages. This new dataset is less regular and intended to be more realistic in that it also features defective or incomplete inflection tables and inflection tables containing various alternate forms, naturally making the classification task substantially more difficult.1 Overall, supervised and semi-supervised learning of morphology by generalizing patterns from inflection tables is an active research field. Recent work sharing our goals includes Toutanova and Cherry (2009), Dreyer and Eisner (2011), which works with a fully Bayesian model, Dinu et al. (2012), Eskander et al. (2013), which attempts to learn lexicons from morphologically annotated corpora, and Durrett and DeNero (2013), who train a discriminative model that learns transformation rules between word forms. We directly compare our results against the last using the same dataset. The paper is organized as follows: section 2 contains the experimental setup, section 3 the datasets, and section 4 the results and discussion. 2 Method As a first step, our system converts inflection tables into paradigms using a procedure given in"
N15-1107,N13-1138,0,0.671701,"signs unknown words to the LCS-learned paradigm based on substring features taken from word edges. This holds in particular for languages where paradigmatic behavior is triggered by material in the beginning of a word (e.g. German verbs). We present experiments on 18 datasets in 11 languages varying in morphological complexity. In all the experiments, the task is to reconstruct a complete inflection table from a base form, which usually corresponds to the lemma or dictionary form of a noun, verb, or adjective. The experiments are divided into two sets. In the first, we use an earlier dataset (Durrett and DeNero, 2013) of Finnish, German, and Spanish to compare against other methods of paradigm learning. In the second, we use a more comprehensive and complex dataset we have developed for 8 additional languages. This new dataset is less regular and intended to be more realistic in that it also features defective or incomplete inflection tables and inflection tables containing various alternate forms, naturally making the classification task substantially more difficult.1 Overall, supervised and semi-supervised learning of morphology by generalizing patterns from inflection tables is an active research field."
N15-1107,D13-1105,0,0.119963,"ve developed for 8 additional languages. This new dataset is less regular and intended to be more realistic in that it also features defective or incomplete inflection tables and inflection tables containing various alternate forms, naturally making the classification task substantially more difficult.1 Overall, supervised and semi-supervised learning of morphology by generalizing patterns from inflection tables is an active research field. Recent work sharing our goals includes Toutanova and Cherry (2009), Dreyer and Eisner (2011), which works with a fully Bayesian model, Dinu et al. (2012), Eskander et al. (2013), which attempts to learn lexicons from morphologically annotated corpora, and Durrett and DeNero (2013), who train a discriminative model that learns transformation rules between word forms. We directly compare our results against the last using the same dataset. The paper is organized as follows: section 2 contains the experimental setup, section 3 the datasets, and section 4 the results and discussion. 2 Method As a first step, our system converts inflection tables into paradigms using a procedure given in Hulden (2014). The system generalizes concrete inflection tables by associating the c"
N15-1107,W14-2804,1,0.865341,", which works with a fully Bayesian model, Dinu et al. (2012), Eskander et al. (2013), which attempts to learn lexicons from morphologically annotated corpora, and Durrett and DeNero (2013), who train a discriminative model that learns transformation rules between word forms. We directly compare our results against the last using the same dataset. The paper is organized as follows: section 2 contains the experimental setup, section 3 the datasets, and section 4 the results and discussion. 2 Method As a first step, our system converts inflection tables into paradigms using a procedure given in Hulden (2014). The system generalizes concrete inflection tables by associating the common symbol subsequences shared by the words (the LCS) with vari1 The data and the code is available at our website https://svn.spraakbanken.gu.se/clt/naacl/ 2015/extract 1025 in�ection tables höfn höfn höfn hafnar hafnir generalize hafnir höfnum hafna paradigms x1 ö x1 ö x1 ö x1 a x1 a x1 a x1 ö x1 a in�ection table x2 x2 x2 gjöf? x2 ar x2 ir classify & x2 ir reconstruct x2 um x2 a gjöf gjöf gjöf gjafar gjafir gjafir gjöfum gjafa Figure 1: General overview of the system, exemplified using Icelandic nouns. First, a large"
N15-1107,padro-stanilovsky-2012-freeling,0,0.027896,"Missing"
N15-1107,W07-1709,0,0.0331681,"Missing"
N15-1107,P09-1055,0,0.0115575,"are against other methods of paradigm learning. In the second, we use a more comprehensive and complex dataset we have developed for 8 additional languages. This new dataset is less regular and intended to be more realistic in that it also features defective or incomplete inflection tables and inflection tables containing various alternate forms, naturally making the classification task substantially more difficult.1 Overall, supervised and semi-supervised learning of morphology by generalizing patterns from inflection tables is an active research field. Recent work sharing our goals includes Toutanova and Cherry (2009), Dreyer and Eisner (2011), which works with a fully Bayesian model, Dinu et al. (2012), Eskander et al. (2013), which attempts to learn lexicons from morphologically annotated corpora, and Durrett and DeNero (2013), who train a discriminative model that learns transformation rules between word forms. We directly compare our results against the last using the same dataset. The paper is organized as follows: section 2 contains the experimental setup, section 3 the datasets, and section 4 the results and discussion. 2 Method As a first step, our system converts inflection tables into paradigms u"
N15-1107,I05-3005,0,0.0574891,"xamples of inflection patterns (inflection tables) and then produces inflection tables from unseen lemmas or base forms. We evaluate the approach on datasets covering 11 different languages and show that this approach results in consistently higher accuracies vis-`a-vis other methods on the same task, thus indicating that the general method is a viable approach to quickly creating highaccuracy morphological resources. 1 Introduction Use of detailed and sophisticated morphological features has been found to be crucial for many downstream NLP tasks, including part-of-speech tagging and parsing (Tseng et al., 2005; Spoustov´a et al., 2007). However, creating an accurate widecoverage morphological analyzer for a new language that can be used in tandem with other higherlevel analyses is an arduous task. Learning word inflection patterns by organizing related word-forms into morphological paradigms based on the longest common subsequence (LCS) found in an inflection table has recently been We used this idea in (Ahlberg et al., 2014) to create a relatively simple-to-implement system that learns paradigms from example inflection tables and is then able to reconstruct inflection tables for unseen words by co"
Q19-1021,J92-1002,0,0.61358,"Missing"
Q19-1021,K18-3001,1,0.871881,"ge word type is observed too rarely for a learner to memorize an irregular surface form for it. Yet even in such a language, some word types are frequent, because some lexemes and some slots are especially useful. Thus, if learnability of the lexicon is indeed the driving force,13 then we should make the finer-grained prediction that irregularity may survive in the more frequently observed word types, regardless of paradigm size. Rarer forms are more likely to be predictable—meaning that they are either regular, or else irregular in a way that is predictable from a related frequent irregular (Cotterell et al., 2018a). perform a nonparametric permutation test that destroys the claimed correlation between the e-complexity and i-complexity values. From our observed points {(x1 , y1 ), . . . , (xm , ym )}, we can stochastically construct a new set of points {(x1 , yσ(1) ), . . . , (xm , yσ(m) )} where σ is a permutation of 1, 2, . . . , m selected uniformly at random. The resulting scatterplot is what we would expect under the null hypothesis of no correlation. Our p-value is the probability that the new scatterplot has an even emptier upper righthand corner—that is, the probability that the area under the"
Q19-1021,K17-2001,1,0.929128,"Missing"
Q19-1021,D07-1093,0,0.124261,"Missing"
Q19-1021,P14-2102,1,0.839978,"mitigate sample bias caused by variable-sized dictionaries in our database. In many languages, irregular words are also very frequent and may be more likely to be included in a dictionary first. If that’s the case, smaller dictionaries might have lexical statistics skewed toward irregulars more so than larger dictionaries. In general, larger dictionaries should be more representative samples of a language’s broader lexicon. 10 In the computer science literature, it is far more common to construct distributions with support over Σ∗ (Paz, 2003; Bouchard-Cˆot´e et al., 2007; Dreyer et al., 2008; Cotterell et al., 2014), which do not have this problem. 336 tween paradigm slots. We call this the ‘‘green scheme.’’ it is difficult to use them in a lower-resource scenario. To estimate a language’s e-complexity (§2.2.1), we average over all paradigms in the UniMorph inflected lexicon. To estimate i-complexity, we first partition those paradigms into training, development and test sets. We identify the paradigm shapes from the training set (§4.1). We also use the training set to train the parameters θ of our conditional distribution (§4.3), then estimate conditional entropies on the development set and use Edmonds"
Q19-1021,J86-2003,0,0.451974,"for Archi, for example). Our hypothesis is subtly different in that we postulate that morphological systems face a trade-off between e-complexity and i-complexity: a system may be complex under either metric, but not under both. The amount of e-complexity permitted is higher when i-complexity is low. This line of thinking harks back to the equal complexity conjecture of Hockett, who stated: ‘‘objective measurement is difficult, but impressionistically it would seem that the total grammatical complexity of any language, counting both the morphology and syntax, is about the same as any other’’ (Hockett, 1958, pp. 180–181). Similar trade-offs have been found in other branches of linguistics (see Oh [2015] for a review). For example, there is a trade-off between rate of speech and syllable complexity (Pellegrino et al., 2011): This means that even though Spanish speakers utter many more syllables per second than Chinese, the overall information rate is quite similar as Chinese syllables carry more information (they contain tone information). Hockett’s equal complexity conjecture is controversial: some languages (such as Riau Indonesian) do seem low in complexity across morphology and syntax (Gil, 1"
Q19-1021,Q15-1031,1,0.850215,"nese, the overall information rate is quite similar as Chinese syllables carry more information (they contain tone information). Hockett’s equal complexity conjecture is controversial: some languages (such as Riau Indonesian) do seem low in complexity across morphology and syntax (Gil, 1994). This is why Ackerman and Malouf instead posit that a linguistic system has bounded integrative complexity—it must not be too high, though it can be low, as indeed it is in isolating languages like Chinese and Thai. 3 3.1 Paradigm Entropy Morphology as a Distribution Following Dreyer and Eisner (2009) and Cotterell et al. (2015), we identify a language’s inflectional system with a probability distribution p(M = m) 329 over possible paradigms.4 Our measure of i-complexity will be related to the entropy of this distribution. For instance, knowing the behavior of the English verb system essentially means knowing a joint distribution over 5-tuples of surface forms such as (run, runs, ran, run, running). More precisely, one knows probabilities such as p(M .pres = run, M .3s = runs, M .past = ran, M .pastp = run, M .presp = running). We do not observe p directly, but each observed paradigm (5-tuple) can help us estimate it"
Q19-1021,P16-2090,0,0.0965679,"Missing"
Q19-1021,E17-2120,1,0.94135,"r setting, both the training and the test examples are paradigms from a given inflected lexicon. 4 A Generative Model of the Paradigm To fit q given the training set, we need a tractable family Q of joint distributions over paradigms, with parameters θ . The structure of the model and the number of parameters θ will be determined automatically from the training set: A language with more slots overall or more paradigm shapes will require more parameters. This means that Q is technically a semi-parametric family. 4.1 4.2 A Tree-Structured Distribution Next, conditioned on the shape s, we follow Cotterell et al. (2017b) and generate all the forms of the paradigm using a tree-structured Bayesian network—a directed graphical model in which the form at each slot is generated conditionally on the form at a single parent slot. Figure 1 illustrates two possible tree structures for Spanish verbs. Each paradigm shape s has its own tree structure. If slot σ exists in shape s, we denote its Paradigm Shapes We say that two paradigms m, m0 have the same shape if they define the same slots (that is, domain(m) = domain(m0 )) and the same pairs of slots are syncretic in both paradigms (that is, 331 parent in our shape s"
Q19-1021,D17-1074,1,0.932816,"r setting, both the training and the test examples are paradigms from a given inflected lexicon. 4 A Generative Model of the Paradigm To fit q given the training set, we need a tractable family Q of joint distributions over paradigms, with parameters θ . The structure of the model and the number of parameters θ will be determined automatically from the training set: A language with more slots overall or more paradigm shapes will require more parameters. This means that Q is technically a semi-parametric family. 4.1 4.2 A Tree-Structured Distribution Next, conditioned on the shape s, we follow Cotterell et al. (2017b) and generate all the forms of the paradigm using a tree-structured Bayesian network—a directed graphical model in which the form at each slot is generated conditionally on the form at a single parent slot. Figure 1 illustrates two possible tree structures for Spanish verbs. Each paradigm shape s has its own tree structure. If slot σ exists in shape s, we denote its Paradigm Shapes We say that two paradigms m, m0 have the same shape if they define the same slots (that is, domain(m) = domain(m0 )) and the same pairs of slots are syncretic in both paradigms (that is, 331 parent in our shape s"
Q19-1021,L18-1293,1,0.883669,"Missing"
Q19-1021,D09-1011,1,0.762439,"syllables per second than Chinese, the overall information rate is quite similar as Chinese syllables carry more information (they contain tone information). Hockett’s equal complexity conjecture is controversial: some languages (such as Riau Indonesian) do seem low in complexity across morphology and syntax (Gil, 1994). This is why Ackerman and Malouf instead posit that a linguistic system has bounded integrative complexity—it must not be too high, though it can be low, as indeed it is in isolating languages like Chinese and Thai. 3 3.1 Paradigm Entropy Morphology as a Distribution Following Dreyer and Eisner (2009) and Cotterell et al. (2015), we identify a language’s inflectional system with a probability distribution p(M = m) 329 over possible paradigms.4 Our measure of i-complexity will be related to the entropy of this distribution. For instance, knowing the behavior of the English verb system essentially means knowing a joint distribution over 5-tuples of surface forms such as (run, runs, ran, run, running). More precisely, one knows probabilities such as p(M .pres = run, M .3s = runs, M .past = ran, M .pastp = run, M .presp = running). We do not observe p directly, but each observed paradigm (5-tu"
Q19-1021,P17-4012,0,0.0417736,"Missing"
Q19-1021,D11-1057,1,0.856952,") from p. Any novel verb paradigm in the future would be drawn from p as well. The distribution p represents the inflectional system because it describes what regular paradigms and plausible irregular paradigms tend to look like. The fact that some paradigms are used more frequently than others (more tokens in a corpus) does not mean that they have higher probability under the morphological system p(m). Rather, their higher usage reflects the higher probability of their lexemes. That is due to unrelated factors—the probability of a lexeme may be modeled separately by a stick-breaking process (Dreyer and Eisner, 2011), or may reflect the semantic meaning associated to that lexeme. The role of p(m) in the model is only to serve as the base distribution from which a lexeme type ` selects the tuple of strings m = M (`) that will be used thereafter to express `. We expect the system to place low probability on implausible paradigms: For example, p(run, , , run, running) is close to zero. Moreover, we expect it to assign high conditional probability to the result of applying highly regular processes: For example, for p(M .presp |M .3s) in English, we have p(wugging |wugs) ≈ p(running |runs) ≈ 1, where wug is a"
Q19-1021,D08-1113,1,0.711343,"ges should also help mitigate sample bias caused by variable-sized dictionaries in our database. In many languages, irregular words are also very frequent and may be more likely to be included in a dictionary first. If that’s the case, smaller dictionaries might have lexical statistics skewed toward irregulars more so than larger dictionaries. In general, larger dictionaries should be more representative samples of a language’s broader lexicon. 10 In the computer science literature, it is far more common to construct distributions with support over Σ∗ (Paz, 2003; Bouchard-Cˆot´e et al., 2007; Dreyer et al., 2008; Cotterell et al., 2014), which do not have this problem. 336 tween paradigm slots. We call this the ‘‘green scheme.’’ it is difficult to use them in a lower-resource scenario. To estimate a language’s e-complexity (§2.2.1), we average over all paradigms in the UniMorph inflected lexicon. To estimate i-complexity, we first partition those paradigms into training, development and test sets. We identify the paradigm shapes from the training set (§4.1). We also use the training set to train the parameters θ of our conditional distribution (§4.3), then estimate conditional entropies on the develo"
Q19-1021,P15-2111,1,0.923479,"Missing"
Q19-1021,W16-2002,1,\N,Missing
W09-0803,W98-1007,0,0.632892,"Missing"
W09-0803,P98-1018,0,0.0396859,"r expression C (V) C (V) C, i.e. where the vowels are optional. Note, however, that the rule that constrains T4 V above only requires that the V matches if there indeed is one. Hence, by declaring vowels in patterns (and vocalizations) to be optional, we can always parse any partially, fully, or unvocalized verb. Of course, fully unvocalized words will be much more ambiguous and yield more parses. k C k C a V a V t C t C a V a V b C b C a a a 7 The idea to preserve the gemination in the grammar is similar to the solutions regarding gemination and spreading of Forms II, V, and IX documented in Beesley (1998b) and Habash and Rambow (2006). 23 4.4 The final automaton jussive forms, the following alignment would be somewhat inefficient: ... T5 t a T6 +3P +Fem +Sg ... As mentioned above, the symbols {T1 , . . . , Tn } are only used during construction of the automaton for the convenience of writing the grammar, and shall be removed after intersecting the Base language with the Rules languages. This is a simple substitution TX → , i.e. the empty string. Hence, the grammar is compiled as: Grammar = h(Base ∩ Rules) This is because the prefix ta, which appears early in the word, is reflected on tape 6"
W09-0803,P06-1086,0,0.0847864,"ning s1 can only occur once on one tape in the same position, i.e. we would be accepting any strings containing a symbol such as s1 :s2 :s2 :s2 :s2 or s2 :s2 :s2 :s2 :s3 but not, s1 :s2 :s3 :s4 :s1 . Without further treatment of the alphabet behavior, this yields a multi-tape automaton which has a single state, but 5,056,506 transitions—each transition naturally representing a legal combination of symbols on the five tapes. This kind of transition blow-up is not completely inevitable: of course one can devise many tricks 2 Two anonymous reviewers point out the work by Habash et al. (2005) and Habash and Rambow (2006) who report an effort to analyze Arabic with such a multitape system based on work by Kiraz (2000, 2001) that relies on custom algorithms devised for a multitape alphabet. Although Habash and Rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above. These approaches also use a small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the face of it appear to scale w"
W09-0803,W05-0703,0,0.0259416,"combination of tapes, meaning s1 can only occur once on one tape in the same position, i.e. we would be accepting any strings containing a symbol such as s1 :s2 :s2 :s2 :s2 or s2 :s2 :s2 :s2 :s3 but not, s1 :s2 :s3 :s4 :s1 . Without further treatment of the alphabet behavior, this yields a multi-tape automaton which has a single state, but 5,056,506 transitions—each transition naturally representing a legal combination of symbols on the five tapes. This kind of transition blow-up is not completely inevitable: of course one can devise many tricks 2 Two anonymous reviewers point out the work by Habash et al. (2005) and Habash and Rambow (2006) who report an effort to analyze Arabic with such a multitape system based on work by Kiraz (2000, 2001) that relies on custom algorithms devised for a multitape alphabet. Although Habash and Rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above. These approaches also use a small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the"
W09-0803,C88-1064,0,0.364154,"n a single tape that can be implemented using any standard finite-automaton toolkit. 1 1.1 Introduction Root-and-pattern morphology and finite-state systems The special problems and challenges embodied by Semitic languages have been recognized from the early days of applying finite-state methods to natural language morphological analysis. The language model which finite-state methods have been most successful in describing—a model where morphemes concatenate in mostly strict linear order—does not translate congenially to the type of root-and-pattern morphology found in e.g. Arabic and Hebrew (Kataja and Koskenniemi, 1988; Lavie et al., 1988). In Arabic, as in most Semitic languages, verbs have for a long time been analyzed as consist1.2 Multitape automata One early approach, suggested by Kay (1987) and later pursued in different variants by Kiraz (1994, 2000) among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with a n-tape automaton, where tapes would carry precisely this interleaving 1 Following autosegmental analyses, this paper assumes the model where the vocalization is not merged with the pattern, i.e. we do not list separate patterns for"
W09-0803,E87-1002,0,0.604553,"ed by Semitic languages have been recognized from the early days of applying finite-state methods to natural language morphological analysis. The language model which finite-state methods have been most successful in describing—a model where morphemes concatenate in mostly strict linear order—does not translate congenially to the type of root-and-pattern morphology found in e.g. Arabic and Hebrew (Kataja and Koskenniemi, 1988; Lavie et al., 1988). In Arabic, as in most Semitic languages, verbs have for a long time been analyzed as consist1.2 Multitape automata One early approach, suggested by Kay (1987) and later pursued in different variants by Kiraz (1994, 2000) among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with a n-tape automaton, where tapes would carry precisely this interleaving 1 Following autosegmental analyses, this paper assumes the model where the vocalization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as CaCaC as is assumed more traditionally. Which analysis to choose largely a matter of convenience, and the methods in this paper apply to either one. Proceeding"
W09-0803,C94-1029,0,0.0870109,"early days of applying finite-state methods to natural language morphological analysis. The language model which finite-state methods have been most successful in describing—a model where morphemes concatenate in mostly strict linear order—does not translate congenially to the type of root-and-pattern morphology found in e.g. Arabic and Hebrew (Kataja and Koskenniemi, 1988; Lavie et al., 1988). In Arabic, as in most Semitic languages, verbs have for a long time been analyzed as consist1.2 Multitape automata One early approach, suggested by Kay (1987) and later pursued in different variants by Kiraz (1994, 2000) among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with a n-tape automaton, where tapes would carry precisely this interleaving 1 Following autosegmental analyses, this paper assumes the model where the vocalization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as CaCaC as is assumed more traditionally. Which analysis to choose largely a matter of convenience, and the methods in this paper apply to either one. Proceedings of the EACL 2009 Workshop on Computational Approaches"
W09-0803,C96-1017,0,\N,Missing
W09-0803,J00-1006,0,\N,Missing
W09-0803,C98-1018,0,\N,Missing
W11-2605,almeida-etal-2010-bigorna,0,0.220576,"ne The baseline of our experiments is a simple method, based on a dictionary of equivalent words with the list of correspondences between words extracted 3 Towards a Syntactic Atlas of the Basque Language, web site: http://www.iker.cnrs.fr/-tsabl-towards-a-syntactic-atlasof-.html 41 4 Overview of methods We have employed two different methods to produce an application that attempts to extract generalizations from the training corpus to ultimately be able to produce the equivalent standard word corresponding to a given dialectal input word. The first method is based on already existing work by Almeida et al. (2010) that extracts all substrings from lexical pairs that are different. From this knowledge we then produce a number of phonological replacement rules that model the differences between the input and output words. In the second method, we likewise produce a set of phonological replacement rules, using an ILP approach that directly induces the rules from the pairs of words in the training corpus. The core difference between the two methods is that while both extract replacement patterns from the word-pairs, the first method does not consider negative evidence in formulating the replacement rules."
W11-2605,P07-3010,0,0.272495,"Missing"
W11-2605,E09-2008,1,0.92932,"pplication, and the question is whether the corresponding loss in precision may be mitigated by judicious application of post-processing filters. 4.1 Format of rules Both of the methods we have evaluated involve learning a set of string-transformation rules to convert words, morphemes, or individual letters (graphemes) in the dialectal forms to the standard variant. The rules that are learned are in the format of so-called phonological replacement rules (Beesley and Karttunen, 2002) which we have later converted into equivalent finite-state transducers using the freely available foma toolkit (Hulden, 2009a). The reason for the ultimate conversion of the rule set to finite-state transducers is twofold: first, the transducers are easy to apply rapidly to input data using available tools, and secondly, the transducers can further be modified and combined with the standard morphology already available to us as a finite transducer. In its simplest form, a replacement rule is of the format A → B ||C D (1) where the arguments A,B,C,D are all single symbols or strings. Such a rule dictates the transformation of a string A to B, whenever the A occurs between the strings C and D. Both C and D are option"
W11-2605,P84-1070,0,0.596427,"Missing"
W11-2605,N01-1020,0,0.28199,"Missing"
W11-4406,J95-4004,0,0.10714,"> <Count> N NOM PL ""<and>"" ""and"" CC ""<teachers>"" ""teacher"" <DER:er> <Count> N NOM PL ""<.>"" ""."" PUNCT Pun Figure 1: Example input (left) and output (right) from a Constraint Grammar disambiguator. yielding a total complexity of O(n3 Gk 2 ). As mentioned above there are various heuristics one can use to avoid blindly testing rules against readings where they cannot apply, but none that guarantee a lower complexity. 3 Related work Many constraint-based tagging systems can be speeded up by appropriate use of finite-state transducers. For example, Roche and Schabes (1995) show that a Brill tagger (Brill, 1995) can be applied in linear time by constructing a sequential (inputdeterministic) transducer that performs the same task as applying a set of transformation-based learning (TBL) rules that change tags according to contextual specifications. This method does not, however, transfer to the problem of CG implementations: for one, TBL rules are vastly simpler in their expressive power, limited only to a few simple templatic statements of tag replacement, while the CG formalism allows for an unlimited number of Boolean and 41 linking constraints; secondly, TBL rules target tags, not words, while CG a"
W11-4406,E95-1021,0,0.053922,"improve on the worstcase asymptotic bound of Constraint Grammar parsing from cubic to quadratic in the length of input sentences. 1 Introduction The Constraint Grammar (CG) paradigm (Karlsson, 1990) is a popular formalism for performing partof-speech disambiguation, surface syntactic tagging, and certain forms of dependency analysis. A CG is a collection of hand-written disambiguation rules for part-of-speech or syntactic functions. The popularity of CGs is explained by a few factors. They typically achieve quite high F-measures on unrestricted text, especially for free word-order languages (Chanod and Tapanainen, 1995; Samuelsson and Voutilainen, 1997). Constraint Grammars can also be developed by linguists rather quickly, even for languages that have only meager resources available as regards tagged or parsed corpora, although it is hard to come by exact measures of how much effort development requires. One drawback to using CG, however, is that applying one to disambiguate input text tends to be very slow: for example, the Apertium project (Forcada et al., 2009), which offers the option of using both n-gram models and CG (by way of the vislcg3 compiler (Bick, 2000)), reports that using n-gram models curr"
W11-4406,2009.freeopmt-1.3,0,0.0482021,"Missing"
W11-4406,E09-2008,1,0.936712,"in the Cond transducer are fairly straightforward to express as Boolean combinations of regular languages since we have explicit symbols marking the beginnings and endings of cohorts as well as readings. Each condition for a rule firing—e.g. something occurring n cohorts (or more) to the left/right—can then be expressed in terms of the auxiliary symbols that separate cohorts and readings. 6.1 Detailed example Figure 2 contains a working example of the rule compilation strategy in the form of a script in the Xerox formalism compilable with either the xfst (Beesley and Karttunen, 2003) or foma (Hulden, 2009) FST toolkits. The majority of the example consists of function and transducer definitions common for compiling any CG-rule, and the last few lines exemplify the actual compilation of the rules. Briefly, compiling a rule with the example code, entails as a preliminary the composition of the following transducers: • InitialFilter disallows, for efficiency reasons, all input that is not correctly formatted. • MarkFormTarget(Wordform,Target) is a function that performs the provisional marking of all target readings and cohorts that could be affected by the rule, given the wordform and the target"
W11-4406,J94-3001,0,0.109197,"mpossible, however. As each ambiguity may last several cohorts ahead, the equivalent sequential transducer must “remember” arbitrary nonoutputted strings for a long time, and will be exponential in size to the original one. By contrast, the resulting left and right sequential rule FSTs are actually smaller than the original rule FSTs. 6 Construction Since each rule can operate in complex ways, we break down the process of compiling a rule into several smaller transducers which are joined by composition (◦). This is similar to techniques used for compiling phonological rewrite rules into FSTs (Kaplan and Kay, 1994; Kempe and Karttunen, 1996). The entire construction process can be encapsulated in the composition of a few auxiliary transducers. Compilation of a basic rule of the format SELECT/REMOVE (X) IF (SCOPE#1 COND#1) ... (SCOPE#n COND#n) can be expressed with the general construction MarkFormTarget ◦ Constrain ◦ Cond1 ◦ . . . ◦ Condn (2) These operate as follows: • MarkFormTarget is a transducer that changes #0#-symbols temporarily to #1#symbols (signaling pending removal) for those cohorts that contain the target reading (if the rule is a REMOVE rule), or for retention (if it is a SELECT rule). 4"
W11-4406,C90-3030,0,0.672389,"ntial finite transducers Mans Hulden University of Helsinki mans.hulden@helsinki.fi Abstract We propose an approach to parsing Constraint Grammars using finite-state transducers and report on a compiler that converts Constraint Grammar rules into transducer representations. The resulting transducers are further optimized by conversion to left and right sequential transducers. Using the method, we show that we can improve on the worstcase asymptotic bound of Constraint Grammar parsing from cubic to quadratic in the length of input sentences. 1 Introduction The Constraint Grammar (CG) paradigm (Karlsson, 1990) is a popular formalism for performing partof-speech disambiguation, surface syntactic tagging, and certain forms of dependency analysis. A CG is a collection of hand-written disambiguation rules for part-of-speech or syntactic functions. The popularity of CGs is explained by a few factors. They typically achieve quite high F-measures on unrestricted text, especially for free word-order languages (Chanod and Tapanainen, 1995; Samuelsson and Voutilainen, 1997). Constraint Grammars can also be developed by linguists rather quickly, even for languages that have only meager resources available as"
W11-4406,W98-1301,0,0.0313448,"tate transducers (FSTs) that perform the corresponding disambiguation task on an ambiguous input sentence. Using this approach, we can improve the worst-case running time of a CG parser to quadratic in the length of a sentence, down from the cubic time requirement reported earlier (Tapanainen, 1999). The method presented here implements faithfully all the operations allowed in the CG-2 system documented in Tapanainen (1996). The same approach can be used for various extensions and variants of the Constraint Grammar paradigm. The idea of representing CG rules as FSTs has been suggested before (Karttunen, 1998), but to our knowledge this implementation represents the first time the idea has been tried in practice.1 We also show that after compiling a collection of CG rules into their equivalent FSTs, the individual transducers can further be converted into left and right sequential transducers which greatly improves the speed of application of a rule. In the following, we give a brief overview of the CG formalism, discuss previous work and CG parsers, provide an account of our method, and finally report on some practical experiments in compiling large-scale grammars into FSTs with our CGrule-to-tran"
W11-4406,C96-2105,0,0.0620875,"each ambiguity may last several cohorts ahead, the equivalent sequential transducer must “remember” arbitrary nonoutputted strings for a long time, and will be exponential in size to the original one. By contrast, the resulting left and right sequential rule FSTs are actually smaller than the original rule FSTs. 6 Construction Since each rule can operate in complex ways, we break down the process of compiling a rule into several smaller transducers which are joined by composition (◦). This is similar to techniques used for compiling phonological rewrite rules into FSTs (Kaplan and Kay, 1994; Kempe and Karttunen, 1996). The entire construction process can be encapsulated in the composition of a few auxiliary transducers. Compilation of a basic rule of the format SELECT/REMOVE (X) IF (SCOPE#1 COND#1) ... (SCOPE#n COND#n) can be expressed with the general construction MarkFormTarget ◦ Constrain ◦ Cond1 ◦ . . . ◦ Condn (2) These operate as follows: • MarkFormTarget is a transducer that changes #0#-symbols temporarily to #1#symbols (signaling pending removal) for those cohorts that contain the target reading (if the rule is a REMOVE rule), or for retention (if it is a SELECT rule). 43 • Constrain changes #1#-sy"
W11-4406,C90-2040,0,0.405825,"les that change tags according to contextual specifications. This method does not, however, transfer to the problem of CG implementations: for one, TBL rules are vastly simpler in their expressive power, limited only to a few simple templatic statements of tag replacement, while the CG formalism allows for an unlimited number of Boolean and 41 linking constraints; secondly, TBL rules target tags, not words, while CG allows for rules to target any mix of both; thirdly, TBL rules only replace single tags with other single tags and do not remove tags from sets of alternative tags.2 Additionally, Koskenniemi (1990); Koskenniemi et al. (1992) have proposed a constraint-based method for surface-syntactic tagging that can be directly implemented—at least in theory—as the intersection of constraints encoded by finite automata. This formalism has been called alternatively by the name finite-state intersection grammar and parallel constraint grammar, and has later been pursued 2 This last circumstance is actually only a theoretical inequivalence: a set of CG tags could conceivably be encoded as a single symbol, and the problem of removing tags from a set of tags could be reduced to changing set-representing t"
W11-4406,C92-1027,0,0.229989,"according to contextual specifications. This method does not, however, transfer to the problem of CG implementations: for one, TBL rules are vastly simpler in their expressive power, limited only to a few simple templatic statements of tag replacement, while the CG formalism allows for an unlimited number of Boolean and 41 linking constraints; secondly, TBL rules target tags, not words, while CG allows for rules to target any mix of both; thirdly, TBL rules only replace single tags with other single tags and do not remove tags from sets of alternative tags.2 Additionally, Koskenniemi (1990); Koskenniemi et al. (1992) have proposed a constraint-based method for surface-syntactic tagging that can be directly implemented—at least in theory—as the intersection of constraints encoded by finite automata. This formalism has been called alternatively by the name finite-state intersection grammar and parallel constraint grammar, and has later been pursued 2 This last circumstance is actually only a theoretical inequivalence: a set of CG tags could conceivably be encoded as a single symbol, and the problem of removing tags from a set of tags could be reduced to changing set-representing tags into other such tags, b"
W11-4406,J95-2004,0,0.250274,"LB> CS ""as"" PREP ""<counselors>"" ""counselor"" <DER:or> <Count> N NOM PL ""<and>"" ""and"" CC ""<teachers>"" ""teacher"" <DER:er> <Count> N NOM PL ""<.>"" ""."" PUNCT Pun Figure 1: Example input (left) and output (right) from a Constraint Grammar disambiguator. yielding a total complexity of O(n3 Gk 2 ). As mentioned above there are various heuristics one can use to avoid blindly testing rules against readings where they cannot apply, but none that guarantee a lower complexity. 3 Related work Many constraint-based tagging systems can be speeded up by appropriate use of finite-state transducers. For example, Roche and Schabes (1995) show that a Brill tagger (Brill, 1995) can be applied in linear time by constructing a sequential (inputdeterministic) transducer that performs the same task as applying a set of transformation-based learning (TBL) rules that change tags according to contextual specifications. This method does not, however, transfer to the problem of CG implementations: for one, TBL rules are vastly simpler in their expressive power, limited only to a few simple templatic statements of tag replacement, while the CG formalism allows for an unlimited number of Boolean and 41 linking constraints; secondly, TBL r"
W11-4406,P97-1032,0,0.0648458,"mptotic bound of Constraint Grammar parsing from cubic to quadratic in the length of input sentences. 1 Introduction The Constraint Grammar (CG) paradigm (Karlsson, 1990) is a popular formalism for performing partof-speech disambiguation, surface syntactic tagging, and certain forms of dependency analysis. A CG is a collection of hand-written disambiguation rules for part-of-speech or syntactic functions. The popularity of CGs is explained by a few factors. They typically achieve quite high F-measures on unrestricted text, especially for free word-order languages (Chanod and Tapanainen, 1995; Samuelsson and Voutilainen, 1997). Constraint Grammars can also be developed by linguists rather quickly, even for languages that have only meager resources available as regards tagged or parsed corpora, although it is hard to come by exact measures of how much effort development requires. One drawback to using CG, however, is that applying one to disambiguate input text tends to be very slow: for example, the Apertium project (Forcada et al., 2009), which offers the option of using both n-gram models and CG (by way of the vislcg3 compiler (Bick, 2000)), reports that using n-gram models currently results in 39 ten times faste"
W12-1003,E09-2008,1,\N,Missing
W12-1003,P05-3029,0,\N,Missing
W12-6202,C00-1038,0,0.413346,"constraints, but not in the particular one given above. 6 Conclusion We have presented a practical method of implementing OT grammars as finite-state transducers. The examples, definitions, and templates given should be sufficient and flexible enough to encode a wide variety of OT grammars as FSTs. Although no method can encode all OT grammars as FSTs, the fundamental advantage with the system outlined is that for a large majority of practical cases, an FST can be produced which is not an approximation that can only tell apart a limited number of violations. As has been noted elsewhere (e.g. Eisner (2000b,a)), some OT constraints, such as Generalized Alignment constraints, are on the face of it not suitable for FST implementation. We may add to this that some very simple constraint systems, assuming a canonical G EN, and only using the most basic faithfulness and markedness constraints, are likewise not encodable as regular relations, and seem to have the generative power to encode phenomena not found in natural language. However, for most practical purposes—and this includes modeling actual phenomena in phonology and morphology—the present approach offers a fruitful way to implement, analyze"
W12-6202,C94-2163,0,0.652604,"inception of the theory itself. In particular, constructing an OT grammar step-by-step as the composition of a set of transducers, akin to rewrite rule composition in (Kaplan and Kay, 1994), has offered the attractive possibility of simultaneously modeling OT parsing and generation as a natural consequence of the bidirectionality of finite-state transducers. Two main approaches have received attention as practical options for implementing OT with finite-state transducers: that of Karttunen (1998) and Gerdemann and van Noord (2000).1 Both ap1 Earlier finite-state approaches do exist, see e.g. Ellison (1994) and Hammond (1997). 10 In Karttunen’s system, auxiliary ‘counting’ transducers are created that first remove candidates with maximally k violation marks for some fixed k, then k − 1, and so on, until nothing can be removed without emptying the candidate set, using a finite-state operation called priority union. Gerdemann and van Noord (2000) present a similar system that they call a ‘matching’ approach, but which does not rely on fixing a maximal number of distinguishable violations k. The matching method is a procedure by which we can in many cases (though not always) distinguish between inf"
W12-6202,J98-2006,0,0.516345,"es to analyze for redundancy in grammars. For example, we have assumed that the VOP-constraint plays no role in the above devoicing tableaux. Using finite-state calculus, we can prove it to be so for any input if the grammar is constructed with the method presented here. 5 Limits on FST implementation We shall conclude the presentation here with a brief discussion of the limits of FST representability, even of simple OT grammars. Previous analyses have shown that OT systems are beyond the generative capacity of finite-state systems, under some assumptions of what G EN looks like. For example, Frank and Satta (1998) present such a constraint system where G EN is taken to be defined through a transduction equivalent to:8 Gen = [a:b|b:a]* |[a|b]*; That is, a relation which either maps all a’s to b’s and vice versa, or leaves the input unchanged. Now, let us assume the presence of a single markedness constraint ∗ a, militating against the letter a. In that case, given an input of the format a∗ b∗ the effective mapping of the entire system is one that is an identity relation if there are fewer a’s than b’s; otherwise the a’s and b’s are swapped. As is easily seen, this is not a regular relation. One possible"
W12-6202,W00-1804,1,0.730763,"Missing"
W12-6202,E09-2008,1,0.861155,"uded as many times as warranted in the definition of Worsen: 15 Now, this yields a transducer that maps every underlying form to n asterisks, n being the number of violations with respect to ConsN in the candidates that have successfully survived ConsN. If this transducer represents a function (is single-valued), then we know that two candidates with a different number of violations have not survived ConsN, and that the worsening yielded the correct answer. Since the question of transducer functionality is known to be decidable (Blattner and Head, 1977), and an efficient algorithm is given in Hulden (2009a), which is included in foma (with the command test functional) we can address this question by calculating the above for each constraint, if necessary, and then permute the violation markers until the above transducer is functional. 3.4 Equivalence testing In many cases, the purpose of an OT grammar is to capture accurately some linguistic phenomenon through the interaction of constraints rather than by other formalisms. However, as has been noted by Karttunen (2006), among others, OT constraint debugging is an arduous task due to the sheer number of unforeseen candidates. One of the advanta"
W12-6202,J94-3001,0,0.583096,"T representations for OT grammars which we illustrate with two practical example grammars. We also provide a new proof of nonregularity of simple OT grammars. 1 Grammar = Gen .o. MarkC1 .o. FilterC1 ... MarkCN .o. FilterCN Introduction The possibility of representing Optimality Theory (OT) grammars (Prince and Smolensky, 1993) as computational models and finite-state transducers, in particular, has been widely studied since the inception of the theory itself. In particular, constructing an OT grammar step-by-step as the composition of a set of transducers, akin to rewrite rule composition in (Kaplan and Kay, 1994), has offered the attractive possibility of simultaneously modeling OT parsing and generation as a natural consequence of the bidirectionality of finite-state transducers. Two main approaches have received attention as practical options for implementing OT with finite-state transducers: that of Karttunen (1998) and Gerdemann and van Noord (2000).1 Both ap1 Earlier finite-state approaches do exist, see e.g. Ellison (1994) and Hammond (1997). 10 In Karttunen’s system, auxiliary ‘counting’ transducers are created that first remove candidates with maximally k violation marks for some fixed k, then"
W12-6202,W98-1301,0,0.853629,"nsky, 1993) as computational models and finite-state transducers, in particular, has been widely studied since the inception of the theory itself. In particular, constructing an OT grammar step-by-step as the composition of a set of transducers, akin to rewrite rule composition in (Kaplan and Kay, 1994), has offered the attractive possibility of simultaneously modeling OT parsing and generation as a natural consequence of the bidirectionality of finite-state transducers. Two main approaches have received attention as practical options for implementing OT with finite-state transducers: that of Karttunen (1998) and Gerdemann and van Noord (2000).1 Both ap1 Earlier finite-state approaches do exist, see e.g. Ellison (1994) and Hammond (1997). 10 In Karttunen’s system, auxiliary ‘counting’ transducers are created that first remove candidates with maximally k violation marks for some fixed k, then k − 1, and so on, until nothing can be removed without emptying the candidate set, using a finite-state operation called priority union. Gerdemann and van Noord (2000) present a similar system that they call a ‘matching’ approach, but which does not rely on fixing a maximal number of distinguishable violations"
W12-6212,atserias-etal-2006-freeling,0,0.0452885,"Missing"
W12-6212,E09-2008,1,0.831125,"r inside or between chunks. Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 65–69, c Donostia–San Sebasti´an, July 23–25, 2012. 2012 Association for Computational Linguistics fer at the verb chunk level is carried out. The verbal chunk transfer is a very complex module because of the nature of Spanish and Basque auxiliary verb constructions, and is the main subject of this paper. This verb chain transfer module is implemented as a series of ordered replacement rules (Beesley and Karttunen, 2003) using the foma finite-state toolkit (Hulden, 2009). In total, the system consists of 166 separate replacement rules that together perform the verb chunk translation. In practice, the input is given to the first transducer, after which its output is passed to the second, and so forth, in a cascade. Each rule in the system is unambiguous in its output; that is, for each input in a particular step along the verb chain transfer, the transducers never produce multiple outputs (i.e. the transducers in question are functional). Some of the rules are joined together with composition, yielding a total of 55 separate transducers. In principle, all the"
W12-6213,W11-4417,0,0.0296907,"Missing"
W12-6213,C96-1017,0,0.121276,"BAMA would as a first step strip off all the vocalization marks, producing qbl. During the parsing process, BAMA could then match qbl with, for instance, qibal, an entirely different word, even though vowels were indicated. The FST design addresses this problem elegantly: if the input word is qabol, it will never match qibal because the vocalized morphemes are used throughout the construction of the FST and only optionally removed from the surface forms, whereas BAMA used the unvocalized forms to match input. This behavior is in line with other finite-state implementations of Arabic, such as Beesley (1996), where diacritics, if they happen to be present, are taken advantage of in order to disambiguate and rule out illegitimate parses. This is of practical importance when parsing Arabic as writers often partially disambiguate words depending on context. For example, the word  . kis ambiguous (Hasabat = compute, Hsbt/ I charge; Hasibat = regard, consider). One would partially vocalize Hsbt as Hsibt to denote “she regards”, or as Hsabt to imply “she computes.” The FST-based system correctly narrows down the parses accordingly, while BAMA would produce all ambiguities regardless of the vocalizat"
W12-6213,halacsy-etal-2004-creating,0,0.0325456,"Missing"
W12-6213,E09-2008,1,0.827674,"as Hsibt to denote “she regards”, or as Hsabt to imply “she computes.” The FST-based system correctly narrows down the parses accordingly, while BAMA would produce all ambiguities regardless of the vocalization in the input. 4.3 Surface lexicon extraction Having the BAMA represented as a FST also allows us to extract the output projection of the grammar, producing an automaton that only accepts legitimate words in Arabic. This can be then be used in spell checking applications, for example, by integrating the lexicon with weighted transducers reflecting frequency information and error models (Hulden, 2009a; Pirinen et al., 2010). 4.4 Constraint analysis Interestingly, the BAMA itself contains a vast amount of redundant information in the cooccurrence constraints. That is, some suffix-stemlexicon constraints are entirely subsumed by other constraints and could be removed without affecting the overall system. This can be observed during the chain of composition of the various transducers representing lexicon constraints. If a constraint X fails to remove any words from the lexicon—something that can be ascertained by noting that the number of paths through the new transducer is the same as in th"
W13-1803,D10-1051,0,0.250482,"Missing"
W13-1803,P07-2053,0,0.0744252,"Missing"
W13-1803,E09-2008,1,0.803602,"unciations are given priority, contains some 133,000 words. ZeuScansion: Technical details 5 The structure of the system is divided into the subtasks shown in figure 1. We begin with preprocessing and tokenization, after which words are part-ofspeech tagged. Following that, we find the default stresses for each word, guessing the stress patterns if words are not found in the dictionary. After these preliminaries, we apply the steps of Groves’ scansion rules and perform some cleanup of the result. The toolchain itself is implented as a chain of finite-state transducers using the foma8 toolkit (Hulden, 2009), save for the part-of-speech tagger which is a Hidden Markov Model (HMM) implementation (Hal´acsy et al., 2007). We use Perl as a glue language to communicate between the components. Preparation of the corpus After tokenization,9 we obtain the part of speech tags of the words of the poem. For the POS-tagger, we trained Hunpos10 (Hal´acsy et al., 2007) with the Wall Street Journal English corpus (Marcus et al., 1993). While other more general corpora might be more suitable for this task, we only need to distinguish between function and non-function words, and thus performance differences would"
W13-1803,J93-2004,0,0.0433988,"es, we apply the steps of Groves’ scansion rules and perform some cleanup of the result. The toolchain itself is implented as a chain of finite-state transducers using the foma8 toolkit (Hulden, 2009), save for the part-of-speech tagger which is a Hidden Markov Model (HMM) implementation (Hal´acsy et al., 2007). We use Perl as a glue language to communicate between the components. Preparation of the corpus After tokenization,9 we obtain the part of speech tags of the words of the poem. For the POS-tagger, we trained Hunpos10 (Hal´acsy et al., 2007) with the Wall Street Journal English corpus (Marcus et al., 1993). While other more general corpora might be more suitable for this task, we only need to distinguish between function and non-function words, and thus performance differences would most likely be slight. Once the first process is completed, the system starts applying Groves’ rules, which we have encoded as finite-state transducers. To apply the rules, however, we must know the stress pattern of each word. The main problem when assigning patterns is that the pronunciation of some words will be unknown, even though the dictionaries used are quite large. This often occurs because a word is either"
W13-1803,J95-2004,0,0.108645,"l meter to entire poems is also very robust. We expect to develop the system in several respects. Of primary concern is to add statistical information about the global properties of poems to resolve uncertain cases in a manner consistent with the overall structure of a given poem. Such additions could resolve ambiguous lines and try to make them fit the global pattern of a poem. Secondly, there is still room for improvement in unknown word performance. Also, the part-of-speech tagging process may be profitably replaced by a deterministic FSTbased tagger such as Brill’s tagger, as presented in Roche and Schabes (1995). This would allow the representation of the entire tool as a single FST. We believe that the availability of a gold-standard corpus of expert scansion offers a valuable improvement in the quantitative assessment of the performance of future systems and modifications. Acknowledgments We must refer to Herbert Tucker, author of the “For Better for Verse” project, which has been fundamental to evaluate our system. We also must mention the Scholar’s Lab, an arm of the University of Virginia Library, without whose aid in development and ongoing maintenance support the cited project would be impossi"
W13-1803,W13-2121,1,\N,Missing
W13-1803,W12-6208,0,\N,Missing
W13-2121,W10-0304,0,0.231214,"Missing"
W13-5641,A92-1016,0,0.325318,"Missing"
W13-5641,carreras-etal-2004-freeling,0,0.0359181,"ng A classic byproduct of encoding a morphological analyzer as an FSM is the ability to quickly implement spell checking tools. This involves extracting the domain or range of the morphological transducer, yielding an automaton that (presumably) contains only valid surface forms of words. This automaton can then be consulted for checking correctness of words—usually with much larger coverage than word lists can provide. For our experiments, we have done so using morphological transducers for Basque (Agirre et al., 1992), English, Finnish (Pirinen, 2011), German (Schmid et al., 2004), Spanish (Carreras et al., 2004), and Swedish. As is seen from table 1, except for the German transducer which encodes many circumfixation phenomena and is rather large to begin with, the compressed sizes of the automata are small enough to be used and integrated into, for instance, web-based text editing environments. 1 3.1 Real-word errors with perceptrons encoded as weighted automata To demonstrate more advanced usage, we have implemented a real-word-error-aware spell checker using weighted automata. Catching real-word spelling errors is a difficult problem 1 Performance is also reasonable. When using a determinized autom"
W13-5641,W02-1001,0,0.0392425,"Missing"
W13-5641,E09-2008,1,0.825819,"ion that also detects real-word errors. KEYWORDS: Finite-state technology, Javascript, spell checking, perceptrons. Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 441 of 474] 1 Introduction Finite-state machine (FSM) technology is widely used in language-processing and FSMs are applied in many contexts ranging from text processing to more complex tasks. Currently, several high-quality toolkits exist for the manipulation and construction of weighted and unweighted finite-state machines, such as foma (Hulden, 2009), HFST (Lindén et al., 2009), OpenFST (Allauzen et al., 2007), SFST (Schmid, 2006), and xfst (Beesley and Karttunen, 2003), to name a few. These toolkits, once compiled, also provide programming interfaces for the real-time use of automata in language processing tasks. However, for online and mobile applications, the use of finite-state machines is complicated by the unavailability of generic application interfaces for applying the finite-state machines built with any of the above toolkits. In the following, we demonstrate a simple Javascript API that allows one to take advantage of finite-sta"
W13-5641,W11-4644,0,0.013839,"compressed formats. 3 Example application: spell checking A classic byproduct of encoding a morphological analyzer as an FSM is the ability to quickly implement spell checking tools. This involves extracting the domain or range of the morphological transducer, yielding an automaton that (presumably) contains only valid surface forms of words. This automaton can then be consulted for checking correctness of words—usually with much larger coverage than word lists can provide. For our experiments, we have done so using morphological transducers for Basque (Agirre et al., 1992), English, Finnish (Pirinen, 2011), German (Schmid et al., 2004), Spanish (Carreras et al., 2004), and Swedish. As is seen from table 1, except for the German transducer which encodes many circumfixation phenomena and is rather large to begin with, the compressed sizes of the automata are small enough to be used and integrated into, for instance, web-based text editing environments. 1 3.1 Real-word errors with perceptrons encoded as weighted automata To demonstrate more advanced usage, we have implemented a real-word-error-aware spell checker using weighted automata. Catching real-word spelling errors is a difficult problem 1"
W13-5641,schmid-etal-2004-smor,0,0.023253,"ample application: spell checking A classic byproduct of encoding a morphological analyzer as an FSM is the ability to quickly implement spell checking tools. This involves extracting the domain or range of the morphological transducer, yielding an automaton that (presumably) contains only valid surface forms of words. This automaton can then be consulted for checking correctness of words—usually with much larger coverage than word lists can provide. For our experiments, we have done so using morphological transducers for Basque (Agirre et al., 1992), English, Finnish (Pirinen, 2011), German (Schmid et al., 2004), Spanish (Carreras et al., 2004), and Swedish. As is seen from table 1, except for the German transducer which encodes many circumfixation phenomena and is rather large to begin with, the compressed sizes of the automata are small enough to be used and integrated into, for instance, web-based text editing environments. 1 3.1 Real-word errors with perceptrons encoded as weighted automata To demonstrate more advanced usage, we have implemented a real-word-error-aware spell checker using weighted automata. Catching real-word spelling errors is a difficult problem 1 Performance is also reasonable"
W13-5641,P94-1013,0,0.425195,"Missing"
W14-2804,E09-2008,1,0.825556,"g paradigms from inflection tables can be represented by the four-step procedure given in figure 1. Here, multiple inflection tables are gathered, and the LCS to each table is found individually. Following that, the LCS is fit into the table, and contiguous segments that participate in the LCS are labeled variables. After paradigm generalization, it may turn out that several identical paradigms have been learned, which may then be collapsed. The first two steps of the method dictate that one: 4.1 Notation and tool The paradigm extraction tool was implemented with the help of the foma toolkit (Hulden, 2009). In the actual implementation, instead of directly compiling regular expressions, we make use of foma’s programming API, but in the following we give regular expression equivalents to the method used. Table 1 contains a summary of the regular expression notation used. 1. Extract the longest common subsequence (LCS) to all the entries in the inflection table. 2. Split the LCS(s)—of which there may be 31 remove from X all strings shorter than the maximum.5 An automaton that contains all LCSs for a set of words w1 , . . . , wn can thus be calculated as: Empty string Any symbol in alphabet End or"
W14-2804,E14-1060,1,0.896405,"on the solution sought complicate the problem further—such as requiring that the particular subsequence extracted, if there is ambiguity, be one that is best alignable in an inflection table. In this paper we present and discuss the design of a tool that performs the extraction through some advanced techniques in finite state calculus and does so efficiently enough for the practical purposes of inflection table generalization. 1 Introduction Supervised learning of morphological paradigms from inflection tables has recently been approached from a number of directions. One approach is given in Hulden et al. (2014), where morphological paradigm induction is performed by extracting the longest common subsequence (LCS) from a set of words representing an inflection table. Although that work presents encouraging results as regards learning morphological paradigms from inflection tables, no details are given as to how the paradigms themselves are extracted. The purpose of this paper is to describe how such a paradigm extraction procedure can be performed using only finite state operations. Extracting the longest common subsequence from a large number of strings is known as the multiple longest common subseq"
W14-2804,D11-1057,0,0.0697382,"as shown that the paradigm extraction and generalization method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g. Dreyer and Eisner (2011); Durrett and DeNero (2013); Eskander et al. (2013) for a variety of current methods. 3 4 Finite-state implementation The main challenge in producing a paradigm from an inflection table is not the extraction of the longest common subsequences, but rather, doing so with the added criterion of minimizing the number of variables used. Extracting the LCS from multiple strings is known to be NP-hard (Maier, 1978) and naive implementations will fail quickly for even a moderate number of strings found in inflection tables. While there exist specialized algorithms that attempt to efficiently either ca"
W14-2804,N13-1138,0,0.295477,"extraction and generalization method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g. Dreyer and Eisner (2011); Durrett and DeNero (2013); Eskander et al. (2013) for a variety of current methods. 3 4 Finite-state implementation The main challenge in producing a paradigm from an inflection table is not the extraction of the longest common subsequences, but rather, doing so with the added criterion of minimizing the number of variables used. Extracting the LCS from multiple strings is known to be NP-hard (Maier, 1978) and naive implementations will fail quickly for even a moderate number of strings found in inflection tables. While there exist specialized algorithms that attempt to efficiently either calculate (Irving and Fraser,"
W14-2804,P02-1008,0,0.0408677,"trings with suboptimal bracket markup. Figure 3 illustrates the process. [hol]en#ge[hol]t would represent a one-variable division. Naturally, these brackets will have to be divided in such a way that there is no better way to achieve the division—i.e. no markup such that fewer variables are instantiated. The crux of the method used here is to first produce an automaton that accepts the set of all valid markups of the MLCS in the table string, and then use that set to in turn define the set of suboptimal markups. Similar finite-state techniques have been used by Gerdemann and van Noord (2000); Eisner (2002); Karttunen (2010); Gerdemann and Hulden (2012), to, among other things, define suboptimal candidates in Optimality Theory. The trick is to set up a transducer T that contains the input-output pair (x, x0 ), iff x0 represents a worse division of variables than x does. In effect, T captures the transitive closure of an ordering relation  of the various factorizations of the strings into variables, and T contains the string pair (x, x0 ) when x + x0 . In general, supposing that we have an identity transducer, i.e. automaton A, and a transducer T that maps strings in A according to the transiti"
W14-2804,D13-1105,0,0.0346668,"ion method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g. Dreyer and Eisner (2011); Durrett and DeNero (2013); Eskander et al. (2013) for a variety of current methods. 3 4 Finite-state implementation The main challenge in producing a paradigm from an inflection table is not the extraction of the longest common subsequences, but rather, doing so with the added criterion of minimizing the number of variables used. Extracting the LCS from multiple strings is known to be NP-hard (Maier, 1978) and naive implementations will fail quickly for even a moderate number of strings found in inflection tables. While there exist specialized algorithms that attempt to efficiently either calculate (Irving and Fraser, 1992) or approximate (W"
W14-2804,W12-6202,1,0.847626,"rkup. Figure 3 illustrates the process. [hol]en#ge[hol]t would represent a one-variable division. Naturally, these brackets will have to be divided in such a way that there is no better way to achieve the division—i.e. no markup such that fewer variables are instantiated. The crux of the method used here is to first produce an automaton that accepts the set of all valid markups of the MLCS in the table string, and then use that set to in turn define the set of suboptimal markups. Similar finite-state techniques have been used by Gerdemann and van Noord (2000); Eisner (2002); Karttunen (2010); Gerdemann and Hulden (2012), to, among other things, define suboptimal candidates in Optimality Theory. The trick is to set up a transducer T that contains the input-output pair (x, x0 ), iff x0 represents a worse division of variables than x does. In effect, T captures the transitive closure of an ordering relation  of the various factorizations of the strings into variables, and T contains the string pair (x, x0 ) when x + x0 . In general, supposing that we have an identity transducer, i.e. automaton A, and a transducer T that maps strings in A according to the transitive closure of an ordering relation , then we c"
W14-2804,W00-1804,0,0.0142036,"Missing"
W15-4807,W12-6209,0,0.0134407,"former being the arguably more popular choice at present. The result of composing the lexicon transducer and the morphophonological transducers is one monolithic transducer that directly performs the bidirectional mapping from underlying-to-surface forms (generation) and vice versa (parsing). The prevalence of this design is probably partly due to known algorithms (Kaplan and Kay, 1994; Kempe and Karttunen, 1996; Mohri and Sproat, 1996; Hulden, 2009a) or software tools designed around this paradigm (such as Xerox’s lexc/xfst/twol (Beesley and Karttunen, 2003), foma (Hulden, 2009b), or Kleene (Beesley, 2012)). In the following, we shall assume the more common ‘rewrite-rule’ paradigm. Table 1 illustrates this standard design using some example words from a grammar of Lardil— an example language often used to illustrate complex rule ordering and word-final phonology with rules that are sensitive to ordering. The original data stems from Hale (1973), and we follow analyses by Kenstowicz and Kisseberth (1979); Hayes (2011); Round (2011). Due to the rich interaction of word-final deletion rules, this is a widely used data set that has been a target of many analyses, all of which illustrate the difficu"
W15-4807,E09-2008,1,0.947937,"uster Reduction Non-apical Truncation Sonorantization Surface form Table 1: Interaction of multiple phonological processes in Lardil. (Koskenniemi, 1983), the former being the arguably more popular choice at present. The result of composing the lexicon transducer and the morphophonological transducers is one monolithic transducer that directly performs the bidirectional mapping from underlying-to-surface forms (generation) and vice versa (parsing). The prevalence of this design is probably partly due to known algorithms (Kaplan and Kay, 1994; Kempe and Karttunen, 1996; Mohri and Sproat, 1996; Hulden, 2009a) or software tools designed around this paradigm (such as Xerox’s lexc/xfst/twol (Beesley and Karttunen, 2003), foma (Hulden, 2009b), or Kleene (Beesley, 2012)). In the following, we shall assume the more common ‘rewrite-rule’ paradigm. Table 1 illustrates this standard design using some example words from a grammar of Lardil— an example language often used to illustrate complex rule ordering and word-final phonology with rules that are sensitive to ordering. The original data stems from Hale (1973), and we follow analyses by Kenstowicz and Kisseberth (1979); Hayes (2011); Round (2011). Due"
W15-4807,J94-3001,0,0.618819,"rm /k/-epenthesis /w/-epenthesis Vowel Deletion Final Lowering Apocope Cluster Reduction Non-apical Truncation Sonorantization Surface form Table 1: Interaction of multiple phonological processes in Lardil. (Koskenniemi, 1983), the former being the arguably more popular choice at present. The result of composing the lexicon transducer and the morphophonological transducers is one monolithic transducer that directly performs the bidirectional mapping from underlying-to-surface forms (generation) and vice versa (parsing). The prevalence of this design is probably partly due to known algorithms (Kaplan and Kay, 1994; Kempe and Karttunen, 1996; Mohri and Sproat, 1996; Hulden, 2009a) or software tools designed around this paradigm (such as Xerox’s lexc/xfst/twol (Beesley and Karttunen, 2003), foma (Hulden, 2009b), or Kleene (Beesley, 2012)). In the following, we shall assume the more common ‘rewrite-rule’ paradigm. Table 1 illustrates this standard design using some example words from a grammar of Lardil— an example language often used to illustrate complex rule ordering and word-final phonology with rules that are sensitive to ordering. The original data stems from Hale (1973), and we follow analyses by K"
W15-4807,C96-2105,0,0.243656,"epenthesis Vowel Deletion Final Lowering Apocope Cluster Reduction Non-apical Truncation Sonorantization Surface form Table 1: Interaction of multiple phonological processes in Lardil. (Koskenniemi, 1983), the former being the arguably more popular choice at present. The result of composing the lexicon transducer and the morphophonological transducers is one monolithic transducer that directly performs the bidirectional mapping from underlying-to-surface forms (generation) and vice versa (parsing). The prevalence of this design is probably partly due to known algorithms (Kaplan and Kay, 1994; Kempe and Karttunen, 1996; Mohri and Sproat, 1996; Hulden, 2009a) or software tools designed around this paradigm (such as Xerox’s lexc/xfst/twol (Beesley and Karttunen, 2003), foma (Hulden, 2009b), or Kleene (Beesley, 2012)). In the following, we shall assume the more common ‘rewrite-rule’ paradigm. Table 1 illustrates this standard design using some example words from a grammar of Lardil— an example language often used to illustrate complex rule ordering and word-final phonology with rules that are sensitive to ordering. The original data stems from Hale (1973), and we follow analyses by Kenstowicz and Kisseberth (1"
W15-4807,P96-1031,0,0.187764,"inal Lowering Apocope Cluster Reduction Non-apical Truncation Sonorantization Surface form Table 1: Interaction of multiple phonological processes in Lardil. (Koskenniemi, 1983), the former being the arguably more popular choice at present. The result of composing the lexicon transducer and the morphophonological transducers is one monolithic transducer that directly performs the bidirectional mapping from underlying-to-surface forms (generation) and vice versa (parsing). The prevalence of this design is probably partly due to known algorithms (Kaplan and Kay, 1994; Kempe and Karttunen, 1996; Mohri and Sproat, 1996; Hulden, 2009a) or software tools designed around this paradigm (such as Xerox’s lexc/xfst/twol (Beesley and Karttunen, 2003), foma (Hulden, 2009b), or Kleene (Beesley, 2012)). In the following, we shall assume the more common ‘rewrite-rule’ paradigm. Table 1 illustrates this standard design using some example words from a grammar of Lardil— an example language often used to illustrate complex rule ordering and word-final phonology with rules that are sensitive to ordering. The original data stems from Hale (1973), and we follow analyses by Kenstowicz and Kisseberth (1979); Hayes (2011); Roun"
W16-2002,P14-2102,1,0.883884,"Missing"
W16-2002,W16-2007,0,0.0605324,"eral tack as the previous two systems—they used a pipelined approach that first discovered an alignment between the string pairs and then discriminatively trained a transduction. The alignment algorithm employed is the same as that of the baseline system, which relies on a rich-get-richer scheme based on the Chinese restaurant process (Sudoh et al., 2013), as discussed in §5. After obtaining the alignments, they extracted edit operations based on the alignments and used a semi-Markov CRF to apply the edits in a manner very similar to the work of Durrett and DeNero (2013). BIU-MIT The BIU-MIT (Aharoni et al., 2016) team submitted two systems. Their first model, like LMU, built upon the sequence-to-sequence architecture (Sutskever et al., 2014; Bahdanau et al., 2014; Faruqui et al., 2016), but with several im16 System LMU-1 LMU-2 BIU/MIT-1 BIU/MIT-2 HEL MSU CU EHU COL/NYU OSU UA O RACLE.E Task 1 1.0 (95.56) 2.0 (95.56) — — — 3.8 (84.06) 4.6 (81.02) 5.5 (79.24) 6.5 (67.86) — 4.6 (81.83) 97.49 Standard Task 2 1.0 (96.35) 2.0 (96.23) — — — 3.6 (86.06) 5.0 (72.98) — 4.7 (75.59) — 4.7 (74.06) 98.15 Task 3 1.0 (95.83) 2.0 (95.83) — — — 3.8 (84.87) 5.0 (71.75) — 4.8 (67.61) — 4.4 (71.23) 97.97 Task 1 1.0 (95.56"
W16-2002,Q15-1031,1,0.850026,"nd then train a classifier, Faruqui et al. (2016) applied a neural sequence-to-sequence architecture (Sutskever et al., 2014) to the problem. In contrast to paradigm completion, the task of reinflection is harder as it may require both morphologically analyzing the source form and transducing it to the target form. In addition, the training set may include only partial paradigms. However, many of the approaches taken by the shared task participants drew inspiration from work on paradigm completion. Some work, however, has considered full reinflection. For example, Dreyer and Eisner (2009) and Cotterell et al. (2015) apply graphical models with string-valued variables to model the paradigm jointly. In such models it is possible to predict values for cells in the paradigm conditioned on sets of other cells, which are not required to include the lemma. 2 a a 3 t t 4 t 5 o o 6 ssa - In general, each edit has the form copy, insert(string), delete(number), or subst(string), where subst(w) has the same effect as delete(|w|) followed by insert(w). The system treats edit sequence prediction as a sequential decision-making problem, greedily choosing each edit action given the previously chosen actions. This choice"
W16-2002,E14-1060,1,0.267684,"nd suffixes. Prefixes and suffixes are directly associated with morphological features. Stems within paradigms are further processed, using either linguistic intuitions or an empirical approach based on string alignments, to extract the stem letters that undergo changes across inflections. The extracted patterns are intended to capture stem-internal changes, such as vowel changes in Arabic. Reinflection is performed by selecting a set of changes to apply to a stem, and attaching appropriate affixes to the result. Moscow State The Moscow State system (Sorokin, 2016) is derived from the work of Ahlberg et al. (2014) and Ahlberg et al. (2015). The general idea is to use finite-state techniques to compactly model all paradigms in an abstract form called an ‘abstract paradigm’. Roughly speaking, an abstract paradigm is a set of rule transformations that derive all slots from the shared string subsequences present in each slot. Their method relies on the computation of longest common subsequence (Gusfield, 1997) to derive the abstract paradigms, which is similar to its use in the related task of lemmatization (Chrupała et al., 2008; ¨ Helsinki The Helsinki system (Ostling, 2016), like LMU and BIU-MIT, built"
W16-2002,D09-1011,1,0.861261,"tions at the paradigm level and then train a classifier, Faruqui et al. (2016) applied a neural sequence-to-sequence architecture (Sutskever et al., 2014) to the problem. In contrast to paradigm completion, the task of reinflection is harder as it may require both morphologically analyzing the source form and transducing it to the target form. In addition, the training set may include only partial paradigms. However, many of the approaches taken by the shared task participants drew inspiration from work on paradigm completion. Some work, however, has considered full reinflection. For example, Dreyer and Eisner (2009) and Cotterell et al. (2015) apply graphical models with string-valued variables to model the paradigm jointly. In such models it is possible to predict values for cells in the paradigm conditioned on sets of other cells, which are not required to include the lemma. 2 a a 3 t t 4 t 5 o o 6 ssa - In general, each edit has the form copy, insert(string), delete(number), or subst(string), where subst(w) has the same effect as delete(|w|) followed by insert(w). The system treats edit sequence prediction as a sequential decision-making problem, greedily choosing each edit action given the previously"
W16-2002,N15-1107,1,0.936397,"work on computational approaches to inflectional morphology has focused on a special case of reinflection, where the input form is always the lemma (i.e. the citation form). Thus, the task is to generate all inflections in a paradigm from the lemma and often goes by the name of paradigm completion in the literature. There has been a flurry of recent work in this vein: Durrett and DeNero (2013) heuristically extracted transformational rules and learned a statistical model to apply the rules, Nicolai et al. (2015) tackled the problem using standard tools from discriminative string transduction, Ahlberg et al. (2015) used a finite-state construction to extract complete candidate inflections at the paradigm level and then train a classifier, Faruqui et al. (2016) applied a neural sequence-to-sequence architecture (Sutskever et al., 2014) to the problem. In contrast to paradigm completion, the task of reinflection is harder as it may require both morphologically analyzing the source form and transducing it to the target form. In addition, the training set may include only partial paradigms. However, many of the approaches taken by the shared task participants drew inspiration from work on paradigm completio"
W16-2002,D11-1057,1,0.266047,"for the addition of bound morphemes, but also incorporation, which involves combining lexical stems that are often used to form independent words (Mithun, 1984). Such languages combine the need to decompound, generate derivational alternatives, and accurately inflect any resulting words. implemented as finite state transducers (Beesley and Karttunen, 2003), often return all morphologically plausible analyses if there is ambiguity. Learning to mimic the behavior of a hand-written analyzer in this respect could offer a more challenging task, and one that is useful within unsupervised learning (Dreyer and Eisner, 2011) as well as parsing. Existing wide-coverage morphological analyzers could be leveraged in the design of a more interactive shared task, where handcoded models or approximate surface rules could serve as informants for grammatical inference algorithms. The current task design did not explore all potential inflectional complexities in the languages included. For example, cliticization processes were generally not present in the language data. Adding such inflectional elements to the task can potentially make it more realistic in terms of real-world data sparsity in L1 learning scenarios. For exa"
W16-2002,W16-2004,0,0.0554931,"em. Like the Colorado system, they followed Durrett and DeNero (2013) and used a semi-Markov CRF to apply the edit operations. In contrast to Durrett and DeNero (2013), who employed a 0th-order model, the OSU system used a 1st-order model. A major drawback of the system was the cost of inference. The unpruned set of edit operations had over 500 elements. As the cost of inference in the model is quadratic in the size of the state space (the number of edit operations), this created a significant slowdown with over 15 days required to train in some cases. CRF (Sarawagi and Cohen, 2004). EHU EHU (Alegria and Etxeberria, 2016) took an approach based on standard grapheme-tophoneme machinery. They extend the Phonetisaurus (Novak et al., 2012) toolkit, based on the OpenFST WFST library (Allauzen et al., 2007), to the task of morphological reinflection. Their system is organized as a pipeline. Given pairs of input and output strings, the first step involves an unsupervised algorithm to extract an alignment (many-to-one or one-to-many). Then, they train the weights of the WFSTs using the imputed alignments, introducing morphological tags as symbols on the input side of the transduction. Alberta The Alberta system (Nicol"
W16-2002,D08-1113,1,0.900508,"Missing"
W16-2002,C04-1022,0,0.0394056,"inct word forms for any given 1 This latter figure rises to 52 if the entire imperfectiveperfective pair (e.g. govorit’/skazat’ ‘speak, tell’) is considered to be a single lemma. 10 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 10–22, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics forms, the probability of encountering any single word form decreases, reducing the effectiveness of frequency-based techniques in performing tasks like word alignment and language modeling (Koehn, 2010; Duh and Kirchhoff, 2004). Techniques like lemmatization and stemming can ameliorate data sparsity (Goldwater and McClosky, 2005), but these rely on morphological knowledge, particularly the mapping from inflected forms to lemmas and the list of morphs together with their ordering. Developing systems that can accurately learn and capture these mappings, overt affixes, and the principles that govern how those affixes combine is crucial to maximizing the crosslinguistic capabilities of most human language technology. The goal of the 2016 SIGMORPHON Shared Task2 was to spur the development of systems that could accuratel"
W16-2002,N13-1138,0,0.0757217,"06 1.05 Table 3: Descriptive statistics on data released to shared task participants. Figures represent averages across tasks. Abbreviations in the headers: ‘Lem’ = lemmas, ‘Full’ = number of full tags, T2T = average occurrences of tag-to-tag pairs, I-Tag & O-Tag = average occurrences of each input or output tag, resp., and ‘Sync’ = average forms per tag (syncretism). • Standard Release: Arabic, Finnish, Georgian, German, Navajo, Russian, Spanish, and Turkish • Surprise: Hungarian and Maltese Finnish, German, and Spanish have been the subject of much recent work, due to data made available by Durrett and DeNero (2013), while the other datasets used in the shared task are released here for the first time. For all languages, the word forms in the data are orthographic (not phonological) strings in the native script, except in the case of Arabic, where we used the romanized forms available from Wiktionary. An accented letter is treated as a single character. Descriptive statistics of the data are provided in Table 3. The typological character of these languages varies widely. German and Spanish inflection generation has been studied extensively, and the morphological character of the languages is similar: Bot"
W16-2002,P15-1033,0,0.00992926,"the context and they represent individual morphosyntactic attributes as well. In addition, they include template-inspired components to better cope with the templatic morphology of Arabic and Maltese. The second architecture, while also neural, more radically departs from previously proposed sequence-to-sequence models. The aligner from the baseline system is used to create a series of edit actions, similar to the systems in Camp 1. Rather than use a CRF, the BIU-MIT team predicted the sequence of edit actions using a neural model, much in the same way as a transition-based LSTM parser does (Dyer et al., 2015; Kiperwasser and Goldberg, 2016). The architectural consequence of this is that it replaces the soft alignment mechanism of (Bahdanau et al., 2014) with a hard attention mechanism, similar to Rastogi et al. (2016). Camp 3: Time for Some Linguistics The third camp relied on linguistics-inspired heuristics to reduce the problem to multi-way classification. This camp is less unified than the other two, as both teams used very different heuristics. Columbia – New York University Abu Dhabi The system developed jointly by Columbia and NYUAD (Taji et al., 2016) is based on the work of Eskander et al"
W16-2002,D13-1105,0,0.0212324,"r et al., 2015; Kiperwasser and Goldberg, 2016). The architectural consequence of this is that it replaces the soft alignment mechanism of (Bahdanau et al., 2014) with a hard attention mechanism, similar to Rastogi et al. (2016). Camp 3: Time for Some Linguistics The third camp relied on linguistics-inspired heuristics to reduce the problem to multi-way classification. This camp is less unified than the other two, as both teams used very different heuristics. Columbia – New York University Abu Dhabi The system developed jointly by Columbia and NYUAD (Taji et al., 2016) is based on the work of Eskander et al. (2013). It is unique among the submitted systems in that the first step in the pipeline is segmentation of the input words into prefixes, stems, and suffixes. Prefixes and suffixes are directly associated with morphological features. Stems within paradigms are further processed, using either linguistic intuitions or an empirical approach based on string alignments, to extract the stem letters that undergo changes across inflections. The extracted patterns are intended to capture stem-internal changes, such as vowel changes in Arabic. Reinflection is performed by selecting a set of changes to apply t"
W16-2002,N16-1077,0,0.544713,"(i.e. the citation form). Thus, the task is to generate all inflections in a paradigm from the lemma and often goes by the name of paradigm completion in the literature. There has been a flurry of recent work in this vein: Durrett and DeNero (2013) heuristically extracted transformational rules and learned a statistical model to apply the rules, Nicolai et al. (2015) tackled the problem using standard tools from discriminative string transduction, Ahlberg et al. (2015) used a finite-state construction to extract complete candidate inflections at the paradigm level and then train a classifier, Faruqui et al. (2016) applied a neural sequence-to-sequence architecture (Sutskever et al., 2014) to the problem. In contrast to paradigm completion, the task of reinflection is harder as it may require both morphologically analyzing the source form and transducing it to the target form. In addition, the training set may include only partial paradigms. However, many of the approaches taken by the shared task participants drew inspiration from work on paradigm completion. Some work, however, has considered full reinflection. For example, Dreyer and Eisner (2009) and Cotterell et al. (2015) apply graphical models wi"
W16-2002,W14-4012,0,0.0716839,"Missing"
W16-2002,chrupala-etal-2008-learning,0,0.161107,"Missing"
W16-2002,L16-1498,1,0.655386,"Missing"
W16-2002,H05-1085,0,0.0534859,"pair (e.g. govorit’/skazat’ ‘speak, tell’) is considered to be a single lemma. 10 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 10–22, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics forms, the probability of encountering any single word form decreases, reducing the effectiveness of frequency-based techniques in performing tasks like word alignment and language modeling (Koehn, 2010; Duh and Kirchhoff, 2004). Techniques like lemmatization and stemming can ameliorate data sparsity (Goldwater and McClosky, 2005), but these rely on morphological knowledge, particularly the mapping from inflected forms to lemmas and the list of morphs together with their ordering. Developing systems that can accurately learn and capture these mappings, overt affixes, and the principles that govern how those affixes combine is crucial to maximizing the crosslinguistic capabilities of most human language technology. The goal of the 2016 SIGMORPHON Shared Task2 was to spur the development of systems that could accurately generate morphologically inflected words for a set of 10 languages based on a range of training parame"
W16-2002,J10-4005,0,0.0133976,"al of 10 distinct word forms for any given 1 This latter figure rises to 52 if the entire imperfectiveperfective pair (e.g. govorit’/skazat’ ‘speak, tell’) is considered to be a single lemma. 10 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 10–22, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics forms, the probability of encountering any single word form decreases, reducing the effectiveness of frequency-based techniques in performing tasks like word alignment and language modeling (Koehn, 2010; Duh and Kirchhoff, 2004). Techniques like lemmatization and stemming can ameliorate data sparsity (Goldwater and McClosky, 2005), but these rely on morphological knowledge, particularly the mapping from inflected forms to lemmas and the list of morphs together with their ordering. Developing systems that can accurately learn and capture these mappings, overt affixes, and the principles that govern how those affixes combine is crucial to maximizing the crosslinguistic capabilities of most human language technology. The goal of the 2016 SIGMORPHON Shared Task2 was to spur the development of sy"
W16-2002,W16-2006,0,0.0709506,"Missing"
W16-2002,N07-1047,0,0.0429849,"e. Given pairs of input and output strings, the first step involves an unsupervised algorithm to extract an alignment (many-to-one or one-to-many). Then, they train the weights of the WFSTs using the imputed alignments, introducing morphological tags as symbols on the input side of the transduction. Alberta The Alberta system (Nicolai et al., 2016) is derived from the earlier work by Nicolai et al. (2015) and is methodologically quite similar to that of EHU—an unsupervised alignment model is first applied to the training pairs to impute an alignment. In this case, they employ the M2M-aligner (Jiampojamarn et al., 2007). In contrast to EHU, Nicolai et al. (2016) do allow many-to-many alignments. After computing the alignments, they discriminatively learn a stringto-string mapping using the DirectTL+ model (Jiampojamarn et al., 2008). This model is stateof-the-art for the grapheme-to-phoneme task and is very similar to the EHU system in that it assumes a monotonic alignment and could therefore be encoded as a WFST. Despite the similarity to the EHU system, the model performs much better overall. This increase in performance may be attributable to the extensive use of language-specific heuristics, detailed in"
W16-2002,D15-1272,1,0.145283,"Missing"
W16-2002,N15-1093,0,0.142748,"te(3). This results in the output katto, via the following alignment: 1 k k Previous Work Much previous work on computational approaches to inflectional morphology has focused on a special case of reinflection, where the input form is always the lemma (i.e. the citation form). Thus, the task is to generate all inflections in a paradigm from the lemma and often goes by the name of paradigm completion in the literature. There has been a flurry of recent work in this vein: Durrett and DeNero (2013) heuristically extracted transformational rules and learned a statistical model to apply the rules, Nicolai et al. (2015) tackled the problem using standard tools from discriminative string transduction, Ahlberg et al. (2015) used a finite-state construction to extract complete candidate inflections at the paradigm level and then train a classifier, Faruqui et al. (2016) applied a neural sequence-to-sequence architecture (Sutskever et al., 2014) to the problem. In contrast to paradigm completion, the task of reinflection is harder as it may require both morphologically analyzing the source form and transducing it to the target form. In addition, the training set may include only partial paradigms. However, many"
W16-2002,P08-1103,0,0.0216551,"s, introducing morphological tags as symbols on the input side of the transduction. Alberta The Alberta system (Nicolai et al., 2016) is derived from the earlier work by Nicolai et al. (2015) and is methodologically quite similar to that of EHU—an unsupervised alignment model is first applied to the training pairs to impute an alignment. In this case, they employ the M2M-aligner (Jiampojamarn et al., 2007). In contrast to EHU, Nicolai et al. (2016) do allow many-to-many alignments. After computing the alignments, they discriminatively learn a stringto-string mapping using the DirectTL+ model (Jiampojamarn et al., 2008). This model is stateof-the-art for the grapheme-to-phoneme task and is very similar to the EHU system in that it assumes a monotonic alignment and could therefore be encoded as a WFST. Despite the similarity to the EHU system, the model performs much better overall. This increase in performance may be attributable to the extensive use of language-specific heuristics, detailed in the paper, or the application of a discriminative reranker. 6.2 Camp 2: Revenge of the RNN A surprising result of the shared task is the large performance gap between the top performing neural models and the rest of t"
W16-2002,W16-2005,0,0.0679067,"Missing"
W16-2002,W16-2010,0,0.168052,"Missing"
W16-2002,W12-6208,0,0.0181364,"In contrast to Durrett and DeNero (2013), who employed a 0th-order model, the OSU system used a 1st-order model. A major drawback of the system was the cost of inference. The unpruned set of edit operations had over 500 elements. As the cost of inference in the model is quadratic in the size of the state space (the number of edit operations), this created a significant slowdown with over 15 days required to train in some cases. CRF (Sarawagi and Cohen, 2004). EHU EHU (Alegria and Etxeberria, 2016) took an approach based on standard grapheme-tophoneme machinery. They extend the Phonetisaurus (Novak et al., 2012) toolkit, based on the OpenFST WFST library (Allauzen et al., 2007), to the task of morphological reinflection. Their system is organized as a pipeline. Given pairs of input and output strings, the first step involves an unsupervised algorithm to extract an alignment (many-to-one or one-to-many). Then, they train the weights of the WFSTs using the imputed alignments, introducing morphological tags as symbols on the input side of the transduction. Alberta The Alberta system (Nicolai et al., 2016) is derived from the earlier work by Nicolai et al. (2015) and is methodologically quite similar to"
W16-2002,W16-2003,0,0.0522292,"rived from the work of Ahlberg et al. (2014) and Ahlberg et al. (2015). The general idea is to use finite-state techniques to compactly model all paradigms in an abstract form called an ‘abstract paradigm’. Roughly speaking, an abstract paradigm is a set of rule transformations that derive all slots from the shared string subsequences present in each slot. Their method relies on the computation of longest common subsequence (Gusfield, 1997) to derive the abstract paradigms, which is similar to its use in the related task of lemmatization (Chrupała et al., 2008; ¨ Helsinki The Helsinki system (Ostling, 2016), like LMU and BIU-MIT, built off of the sequenceto-sequence architecture, augmenting the system with several innovations. First, a single decoder was used, rather than a unique one for all possible morphological tags, which allows for additional parameter sharing, similar to LMU. More LSTM layers were also added to the decoder, creating a deeper network. Finally, a convolutional layer over the character inputs was used, which was found to significantly increase performance over models without the convolutional layers. 17 trained a neural model to predict edit operations, consistently ranked b"
W16-2002,W16-2008,0,0.0168371,"eline system are given in Table 5. Most participants in the shared task were able to outperform the baseline, often by a significant margin. 6.1 Camp 1: Align and Transduce Most of the systems in this camp drew inspiration from the work of Durrett and DeNero (2013), who extracted a set of edit operations and applied the transformations with a semi-Markov 8 Note that at training time, we know the correct lemma for S thanks to the task 1 data, which is permitted for use by task 2 in the standard track. This is also why task 2 is permitted to use the trained task 1 system. 15 OSU The OSU system (King, 2016) also used a pipelined approach. They first extracted sequences of edit operations using Hirschberg’s algorithm (Hirschberg, 1975). This reduces the string-to-string mapping problem to a sequence tagging problem. Like the Colorado system, they followed Durrett and DeNero (2013) and used a semi-Markov CRF to apply the edit operations. In contrast to Durrett and DeNero (2013), who employed a 0th-order model, the OSU system used a 1st-order model. A major drawback of the system was the cost of inference. The unpruned set of edit operations had over 500 elements. As the cost of inference in the mo"
W16-2002,Q16-1023,0,0.0186037,"ey represent individual morphosyntactic attributes as well. In addition, they include template-inspired components to better cope with the templatic morphology of Arabic and Maltese. The second architecture, while also neural, more radically departs from previously proposed sequence-to-sequence models. The aligner from the baseline system is used to create a series of edit actions, similar to the systems in Camp 1. Rather than use a CRF, the BIU-MIT team predicted the sequence of edit actions using a neural model, much in the same way as a transition-based LSTM parser does (Dyer et al., 2015; Kiperwasser and Goldberg, 2016). The architectural consequence of this is that it replaces the soft alignment mechanism of (Bahdanau et al., 2014) with a hard attention mechanism, similar to Rastogi et al. (2016). Camp 3: Time for Some Linguistics The third camp relied on linguistics-inspired heuristics to reduce the problem to multi-way classification. This camp is less unified than the other two, as both teams used very different heuristics. Columbia – New York University Abu Dhabi The system developed jointly by Columbia and NYUAD (Taji et al., 2016) is based on the work of Eskander et al. (2013). It is unique among the"
W16-2002,N16-1076,1,0.132588,"nd architecture, while also neural, more radically departs from previously proposed sequence-to-sequence models. The aligner from the baseline system is used to create a series of edit actions, similar to the systems in Camp 1. Rather than use a CRF, the BIU-MIT team predicted the sequence of edit actions using a neural model, much in the same way as a transition-based LSTM parser does (Dyer et al., 2015; Kiperwasser and Goldberg, 2016). The architectural consequence of this is that it replaces the soft alignment mechanism of (Bahdanau et al., 2014) with a hard attention mechanism, similar to Rastogi et al. (2016). Camp 3: Time for Some Linguistics The third camp relied on linguistics-inspired heuristics to reduce the problem to multi-way classification. This camp is less unified than the other two, as both teams used very different heuristics. Columbia – New York University Abu Dhabi The system developed jointly by Columbia and NYUAD (Taji et al., 2016) is based on the work of Eskander et al. (2013). It is unique among the submitted systems in that the first step in the pipeline is segmentation of the input words into prefixes, stems, and suffixes. Prefixes and suffixes are directly associated with mo"
W16-2002,W16-2009,0,0.0638163,"of the input words into prefixes, stems, and suffixes. Prefixes and suffixes are directly associated with morphological features. Stems within paradigms are further processed, using either linguistic intuitions or an empirical approach based on string alignments, to extract the stem letters that undergo changes across inflections. The extracted patterns are intended to capture stem-internal changes, such as vowel changes in Arabic. Reinflection is performed by selecting a set of changes to apply to a stem, and attaching appropriate affixes to the result. Moscow State The Moscow State system (Sorokin, 2016) is derived from the work of Ahlberg et al. (2014) and Ahlberg et al. (2015). The general idea is to use finite-state techniques to compactly model all paradigms in an abstract form called an ‘abstract paradigm’. Roughly speaking, an abstract paradigm is a set of rule transformations that derive all slots from the shared string subsequences present in each slot. Their method relies on the computation of longest common subsequence (Gusfield, 1997) to derive the abstract paradigms, which is similar to its use in the related task of lemmatization (Chrupała et al., 2008; ¨ Helsinki The Helsinki sy"
W16-2002,D13-1021,0,0.118112,"Missing"
W16-2002,P15-2111,1,0.178102,"Missing"
W16-2112,W10-2209,0,0.0695687,"Missing"
W16-2112,N01-1020,0,0.19319,"Missing"
W16-2112,W12-6208,0,0.145369,"f variants, we have studied the state-of-theart on unsupervised and semi-supervised morphology learning. Paradigms or morphological segmentations can be inferred from historical texts without supervision. Hammarstr¨om and Borin (2011) presents an interesting survey on unsupervised methods in morphology induction. Morfessor (Creutz and Lagus, 2002) is probably the most popular out-of-the-box tool for this task. (Bernhard, 2006) proposes an alternative solution to Morfessor. In our previous work (Etxeberria et al., 2016) we have mainly used the Phonetisaurus tool,1 a WFST-driven phonology tool (Novak et al., 2012) which is commonly used to map grapheme sequences to phoneme sequences under a noisy channel model. It is a solution that relies on some amount of supervision in order to achieve adequate performance, without however, requiring large amounts of manual development. We evaluated the system on the same corpus used in this paper using the usual parameters: precision, recall and F1 -score. In the same paper we showed that the method works language-independently as we employed the same setup for both Spanish and Slovene and obtained similar or stronger results than that of previous systems reported"
W16-2112,W14-0605,0,0.0526739,"Missing"
W16-2112,E12-2021,0,0.0519672,"Missing"
W16-2112,L16-1169,1,\N,Missing
W16-2405,E09-2008,1,0.837106,"and-constructed morphophonological analyzer extended with a ‘guesser’ module to handle unknown word forms. The system takes as input sets of lemmatized words annotated with an MSD, all grouped into inflection tables—such as can be found in, for example, the Wiktionary. The output is a morphological analyzer either as an unweighted (in the non-probabilistic case) or a weighted model (in the probabilistic case). For the non-probabilistic case we use the Xerox regular expression formalism (Karttunen et al., 1996), which we compile into a transducer with the open-source finite-state toolkit foma (Hulden, 2009) and for the weighted case we have used the Kleene toolkit (Beesley, 2012).1 In this paper, we present a method to convert morphological inflection tables into unweighted and weighted finite transducers that perform parsing and generation. These transducers model the inflectional behavior of morphological paradigms induced from examples and can map inflected forms of previously unseen word forms into their lemmas and give morphosyntactic descriptions of them. The system is evaluated on several languages with data collected from the Wiktionary. 1 Introduction Wide-coverage morphological parsers"
W16-2405,E14-1060,1,0.886237,"radigms are merged. If the resulting paradigm f1 is interpreted as a function, f1 (shr, nk) produces shrink, shrank, shrunk. 2.1 Robins, 1959; Matthews, 1972; Stump, 2001). In particular, we assume a model where a single function generates all the possible inflected forms of a group of lemmas that behave alike. This approach has earlier been seen as an alternative to finite-state morphology, and the functions that model inflectional behavior have been hand-built in much previous work (Forsberg and Ranta, 2004; Forsberg et al., 2006; Détrez and Ranta, 2012). Here, we assume the recent model of Ahlberg et al. (2014) and Ahlberg et al. (2015), which work with a system that automatically learns these functions that model inflection tables from labeled data. Paradigm functions The variables x1 , . . . , xn that are used in the paradigm function representation capture possible inter-word variation. This means that each lemma that gives rise to an inflection table can be directly represented as simply an instantiation of the variables, together with the inflection function. As seen in Figure 1, the function f1 learned from the inflection tables swim and drink can be used to represent some other word, e.g. sin"
W16-2405,W14-2804,1,0.902317,"example, in Figure 1, we know that we can, for some verbs, go from the past participle (e.g. drunk) to the past (e.g. drank) by a string transformation x1 u x2 → x1 a x2 , with some constraints The purpose of modeling inflection types as functions is to be able to generalize concrete manifestations of word inflection for specific lemmas, and to apply those generalizations to unseen word forms. The generalization in question is performed by extracting the Longest Common Subsequence (LCS) from all word forms related to some specific lemma and then expressing each word form in terms of the LCS (Hulden, 2014). The LCS in turn is broken down into possibly discontiguous sequences that express parts of word forms that are variable in nature. Figure 1 shows a toy example of four inflection tables generalized into variable- and nonvariable parts by first extracting the LCS, expressing the original word forms in terms of this LCS, and then collapsing the resulting functions that are identical. The resulting representation, which is essentially a set of strings which have variable parts (x1 , . . . , xn ), and fixed parts (such as i, a, u) that 43 on the nature of x1 and x2 . This information can then be"
W16-2405,N15-1107,1,0.862371,"resulting paradigm f1 is interpreted as a function, f1 (shr, nk) produces shrink, shrank, shrunk. 2.1 Robins, 1959; Matthews, 1972; Stump, 2001). In particular, we assume a model where a single function generates all the possible inflected forms of a group of lemmas that behave alike. This approach has earlier been seen as an alternative to finite-state morphology, and the functions that model inflectional behavior have been hand-built in much previous work (Forsberg and Ranta, 2004; Forsberg et al., 2006; Détrez and Ranta, 2012). Here, we assume the recent model of Ahlberg et al. (2014) and Ahlberg et al. (2015), which work with a system that automatically learns these functions that model inflection tables from labeled data. Paradigm functions The variables x1 , . . . , xn that are used in the paradigm function representation capture possible inter-word variation. This means that each lemma that gives rise to an inflection table can be directly represented as simply an instantiation of the variables, together with the inflection function. As seen in Figure 1, the function f1 learned from the inflection tables swim and drink can be used to represent some other word, e.g. sing by instantiating x1 as s"
W16-2405,P08-1087,0,0.119459,"rform parsing and generation. These transducers model the inflectional behavior of morphological paradigms induced from examples and can map inflected forms of previously unseen word forms into their lemmas and give morphosyntactic descriptions of them. The system is evaluated on several languages with data collected from the Wiktionary. 1 Introduction Wide-coverage morphological parsers that return lemmas and morphosyntactic descriptions (MSDs) of arbitrary word forms are fundamental for achieving strong performance of many downstream tasks in NLP (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012). This is particularly true for languages that exhibit rich inflectional and derivational morphology. Finite-state transducers are the standard technology for addressing this issue, but constructing them often requires not only significant commitment of resources but also demands linguistic expertise from the developers (Maxwell, 2015). Access to large numbers of example inflections organized into inflection tables in resources such as the Wiktionary promises to offer a less laborious route to constructing robust large-scale analyzers. Learning morpholog"
W16-2405,W12-6209,0,0.371518,"ule to handle unknown word forms. The system takes as input sets of lemmatized words annotated with an MSD, all grouped into inflection tables—such as can be found in, for example, the Wiktionary. The output is a morphological analyzer either as an unweighted (in the non-probabilistic case) or a weighted model (in the probabilistic case). For the non-probabilistic case we use the Xerox regular expression formalism (Karttunen et al., 1996), which we compile into a transducer with the open-source finite-state toolkit foma (Hulden, 2009) and for the weighted case we have used the Kleene toolkit (Beesley, 2012).1 In this paper, we present a method to convert morphological inflection tables into unweighted and weighted finite transducers that perform parsing and generation. These transducers model the inflectional behavior of morphological paradigms induced from examples and can map inflected forms of previously unseen word forms into their lemmas and give morphosyntactic descriptions of them. The system is evaluated on several languages with data collected from the Wiktionary. 1 Introduction Wide-coverage morphological parsers that return lemmas and morphosyntactic descriptions (MSDs) of arbitrary w"
W16-2405,P96-1041,0,0.251557,"cover variables that show variation only in non-edge positions. For example, x2 in the avenir-paradigm in Table 3 is always n and can be assumed to not be subject to variation by the calculation above. The paradigm’s x1 -variable, however, cannot. That variable seems to vary much more, with the exception of the last letter, which is always v. To capture this, we extend the method to apply not only to the whole 2 Estimating the probability of the existence of unseen types is a classical problem (Good, 1953); see Ogino (1999) and Kageura and Sekine (1999) for linguistics-related discussions and Chen and Goodman (1996) for the relationship to smoothing in language models. 44 x1 x2 @ 0 @ 1 v v @ i:e 2 n 3 4 i 5 e:r 6 n:ϵ 7 d:ϵ o:ϵ 8 9 ϵ:[ 10 ϵ:type=participle 11 ϵ:] 12 aviniendo → avenir[type=participle] x2 x1 @ 0 @ 1 i:ϵ 2 e 3 g 4 o:a 5 ϵ:r 6 ϵ:[ 7 ϵ:person=1st 8 ϵ:number=singular 9 ϵ:tense=present 10 ϵ:mood=indicative 11 ϵ:] 12 ciego → cegar[person=1st number=singular mood=indicative] Figure 2: Examples of two single generalized word forms mapped to lemmas followed by morphosyntactic description. The parts that correspond to constraints of the variables x1 and x2 are marked. Transitions marked @ are identi"
W16-2405,E12-1066,0,0.0278457,"t Common Subsequence is extracted; (3) resulting identical paradigms are merged. If the resulting paradigm f1 is interpreted as a function, f1 (shr, nk) produces shrink, shrank, shrunk. 2.1 Robins, 1959; Matthews, 1972; Stump, 2001). In particular, we assume a model where a single function generates all the possible inflected forms of a group of lemmas that behave alike. This approach has earlier been seen as an alternative to finite-state morphology, and the functions that model inflectional behavior have been hand-built in much previous work (Forsberg and Ranta, 2004; Forsberg et al., 2006; Détrez and Ranta, 2012). Here, we assume the recent model of Ahlberg et al. (2014) and Ahlberg et al. (2015), which work with a system that automatically learns these functions that model inflection tables from labeled data. Paradigm functions The variables x1 , . . . , xn that are used in the paradigm function representation capture possible inter-word variation. This means that each lemma that gives rise to an inflection table can be directly represented as simply an instantiation of the variables, together with the inflection function. As seen in Figure 1, the function f1 learned from the inflection tables swim a"
W16-2405,N13-1138,0,0.0475868,"d, and if that also fails, consults Unconstrained. The same effect can also be modeled in runtime code by keeping the three transducers separate for potential savings of space. Table 2 illustrates this priority effect with two Spanish words being analyzed. (3) the prior of picking a paradigm (we include a paradigm weight for each individual paradigm). Similarly to the unweighted case, the final model is a union of all the individual inflection models for each paradigm and word, with the language models for the variables interleaved. 6 To evaluate the systems, we used the data set published by Durrett and DeNero (2013) (D&DN13), which includes full inflection tables for a large number of lemmas in German (nouns and verbs), Spanish (verbs), and Finnish (nouns+adjectives and verbs). That source also provides a division into train/dev/test splits, with 200 tables in dev and test, respectively. We then evaluated the ability of our systems to provide a correct lemmatization and MSD of each word form in the held-out tables, testing separately on each part of speech. For the unweighted analyzer, we use the three-part setup as described above. For the weighted case, we produce a single highest scoring analysis. The"
W16-2405,W07-1709,0,0.0305611,"Missing"
W16-2405,I05-3005,0,0.0632046,"hted and weighted finite transducers that perform parsing and generation. These transducers model the inflectional behavior of morphological paradigms induced from examples and can map inflected forms of previously unseen word forms into their lemmas and give morphosyntactic descriptions of them. The system is evaluated on several languages with data collected from the Wiktionary. 1 Introduction Wide-coverage morphological parsers that return lemmas and morphosyntactic descriptions (MSDs) of arbitrary word forms are fundamental for achieving strong performance of many downstream tasks in NLP (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012). This is particularly true for languages that exhibit rich inflectional and derivational morphology. Finite-state transducers are the standard technology for addressing this issue, but constructing them often requires not only significant commitment of resources but also demands linguistic expertise from the developers (Maxwell, 2015). Access to large numbers of example inflections organized into inflection tables in resources such as the Wiktionary promises to offer a less laborious route to constructi"
W16-2405,zeman-2008-reusable,0,0.0154261,"n. These transducers model the inflectional behavior of morphological paradigms induced from examples and can map inflected forms of previously unseen word forms into their lemmas and give morphosyntactic descriptions of them. The system is evaluated on several languages with data collected from the Wiktionary. 1 Introduction Wide-coverage morphological parsers that return lemmas and morphosyntactic descriptions (MSDs) of arbitrary word forms are fundamental for achieving strong performance of many downstream tasks in NLP (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012). This is particularly true for languages that exhibit rich inflectional and derivational morphology. Finite-state transducers are the standard technology for addressing this issue, but constructing them often requires not only significant commitment of resources but also demands linguistic expertise from the developers (Maxwell, 2015). Access to large numbers of example inflections organized into inflection tables in resources such as the Wiktionary promises to offer a less laborious route to constructing robust large-scale analyzers. Learning morphological generali"
W16-2405,hulden-francom-2012-boosting,1,0.866134,"sducers model the inflectional behavior of morphological paradigms induced from examples and can map inflected forms of previously unseen word forms into their lemmas and give morphosyntactic descriptions of them. The system is evaluated on several languages with data collected from the Wiktionary. 1 Introduction Wide-coverage morphological parsers that return lemmas and morphosyntactic descriptions (MSDs) of arbitrary word forms are fundamental for achieving strong performance of many downstream tasks in NLP (Tseng et al., 2005; Spoustová et al., 2007; Avramidis and Koehn, 2008; Zeman, 2008; Hulden and Francom, 2012). This is particularly true for languages that exhibit rich inflectional and derivational morphology. Finite-state transducers are the standard technology for addressing this issue, but constructing them often requires not only significant commitment of resources but also demands linguistic expertise from the developers (Maxwell, 2015). Access to large numbers of example inflections organized into inflection tables in resources such as the Wiktionary promises to offer a less laborious route to constructing robust large-scale analyzers. Learning morphological generalizations from such example d"
W16-2405,W16-2002,1,\N,Missing
W17-0102,W12-6201,0,0.0137008,", -een = 1P/2S, etc.4 ). Since Ara4 3 3.1 Creating Computer Resources for Arapaho Morphological Parser The best first-step solution for many of the typical problems faced by polysynthetic and agglutinating languages such as Arapaho is a morphological parser. Similar efforts has taken place for another Algonquian language, Plains Cree (Snoek et al., 2014). Having developed a finite-state morphological parser for a morphologically complex language, developing a spell checker (or even corrector), a lemmatizer, or e-dictionary tools would be more accessible for any language (Alegria et al., 2009; Pirinen and Hardwick, 2012). This is much more crucial for languages with a heavy use of morphology, such as the Algonquian languages. Since in heavily agglutinating languages one word contains what in more isolating languages is equal to several isolated words (or maybe even a full 1S/2P: 1SG Agent, 2PL Patient 12 sentence), access to a morphological analyzer for such languages is indispensable, and furthermore a prerequisite for other NLP tasks such as dependency parsing (Wagner et al., 2016). We used the foma finite-state toolkit (Hulden, 2009) to construct a finite state transducer (FST)— the standard technology for"
W17-0102,C16-1018,0,0.0676586,"Missing"
W17-0102,W14-2205,0,0.269776,"Missing"
W17-0102,W16-1719,1,0.838526,"or even corrector), a lemmatizer, or e-dictionary tools would be more accessible for any language (Alegria et al., 2009; Pirinen and Hardwick, 2012). This is much more crucial for languages with a heavy use of morphology, such as the Algonquian languages. Since in heavily agglutinating languages one word contains what in more isolating languages is equal to several isolated words (or maybe even a full 1S/2P: 1SG Agent, 2PL Patient 12 sentence), access to a morphological analyzer for such languages is indispensable, and furthermore a prerequisite for other NLP tasks such as dependency parsing (Wagner et al., 2016). We used the foma finite-state toolkit (Hulden, 2009) to construct a finite state transducer (FST)— the standard technology for producing morphological analyzers—which is bidirectional and able to simultaneously parse given surface forms and generate all possible forms for a given stem (Beesley and Karttunen, 2003). All the concatenative morphological rules as well as irregularities of the morphology of the language were taken care of using a finite-state lexicon compiler within foma, or lexc, which is a separate component in the system with a high-level declarative language for streamlining"
W17-0102,E09-2008,1,0.866271,"be more accessible for any language (Alegria et al., 2009; Pirinen and Hardwick, 2012). This is much more crucial for languages with a heavy use of morphology, such as the Algonquian languages. Since in heavily agglutinating languages one word contains what in more isolating languages is equal to several isolated words (or maybe even a full 1S/2P: 1SG Agent, 2PL Patient 12 sentence), access to a morphological analyzer for such languages is indispensable, and furthermore a prerequisite for other NLP tasks such as dependency parsing (Wagner et al., 2016). We used the foma finite-state toolkit (Hulden, 2009) to construct a finite state transducer (FST)— the standard technology for producing morphological analyzers—which is bidirectional and able to simultaneously parse given surface forms and generate all possible forms for a given stem (Beesley and Karttunen, 2003). All the concatenative morphological rules as well as irregularities of the morphology of the language were taken care of using a finite-state lexicon compiler within foma, or lexc, which is a separate component in the system with a high-level declarative language for streamlining lexicon creation modeled as finite transducers (Beesle"
W17-0418,D16-1097,0,0.0233489,"Missing"
W17-0418,N16-1080,0,0.0224562,"Missing"
W17-0418,W10-2210,0,0.107231,"to provide a more detailed morphosyntactic labeling and segmentation of the UD data. 1 2 Related Work Morphological segmentation, particularly in unsupervised scenarios, is a standard problem in NLP, and has been explored in numerous works (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more modern counterpart, word embeddings (Soricut and Och, 2015). The specific formulation of an inference problem like the one presented in this paper has to our knowledge not been directly addressed previously, probably due to the necessity of annotated resource schemas such as those present in UD 2.0. A related problem, dealt with in Cotterell et al. (2016b) and Kan"
W17-0418,N09-1024,0,0.0870541,"ings of word forms. We evaluate the method on three languages where we have manually labeled part of the Universal Dependencies data—Finnish, Swedish, and Spanish—and show that the method is robust enough to use for automatic discovery, segmentation, and labeling of allomorphs in the data sets. The model allows us to provide a more detailed morphosyntactic labeling and segmentation of the UD data. 1 2 Related Work Morphological segmentation, particularly in unsupervised scenarios, is a standard problem in NLP, and has been explored in numerous works (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more modern counterpart, word embeddings (Soricut and"
W17-0418,W00-0712,0,0.0384042,"plored in numerous works (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more modern counterpart, word embeddings (Soricut and Och, 2015). The specific formulation of an inference problem like the one presented in this paper has to our knowledge not been directly addressed previously, probably due to the necessity of annotated resource schemas such as those present in UD 2.0. A related problem, dealt with in Cotterell et al. (2016b) and Kann et al. (2016), concerns simultaneous segmentation and canonicalization— Introduction Recent versions of Universal Dependencies (UD) (Nivre et al., 2017) provide not only part-ofspeech labeling, but also universal lexica"
W17-0418,D11-1057,0,0.0119875,"We evaluate the method on three languages where we have manually labeled part of the Universal Dependencies data—Finnish, Swedish, and Spanish—and show that the method is robust enough to use for automatic discovery, segmentation, and labeling of allomorphs in the data sets. The model allows us to provide a more detailed morphosyntactic labeling and segmentation of the UD data. 1 2 Related Work Morphological segmentation, particularly in unsupervised scenarios, is a standard problem in NLP, and has been explored in numerous works (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more modern counterpart, word embeddings (Soricut and Och, 2015). The specific"
W17-0418,Q13-1021,0,0.0729929,"eling and segmentation of the UD data. 1 2 Related Work Morphological segmentation, particularly in unsupervised scenarios, is a standard problem in NLP, and has been explored in numerous works (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more modern counterpart, word embeddings (Soricut and Och, 2015). The specific formulation of an inference problem like the one presented in this paper has to our knowledge not been directly addressed previously, probably due to the necessity of annotated resource schemas such as those present in UD 2.0. A related problem, dealt with in Cotterell et al. (2016b) and Kann et al. (2016), concerns simultaneous segmentation"
W17-0418,J01-2001,0,0.0509452,"t between morphosyntactic labels and substrings of word forms. We evaluate the method on three languages where we have manually labeled part of the Universal Dependencies data—Finnish, Swedish, and Spanish—and show that the method is robust enough to use for automatic discovery, segmentation, and labeling of allomorphs in the data sets. The model allows us to provide a more detailed morphosyntactic labeling and segmentation of the UD data. 1 2 Related Work Morphological segmentation, particularly in unsupervised scenarios, is a standard problem in NLP, and has been explored in numerous works (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more mod"
W17-0418,P07-1094,0,0.013796,"obability P (s|f )P (f |s), provided that no features have yet been assigned to s, and f has not been assigned to a substring. When each substring in c has been assigned exactly one label, assign remaining labels to substrings in c which maximize the symmetric conditional probability. (1) Using c(s, f ) we express the probability of the co-occurrence of a feature and substring in Equation 2. P(s, f ) ∝ c(s, f ) + αB(s, f ) (2) The function B in Equation 2 expresses a prior belief about the joint counts of segments and labels, and hyper-parameter α controls the weight of the prior information (Goldwater and Griffiths, 2007). A large α will result in P(s, f ) which very closely reflects the prior belief while a smaller α lets P adapt more closely to the current segmentation and label assignment. We set α to 0.1 in all experiments. We use the joint distribution of substrings and labels in the unsegmented data set D as prior information. Thus B(s, f ) = #(s, f )/#(f ), where #(s, f ) is the count of substrings s in words with morphological feature f and #(f ) is the count of feature f in D. For lemma features, for example lemma=dog, we add an additional factor to the co-occurrence probability P(s, f ) as shown in E"
W17-0418,N15-1186,0,0.0306464,"al. (2009), Dreyer and Eisner (2011) inter alia). We recommend Ruokolainen et al. (2016) for an overview. Likewise, semi-supervised, or minimally supervised models—where the supervision usually implies access to some small number of segmented words—have also been widely investigated (Dasgupta and Ng, 2007; Kohonen et al., 2010; Gr¨onroos et al., 2014; Sirts and Goldwater, 2013). Many approaches also take advantage of a semantic signal, or a proxy for semantic similarity between words such as Latent Semantic Analysis (Schone and Jurafsky, 2000) or its more modern counterpart, word embeddings (Soricut and Och, 2015). The specific formulation of an inference problem like the one presented in this paper has to our knowledge not been directly addressed previously, probably due to the necessity of annotated resource schemas such as those present in UD 2.0. A related problem, dealt with in Cotterell et al. (2016b) and Kann et al. (2016), concerns simultaneous segmentation and canonicalization— Introduction Recent versions of Universal Dependencies (UD) (Nivre et al., 2017) provide not only part-ofspeech labeling, but also universal lexical and inflectional features on most word forms. Table 1 illustrates a fe"
W17-0418,C14-1111,0,0.130796,"Missing"
W17-4009,E14-1060,1,0.857015,"tion. Figure 1 illustrates this process by showing a few forms of the German verb schreiben, the extraction of the LCS, and the assignment of the LCS into variable parts. After such a generalization process, many paradigm representations which were generated from inflection tables turn out to be identical— indicating that the participating lemmas inflect according to the same pattern. Identical paradigms are collapsed, and the information about what strings were witnessed in the variable slots is stored for creating a probabilistic model of inflection. The reader is referred to (Hulden, 2014; Ahlberg et al., 2014; Ahlberg et al., 2015) for details. This model already provides a method for performing morphological analysis when previously unseen word forms are encountered. One can create a transducer based on the paradigms that maps entries in a paradigm back to their lemma form in such a way that the variable parts xi may correspond to any arbitrary string. For example, the paradigm in figure 1 would yield a lemmatizing transducer that would map e.g. geliehen P (v1 , . . . , vn ) = n Y i=1 P (vi |vi−(n−1) , . . . , vi−1 ) (1) These quantities can be estimated by maximum likelihood from the the trainin"
W17-4009,I05-3005,0,0.0101648,"based on these paradigms are tested. 1 Introduction Morphological inflection is used in many languages to convey syntactic and semantic information. It is a systematic source of sparsity for NLP tasks, especially for languages with rich morphological systems where one lexeme can be inflected into as many as over a million distinct word forms (Kibrik, 1998). In this case, morphological parsers which can convert the inflected word forms back to the lemma forms, or the other way around can largely benefit downstream tasks, like part-of-speech tagging, language modeling, and machine translation (Tseng et al., 2005; Hulden and Francom, 2012; Duh and Kirchhoff, 2004; Avramidis and Koehn, 2008). Various approaches have been adopted to tackle the morphological inflection and lemmatization problem. For example, Durrett and DeNero (2013) automatically extracts transformation rules from labeled data and learns how to apply these rules with a discriminative sequence model. Kann and Sch¨utze (2016) proposes to use a recurrent neural 1 http://www.wiktionary.org 69 Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing, pages 69–74, c 2017 Association for Computat"
W17-4009,N15-1107,1,0.815513,"ates this process by showing a few forms of the German verb schreiben, the extraction of the LCS, and the assignment of the LCS into variable parts. After such a generalization process, many paradigm representations which were generated from inflection tables turn out to be identical— indicating that the participating lemmas inflect according to the same pattern. Identical paradigms are collapsed, and the information about what strings were witnessed in the variable slots is stored for creating a probabilistic model of inflection. The reader is referred to (Hulden, 2014; Ahlberg et al., 2014; Ahlberg et al., 2015) for details. This model already provides a method for performing morphological analysis when previously unseen word forms are encountered. One can create a transducer based on the paradigms that maps entries in a paradigm back to their lemma form in such a way that the variable parts xi may correspond to any arbitrary string. For example, the paradigm in figure 1 would yield a lemmatizing transducer that would map e.g. geliehen P (v1 , . . . , vn ) = n Y i=1 P (vi |vi−(n−1) , . . . , vi−1 ) (1) These quantities can be estimated by maximum likelihood from the the training data as: P (vi |vi−(n"
W17-4009,P08-1087,0,0.0257636,"ection is used in many languages to convey syntactic and semantic information. It is a systematic source of sparsity for NLP tasks, especially for languages with rich morphological systems where one lexeme can be inflected into as many as over a million distinct word forms (Kibrik, 1998). In this case, morphological parsers which can convert the inflected word forms back to the lemma forms, or the other way around can largely benefit downstream tasks, like part-of-speech tagging, language modeling, and machine translation (Tseng et al., 2005; Hulden and Francom, 2012; Duh and Kirchhoff, 2004; Avramidis and Koehn, 2008). Various approaches have been adopted to tackle the morphological inflection and lemmatization problem. For example, Durrett and DeNero (2013) automatically extracts transformation rules from labeled data and learns how to apply these rules with a discriminative sequence model. Kann and Sch¨utze (2016) proposes to use a recurrent neural 1 http://www.wiktionary.org 69 Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing, pages 69–74, c 2017 Association for Computational Linguistics Ume˚a, Sweden, 4–6 September 2017. https://doi.org/10.18653/v"
W17-4009,C04-1022,0,0.0104299,"uction Morphological inflection is used in many languages to convey syntactic and semantic information. It is a systematic source of sparsity for NLP tasks, especially for languages with rich morphological systems where one lexeme can be inflected into as many as over a million distinct word forms (Kibrik, 1998). In this case, morphological parsers which can convert the inflected word forms back to the lemma forms, or the other way around can largely benefit downstream tasks, like part-of-speech tagging, language modeling, and machine translation (Tseng et al., 2005; Hulden and Francom, 2012; Duh and Kirchhoff, 2004; Avramidis and Koehn, 2008). Various approaches have been adopted to tackle the morphological inflection and lemmatization problem. For example, Durrett and DeNero (2013) automatically extracts transformation rules from labeled data and learns how to apply these rules with a discriminative sequence model. Kann and Sch¨utze (2016) proposes to use a recurrent neural 1 http://www.wiktionary.org 69 Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing, pages 69–74, c 2017 Association for Computational Linguistics Ume˚a, Sweden, 4–6 September 2017"
W17-4009,N13-1138,0,0.05374,"or languages with rich morphological systems where one lexeme can be inflected into as many as over a million distinct word forms (Kibrik, 1998). In this case, morphological parsers which can convert the inflected word forms back to the lemma forms, or the other way around can largely benefit downstream tasks, like part-of-speech tagging, language modeling, and machine translation (Tseng et al., 2005; Hulden and Francom, 2012; Duh and Kirchhoff, 2004; Avramidis and Koehn, 2008). Various approaches have been adopted to tackle the morphological inflection and lemmatization problem. For example, Durrett and DeNero (2013) automatically extracts transformation rules from labeled data and learns how to apply these rules with a discriminative sequence model. Kann and Sch¨utze (2016) proposes to use a recurrent neural 1 http://www.wiktionary.org 69 Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing, pages 69–74, c 2017 Association for Computational Linguistics Ume˚a, Sweden, 4–6 September 2017. https://doi.org/10.18653/v1/W17-4009 A model of Analogy is that we do not attempt to encode variation x1 in this case would coincide with the infinitive as string-changi"
W17-4009,W16-2405,1,0.85075,"for a target morphological tag combination. The SIGMORPHON 2016 shared task (Cotterell et al., 2016) of morphological reinflection received 11 systems which used various approaches such as conditional random fields (CRF), RNNs, and other linguisticsinspired heuristics. Among all the methods, one standard technology is to use finite-state transducers, which are more interpretable and manually modifiable, and thus more easily incorporated into and made to assist linguists’ work. Hulden (2014) presents a method to generalize inflection tables into paradigms with finite state implementations and Forsberg and Hulden (2016) subsequently introduce how to transform morphological inflection tables into both unweighted and weighted finite transducers and apply the transducers to parsing and generation, the result of which is very promising, especially for facilitating and assisting linguists’ work in addition to applications to morphological parsing and generation for downstream NLP tasks. However, the system was evaluated with only three languages (German, Spanish, and Finnish), all with Latin script. This paper intends to carry out a more extensive evaluation of this method. Wiktionary1 provides a source of morpho"
W17-4009,hulden-francom-2012-boosting,1,0.738559,"digms are tested. 1 Introduction Morphological inflection is used in many languages to convey syntactic and semantic information. It is a systematic source of sparsity for NLP tasks, especially for languages with rich morphological systems where one lexeme can be inflected into as many as over a million distinct word forms (Kibrik, 1998). In this case, morphological parsers which can convert the inflected word forms back to the lemma forms, or the other way around can largely benefit downstream tasks, like part-of-speech tagging, language modeling, and machine translation (Tseng et al., 2005; Hulden and Francom, 2012; Duh and Kirchhoff, 2004; Avramidis and Koehn, 2008). Various approaches have been adopted to tackle the morphological inflection and lemmatization problem. For example, Durrett and DeNero (2013) automatically extracts transformation rules from labeled data and learns how to apply these rules with a discriminative sequence model. Kann and Sch¨utze (2016) proposes to use a recurrent neural 1 http://www.wiktionary.org 69 Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing, pages 69–74, c 2017 Association for Computational Linguistics Ume˚a, S"
W17-4009,W14-2804,1,0.918412,"olorado first.last@colorado.edu Abstract network (RNN) encoder-decoder model to generate an inflected form of a lemma for a target morphological tag combination. The SIGMORPHON 2016 shared task (Cotterell et al., 2016) of morphological reinflection received 11 systems which used various approaches such as conditional random fields (CRF), RNNs, and other linguisticsinspired heuristics. Among all the methods, one standard technology is to use finite-state transducers, which are more interpretable and manually modifiable, and thus more easily incorporated into and made to assist linguists’ work. Hulden (2014) presents a method to generalize inflection tables into paradigms with finite state implementations and Forsberg and Hulden (2016) subsequently introduce how to transform morphological inflection tables into both unweighted and weighted finite transducers and apply the transducers to parsing and generation, the result of which is very promising, especially for facilitating and assisting linguists’ work in addition to applications to morphological parsing and generation for downstream NLP tasks. However, the system was evaluated with only three languages (German, Spanish, and Finnish), all with"
W17-4009,P16-2090,0,0.191079,"Missing"
W17-4009,L16-1498,0,0.01292,"presentativeness of the data. A summary of the languages, language groups and scripts is presented in table 1. The data for each language is used just at it is from the database. Little work is done to improve the quality of the data. Therefore, if there are misspellings or incorrect inflections in the data set, the paradigms are extracted and tested with any errors uncorrected. Table 1: Languages, Language Groups, and Scripts 2.2 Evaluation The paradigm extraction and application method presented in the previous part is evaluated with 55 languages from the Wiktionary Morphological Database2 (Kirov et al., 2016) as part of the UniMorph project3 which includes data for 350 languages at the time we downloaded it.4 For each The number of inflection tables may not be the same as the number of lemmas, because in cases where there are alternative inflected forms for one morphosyntactic description of a lemma in the UniMorph database, each form is represented in a separate table. 2 https://github.com/ckirov/UniMorph/tree/master/data http://www.unimorph.org 4 The 55 languages are: Adyghe, Albanian, Armenian, Asturian, Bashkir, Basque, Bengali, Bulgarian, Catalan, Danish, Dutch, Esperanto, Estonian, Faroese,"
W17-4107,J93-2003,0,0.142346,"Missing"
W17-4107,D11-1057,0,0.0276573,"abels and allomorphs have similar distributions throughout a data set.1 We also compare the performance of the various methods to a baseline unsupervised model, Morfessor2 , augmented with the capacity to also provide labels of allomorphs in addition to segmenting. 1 Our code is freely available at https://github. com/mpsilfve/learn-allomorphs 2 http://www.cis.hut.fi/projects/ morpho/morfessor2.shtml 2 Related Work In the realm of natural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is s"
W17-4107,Q16-1001,0,0.0182115,"onen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological inflection from examples (Cotterell et al., 2016a). To our knowledge, the weakly supervised learning problem addressed in this paper has not been considered in the literature. Cotterell et al. (2015) present a closely related task. They investigate labeled morphological segmentation, that is, simultaneous segmentation and labeling of segments with morphological features. The crucial difference between our work and the work by Cotterell et al. (2015) is that our models are learned in a weakly supervised manner from plain word forms and sets of morphological features. In cont"
W17-4107,J01-2001,0,0.183776,", and a model of Kullback-Leibler divergence that favors that labels and allomorphs have similar distributions throughout a data set.1 We also compare the performance of the various methods to a baseline unsupervised model, Morfessor2 , augmented with the capacity to also provide labels of allomorphs in addition to segmenting. 1 Our code is freely available at https://github. com/mpsilfve/learn-allomorphs 2 http://www.cis.hut.fi/projects/ morpho/morfessor2.shtml 2 Related Work In the realm of natural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allom"
W17-4107,C14-1111,0,0.0230225,"menting. 1 Our code is freely available at https://github. com/mpsilfve/learn-allomorphs 2 http://www.cis.hut.fi/projects/ morpho/morfessor2.shtml 2 Related Work In the realm of natural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological"
W17-4107,K15-1017,0,0.078384,"iple morphological features. We treat the problem of joint segmentation and feature assignment as a search problem in the space of all possible segmentations and labelings of each word form in a (weakly) annotated corpus. The crucial constraint provided by the weak labeling is that not all labels can be present in a word form—the set of labels present for each inflected word must be restricted to those given by the resource. To our knowledge, this weakly supervised task has not previously been explored although joint segmentation and labeling has been explored in a fully supervised setting by Cotterell et al. (2015). To solve the problem, we explore global metrics that indirectly favor re-use of allomorphs according to the intuition given above. We formalize a generic objective function that scores the goodness of segmentations and labeling globally in a corpus. The scoring portion of this objective function is tested with several metrics: symmetric conditional probability, which favors that allomorphs be good predictors of labels and vice versa, a perceptron learner that weights allomorph-label association, a Rescorla-Wagner model based on classical conditioning that also learns such association weights"
W17-4107,N16-1080,0,0.06286,"). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological inflection from examples (Cotterell et al., 2016a). To our knowledge, the weakly supervised learning problem addressed in this paper has not been considered in the literature. Cotterell et al. (2015) present a closely related task. They investigate labeled morphological segmentation, that is, simultaneous segmentation and labeling of segments with morphological features. The crucial difference between our work and the work by Cotterell et al. (2015) is that our models are learned in a weakly supervised manner from plain word forms and sets of morphological features. In contrast, Cotterell et al. (2015) learn segmentation models in a fully s"
W17-4107,D16-1097,0,0.0142084,"on is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological inflection from examples (Cotterell et al., 2016a). To our knowledge, the weakly supervised learning problem addressed in this paper has not been considered in the literature. Cotterell et al. (2015) present a closely related t"
W17-4107,W10-2210,0,0.0213661,"phs in addition to segmenting. 1 Our code is freely available at https://github. com/mpsilfve/learn-allomorphs 2 http://www.cis.hut.fi/projects/ morpho/morfessor2.shtml 2 Related Work In the realm of natural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2"
W17-4107,W00-0712,0,0.201791,"tural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological inflection from examples (Cotterell et al., 2016a). To our knowledge, the weakly supervised learning problem addressed in this paper has not been considered in the literature. Cottere"
W17-4107,Q13-1021,0,0.0152242,"freely available at https://github. com/mpsilfve/learn-allomorphs 2 http://www.cis.hut.fi/projects/ morpho/morfessor2.shtml 2 Related Work In the realm of natural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological inflection from examples (C"
W17-4107,N15-1186,0,0.0288879,"morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to have ing, a task which is somewhat related to the problem addressed in this paper. Many methods that tackle specific morphology-related NLP tasks implicitly learn some model of allomorphy. This includes semi-supervised vocabulary expansion (Faruqui et al., 2016), and morphological inflection from examples (Cotterell et al., 2016a). To our knowledge, the weakly supervised learning problem addressed in this paper has not been considered in the literature. Cotterell et al. (2015) present"
W17-4107,N09-1024,0,0.029905,"e that favors that labels and allomorphs have similar distributions throughout a data set.1 We also compare the performance of the various methods to a baseline unsupervised model, Morfessor2 , augmented with the capacity to also provide labels of allomorphs in addition to segmenting. 1 Our code is freely available at https://github. com/mpsilfve/learn-allomorphs 2 http://www.cis.hut.fi/projects/ morpho/morfessor2.shtml 2 Related Work In the realm of natural language processing, morphological segmentation is a well-researched and established problem (Goldsmith (2001), Creutz and Lagus (2005), Poon et al. (2009), Dreyer and Eisner (2011), Ruokolainen et al. (2016)). While most approaches to pure segmentation are unsupervised, semi-supervised work usually assumes the availability of a limited number of gold segmentations (Dasgupta and Ng, 2007; Kohonen et al., 2010; Grönroos et al., 2014; Sirts and Goldwater, 2013). Using vector space representations of words to produce a weak labeling that identifies related forms has also been investigated (Schone and Jurafsky, 2000; Soricut and Och, 2015). Kann et al. (2016) perform unsupervised canonicalization of allomorphs, transforming words such as having to h"
W18-0209,K17-2001,1,0.829145,"a given sentence context. Because hand-crafted morphological analyzers have been shown to improve the performance of neural taggers (Sagot and Martínez Alonso, 2017), the task of data-driven morphological analysis is, nevertheless, important. The task explored in this paper is closely related to the construction of morphological guessers (Lindén, 2009), where the aim is to guess the inflectional type of a word. To the best of our knowledge deep learning methods have, however, not been applied to this task. In contrast, there is a growing body of work on deep learning for word form generation (Cotterell et al., 2017, 2016). In word form generation, or morphological reinflection, the aim is to generate word forms given lemmas and morphological analyses. Therefore, it can be seen as a natural counterpart to morphological analysis. Our work is inspired by the encoder-decoder models commonly applied in morphological reinflection (for example Kann and Schütze (2017)) but the task at hand is naturally quite different. Several approaches have been explored for returning one analysis, or a small set of possible analyses, for a word form in context. For example, Kudo et al. (2004) apply 101 Conditional Random Fie"
W18-0209,W04-3230,0,0.0912063,"ng for word form generation (Cotterell et al., 2017, 2016). In word form generation, or morphological reinflection, the aim is to generate word forms given lemmas and morphological analyses. Therefore, it can be seen as a natural counterpart to morphological analysis. Our work is inspired by the encoder-decoder models commonly applied in morphological reinflection (for example Kann and Schütze (2017)) but the task at hand is naturally quite different. Several approaches have been explored for returning one analysis, or a small set of possible analyses, for a word form in context. For example, Kudo et al. (2004) apply 101 Conditional Random Fields for morphological analysis of Japanese but their system only returns one tokenization for a sentence and one analysis per token. This is not the same task as the one we are exploring, where the objective is to return the complete set of possible analyses. Similar in spirit is the work on Kazakh morphological analysis by Makhambetov et al. (2015). Their system, based on Hidden Markov Models, returns a subset of the analyses of a token which could plausibly occur in a given context. Sequence models are a natural choice when the aim is to generate one analysis"
W18-0209,W15-1821,0,0.0565816,"o hand-crafted analyzers, namely, data-driven morphological analyzers which are learned from annotated training data. In our case, the training data consists of words and complete sets of analyses. During test time, the system takes a Finnish word such as kisaan (‘into the competition’ or ‘I am competing’) as input and gives a set of analyses {Noun+Sg+Ill, Verb+Act+Indv+Pres+Sg1} as output. We present experiments in data-driven morphological analysis of Finnish. We learn to mimic the OMorFi analyzer (Pirinen et al., 2017) on the Finnish portion of the Universal Dependency treebank collection (Pyysalo et al., 2015). The data sets and OMorFi analyzer are further discussed in Section 3. We use a deep learning model encompassing a character-level recurrent model, which maps words onto sets of analyses as explained in Section 4. Our results, described in Section 5, show that this line of research is encouraging. We present related work in Section 2 and present concluding remarks in Section 6. 2 Related Work The task of data-driven morphological analysis has received far less attention than morphological tagging and disambiguation which aim at producing exactly one analysis, which is correct in a given sente"
W18-0209,W17-6304,0,0.0408634,"Missing"
W18-0314,N16-1077,0,0.0386412,"el, coronal/non-coronal, and front/back distinctions from unlabeled phonetic data or orthographic data from phonemic writing systems. 137 Learning features directly from waveform representations (see e.g. Lin (2005))—while not addressed in this paper—is also highly relevant to the current study, and is indeed a question to which some lower-level, speech signal-based form of distributed representations may be adapted. The idea explored in this paper—that phonemes (or graphemes) might exhibit linguistically apt correlations in an embedding space—has been implied by earlier research, for example Faruqui et al. (2016). In that work, a neural encoder-decoder model (Cho et al., 2014; Sutskever et al., 2014) was trained to perform a transformation of words from their citation forms to a ‘target’ inflected form and, after training, the vowels in the embedding layer of the long-short term memory (LSTM) neural model trained for Finnish were found to clearly group themselves according to known harmony patterns in the language. Li et al. (2016) take advantage of phoneme transcriptions in a neural speech synthesis application, showing improvements on this task and indicating that similar phonemes in a bidirectional"
W18-0314,K17-1030,1,0.843096,"nt often take advantage of such patterns (Guy, 1991; Sukhotin, 1962, 1973). Local co-occurrence counts have also been analyzed through spectral methods, such as singular value decomposition (Moler and Morrison, 1983; Goldsmith and Xanthos, 2009; Thaine and Penn, 2017), revealing that significant latent structure can be recovered, mainly with respect to vowels and consonants. Recent works along the same lines of inquiry include Kim and Snyder (2013) that presents a Bayesian approach that simultaneously clusters languages and reveals consonant/vowel/nasal distinctions in an unsupervised manner. Hulden (2017) shows that an algorithm based on the obligatory contour principle (Leben, 1973) and an additional assumption of phonological tiers being present (Goldsmith, 1976) robustly reveals at least consonant/vowel, coronal/non-coronal, and front/back distinctions from unlabeled phonetic data or orthographic data from phonemic writing systems. 137 Learning features directly from waveform representations (see e.g. Lin (2005))—while not addressed in this paper—is also highly relevant to the current study, and is indeed a question to which some lower-level, speech signal-based form of distributed represen"
W18-0314,P13-1150,0,0.0284827,"way in phonemic writing systems is an early observation that some articulatory features can be recovered in an unsupervised way. Algorithms for cryptographic decipherment often take advantage of such patterns (Guy, 1991; Sukhotin, 1962, 1973). Local co-occurrence counts have also been analyzed through spectral methods, such as singular value decomposition (Moler and Morrison, 1983; Goldsmith and Xanthos, 2009; Thaine and Penn, 2017), revealing that significant latent structure can be recovered, mainly with respect to vowels and consonants. Recent works along the same lines of inquiry include Kim and Snyder (2013) that presents a Bayesian approach that simultaneously clusters languages and reveals consonant/vowel/nasal distinctions in an unsupervised manner. Hulden (2017) shows that an algorithm based on the obligatory contour principle (Leben, 1973) and an additional assumption of phonological tiers being present (Goldsmith, 1976) robustly reveals at least consonant/vowel, coronal/non-coronal, and front/back distinctions from unlabeled phonetic data or orthographic data from phonemic writing systems. 137 Learning features directly from waveform representations (see e.g. Lin (2005))—while not addressed"
W18-0314,W14-1618,0,0.23462,"1 1 “the meaning of a word is its use in the language” (Wittgenstein, 1953, p.43) Firth,2 Harris,3 and other contemporaries. Often overlooked is that this hypothesis among linguists has extended itself much wider to include phonology and grammar: ”all elements of speech (phonological, lexical, and grammatical) are now to be defined and classified in terms of their relations to one another” (Haas, 1954, p.54). Given the successes of distributional models not only in specifying semantic similarity, but also addressing proportional analogy tasks (Turney and Pantel, 2010; Mikolov et al., 2013a,b; Levy et al., 2014), we want to investigate if distributional representations of phonemes induce a similarly coherent space as lexical items do, and if the properties of such spaces conform to linguistic expectations, a question posed in another form as early as in Fischer-Jørgensen (1952). In particular, we address two questions: (1) whether learned vector representations of phonemes are congruent with commonly assumed binary phonological distinctive feature spaces, and (2) whether a proportional analogy of the type a:b::c:d (a is to b as c is to d) discovered in a phoneme embedding space is also a valid analog"
W18-0314,N13-1090,0,0.393283,"he likes of Wittgenstein,1 1 “the meaning of a word is its use in the language” (Wittgenstein, 1953, p.43) Firth,2 Harris,3 and other contemporaries. Often overlooked is that this hypothesis among linguists has extended itself much wider to include phonology and grammar: ”all elements of speech (phonological, lexical, and grammatical) are now to be defined and classified in terms of their relations to one another” (Haas, 1954, p.54). Given the successes of distributional models not only in specifying semantic similarity, but also addressing proportional analogy tasks (Turney and Pantel, 2010; Mikolov et al., 2013a,b; Levy et al., 2014), we want to investigate if distributional representations of phonemes induce a similarly coherent space as lexical items do, and if the properties of such spaces conform to linguistic expectations, a question posed in another form as early as in Fischer-Jørgensen (1952). In particular, we address two questions: (1) whether learned vector representations of phonemes are congruent with commonly assumed binary phonological distinctive feature spaces, and (2) whether a proportional analogy of the type a:b::c:d (a is to b as c is to d) discovered in a phoneme embedding space"
W18-0314,W17-4112,0,0.0162977,"ored in the literature for unsupervised discovery of phonological features. The observation of Markov (1913, 2006) that vowels and consonants tend to alternate in a statistically robust way in phonemic writing systems is an early observation that some articulatory features can be recovered in an unsupervised way. Algorithms for cryptographic decipherment often take advantage of such patterns (Guy, 1991; Sukhotin, 1962, 1973). Local co-occurrence counts have also been analyzed through spectral methods, such as singular value decomposition (Moler and Morrison, 1983; Goldsmith and Xanthos, 2009; Thaine and Penn, 2017), revealing that significant latent structure can be recovered, mainly with respect to vowels and consonants. Recent works along the same lines of inquiry include Kim and Snyder (2013) that presents a Bayesian approach that simultaneously clusters languages and reveals consonant/vowel/nasal distinctions in an unsupervised manner. Hulden (2017) shows that an algorithm based on the obligatory contour principle (Leben, 1973) and an additional assumption of phonological tiers being present (Goldsmith, 1976) robustly reveals at least consonant/vowel, coronal/non-coronal, and front/back distinctions"
W18-0314,W16-2010,0,\N,Missing
W18-4802,P17-4012,0,0.102562,"Missing"
W18-4802,W18-0209,1,0.705361,"ed to mimic the behavior of a classical morphological analyzer, since it needs to return multiple options, and a neural encoder-decoder really encapsulates a distribution over all possible output strings Σ∗ for any input string read by the encoder. An unexpected “advantage” of applying this to polysynthetic languages is that, while the verb complex in polysynthetic languages tends to be very intricate and is time-consuming to model, it proffers typically less ambiguity of a parse (as will be discussed in Section 6). Even when ambiguous readings are possible, they tend to be highly systematic. Silfverberg and Hulden (2018) documents a neural model from an FST model for Finnish (an agglutinative language) to retrieve all plausible parses of a word form, reporting an F1 -score of 0.92. The authors report that the recall was far lower than the precision, indicating difficulty in learning to return all the valid parses. The problem of unsystematic ambiguity, however, can often be avoided in the parsing of verbs in polysynthetic languages with mostly systematic ambiguity. Navajo, for example, collapses singulars and duoplurals in the 3rd and 4th person, and so the ambiguity between the two could be encoded by introd"
W18-4809,E14-1060,1,0.842717,"urce languages. Under-documented languages rarely have sufficient data for a thorough morphological description. If unsupervised approaches were better known among documentary linguists, it might encourage them to archive more minimally-annotated data, which is a high-priority but rarely-met goal in language documentation. For language documentation methods, more interesting approaches are those that augment small amounts of supervised data with unsupervised data. Supervised and semi-supervised learning generally requires less data to train and yields better results than unsupervised methods (Ahlberg et al., 2014; Ruokolainen et al., 2013; Cotterell et al., 2015; Kann et al., 2017). Several recent CoNLL papers (Cotterell et al., 2017) showed that very small amounts of annotated data could be augmented by exploiting either structured, labeled data, raw texts, or even artificial data. This assumes, however, that the data has already been processed in some way and made accessible. This paper looks at ongoing annotation and not generally accessible data. This paper is most closely related to experiments on whether active learning could speed the timeconsuming analysis of documentation data (Baldridge and"
W18-4809,auer-etal-2010-elan,0,0.219407,"d those marking objects, dative, or genitive arguments may be nearly as frequent. Only a small percentage of tokens contain unusual and interesting morphological forms. Thus, a large chunk of this highly time-consuming work is as monotonous to the annotator as it is uninformative to language science—in short, we are faced with a bottleneck (Holton et al., 2017; Simons, 2013). After nearly 30 years of emphasis on increasing accessible documentation data, very few computational tools have been applied to this bottleneck. The most popular software packages designed for linguistic analysis, ELAN (Auer et al., 2010) and FLEx (Rogers, 2010), provide almost no automated aid for common, repetitive tasks, although FLEx does copy the annotator’s work onto subsequent tokens if they are identical to previously analyzed tokens. To address this problem, we apply machine learning models to two common tasks applied to documentation data: morpheme segmentation and glossing. The models use about 3,000 words of manuallyannotated data that train sequence models to predict morpheme labels (and glosses). The goal is to achieve accurate results on more data in less time. A case study on Lezgi [lez] explores three issues a"
W18-4809,D09-1031,0,0.708752,"g et al., 2014; Ruokolainen et al., 2013; Cotterell et al., 2015; Kann et al., 2017). Several recent CoNLL papers (Cotterell et al., 2017) showed that very small amounts of annotated data could be augmented by exploiting either structured, labeled data, raw texts, or even artificial data. This assumes, however, that the data has already been processed in some way and made accessible. This paper looks at ongoing annotation and not generally accessible data. This paper is most closely related to experiments on whether active learning could speed the timeconsuming analysis of documentation data (Baldridge and Palmer, 2009; Palmer, 2009; Palmer et al., 2010). The experiments used field data processed with linguistic analysis software that are no longer supported. Our paper uses data from FLEx, currently one of the two most popular software modules for linguistic analysis. Earlier work has encountered complications because the analysis of certain morphemes has changed the middle of the project. This is normal—linguistic analysis, especially when a language has not been well-described before, is a dynamic, continually evolving process. Palmer et al. (2010) performed unsupervised morphological processing and semi-"
W18-4809,W02-1502,0,0.0606188,"Missing"
W18-4809,P16-1184,0,0.0600931,"Missing"
W18-4809,D07-1022,0,0.0218549,"th very high accuracy. These exceptions—aorist tense (AOR) - identical to the aorist converb, genitive case (GEN) - identical to the nominalized verb marker (masdar), ergative case (ERG) and the oblique affix (OBL) which are identical to each other and highly allomorphic—indicate that limited data may not be sufficient for languages with extensive allomorphy. When the CRF is placed in a pipeline with a SVM classifier, the CRF only identified morpheme boundaries. Overall accuracy of the pipeline was worse than the CRF-only model, achieving an average 0.86 F1 -score. This echoes the findings of Cohen and Smith (2007) and Lee et al. (2011) that joint training of syntax and morphology produce better results than separate training. The pipeline model had slightly higher accuracy on morphemes with multiple allomorphs but tended to perform worse on less frequent morphemes. Lastly, the data was run on a bidirectional sequence-to-sequence deep neural network. The best result on the test set was over 0.76 F1 , reached at 500 epochs with early stopping. 6 Discussion and Future Work It is crucial to test the models on other languages, especially polysynthetic languages which may not have many more morphemes per wor"
W18-4809,K15-1017,0,0.0584353,"y have sufficient data for a thorough morphological description. If unsupervised approaches were better known among documentary linguists, it might encourage them to archive more minimally-annotated data, which is a high-priority but rarely-met goal in language documentation. For language documentation methods, more interesting approaches are those that augment small amounts of supervised data with unsupervised data. Supervised and semi-supervised learning generally requires less data to train and yields better results than unsupervised methods (Ahlberg et al., 2014; Ruokolainen et al., 2013; Cotterell et al., 2015; Kann et al., 2017). Several recent CoNLL papers (Cotterell et al., 2017) showed that very small amounts of annotated data could be augmented by exploiting either structured, labeled data, raw texts, or even artificial data. This assumes, however, that the data has already been processed in some way and made accessible. This paper looks at ongoing annotation and not generally accessible data. This paper is most closely related to experiments on whether active learning could speed the timeconsuming analysis of documentation data (Baldridge and Palmer, 2009; Palmer, 2009; Palmer et al., 2010)."
W18-4809,K17-2001,1,0.926406,"ervised approaches were better known among documentary linguists, it might encourage them to archive more minimally-annotated data, which is a high-priority but rarely-met goal in language documentation. For language documentation methods, more interesting approaches are those that augment small amounts of supervised data with unsupervised data. Supervised and semi-supervised learning generally requires less data to train and yields better results than unsupervised methods (Ahlberg et al., 2014; Ruokolainen et al., 2013; Cotterell et al., 2015; Kann et al., 2017). Several recent CoNLL papers (Cotterell et al., 2017) showed that very small amounts of annotated data could be augmented by exploiting either structured, labeled data, raw texts, or even artificial data. This assumes, however, that the data has already been processed in some way and made accessible. This paper looks at ongoing annotation and not generally accessible data. This paper is most closely related to experiments on whether active learning could speed the timeconsuming analysis of documentation data (Baldridge and Palmer, 2009; Palmer, 2009; Palmer et al., 2010). The experiments used field data processed with linguistic analysis softwar"
W18-4809,J01-2001,0,0.490543,"ed an agglutinative language like Lezgi, then minimal feature-tweaking could make the model equally successful on more fusional languages. Lastly, what might the errors in the case study indicate for typologically different languages? Section 2 reviews related work. Section 3 introduces the case study and Section 4 describes the models used. The results are compared and analyzed in Section 5. Implications and future work are discussed in Section 6, before the conclusion in Section 7. 2 Related Work Computational linguistics boasts a long history of successful unsupervised morphology learning (Goldsmith, 2001; Creutz and Lagus, 2005; Monson et al., 2007). One feature that unsupervised models share 85 is the requirement for large amounts of data. Ironically, languages with large amounts of data available likely already have published morphological descriptions and some interlinearized text, even though they may be considered low-resource languages. Under-documented languages rarely have sufficient data for a thorough morphological description. If unsupervised approaches were better known among documentary linguists, it might encourage them to archive more minimally-annotated data, which is a high-p"
W18-4809,W17-0105,0,0.0239273,"ces inconsistent annotations. It is noteworthy that many mistakes are not due to the difficulty of the task but because of its repetitive nature. In case marking languages, for example, morphemes marking subjects will be found in practically every clause and those marking objects, dative, or genitive arguments may be nearly as frequent. Only a small percentage of tokens contain unusual and interesting morphological forms. Thus, a large chunk of this highly time-consuming work is as monotonous to the annotator as it is uninformative to language science—in short, we are faced with a bottleneck (Holton et al., 2017; Simons, 2013). After nearly 30 years of emphasis on increasing accessible documentation data, very few computational tools have been applied to this bottleneck. The most popular software packages designed for linguistic analysis, ELAN (Auer et al., 2010) and FLEx (Rogers, 2010), provide almost no automated aid for common, repetitive tasks, although FLEx does copy the annotator’s work onto subsequent tokens if they are identical to previously analyzed tokens. To address this problem, we apply machine learning models to two common tasks applied to documentation data: morpheme segmentation and"
W18-4809,E17-1049,0,0.0773881,"or a thorough morphological description. If unsupervised approaches were better known among documentary linguists, it might encourage them to archive more minimally-annotated data, which is a high-priority but rarely-met goal in language documentation. For language documentation methods, more interesting approaches are those that augment small amounts of supervised data with unsupervised data. Supervised and semi-supervised learning generally requires less data to train and yields better results than unsupervised methods (Ahlberg et al., 2014; Ruokolainen et al., 2013; Cotterell et al., 2015; Kann et al., 2017). Several recent CoNLL papers (Cotterell et al., 2017) showed that very small amounts of annotated data could be augmented by exploiting either structured, labeled data, raw texts, or even artificial data. This assumes, however, that the data has already been processed in some way and made accessible. This paper looks at ongoing annotation and not generally accessible data. This paper is most closely related to experiments on whether active learning could speed the timeconsuming analysis of documentation data (Baldridge and Palmer, 2009; Palmer, 2009; Palmer et al., 2010). The experiments used"
W18-4809,W11-0301,0,0.0193763,"e exceptions—aorist tense (AOR) - identical to the aorist converb, genitive case (GEN) - identical to the nominalized verb marker (masdar), ergative case (ERG) and the oblique affix (OBL) which are identical to each other and highly allomorphic—indicate that limited data may not be sufficient for languages with extensive allomorphy. When the CRF is placed in a pipeline with a SVM classifier, the CRF only identified morpheme boundaries. Overall accuracy of the pipeline was worse than the CRF-only model, achieving an average 0.86 F1 -score. This echoes the findings of Cohen and Smith (2007) and Lee et al. (2011) that joint training of syntax and morphology produce better results than separate training. The pipeline model had slightly higher accuracy on morphemes with multiple allomorphs but tended to perform worse on less frequent morphemes. Lastly, the data was run on a bidirectional sequence-to-sequence deep neural network. The best result on the test set was over 0.76 F1 , reached at 500 epochs with early stopping. 6 Discussion and Future Work It is crucial to test the models on other languages, especially polysynthetic languages which may not have many more morphemes per word but have more fusion"
W18-4809,W13-3504,0,0.0262875,"documented languages rarely have sufficient data for a thorough morphological description. If unsupervised approaches were better known among documentary linguists, it might encourage them to archive more minimally-annotated data, which is a high-priority but rarely-met goal in language documentation. For language documentation methods, more interesting approaches are those that augment small amounts of supervised data with unsupervised data. Supervised and semi-supervised learning generally requires less data to train and yields better results than unsupervised methods (Ahlberg et al., 2014; Ruokolainen et al., 2013; Cotterell et al., 2015; Kann et al., 2017). Several recent CoNLL papers (Cotterell et al., 2017) showed that very small amounts of annotated data could be augmented by exploiting either structured, labeled data, raw texts, or even artificial data. This assumes, however, that the data has already been processed in some way and made accessible. This paper looks at ongoing annotation and not generally accessible data. This paper is most closely related to experiments on whether active learning could speed the timeconsuming analysis of documentation data (Baldridge and Palmer, 2009; Palmer, 2009"
W18-5818,K17-2003,0,0.0571645,"Missing"
W18-5818,D15-1166,0,0.0432203,"segments. c a t s <EOS> E E E E E E Decoder RNN Attn Encoder Bi-RNN E E E E E E E <EOS> c a t N PL <EOS> Figure 1: The encoder-decoder with an attention mechanism used for morphological inflection [k,æ,t] -syl -son … -ant +hi +syl +son … 0ant -hi -syl -son … +ant -hi Figure 2: PanPhon transforms a sequence of IPA segments into a matrix of features output embedding, and all of the encoder states ei ∈ Encoder. We then use an attention mechanism (Bahdanau et al., 2014) to ‘attend’ over the encoder states, assigning a score to each ei given the previous decoder state dj−1 . The scoring function (Luong et al., 2015) is calculated as Related Work Phonetic distributional vectors have been explored for their effectiveness in several NLP applications; especially for informing scenarios that utilize borrowing or transfer learning (Tsvetkov et al., 2016). Phonological distinctive features have also been successfully used to inform NER (Bharadwaj et al., 2016). However, to our knowledge, there does not seem to be work in learning distributional properties of phonological features that compares them directly to vectors of IPA segments. 2 <EOS> score(ei ; dj−1 ) = tanh([dj−1 ; ei ] × W ) (1) where W is a paramete"
W18-5818,K17-2002,0,0.0587406,"Missing"
W18-5818,D16-1153,0,0.0658242,"f features output embedding, and all of the encoder states ei ∈ Encoder. We then use an attention mechanism (Bahdanau et al., 2014) to ‘attend’ over the encoder states, assigning a score to each ei given the previous decoder state dj−1 . The scoring function (Luong et al., 2015) is calculated as Related Work Phonetic distributional vectors have been explored for their effectiveness in several NLP applications; especially for informing scenarios that utilize borrowing or transfer learning (Tsvetkov et al., 2016). Phonological distinctive features have also been successfully used to inform NER (Bharadwaj et al., 2016). However, to our knowledge, there does not seem to be work in learning distributional properties of phonological features that compares them directly to vectors of IPA segments. 2 <EOS> score(ei ; dj−1 ) = tanh([dj−1 ; ei ] × W ) (1) where W is a parameter matrix that is learned during training, and [x; y] indicates the concatenation of x and y. These scores are then normalized by applying a softmax over all encoder states in Encoder to compute each i,j−1 . Finally, the attention vector is computed as the weighted mean of all encoder states according to their normalized score: A(dj−1 , E) ="
W18-5818,C16-1328,0,0.0513823,"ll have been found. In the medium setting, the difference in accuracy is much more apparent. This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (Zhou and Neubig (2017), Silfverberg et al. (2017), Sudhakar and Kumar (2017), Kann and Sch¨utze (2017), Bergmanis et al. (2017)) a hard alignment method (Makarov et al., 2017), or both (Nicolai et al., 2017). These results illustrate the common observation that neural systems require a large amount of data to be very accurate, We then use the Python library PanPhon (Mortensen et al., 2016), which maps IPA segments to features as in Figure 2, to obtain vectors of phonological distinctive features. The features are represented numerically whereby each index of the vector corresponds to a specific feature such as [±coronal] and stores a value from the set {1, 0, -1}. These values correspond to ‘exhibits feature’, ‘unspecified for given class of sounds’, and ‘does not exhibit feature’, respectively. In practice we map -1 to 0 to obtain strictly binary feature vectors. Now, each IPA segment can be represented as a vector v which has a 1 for each feature that it exhibits, and a 0 oth"
W18-5818,K17-2008,0,0.0264296,"red task did (Cotterell et al., 2017), and that this is a comparison to the maximum score of 25 systems per language, which increases the likelihood that the optimal initialization will have been found. In the medium setting, the difference in accuracy is much more apparent. This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (Zhou and Neubig (2017), Silfverberg et al. (2017), Sudhakar and Kumar (2017), Kann and Sch¨utze (2017), Bergmanis et al. (2017)) a hard alignment method (Makarov et al., 2017), or both (Nicolai et al., 2017). These results illustrate the common observation that neural systems require a large amount of data to be very accurate, We then use the Python library PanPhon (Mortensen et al., 2016), which maps IPA segments to features as in Figure 2, to obtain vectors of phonological distinctive features. The features are represented numerically whereby each index of the vector corresponds to a specific feature such as [±coronal] and stores a value from the set {1, 0, -1}. These values correspond to ‘exhibits feature’, ‘unspecified for given class of sounds’, and ‘does not exhibit feature’, respectively."
W18-5818,W18-0314,1,0.739806,"from phonological features should quickly be able to generalize that this English past tense is realized as /t/ before voiceless segments. Similarly, in the example of ”rob”: /ôAb/ → /ôAbd/, the generated /d/ can be conditioned on [+voice] rather than the individual segment /b/. An alternative hypothesis is that the proposed distinctive feature representation may, however, not have such a profound effect on the inflection model. This is because distributional representations of IPA segments or phonemic graphemes have been shown to capture good approximations of the distinctive feature space (Silfverberg et al., 2018). In order to test these two hypotheses, we experiment on a subset of data provided by task 1 of the CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological Reinflection (Cotterell et al., 2017), which introduced 42 more languages than the year before (Cotterell et al., 2016) for a total of 52 languages. We use an existing tool to perform G2P on the data, and, as a second step, to produce distinctive feature vectors from the resulting IPA segments. We evaluate the resulting models on their ability to generate IPA segments. c a t s <EOS> E E E E E E Decoder RNN Attn Encoder Bi-RNN E E E E"
W18-5818,K17-2010,1,0.824103,"r each language. The slight degradation in performance can be attributed to the fact that we did not use ensemble voting, as the top performing systems in the shared task did (Cotterell et al., 2017), and that this is a comparison to the maximum score of 25 systems per language, which increases the likelihood that the optimal initialization will have been found. In the medium setting, the difference in accuracy is much more apparent. This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (Zhou and Neubig (2017), Silfverberg et al. (2017), Sudhakar and Kumar (2017), Kann and Sch¨utze (2017), Bergmanis et al. (2017)) a hard alignment method (Makarov et al., 2017), or both (Nicolai et al., 2017). These results illustrate the common observation that neural systems require a large amount of data to be very accurate, We then use the Python library PanPhon (Mortensen et al., 2016), which maps IPA segments to features as in Figure 2, to obtain vectors of phonological distinctive features. The features are represented numerically whereby each index of the vector corresponds to a specific feature such as [±coronal] and stores a value f"
W18-5818,K17-2007,0,0.0276726,"degradation in performance can be attributed to the fact that we did not use ensemble voting, as the top performing systems in the shared task did (Cotterell et al., 2017), and that this is a comparison to the maximum score of 25 systems per language, which increases the likelihood that the optimal initialization will have been found. In the medium setting, the difference in accuracy is much more apparent. This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (Zhou and Neubig (2017), Silfverberg et al. (2017), Sudhakar and Kumar (2017), Kann and Sch¨utze (2017), Bergmanis et al. (2017)) a hard alignment method (Makarov et al., 2017), or both (Nicolai et al., 2017). These results illustrate the common observation that neural systems require a large amount of data to be very accurate, We then use the Python library PanPhon (Mortensen et al., 2016), which maps IPA segments to features as in Figure 2, to obtain vectors of phonological distinctive features. The features are represented numerically whereby each index of the vector corresponds to a specific feature such as [±coronal] and stores a value from the set {1, 0, -1}. The"
W18-5818,N16-1161,0,0.0288235,"ll have been found. In the medium setting, the difference in accuracy is much more apparent. This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (Zhou and Neubig (2017), Silfverberg et al. (2017), Sudhakar and Kumar (2017), Kann and Sch¨utze (2017), Bergmanis et al. (2017)) a hard alignment method (Makarov et al., 2017), or both (Nicolai et al., 2017). These results illustrate the common observation that neural systems require a large amount of data to be very accurate, We then use the Python library PanPhon (Mortensen et al., 2016), which maps IPA segments to features as in Figure 2, to obtain vectors of phonological distinctive features. The features are represented numerically whereby each index of the vector corresponds to a specific feature such as [±coronal] and stores a value from the set {1, 0, -1}. These values correspond to ‘exhibits feature’, ‘unspecified for given class of sounds’, and ‘does not exhibit feature’, respectively. In practice we map -1 to 0 to obtain strictly binary feature vectors. Now, each IPA segment can be represented as a vector v which has a 1 for each feature that it exhibits, and a 0 oth"
W18-5818,K17-2005,0,0.0284175,"t shared task systems for each language. The slight degradation in performance can be attributed to the fact that we did not use ensemble voting, as the top performing systems in the shared task did (Cotterell et al., 2017), and that this is a comparison to the maximum score of 25 systems per language, which increases the likelihood that the optimal initialization will have been found. In the medium setting, the difference in accuracy is much more apparent. This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (Zhou and Neubig (2017), Silfverberg et al. (2017), Sudhakar and Kumar (2017), Kann and Sch¨utze (2017), Bergmanis et al. (2017)) a hard alignment method (Makarov et al., 2017), or both (Nicolai et al., 2017). These results illustrate the common observation that neural systems require a large amount of data to be very accurate, We then use the Python library PanPhon (Mortensen et al., 2016), which maps IPA segments to features as in Figure 2, to obtain vectors of phonological distinctive features. The features are represented numerically whereby each index of the vector corresponds to a specific feature such as [±co"
W18-6011,P17-1080,0,0.0204505,"ph represents both categories as a single templatic value. 2. We discard any values that UniMorph doesn’t annotate for a particular part of speech, like gender and number in French verb participles, or German noun genders. Our approach to converting UD MSDs to UniMorph MSDs begins with the attribute-value lookup, then amends it on a language-specific basis. Alterations informed by the MSD and the word form, like insertion, substitution, and deletion, increase the number of agreeing annotations. They are critical for work that examines the MSD monolithically instead of feature-by-feature (e.g. Belinkov et al., 2017; Cotterell and Heigold, 2017): Without exact matches, converting the individual tags becomes hollow. 3. We make MSD additions when they are unambiguously implied by the resources, like PFV to accompany PST in Spanish “pasado simple”, but PST to accompany IPFV in Spanish “pasado continuo”. 4. We also incorporate fixes using information outside of the MSD like the L G S PEC 1 tag for Spanish’s “-ra” forms, as described in §4, and other language-specific corrections, like mapping the various dative cases to the crosslingually comparable case annotations used in UniMorph. Beginning our process, w"
W18-6011,J93-2003,0,0.0985893,"ords to be a match if their form and lemma are present in both resources. Syncretism allows a single surface form to realize multiple MSDs (Spanish “mandaba” can be first- or third-person), so we define success as the computed MSD matching any of the word’s UniMorph MSDs. This gives rise to an equation for recall: of the word–lemma pairs found in both resources, how many of their UniMorph-converted MSDs are present in the UniMorph tables? Why not a learned mapping? One can imagine learning the UniMorph MSD corresponding to a UD dataset’s MSD by a set-to-set translation model like IBM Model 1 (Brown et al., 1993). Unfortunately, statistical (and especially neural) machine translation generalizes in unreliable ways. Our goal is a straightforward, easily manipulable and extensible conversion that prioritizes correctness over coverage. 6 Intrinsic evaluation Experiments Why no held-out test set? Our problem here is not a learning problem, so the question is ill-posed. There is no training set, and the two resources for a given language make up a test set. The quality of our model—the conversion tool—comes from how well we encode prior knowledge about the relationship between the UD and UniMorph corpora."
W18-6011,D17-1078,1,0.850043,"gories as a single templatic value. 2. We discard any values that UniMorph doesn’t annotate for a particular part of speech, like gender and number in French verb participles, or German noun genders. Our approach to converting UD MSDs to UniMorph MSDs begins with the attribute-value lookup, then amends it on a language-specific basis. Alterations informed by the MSD and the word form, like insertion, substitution, and deletion, increase the number of agreeing annotations. They are critical for work that examines the MSD monolithically instead of feature-by-feature (e.g. Belinkov et al., 2017; Cotterell and Heigold, 2017): Without exact matches, converting the individual tags becomes hollow. 3. We make MSD additions when they are unambiguously implied by the resources, like PFV to accompany PST in Spanish “pasado simple”, but PST to accompany IPFV in Spanish “pasado continuo”. 4. We also incorporate fixes using information outside of the MSD like the L G S PEC 1 tag for Spanish’s “-ra” forms, as described in §4, and other language-specific corrections, like mapping the various dative cases to the crosslingually comparable case annotations used in UniMorph. Beginning our process, we relied on documentation of t"
W18-6011,K18-3001,1,0.882683,"Missing"
W18-6011,K17-2001,1,0.892721,"Missing"
W18-6011,W17-0405,0,0.0486603,"Missing"
W18-6011,W05-0807,1,0.760167,"Missing"
W18-6011,L18-1293,1,0.652734,"Missing"
W18-6011,E17-2018,1,0.849189,"Morph’s schema does not indicate the type of pronoun (demonstrative, interrogative, etc.), and when lexical information is not recorded in UniMorph, we delete it from the MSD during transformation. On the other hand, UniMorph’s atomic tags have more parts to guess, but they are often related. (E.g. I PFV always entails P ST in Spanish.) Altogether, these forces seem to have little impact on tagging performance. 8 In addition to using the number of extra rules as a proxy for harmony between resources, one could perform cross-lingual projection of morphological tags (Dr´abek and Yarowsky, 2005; Kirov et al., 2017). Our approach succeeds even without parallel corpora. 9 Conclusion and Future Work We created a tool for annotating Universal Dependencies CoNLL-U files with UniMorph annotations. Our tool is ready to use off-the-shelf today, requires no training, and is deterministic. While under-specification necessitates a lossy and imperfect conversion, ours is interpretable. Patterns of mistakes can be identified and ameliorated. The tool allows a bridge between resources annotated in the Universal Dependencies and Universal Morphology (UniMorph) schemata. As the Universal Dependencies project provides a"
W18-6011,L16-1498,1,0.848261,"directly comparable across languages. Its features are informed by a distinction between universal categories, which are widespread and psychologically “real” to speakers; and comparative concepts, only used by linguistic typologists to compare languages (Haspelmath, 2010). Additionally, it strives for identity of meaning across languages, not simply similarity of terminology. As a prime example, it does not regularly label a dative case for nouns, for reasons explained in depth by Haspelmath (2010).4 The UniMorph resources for a language contain complete paradigms extracted from Wiktionary (Kirov et al., 2016, 2018). Word types are annotated to form a database, mapping a lemma–tag pair to a surface form. The schema is explained in detail in Sylak-Glassman (2016). It has been used in the SIGMORPHON shared task (Cotterell et al., 2016) and the CoNLL–SIGMORPHON shared tasks (Cotterell et al., 2017, 2018). Several components of the UniMorph schema have been adopted by UD.5 Universal Dependencies The Universal Dependencies morphological schema comprises part of speech and 23 additional attributes (also called features in UD) annotating meaning or syntax, as well as language-specific attributes. In orde"
W18-6011,P18-1247,0,0.200895,"tated datasets. UD’s v2.1 release (Nivre et al., 2017) has 102 treebanks in 60 languages. The large resource, constructed by independent parties, evinces problems in the goal of a universal inventory of annotations. Annotators may choose to omit certain values (like the coerced gender of refrescante in Figure 1), and they may disagree on how a linguistic concept is encoded. (See, e.g., Haspelmath’s (2010) description of the dative case.) Additionally, many of the treebanks “were created by fully- or semi-automatic conversion from treebanks with less comprehensive annotation schemata than UD” (Malaviya et al., 2018). For instance, the Spanish word “vas” “you go” is incorrectly labeled G ENDER : F EM|N UMBER : P L because it ends in a character sequence which is common among feminine plural nouns. (Nevertheless, the part of speech field for “vas” is correct.) UniMorph’s development is more centralized and pipelined.7 Inflectional paradigms are scraped from Wiktionary, annotators map positions in the scraped data to MSDs, and the mapping is automatically applied to all of the scraped paradigms. Because annotators handle languages they are familiar with (or related ones), realization of the schema is also d"
W18-6011,J93-2004,0,0.0604809,"a given lemma and part of speech gives a paradigm: a mapping from slots to surface forms. Regular English verbs have five slots in their paradigm (Long, 1957), which we illustrate for the verb prove, using simple labels for the forms in Table 1. A morphosyntactic schema prescribes how language can be annotated—giving stricter categories than our simple labels for prove—and can vary in the level of detail provided. Part of speech tags are an example of a very coarse schema, ignoring details of person, gender, and number. A slightly finer-grained schema for English is the Penn Treebank tagset (Marcus et al., 1993), which includes signals for English morphology. For instance, its VBZ tag pertains to the specially inflected 3rd-person singular, present-tense verb form (e.g. “proves” in Table 1). If the tag in a schema is detailed enough that it exactly specifies a slot in a paradigm, it is • We detail a deterministic mapping from UD morphological annotations to UniMorph. Language-specific edits of the tags in 31 languages increase harmony between converted UD and existing UniMorph data (§5). • We provide an implementation of this mapping and post-editing, which replaces the UD features in a CoNLL-U file"
W18-6011,W17-0419,0,0.0599591,"Missing"
W18-6011,petrov-etal-2012-universal,0,0.0495453,"nguage. Our approach, by contrast, is a direct flight from the source to the target.) Because UniMorph corpora are noisy, the encoding from the interlingua would have to be rewritten for each target. Further, decoding the UD MSD into the interlingua cannot leverage external information like the lemma and form. The creators of HamleDT sought to harmonize dependency annotations among treebanks, similar to our goal of harmonizing across resources (Zeman et al., 2014). The treebanks they sought to harmonize used multiple diverse annotation schemes, which the authors unified under a single scheme. Petrov et al. (2012) present mappings into a coarse, “universal” part of speech for 22 languages. Working with POS tags rather than morphological tags (which have far more dimensions), their space of options to harmonize is much smaller than ours. Our extrinsic evaluation is most in line with the paradigm of Wisniewski and Lacroix (2017) (and similar work therein), who compare syntactic parser performance on UD treebanks annotated with two styles of dependency representation. Our problem differs, though, in that the dependency representations express different relationships, while our two schemata vastly overlap."
W18-6011,W17-0412,0,0.0275171,"ject releases type-level annotated tables, the newfound compatibility opens up new experiments. A prime example of exploiting tokenand type-level data is T¨ackstr¨om et al. (2013). That work presents a part-of-speech (POS) dictionary built from Wiktionary, where the POS tagger is also constrained to options available in their typelevel POS dictionary, improving performance. Our transformation means that datasets are prepared for similar experiments with morphological tagging. It would also be reasonable to incorporate this tool as a subroutine to UDPipe (Straka and Strakov´a, 2017) and Udapi (Popel et al., 2017). We leave open the task of converting in the opposite direction, turning UniMorph MSDs into Universal Dependencies MSDs. Because our conversion rules are interpretable, we identify shortcomings in both resources, using each as validation for the other. We were able to find specific instances of incorrectly applied UniMorph annotation, as well as specific instances of cross-lingual inconsistency in both resources. These findings will harden both resources and better align them with their goal of universal, crosslingual annotation. Related Work The goal of a tagset-to-tagset mapping of morpholo"
W18-6011,K17-3009,0,0.0457031,"Missing"
W18-6011,P15-2111,1,0.851167,"Missing"
W18-6011,K17-3001,0,0.0560233,"alled a morphosyntactic description (MSD).2 These descriptions require varying amounts of detail: While the English verbal paradigm is small enough to fit on a page, the verbal paradigm of the Northeast Caucasian language Archi can have over 1,500,000 slots (Kibrik, 1998). 3 is an annotated treebank, making it a resource of token-level annotations. The schema is guided by these treebanks, with feature names chosen for relevance to native speakers. (In §3.2, we will contrast this with UniMorph’s treatment of morphosyntactic categories.) The UD datasets have been used in the CoNLL shared tasks (Zeman et al., 2017, 2018 to appear). Two Schemata, Two Philosophies Unlike the Penn Treebank tags, the UD and UniMorph schemata are cross-lingual and include a fuller lexicon of attribute-value pairs, such as P ER SON : 1. Each was built according to a different set of principles. UD’s schema is constructed bottomup, adapting to include new features when they’re identified in languages. UniMorph, conversely, is top-down: A cross-lingual survey of the literature of morphological phenomena guided its design. UniMorph aims to be linguistically complete, containing all known morphosyntactic attributes. Both schemat"
W19-4226,P17-2107,0,0.0357656,"Missing"
W19-4226,N18-1126,0,0.0330462,"gs (BERT) provided by Google (Devlin et al., 2019). CBNU1 used a mix of pre-trained embeddings from the CoNLL 2017 shared task and fastText. Further, some teams trained their own embeddings to aid performance. CUNI–Malta performs lemmatization as operations over edit actions with LSTM and ReLU. Tagging is a bidirectional LSTM augmented by the edit actions (i.e., two-stage decoding), predicting features separately. The Edinburgh system is a character-based LSTM encoder-decoder with attention, implemented in OpenNMT. It can be seen as an extension of the contextual lemmatization system Lematus (Bergmanis and Goldwater, 2018) to include morphological tagging, or alternatively as an adaptation of the morphological re-inflection system MED (Kann and Sch¨utze, 2016) to incorporate context and perform analysis rather than re-inflection. Like these systems it uses a completely generic encoderdecoder architecture with no specific adaptation to the morphological processing task other than the form of the input. In the submitted version of the system, the input is split into short chunks corresponding to the target word plus one word of context on either side, and the system is trained to output the corresponding lemmas a"
W19-4226,K18-3001,1,0.746475,"previous shared task (Cotterell et al., 2018), training a neural network on unambiguous forms to estimate the distribution over all, even ambiguous, forms. We then sampled 12,000 triples without replacement from this distribution. The first 100 were taken as training data for low-resource settings. The first 10,000 were used as high-resource training sets. As these sets are nested, the highest-count triples tend to appear in the smaller training sets.3 Data conversion The morphological annotations for the 2019 shared task were converted to the UniMorph schema (Kirov et al., 2018) according to McCarthy et al. (2018), who provide a deterministic mapping that increases agreement across languages. This also moves the part of speech into the bundle of morphological features. We do not attempt to individually correct any errors in the UD source material. Further, some languages received additional pre-processing. In the Finnish data, we removed morpheme boundaries that were present in the lemmata (e.g., puhe#kieli 7→ puhekieli ‘spoken+language’). Russian lemmata in the GSD treebank were presented in all uppercase; to match Swahili. Likewise, the low-resource language Telugu had fewer than 100 forms. 4 When su"
W19-4226,K17-2001,1,0.692718,"Missing"
W19-4226,N19-1155,1,0.843499,"ive teams participated in the first Task, with a variety of methods aimed at leveraging the crosslingual data to improve system performance. The University of Alberta (UAlberta) performed a focused investigation on four language pairs, training cognate-projection systems from external cognate lists. Two methods were considered: one which trained a high-resource neural encoderdecoder, and projected the test data into the HRL, and one that projected the HRL data into the LRL, and trained a combined system. Results demonstrated that certain language pairs may be amenable to such methods. Neural (Malaviya et al., 2019): This is a stateof-the-art neural model that also performs joint morphological tagging and lemmatization, but also accounts for the exposure bias with the application of maximum likelihood (MLE). The model stitches the tagger and lemmatizer together with the use of jackknifing (Agi´c and Schluter, 2017) to expose the lemmatizer to the errors made by the tagger model during training. The morphological tagger is based on a character-level biLSTM embedder that produces the embedding for a word, 4 HRL–LRL adyghe–kabardian albanian–breton arabic–classical-syriac arabic–maltese arabic–turkmen armen"
W19-4226,N19-1423,0,0.0153778,"only applied to a subset of languages, making scores incomparable. † indicates that additional external resources were used for training, and ‡ indicates that training data were shared across languages or treebanks. ging). Although they predict complete tags, they use the individual features to regularize the decoder. Small gains are also obtained from joining multilingual corpora and ensembling. improve their lemmatization and feature analysis. Several teams made use of pre-trained embeddings. CHARLES-SAARLAND-2 and UFALPRAGUE1 used pretrained contextual embeddings (BERT) provided by Google (Devlin et al., 2019). CBNU1 used a mix of pre-trained embeddings from the CoNLL 2017 shared task and fastText. Further, some teams trained their own embeddings to aid performance. CUNI–Malta performs lemmatization as operations over edit actions with LSTM and ReLU. Tagging is a bidirectional LSTM augmented by the edit actions (i.e., two-stage decoding), predicting features separately. The Edinburgh system is a character-based LSTM encoder-decoder with attention, implemented in OpenNMT. It can be seen as an extension of the contextual lemmatization system Lematus (Bergmanis and Goldwater, 2018) to include morpholo"
W19-4226,Q18-1032,0,0.0456659,"Missing"
W19-4226,W17-4110,0,0.124781,"Missing"
W19-4226,D15-1272,1,0.898864,"Missing"
W19-4226,W16-2010,0,0.0549216,"Missing"
W19-4226,D18-1103,0,0.0261867,"he system, the input is split into short chunks corresponding to the target word plus one word of context on either side, and the system is trained to output the corresponding lemmas and tags for each three-word chunk. 6 Future Directions In general, the application of typology to natural language processing (e.g., Gerz et al., 2018; Ponti et al., 2018) provides an interesting avenue for multilinguality. Further, our shared task was designed to only leverage a single helper language, though many may exist with lexical or morphological overlap with the target language. Techniques like those of Neubig and Hu (2018) may aid in designing universal inflection architectures. Neither task this year included unannotated monolingual corpora. Using such data is well-motivated from an L1-learning point of view, and may affect the performance of low-resource data settings. In the case of inflection an interesting future topic could involve departing from orthographic representation and using more IPA-like representations, i.e. transductions over pronunciations. DifferSeveral teams relied on external resources to 8 Table 6: Task 2 Lemma Accuracy scores 9 UD UD UD UD UD UD UD UD UD UD UD UD UD UD UD UD UD UD UD UD"
W19-4226,L18-1293,1,0.829575,"previous shared task (Cotterell et al., 2018), training a neural network on unambiguous forms to estimate the distribution over all, even ambiguous, forms. We then sampled 12,000 triples without replacement from this distribution. The first 100 were taken as training data for low-resource settings. The first 10,000 were used as high-resource training sets. As these sets are nested, the highest-count triples tend to appear in the smaller training sets.3 Data conversion The morphological annotations for the 2019 shared task were converted to the UniMorph schema (Kirov et al., 2018) according to McCarthy et al. (2018), who provide a deterministic mapping that increases agreement across languages. This also moves the part of speech into the bundle of morphological features. We do not attempt to individually correct any errors in the UD source material. Further, some languages received additional pre-processing. In the Finnish data, we removed morpheme boundaries that were present in the lemmata (e.g., puhe#kieli 7→ puhekieli ‘spoken+language’). Russian lemmata in the GSD treebank were presented in all uppercase; to match Swahili. Likewise, the low-resource language Telugu had fewer than 100 forms. 4 When su"
W19-4226,D15-1166,0,0.0843899,"ani Kurdish were created as part of the Alexina project (Walther et al., 2010; Walther and Sagot, 2010). 2 These datasets can be obtained from https:// sigmorphon.github.io/sharedtasks/2019/ 3 Several high-resource languages had necessarily fewer, but on a similar order of magnitude. Bengali, Uzbek, Kannada, 3 the 2018 shared task, we lowercased these. In development and test data, all fields except for form and index within the sentence were struck. 4 4.1 Team Baselines Task 1 Baseline We include four neural sequence-to-sequence models mapping lemma into inflected word forms: soft attention (Luong et al., 2015), non-monotonic hard attention (Wu et al., 2018), monotonic hard attention and a variant with offset-based transition distribution (Wu and Cotterell, 2019). Neural sequenceto-sequence models with soft attention (Luong et al., 2015) have dominated previous SIGMORPHON shared tasks (Cotterell et al., 2017). Wu et al. (2018) instead models the alignment between characters in the lemma and the inflected word form explicitly with hard attention and learns this alignment and transduction jointly. Wu and Cotterell (2019) shows that enforcing strict monotonicity with hard attention is beneficial in tas"
W19-4226,P18-1247,1,0.817396,"ciently prescribed by the lemma, as with the Romanian verbal inflection classes or nominal gender in German. As we move toward multilingual models for morphology, it becomes important to understand which representations are critical or irrelevant for adapting to new languages; this may be probed in the style of (Thompson et al., 2018), and it can be used as a first step toward designing systems that avoid “catastrophic forgetting” as they learn to inflect new languages (Thompson et al., 2019). Future directions for Task 2 include exploring cross-lingual analysis—in stride with both Task 1 and Malaviya et al. (2018)—and leveraging these analyses in downstream tasks. 7 In the second task, several methods were implemented by multiple groups, with the most successful systems implementing variations of multiheaded attention, multi-level encoding, multiple decoders, and ELMo and BERT contextual embeddings. We have released the training, development, and test sets, and expect these datasets to provide a useful benchmark for future research into learning of inflectional morphology and string-to-string transduction. Acknowledgments MS has received funding from the European Research Council (ERC) under the Europe"
W19-4226,P15-2111,1,0.881319,"Missing"
W19-4226,N19-1209,0,0.0249795,"tasks. One pertinent facet of this is information about inflectional categories—often the inflectional information is insufficiently prescribed by the lemma, as with the Romanian verbal inflection classes or nominal gender in German. As we move toward multilingual models for morphology, it becomes important to understand which representations are critical or irrelevant for adapting to new languages; this may be probed in the style of (Thompson et al., 2018), and it can be used as a first step toward designing systems that avoid “catastrophic forgetting” as they learn to inflect new languages (Thompson et al., 2019). Future directions for Task 2 include exploring cross-lingual analysis—in stride with both Task 1 and Malaviya et al. (2018)—and leveraging these analyses in downstream tasks. 7 In the second task, several methods were implemented by multiple groups, with the most successful systems implementing variations of multiheaded attention, multi-level encoding, multiple decoders, and ELMo and BERT contextual embeddings. We have released the training, development, and test sets, and expect these datasets to provide a useful benchmark for future research into learning of inflectional morphology and str"
W19-4226,W18-6313,1,0.850382,"sentangle.8 Creating new data sets that accurately reflect learner exposure (whether L1 or L2) is also an important consideration in the design of future shared tasks. One pertinent facet of this is information about inflectional categories—often the inflectional information is insufficiently prescribed by the lemma, as with the Romanian verbal inflection classes or nominal gender in German. As we move toward multilingual models for morphology, it becomes important to understand which representations are critical or irrelevant for adapting to new languages; this may be probed in the style of (Thompson et al., 2018), and it can be used as a first step toward designing systems that avoid “catastrophic forgetting” as they learn to inflect new languages (Thompson et al., 2019). Future directions for Task 2 include exploring cross-lingual analysis—in stride with both Task 1 and Malaviya et al. (2018)—and leveraging these analyses in downstream tasks. 7 In the second task, several methods were implemented by multiple groups, with the most successful systems implementing variations of multiheaded attention, multi-level encoding, multiple decoders, and ELMo and BERT contextual embeddings. We have released the t"
W19-4226,W18-5818,1,0.888961,"Missing"
W19-4226,P19-1148,1,0.888951,"sigmorphon.github.io/sharedtasks/2019/ 3 Several high-resource languages had necessarily fewer, but on a similar order of magnitude. Bengali, Uzbek, Kannada, 3 the 2018 shared task, we lowercased these. In development and test data, all fields except for form and index within the sentence were struck. 4 4.1 Team Baselines Task 1 Baseline We include four neural sequence-to-sequence models mapping lemma into inflected word forms: soft attention (Luong et al., 2015), non-monotonic hard attention (Wu et al., 2018), monotonic hard attention and a variant with offset-based transition distribution (Wu and Cotterell, 2019). Neural sequenceto-sequence models with soft attention (Luong et al., 2015) have dominated previous SIGMORPHON shared tasks (Cotterell et al., 2017). Wu et al. (2018) instead models the alignment between characters in the lemma and the inflected word form explicitly with hard attention and learns this alignment and transduction jointly. Wu and Cotterell (2019) shows that enforcing strict monotonicity with hard attention is beneficial in tasks such as morphological inflection where the transduction is mostly monotonic. The encoder is a biLSTM while the decoder is a left-to-right LSTM. All mode"
W19-4226,D18-1473,1,0.906631,"Missing"
W19-4226,D16-1163,0,0.0280678,"larger number of examples in either a related or unrelated language. Each test example asked participants to produce some other inflected form when given a lemma and a bundle of morphosyntactic features as input. The goal, thus, is to perform morphological inflection in the low-resource language, having hopefully exploited some similarity to the high-resource language. Models which perform well here can aid downstream tasks like machine translation in lowresource settings. All datasets were resampled from UniMorph, which makes them distinct from past years. The mode of the task is inspired by Zoph et al. (2016), who fine-tune a model pre-trained on a high-resource language to perform well on a lowresource language. We do not, though, require that models be trained by fine-tuning. Joint modeling or any number of methods may be explored instead. Task 2: Morphological analysis in context Although inflection of words in a context-agnostic manner is a useful evaluation of the morphological quality of a system, people do not learn morphology in isolation. In 2018, the second task of the CoNLL– SIGMORPHON Shared Task (Cotterell et al., 2018) required submitting systems to complete an inflectional cloze tas"
W19-4226,W18-6011,1,\N,Missing
W19-6011,K18-3001,1,0.893885,"Missing"
W19-6011,K17-2001,1,0.897814,"Missing"
W19-6011,E09-2008,1,0.809599,"logical rewrite rules are applied. An initial change (IC) epenthesizes -en before the first vowel in the verb stem because it is a long vowel and because the verb is affirmative present. Then vowel harmony is at work, changing n-en-oohow-een to n-on-oohow-een. Finally a consonant mutation rule changes w to b, producing the surface form nonoohobeen (cf. Figure 1). 3 Finite State Model One of the clear successes in computational modeling of linguistic patterns has been finite state transducer (FST) models for morphological analysis and generation (Koskenniemi, 1983; Beesley and Karttunen, 2003; Hulden, 2009; Lind´en et al., 2009). An FST is bidirectional, able to both parse inflected word forms and generate all possible word forms for a given stem (Beesley and Karttunen, 2003). Given enough linguistic expertise and time investment, FSTs provide the capability to analyze any well-formed word in a language. The Arapaho FST model used in this paper was constructed with the foma finite-state toolkit (Hulden, 2009). It used 18,559 verb stems taken from around 91,000 lines of natural discourse in a large transcribed and annotated spoken corpus of Arapaho, parts of which are publicly available in the E"
W19-6011,P16-2090,0,0.0560158,"Missing"
W19-6011,W17-0102,1,0.831497,"are concatenated together and then phonological rules are applied to produce the inflected forms. The operation of phonological rules can reshape the string of fixed morphemes considerably, making it difficult for learners, whether human or machines, to recreate correct forms (generation) from the morpheme sequence or to analyze the reshaped inflected forms into their individual morphemes (parsing). In this paper we describe an experiment in training a neural encoder-decoder model to replicate the bidirectional behavior of an existing finite state morphological analyzer for the Arapaho verb (Kazeminejad et al., 2017). When a language is low-resource, natural language processing needs strategies that achieve usable results with less data. We attempt to replicate a low-resource context by using a limited number of training examples. We evaluate the feasibility of learning abstract intermediate forms to achieve better results on various training set sizes. While common wisdom regarding neural models has it that, given enough data (Graves and Jaitly, 2014), end-to-end training is usually preferable to pipelined models, an argument can be made that morphology is an exception to this: learning two regular mappi"
W19-6011,W18-1817,0,0.0196748,"unseen forms than finite state machines are. However, neural models are hampered in low-resource contexts by their data greediness. In order to see whether this limitation could be addressed we simulated training a neural model in low-resource contexts using output from the Arapaho FST. Since the currently strongest performing models for morphological inflection (Cotterell et al., 2017; Kann and Sch¨utze, 2016; Makarov et al., 2017) use an LSTM-based sequence-to-sequence (seq2seq) model (Sutskever et al., 2014), we follow this design in our work. We implement the seq2seq model with OpenNMT’s (Klein et al., 2018) default parameters of 2 layers for both the encoder and decoder, a hidden size of 500 for the recurrent unit, and a maximum batch size of 64. Training corpora of various sizes are created by randomly selecting examples of inflected word forms and their corresponding intermediate and parsed forms from the bidirectional output of the Arapaho FST. This results in triplets like in Figure 1. The triplets are arranged into three pairs— inflected “surface” forms (SF) & intermediate forms (IF), IF & parsed forms (PF), and SF & PF. Re-using the pairs for both parsing and generation gives six data sets"
W19-6011,K18-3010,1,0.885664,"strategies that achieve usable results with less data. We attempt to replicate a low-resource context by using a limited number of training examples. We evaluate the feasibility of learning abstract intermediate forms to achieve better results on various training set sizes. While common wisdom regarding neural models has it that, given enough data (Graves and Jaitly, 2014), end-to-end training is usually preferable to pipelined models, an argument can be made that morphology is an exception to this: learning two regular mappings separately may be easier than learning a single complex one. In Liu et al. (2018), adressing a related task, noticeably better results were reached for German, Finnish, and Russian when a neural system was first tasked to learn morphosyntactic tags than when it was tasked to produce an inflected form directly from uninflected forms and context. These three languages are morphologically complex or unpredictable, but marginally better results were achieved for the less complex languages. 2 Arapaho Verbs Arapaho is a member of the Algonquian (and larger Algic) language family; it is an agglutinating, polysynthetic language, with free word order (Cowell and Moss Sr, 2008). The"
W19-6011,W18-4802,1,0.759962,"nflected word forms and their corresponding intermediate and parsed forms from the bidirectional output of the Arapaho FST. This results in triplets like in Figure 1. The triplets are arranged into three pairs— inflected “surface” forms (SF) & intermediate forms (IF), IF & parsed forms (PF), and SF & PF. Re-using the pairs for both parsing and generation gives six data sets. For simplicity’s sake, since the primary aim is to compare the two strategies’ performance and not to measure accuracy, forms with ambiguous inflected forms, parses, or intermediate forms were filtered. Other experiments (Moeller et al., 2018) indicate that pre-processing the data to account for ambiguous forms would not greatly Figure 2: An example from training/test sets. In parsing, surface forms (SF) predict intermediate forms (IF). The output trains another encoder-decoder to predict parsed forms (PF). Generation follows the same steps but proceeding from the PF instead. The selected data is divided roughly in half. The first half serves as training and development and the second half as testing data in the first step of the intermediate training strategy (SF⇔IF or PF⇔IF). In order to compare the two training strategies, the o"
