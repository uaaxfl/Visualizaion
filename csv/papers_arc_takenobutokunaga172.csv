2021.wat-1.2,{NHK}{'}s Lexically-Constrained Neural Machine Translation at {WAT} 2021,2021,-1,-1,6,1,287,hideya mino,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"This paper describes the system of our team (NHK) for the WAT 2021 Japanese-English restricted machine translation task. In this task, the aim is to improve quality while maintaining consistent terminology for scientific paper translation. This task has a unique feature, where some words in a target sentence are given in addition to a source sentence. In this paper, we use a lexically-constrained neural machine translation (NMT), which concatenates the source sentence and constrained words with a special token to input them into the encoder of NMT. The key to the successful lexically-constrained NMT is the way to extract constraints from a target sentence of training data. We propose two extraction methods: proper-noun constraint and mistranslated-word constraint. These two methods consider the importance of words and fallibility of NMT, respectively. The evaluation results demonstrate the effectiveness of our lexical-constraint method."
2021.bea-1.10,Parsing Argumentative Structure in {E}nglish-as-Foreign-Language Essays,2021,-1,-1,3,1,12222,jan putra,Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications,0,"This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. The parsing process consists of two steps, linking related sentences and then labelling their relations. We experiment with several deep learning architectures to address each task independently. In the sentence linking task, a biaffine model performed the best. In the relation labelling task, a fine-tuned BERT model performed the best. Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. We trained our models using two types of parallel texts: original noisy EFL essays and those improved by annotators, then evaluate them on the original essays. The experiment shows that an end-to-end in-domain system achieved an accuracy of .341. On the other hand, the cross-domain system achieved 94{\%} performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts."
2021.argmining-1.2,Multi-task and Multi-corpora Training Strategies to Enhance Argumentative Sentence Linking Performance,2021,-1,-1,3,1,12222,jan putra,Proceedings of the 8th Workshop on Argument Mining,0,"Argumentative structure prediction aims to establish links between textual units and label the relationship between them, forming a structured representation for a given input text. The former task, linking, has been identified by earlier works as particularly challenging, as it requires finding the most appropriate structure out of a very large search space of possible link combinations. In this paper, we improve a state-of-the-art linking model by using multi-task and multi-corpora training strategies. Our auxiliary tasks help the model to learn the role of each sentence in the argumentative structure. Combining multi-corpora training with a selective sampling strategy increases the training data size while ensuring that the model still learns the desired target distribution well. Experiments on essays written by English-as-a-foreign-language learners show that both strategies significantly improve the model{'}s performance; for instance, we observe a 15.8{\%} increase in the F1-macro for individual link predictions."
2020.lrec-1.445,Content-Equivalent Translated Parallel News Corpus and Extension of Domain Adaptation for {NMT},2020,-1,-1,6,1,287,hideya mino,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper, we deal with two problems in Japanese-English machine translation of news articles. The first problem is the quality of parallel corpora. Neural machine translation (NMT) systems suffer degraded performance when trained with noisy data. Because there is no clean Japanese-English parallel data for news articles, we build a novel parallel news corpus consisting of Japanese news articles translated into English in a content-equivalent manner. This is the first content-equivalent Japanese-English news corpus translated specifically for training NMT systems. The second problem involves the domain-adaptation technique. NMT systems suffer degraded performance when trained with mixed data having different features, such as noisy data and clean data. Though the existing methods try to overcome this problem by using tags for distinguishing the differences between corpora, it is not sufficient. We thus extend a domain-adaptation method using multi-tags to train an NMT model effectively with the clean corpus and existing parallel news corpora with some types of noise. Experimental results show that our corpus increases the translation quality, and that our domain-adaptation method is more effective for learning with the multiple types of corpora than existing domain-adaptation methods are."
2020.lrec-1.854,{TIARA}: A Tool for Annotating Discourse Relations and Sentence Reordering,2020,-1,-1,4,1,12222,jan putra,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper introduces TIARA, a new publicly available web-based annotation tool for discourse relations and sentence reordering. Annotation tasks such as these, which are based on relations between large textual objects, are inherently hard to visualise without either cluttering the display and/or confusing the annotators. TIARA deals with the visual complexity during the annotation process by systematically simplifying the layout, and by offering interactive visualisation, including coloured links, indentation, and dual-view. TIARA{'}s text view allows annotators to focus on the analysis of logical sequencing between sentences. A separate tree view allows them to review their analysis in terms of the overall discourse structure. The dual-view gives it an edge over other discourse annotation tools and makes it particularly attractive as an educational tool (e.g., for teaching students how to argue more effectively). As it is based on standard web technologies and can be easily customised to other annotation schemes, it can be easily used by anybody. Apart from the project it was originally designed for, in which hundreds of texts were annotated by three annotators, TIARA has already been adopted by a second discourse annotation study, which uses it in the teaching of argumentation."
2020.lrec-1.876,Gamification Platform for Collecting Task-oriented Dialogue Data,2020,-1,-1,3,0,18347,haruna ogawa,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Demand for massive language resources is increasing as the data-driven approach has established a leading position in Natural Language Processing. However, creating dialogue corpora is still a difficult task due to the complexity of the human dialogue structure and the diversity of dialogue topics. Though crowdsourcing is majorly used to assemble such data, it presents problems such as less-motivated workers. We propose a platform for collecting task-oriented situated dialogue data by using gamification. Combining a video game with data collection benefits such as motivating workers and cost reduction. Our platform enables data collectors to create their original video game in which they can collect dialogue data of various types of tasks by using the logging function of the platform. Also, the platform provides the annotation function that enables players to annotate their own utterances. The annotation can be gamified aswell. We aim at high-quality annotation by introducing such self-annotation method. We implemented a prototype of the proposed platform and conducted a preliminary evaluation to obtain promising results in terms of both dialogue data collection and self-annotation."
2020.coling-main.396,Effective Use of Target-side Context for Neural Machine Translation,2020,-1,-1,5,1,287,hideya mino,Proceedings of the 28th International Conference on Computational Linguistics,0,"In this paper, we deal with two problems in Japanese-English machine translation of news articles. The first problem is the quality of parallel corpora. Neural machine translation (NMT) systems suffer degraded performance when trained with noisy data. Because there is no clean Japanese-English parallel data for news articles, we build a novel parallel news corpus consisting of Japanese news articles translated into English in a content-equivalent manner. This is the first content-equivalent Japanese-English news corpus translated specifically for training NMT systems. The second problem involves the domain-adaptation technique. NMT systems suffer degraded performance when trained with mixed data having different features, such as noisy data and clean data. Though the existing methods try to overcome this problem by using tags for distinguishing the differences between corpora, it is not sufficient. We thus extend a domain-adaptation method using multi-tags to train an NMT model effectively with the clean corpus and existing parallel news corpora with some types of noise. Experimental results show that our corpus increases the translation quality, and that our domain-adaptation method is more effective for learning with the multiple types of corpora than existing domain-adaptation methods are."
W19-4436,Supporting content evaluation of student summaries by Idea Unit embedding,2019,0,0,3,0,24197,marcello gecchele,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"This paper discusses the computer-assisted content evaluation of summaries. We propose a method to make a correspondence between the segments of the source text and its summary. As a unit of the segment, we adopt {``}Idea Unit (IU){''} which is proposed in Applied Linguistics. Introducing IUs enables us to make a correspondence even for the sentences that contain multiple ideas. The IU correspondence is made based on the similarity between vector representations of IU. An evaluation experiment with two source texts and 20 summaries showed that the proposed method is more robust against rephrased expressions than the conventional ROUGE-based baselines. Also, the proposed method outperformed the baselines in recall. We im-plemented the proposed method in a GUI tool{``}Segment Matcher{''} that aids teachers to estab-lish a link between corresponding IUs acrossthe summary and source text."
D19-5212,Neural Machine Translation System using a Content-equivalently Translated Parallel Corpus for the Newswire Translation Tasks at {WAT} 2019,2019,0,0,6,1,287,hideya mino,Proceedings of the 6th Workshop on Asian Translation,0,"This paper describes NHK and NHK Engineering System (NHK-ES){'}s submission to the newswire translation tasks of WAT 2019 in both directions of JapaneseâEnglish and EnglishâJapanese. In addition to the JIJI Corpus that was officially provided by the task organizer, we developed a corpus of 0.22M sentence pairs by manually, translating Japanese news sentences into English content- equivalently. The content-equivalent corpus was effective for improving translation quality, and our systems achieved the best human evaluation scores in the newswire translation tasks at WAT 2019."
Y18-1066,Effectiveness of Domain Adaptation in {J}apanese Predicate-Argument Structure Analysis,2018,0,0,3,0,27549,mizuki sango,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
Y18-1089,Neural {J}apanese Zero Anaphora Resolution using Smoothed Large-scale Case Frames with Word Embedding,2018,0,0,3,0,27583,souta yamashiro,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
L18-1434,Analysis of Implicit Conditions in Database Search Dialogues,2018,0,0,3,0,29985,shunya fukunaga,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1040,Interpretation of Implicit Conditions in Database Search Dialogues,2018,0,0,3,0,29985,shunya fukunaga,Proceedings of the 27th International Conference on Computational Linguistics,0,"Targeting the database search dialogue, we propose to utilise information in the user utterances that do not directly mention the database (DB) field of the backend database system but are useful for constructing database queries. We call this kind of information implicit conditions. Interpreting the implicit conditions enables the dialogue system more natural and efficient in communicating with humans. We formalised the interpretation of the implicit conditions as classifying user utterances into the related DB field while identifying the evidence for that classification at the same time. Introducing this new task is one of the contributions of this paper. We implemented two models for this task: an SVM-based model and an RCNN-based model. Through the evaluation using a corpus of simulated dialogues between a real estate agent and a customer, we found that the SVM-based model showed better performance than the RCNN-based model."
W17-5103,Annotation of argument structure in {J}apanese legal documents,2017,8,2,3,0,24198,hiroaki yamada,Proceedings of the 4th Workshop on Argument Mining,0,"We propose a method for the annotation of Japanese civil judgment documents, with the purpose of creating flexible summaries of these. The first step, described in the current paper, concerns content selection, i.e., the question of which material should be extracted initially for the summary. In particular, we utilize the hierarchical argument structure of the judgment documents. Our main contributions are a) the design of an annotation scheme that stresses the connection between legal points (called issue topics) and argument structure, b) an adaptation of rhetorical status to suit the Japanese legal system and c) the definition of a linked argument structure based on legal sub-arguments. In this paper, we report agreement between two annotators on several aspects of the overall task."
W17-5008,Evaluation of Automatically Generated Pronoun Reference Questions,2017,12,2,2,0,31580,arief satria,Proceedings of the 12th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,This study provides a detailed analysis of evaluation of English pronoun reference questions which are created automatically by machine. Pronoun reference questions are multiple choice questions that ask test takers to choose an antecedent of a target pronoun in a reading passage from four options. The evaluation was performed from two perspectives: the perspective of English teachers and that of English learners. Item analysis suggests that machine-generated questions achieve comparable quality with human-made questions. Correlation analysis revealed a strong correlation between the scores of machine-generated questions and that of human-made questions.
W17-2410,Evaluating text coherence based on semantic similarity graph,2017,10,6,2,1,12222,jan putra,Proceedings of {T}ext{G}raphs-11: the Workshop on Graph-based Methods for Natural Language Processing,0,"Coherence is a crucial feature of text because it is indispensable for conveying its communication purpose and meaning to its readers. In this paper, we propose an unsupervised text coherence scoring based on graph construction in which edges are established between semantically similar sentences represented by vertices. The sentence similarity is calculated based on the cosine similarity of semantic vectors representing sentences. We provide three graph construction methods establishing an edge from a given vertex to a preceding adjacent vertex, to a single similar vertex, or to multiple similar vertices. We evaluated our methods in the document discrimination task and the insertion task by comparing our proposed methods to the supervised (Entity Grid) and unsupervised (Entity Graph) baselines. In the document discrimination task, our method outperformed the unsupervised baseline but could not do the supervised baseline, while in the insertion task, our method outperformed both baselines."
tokunaga-etal-2017-eye,An Eye-tracking Study of Named Entity Annotation,2017,16,2,1,1,301,takenobu tokunaga,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Utilising effective features in machine learning-based natural language processing (NLP) is crucial in achieving good performance for a given NLP task. The paper describes a pilot study on the analysis of eye-tracking data during named entity (NE) annotation, aiming at obtaining insights into effective features for the NE recognition task. The eye gaze data were collected from 10 annotators and analysed regarding working time and fixation distribution. The results of the preliminary qualitative analysis showed that human annotators tend to look at broader contexts around the target NE than recent state-of-the-art automatic NE recognition systems and to use predicate argument relations to identify the NE categories."
I17-2049,Key-value Attention Mechanism for Neural Machine Translation,2017,12,3,4,1,287,hideya mino,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In this paper, we propose a neural machine translation (NMT) with a key-value attention mechanism on the source-side encoder. The key-value attention mechanism separates the source-side content vector into two types of memory known as the key and the value. The key is used for calculating the attention distribution, and the value is used for encoding the context representation. Experiments on three different tasks indicate that our model outperforms an NMT model with a conventional attention mechanism. Furthermore, we perform experiments with a conventional NMT framework, in which a part of the initial value of a weight matrix is set to zero so that the matrix is as the same initial-state as the key-value attention mechanism. As a result, we obtain comparable results with the key-value attention mechanism without changing the network structure."
W16-5401,An extension of {ISO}-Space for annotating object direction,2016,0,0,3,0,33472,daiki gotou,Proceedings of the 12th Workshop on {A}sian Language Resources ({ALR}12),0,"In this paper, we extend an existing annotation scheme ISO-Space for annotating necessary spatial information for the task placing an specified object at a specified location with a specified direction according to a natural language instruction. We call such task the spatial placement problem. Our extension particularly focuses on describing the object direction, when the object is placed on the 2D plane. We conducted an annotation experiment in which a corpus of 20 situated dialogues were annotated. The annotation result showed the number of newly introduced tags by our proposal is not negligible. We also implemented an analyser that automatically assigns the proposed tags to the corpus and evaluated its performance. The result showed that the performance for entity tag was quite high ranging from 0.68 to 0.99 in F-measure, but not the case for relation tags, i.e. less than 0.4 in F-measure."
L16-1697,Solving the {AL} Chicken-and-Egg Corpus and Model Problem: Model-free Active Learning for Phenomena-driven Corpus Construction,2016,41,0,4,1,20637,dain kaplan,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Active learning (AL) is often used in corpus construction (CC) for selecting {``}informative{''} documents for annotation. This is ideal for focusing annotation efforts when all documents cannot be annotated, but has the limitation that it is carried out in a closed-loop, selecting points that will improve an existing model. For phenomena-driven and exploratory CC, the lack of existing-models and specific task(s) for using it make traditional AL inapplicable. In this paper we propose a novel method for model-free AL utilising characteristics of phenomena for applying AL to select documents for annotation. The method can also supplement traditional closed-loop AL-based CC to extend the utility of the corpus created beyond a single task. We introduce our tool, MOVE, and show its potential with a real world case-study."
C16-1269,Parameter estimation of {J}apanese predicate argument structure analysis model using eye gaze information,2016,17,1,3,0,35826,ryosuke maki,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"In this paper, we propose utilising eye gaze information for estimating parameters of a Japanese predicate argument structure (PAS) analysis model. We employ not only linguistic information in the text, but also the information of annotator eye gaze during their annotation process. We hypothesise that annotator{'}s frequent looks at certain candidates imply their plausibility of being the argument of the predicate. Based on this hypothesis, we consider annotator eye gaze for estimating the model parameters of the PAS analysis. The evaluation experiment showed that introducing eye gaze information increased the accuracy of the PAS analysis by 0.05 compared with the conventional methods."
N15-1031,Incrementally Tracking Reference in Human/Human Dialogue Using Linguistic and Extra-Linguistic Information,2015,35,6,3,0,821,casey kennington,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"A large part of human communication involves referring to entities in the world and often these entities are objects that are visually present for the interlocutors. A system that aims to resolve such references needs to tackle a complex task: objects and their visual features need to be determined, the referring expressions must be recognised, and extra-linguistic information such as eye gaze or pointing gestures need to be incorporated. Systems that can make use of such information sources exist, but have so far only been tested under very constrained settings, such as WOz interactions. In this paper, we apply to a more complex domain a reference resolution model that works incrementally (i.e., word by word), grounds words with visually present properties of objects (such as shape and size), and can incorporate extra-linguistic information. We find that the model works well compared to previous work on the same data, despite using fewer features. We conclude that the model shows potential for use in a realtime interactive dialogue system."
iida-tokunaga-2014-building,Building a Corpus of Manually Revised Texts from Discourse Perspective,2014,13,1,2,0.639184,12930,ryu iida,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents building a corpus of manually revised texts which includes both before and after-revision information. In order to create such a corpus, we propose a procedure for revising a text from a discourse perspective, consisting of dividing a text to discourse units, organising and reordering groups of discourse units and finally modifying referring and connective expressions, each of which imposes limits on freedom of revision. Following the procedure, six revisers who have enough experience in either teaching Japanese or scoring Japanese essays revised 120 Japanese essays written by Japanese native speakers. Comparing the original and revised texts, we found some specific manual revisions frequently occurred between the original and revised texts, e.g. ÂthesisÂ statements were frequently placed at the beginning of a text. We also evaluate text coherence using the original and revised texts on the task of pairwise information ordering, identifying a more coherent text. The experimental results using two text coherence models demonstrated that the two models did not outperform the random baseline."
W13-4303,Detecting Missing Annotation Disagreement using Eye Gaze Information,2013,22,3,3,0,17976,koh mitsuda,Proceedings of the 11th Workshop on {A}sian Language Resources,0,"This paper discusses the detection of missing annotation disagreements (MADs), in which an annotator misses annotating an annotation instance while her counterpart correctly annotates it. We employ annotator eye gaze as a clue for detecting this type of disagreement together with linguistic information. More precisely, we extract highly frequent gaze patterns from the pre-extracted gaze sequences related to the annotation target, and then use the gaze patterns as features for detecting the MADs. Through the empirical evaluation using the data set collected in our previous study, we investigated the effectiveness of each type of information. The results showed that both eye gaze and linguistic information contributed to improving performance of our MAD detection model compared with the baseline model. Furthermore, our additional investigation revealed that some specific gaze patterns could be a good indicator for detecting the MADs."
W13-2326,Investigation of annotator{'}s behaviour using eye-tracking data,2013,19,1,3,0.648974,12930,ryu iida,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"This paper presents an analysis of an annotatorxe2x80x99s behaviour during her/his annotation process for eliciting useful information for natural language processing (NLP) tasks. Text annotation is essential for machine learning-based NLP where annotated texts are used for both training and evaluating supervised systems. Since an annotatorxe2x80x99s behaviour during annotation can be seen as reflecting her/his cognitive process during her/his attempt to understand the text for annotation, analysing the process of text annotation has potential to reveal useful information for NLP tasks, in particular semantic and discourse processing that require deeper language understanding. We conducted an experiment for collecting annotator actions and eye gaze during the annotation of predicate-argument relations in Japanese texts. Our analysis of the collected data suggests that obtained insight into human annotation behaviour is useful for exploring effective linguistic features in machine learning-based approaches."
W13-2118,Automatic Voice Selection in {J}apanese based on Various Linguistic Information,2013,13,0,2,0.648974,12930,ryu iida,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"This paper focuses on a subtask of natural language generation (NLG), voice selection, which decides whether a clause is realised in the active or passive voice according to its contextual information. Automatic voice selection is essential for realising more sophisticated MT and summarisation systems, because it impacts the readability of generated texts. However, to the best of our knowledge, the NLG community has been less concerned with explicit voice selection. In this paper, we propose an automatic voice selection model based on various linguistic information, ranging from lexical to discourse information. Our empirical evaluation using a manually annotated corpus in Japanese demonstrates that the proposed model achieved 0.758 in F-score, outperforming the two baseline models."
W13-0508,Annotation for annotation - Toward eliciting implicit linguistic knowledge through annotation - (Project Note),2013,17,0,1,1,301,takenobu tokunaga,Proceedings of the 9th Joint {ISO} - {ACL} {SIGSEM} Workshop on Interoperable Semantic Annotation,0,"The last two decades witnessed a great success of revived empiricism in NLP research. However, there are still several NLP tasks that are not successful enough. As one of many directions for going beyond the revived empiricism, this paper introduces a project for annotating annotations with annotatorsxe2x80x99 rationales behind them. As a first step of this enterprise, the paper particularly focuses on data collection during the annotation and discusses their potential uses. Finally a preliminary experiment for data collection is described with the data analysis."
W12-1633,A Unified Probabilistic Approach to Referring Expressions,2012,29,12,3,0.979349,10700,kotaro funakoshi,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper proposes a probabilistic approach to the resolution of referring expressions for task-oriented dialogue systems. The approach resolves descriptions, anaphora, and deixis in a unified manner. In this approach, the notion of reference domains serves an important role to handle context-dependent attributes of entities and references to sets. The evaluation with the REX-J corpus shows promising results."
tokunaga-etal-2012-rex,The {REX} corpora: A collection of multimodal corpora of referring expressions in collaborative problem solving dialogues,2012,19,12,1,1,301,takenobu tokunaga,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper describes a collection of multimodal corpora of referring expressions, the REX corpora. The corpora have two notable features, namely (1) they include time-aligned extra-linguistic information such as participant actions and eye-gaze on top of linguistic information, (2) dialogues were collected with various configurations in terms of the puzzle type, hinting and language. After describing how the corpora were constructed and sketching out each, we present an analysis of various statistics for the corpora with respect to the various configurations mentioned above. The analysis showed that the corpora have different characteristics in the number of utterances and referring expressions in a dialogue, the task completion time and the attributes used in the referring expressions. In this respect, we succeeded in constructing a collection of corpora that included a variety of characteristics by changing the configurations for each set of dialogues, as originally planned. The corpora are now under preparation for publication, to be used for research on human reference behaviour."
fujii-etal-2012-effects,Effects of Document Clustering in Modeling {W}ikipedia-style Term Descriptions,2012,8,1,3,0,37781,atsushi fujii,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Reflecting the rapid growth of science, technology, and culture, it has become common practice to consult tools on the World Wide Web for various terms. Existing search engines provide an enormous volume of information, but retrieved information is not organized. Hand-compiled encyclopedias provide organized information, but the quantity of information is limited. In this paper, aiming to integrate the advantages of both tools, we propose a method to organize a search result based on multiple viewpoints as in Wikipedia. Because viewpoints required for explanation are different depending on the type of a term, such as animal and disease, we model articles in Wikipedia to extract a viewpoint structure for each term type. To identify a set of term types, we independently use manual annotation and automatic document clustering for Wikipedia articles. We also propose an effective feature for clustering of Wikipedia articles. We experimentally show that the document clustering reduces the cost for the manual annotation while maintaining the accuracy for modeling Wikipedia articles."
C12-2048,A Metric for Evaluating Discourse Coherence based on Coreference Resolution,2012,25,5,2,0.682826,12930,ryu iida,Proceedings of {COLING} 2012: Posters,0,"We propose a simple and effective metric for automatically evaluating discourse coherence of a text using the outputs of a coreference resolution model. According to the idea that a writer tends to appropriately utilise coreference relations when writing a coherent text, we introduce a metric of discourse coherence based on automatically identified coreference relations. We empirically evaluated our metric by comparing it to the entity grid modelling by Barzilay and Lapata (2008) using Japanese newspaper articles as a target data set. The results indicate that our metric better reflects discourse coherence of texts than the existing model."
I11-1010,Multi-modal Reference Resolution in Situated Dialogue by Integrating Linguistic and Extra-Linguistic Clues,2011,37,14,3,0.821245,12930,ryu iida,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper focuses on examining the effect of extra-linguistic information, such as eye gaze, integrated with linguistic information on multi-modal reference resolution. In our evaluation, we employ eye gaze information together with other linguistic factors in machine learning, while in prior work such as Kelleher (2006) and Prasov and Chai (2008) the incorporation of eye gaze and linguistic clues was heuristically realised. Conducting our empirical evaluation using a data set extended the REX-J corpus (Spanger et al., 2010) including eye gaze information, we examine which types of clues are useful on these three data sets, which consist largely of pronouns, nonpronouns and both respectively. Our results demonstrate that a dynamically moving visible indicator within the computer display (e.g. a mouse cursor) contributes to reference resolution for pronouns, while eye gaze information is more useful for the resolution of non-pronouns."
W10-4214,Towards an Extrinsic Evaluation of Referring Expressions in Situated Dialogs,2010,25,3,3,1,45121,philipp spanger,Proceedings of the 6th International Natural Language Generation Conference,0,"In the field of referring expression generation, while in the static domain both intrinsic and extrinsic evaluations have been considered, extrinsic evaluation in the dynamic domain, such as in a situated collaborative dialog, has not been discussed in depth. In a dynamic domain, a crucial problem is that referring expressions do not make sense without an appropriate preceding dialog context. It is unrealistic for an evaluation to simply show a human evaluator the whole period from the beginning of a dialog up to the time point at which a referring expression is used. Hence, to make evaluation feasible it is indispensable to determine an appropriate shorter context. In order to investigate the context necessary to understand a referring expression in a situated collaborative dialog, we carried out an experiment with 33 evaluators and a Japanese referring expression corpus. The results contribute to finding the proper contexts for extrinsic evalution in dynamic domains."
W10-3206,Construction of bilingual multimodal corpora of referring expressions in collaborative problem solving,2010,20,2,1,1,301,takenobu tokunaga,Proceedings of the Eighth Workshop on {A}sian Language Resouces,0,"This paper presents on-going work on constructing bilingual multimodal corpora of referring expressions in collaborative problem solving for English and Japanese. The corpora were collected from dialogues in which two participants collaboratively solved Tangram puzzles with a puzzle simulator. Extra-linguistic information such as operations on puzzle pieces, mouse cursor position and piece positions were recorded in synchronisation with utterances. The speech data was transcribed and time-aligned with the extra-linguistic information. Referring expressions in utterances that refer to puzzle pieces were annotated in terms of their spans, their referents and their other attributes. The Japanese corpus has already been completed, but the English counterpart is still undergoing annotation. We have conducted a preliminary comparative analysis of both corpora, mainly with respect to task completion time, task success rates and attributes of referring expressions. These corpora showed significant differences in task completion time and success rate."
P10-1128,Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue,2010,25,11,3,0.931052,12930,ryu iida,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"This paper proposes an approach to reference resolution in situated dialogues by exploiting extra-linguistic information. Recently, investigations of referential behaviours involved in situations in the real world have received increasing attention by researchers (Di Eugenio et al., 2000; Byron, 2005; van Deemter, 2007; Spanger et al., 2009). In order to create an accurate reference resolution model, we need to handle extra-linguistic information as well as textual information examined by existing approaches (Soon et al., 2001; Ng and Cardie, 2002, etc.). In this paper, we incorporate extra-linguistic information into an existing corpus-based reference resolution model, and investigate its effects on reference resolution problems within a corpus of Japanese dialogues. The results demonstrate that our proposed model achieves an accuracy of 79.0% for this task."
kaplan-etal-2010-annotation,Annotation Process Management Revisited,2010,14,7,3,1,20637,dain kaplan,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Proper annotation process management is crucial to the construction of corpora, which are in turn indispensable to the data-driven techniques that have come to the forefront in NLP during the last two decades. It is still common to see ad-hoc tools created for a specific annotation project, but it is time this changed; creation of such tools is labor and time expensive, and is secondary to corpus creation. In addition, such tools likely lack proper annotation process management, increasingly more important as corpora sizes grow in size and complexity. This paper first raises a list of ten needs that any general purpose annotation system should address moving forward, such as user {\&} role management, delegation {\&} monitoring of work, diffing {\&} merging annotatorsÂ work, versioning of corpora, multilingual support, import/export format flexibility, and so on. A framework to address these needs is then proposed, and how having proper annotation process management can be beneficial to the creation and maintenance of corpora explained. The paper then introduces SLATE (Segment and Link-based Annotation Tool Enhanced), the second iteration of a web-based annotation tool, which is being rewritten to implement the proposed framework."
W09-3611,Automatic Extraction of Citation Contexts for Research Paper Summarization: A Coreference-chain based Approach,2009,21,38,3,1,20637,dain kaplan,Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries ({NLPIR}4{DL}),0,"This paper proposes a new method based on coreference-chains for extracting citations from research papers. To evaluate our method we created a corpus of citations comprised of citing papers for 4 cited papers. We analyze some phenomena of citations that are present in our corpus, and then evaluate our method against a cue-phrase-based technique. Our method demonstrates higher precision by 7--10%."
W09-3421,Query Expansion using {LMF}-Compliant Lexical Resources,2009,8,4,1,1,301,takenobu tokunaga,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper reports prototype multilingual query expansion system relying on LMF compliant lexical resources. The system is one of the deliverables of a three-year project aiming at establishing an international standard for language resources which is applicable to Asian languages. Our important contributions to ISO 24613, standard Lexical Markup Framework (LMF) include its robustness to deal with Asian languages, and its applicability to cross-lingual query tasks, as illustrated by the prototype introduced in this paper."
W09-0618,A {J}apanese Corpus of Referring Expressions Used in a Situated Collaboration Task,2009,8,6,4,1,45121,philipp spanger,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,"In order to pursue research on generating referring expressions in a situated collaboration task, we set up a data-collection experiment based on the Tangram puzzle. For a pair of participants we recorded every utterance in synchronisation with the current state of the puzzle as well as all operations by the participants. Referring expressions were annotated with their referents in order to build a referring expression corpus in Japanese. We provide preliminary results on the analysis of the corpus from various standpoints, focussing on action-mentioning expressions."
W09-0634,A Probabilistic Model of Referring Expressions for Complex Objects,2009,8,4,4,1,10700,kotaro funakoshi,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,"This paper presents a probabilistic model both for generation and understanding of referring expressions. This model introduces the concept of parts of objects, modelling the necessity to deal with the characteristics of separate parts of an object in the referring process. This was ignored or implicit in previous literature. Integrating this concept into a probabilistic formulation, the model captures human characteristics of visual perception and some type of pragmatic implicature in referring expressions. Developing this kind of model is critical to deal with more complex domains in the future. As a first step in our research, we validate the model with the TUNA corpus to show that it includes conventional domain modeling as a subset."
J09-4003,{O}bituaries: Hozumi {T}anaka,2009,-1,-1,2,0.0804737,1468,timothy baldwin,Computational Linguistics,0,None
tokunaga-etal-2008-adapting,Adapting International Standard for {A}sian Language Technologies,2008,8,6,1,1,301,takenobu tokunaga,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Corpus-based approaches and statistical approaches have been the main stream of natural language processing research for the past two decades. Language resources play a key role in such approaches, but there is an insufficient amount of language resources in many Asian languages. In this situation, standardisation of language resources would be of great help in developing resources in new languages. This paper presents the latest development efforts of our project which aims at creating a common standard for Asian language resources that is compatible with an international standard. In particular, the paper focuses on i) lexical specification and data categories relevant for building multilingual lexical resources for Asian languages; ii) a core upper-layer ontology needed for ensuring multilingual interoperability and iii) the evaluation platform used to test the entire architectural framework."
I08-1052,Constructing Taxonomy of Numerative Classifiers for {A}sian Languages,2008,5,9,2,0.710689,29633,kiyoaki shirai,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"Numerative classifiers are ubiquitous in many Asian languages. This paper proposes a method to construct a taxonomy of numerative classifiers based on a nounclassifier agreement database. The taxonomy defines superordinate-subordinate relation among numerative classifiers and represents the relations in tree structures. The experiments to construct taxonomies were conducted for evaluation by using data from three different languages: Chinese, Japanese and Thai. We found that our method was promising for Chinese and Japanese, but inappropriate for Thai. It confirms that there really is no hierarchy among Thai classifiers."
C08-2029,On {``}Redundancy{''} in Selecting Attributes for Generating Referring Expressions,2008,3,3,3,1,45121,philipp spanger,Coling 2008: Companion volume: Posters,0,"We seek to develop an efficient algorithm selecting attributes that approximates human selection. In contrast to previous work we sought to combine the strengths of cognitive theories and simple learning algorithms. We then developed a new algorithm for attribute selection based on observations from a corpus, which outperformed a simple base algorithm by a significant margin. We then carried out a detailed comparison between our algorithm and Reiter & Dalexe2x80x99s xe2x80x9cIncremental Algorithmxe2x80x9d. In terms of achieving a human-like attribute selection, the overall performance of both algorithms is fundamentally equivalent, while differing in the handling of redundancy in selected attributes. We further investigated this phenomenon and draw some conclusions for further improvement of attribute-selection algorithms."
2007.tmi-papers.12,Extracting phrasal alignments from comparable corpora by using joint probability {SMT} model,2007,-1,-1,3,0,36676,tadashi kumano,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
W06-1411,Group-Based Generation of Referring Expressions,2006,13,14,3,1,10700,kotaro funakoshi,Proceedings of the Fourth International Natural Language Generation Conference,0,"Past work of generating referring expressions mainly utilized attributes of objects and binary relations between objects in order to distinguish the target object from others. However, such an approach does not work well when there is no distinctive attribute among objects. To overcome this limitation, this paper proposes a novel generation method utilizing perceptual groups of objects and n-ary relations among them. The evaluation using 18 subjects showed that the proposed method could effectively generate proper referring expressions."
P06-2052,Efficient Sentence Retrieval Based on Syntactic Structure,2006,5,6,4,1,39152,hiroshi ichikawa,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"This paper proposes an efficient method of sentence retrieval based on syntactic structure. Collins proposed Tree Kernel to calculate structural similarity. However, structual retrieval based on Tree Kernel is not practicable because the size of the index table by Tree Kernel becomes impractical. We propose more efficient algorithms approximating Tree Kernel: Tree Overlapping and Subpath Set. These algorithms are more efficient than Tree Kernel because indexing is possible with practical computation resources. The results of the experiments comparing these three algorithms showed that structural retrieval with Tree Overlapping and Subpath Set were faster than that with Tree Kernel by 100 times and 1,000 times respectively."
P06-2106,Infrastructure for Standardization of {A}sian Language Resources,2006,10,18,1,1,301,takenobu tokunaga,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"As an area of great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least three strong advantages: to increase the competitive edge of Asian countries, to bring Asian countries to closer to their western counterparts, and to bring more cohesion among Asian countries. To achieve this goal, we have launched a two year project to create a common standard for Asian language resources. The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upper-layer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach."
noguchi-etal-2006-new,A new approach to syntactic annotation,2006,6,1,4,0,37838,masaki noguchi,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Many systems have been developed for creating syntactically annotated corpora. However, they mainly focus on interface usability and hardly pay attention toknowledge sharing among annotators in the task. In order to incorporate the functionality of knowledge sharing, we emphasized the importance of normalizingthe annotation process. As a first step toward knowledge sharing, this paper proposes a method of system initiative annotation in which the system suggests annotators the order of ambiguities to solve. To be more concrete, the system forces annotators to solve ambiguity of constituent structure in a top-down and depth-first manner, and then to solve ambiguity of grammatical category in a bottom-up and breadth-first manner. We implemented the system on top of eBonsai, our annotation tool, and conducted experiments to compare eBonsai and the proposed system in terms of annotation accuracy and efficiency. We found that at least for novice annotators, the proposed system is more efficient while keeping annotation accuracy comparable with eBonsai."
E06-1023,Identifying Repair Targets in Action Control Dialogue,2006,6,3,2,1,10700,kotaro funakoshi,11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper proposes a method for dealing with repairs in action control dialogue to resolve participantsxe2x80x99 misunderstanding. The proposed method identifies the repair target based on common grounding rather than surface expressions. We extend Traumxe2x80x99s grounding act model by introducing degree of groundedness, and partial and mid-discourse unit grounding. This paper contributes to achieving more natural human-machine dialogue and instantaneous and flexible control of agents."
I05-4002,Evaluation of a {J}apanese {CFG} Derived from a Syntactically Annotated Corpus with Respect to Dependency Measures,2005,11,4,4,0,48618,tomoya noro,Proceedings of the Fifth Workshop on {A}sian Language Resources ({ALR}-05) and First Symposium on {A}sian Language Resources Network ({ALRN}),0,"Parsing is one of the important processes for natural language processing and, in general, a large-scale CFG is used to parse a wide variety of sentences. For many languages, a CFG is derived from a large-scale syntactically annotated corpus, and many parsing algorithms using CFGs have been proposed. However, we could not apply them to Japanese since a Japanese syntactically annotated corpus has not been available as of yet. In order to solve the problem, we have been building a large-scale Japanese syntactically annotated corpus. In this paper, we show the evaluation results of a CFG derived from our corpus and compare it with results of some Japanese dependency analyzers."
I05-2019,e{B}onsai: An Integrated Environment for Annotating Treebanks,2005,6,6,4,1,39152,hiroshi ichikawa,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,None
yoshida-etal-2004-retrieving,Retrieving Annotated Corpora for Corpus Annotation,2004,2,2,3,0,41969,kyosuke yoshida,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper introduces a tool {\textbackslash}Bonsai which supports human in annotating corpora with morphosyntactic information, and in retrieving syntactic structures stored in the database. Integrating annotation and retrieval enables users to annotate a new instance while looking back at the already annotated sentences which share the similar morphosyntactic structure. We focus on the retrieval part of the system, and describe a method to decompose a large input query into smaller ones in order to gain retrieval efficiency. The proposed method is evaluated with the Penn Treebank corpus, showing significant improvements."
tokunaga-etal-2004-classification,Classification of {J}apanese Spatial Nouns,2004,13,2,1,1,301,takenobu tokunaga,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We have already proposed a framework to represent a location in terms of both symbolic and numeric aspects. In order to deal with vague linguistic expressions of a location, the representation adopts a potential function mapping a location to its plausibility. This paper proposes classification of Japanese spatial nouns and potential functions corresponding to each class. We focused on a common Japanese spatial expression ``X no Y (Y of X)'' where X is a reference object and Y is a spatial noun. For example, ``tukue no migi (the right of the desk)'' denotes a location with reference to the desk. This expression were collected from corpora, and spatial nouns appearing in the Y position were classified into two major classes; designating a part of the reference object and designating a location apart from the reference object . And the latter class were further classified into two subclasses; direction-oriented and distance-oriented. For each class, a potential function were designed for providing meaning of spatial nouns."
C04-1096,Generation of Relative Referring Expressions based on Perceptual Grouping,2004,17,6,4,1,10700,kotaro funakoshi,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Past work of generating referring expressions mainly utilized attributes of objects and binary relations between objects. However, such an approach does not work well when there is no distinctive attribute among objects. To overcome this limitation, this paper proposes a method utilizing the perceptual groups of objects and n-ary relations among them. The key is to identify groups of objects that are naturally recognized by humans. We conducted psychological experiments with 42 subjects to collect referring expressions in such situations, and built a generation algorithm based on the results. The evaluation using another 23 subjects showed that the proposed method could effectively generate proper referring expressions."
W03-1611,Paraphrasing {J}apanese Noun Phrases using Character-based Indexing,2003,17,4,1,1,301,takenobu tokunaga,Proceedings of the Second International Workshop on Paraphrasing,0,"This paper proposes a novel method to extract paraphrases of Japanese noun phrases from a set of documents. The proposed method consists of three steps: (1) retrieving passages using character-based index terms given a noun phrase as an input query, (2) filtering the retrieved passages with syntactic and semantic constraints, and (3) ranking the passages and reformatting them into grammatical forms. Experiments were conducted to evaluate the method by using 53 noun phrases and three years worth of newspaper articles. The accuracy of the method needs to be further improved for fully automatic paraphrasing but the proposed method can extract novel paraphrases which past approaches could not."
W03-1107,Feature Selection in Categorizing Procedural Expressions,2003,15,25,2,0,52705,mineki takechi,Proceedings of the Sixth International Workshop on Information Retrieval with {A}sian Languages,0,"Text categorization, as an essential component of applications for user navigation on the World Wide Web using Question-Answering in Japanese, requires more effective features for the categorization of documents and the efficient acquisition of knowledge. In the questions addressed by such navigation, we focus on those questions for procedures and intend to clarify specification of the answers."
tokunaga-etal-2002-constructing,Constructing a lexicon of action,2002,3,2,1,1,301,takenobu tokunaga,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper describes a Japanese speech dialogue system that enables a user to interact with agents in a virtual world and proposes a design framework for building a lexicon of action. This lexicon is used to realize the behavior of the agents in response to the userxe2x80x99s commands. The lexicon has two levels xe2x80x93 a macro and micro level. The system uses the macro-level lexicon, which is similar to a conventional plan library, to translate the userxe2x80x99s goal to a sequence of basic movements. This process is the same as conventional planning with symbol manipulation. The micro-level lexicon is used to translate the basic movements into animation, which is represented by a sequence of avatar postures. We discuss how to define a set of basic movements and how to make these basic movements reusable."
baldwin-etal-2002-enhanced,Enhanced {J}apanese Electronic Dictionary Look-up,2002,7,2,4,0.512821,1468,timothy baldwin,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper describes the process of data preparation and reading generation for an ongoing project aimed at improving the accessibility of unknown words for learners of foreign languages, focusing initially on Japanese. Rather then requiring absolute knowledge of the readings of words in the foreign language, we allow look-up of dictionary entries by readings which learners can predictably be expected to associate with them. We automatically extract an exhaustive set of phonemic readings for each grapheme segment and learn basic morpho-phonological rules governing compound word formation, associating a probability with each. Then we apply the naive Bayes model to generate a set of readings and give each a likeliness score based on previously extracted evidence and corpus frequencies."
C02-1059,Processing {J}apanese Self-correction in Speech Dialog Systems,2002,6,5,2,1,10700,kotaro funakoshi,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Speech dialog systems need to deal with various kinds of ill-formed speech inputs that appear in natural human-human dialog. Self-correction (or speech-repair) is a particularly problematic phenomenon. Although many ways of dealing with self-correction have been proposed, these have limitations in both detecting and correcting for this phenomenon. In this paper, we propose a method to overcome these problems in Japanese speech dialog. We evaluate the proposed method using our speech dialog corpus and discuss its limitations and the work that remains to be done."
S01-1013,The {J}apanese Translation Task: Lexical and Structural Perspectives,2001,4,1,3,0.512821,1468,timothy baldwin,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"This paper describes two distinct attempts at the SENSEVAL-2 Japanese translation task. The first implementation is based on lexical similarity and builds on the results of Baldwin (2001b; 2001a), whereas the second is based on structural similarity via the medium of parse trees and includes a basic model of conceptual similarity. Despite its simplistic nature, the lexical method was found to perform the better of the two, at 49.1% accuracy, as compared to 41.2% for the structural method and 36.8% for the baseline."
2001.mtsummit-papers.28,Decision lists for determining adjective dependency in {J}apanese,2001,5,1,4,1,49931,taiichi hashimoto,Proceedings of Machine Translation Summit VIII,0,"In Japanese constructions of the form [N1 no Adj N2], the adjective Adj modifies either N1 or N2. Determing the semantic dependencies of adjective in such phrase is an important task for machine translation. This paper describes a method for determining the adjective dependency in such constructions using decision lists, and inducing decision lists from training contexts with correct semantic dependencies and without. Based on evaluation, our method is able to determine adjective dependency with an precision of about 94{\%}. We further analyze rules in the induced decision lists and examine effective features to determine the semantic dependencies of adjectives."
shirai-etal-2000-semi,Semi-automatic Construction of a Tree-annotated Corpus Using an Iterative Learning Statistical Language Model,2000,9,0,3,1,29633,kiyoaki shirai,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"In this paper, we propose a method to construct a tree-annotated corpus, when a certain statistical parsing system exists and no tree-annotated corpus is available as training data. The basic idea of our method is to sequentially annotate plain text inputs with syntactic trees using a parser with a statistical language model, and iteratively retrain the statistical language model over the obtained annotated trees. The major characteristics of our method are as follows: (1)in the first step of the iterative learning process, we manually construct a tree-annotated corpus to initialize the statistical language model over, and (2) at each step of the parse tree annotation process, we use both syntactic statistics obtained from the iterative learning process and lexical statistics pre-derived from existing language resources, to choose the most probable"
E99-1013,Complementing {W}ord{N}et with {R}oget{'}s and Corpus-based Thesauri for Information Retrieval,1999,23,25,2,0,54967,rila mandala,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,This paper proposes a method to overcome the drawbacks of WordNet when applied to information retrieval by complementing it with Roget's thesaurus and corpus-derived thesauri. Words and relations which are not included in WordNet can be found in the corpus-derived thesauri. Effects of polysemy can be minimized with weighting method considering all query terms and all of the thesauri. Experimental results show that our method enhances information retrieval performance significantly.
1999.mtsummit-1.80,Sharing syntactic structures,1999,-1,-1,2,0,55042,masahiro ueki,Proceedings of Machine Translation Summit VII,0,"Bracketed corpora are a very useful resource for natural language processing, but hard to build efficiently, leading to quantitative insufficiency for practical use. Disparities in morphological information, such as word segmentation and part-of-speech tag sets, are also troublesome. An application specific to a particular corpus often cannot be applied to another corpus. In this paper, we sketch out a method to build a corpus that has a fixed syntactic structure but varying morphological annotation based on the different tag set schemes utilized. Our system uses a two layered grammar, one layer of which is made up of replaceable tag-set-dependent rules while the other has no such tag set dependency. The input sentences of our system are bracketed corresponding to structural information of corpus. The parser can work using any tag set and grammar, and using the same input bracketing, we obtain corpus that shares partial syntactic structure."
W98-1510,An Empirical Evaluation on Statistical Parsing of {J}apanese Sentences Using Lexical Association Statistics,1998,11,7,3,1,29633,kiyoaki shirai,Proceedings of the Third Conference on Empirical Methods for Natural Language Processing,0,"We are proposing a new framework of statistical language modeling which integrates lexical association statistics with syntactic preference, while maintaining the modularity of those different statistics types, facilitating both training of the model and analysis of its behavior. In this paper, we report the result of an empirical evaluation of our model, where the model is applied to disambiguation of dependency structures of Japanese sentences. We also discussed the room remained for further improvement based on our error analysis."
W98-0704,The Use of {W}ord{N}et in Information Retrieval,1998,10,104,2,0,55196,mandala rila,Usage of {W}ord{N}et in Natural Language Processing Systems,0,None
J98-4002,Selective Sampling for Example-based Word Sense Disambiguation,1998,49,95,3,1,37781,atsushi fujii,Computational Linguistics,0,"This paper proposes an efficient example sampling method for example-based word sense disambiguation systems. To construct a database of practical size, a considerable overhead for manual sense disambiguation (overhead for supervision) is required. In addition, the time complexity of searching a large-sized database poses a considerable problem (overhead for search). To counter these problems, our method selectively samples a smaller-sized effective subset from a given example set for use in word sense disambiguation. Our method is characterized by the reliance on the notion of training utility: the degree to which each example is informative for future example sampling when used for the training of the system. The system progressively collects examples by selecting those with greatest utility. The paper reports the effectiveness of our method through experiments on about one thousand sentences. Compared to experiments with other example sampling methods, our method reduced both the overhead for supervision and the overhead for search, without the degeneration of the performance of the system."
W97-0803,Extending a thesaurus by classifying words,1997,15,16,1,1,301,takenobu tokunaga,Automatic Information Extraction and Building of Lexical Semantic Resources for {NLP} Applications,0,None
W97-0807,Integration of Hand-Crafted and Statistical Resources in Measuring Word Similarity,1997,13,5,3,1,37781,atsushi fujii,Automatic Information Extraction and Building of Lexical Semantic Resources for {NLP} Applications,0,None
J97-4006,Book Reviews: The Balancing Act: Combining Symbolic and Statistical Approaches to Language,1997,2,0,1,1,301,takenobu tokunaga,Computational Linguistics,0,None
1997.iwpt-1.16,A New Formalization of Probabilistic {GLR} Parsing,1997,-1,-1,4,0,55795,kentaro unui,Proceedings of the Fifth International Workshop on Parsing Technologies,0,"This paper presents a new formalization of probabilistic GLR language modeling for statistical parsing. Our model inherits its essential features from Briscoe and Carroll{'}s generalized probabilistic LR model, which obtains context-sensitivity by assigning a probability to each LR parsing action according to its left and right context. Briscoe and Carroll{'}s model, however, has a drawback in that it is not formalized in any probabilistically well-founded way, which may degrade its parsing performance. Our formulation overcomes this drawback with a few significant refinements, while maintaining all the advantages of Briscoe and Carroll{'}s modeling."
W96-0105,Selective Sampling of Effective Example Sentence Sets for Word Sense Disambiguation,1996,18,4,3,1,37781,atsushi fujii,Fourth Workshop on Very Large Corpora,0,None
C96-1012,To what extent does case contribute to verb sense disambiguation?,1996,13,7,3,1,37781,atsushi fujii,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"Word sense disambugation has recently been utillized in corpus-based approaches, reflecting the growth in the number of machine readable texts. One category of approaches disambiguates an input verb sense based on the similarity between its governing case fillers and those in given examples. In this paper, we introduce the degree of contribution of case to verb sense disambiguation into this existing method. In this, greater diversity of semantic range of case filler examples will lead to that case contributing to verb sense disambiguation more. We also report the result of a comparative experiment, in which the performance of disambiguation is improved by considering this notion of semantic contribution."
C94-2139,Analysis of {J}apanese Compound Nouns using Collocational Information,1994,9,22,2,0,56453,yosiyuki kobayasi,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"Analyzing compound nouns is one of the crucial issues for natural language processing systems, in particular for those systems that aim at a wide coverage of domains. In this paper, we propose a method to analyze structures of Japanese compound nouns by using both word collocations statistics and a thesaurus. An experiment is conducted with 160,000 word collocations to analyze compound nouns of with an average length of 4.9 characters. The accuracy of this method is about 80%."
A94-1027,A Probabilistic Model for Text Categorization: Based on a Single Random Variable with Multiple Values,1994,17,43,2,0,27879,makoto iwayama,Fourth Conference on Applied Natural Language Processing,0,"Text categorization is the classification of documents with respect to a set of predefined categories. In this paper, we propose a new probabilistic model for text categorization, that is based on a Single random Variable with Multiple Values (SVMV). Compared to previous probabilistic models, our model has the following advantages; 1) it considers within-document term frequencies, 2) considers term weighting for target documents, and 3) is less affected by having insufficient training cases. We verify our model's superiority over the others in the task of categorizing news articles from the Wall Street Journal."
C88-2136,{L}ang{LAB}: A Natural Language Analysis System,1988,11,3,1,1,301,takenobu tokunaga,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper presents a natural language analysis system LangLAB based on BUP-XG which parses with a bottom-up and depth-first strategy and has ability to handle left extraposition. We have already developed a grammar formalism XGS, which is a superset of DCG. With XGS, left extraposition phenomena is naturally expressed in grammar rules. We have also optimized BUP-XG clauses. Experiments showed that in comparison to the original BUP-XG system, the analysis sped up 10 times in the interpreter mode and 4 times in the compiled mode. The TRIE structured dictionary in LangLAB requires less memory, provides faster dictionary reference and also handles complicated idioms with versatility. Consequently, the utilization of LangLAB for practical purposes has become feasible."
