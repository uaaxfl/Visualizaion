W18-2404,Attention-based Semantic Priming for Slot-filling,2018,0,1,2,0,8447,jiewen wu,Proceedings of the Seventh Named Entities Workshop,0,"The problem of sequence labelling in language understanding would benefit from approaches inspired by semantic priming phenomena. We propose that an attention-based RNN architecture can be used to simulate semantic priming for sequence labelling. Specifically, we employ pre-trained word embeddings to characterize the semantic relationship between utterances and labels. We validate the approach using varying sizes of the ATIS and MEDIA datasets, and show up to 1.4-1.9{\%} improvement in F1 score. The developed framework can enable more explainable and generalizable spoken language understanding systems."
W18-2408,{NEWS} 2018 Whitepaper,2018,0,0,4,0,1461,nancy chen,Proceedings of the Seventh Named Entities Workshop,0,"Transliteration is defined as phonetic translation of names across languages. Transliteration of Named Entities (NEs) is necessary in many applications, such as machine translation, corpus alignment, cross-language IR, information extraction and automatic lexicon acquisition. All such systems call for high-performance transliteration, which is the focus of shared task in the NEWS 2018 workshop. The objective of the shared task is to promote machine transliteration research by providing a common benchmarking platform for the community to evaluate the state-of-the-art technologies."
W18-2409,Report of {NEWS} 2018 Named Entity Transliteration Shared Task,2018,0,3,2,0,1461,nancy chen,Proceedings of the Seventh Named Entities Workshop,0,"This report presents the results from the Named Entity Transliteration Shared Task conducted as part of The Seventh Named Entities Workshop (NEWS 2018) held at ACL 2018 in Melbourne, Australia. Similar to previous editions of NEWS, the Shared Task featured 19 tasks on proper name transliteration, including 13 different languages and two different Japanese scripts. A total of 6 teams from 8 different institutions participated in the evaluation, submitting 424 runs, involving different transliteration methodologies. Four performance metrics were used to report the evaluation results. The NEWS shared task on machine transliteration has successfully achieved its objectives by providing a common ground for the research community to conduct comparative evaluations of state-of-the-art technologies that will benefit the future research and development in this area."
W16-2703,Evaluating and Combining Name Entity Recognition Systems,2016,19,17,2,0,19507,ridong jiang,Proceedings of the Sixth Named Entity Workshop,0,"Name entity recognition (NER) is an important subtask in natural language processing. Various NER systems have been developed in the last decade. They may target for different domains, employ different methodologies, work on different languages, detect different types of entities, and support different inputs and output formats. These conditions make it difficult for a user to select the right NER tools for a specific task. Motivated by the need of NER tools in our research work, we select several publicly available and well-established NER tools to validate their outputs against both Wikipedia gold standard corpus and a small set of manually annotated documents. All the evaluations show consistent results on the selected tools. Finally, we constructed a hybrid NER tool by combining the best performing tools for the domains of our interest."
W16-2708,Whitepaper of {NEWS} 2016 Shared Task on Machine Transliteration,2016,1,0,4,1,8136,xiangyu duan,Proceedings of the Sixth Named Entity Workshop,0,None
W16-2709,Report of {NEWS} 2016 Machine Transliteration Shared Task,2016,25,3,2,1,8136,xiangyu duan,Proceedings of the Sixth Named Entity Workshop,0,None
W16-0506,A Report on the Automatic Evaluation of Scientific Writing Shared Task,2016,8,11,2,1,24662,vidas daudaravicius,Proceedings of the 11th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,None
P16-1091,Exploring Convolutional and Recurrent Neural Networks in Sequential Labelling for Dialogue Topic Tracking,2016,30,10,2,1,1451,seokhwan kim,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
D16-2005,Continuous Vector Spaces for Cross-language {NLP} Applications,2016,-1,-1,1,1,28438,rafael banchs,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,0,"The mathematical metaphor offered by the geometric concept of distance in vector spaces with respect to semantics and meaning has been proven to be useful in many monolingual natural language processing applications. There is also some recent and strong evidence that this paradigm can also be useful in the cross-language setting. In this tutorial, we present and discuss some of the most recent advances on exploiting the vector space model paradigm in specific cross-language natural language processing applications, along with a comprehensive review of the theoretical background behind them.First, the tutorial introduces some fundamental concepts of distributional semantics and vector space models. More specifically, the concepts of distributional hypothesis and term-document matrices are revised, followed by a brief discussion on linear and non-linear dimensionality reduction techniques and their implications to the parallel distributed approach to semantic cognition. Next, some classical examples of using vector space models in monolingual natural language processing applications are presented. Specific examples in the areas of information retrieval, related term identification and semantic compositionality are described.Then, the tutorial focuses its attention on the use of the vector space model paradigm in cross-language applications. To this end, some recent examples are presented and discussed in detail, addressing the specific problems of cross-language information retrieval, cross-language sentence matching, and machine translation. Some of the most recent developments in the area of Neural Machine Translation are also discussed.Finally, the tutorial concludes with a discussion about current and future research problems related to the use of vector space models in cross-language settings. Future avenues for scientific research are described, with major emphasis on the extension from vector and matrix representations to tensors, as well as the problem of encoding word position information into the vector-based representations."
W15-4615,Towards Improving Dialogue Topic Tracking Performances with Wikification of Concept Mentions,2015,17,1,2,1,1451,seokhwan kim,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,Dialogue topic tracking aims at analyzing and maintaining topic transitions in on-going dialogues. This paper proposes to utilize Wikification-based features for providing mention-level correspondences to Wikipedia concepts for dialogue topic tracking. The experimental results show that our proposed features can significantly improve the performances of the task in mixed-initiative human-human dialogues.
W15-4106,Automated Simultaneous Interpretation: Hints of a Cognitive Framework for Machine Translation,2015,14,0,1,1,28438,rafael banchs,Proceedings of the Fourth Workshop on Hybrid Approaches to Translation ({H}y{T}ra),0,"This discussion paper presents and analyses the main conceptual differences and similarities between the human task of simultaneous interpretation and the statistical approach to machine translation. A psycho-cognitive model of the simultaneous interpretation process is reviewed and compared with the phrase-based statistical machine translation approach. Some interesting differences are identified and their possible implications on machine translation methods are discussed. Finally, the most relevant research problems related to them are identified."
W15-3901,Whitepaper of {NEWS} 2015 Shared Task on Machine Transliteration,2015,1,6,3,0,3694,min zhang,Proceedings of the Fifth Named Entity Workshop,0,None
W15-3902,Report of {NEWS} 2015 Machine Transliteration Shared Task,2015,30,7,1,1,28438,rafael banchs,Proceedings of the Fifth Named Entity Workshop,0,None
W15-0618,{R}ev{UP}: Automatic Gap-Fill Question Generation from Educational Texts,2015,11,9,2,0,13117,girish kumar,Proceedings of the Tenth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"This paper describes RevUP which deals with automatically generating gap-fill questions. RevUP consists of 3 parts: Sentence Selection, Gap Selection & Multiple Choice Distractor Selection. To select topicallyimportant sentences from texts, we propose a novel sentence ranking method based on topic distributions obtained from topic models. To select gap-phrases from each selected sentence, we collected human annotations, using the Amazon Mechanical Turk, on the relative relevance of candidate gaps. This data is used to train a discriminative classifier to predict the relevance of gaps, achieving an accuracy of 81.0%. Finally, we propose a novel method to choose distractors that are semantically similar to the gap-phrase and have contextual fit to the gap-fill question. By crowdsourcing the evaluation of our method through the Amazon Mechanical Turk, we found that 94% of the distractors selected were good. RevUP fills the semantic gap left open by previous work in this area, and represents a significant step towards automatically generating quality tests for teachers and self-motivated learners."
D15-1265,Wikification of Concept Mentions within Spoken Dialogues Using Domain Constraints from {W}ikipedia,2015,16,0,2,1,1451,seokhwan kim,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"While most previous work on Wikification has focused on written texts, this paper presents a Wikification approach for spoken dialogues. A set of analyzers are proposed to learn dialogue-specific properties along with domain knowledge of conversations from Wikipedia. Then, the analyzed properties are used as constraints for generating candidates, and the candidates are ranked to find the appropriate links. The experimental results show that our proposed approach can significantly improve the performances of the task in human-human dialogues."
W14-4345,Sequential Labeling for Tracking Dynamic Dialog States,2014,17,12,2,1,1451,seokhwan kim,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,This paper presents a sequential labeling approach for tracking the dialog states for the cases of goal changes in a dialog session. The tracking models are trained using linear-chain conditional random fields with the features obtained from the results of SLU. The experimental results show that our proposed approach can improve the performances of the sub-tasks of the second dialog state tracking challenge.
W14-3306,{E}nglish-to-{H}indi system description for {WMT} 2014: Deep Source-Context Features for {M}oses,2014,12,3,4,0.4471,5326,marta costajussa,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the IPN-UPV participation on the English-to-Hindi translation task from WMT 2014 International Evaluation Campaign. The system presented is based on Moses and enhanced with deep learning by means of a source-context feature function. This feature depends on the input sentence to translate, which makes it more challenging to adapt it into the Moses framework. This work reports the experimental details of the system putting special emphasis on: how the feature function is integrated in Moses and how the deep learning representations are trained and used."
W14-1013,A Principled Approach to Context-Aware Machine Translation,2014,11,3,1,1,28438,rafael banchs,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"This paper presents a new principled approach to context-aware machine translation. The proposed approach reformulates the posterior probability of a translation hypothesis given the source input by incorporating the source-context information as an additional conditioning variable. As a result, a new model component, which is referred to as the context-awareness model, is added into the original noisy channel framework. A specific computational implementation for the new model component is also described along with its main properties and limitations."
P14-2004,A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from {W}ikipedia,2014,18,2,2,1,1451,seokhwan kim,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,Dialog topic tracking aims at analyzing and maintaining topic transitions in ongoing dialogs. This paper proposes a composite kernel approach for dialog topic tracking to utilize various types of domain knowledge obtained from Wikipedia. Two kernels are defined based on history sequences and context trees constructed based on the extracted features. The experimental results show that our composite kernel approach can significantly improve the performances of topic tracking in mixed-initiative human-human dialogs.
E14-2009,{CHISPA} on the {GO}: A mobile {C}hinese-{S}panish translation service for travellers in trouble,2014,7,4,3,0,38798,jordi centelles,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,This demo showcases a translation service that allows travelers to have an easy and convenient access to Chinese-Spanish translations via a mobile app. The system integrates a phrase-based translation system with other open source components such as Optical Character Recognition and Automatic Speech Recognition to provide a very friendly user experience.
W13-4023,{AIDA}: Artificial Intelligent Dialogue Agent,2013,5,3,1,1,28438,rafael banchs,Proceedings of the {SIGDIAL} 2013 Conference,0,"This demo paper describes our Artificial Intelligent Dialogue Agent (AIDA), a dialogue management and orchestration platform under development at the Institute for Infocomm Research. Among other features, it integrates different human-computer interaction engines across multiple domains and communication styles such as command, question answering, task-oriented dialogue and chat-oriented dialogue. The platform accepts both speech and text as input modalities by either direct microphone/keyboard connections or by means of mobile device wireless connection. The output interface, which is supported by a talking avatar, integrates speech and text along with other visual aids."
W13-3301,Meaning Unit Segmentation in {E}nglish and {C}hinese: a New Approach to Discourse Phenomena,2013,20,2,2,0,28321,jennifer williams,Proceedings of the Workshop on Discourse in Machine Translation,0,"We present a new approach to dialogue processing in terms of xe2x80x9cmeaning unitsxe2x80x9d. In our annotation task, we asked speakers of English and Chinese to mark boundaries where they could construct the maximal concept using minimal words. We compared English data across genres (news, literature, and policy). We analyzed the agreement for annotators using a state-ofthe-art segmentation similarity algorithm and compared annotations with a random baseline. We found that annotators are able to identify meaning units systematically, even though they may disagree on the quantity and position of units. Our analysis includes an examination of phrase structure for annotated units using constituency parses."
W13-2801,Workshop on Hybrid Approaches to Translation: Overview and Developments,2013,17,6,2,0.474751,5326,marta costajussa,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,"A current increasing trend in machine translation is to combine data-driven and rule-based techniques. Such combinations typically involve the hybridization of different paradigms such as, for instance, the introduction of linguistic knowledge into statistical paradigms, the incorporation of data-driven components into rulebased paradigms, or the pre- and postprocessing of either sort of translation system outputs. Aiming at bringing together researchers and practitioners from the different multidisciplinary areas working in these directions, as well as at creating a brainstorming and discussion venue for Hybrid Translation approaches, the HyTra initiative was born. This paper gives an overview of the Second Workshop on Hybrid Approaches to Translation (HyTra 2013) concerning its motivation, contents and outcomes."
P13-2042,Modeling of term-distance and term-occurrence information for improving n-gram language model performance,2013,20,3,2,0,41414,tze chong,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In this paper, we explore the use of distance and co-occurrence information of word-pairs for language modeling. We attempt to extract this information from history-contexts of up to ten words in size, and found it complements well the n-gram model, which inherently suffers from data scarcity in learning long history-contexts. Evaluated on the WSJ corpus, bigram and trigram model perplexity were reduced up to 23.5% and 14.0%, respectively. Compared to the distant bigram, we show that word-pairs can be more effectively modeled in terms of both distance and occurrence."
W12-0104,An Empirical Evaluation of Stop Word Removal in Statistical Machine Translation,2012,14,4,2,0,41414,tze chong,Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation ({ESIRMT}) and Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"In this paper we evaluate the possibility of improving the performance of a statistical machine translation system by relaxing the complexity of the translation task by removing the most frequent and predictable terms from the target language vocabulary. Afterwards, the removed terms are inserted back in the relaxed output by using an n-gram based word predictor. Empirically, we have found that when these words are omitted from the text, the perplexity of the text decreases, which may imply the reduction of confusion in the text. We conducted some machine translation experiments to see if this perplexity reduction produced a better translation output. While the word prediction results exhibits 77% accuracy in predicting 40% of the most frequent words in the text, the perplexity reduction did not help to produce better translations."
P12-3007,{IRIS}: a Chat-oriented Dialogue System based on the Vector Space Model,2012,16,103,1,1,28438,rafael banchs,Proceedings of the {ACL} 2012 System Demonstrations,0,"This system demonstration paper presents IRIS (Informal Response Interactive System), a chat-oriented dialogue system based on the vector space model framework. The system belongs to the class of example-based dialogue systems and builds its chat capabilities on a dual search strategy over a large collection of dialogue samples. Additional strategies allowing for system adaptation and learning implemented over the same vector model space framework are also described and discussed."
P12-2040,Movie-{D}i{C}: a Movie Dialogue Corpus for Research and Development,2012,12,64,1,1,28438,rafael banchs,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper describes Movie-DiC a Movie Dialogue Corpus recently collected for research and development purposes. The collected dataset comprises 132,229 dialogues containing a total of 764,146 turns that have been extracted from 753 movies. Details on how the data collection has been created and how it is structured are provided along with its main statistics and characteristics."
W11-3207,Comparative Evaluation of {S}panish Segmentation Strategies for {S}panish-{C}hinese Transliteration,2011,29,0,1,1,28438,rafael banchs,Proceedings of the 3rd Named Entities Workshop ({NEWS} 2011),0,"This work presents a comparative evaluation among three different Spanish segmentation strategies for Spanish-Chinese transliteration. The transliteration task is implemented by means of Statistical Machine Translation, using Chinese characters and Spanish sub-word segments as the textual units to be translated. Three different Spanish segmentation strategies are evaluated: character-based, syllabicbased and a proposed sub-syllabic segmentation scheme. Experimental results show that syllabic-based segmentation is the most effective strategy for Spanish-to-Chinese transliteration, while the proposed sub-syllabic segmentation is the most effective scheme in the case of Chinese-to-Spanish transliteration."
W11-2156,The {BM}-{I}2{R} {H}aitian-Cr{\\'e}ole-to-{E}nglish translation system description for the {WMT} 2011 evaluation campaign,2011,7,4,2,0.557518,5326,marta costajussa,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,This work describes the Haitian-Creole to English statistical machine translation system built by Barcelona Media Innovation Center (BM) and Institute for Infocomm Research (I2R) for the 6th Workshop on Statistical Machine Translation (WMT 2011). Our system carefully processes the available data and uses it in a standard phrase-based system enhanced with a source context semantic feature that helps conducting a better lexical selection and a feature orthogonalization procedure that helps making MERT optimization more reliable and stable. Our system was ranked first (among a total of 9 participant systems) by the conducted human evaluation.
W11-1014,A Semantic Feature for Statistical Machine Translation,2011,19,28,1,1,28438,rafael banchs,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"A semantic feature for statistical machine translation, based on Latent Semantic Indexing, is proposed and evaluated. The objective of the proposed feature is to account for the degree of similarity between a given input sentence and each individual sentence in the training dataset. This similarity is computed in a reduced vector-space constructed by means of the Latent Semantic Indexing decomposition. The computed similarity values are used as an additional feature in the log-linear model combination approach to statistical machine translation. In our implementation, the proposed feature is dynamically adjusted for each translation unit in the translation table according to the current input sentence to be translated. This model aims at favoring those translation units that were extracted from training sentences that are semantically related to the current input sentence being translated. Experimental results on a Spanish-to-English translation task on the Bible corpus demonstrate a significant improvement on translation quality with respect to a baseline system."
P11-2027,{AM}-{FM}: A Semantic Framework for Translation Quality Assessment,2011,19,6,1,1,28438,rafael banchs,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"This work introduces AM-FM, a semantic framework for machine translation evaluation. Based upon this framework, a new evaluation metric, which is able to operate without the need for reference translations, is implemented and evaluated. The metric is based on the concepts of adequacy and fluency, which are independently assessed by using a cross-language latent semantic indexing approach and an n-gram based language model approach, respectively. Comparative analyses with conventional evaluation metrics are conducted on two different evaluation tasks (overall quality assessment and comparative ranking) over a large collection of human evaluations involving five European languages. Finally, the main pros and cons of the proposed framework are discussed along with future research directions."
I11-1154,Enhancing scarce-resource language translation through pivot combinations,2011,17,10,3,0.557518,5326,marta costajussa,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Chinese and Spanish are the most spoken languages in the world. However, there is not much research done in machine translation for this language pair. We experiment with the parallel Chinese-Spanish corpus (United Nations) to explore alternatives of SMT strategies which consist on using a pivot language. Particularly, two well-known alternatives are shown for pivoting: the cascade system and the pseudo-corpus. As Pivot language we use English, Arabic and French. Results show that English is the best pivot language between Chinese and Spanish. As a new strategy, we propose to perform a combination of the pivot strategies which is capable to highly outperform the direct translation strategy."
2011.eamt-1.18,Deriving translation units using small additional corpora,2011,18,6,3,1,42253,carlos henriquez,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"We present a novel strategy to derive new translation units using an additional bilingual corpus and a previously trained SMT system. The units were used to adapt the SMT system. The derivation process can be applied when the additional corpus is very small compared with the original train corpus and it does not require to compute new word alignments using all corpora. The strategy is based in the Levenshtein Distance and its resulting path. We reported a statistically significant improvement, with a confidence level of 99%, when adapting an Ngram-based CatalanSpanish system using an additional corpus that represents less than 0.5% of the original train corpus. The additional translation units were able to solve morphological and lexical errors and added previously unknown words to the vocabulary."
2011.eamt-1.20,Deriving translation units using small additional corpora,2011,18,6,3,1,42253,carlos henriquez,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"We present a novel strategy to derive new translation units using an additional bilingual corpus and a previously trained SMT system. The units were used to adapt the SMT system. The derivation process can be applied when the additional corpus is very small compared with the original train corpus and it does not require to compute new word alignments using all corpora. The strategy is based in the Levenshtein Distance and its resulting path. We reported a statistically significant improvement, with a confidence level of 99%, when adapting an Ngram-based CatalanSpanish system using an additional corpus that represents less than 0.5% of the original train corpus. The additional translation units were able to solve morphological and lexical errors and added previously unknown words to the vocabulary."
W10-1712,Using Collocation Segmentation to Augment the Phrase Table,2010,11,9,4,1,42253,carlos henriquez,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the 2010 phrase-based statistical machine translation system developed at the TALP Research Center of the UPC in cooperation with BMIC and VMU. In phrase-based SMT, the phrase table is the main tool in translation. It is created extracting phrases from an aligned parallel corpus and then computing translation model scores with them. Performing a collocation segmentation over the source and target corpus before the alignment causes that different and larger phrases are extracted from the same original documents. We performed this segmentation and used the union of this phrase set with the phrase set extracted from the non-segmented corpus to compute the phrase table. We present the configurations considered and also report results obtained with internal and official test sets."
W10-0718,Opinion Mining of {S}panish Customer Comments with Non-Expert Annotations on {M}echanical {T}urk,2010,7,30,6,0,45520,bart mellebeek,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"One of the major bottlenecks in the development of data-driven AI Systems is the cost of reliable human annotations. The recent advent of several crowdsourcing platforms such as Amazon's Mechanical Turk, allowing requesters the access to affordable and rapid results of a global workforce, greatly facilitates the creation of massive training data. Most of the available studies on the effectiveness of crowdsourcing report on English data. We use Mechanical Turk annotations to train an Opinion Mining System to classify Spanish consumer comments. We design three different Human Intelligence Task (HIT) strategies and report high inter-annotator agreement between non-experts and expert annotators. We evaluate the advantages/drawbacks of each HIT design and show that, in our case, the use of non-expert annotations is a viable and cost-effective alternative to expert annotations."
2010.iwslt-evaluation.7,{I}2{R}{'}s machine translation system for {IWSLT} 2010,2010,0,0,2,0.707898,8136,xiangyu duan,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2010.iwslt-evaluation.26,{UPC}-{BMIC}-{VDU} system description for the {IWSLT} 2010: testing several collocation segmentations in a phrase-based {SMT} system,2010,0,1,4,1,42253,carlos henriquez,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the UPC-BMIC-VMU participation in the IWSLT 2010 evaluation campaign. The SMT system is a standard phrase-based enriched with novel segmentations. These novel segmentations are computed using statistical measures such as Log-likelihood, T-score, Chi-squared, Dice, Mutual Information or Gravity-Counts. The analysis of translation results allows to divide measures into three groups. First, Log-likelihood, Chi-squared and T-score tend to combine high frequency words and collocation segments are very short. They improve the SMT system by adding new translation units. Second, Mutual Information and Dice tend to combine low frequency words and collocation segments are short. They improve the SMT system by smoothing the translation units. And third, GravityCounts tends to combine high and low frequency words and collocation segments are long. However, in this case, the SMT system is not improved. Thus, the road-map for translation system improvement is to introduce new phrases with either low frequency or high frequency words. It is hard to introduce new phrases with low and high frequency words in order to improve translation quality. Experimental results are reported in the French-to-English IWSLT 2010 evaluation where our system was ranked 3rd out of nine systems."
2010.eamt-1.17,Integration of statistical collocation segmentations in a phrase-based statistical machine translation system,2010,15,2,3,0.584521,5326,marta costajussa,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,This study evaluates the impact of integrating two different collocation segmentations methods in a standard phrase-based statistical machine translation approach. The collocation segmentation techniques are implemented simultaneously in the source and target side. Each resulting collocation segmentation is used to extract translation units. Experiments are reported in the English-to-Spanish Bible task and promising results (an improvement over 0.7 BLEU absolute) are achieved in translation quality.
W09-0414,The {TALP}-{UPC} Phrase-Based Translation System for {EACL}-{WMT} 2009,2009,13,3,7,0,5758,jose fonollosa,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"This study presents the TALP-UPC submission to the EACL Fourth Worskhop on Statistical Machine Translation 2009 evaluation campaign. It outlines the architecture and configuration of the 2009 phrase-based statistical machine translation (SMT) system, putting emphasis on the major novelty of this year: combination of SMT systems implementing different word reordering algorithms.n n Traditionally, we have concentrated on the Spanish-to-English and English-to-Spanish News Commentary translation tasks."
2009.iwslt-evaluation.3,{B}arcelona Media {SMT} system description for the {IWSLT} 2009,2009,11,1,2,0.667122,5326,marta costajussa,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the Barcelona Media SMT system in the IWSLT 2009 evaluation campaign. The Barcelona Media system is an statistical phrase-based system enriched with source context information. Adding source context in an SMT system is interesting to enhance the translation in order to solve lexical and structural choice errors. The novel technique uses a similarity metric among each test sentence and each training sentence. First experimental results of this technique are reported in the Arabic and Chinese Basic Traveling Expression Corpus (BTEC) task. Although working in a single domain, there are ambiguities in SMT translation units and slight improvements in BLEU are shown in both tasks (Zh2En and Ar2En)."
W08-0315,The {TALP}-{UPC} {N}gram-Based Statistical Machine Translation System for {ACL}-{WMT} 2008,2008,11,6,9,0.757576,17603,maxim khalilov,Proceedings of the Third Workshop on Statistical Machine Translation,0,"This paper reports on the participation of the TALP Research Center of the UPC (Universitat Politecnica de Catalunya) to the ACL WMT 2008 evaluation campaign.n n This year's system is the evolution of the one we employed for the 2007 campaign. Main updates and extensions involve linguistically motivated word reordering based on the reordering patterns technique. In addition, this system introduces a target language model, based on linguistic classes (Part-of-Speech), morphology reduction for an inflectional language (Spanish) and an improved optimization procedure.n n Results obtained over the development and test sets on Spanish to English (and the other way round) translations for both the traditional Europarl and a challenging News stories tasks are analyzed and commented."
2008.iwslt-evaluation.17,The {TALP}{\\&}{I}2{R} {SMT} systems for {IWSLT} 2008.,2008,19,13,7,0.757576,17603,maxim khalilov,Proceedings of the 5th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper gives a description of the statistical machine translation (SMT) systems developed at the TALP Research Center of the UPC (Universitat Polite`cnica de Catalunya) for our participation in the IWSLT{'}08 evaluation campaign. We present Ngram-based (TALPtuples) and phrase-based (TALPphrases) SMT systems. The paper explains the 2008 systems{'} architecture and outlines translation schemes we have used, mainly focusing on the new techniques that are challenged to improve speech-to-speech translation quality. The novelties we have introduced are: improved reordering method, linear combination of translation and reordering models and new technique dealing with punctuation marks insertion for a phrase-based SMT system. This year we focus on the Arabic-English, Chinese-Spanish and pivot Chinese-(English)-Spanish translation tasks."
2008.eamt-1.15,Word association models and search strategies for discriminative word alignment,2008,11,3,2,1,23604,patrik lambert,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,"This paper deals with core aspects of discriminative word alignment systems, namely basic word association models as well as search strategies. We compare various low-computational-cost word as- sociation models: 2 score, log-likelihood ratio and IBM model 1. We also compare three beam-search strategies. We show that it is more ex- ible and accurate to let links to the same word compete together, than introducing them sequentially in the alignment hypotheses, which is the strategy followed in several systems."
W07-0713,Human Evaluation of Machine Translation Through Binary System Comparisons,2007,17,20,4,0,5800,david vilar,Proceedings of the Second Workshop on Statistical Machine Translation,0,"We introduce a novel evaluation scheme for the human evaluation of different machine translation systems. Our method is based on direct comparison of two sentences at a time by human judges. These binary judgments are then used to decide between all possible rankings of the systems. The advantages of this new method are the lower dependency on extensive evaluation guidelines, and a tighter focus on a typical evaluation task, namely the ranking of systems. Furthermore we argue that machine translation evaluations should be regarded as statistical processes, both for human and automatic evaluation. We show how confidence ranges for state-of-the-art evaluation measures such as WER and TER can be computed accurately and efficiently without having to resort to Monte Carlo estimates. We give an example of our new evaluation scheme, as well as a comparison with classical automatic and human evaluation on data from a recent international evaluation campaign."
W07-0720,Ngram-Based Statistical Machine Translation Enhanced with Multiple Weighted Reordering Hypotheses,2007,7,9,7,0.777778,5326,marta costajussa,Proceedings of the Second Workshop on Statistical Machine Translation,0,"This paper describes the 2007 Ngram-based statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Politecnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the previous years system, being highlyghted and empirically compared. Mainly, these include a novel word ordering strategy based on: (1) statistically monotonizing the training source corpus and (2) a novel reordering approach based on weighted reordering graphs. In addition, this system introduces a target language model based on statistical classes, a feature for out-of-domain units and an improved optimization procedure.n n The paper provides details of this system participation in the ACL 2007 SECOND WORKSHOP ON STATISTICAL MACHINE TRANSLATION. Results on three pairs of languages are reported, namely from Spanish, French and German into English (and the other way round) for both the in-domain and out-of-domain tasks."
N07-2022,Discriminative Alignment Training without Annotated Data for Machine Translation,2007,19,14,2,1,23604,patrik lambert,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"In present Statistical Machine Translation (SMT) systems, alignment is trained in a previous stage as the translation model. Consequently, alignment model parameters are not tuned in function of the translation task, but only indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. In this approach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed."
2007.iwslt-1.26,The {TALP} ngram-based {SMT} system for {IWSLT} 2007,2007,-1,-1,6,1,23604,patrik lambert,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper describes TALPtuples, the 2007 N-gram-based statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Polite`cnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the system of previous years. Mainly, these include optimizing alignment parameters in function of translation metric scores and rescoring with a neural network language model. Results on two translation directions are reported, namely from Arabic and Chinese into English, thoroughly explaining all language-related preprocessing and translation schemes."
W06-3101,Morpho-syntactic Information for Automatic Error Analysis of Statistical Machine Translation Output,2006,16,33,8,0,5059,maja popovic,Proceedings on the Workshop on Statistical Machine Translation,0,"Evaluation of machine translation output is an important but difficult task. Over the last years, a variety of automatic evaluation measures have been studied, some of them like Word Error Rate (WER), Position Independent Word Error Rate (PER) and BLEU and NIST scores have become widely used tools for comparing different systems as well as for evaluating improvements within one system. However, these measures do not give any details about the nature of translation errors. Therefore some analysis of the generated output is needed in order to identify the main problems and to focus the research efforts. On the other hand, human evaluation is a time consuming and expensive task. In this paper, we investigate methods for using of morpho-syntactic information for automatic evaluation: standard error measures WER and PER are calculated on distinct word classes and forms in order to get a better idea about the nature of translation errors and possibilities for improvements."
W06-3120,{TALP} Phrase-based statistical translation system for {E}uropean language pairs,2006,15,9,8,0.777778,5326,marta costajussa,Proceedings on the Workshop on Statistical Machine Translation,0,This paper reports translation results for the Exploiting Parallel Texts for Statistical Machine Translation (HLT-NAACL Workshop on Parallel Texts 2006). We have studied different techniques to improve the standard Phrase-Based translation system. Mainly we introduce two reordering approaches and add morphological information.
W06-3125,N-gram-based {SMT} System Enhanced with Reordering Patterns,2006,13,20,6,0.798611,836,josep crego,Proceedings on the Workshop on Statistical Machine Translation,0,"This work presents translation results for the three data sets made available in the shared task Exploiting Parallel Texts for Statistical Machine Translation of the HLT-NAACL 2006 Workshop on Statistical Machine Translation. All results presented were generated by using the N-gram-based statistical machine translation system which has been enhanced from the last year's evaluation with a tagged target language model (using Part-Of-Speech tags). For both Spanish-English translation directions and the English-to-French translation task, the baseline system allows for linguistically motivated source-side reorderings."
W06-2402,Grouping Multi-word Expressions According to Part-Of-Speech in Statistical Machine Translation,2006,-1,-1,2,1,23604,patrik lambert,Proceedings of the Workshop on Multi-word-expressions in a multilingual context,0,None
banchs-etal-2006-acceptance,Acceptance Testing of a Spoken Language Translation System,2006,10,2,1,1,28438,rafael banchs,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes an acceptance test procedure for evaluating a spoken language translation system between Catalan and Spanish. The procedure consists of two independent tests. The first test was an utterance-oriented evaluation for determining how the use of speech benefits communication. This test allowed for comparing relative performance of the different system components, explicitly: source text to target text, source text to target speech, source speech to target text, and source speech to target speech. The second test was a task-oriented experiment for evaluating if users could achieve some predefined goals for a given task with the state of the technology. Eight subjects familiar with the technology and four subjects not familiar with the technology participated in the tests. From the results we can conclude that state of technology is getting closer to provide effective speech-to-speech translation systems but there is still lot of work to be done in this area. No significant differences in performance between users that are familiar with the technology and users that are not familiar with the technology were evidenced. This constitutes, as far as we know, the first evaluation of a Spoken Translation System that considers performance at both, the utterance level and the task level."
J06-4004,N-gram-based Machine Translation,2006,36,210,2,0.909091,40951,jose marino,Computational Linguistics,0,"This article describes in detail an n-gram approach to statistical machine translation. This approach consists of a log-linear combination of a translation model based on n-grams of bilingual units, which are referred to as tuples, along with four specific feature functions. Translation performance, which happens to be in the state of the art, is demonstrated with Spanish-to-English and English-to-Spanish translations of the European Parliament Plenary Sessions (EPPS)."
2006.iwslt-papers.5,Tuning machine translation parameters with {SPSA},2006,18,11,2,1,23604,patrik lambert,Proceedings of the Third International Workshop on Spoken Language Translation: Papers,0,"Most of statistical machine translation systems are combinations of various models, and tuning of the scaling factors is an important step. However, this optimisation problem is hard because the objective function has many local minima and the available algorithms cannot achieve a global optimum. Consequently, optimisations starting from different initial settings can converge to fairly different solutions. We present tuning experiments with the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm, and compare them to tuning with the widely used downhill simplex method. With IWSLT 2006 Chinese-English data, both methods showed similar performance, but SPSA was more robust to the choice of initial settings."
2006.iwslt-evaluation.17,The {TALP} Ngram-based {SMT} systems for {IWSLT} 2006,2006,37,25,7,0.798611,836,josep crego,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes TALPtuples, the 2006 Ngrambased statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Polit ecnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the system of previous years, being highlighted and empirically compared. Mainly, these include a novel and much more efcient word ordering strategy based on reordering patterns, a linguistically-guided tuple segmentation criterion and improved optimization procedures. The paper provides details of this system participation in the third International Workshop on Spoken Language Translation (IWSLT) held in Kyoto, Japan in November 2006. Results on four translation directions are reported, namely from Arabic, Chinese, Italian and Japanese into English for the open data track, thoroughly explaining all language-related preprocessing and optimization schemes."
2006.iwslt-evaluation.18,{TALP} phrase-based system and {TALP} system combination for {IWSLT} 2006,2006,14,7,8,0.777778,5326,marta costajussa,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the TALP phrase-based statistical machine translation system, enriched with the statistical machine reordering technique. We also report the combination of this system and the TALP-tuple, the n-gram-based statistical machine translation system. We report the results for all the tasks (Chinese, Arabic, Italian and Japanese to English) in the framework of the third evaluation campaign of the International Workshop on Spoken Language Translation."
W05-0823,Statistical Machine Translation of {E}uparl Data by using Bilingual N-grams,2005,10,18,1,1,28438,rafael banchs,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,This work discusses translation results for the four Euparl data sets which were made available for the shared task Exploiting Parallel Texts for Statistical Machine Translation. All results presented were generated by using a statistical machine translation system which implements a log-linear combination of feature functions along with a bilingual n-gram translation model.
2005.mtsummit-posters.11,Data Inferred Multi-word Expressions for Statistical Machine Translation,2005,15,29,2,0,50680,patrick lambert,Proceedings of Machine Translation Summit X: Posters,0,This paper presents a strategy for detecting and using multi-word expressions in Statistical Machine Translation. Performance of the proposed strategy is evaluated in terms of alignment quality as well as translation accuracy. Evaluations are performed by using the Verbmobil corpus. Results from translation tasks from English-to-Spanish and from Spanish-to-English are presented and discussed.
2005.mtsummit-papers.36,Bilingual N-gram Statistical Machine Translation,2005,22,37,2,0,40951,jose marino,Proceedings of Machine Translation Summit X: Papers,0,"This paper describes a statistical machine translation system that uses a translation model which is based on bilingual n-grams. When this translation model is log-linearly combined with four specific feature functions, state of the art translations are achieved for Spanish-to-English and English-to-Spanish translation tasks. Some specific results obtained for the EPPS (European Parliament Plenary Sessions) data are presented and discussed. Finally, future research issues are depicted."
