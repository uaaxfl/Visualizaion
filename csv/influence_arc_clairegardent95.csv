2006.jeptalnrecital-long.11,C94-1042,0,0.082995,"Missing"
2006.jeptalnrecital-long.11,J93-1002,0,\N,Missing
2006.jeptalnrecital-long.12,E03-1030,1,0.908396,"Missing"
2006.jeptalnrecital-long.12,W05-1605,1,0.818314,"Missing"
2006.jeptalnrecital-long.12,W02-2218,0,0.0366425,"Missing"
2006.jeptalnrecital-long.12,C88-2147,0,0.623927,"Missing"
2007.jeptalnrecital-long.16,2005.jeptalnrecital-long.2,1,0.899633,"Missing"
2007.jeptalnrecital-long.16,2006.jeptalnrecital-long.12,1,0.861007,"Missing"
2007.jeptalnrecital-long.16,E03-1030,1,0.882523,"Missing"
2007.jeptalnrecital-long.16,W04-3321,0,0.0310095,"Missing"
2007.jeptalnrecital-long.16,C96-2120,0,0.08343,"Missing"
2007.jeptalnrecital-long.16,P06-1042,0,0.0251892,"Missing"
2007.jeptalnrecital-long.16,C88-2147,0,0.427282,"Missing"
2007.jeptalnrecital-long.31,P91-1027,0,0.259668,"Missing"
2007.jeptalnrecital-long.31,A97-1052,0,0.0978081,"Missing"
2007.jeptalnrecital-long.31,clement-etal-2004-morphology,0,0.0316053,"Missing"
2007.jeptalnrecital-long.31,2006.jeptalnrecital-long.11,1,0.815725,"Missing"
2007.jeptalnrecital-long.31,P93-1032,0,0.0995142,"Missing"
2007.jeptalnrecital-long.31,W04-2104,1,0.890309,"Missing"
2007.jeptalnrecital-poster.7,I05-1015,0,0.0261666,"Missing"
2007.jeptalnrecital-poster.7,2006.jeptalnrecital-long.12,1,0.844182,"Missing"
2007.jeptalnrecital-poster.7,E03-1030,1,0.885534,"Missing"
2007.jeptalnrecital-poster.7,W05-1605,1,0.878951,"Missing"
2007.jeptalnrecital-poster.7,P96-1027,0,0.113011,"Missing"
2007.jeptalnrecital-poster.7,P02-1003,0,0.0268397,"Missing"
2008.jeptalnrecital-long.2,de-marneffe-etal-2006-generating,0,0.030229,"Missing"
2008.jeptalnrecital-long.2,W07-1412,0,0.0359669,"Missing"
2008.jeptalnrecital-long.2,P03-1054,0,0.00747782,"Missing"
2009.jeptalnrecital-long.21,2007.jeptalnrecital-long.17,1,0.824701,"Missing"
2009.jeptalnrecital-long.21,messiant-etal-2008-lexschem,0,\N,Missing
2009.jeptalnrecital-long.21,sagot-etal-2006-lefff,0,\N,Missing
2020.coling-main.55,W17-5526,0,0.0353549,"Missing"
2020.coling-main.55,D19-1508,0,0.0186625,"and Wei-Haas, 1985; El Asri et al., 2017) or crowdsourcing settings where workers provide continuations to incomplete dialogs (Wen et al., 2017). Both approaches are time intensive. Crowdsourcing is also expensive while the humanhuman dialogs that are collected by both approaches may be very different from the human-machine interactions that should be learned to support efficient human-machine communication where typically, chat messages are restricted in length. Other work has relied on already available dialog data or on question/answer pairs extracted from online forums (Wei et al., 2018; Lin et al., 2019; Xu et al., 2019). In the health domain however, such data is extremely scarce and difficult to obtain. When obtainable, it also requires extensive pre-processing due to anonymization constraints. Another line of research has been to acquire data through machine-machine simulations (Xu et al., 2019; Majumdar et al., 2019; Shah et al., 2018). In particular, (Majumdar et al., 2019) combines pre-defined dialog outlines with templatebased verbalizations of dialog turns to automatically create a synthetic dialog corpus. Our work is similar to (Majumdar et al., 2019) but differs from it in two main"
2020.coling-main.55,R19-1081,0,0.0281941,"-machine interactions that should be learned to support efficient human-machine communication where typically, chat messages are restricted in length. Other work has relied on already available dialog data or on question/answer pairs extracted from online forums (Wei et al., 2018; Lin et al., 2019; Xu et al., 2019). In the health domain however, such data is extremely scarce and difficult to obtain. When obtainable, it also requires extensive pre-processing due to anonymization constraints. Another line of research has been to acquire data through machine-machine simulations (Xu et al., 2019; Majumdar et al., 2019; Shah et al., 2018). In particular, (Majumdar et al., 2019) combines pre-defined dialog outlines with templatebased verbalizations of dialog turns to automatically create a synthetic dialog corpus. Our work is similar to (Majumdar et al., 2019) but differs from it in two main ways. First, instead of using templates, we use automatically extracted paraphrases to enrich the initial dialogs. Second we experiment with two dialog models to investigate how domain knowledge (in the form of dialog tree positional information) can best be exploited to guide learning and to support error analysis. 3 Cr"
2020.coling-main.55,P16-1162,0,0.0144745,"Missing"
2020.coling-main.55,N18-3006,0,0.0423303,"Missing"
2020.coling-main.55,E17-1042,0,0.0729652,"Missing"
2020.coling-main.55,P18-1205,0,0.0436655,"sitions sequences that were defined as natural sounding by the expert and that they can deviate from those, learning new ways to conduct the dialog. We leave a detailed exploration of how these deviations could be used to create alternative dialog paths and thereby enrich the model for further research. The Acute-Eval results are more nuanced. While the satisfaction (Table 6) and the interest scores (Table 5) are higher for the generative model, the classification model is found more human sounding, more coherent and is preferred for a long conversation. This is in line with previous results (Zhang et al., 2018; Dinan et al., 2018) where retrieval models (approximated here by our hybrid classification/retrieval model) were found to score very well in dialog level evaluations because they return human-written utterances from the training set and thus do not suffer from decoding mistakes present in generative models. 645 Model: Error Type Correct Child Node Parent Node Same Gd Parent Diff. Leaves In Domain Out of Domain CLASSIF 62.59 4.4 9.53 1.69 15.96 4.28 1.53 GEN 65.86 3.28 10.87 1.31 11.51 6.65 0.26 Human: Model: Human: Model: Human: Model: Table 4: Error Analysis on Predicted Dialog States (GEN"
2020.emnlp-main.231,N19-1388,0,0.0291765,"performance (Dong et al., 2019; Song et al., 2019; Lawrence et al., 2019; Rothe et al., 2019). Finally, multilingual models, where a single model 1 AMR datasets from the LDC can be found at https://amr.isi.edu/download.html 2889 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2889–2901, c November 16–20, 2020. 2020 Association for Computational Linguistics is trained to translate from multiple source languages into multiple target languages, are achieving increasingly better results in machine translation (Johnson et al., 2017; Firat et al., 2017; Aharoni et al., 2019; Arivazhagan et al., 2019). By combining these techniques, we demonstrate that fluent generation is possible for multilingual AMR-to-Text models. We use automatic and human evaluation to assess performance on (1) EU ROPARL data with silver English-centric AMR as input and the 21 EUROPARL languages as target and (2) on LDC 2015E86 data with gold English-centric AMR as input and English, Spanish, Italian, and German as target. Our results demonstrate, for the first time, that it is possible to generate from AMRs into multiple languages. We show that multilingual models have strong performance c"
2020.emnlp-main.231,N19-1253,0,0.028202,"characteristics and vocabulary. First, we analyze the performance of training on languages within a family. Table 6 displays that a model trained on languages within a family has the strongest performance. Second, we analyze languages within the same family. For four families: Romance, Germanic, Uralic, and Slavic, we create multilingual models trained on pairs. One pair is for the most related languages within that family (e.g. Spanish and Portuguese) and another pair is for the farthest languages within that family (e.g. Spanish and Romanian). We determine which pairs are close and far from Ahmad et al. (2019). Results in Figure 5 display that training on pairs of closely related languages has better performance than pairs of less closely related languages, even within a family. Multilingual models could pick up on similarities between languages to improve performance. Semantic Accuracy and Paraphrasing. We ask human evaluators to grade the faithfulness of the hypothesis compared to the reference on a scale of 1 to 3. As shown in Table 3, the overall semantic accuracy is very high (note a score of 2 indicates minor differences). We also asked annotators to 2896 is also influenced by English syntax."
2020.emnlp-main.231,W13-2322,0,0.626433,"ion Generating text from structured data has a variety of applications in natural language processing. Tasks such as decoding from tables (Lebret et al., 2016; Sha et al., 2018), question answering from knowledge bases (Fan et al., 2019a), and generation from RDF Triples (Gardent et al., 2017), knowledge graphs (Marcheggiani and Perez-Beltrachini, 2018) and linguistic meaning representations (Konstas et al., 2017) face similar challenges: interpreting structured input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into twenty one different languages. Claire Gardent CNRS/LORIA Nancy, France cgardent@loria.fr Compared to multilingual translation, decoding from structured input has distinct challenges. Translation models take natural language input and must faithfully decode into natural language output. However, as shown in Zhao et al. (2020), bridging the gap between structured input and linear output is a difficult task. In addition, in structured input such as graphs, the inpu"
2020.emnlp-main.231,D19-6307,0,0.0246635,"e the dependency tree edges are labelled with semantic rather than syntactic relations and where function words have been removed. The participants approaches to this multilingual generation task use gold training data and mostly focus on the shallow track where the input is an unordered lemmatized dependency tree and the generation task reduces to linearization and morphological realization. The models proposed are pipelines that model each of these subtasks and separate models are trained for each target language (Kov´acs et al., 2019; Yu et al., 2019; Shimorina and Gardent, 2019a,b; Castro Ferreira and Krahmer, 2019). In this work, we focus instead on more abstract, deeper, input (AMRs) and propose end-toend, multilingual models for all target languages. Method To generate from AMRs, we use neural sequence to sequence models that model the input AMR with a Transformer Encoder and generate natural language with a Transformer Decoder. For all languages, the input is an English-centric AMR that was derived automatically using the jamr semantic parser from English text. We pre-train both the AMR encoder and the multilingual decoder and we leverage crosslingual embeddings. 3.1 Encoding English AMR Abstract Mea"
2020.emnlp-main.231,P19-4007,0,0.0343866,"Missing"
2020.emnlp-main.231,D18-1269,0,0.0265547,"tions, and generates text into many different languages with varied word order and morphology. As displayed in Figure 2, we use both language model pretraining and crosslingual embeddings to improve decoder quality. Monolingual data from various languages is used to pretrain each language model. Further, we incorporate crosslingual em2891 beddings. These embeddings aim to learn universal representations that encode sentences into shared embedding spaces. Various recent work in crosslingual embeddings (Conneau and Lample, 2019) show strong performance on other multilingual tasks, such as XNLI (Conneau et al., 2018), XTREME (Hu et al., 2020), and MLQA (Lewis et al., 2019b). We use the embeddings from XLM (Conneau and Lample, 2019) to initialize the multilingual embeddings of our decoder. 3.3 Model Training in ten new languages do not have a validation or test set. Thus, for the languages where the standard split is applicable, we report results on the common testing set, splitting it in half for validation and testing. For languages where there is no evaluation set, we take a part of the training set and reserve it for validation and another portion for testing. We use jamr to parse the English text of t"
2020.emnlp-main.231,N18-1104,0,0.245188,"AMR-to-text generation model, we use pairs of English AMR and text in multiple different languages. The English AMR does not need to be aligned to sentences in multiple languages. Instead, we create one AMRto-text corpus for each language and concatenate all of them for training a multilingual model. During the training process, the pretrained AMR encoder and pretrained crosslingual decoder are finetuned on our multilingual AMR-to-text training corpus. Gold AMR We also evaluate our models (trained on silver AMRs) on gold AMR where available. For this, we use the CROSSLINGUAL AMR dataset from Damonte and Cohen (2018)4 .The corpus was constructed by having professional translators translate the English text of the LDC 2015E86 test set into Spanish, Italian, German, and Chinese. We only evaluate on languages where we have training data from EUROPARL (i.e. we do not include Chinese as it is not in EUROPARL). 4 Preprocessing All data remains untokenized and cased. For AMR, we follow Konstas et al. (2017) in processing the jamr output into a simpler form. We remove variable names and instance-of relation ( / ) before every concept. However, we do not anonymize entities or dates, as improvements in modeling hav"
2020.emnlp-main.231,N19-1366,0,0.210188,"use very different methods and generate from English-centric AMRs, not target-language AMRs. 2 3 Related Work AMR-to-Text Generation. Initial work on AMR-to-text generation adapted methods from statistical machine translation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align English with the Portuguese translation to create Portuguese-centric AMRs. However, this work focuses only on one language. In contrast, we consider generation into twenty one languages. Multilingual MR-to-Text Generation. While work on AMR-to-Text generation has m"
2020.emnlp-main.231,N19-1423,0,0.122063,"on AMR-to-text generation has overwhelmingly focused on English. We create training data for multilingual AMR-toText models, by taking the EUROPARL multilingual corpus and automatically annotating the English data with AMRs using the jamr semantic parser. We then use the English AMRs as the input for all generation tasks. To improve quality, we leverage recent advances in natural language processing such as cross-lingual embeddings, pretraining and multilingual learning. Cross-lingual embeddings have shown striking improvements on a range of cross-lingual natural language understanding tasks (Devlin et al., 2019; Conneau et al., 2019; Wu and Dredze, 2019; Pires et al., 2019). Other work has shown that the pre-training and fine-tuning approaches also help improve generation performance (Dong et al., 2019; Song et al., 2019; Lawrence et al., 2019; Rothe et al., 2019). Finally, multilingual models, where a single model 1 AMR datasets from the LDC can be found at https://amr.isi.edu/download.html 2889 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2889–2901, c November 16–20, 2020. 2020 Association for Computational Linguistics is trained to translate from m"
2020.emnlp-main.231,D19-1428,1,0.820322,"that generate in twenty one different languages. For eighteen languages, based on automatic metrics, our multilingual models surpass baselines that generate into a single language. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent. 1 Introduction Generating text from structured data has a variety of applications in natural language processing. Tasks such as decoding from tables (Lebret et al., 2016; Sha et al., 2018), question answering from knowledge bases (Fan et al., 2019a), and generation from RDF Triples (Gardent et al., 2017), knowledge graphs (Marcheggiani and Perez-Beltrachini, 2018) and linguistic meaning representations (Konstas et al., 2017) face similar challenges: interpreting structured input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into twenty one different languages. Claire Gardent CNRS/LORIA Nancy, France cgardent"
2020.emnlp-main.231,P19-1254,1,0.851926,"Missing"
2020.emnlp-main.231,N16-1087,0,0.0604041,"s in language word order and morphological properties, and differences in the set of languages used for training many-to-one models, impact results. We will make code and models available, to aid research in multilingual AMR-to-Text Natural Language Generation. We use very different methods and generate from English-centric AMRs, not target-language AMRs. 2 3 Related Work AMR-to-Text Generation. Initial work on AMR-to-text generation adapted methods from statistical machine translation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align"
2020.emnlp-main.231,W17-3518,1,0.93835,"eighteen languages, based on automatic metrics, our multilingual models surpass baselines that generate into a single language. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent. 1 Introduction Generating text from structured data has a variety of applications in natural language processing. Tasks such as decoding from tables (Lebret et al., 2016; Sha et al., 2018), question answering from knowledge bases (Fan et al., 2019a), and generation from RDF Triples (Gardent et al., 2017), knowledge graphs (Marcheggiani and Perez-Beltrachini, 2018) and linguistic meaning representations (Konstas et al., 2017) face similar challenges: interpreting structured input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into twenty one different languages. Claire Gardent CNRS/LORIA Nancy, France cgardent@loria.fr Compared to multilingual translation, decoding f"
2020.emnlp-main.231,P17-1014,0,0.232145,"age. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent. 1 Introduction Generating text from structured data has a variety of applications in natural language processing. Tasks such as decoding from tables (Lebret et al., 2016; Sha et al., 2018), question answering from knowledge bases (Fan et al., 2019a), and generation from RDF Triples (Gardent et al., 2017), knowledge graphs (Marcheggiani and Perez-Beltrachini, 2018) and linguistic meaning representations (Konstas et al., 2017) face similar challenges: interpreting structured input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into twenty one different languages. Claire Gardent CNRS/LORIA Nancy, France cgardent@loria.fr Compared to multilingual translation, decoding from structured input has distinct challenges. Translation models take natural language input and must faithfully decode int"
2020.emnlp-main.231,D19-6304,0,0.0719237,"Missing"
2020.emnlp-main.231,S17-2096,0,0.0453416,"Missing"
2020.emnlp-main.231,D19-1001,0,0.13554,"amr semantic parser. We then use the English AMRs as the input for all generation tasks. To improve quality, we leverage recent advances in natural language processing such as cross-lingual embeddings, pretraining and multilingual learning. Cross-lingual embeddings have shown striking improvements on a range of cross-lingual natural language understanding tasks (Devlin et al., 2019; Conneau et al., 2019; Wu and Dredze, 2019; Pires et al., 2019). Other work has shown that the pre-training and fine-tuning approaches also help improve generation performance (Dong et al., 2019; Song et al., 2019; Lawrence et al., 2019; Rothe et al., 2019). Finally, multilingual models, where a single model 1 AMR datasets from the LDC can be found at https://amr.isi.edu/download.html 2889 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2889–2901, c November 16–20, 2020. 2020 Association for Computational Linguistics is trained to translate from multiple source languages into multiple target languages, are achieving increasingly better results in machine translation (Johnson et al., 2017; Firat et al., 2017; Aharoni et al., 2019; Arivazhagan et al., 2019). By combining these tech"
2020.emnlp-main.231,D16-1128,0,0.0252152,", pretraining, and multilingual models to create multilingual AMR-to-text models that generate in twenty one different languages. For eighteen languages, based on automatic metrics, our multilingual models surpass baselines that generate into a single language. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent. 1 Introduction Generating text from structured data has a variety of applications in natural language processing. Tasks such as decoding from tables (Lebret et al., 2016; Sha et al., 2018), question answering from knowledge bases (Fan et al., 2019a), and generation from RDF Triples (Gardent et al., 2017), knowledge graphs (Marcheggiani and Perez-Beltrachini, 2018) and linguistic meaning representations (Konstas et al., 2017) face similar challenges: interpreting structured input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into tw"
2020.emnlp-main.231,2020.acl-main.703,0,0.088244,"Missing"
2020.emnlp-main.231,W18-6501,0,0.0232294,"trics, our multilingual models surpass baselines that generate into a single language. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent. 1 Introduction Generating text from structured data has a variety of applications in natural language processing. Tasks such as decoding from tables (Lebret et al., 2016; Sha et al., 2018), question answering from knowledge bases (Fan et al., 2019a), and generation from RDF Triples (Gardent et al., 2017), knowledge graphs (Marcheggiani and Perez-Beltrachini, 2018) and linguistic meaning representations (Konstas et al., 2017) face similar challenges: interpreting structured input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into twenty one different languages. Claire Gardent CNRS/LORIA Nancy, France cgardent@loria.fr Compared to multilingual translation, decoding from structured input has distinct challenges. Translation mod"
2020.emnlp-main.231,W18-3601,0,0.0257039,"datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align English with the Portuguese translation to create Portuguese-centric AMRs. However, this work focuses only on one language. In contrast, we consider generation into twenty one languages. Multilingual MR-to-Text Generation. While work on AMR-to-Text generation has mostly focused on generation into English, the Multilingual Surface Realization shared tasks (Mille et al., 2018, 2019) have made parallel MR/Text datasets available for 11 languages. Two tracks are proposed: a shallow track where the input is an unordered, lemmatized dependency tree and a deep track where the dependency tree edges are labelled with semantic rather than syntactic relations and where function words have been removed. The participants approaches to this multilingual generation task use gold training data and mostly focus on the shallow track where the input is an unordered lemmatized dependency tree and the generation task reduces to linearization and morphological realization. The models"
2020.emnlp-main.231,D19-6301,0,0.0314186,"Missing"
2020.emnlp-main.231,S17-2158,0,0.0597547,"Missing"
2020.emnlp-main.231,N19-4009,1,0.826768,"om each language split of CCNET. Multilingual Data We use EUROPARL, an aligned corpus of European Union parliamentary debates. Each language in EUROPARL is aligned to English. We study the twenty one languages available in EUROPARL: Bulgarian, Czech, Danish, Dutch, English, German, Greek, Spanish, Estonian, Finnish, French, Hungarian, Italian, Lithuanian, Latvian, Polish, Portuguese, Romanian, Slovak, Slovenian, and Swedish. The earliest releases in EUROPARL were prepared with a fixed common testing set across all languages, but later releases 4.2 Models We implement our models in fairseq-py (Ott et al., 2019). We use large Transformer (Vaswani et al., 2017) sequence-to-sequence models and train all models for 50 epochs with LayerDrop (Fan et al., 2019b), which takes around 2 days. We initialize all weights with the pretrained models. When combining crosslingual word embeddings and encoder and decoder pretraining, we initialize all weights 2 https://github.com/facebookresearch/ cc_net 3 https://github.com/jflanigan/jamr 4 To evaluate on this data, please contact Damonte and Cohen (2018) 2892 Model Amount of Data en 8.2M da 1.9M de 1.9M el 1.2M es 1.9M fi 1.9M fr 2M it 1.9M nl 1.9M pt 1.9M sv 1.9M M"
2020.emnlp-main.231,P19-1493,0,0.0259463,"We create training data for multilingual AMR-toText models, by taking the EUROPARL multilingual corpus and automatically annotating the English data with AMRs using the jamr semantic parser. We then use the English AMRs as the input for all generation tasks. To improve quality, we leverage recent advances in natural language processing such as cross-lingual embeddings, pretraining and multilingual learning. Cross-lingual embeddings have shown striking improvements on a range of cross-lingual natural language understanding tasks (Devlin et al., 2019; Conneau et al., 2019; Wu and Dredze, 2019; Pires et al., 2019). Other work has shown that the pre-training and fine-tuning approaches also help improve generation performance (Dong et al., 2019; Song et al., 2019; Lawrence et al., 2019; Rothe et al., 2019). Finally, multilingual models, where a single model 1 AMR datasets from the LDC can be found at https://amr.isi.edu/download.html 2889 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2889–2901, c November 16–20, 2020. 2020 Association for Computational Linguistics is trained to translate from multiple source languages into multiple target languages, are ach"
2020.emnlp-main.231,W18-6319,0,0.0124432,"line. For the latter, we first generate with the AMR-to-English model and then translate the generation output to the target language using MT. Our translation models are Transformer Big models trained with LayerDrop (Fan et al., 2019b) for 100k updates on public benchmark data from WMT where available and supplemented with mined data from the ccMatrix project (Schwenk et al., 2019). We trained translation models for languages where large quantities of aligned bitext data are readily available, and cover a variety of languages. 4.4 Evaluation We evaluate with detokenized BLEU using sacrebleu (Post, 2018). We conduct human evaluation by asking native speakers to evaluate 5 https://github.com/facebookresearch/ m-amr2text Model en es it de Konstas et al. (2017) Song et al. (2018) Cao et al. (2019) Damonte et al. (2019) Guo et al. (2019) Ribeiro et al. (2019) Zhu et al. (2019) 22.0 23.3 23.5 24.4 25.7 24.3 29.7 — — — — — — — — — — — — — — — — — — — — — Machine Translation — 21.6 19.6 15.7 English-XX Seq2Seq 25.2 21.1 19.8 14.9 Multilingual Seq2Seq + Graph Attribute + Crosslingual Embed + AMR Enc Pretrain + Multiling Dec Pretrain + Finetune on Gold AMR 24.2 24.5 24.6 24.7 24.9 26.3 21.0 21.0 21.3"
2020.emnlp-main.231,W16-6603,0,0.0217966,"s. We further investigate how factors, such as differences in the size of the training data, differences in language word order and morphological properties, and differences in the set of languages used for training many-to-one models, impact results. We will make code and models available, to aid research in multilingual AMR-to-Text Natural Language Generation. We use very different methods and generate from English-centric AMRs, not target-language AMRs. 2 3 Related Work AMR-to-Text Generation. Initial work on AMR-to-text generation adapted methods from statistical machine translation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automati"
2020.emnlp-main.231,D19-1314,1,0.868953,"s and generate from English-centric AMRs, not target-language AMRs. 2 3 Related Work AMR-to-Text Generation. Initial work on AMR-to-text generation adapted methods from statistical machine translation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align English with the Portuguese translation to create Portuguese-centric AMRs. However, this work focuses only on one language. In contrast, we consider generation into twenty one languages. Multilingual MR-to-Text Generation. While work on AMR-to-Text generation has mostly focused on gener"
2020.emnlp-main.231,D19-6312,1,0.825937,"d dependency tree and a deep track where the dependency tree edges are labelled with semantic rather than syntactic relations and where function words have been removed. The participants approaches to this multilingual generation task use gold training data and mostly focus on the shallow track where the input is an unordered lemmatized dependency tree and the generation task reduces to linearization and morphological realization. The models proposed are pipelines that model each of these subtasks and separate models are trained for each target language (Kov´acs et al., 2019; Yu et al., 2019; Shimorina and Gardent, 2019a,b; Castro Ferreira and Krahmer, 2019). In this work, we focus instead on more abstract, deeper, input (AMRs) and propose end-toend, multilingual models for all target languages. Method To generate from AMRs, we use neural sequence to sequence models that model the input AMR with a Transformer Encoder and generate natural language with a Transformer Decoder. For all languages, the input is an English-centric AMR that was derived automatically using the jamr semantic parser from English text. We pre-train both the AMR encoder and the multilingual decoder and we leverage crosslingual embeddings"
2020.emnlp-main.231,D19-1305,1,0.797606,"d dependency tree and a deep track where the dependency tree edges are labelled with semantic rather than syntactic relations and where function words have been removed. The participants approaches to this multilingual generation task use gold training data and mostly focus on the shallow track where the input is an unordered lemmatized dependency tree and the generation task reduces to linearization and morphological realization. The models proposed are pipelines that model each of these subtasks and separate models are trained for each target language (Kov´acs et al., 2019; Yu et al., 2019; Shimorina and Gardent, 2019a,b; Castro Ferreira and Krahmer, 2019). In this work, we focus instead on more abstract, deeper, input (AMRs) and propose end-toend, multilingual models for all target languages. Method To generate from AMRs, we use neural sequence to sequence models that model the input AMR with a Transformer Encoder and generate natural language with a Transformer Decoder. For all languages, the input is an English-centric AMR that was derived automatically using the jamr semantic parser from English text. We pre-train both the AMR encoder and the multilingual decoder and we leverage crosslingual embeddings"
2020.emnlp-main.231,D19-6313,0,0.138441,"anslation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align English with the Portuguese translation to create Portuguese-centric AMRs. However, this work focuses only on one language. In contrast, we consider generation into twenty one languages. Multilingual MR-to-Text Generation. While work on AMR-to-Text generation has mostly focused on generation into English, the Multilingual Surface Realization shared tasks (Mille et al., 2018, 2019) have made parallel MR/Text datasets available for 11 languages. Two tracks are proposed: a shall"
2020.emnlp-main.231,P18-1150,0,0.0603745,"glish-centric AMRs, not target-language AMRs. 2 3 Related Work AMR-to-Text Generation. Initial work on AMR-to-text generation adapted methods from statistical machine translation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align English with the Portuguese translation to create Portuguese-centric AMRs. However, this work focuses only on one language. In contrast, we consider generation into twenty one languages. Multilingual MR-to-Text Generation. While work on AMR-to-Text generation has mostly focused on generation into English,"
2020.emnlp-main.231,D19-1077,0,0.0539081,"y focused on English. We create training data for multilingual AMR-toText models, by taking the EUROPARL multilingual corpus and automatically annotating the English data with AMRs using the jamr semantic parser. We then use the English AMRs as the input for all generation tasks. To improve quality, we leverage recent advances in natural language processing such as cross-lingual embeddings, pretraining and multilingual learning. Cross-lingual embeddings have shown striking improvements on a range of cross-lingual natural language understanding tasks (Devlin et al., 2019; Conneau et al., 2019; Wu and Dredze, 2019; Pires et al., 2019). Other work has shown that the pre-training and fine-tuning approaches also help improve generation performance (Dong et al., 2019; Song et al., 2019; Lawrence et al., 2019; Rothe et al., 2019). Finally, multilingual models, where a single model 1 AMR datasets from the LDC can be found at https://amr.isi.edu/download.html 2889 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2889–2901, c November 16–20, 2020. 2020 Association for Computational Linguistics is trained to translate from multiple source languages into multiple targ"
2020.emnlp-main.231,D19-6306,0,0.0241403,"rdered, lemmatized dependency tree and a deep track where the dependency tree edges are labelled with semantic rather than syntactic relations and where function words have been removed. The participants approaches to this multilingual generation task use gold training data and mostly focus on the shallow track where the input is an unordered lemmatized dependency tree and the generation task reduces to linearization and morphological realization. The models proposed are pipelines that model each of these subtasks and separate models are trained for each target language (Kov´acs et al., 2019; Yu et al., 2019; Shimorina and Gardent, 2019a,b; Castro Ferreira and Krahmer, 2019). In this work, we focus instead on more abstract, deeper, input (AMRs) and propose end-toend, multilingual models for all target languages. Method To generate from AMRs, we use neural sequence to sequence models that model the input AMR with a Transformer Encoder and generate natural language with a Transformer Decoder. For all languages, the input is an English-centric AMR that was derived automatically using the jamr semantic parser from English text. We pre-train both the AMR encoder and the multilingual decoder and we lev"
2020.emnlp-main.231,2020.acl-main.224,0,0.0245487,"d input and writing fluent output. We focus on generating from graph structures in the form of Abstract Meaning Representations (AMR) (Banarescu et al., 2013). Previous work has largely focused on generating from AMR into English, but we propose a multilingual approach that can decode into twenty one different languages. Claire Gardent CNRS/LORIA Nancy, France cgardent@loria.fr Compared to multilingual translation, decoding from structured input has distinct challenges. Translation models take natural language input and must faithfully decode into natural language output. However, as shown in Zhao et al. (2020), bridging the gap between structured input and linear output is a difficult task. In addition, in structured input such as graphs, the input is usually semantically under-specified. For example, in AMRs, function words are missing and tense and number are not given. Thus, generation from structured input must bridge the gap between (i) structure and string and (ii) underspecified input and fully specified output. Multilinguality brings a third challenge — that of generating in languages that have varied morphological and word order properties. Annotating natural language with AMR is a complex"
2020.emnlp-main.231,D19-1548,0,0.295372,"not target-language AMRs. 2 3 Related Work AMR-to-Text Generation. Initial work on AMR-to-text generation adapted methods from statistical machine translation (MT) (Pourdamghani et al., 2016), grammar-based generation (Mille et al., 2017), tree-to-string transducers (Flanigan et al., 2016), and inverted semantic parsing (Lampouras and Vlachos, 2017). Neural approaches explored sequence-to-sequence models where the AMR is linearized (Konstas et al., 2017) or modeled with a graph encoder (Marcheggiani and PerezBeltrachini, 2018; Damonte and Cohen, 2019; Ribeiro et al., 2019; Song et al., 2018; Zhu et al., 2019). As professionally-annotated AMR datasets are in English, all this work focuses on English. One exception is the work of Sobrevilla Cabezudo et al. (2019) which uses automatic translation to translate the English text of the LDC AMR data into Brazilian Portuguese and align English with the Portuguese translation to create Portuguese-centric AMRs. However, this work focuses only on one language. In contrast, we consider generation into twenty one languages. Multilingual MR-to-Text Generation. While work on AMR-to-Text generation has mostly focused on generation into English, the Multilingual S"
2020.nl4xai-1.5,P18-1151,0,0.0279074,"ates are lists of ordered triples divided into sentences. Castro Ferreira et al. (2019) first order the input triples in the way they will be expressed and then divides this ordered list into sentences and paragraphs. This ordering of triples and segmentation into sentences is studied with different models : two rulebased baselines (which apply either random selection of triples or most frequent order seen on the training set) and two neural models (GRU and Input structure encoding Some approaches use the structure of the input to constrain the order in which input units are verbalised. Thus, Distiawan et al. (2018) capture the inter and intra RDF triples relationships using a graph-based encoder (GRT-LSTM). It then combines topological sort and breadth-first traversal algorithms to determine in which order the vertices of the GRT-LSTM will be input with data during training thereby performing content planning. Dedicated Attention mechanisms Instead of encoding input structure, some of the approaches use attention mechanisms to make their model focus on specific aspects of the data structure. Sha et al. (2018) take advantage of the information given by table field names and by relations between table fie"
2020.nl4xai-1.5,W18-6505,0,0.332608,"where a template is a sequence of latent variables (transitions) learned by the model on the training data. Decoding (emissions) is then conditioned on both the input and the template latent variables. Intuitively, the approach learns an alignment between input tokens, latent variables and output text segments (cf. Table 2). A key feature of this approach is that this learned alignment can be used both to control (by generating from different templates) and to explain (by examining the mapping between input data and output text mediated by the latent variable) the generation model. Similarly, Gehrmann et al. (2018) develop a mixture of models where each model learns a latent sentence template style based on a subset of the Similarly Shao et al. (2019) decompose text generation into a sequence of sentence generation subtasks where a planning latent variable is learned based on the encoded input data. Using this latent variable, the generation is made hierarchically with a sentence decoder and a word decoder. The plan decoder specifies the content of each output sentence. The sentence decoder also improves highlevel planning of the text. Indeed this model helps capture inter-sentence dependencies in parti"
2020.nl4xai-1.5,W19-8645,0,0.330563,"on unseen data. Zhao et al. (2020) model a plan as a sequence of RDF properties which, before decoding, is enriched with its input subject and object. A Graph Convolutional Network (GCN) encodes the graph input and a Feed Forward Network is used to predict a plan which is then encoded by an LSTM. The LSTM decoder takes as input the hidden states from both encoders. In this approach the document structuring sub-task is tackled by an additional plan encoder. Explicit Content Structuring using Supervised Learning. Other approaches explicitly generate content plans using supervised learning. In (Moryossef et al., 2019b), a text plan is a sequence of sentence plans where each sentence plan is an ordered tree. Linearisation is then given by a pre-order traversal of the sentence trees. The authors adopt an overgenerate-and-rank approach where the text plans are generated using symbolic methods and ranked using a product of expert model integrating different probabilities such as the relation direction probability (e.g. the probability that the triple {A, manager, B} is expressed as “A is the manager of B” or, in reverse order, as “B is managed by A”) or the relation transition probability (which relations are"
2020.nl4xai-1.5,N19-1236,0,0.344474,"on unseen data. Zhao et al. (2020) model a plan as a sequence of RDF properties which, before decoding, is enriched with its input subject and object. A Graph Convolutional Network (GCN) encodes the graph input and a Feed Forward Network is used to predict a plan which is then encoded by an LSTM. The LSTM decoder takes as input the hidden states from both encoders. In this approach the document structuring sub-task is tackled by an additional plan encoder. Explicit Content Structuring using Supervised Learning. Other approaches explicitly generate content plans using supervised learning. In (Moryossef et al., 2019b), a text plan is a sequence of sentence plans where each sentence plan is an ordered tree. Linearisation is then given by a pre-order traversal of the sentence trees. The authors adopt an overgenerate-and-rank approach where the text plans are generated using symbolic methods and ranked using a product of expert model integrating different probabilities such as the relation direction probability (e.g. the probability that the triple {A, manager, B} is expressed as “A is the manager of B” or, in reverse order, as “B is managed by A”) or the relation transition probability (which relations are"
2020.nl4xai-1.5,P17-1099,0,0.0344407,"ty is model analysis such as supported e.g., by the AllenNLP Interpret toolkit (Wallace et al., 2019) which provides two alternative means for interpreting neural models. Gradient-based methods explain a model’s prediction by identifying the importance of input tokens based on the gradient of the loss with respect to the tokens (Simonyan et al., 2014) Lexicalisation Lexicalisation maps input symbols to words. In neural approach, lexicalisation is mostly driven by the decoder which produces a distribution over the next word, from which a lexical choice is made. The copy mechanism introduced by See et al. (2017) is also widely used as it allows copying from the input (Sha et al., 2018; Moryossef et al., 2019b; Laha et al., 2020). At each decoding step, a learned “switch variable” is computed to decide whether the next word should be generated by the S2S model or simply copied from the input. Inspecting the value of the switch variable permits assessing how much lexicalisation tends to copy vs to generate and can provide some explainability in the lexicalisation sub-task. Finally, a few approaches use lexicons and rule-based mapping. In particular, Castro Ferreira et al. (2019) use a rulebased model t"
2020.nl4xai-1.5,D19-1052,0,0.0376709,"Missing"
2020.nl4xai-1.5,P18-1182,0,0.0402737,"Missing"
2020.nl4xai-1.5,2020.acl-main.641,0,0.0185632,"previously selected content is ordered and divided into sentences and paragraphs. The goal of this task is to produce a text plan. Many approaches choose to model document structuring. Four main types of approaches can be distinguished depending on whether the content plan is determined by latent variables, explicit content structuring, based on the input structure or guided by a dedicated attention mechanism. Latent variable approaches have also been proposed for so-called hierarchical approaches where the generation of text segments, generally sentences, is conditioned on a text plan. Thus, Shen et al. (2020) propose a model where, given a set of input records, the model first selects a data record based on a transition probability which takes into account previously selected data records and second, generates tokens based on the word generation probability and attending only to the selected data record. This “strong attention” mechanism allows control of the output structure. It also reduces hallucination by using the constraints that all data records must be used only once. The model automatically learns the optimal content planning by exploring exponentially many segmentation/correspondence pos"
2020.nl4xai-1.5,D19-1054,0,0.254302,"ning Macroplanning is the first subtask of the traditional pre-neural NLG pipeline. It answers the “what to say” question and can be decomposed into selecting and organising the content that should be expressed in the generated text. 2.1 Motivation Content Determination Content determination is the task of selecting information in the input data that should be expressed in the output text. The importance of this subtask depends on the goal of a generation model. In the papers surveyed, papers which verbalise RDF or Meaning Representations (MR) input do not perform content determination, while Shen et al. (2019), who generate headlines from source text, do. In this approach, content selection is viewed as a sequence labelling task where masking binary latent variables are applied to the input. Texts are generated by first sampling from the input to decide which content to cover, then decoding by conditioning on the selected content. The proposed content selector has a ratio of selected tokens that can be adjusted, bringing controllability in the content selection. It should also be noted that in template-based approaches such as (Wiseman et al., 2018), which use templates for text structuring (cf. Se"
2020.nl4xai-1.5,D19-3002,0,0.0274646,"Table 2 which shows examples of latent templates used to generate from the input, latent variables provide a natural means to explain the model’s behaviour i.e., to understand which part of the input licenses which part of the output. They are also domain agnostic and, in contrast to the explicit pipeline models mentioned in the previous paragraph, they do not require the additional creation of labelled data which often relies on complex, domain specific, heuristics. A third alternative way to support explainability is model analysis such as supported e.g., by the AllenNLP Interpret toolkit (Wallace et al., 2019) which provides two alternative means for interpreting neural models. Gradient-based methods explain a model’s prediction by identifying the importance of input tokens based on the gradient of the loss with respect to the tokens (Simonyan et al., 2014) Lexicalisation Lexicalisation maps input symbols to words. In neural approach, lexicalisation is mostly driven by the decoder which produces a distribution over the next word, from which a lexical choice is made. The copy mechanism introduced by See et al. (2017) is also widely used as it allows copying from the input (Sha et al., 2018; Moryosse"
2020.nl4xai-1.5,D18-1356,0,0.356395,"R) input do not perform content determination, while Shen et al. (2019), who generate headlines from source text, do. In this approach, content selection is viewed as a sequence labelling task where masking binary latent variables are applied to the input. Texts are generated by first sampling from the input to decide which content to cover, then decoding by conditioning on the selected content. The proposed content selector has a ratio of selected tokens that can be adjusted, bringing controllability in the content selection. It should also be noted that in template-based approaches such as (Wiseman et al., 2018), which use templates for text structuring (cf. Sec. 2.2), the template choice determines the structure of the output text but also has an influence on the content selection since some templates will not express some of the input information. For instance, the output 2 in The end-to-end encoder-decoder is a popular neural approach that is efficient to generate fluent texts. However it has often been shown to face some adequacy problems such as hallucination, repetition or omission of information. As the end-to-end encoder-decoder approaches are often “black box” approaches, such adequacy probl"
2020.nl4xai-1.5,2020.acl-main.224,0,0.123487,"d attention mechanisms in the sentence decoder. Remark. Learning a template can cover different NLG subtasks at once. For instance Gehrmann et al. (2018) use sentence templates, which determine the order in which the selected content is expressed (document structuring), define aggregation and for some cases encourage the use of referring expressions and of some turns of phrase (usually included in the lexicalisation sub-task) and defines to some extent the surface realization. Transformer). They show that neural models perform better on the seen data but do not generalize well on unseen data. Zhao et al. (2020) model a plan as a sequence of RDF properties which, before decoding, is enriched with its input subject and object. A Graph Convolutional Network (GCN) encodes the graph input and a Feed Forward Network is used to predict a plan which is then encoded by an LSTM. The LSTM decoder takes as input the hidden states from both encoders. In this approach the document structuring sub-task is tackled by an additional plan encoder. Explicit Content Structuring using Supervised Learning. Other approaches explicitly generate content plans using supervised learning. In (Moryossef et al., 2019b), a text pl"
2020.tacl-1.38,P18-1026,0,0.167178,"istical methods (Flanigan et al., 2016; Pourdamghani et al., 2016; Song et al., 2017). Recently, several neural graph-to-text models have exhibited success by leveraging encoder mechanisms based on LSTMs, GNNs, and Transformers. AMR-to-Text Generation. Various neural models have been proposed to generate sentences from Abstract Meaning Representation (AMR) graphs. Konstas et al. (2017) provide the first neural approach for this task, by linearizing the input graph as a sequence of nodes and edges. Song et al. (2018) propose the graph recurrent network to directly encode the AMR nodes, whereas Beck et al. (2018) develop a model based on gated GNNs. 590 However, both approaches only use local node aggregation strategies. Damonte and Cohen (2019) combine graph convolutional networks and LSTMs in order to learn complementary node contexts. However, differently from Transformers and GNNs, LSTMs generate node representations that are influenced by the node order. Ribeiro et al. (2019) develop a model based on different GNNs that learns node representations which simultaneously encode a top–down and a bottom–up views of the AMR graphs, whereas Guo et al. (2019) leverage dense connectivity in GNNs. Recently"
2020.tacl-1.38,D19-1052,0,0.0837704,"Missing"
2020.tacl-1.38,D14-1179,0,0.026513,"Missing"
2020.tacl-1.38,N16-1087,0,0.0487873,"ing distant connections between all nodes, we allow for these missing links to be captured, as KGs are known to be highly incomplete (Dong et al., 2014; Schlichtkrull et al., 2018). In contrast, the local strategy refines the node representation with richer neighborhood information, as nodes that share the same neighborhood exhibit a strong homophily: Two similar entities are much more likely to be connected than at random. Consequently, the local context enriches the node representation with local information 2 Related Work Early efforts for graph-to-text generation used statistical methods (Flanigan et al., 2016; Pourdamghani et al., 2016; Song et al., 2017). Recently, several neural graph-to-text models have exhibited success by leveraging encoder mechanisms based on LSTMs, GNNs, and Transformers. AMR-to-Text Generation. Various neural models have been proposed to generate sentences from Abstract Meaning Representation (AMR) graphs. Konstas et al. (2017) provide the first neural approach for this task, by linearizing the input graph as a sequence of nodes and edges. Song et al. (2018) propose the graph recurrent network to directly encode the AMR nodes, whereas Beck et al. (2018) develop a model bas"
2020.tacl-1.38,D18-1113,1,0.856445,"nerating text from KGs. In comparison to AMRs, which are rooted and connected graphs, KGs do not have a defined topology, which may vary widely among different datasets, making the generation process more demanding. KGs are sparse structures that potentially contain a large number of relations. Moreover, we are typically interested in generating multisentence texts from KGs, and this involves solving document planning issues (Konstas and Lapata, 2013). Recent neural approaches for KG-to-text generation simply linearize the KG triples, thereby loosing graph structure information. For instance, Colin and Gardent (2018), Moryossef et al. (2019), and Adapt (Gardent et al., 2017) utilize LSTM/ GRU to encode WebNLG graphs. Castro Ferreira et al. (2019) systematically compare pipeline and end-to-end models for text generation from WebNLG graphs. Trisedya et al. (2018) develop a graph encoder based on LSTMs that captures relationships within and between triples. Previous work has also studied how to explicitly encode the graph structure using GNNs or Transformers. Marcheggiani and Perez Beltrachini (2018) propose an encoder based on graph convolutional networks, that consider explicitly local node contexts, and s"
2020.tacl-1.38,W17-3518,1,0.256222,"F. R. Ribeiro† , Yue Zhang‡ , Claire Gardent§ and Iryna Gurevych† † Research Training Group AIPHES and UKP Lab, Technische Universit¨at Darmstadt ‡ School of Engineering, Westlake University, § CNRS/LORIA, Nancy, France ribeiro@aiphes.tu-darmstadt.de, yue.zhang@wias.org.cn claire.gardent@loria.fr, gurevych@ukp.informatik.tu-darmstadt.de Abstract be ordered and connected using appropriate discourse markers; and inter-sentential anaphora and ellipsis may need to be generated to avoid repetition. In this paper, we focus on generating texts rather than sentences where the output are short texts (Gardent et al., 2017) or paragraphs (KoncelKedziorski et al., 2019). A key issue in neural graph-to-text generation is how to encode the input graphs. The basic idea is to incrementally compute node representations by aggregating structural context information. To this end, two main approaches have been proposed: (i) models based on local node aggregation, usually built upon Graph Neural Networks (GNNs) (Kipf and Welling, 2017; Hamilton et al., 2017) and (ii) models that leverage global node aggregation. Systems that adopt global encoding strategies are typically based on Transformers (Vaswani et al. 2017), using"
2020.tacl-1.38,N19-1366,0,0.0564672,"Missing"
2020.tacl-1.38,W14-3348,0,0.0087213,"That is, we create a new relation node for each edge relation between two nodes. The new relation node is connected to the subject and object token entities by two binary relations, respectively. seeds, for the test sets, we report the averages over 4 training runs along with their standard deviation. We use byte pair encoding (Sennrich et al., 2016) to split entity words into smaller more frequent pieces. Therefore some nodes in the graph can be sub-words. We also obtain sub-words on the target side. Following previous works, we evaluate the results with BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014), and CHRF++ (Popovi´c, 2015) automatic metrics and also perform a human evaluation (Section 5.6). For layer-wise models, the number of encoder layers are chosen from {2, 4, 6}, and for PGE and CGE, the global and local layers are chosen from and {2, 4, 6} and {1, 2, 3}, respectively. The hidden encoder dimensions are chosen from {256, 384, 448} (see Figure 3). Hyperparameters are tuned on the development set of both datasets. We report the test results when the BLEU score on dev set is optimal. 5 Experiments 5.1 Results on AGENDA We implemented all our models using PyTorch Geometric (PyG) (Fe"
2020.tacl-1.38,P17-4012,0,0.0669681,"Missing"
2020.tacl-1.38,P02-1040,0,0.109526,"n entities (Beck et al., 2018). That is, we create a new relation node for each edge relation between two nodes. The new relation node is connected to the subject and object token entities by two binary relations, respectively. seeds, for the test sets, we report the averages over 4 training runs along with their standard deviation. We use byte pair encoding (Sennrich et al., 2016) to split entity words into smaller more frequent pieces. Therefore some nodes in the graph can be sub-words. We also obtain sub-words on the target side. Following previous works, we evaluate the results with BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014), and CHRF++ (Popovi´c, 2015) automatic metrics and also perform a human evaluation (Section 5.6). For layer-wise models, the number of encoder layers are chosen from {2, 4, 6}, and for PGE and CGE, the global and local layers are chosen from and {2, 4, 6} and {1, 2, 3}, respectively. The hidden encoder dimensions are chosen from {256, 384, 448} (see Figure 3). Hyperparameters are tuned on the development set of both datasets. We report the test results when the BLEU score on dev set is optimal. 5 Experiments 5.1 Results on AGENDA We implemented all our mode"
2020.tacl-1.38,N19-1238,0,0.214575,"Missing"
2020.tacl-1.38,W15-3049,0,0.0541798,"Missing"
2020.tacl-1.38,P17-1014,0,0.167206,"odels that encode an input graph combining both global and local node contexts, in order to learn better contextualized node embeddings. In our experiments, we demonstrate that our approaches lead to significant improvements on two graph-totext datasets achieving BLEU scores of 18.01 on the AGENDA dataset, and 63.69 on the WebNLG dataset for seen categories, outperforming state-of-the-art models by 3.7 and 3.1 points, respectively.1 1 Introduction Graph-to-text generation refers to the task of generating natural language text from input graph structures, which can be semantic representations (Konstas et al., 2017) or knowledge graphs (KGs) (Gardent et al., 2017; Koncel-Kedziorski et al., 2019). Whereas most recent work (Song et al., 2018; Ribeiro et al., 2019; Guo et al., 2019) focuses on generating sentences, a more challenging and interesting scenario emerges when the goal is to generate multisentence texts. In this context, in addition to sentence generation, document planning needs to be handled: The input needs to be mapped into several sentences; sentences need to 1 Code is available at https://github.com/UKPLab/ kg2text. 589 Transactions of the Association for Computational Linguistics, vol. 8,"
2020.tacl-1.38,W16-6603,0,0.0488296,"between all nodes, we allow for these missing links to be captured, as KGs are known to be highly incomplete (Dong et al., 2014; Schlichtkrull et al., 2018). In contrast, the local strategy refines the node representation with richer neighborhood information, as nodes that share the same neighborhood exhibit a strong homophily: Two similar entities are much more likely to be connected than at random. Consequently, the local context enriches the node representation with local information 2 Related Work Early efforts for graph-to-text generation used statistical methods (Flanigan et al., 2016; Pourdamghani et al., 2016; Song et al., 2017). Recently, several neural graph-to-text models have exhibited success by leveraging encoder mechanisms based on LSTMs, GNNs, and Transformers. AMR-to-Text Generation. Various neural models have been proposed to generate sentences from Abstract Meaning Representation (AMR) graphs. Konstas et al. (2017) provide the first neural approach for this task, by linearizing the input graph as a sequence of nodes and edges. Song et al. (2018) propose the graph recurrent network to directly encode the AMR nodes, whereas Beck et al. (2018) develop a model based on gated GNNs. 590 Howev"
2020.tacl-1.38,D13-1157,0,0.0618111,"ransformers, but learn globalized node representations, modeling graph paths in order to capture structural relations. KG-to-Text Generation. In this work, we focus on generating text from KGs. In comparison to AMRs, which are rooted and connected graphs, KGs do not have a defined topology, which may vary widely among different datasets, making the generation process more demanding. KGs are sparse structures that potentially contain a large number of relations. Moreover, we are typically interested in generating multisentence texts from KGs, and this involves solving document planning issues (Konstas and Lapata, 2013). Recent neural approaches for KG-to-text generation simply linearize the KG triples, thereby loosing graph structure information. For instance, Colin and Gardent (2018), Moryossef et al. (2019), and Adapt (Gardent et al., 2017) utilize LSTM/ GRU to encode WebNLG graphs. Castro Ferreira et al. (2019) systematically compare pipeline and end-to-end models for text generation from WebNLG graphs. Trisedya et al. (2018) develop a graph encoder based on LSTMs that captures relationships within and between triples. Previous work has also studied how to explicitly encode the graph structure using GNNs"
2020.tacl-1.38,D19-1314,1,0.905479,"iments, we demonstrate that our approaches lead to significant improvements on two graph-totext datasets achieving BLEU scores of 18.01 on the AGENDA dataset, and 63.69 on the WebNLG dataset for seen categories, outperforming state-of-the-art models by 3.7 and 3.1 points, respectively.1 1 Introduction Graph-to-text generation refers to the task of generating natural language text from input graph structures, which can be semantic representations (Konstas et al., 2017) or knowledge graphs (KGs) (Gardent et al., 2017; Koncel-Kedziorski et al., 2019). Whereas most recent work (Song et al., 2018; Ribeiro et al., 2019; Guo et al., 2019) focuses on generating sentences, a more challenging and interesting scenario emerges when the goal is to generate multisentence texts. In this context, in addition to sentence generation, document planning needs to be handled: The input needs to be mapped into several sentences; sentences need to 1 Code is available at https://github.com/UKPLab/ kg2text. 589 Transactions of the Association for Computational Linguistics, vol. 8, pp. 589–604, 2020. https://doi.org/10.1162/tacl a 00332 Action Editor: Alessandro Moschitti. Submission batch: 2/2019; Revision batch: 5/2020; Publi"
2020.tacl-1.38,W18-6501,0,0.122303,"Missing"
2020.tacl-1.38,P16-1162,0,0.0556469,"osion, we use regularization based on the basis function decomposition to define the model relation weights (Schlichtkrull et al., 2018). Also, as an alternative, we use the Levi Transformation to create nodes from relational edges between entities (Beck et al., 2018). That is, we create a new relation node for each edge relation between two nodes. The new relation node is connected to the subject and object token entities by two binary relations, respectively. seeds, for the test sets, we report the averages over 4 training runs along with their standard deviation. We use byte pair encoding (Sennrich et al., 2016) to split entity words into smaller more frequent pieces. Therefore some nodes in the graph can be sub-words. We also obtain sub-words on the target side. Following previous works, we evaluate the results with BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014), and CHRF++ (Popovi´c, 2015) automatic metrics and also perform a human evaluation (Section 5.6). For layer-wise models, the number of encoder layers are chosen from {2, 4, 6}, and for PGE and CGE, the global and local layers are chosen from and {2, 4, 6} and {1, 2, 3}, respectively. The hidden encoder dimensions are chosen"
2020.tacl-1.38,P16-1000,0,0.208449,"Missing"
2020.tacl-1.38,P17-2002,1,0.873213,"w for these missing links to be captured, as KGs are known to be highly incomplete (Dong et al., 2014; Schlichtkrull et al., 2018). In contrast, the local strategy refines the node representation with richer neighborhood information, as nodes that share the same neighborhood exhibit a strong homophily: Two similar entities are much more likely to be connected than at random. Consequently, the local context enriches the node representation with local information 2 Related Work Early efforts for graph-to-text generation used statistical methods (Flanigan et al., 2016; Pourdamghani et al., 2016; Song et al., 2017). Recently, several neural graph-to-text models have exhibited success by leveraging encoder mechanisms based on LSTMs, GNNs, and Transformers. AMR-to-Text Generation. Various neural models have been proposed to generate sentences from Abstract Meaning Representation (AMR) graphs. Konstas et al. (2017) provide the first neural approach for this task, by linearizing the input graph as a sequence of nodes and edges. Song et al. (2018) propose the graph recurrent network to directly encode the AMR nodes, whereas Beck et al. (2018) develop a model based on gated GNNs. 590 However, both approaches"
2020.tacl-1.38,2020.tacl-1.2,0,0.0329849,"evelop a model based on gated GNNs. 590 However, both approaches only use local node aggregation strategies. Damonte and Cohen (2019) combine graph convolutional networks and LSTMs in order to learn complementary node contexts. However, differently from Transformers and GNNs, LSTMs generate node representations that are influenced by the node order. Ribeiro et al. (2019) develop a model based on different GNNs that learns node representations which simultaneously encode a top–down and a bottom–up views of the AMR graphs, whereas Guo et al. (2019) leverage dense connectivity in GNNs. Recently, Wang et al. (2020) propose a local graph encoder based on Transformers using separated attentions for incoming and outgoing neighbors. Recent methods (Zhu et al., 2019; Cai and Lam, 2020) also use Transformers, but learn globalized node representations, modeling graph paths in order to capture structural relations. KG-to-Text Generation. In this work, we focus on generating text from KGs. In comparison to AMRs, which are rooted and connected graphs, KGs do not have a defined topology, which may vary widely among different datasets, making the generation process more demanding. KGs are sparse structures that pot"
2020.tacl-1.38,P18-1150,1,0.930784,"dings. In our experiments, we demonstrate that our approaches lead to significant improvements on two graph-totext datasets achieving BLEU scores of 18.01 on the AGENDA dataset, and 63.69 on the WebNLG dataset for seen categories, outperforming state-of-the-art models by 3.7 and 3.1 points, respectively.1 1 Introduction Graph-to-text generation refers to the task of generating natural language text from input graph structures, which can be semantic representations (Konstas et al., 2017) or knowledge graphs (KGs) (Gardent et al., 2017; Koncel-Kedziorski et al., 2019). Whereas most recent work (Song et al., 2018; Ribeiro et al., 2019; Guo et al., 2019) focuses on generating sentences, a more challenging and interesting scenario emerges when the goal is to generate multisentence texts. In this context, in addition to sentence generation, document planning needs to be handled: The input needs to be mapped into several sentences; sentences need to 1 Code is available at https://github.com/UKPLab/ kg2text. 589 Transactions of the Association for Computational Linguistics, vol. 8, pp. 589–604, 2020. https://doi.org/10.1162/tacl a 00332 Action Editor: Alessandro Moschitti. Submission batch: 2/2019; Revisio"
2020.tacl-1.38,P18-1151,0,0.287663,"ntially contain a large number of relations. Moreover, we are typically interested in generating multisentence texts from KGs, and this involves solving document planning issues (Konstas and Lapata, 2013). Recent neural approaches for KG-to-text generation simply linearize the KG triples, thereby loosing graph structure information. For instance, Colin and Gardent (2018), Moryossef et al. (2019), and Adapt (Gardent et al., 2017) utilize LSTM/ GRU to encode WebNLG graphs. Castro Ferreira et al. (2019) systematically compare pipeline and end-to-end models for text generation from WebNLG graphs. Trisedya et al. (2018) develop a graph encoder based on LSTMs that captures relationships within and between triples. Previous work has also studied how to explicitly encode the graph structure using GNNs or Transformers. Marcheggiani and Perez Beltrachini (2018) propose an encoder based on graph convolutional networks, that consider explicitly local node contexts, and show superior performance compared with LSTMs. Recently, Koncel-Kedziorski et al. (2019) proposed a Transformer-based approach that computes the node representations by attending over node neighborhoods following a self-attention 591 strategy. In con"
2020.tacl-1.38,P18-1030,1,0.83059,"etter node representations in graph-to-text generation. To this end, existing methods use an artificial global node for message exchange with the other nodes. This strategy can be regarded as extending the graph structure but using similar message passing mechanisms. In particular, Koncel-Kedziorski et al. (2019) add a global node to the graph and use its representation to initialize the decoder. Recently, Guo et al. (2019) and Cai and Lam (2020) also utilized an artificial global node with direct edges to all other nodes to allow global message exchange for AMR-to-text generation. Similarly, Zhang et al. (2018) use a global node to a graph recurrent network model for sentence representation. Different from the above methods, we consider integrating global and local contexts at the node level, rather than the graph level, by investigating model alternatives rather than graph structure changes. In addition, we integrate GAT and Transformer architectures into a unified global-local model. 3 Graph-to-Text Model This section first describes (i) the graph transformation adopted to create a relational graph from the input (Section 3.1), and (ii) the graph encoders of our framework based on GAT (Veliˇckovi´"
2020.tacl-1.38,N19-1236,0,\N,Missing
2020.tacl-1.38,Q19-1019,0,\N,Missing
2020.tacl-1.38,D19-1548,0,\N,Missing
2020.tacl-1.38,2020.acl-main.640,0,\N,Missing
2020.webnlg-1.3,D19-1052,1,0.864153,"Missing"
2020.webnlg-1.3,W05-0909,0,0.0280667,"tion of text generated outputs. ChrF++ has shown a good correlation with human rankings of different MT outputs, especially for morphologically rich target languages. Additionally, it is language- and tokenisation- independent.7 3.2.1.1 N-gram-based metrics BLEU (Papineni et al., 2002) is widely chosen for evaluating text generation outputs due to its low costs. BLEU uses a modified precision metric for comparing the hypotheses with the references. For the sake of comparison, BENG uses two implementations of BLEU: (1) Multi-bleu-detok from Moses,4 (2) BLEU-NLTK from the NLTK library.5 METEOR (Banerjee and Lavie, 2005) relies on semantic features to improve correlation quality between system hypotheses and human references. To this end, METEOR considers the synonymy overlap through a shared WordNet synset of the words to overcome some weaknesses of BLEU and TER (Snover et al., 2006) is different from the aforementioned metrics. TER measures the number of necessary edits in an MT/NLG output to match the reference text exactly. The edits consist of insertions, deletions, substitutions and shift of words, as well as capitalisation and punctuation. The TER score is calculated by computing the number of edits di"
2020.webnlg-1.3,P17-1017,1,0.930658,"g platform GERBIL, is opensource and is publicly available along with the data it contains. 1 Introduction NLG is the process of generating coherent natural language text from non-linguistic data (Reiter and Dale, 2000). A large number of approaches with distinct inputs have been employed for NLG systems over the last years (Gatt and Krahmer, 2018). After having been addressed in only a few papers at the beginning of the last decade (Ell et al., 2012; Ngonga Ngomo et al., 2013), the generation of natural language from Resource Description Framework (RDF) data has gained substantial attention (Gardent et al., 2017b). The RDF-totext task has hence been proposed to investigate the quality of automatically generated texts from RDF Knowledge Graphs (KGs) (Colin et al., 2016; Moussallem et al., 2020). Recent studies have focused on comparing systematically neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples (Ferreira et al., 2019). However, a transparent comparison of RDFbased NLG systems is costly and prone to failure when relying only on benchmarking datasets such as WebNLG without a proper benchmarking platform. Recent works have hence proposed evaluation to"
2020.webnlg-1.3,W11-2832,0,0.0213396,"s service-oriented architecture. We in3.3 Datasets tegrated new experiment types, datasets, and measures. The main advantages of BENG are that it BENG includes the WebNLG datasets for the follows the FAIR Guiding Principles and provides RDF2Text task (refer to Table 2). WebNLG2017 a web-based frontend that allows for several use 9 https://github.com/Tiiiger/bert_score 10 cases enabling lay people and expert users to perhttps://github.com/google-research/ bleurt form informed comparisons of annotation tools. In 30 future work, we plan to include other popular NLG benchmarks such as E2E and SR (Belz et al., 2011; Novikova et al., 2017; Mille et al., 2018) and extend the experiment types as well as include the web-services for models instead of uploading the hypotheses. Emilie Colin, Claire Gardent, Yassine Mrabet, Shashi Narayan, and Laura Perez-Beltrachini. 2016. The webnlg challenge: Generating text from dbpedia data. In Proceedings of the 9th INLG conference, pages 163–167. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of th"
2020.webnlg-1.3,W17-3518,1,0.928991,"g platform GERBIL, is opensource and is publicly available along with the data it contains. 1 Introduction NLG is the process of generating coherent natural language text from non-linguistic data (Reiter and Dale, 2000). A large number of approaches with distinct inputs have been employed for NLG systems over the last years (Gatt and Krahmer, 2018). After having been addressed in only a few papers at the beginning of the last decade (Ell et al., 2012; Ngonga Ngomo et al., 2013), the generation of natural language from Resource Description Framework (RDF) data has gained substantial attention (Gardent et al., 2017b). The RDF-totext task has hence been proposed to investigate the quality of automatically generated texts from RDF Knowledge Graphs (KGs) (Colin et al., 2016; Moussallem et al., 2020). Recent studies have focused on comparing systematically neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples (Ferreira et al., 2019). However, a transparent comparison of RDFbased NLG systems is costly and prone to failure when relying only on benchmarking datasets such as WebNLG without a proper benchmarking platform. Recent works have hence proposed evaluation to"
2020.webnlg-1.3,W18-1817,0,0.0128354,"es, videos, texts) sources and multiple text references to provide a detailed picture of system evaluations. In MT, compare-mt (Neubig et al., 2019) and MT-ComparEval (Klejch et al., 2015) are related tools for comparative analysis with automatic measures that provide a high-level view of major differences between MT outputs. In turn, Vis-Eval Metric Viewer (Steele and Specia, 2018) and iBLEU (Madnani, 2011) present metric scores as a visual interface. Other tools focus on the interpretability of the text generation process and language model parameters such as the OpenNMT visualisation tool (Klein et al., 2018), LM (Rong and Adar, 2016), and Seq2Seq (Strobelt et al., 2019). Although MT and NLG tasks rely on the same metrics for evaluating their outputs, none of the aforementioned tools rely on FAIR principles for the sake of reproducible research. Therefore, BENG is the first evaluation tool that abides by the FAIR principles for the text generation task. 3 Framework BENG addresses the problem of comparing different NLG systems using automatic metric results while relying on FAIR principles. It is based on a service-oriented architecture that reuses components from the FAIR benchmarking platform GER"
2020.webnlg-1.3,W18-6521,1,0.894335,"Missing"
2020.webnlg-1.3,W18-3601,1,0.827371,"Datasets tegrated new experiment types, datasets, and measures. The main advantages of BENG are that it BENG includes the WebNLG datasets for the follows the FAIR Guiding Principles and provides RDF2Text task (refer to Table 2). WebNLG2017 a web-based frontend that allows for several use 9 https://github.com/Tiiiger/bert_score 10 cases enabling lay people and expert users to perhttps://github.com/google-research/ bleurt form informed comparisons of annotation tools. In 30 future work, we plan to include other popular NLG benchmarks such as E2E and SR (Belz et al., 2011; Novikova et al., 2017; Mille et al., 2018) and extend the experiment types as well as include the web-services for models instead of uploading the hypotheses. Emilie Colin, Claire Gardent, Yassine Mrabet, Shashi Narayan, and Laura Perez-Beltrachini. 2016. The webnlg challenge: Generating text from dbpedia data. In Proceedings of the 9th INLG conference, pages 163–167. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:"
2020.webnlg-1.3,2020.acl-main.704,0,0.104713,"upload the candidate triples and reference triples. The results are presented in the generated URI, not in the leaderboard as there is no common dataset. Name 3.2 Automatic Evaluation Metrics Experiment Type Lang. Texts WebNLG2017 RDF2Text EN DE WebNLG2019 RDF2Text RU EN WebNLG2020 RDF2Text/Text2RDF RU Sets T /S D 25,298 9,674 20,370 7,812 7 15 7 15 20,800 5,185 7 45,032 16,677 20,800 5,185 7 19 7 9 9 3.2.1 Metrics for Text Generation BENG includes the most used metrics according to Gatt and Krahmer (2018) and the metrics which correlate better with human evaluations based on recent findings (Sellam et al., 2020). We briefly explain below the automatic evaluation metrics present in BENG. NIST (Doddington, 2002). BENG relies on the latest METEOR version.6 chrF++ (Popovi´c, 2015, 2016) proposes the use of character n-gram precision and recall (F-score) for automatic evaluation of text generated outputs. ChrF++ has shown a good correlation with human rankings of different MT outputs, especially for morphologically rich target languages. Additionally, it is language- and tokenisation- independent.7 3.2.1.1 N-gram-based metrics BLEU (Papineni et al., 2002) is widely chosen for evaluating text generation ou"
2020.webnlg-1.3,2006.amta-papers.25,0,0.0587913,"t al., 2002) is widely chosen for evaluating text generation outputs due to its low costs. BLEU uses a modified precision metric for comparing the hypotheses with the references. For the sake of comparison, BENG uses two implementations of BLEU: (1) Multi-bleu-detok from Moses,4 (2) BLEU-NLTK from the NLTK library.5 METEOR (Banerjee and Lavie, 2005) relies on semantic features to improve correlation quality between system hypotheses and human references. To this end, METEOR considers the synonymy overlap through a shared WordNet synset of the words to overcome some weaknesses of BLEU and TER (Snover et al., 2006) is different from the aforementioned metrics. TER measures the number of necessary edits in an MT/NLG output to match the reference text exactly. The edits consist of insertions, deletions, substitutions and shift of words, as well as capitalisation and punctuation. The TER score is calculated by computing the number of edits divided by the average referenced words.8 6 rb.gy/6q5zsv https://github.com/m-popovic/chrF 8 https://github.com/roy-ht/pyter 4 7 rb.gy/zaffdt 5 https://www.nltk.org/ 29 Figure 2: Screenshot of the Leaderboard - RDF2Text is a semantically varied corpus containing diverse"
2020.webnlg-1.3,N19-4007,0,0.0128991,"s which convert text into a set of RDF triples. The evaluation script uses Precision, Recall, F1-score as metrics. The evaluation algorithm relies on four types of matches (exact, partial, strict, and Enttype3 ) to compare the candidate triples with the reference triples. In the WebNLG Text2RDF experiment type, the users can upload the candidate triples and select the text generation tasks, for example, Machine Translation (MT) or NLG. VizSeq supports multimodal (images, videos, texts) sources and multiple text references to provide a detailed picture of system evaluations. In MT, compare-mt (Neubig et al., 2019) and MT-ComparEval (Klejch et al., 2015) are related tools for comparative analysis with automatic measures that provide a high-level view of major differences between MT outputs. In turn, Vis-Eval Metric Viewer (Steele and Specia, 2018) and iBLEU (Madnani, 2011) present metric scores as a visual interface. Other tools focus on the interpretability of the text generation process and language model parameters such as the OpenNMT visualisation tool (Klein et al., 2018), LM (Rong and Adar, 2016), and Seq2Seq (Strobelt et al., 2019). Although MT and NLG tasks rely on the same metrics for evaluatin"
2020.webnlg-1.3,N18-5015,0,0.011764,"ate triples with the reference triples. In the WebNLG Text2RDF experiment type, the users can upload the candidate triples and select the text generation tasks, for example, Machine Translation (MT) or NLG. VizSeq supports multimodal (images, videos, texts) sources and multiple text references to provide a detailed picture of system evaluations. In MT, compare-mt (Neubig et al., 2019) and MT-ComparEval (Klejch et al., 2015) are related tools for comparative analysis with automatic measures that provide a high-level view of major differences between MT outputs. In turn, Vis-Eval Metric Viewer (Steele and Specia, 2018) and iBLEU (Madnani, 2011) present metric scores as a visual interface. Other tools focus on the interpretability of the text generation process and language model parameters such as the OpenNMT visualisation tool (Klein et al., 2018), LM (Rong and Adar, 2016), and Seq2Seq (Strobelt et al., 2019). Although MT and NLG tasks rely on the same metrics for evaluating their outputs, none of the aforementioned tools rely on FAIR principles for the sake of reproducible research. Therefore, BENG is the first evaluation tool that abides by the FAIR principles for the text generation task. 3 Framework BE"
2020.webnlg-1.3,W17-5525,0,0.0200914,"architecture. We in3.3 Datasets tegrated new experiment types, datasets, and measures. The main advantages of BENG are that it BENG includes the WebNLG datasets for the follows the FAIR Guiding Principles and provides RDF2Text task (refer to Table 2). WebNLG2017 a web-based frontend that allows for several use 9 https://github.com/Tiiiger/bert_score 10 cases enabling lay people and expert users to perhttps://github.com/google-research/ bleurt form informed comparisons of annotation tools. In 30 future work, we plan to include other popular NLG benchmarks such as E2E and SR (Belz et al., 2011; Novikova et al., 2017; Mille et al., 2018) and extend the experiment types as well as include the web-services for models instead of uploading the hypotheses. Emilie Colin, Claire Gardent, Yassine Mrabet, Shashi Narayan, and Laura Perez-Beltrachini. 2016. The webnlg challenge: Generating text from dbpedia data. In Proceedings of the 9th INLG conference, pages 163–167. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Compu"
2020.webnlg-1.3,P02-1040,0,0.107682,"ter with human evaluations based on recent findings (Sellam et al., 2020). We briefly explain below the automatic evaluation metrics present in BENG. NIST (Doddington, 2002). BENG relies on the latest METEOR version.6 chrF++ (Popovi´c, 2015, 2016) proposes the use of character n-gram precision and recall (F-score) for automatic evaluation of text generated outputs. ChrF++ has shown a good correlation with human rankings of different MT outputs, especially for morphologically rich target languages. Additionally, it is language- and tokenisation- independent.7 3.2.1.1 N-gram-based metrics BLEU (Papineni et al., 2002) is widely chosen for evaluating text generation outputs due to its low costs. BLEU uses a modified precision metric for comparing the hypotheses with the references. For the sake of comparison, BENG uses two implementations of BLEU: (1) Multi-bleu-detok from Moses,4 (2) BLEU-NLTK from the NLTK library.5 METEOR (Banerjee and Lavie, 2005) relies on semantic features to improve correlation quality between system hypotheses and human references. To this end, METEOR considers the synonymy overlap through a shared WordNet synset of the words to overcome some weaknesses of BLEU and TER (Snover et al"
2020.webnlg-1.3,W15-3049,0,0.0272179,"Missing"
2020.webnlg-1.3,D19-3043,0,0.0531727,"roposed to investigate the quality of automatically generated texts from RDF Knowledge Graphs (KGs) (Colin et al., 2016; Moussallem et al., 2020). Recent studies have focused on comparing systematically neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples (Ferreira et al., 2019). However, a transparent comparison of RDFbased NLG systems is costly and prone to failure when relying only on benchmarking datasets such as WebNLG without a proper benchmarking platform. Recent works have hence proposed evaluation tools for text generation such as VizSeq (Wang et al., 2019) and MT-ComparEval (Klejch et al., 2015). However, none of these tools abides by the FAIR principles (Wilkinson et al., 2016), which are now widely regarded as a key first step to ensure reproducible research in scientific experiments. Moreover, none of the tools aforementioned involves RDF data for the knowledge (relations and entities) extraction task (KE). In this paper, we address this gap by presenting BENG, a FAIR benchmarking platform for NLG and Knowledge Extraction systems. BENG is available as an online instance with a user-friendly interface that can be freely used by researchers to"
2020.webnlg-1.3,W16-2341,0,0.0850823,"Missing"
2020.webnlg-1.7,2020.webnlg-1.17,0,0.0322949,"ts (Russian native speakers), and they edited delexicalised templates from the data by replacing the texts one more time if needed. RDF subjects and objects with placeholders and Based on this procedure, we assume that the identifying their text counterparts using the JaroRussian data is of a decent quality. However, based Winkler similarlity metrics. on manual inspections, some texts may still be 3.2 Mono-lingual, Mono-task, Neural lacking in terms of fluency and correctness. Note Approaches also that the Russian version was derived from the English WebNLG version 2.0, where some errors med. Blinov (2020) focuses on generation into in semantic content realisation were present. Russian. They used the pre-trained Russian GPT-2 Train 3 Dev Test (D2T) Test (SP) Participating Systems The WebNLG+ data was downloaded more than 100 times, 17 teams submitted 48 system runs. language model (Radford et al., 2019) augmented with a classification head and fine-tuned on the WebNLG+ RDF-to-Russian dataset. The author experimented with various sampling methods and Team med RALI-Universit´e de Montr´eal ORANGE-NLG cuni-ufal TGen bt5 UPC-POE DANGNT-SGU Huawei Noah’s Ark Lab Amazon AI (Shanghai) NILC NUIG-DSI Cy"
2020.webnlg-1.7,W14-3346,0,0.0336319,"Missing"
2020.webnlg-1.7,2020.webnlg-1.19,0,0.0612738,"Missing"
2020.webnlg-1.7,P17-1017,1,0.933665,"(KBs) and natural language. There is a clear parallel between open information extraction (Open IE) and RDF-based semantic parsing, and between RDFto-Text generation and KB verbalisation. Yet the interaction between NLP and Semantic Web research remains limited. By highlighting the NLP tasks involved in mapping RDF triples and natural language, we aim to stimulate cross-fertilisation between NLP and Semantic Web research. WebNLG datasets align sets of RDF triples with text. While the 2017 WebNLG shared task required participating systems to generate English text from a set of DBpedia triples (Gardent et al., 2017b), the 2020 WebNLG+ challenge additionally includes generation into Russian and semantic parsing of English and Russian texts. Thus the WebNLG+ challenge encompasses four tasks: RDF-to-English, RDF-to-Russian, English-to-RDF and Russian-toRDF. Timeline. The training and development data was released on April 15, 2020, preliminary evaluation scripts on April, 30th and final evaluation scripts on May, 30th. The test data was made available on September, 13th and the deadline for submitting system results was September, 27th. Automatic evaluation results were announced on October, 9th and the fi"
2020.webnlg-1.7,W17-3518,1,0.843878,"(KBs) and natural language. There is a clear parallel between open information extraction (Open IE) and RDF-based semantic parsing, and between RDFto-Text generation and KB verbalisation. Yet the interaction between NLP and Semantic Web research remains limited. By highlighting the NLP tasks involved in mapping RDF triples and natural language, we aim to stimulate cross-fertilisation between NLP and Semantic Web research. WebNLG datasets align sets of RDF triples with text. While the 2017 WebNLG shared task required participating systems to generate English text from a set of DBpedia triples (Gardent et al., 2017b), the 2020 WebNLG+ challenge additionally includes generation into Russian and semantic parsing of English and Russian texts. Thus the WebNLG+ challenge encompasses four tasks: RDF-to-English, RDF-to-Russian, English-to-RDF and Russian-toRDF. Timeline. The training and development data was released on April 15, 2020, preliminary evaluation scripts on April, 30th and final evaluation scripts on May, 30th. The test data was made available on September, 13th and the deadline for submitting system results was September, 27th. Automatic evaluation results were announced on October, 9th and the fi"
2020.webnlg-1.7,2020.webnlg-1.8,0,0.302633,"nce. To help bridge the gap between the input graph and the output linear structure, a second phase of pre-training is applied using DocRED, a noisy parallel corpus of sentences and their automatically extracted relation (17K entries). Lexicalisation of RDF properties are also curated from the WebNLG+ and the DocRED datasets. 3.4 Bi-Directional, Monolingual Approaches Amazon AI (Shanghai). Zhao et al. (2020) introduced a two-step model for RDF-to-Text generation which combines a planner trained to learn the order in which triples should be verbalised and a decoder for verbalising each triple. Guo et al. (2020a) train Zhao et al. (2020)’s planner on the WebNLG+ dataset and use the pre-trained T5-large model to verbalise the linearised triples. For the Text-to-RDF task, entity linking is applied to the text and DBpedia is queried to retrieve the corresponding triples. CycleGT. Guo et al. (2020b) present a weakly supervised method where generation and semantic parsing models are learned by bootstrapping from purely text and purely RDF data and iteratively mapping between the two forms. The T5 pre-trained sequence-to-sequence model is used to bootstrap the generation model. For semantic parsing, the a"
2020.webnlg-1.7,2020.webnlg-1.20,0,0.329984,"Missing"
2020.webnlg-1.7,2020.webnlg-1.18,0,0.0265484,"Missing"
2020.webnlg-1.7,2020.webnlg-1.16,0,0.135144,"ion followed the proceIn what follows, we summarise the primary subdure below: missions of the 15 participating teams. 1. Russian WebNLG was translated from the English WebNLG version 2.0 with the MT system 3.1 Monolingual, Mono-Task, of Sennrich et al. (2017), as described in Shimorina Template-based Approaches et al. (2019). Among all system submissions, two of them 2. It was then post-edited using crowdsourcing used templates: RALI-Universit´e de Montr´eal and on the Yandex.Toloka platform in two steps: DANGNT-SGU. • we asked people to post-edit Russian texts RALI-Universit´e de Montr´eal. Lapalme (2020) given original English texts and provided them implements a symbolic approach which captures with some pointers for translation of entities the various substeps of NLG programmatically. (the links described above). Crowdworkers The input set of RDF triples is partitioned and orwere asked to use the pointers as much as dered into sentence sized subsets. Each subset possible. is then transformed into a sentence using Python • given the post-edited sentences, we asked peo- procedures designed to encode 200 manually defined sentence templates. Aggregation is handled ple to check if the text was t"
2020.webnlg-1.7,W07-0734,0,0.720903,"Missing"
2020.webnlg-1.7,2020.acl-main.703,0,0.110317,"Missing"
2020.webnlg-1.7,2020.tacl-1.47,0,0.0691849,"Missing"
2020.webnlg-1.7,W02-0109,0,0.0192729,"Missing"
2020.webnlg-1.7,P14-5010,0,0.00278563,"architect PRED architect COR COR SUB Capers OBJ Super Capers INC PAR MIS SPU INC COR COR INC MIS SPU INC INC COR INC Table 7: Examples of possible error types for semantic parsing, and how these are interpreted by the measures. COR = correct, INC = incorrect, PAR = partial, MIS = missed, SPU = spurious. For development purposes, the evaluation script also provided information about the number of correct, incorrect, partial missed, spurious, possible, and actual matches for the four measures. Baselines. A baseline was constructed by using Stanford CoreNLP’s Open Information Extraction module (Manning et al., 2014) on the texts in the test set. This module allows for the extraction of subjects, relations, and objects in a string without any training necessary. Extraction of these triples was limited to 10 per text, to avoid memory overflow errors when running the evaluation script. As this Open Information Extraction module was only developed for English, the Russian sentences were translated to English using DeepL,7 before extracting the RDF triples using Stanford CoreNLP’s Open Information Extraction module. 5 Results of Automatic Evaluation In this section, we present the automatic scores on English"
2020.webnlg-1.7,W19-8659,1,0.935546,"lcoxon Rank-Sum Test to evaluate whether there is a statistically significant difference between the average evaluation scores of the systems. The result is shown as a system’s rank, which was set measuring the pair-wise statistical tests between the averaged z-score results of a top-performing systems with the results of each of its lowerperforming ones. • We computed final human evaluation results for (i) the whole set of sampled test set outputs per system, (ii) for outputs per each test set type (seen categories, unseen entities, unseen categories). Baselines. We used the FORGe generator (Mille et al., 2019a) as a baseline, an all-purpose grammarand template-based generator that takes predicateargument structures as input. FORGe was adapted to triple-based inputs such as the E2E and several DBpedia-oriented datasets — including WebNLG and WebNLG+ — with the addition of a module for the mapping of RDF to predicate-argument (external module) and a module for aggregation. It consists of 16 graph-transduction grammars that perform the following tasks as a pipeline: (i) aggregation of predicate-argument templates, (ii) definition of sentence structure for each resulting aggregated graph, (iii) introd"
2020.webnlg-1.7,2020.webnlg-1.9,0,0.0276582,"Missing"
2020.webnlg-1.7,P02-1040,0,0.107432,"Missing"
2020.webnlg-1.7,2020.webnlg-1.15,0,0.227841,"Missing"
2020.webnlg-1.7,W17-4770,0,0.177685,"Missing"
2020.webnlg-1.7,2020.acl-demos.14,0,0.0152759,"ao et al. (2020)’s planner on the WebNLG+ dataset and use the pre-trained T5-large model to verbalise the linearised triples. For the Text-to-RDF task, entity linking is applied to the text and DBpedia is queried to retrieve the corresponding triples. CycleGT. Guo et al. (2020b) present a weakly supervised method where generation and semantic parsing models are learned by bootstrapping from purely text and purely RDF data and iteratively mapping between the two forms. The T5 pre-trained sequence-to-sequence model is used to bootstrap the generation model. For semantic parsing, the authors use Qi et al. (2020) entity extraction model to identify all entities present in the input text and a multi-label classifier to predict the relation between pairs of entities. Each input text and each input graph is aligned with its back-translated version and the resulting aligned data for training. The two models are improved by repeatedly alternating the optimisation of each model. The text and the RDF data used to bootstrap the model are the WebNLG+ 2020 dataset, shuffled to ensure that the data is fully non parallel (text and RDF in each of the datasets are not aligned). 3.5 Bi-directional, Bi-lingual Approa"
2020.webnlg-1.7,S13-2056,0,0.0357247,"Missing"
2020.webnlg-1.7,2020.acl-main.704,0,0.155201,"Missing"
2020.webnlg-1.7,W19-3706,1,0.842449,"Missing"
2020.webnlg-1.7,2006.amta-papers.25,0,0.292963,"Missing"
2020.webnlg-1.7,2020.webnlg-1.12,0,0.185192,"Missing"
2020.webnlg-1.7,2020.acl-main.224,0,0.302039,"cketed representations) are compared. Multi-tasking and pipeline architectures are also examined to analyse how different ways of integrating generation with document planning (triples order) impact performance. To help bridge the gap between the input graph and the output linear structure, a second phase of pre-training is applied using DocRED, a noisy parallel corpus of sentences and their automatically extracted relation (17K entries). Lexicalisation of RDF properties are also curated from the WebNLG+ and the DocRED datasets. 3.4 Bi-Directional, Monolingual Approaches Amazon AI (Shanghai). Zhao et al. (2020) introduced a two-step model for RDF-to-Text generation which combines a planner trained to learn the order in which triples should be verbalised and a decoder for verbalising each triple. Guo et al. (2020a) train Zhao et al. (2020)’s planner on the WebNLG+ dataset and use the pre-trained T5-large model to verbalise the linearised triples. For the Text-to-RDF task, entity linking is applied to the text and DBpedia is queried to retrieve the corresponding triples. CycleGT. Guo et al. (2020b) present a weakly supervised method where generation and semantic parsing models are learned by bootstrap"
2020.webnlg-1.7,2020.webnlg-1.22,0,0.0889317,"Missing"
2021.findings-emnlp.132,W05-0909,0,0.382325,"Missing"
2021.findings-emnlp.132,2020.webnlg-1.7,1,0.84159,"Missing"
2021.findings-emnlp.132,W18-6521,0,0.156526,"ects entityevaluation setup. This suggests that in order based semantic adequacy. These metrics rely on an to measure the entity-based adequacy of generalgorithm designed to automatically detect whether ated texts, an automatic metric such as the one proposed here might be more reliable, as less an entity present in the input graph has a corresubjective and more focused on correct verbalisponding mention in the output text. We evaluate sation of the input, than human evaluation meathis algorithm on a corpus of 25,173 (RDF, Text) sures. pairs with manually annotated entity mentions from Castro Ferreira et al. (2018) and show that our al1 Introduction gorithm has a recall of 0.74 and a precision of 0.75. We apply these metrics to the output of 25 RDF With the introduction of pretrained models, the fluency of text generation systems has improved. verbalisers developed for the WebNLG 2017 and However, semantic adequacy (faithfulness to the in- 2020 challenges and show that some of the systems which rank highest in terms of BLEU scores put) remains an unsolved issue. It remains difficult actually rank in the lower half with respect to entityto ensure that the generated text faithfully captures the input (Wis"
2021.findings-emnlp.132,P19-1483,0,0.0228599,"find that the correlation with human scores varies with the specifics of the human evaluation setup. This suggests that our automatic metric might be a more reliable means of identifying models with low entity-based semantic adequacy than human evaluation. We are publicly releasing our source code. 1 captions and computes an F-score over the semantic propositions in the scene graph (Anderson et al., 2016). Similarly, the MEANT metric applies Semantic Role Labelling to generated and reference texts and computes similarity by matching the resulting semantic frames. In data-to-text generation, (Dhingra et al., 2019) uses custom entailment models to determine whether an n-gram in the generated text is entailed by the input and computes an F-score based on these n-grams. In text sum2 Related work marisation, Goodrich et al. (2019) compare relation Various methods have been proposed to evaluate tuples extracted from a ground-truth summary and the semantic adequacy of generated texts. a generated one using either a Named entity RecogCommonly-used metrics are surface-based (ei- nition and a Relation Classifier or an end-to-end ther word- or character-based) such as BLEU (Pa- Transformer model to extract these"
2021.findings-emnlp.132,2020.inlg-1.19,0,0.0309734,"ne graph reference or to human judgments, but with respect encoding the objects and relations present in these to the input. Wiseman et al. (2017) define Re1 lation Generation score as the precision of input https://gitlab.nl4xai.eu/juliette. faille/entity-based-semantic-adequacy relations found in the output texts (the relation ex1531 traction is performed by a neural model). Reed et al. (2018) define information extraction patterns to measure the occurrence of the input attributes and their values in the outputs and compute semantic adequacy using the Slot Error Rate. Ribeiro et al. (2020); Dušek and Kasner (2020) use natural language inference (NLI) to detect two way entailment between the generated text and the input. Sulem et al. (2020) introduce SAMSA which assesses simplification quality by comparing the predicate/argument structures contained in the input with those contained in the output summary. Similarly, we evaluate the semantic adequacy of a generated text by comparing it with the input. We focus on entities however and provide a detailed assessment of both the reliability of our metrics and its correlation with human and with automatic metrics. 3 Defining E-Based Semantic Adequacy We assum"
2021.findings-emnlp.132,P02-1040,0,0.108961,"Missing"
2021.findings-emnlp.132,W15-3049,0,0.03869,"Missing"
2021.findings-emnlp.132,2020.acl-demos.14,0,0.0130607,"he Appendix. 1532 the dictionary was developed by updating it with entities for which no mention was detected in an evaluated text; these were manually included in the dictionary. This dictionary provides a symbolic means to improve entity mention detection and more generally, to adapt the algorithm to a new domain. However, it should be noted that, on the WebNLG 2017 dataset, adding this dictionary only slightly improves entity mention detection and is not essential. Pronominal entity mentions In order to detect which input entity a pronoun refers to, we use two methods. We first use Stanza (Qi et al., 2020) to compute co-reference chains in our texts, keeping only the pronominal mentions. For the pronouns that were not detected by the previous method, we used a simple heuristic. In the WebNLG corpus, RDF graphs are created with a single entity as &quot;root&quot;. Other entities are meant to describe and provide information about this root. As the texts are quite short we assume that most pronominal anaphors refer to the &quot;root&quot; of the graph. We therefore associate all remaining pronouns to the root entity of the RDF graph. Dates We use the python library dateparser to normalise dates both in the text and"
2021.findings-emnlp.132,W18-6535,0,0.0127083,"f propositional content. In comClosest to our approach are metrics which evalputer vision for instance, SPICE transforms both uate the generated output, not with respect to the generated and reference captions into a scene graph reference or to human judgments, but with respect encoding the objects and relations present in these to the input. Wiseman et al. (2017) define Re1 lation Generation score as the precision of input https://gitlab.nl4xai.eu/juliette. faille/entity-based-semantic-adequacy relations found in the output texts (the relation ex1531 traction is performed by a neural model). Reed et al. (2018) define information extraction patterns to measure the occurrence of the input attributes and their values in the outputs and compute semantic adequacy using the Slot Error Rate. Ribeiro et al. (2020); Dušek and Kasner (2020) use natural language inference (NLI) to detect two way entailment between the generated text and the input. Sulem et al. (2020) introduce SAMSA which assesses simplification quality by comparing the predicate/argument structures contained in the input with those contained in the output summary. Similarly, we evaluate the semantic adequacy of a generated text by comparing"
2021.findings-emnlp.132,2020.tacl-1.38,1,0.834984,"nce captions into a scene graph reference or to human judgments, but with respect encoding the objects and relations present in these to the input. Wiseman et al. (2017) define Re1 lation Generation score as the precision of input https://gitlab.nl4xai.eu/juliette. faille/entity-based-semantic-adequacy relations found in the output texts (the relation ex1531 traction is performed by a neural model). Reed et al. (2018) define information extraction patterns to measure the occurrence of the input attributes and their values in the outputs and compute semantic adequacy using the Slot Error Rate. Ribeiro et al. (2020); Dušek and Kasner (2020) use natural language inference (NLI) to detect two way entailment between the generated text and the input. Sulem et al. (2020) introduce SAMSA which assesses simplification quality by comparing the predicate/argument structures contained in the input with those contained in the output summary. Similarly, we evaluate the semantic adequacy of a generated text by comparing it with the input. We focus on entities however and provide a detailed assessment of both the reliability of our metrics and its correlation with human and with automatic metrics. 3 Defining E-Based S"
2021.findings-emnlp.132,2020.acl-main.704,0,0.0246783,"ed (ei- nition and a Relation Classifier or an end-to-end ther word- or character-based) such as BLEU (Pa- Transformer model to extract these tuples. pineni et al., 2002), TER (Snover et al., 2006) or Rather than abstract over the lexical content of chrF (Popovi´c, 2015). As these methods fail to the generated and reference text, other work has account for paraphrases, alternative metrics have focused on developing metrics which model hubeen proposed such as METEOR (Banerjee and man judgement in particular, judgments of semanLavie, 2005), which measures n-gram overlap but tic similarity. Thus Sellam et al. (2020) introduced integrates synonyms and BERTscore, a trained met- BLEURT, an automatic metric pre-trained on synric based on word-embeddings similarity (Zhang* thetic and automatically rated data and fine-tuned et al., 2020). Semantic similarity has also been on human judgments. modeled in terms of propositional content. In comClosest to our approach are metrics which evalputer vision for instance, SPICE transforms both uate the generated output, not with respect to the generated and reference captions into a scene graph reference or to human judgments, but with respect encoding the objects and re"
2021.findings-emnlp.132,2006.amta-papers.25,0,0.157658,"termine whether an n-gram in the generated text is entailed by the input and computes an F-score based on these n-grams. In text sum2 Related work marisation, Goodrich et al. (2019) compare relation Various methods have been proposed to evaluate tuples extracted from a ground-truth summary and the semantic adequacy of generated texts. a generated one using either a Named entity RecogCommonly-used metrics are surface-based (ei- nition and a Relation Classifier or an end-to-end ther word- or character-based) such as BLEU (Pa- Transformer model to extract these tuples. pineni et al., 2002), TER (Snover et al., 2006) or Rather than abstract over the lexical content of chrF (Popovi´c, 2015). As these methods fail to the generated and reference text, other work has account for paraphrases, alternative metrics have focused on developing metrics which model hubeen proposed such as METEOR (Banerjee and man judgement in particular, judgments of semanLavie, 2005), which measures n-gram overlap but tic similarity. Thus Sellam et al. (2020) introduced integrates synonyms and BERTscore, a trained met- BLEURT, an automatic metric pre-trained on synric based on word-embeddings similarity (Zhang* thetic and automatica"
2021.findings-emnlp.132,2020.starsem-1.6,0,0.0373707,"et al. (2017) define Re1 lation Generation score as the precision of input https://gitlab.nl4xai.eu/juliette. faille/entity-based-semantic-adequacy relations found in the output texts (the relation ex1531 traction is performed by a neural model). Reed et al. (2018) define information extraction patterns to measure the occurrence of the input attributes and their values in the outputs and compute semantic adequacy using the Slot Error Rate. Ribeiro et al. (2020); Dušek and Kasner (2020) use natural language inference (NLI) to detect two way entailment between the generated text and the input. Sulem et al. (2020) introduce SAMSA which assesses simplification quality by comparing the predicate/argument structures contained in the input with those contained in the output summary. Similarly, we evaluate the semantic adequacy of a generated text by comparing it with the input. We focus on entities however and provide a detailed assessment of both the reliability of our metrics and its correlation with human and with automatic metrics. 3 Defining E-Based Semantic Adequacy We assume a corpus of (R, T ) instances where R is an RDF graph (a set of RDF triples) and T is a text verbalising that graph. RDF tripl"
2021.findings-emnlp.25,P18-2114,0,0.0194312,"ng a discourse relation but generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, gerund or appositive constructions, discourse-based splitting is licensed by the presence of a discourse relation between two discourse units."
2021.findings-emnlp.25,D19-3009,0,0.0121222,"rse structure in the generated output, we use a combination of metrics. Pipeline Model (PL) A pipeline of two models. The first model is pre-trained BART finetuned on (C, T ) data and the second is a pretrained BART fine-tuned on (T, S) data from DCCNews-S. We report results for pipelines with a C2T component trained on all D-CCNews data Meaning Preservation. We measure meaning preservation using BLEU-4 and SAMSA. We calculate BLEU scores (Papineni et al., 2002) between the ground-truth reference and the generated text using the SacreBLEU library (Post, 2018). We use the EASSE python library (Alva-Manchego et al., 2019) to compute SAMSA scores. SAMSA (Sulem et al., 2018) aims to put more focus on the structural aspects of the text, by leveraging a semantic parser. It observes changes made to predicate-argument structures, and thus for the sentence ""John got home and gave Mary a call."", a higher score will be given to ""John got home. John gave Mary a call."" than for ""John got home and gave. Mary called."". This indicates whether a model actually produces semantically coherent splits irrespective of whether a valid discourse connective and order is used. 5 4 https://huggingface.co/facebook/ bart-base 5 Despite"
2021.findings-emnlp.25,D18-1080,0,0.0756705,"generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, gerund or appositive constructions, discourse-based splitting is licensed by the presence of a discourse relation between two discourse units. Importantly, in the"
2021.findings-emnlp.25,C96-2183,0,0.625414,"corresponding inversion in the linear order of the text. In this paper, we focus on discourse-based sentence splitting and make the following contributions: Sentence splitting segments a sentence into two or more shorter sentences. It is a key component of sentence simplification. It has also been shown to help human comprehension (Mason, 1978; Williams et al., 2003) and to be a useful preprocessing step for several NLP tasks, such as rela1. We create synthetic and organic training data tion extraction (Niklaus et al., 2016) and machine for discourse splitting and investigate varitranslation (Chandrasekar et al., 1996; Mishra et al., ous ways of leveraging this data for training 2014; Li and Nenkova, 2015; Mishra et al., 2014). discourse-based sentence splitting models. There is a large body of work on sentence splitting. It has been studied in the context of many text 2. We compare a discourse-agnostic, end-to-end simplification systems (Siddharthan, 2006; Zhu approach with a pipeline model that uses dis261 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 261–273 November 7–11, 2021. ©2021 Association for Computational Linguistics C1. S1. 3 S2. 3 S3. 7 T C2. S4. C3. S5. The Mas"
2021.findings-emnlp.25,2020.acl-main.703,0,0.0998972,"Missing"
2021.findings-emnlp.25,D15-1148,0,0.0147705,"based sentence splitting and make the following contributions: Sentence splitting segments a sentence into two or more shorter sentences. It is a key component of sentence simplification. It has also been shown to help human comprehension (Mason, 1978; Williams et al., 2003) and to be a useful preprocessing step for several NLP tasks, such as rela1. We create synthetic and organic training data tion extraction (Niklaus et al., 2016) and machine for discourse splitting and investigate varitranslation (Chandrasekar et al., 1996; Mishra et al., ous ways of leveraging this data for training 2014; Li and Nenkova, 2015; Mishra et al., 2014). discourse-based sentence splitting models. There is a large body of work on sentence splitting. It has been studied in the context of many text 2. We compare a discourse-agnostic, end-to-end simplification systems (Siddharthan, 2006; Zhu approach with a pipeline model that uses dis261 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 261–273 November 7–11, 2021. ©2021 Association for Computational Linguistics C1. S1. 3 S2. 3 S3. 7 T C2. S4. C3. S5. The Masovians were caught by surprise, since virtually without any defense the capital, Płock, f"
2021.findings-emnlp.25,W14-5603,0,0.0233267,"ng and make the following contributions: Sentence splitting segments a sentence into two or more shorter sentences. It is a key component of sentence simplification. It has also been shown to help human comprehension (Mason, 1978; Williams et al., 2003) and to be a useful preprocessing step for several NLP tasks, such as rela1. We create synthetic and organic training data tion extraction (Niklaus et al., 2016) and machine for discourse splitting and investigate varitranslation (Chandrasekar et al., 1996; Mishra et al., ous ways of leveraging this data for training 2014; Li and Nenkova, 2015; Mishra et al., 2014). discourse-based sentence splitting models. There is a large body of work on sentence splitting. It has been studied in the context of many text 2. We compare a discourse-agnostic, end-to-end simplification systems (Siddharthan, 2006; Zhu approach with a pipeline model that uses dis261 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 261–273 November 7–11, 2021. ©2021 Association for Computational Linguistics C1. S1. 3 S2. 3 S3. 7 T C2. S4. C3. S5. The Masovians were caught by surprise, since virtually without any defense the capital, Płock, fell and after this Min"
2021.findings-emnlp.25,P14-1041,1,0.824159,"ula river and captured the fortress of Jazdów <EOS> He settled in London, devoting himself chiefly to practical teaching. He settled in London. He devoted himself chiefly to practical teaching. It was a time to go back to nature, and the plastic flamingo quickly became the prototype of bad taste and anti-nature. It was a time to go back to nature. The plastic flamingo quickly became the prototype of bad taste and anti-nature. Table 1: Discourse- (1) vs. Syntax-Based (2) Sentence Splitting course structure to mediate the split. sentence splitting. Probabilistic models have also been proposed. (Narayan and Gardent, 2014) de3. We show that training on discourse-focused termine splitting points using a dedicated probarather than general sentence splitting data bilistic module trained on the Parallel Wikipedia helps to improve performance. corpus annotated with semantic structures while (Narayan and Gardent, 2016) extends this approach 4. To help spur research on discourse-based sento an unsupervised setting where splitting points tence splitting, we make our dataset and code are determined based on the maximum likelihood publicly available. 1 of sequences of thematic role sets present in the simplified version"
2021.findings-emnlp.25,W16-6620,1,0.918952,"rse structure to mediate sentence splitting outperform end-to-end models in learning the various ways of expressing a discourse relation but generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, gerund or appositive construc"
2021.findings-emnlp.25,D17-1064,1,0.925543,"odels which use discourse structure to mediate sentence splitting outperform end-to-end models in learning the various ways of expressing a discourse relation but generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, ge"
2021.findings-emnlp.25,C16-2036,0,0.023039,"t can also use a discourse adverbial with an inverse meaning (Before this) which induces a corresponding inversion in the linear order of the text. In this paper, we focus on discourse-based sentence splitting and make the following contributions: Sentence splitting segments a sentence into two or more shorter sentences. It is a key component of sentence simplification. It has also been shown to help human comprehension (Mason, 1978; Williams et al., 2003) and to be a useful preprocessing step for several NLP tasks, such as rela1. We create synthetic and organic training data tion extraction (Niklaus et al., 2016) and machine for discourse splitting and investigate varitranslation (Chandrasekar et al., 1996; Mishra et al., ous ways of leveraging this data for training 2014; Li and Nenkova, 2015; Mishra et al., 2014). discourse-based sentence splitting models. There is a large body of work on sentence splitting. It has been studied in the context of many text 2. We compare a discourse-agnostic, end-to-end simplification systems (Siddharthan, 2006; Zhu approach with a pipeline model that uses dis261 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 261–273 November 7–11, 2021."
2021.findings-emnlp.25,W19-8662,0,0.0922004,"s less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, gerund or appositive constructions, discourse-based splitting is licensed by the presence of a discourse relation between two discourse units. Importantly, in the case of discourse-base"
2021.findings-emnlp.25,P19-1333,0,0.0522045,"s less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, gerund or appositive constructions, discourse-based splitting is licensed by the presence of a discourse relation between two discourse units. Importantly, in the case of discourse-base"
2021.findings-emnlp.25,W19-8615,0,0.0808148,"s less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sentence coordinations, gerund or appositive constructions, discourse-based splitting is licensed by the presence of a discourse relation between two discourse units. Importantly, in the case of discourse-base"
2021.findings-emnlp.25,P02-1040,0,0.109686,"in terms of sentence order, discourse connnective and rephrasing. To account for such variants while automatically assessing meaning preservation and discourse structure in the generated output, we use a combination of metrics. Pipeline Model (PL) A pipeline of two models. The first model is pre-trained BART finetuned on (C, T ) data and the second is a pretrained BART fine-tuned on (T, S) data from DCCNews-S. We report results for pipelines with a C2T component trained on all D-CCNews data Meaning Preservation. We measure meaning preservation using BLEU-4 and SAMSA. We calculate BLEU scores (Papineni et al., 2002) between the ground-truth reference and the generated text using the SacreBLEU library (Post, 2018). We use the EASSE python library (Alva-Manchego et al., 2019) to compute SAMSA scores. SAMSA (Sulem et al., 2018) aims to put more focus on the structural aspects of the text, by leveraging a semantic parser. It observes changes made to predicate-argument structures, and thus for the sentence ""John got home and gave Mary a call."", a higher score will be given to ""John got home. John gave Mary a call."" than for ""John got home and gave. Mary called."". This indicates whether a model actually produc"
2021.findings-emnlp.25,W18-6319,0,0.0119049,"ally assessing meaning preservation and discourse structure in the generated output, we use a combination of metrics. Pipeline Model (PL) A pipeline of two models. The first model is pre-trained BART finetuned on (C, T ) data and the second is a pretrained BART fine-tuned on (T, S) data from DCCNews-S. We report results for pipelines with a C2T component trained on all D-CCNews data Meaning Preservation. We measure meaning preservation using BLEU-4 and SAMSA. We calculate BLEU scores (Papineni et al., 2002) between the ground-truth reference and the generated text using the SacreBLEU library (Post, 2018). We use the EASSE python library (Alva-Manchego et al., 2019) to compute SAMSA scores. SAMSA (Sulem et al., 2018) aims to put more focus on the structural aspects of the text, by leveraging a semantic parser. It observes changes made to predicate-argument structures, and thus for the sentence ""John got home and gave Mary a call."", a higher score will be given to ""John got home. John gave Mary a call."" than for ""John got home and gave. Mary called."". This indicates whether a model actually produces semantically coherent splits irrespective of whether a valid discourse connective and order is u"
2021.findings-emnlp.25,E14-1076,0,0.01497,"tures. We show that pipeline models which use discourse structure to mediate sentence splitting outperform end-to-end models in learning the various ways of expressing a discourse relation but generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such as relative clauses, VP or sent"
2021.findings-emnlp.25,N18-1063,0,0.0311343,"Missing"
2021.findings-emnlp.25,W03-2317,0,0.560944,"Missing"
2021.findings-emnlp.25,D11-1038,0,0.0391704,"ng different model architectures. We show that pipeline models which use discourse structure to mediate sentence splitting outperform end-to-end models in learning the various ways of expressing a discourse relation but generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting. 1 Introduction Claire Gardent CNRS/LORIA Université de Lorraine claire.gardent@loria.fr et al., 2010; Woodsend and Lapata, 2011; Siddharthan and Mandya, 2014; Narayan et al., 2017; Narayan and Gardent, 2016, 2014) and is the focus of so-called, split-and-rephrase models (Narayan et al., 2017; Aharoni and Goldberg, 2018; Botha et al., 2018; Niklaus et al., 2019b,a,c). So far however, little attention has been paid to how discourse splitting interacts with discourse structure. As illustrated in Table 1, two main types of splitting can be distinguished depending on whether the split is licensed by a syntactic construct or by a discourse connective. Whereas syntax-based splitting is licensed by syntactic constructs such a"
2021.findings-emnlp.25,C10-1152,0,0.104074,"Missing"
2021.nlpmc-1.3,J00-3003,0,0.681885,"Missing"
2021.nlpmc-1.3,W19-8609,0,0.0214069,"on starts randomly with one of the initial questions of M ED B OT. The interaction stops either when all candidates scores are less than 0.1 (cf. Section 3.4) or when the user ends the conversation. For each model, we collect 50 dialogs. Each annotator interacts at most once with a bot. At the end of each human-bot conversation, the annotator is asked to rate satisfaction on a 1-5 Likert scale (a higher score indicates more satisfaction). Assigning a satisfaction score to a single dialog is a highly subjective task however with scores suffering from different bias and variance per annotators (Kulikov et al., 2019). As argued by Li et al. (2019), comparing two dialogs, each produced by different models, and deciding on which dialog is best with respect to a predefined set of questions, helps support a more objective evaluation. We therefore use the Acute-Eval human evaluation framework to compare the dialogs collected using different bots. Since the automatic evaluation (cf. Section 5.1) shows that C OM B OT and M ED B OT are the best systems, we compare only these two systems asking annotators to read pairs of dialogs created by these two bots and to then answer the pre-defined set of questions recomme"
2021.nlpmc-1.3,D18-1432,0,0.0260292,".1) shows that C OM B OT and M ED B OT are the best systems, we compare only these two systems asking annotators to read pairs of dialogs created by these two bots and to then answer the pre-defined set of questions recommended by Li et al. (2019)’s evaluation protocol namely: Automatic Metrics. After collecting dialogues we perform their automatic evaluation. All scores are computed on the 50 bot-human dialogs collected for a given model. Table 3 shows the result scores averaged over 50 dialogs. To measure coherence, we exploit the unsupervised model CoSim introduced by Mesgar et al. (2019); Xu et al. (2018); Zhang et al. (2017). This model measures the coherence of a dialog as the average of the cosine similarities between ConveRT embedding vectors of its adjacent turns. To assess task success, we count the number of unique medical entities (Slots) mentioned. We do this using the clinical NER-model from gthe Stanza library (Zhang et al., 2020) 9 , a model trained on the 2010 i2b2/VA dataset (Uzuner et al., 2011) to extract named entities denoting a medical problem, test or treatment. We report the average number of medical entities both per dialog and in the user turns (to assess how much medica"
2021.nlpmc-1.3,2020.coling-main.55,1,0.905193,"of information units and encouraging domain related user input. • We provide a generic method to create training data for a bot that can follow-up on the user response while remaining in a given domain (in this case the health domain). • We show that such a follow-up bot is crucial to support both information gathering and user 21 Proceedings of the Second Workshop on Natural Language Processing for Medical Conversations, pages 21–29 July 6, 2021. ©2021 Association for Computational Linguistics engagement and we provide a detailed analysis of how the three bots interact. 2 the MedTree Corpus (Liednikova et al., 2020). It is designed to collect information from the user based on a predefined set of questions contained in a questionaire. Related Work Several approaches have explored the use of ensemble models for dialog. While Song et al. (2016) proposed an ensemble model for human-machine dialog which combines a generative and a retrieval model, further ensemble models for dialog have focused on combining agents/bots designed to model different conversation strategies. Yu et al. (2016) focus on open domain conversation and combines three agents, two to improve dialog coherence (ensuring that pronouns can b"
2021.nlpmc-1.3,W16-3649,0,0.0299054,"al Linguistics engagement and we provide a detailed analysis of how the three bots interact. 2 the MedTree Corpus (Liednikova et al., 2020). It is designed to collect information from the user based on a predefined set of questions contained in a questionaire. Related Work Several approaches have explored the use of ensemble models for dialog. While Song et al. (2016) proposed an ensemble model for human-machine dialog which combines a generative and a retrieval model, further ensemble models for dialog have focused on combining agents/bots designed to model different conversation strategies. Yu et al. (2016) focus on open domain conversation and combines three agents, two to improve dialog coherence (ensuring that pronouns can be resolved and maximising semantic similarity with the current context) and one to handle topic switch (moving to a new topic when the retrieval confidence score is low). The ALANA ensemble model (Papaioannou et al., 2017b,a), developed for the Amazon Alexa Challenge i.e., for open domain chitchat, combines domain specific bots used to provide information from different sources with social bots to smooth the interactions (by asking for clarification, expressing personal vi"
2021.nlpmc-1.3,P18-1205,0,0.0307434,"between the remaining selected questions and the questions included in the current dialog context (all preceding dialog turns) and we exclude candidates with similarity score 0.8 or higher. After filtering, the top ranking candidate is selected and the associated follow-up question is output. 3.3 Ensemble Model (ComBot) Empathy Bot As the name suggests, the role of the E MPATHYB OT is to engage the user by showing empathy. For this bot, we use Roller et al. (2020) generative model which was pre-trained on a variant of Reddit discussion (Baumgartner et al., 2020) and finetuned on the ConvAI2 (Zhang et al., 2018), Wizard of Wikipedia (Dinan et al., 2019), Empathetic Dialogues (Rashkin et al., 2019), and Blended Skill Talk datasets (BST) (Smith et al., 2020) to opti6 MMR is a measure for quantifying the extent to which a new item is both dissimilar to those already selected and similar to the target (here a selected question). A λ value of 0.5 favors similarity and diversity equally, both matter equally. 7 https://github.com/connorbrinton/polyaimodels/releases/tag/v1.0 8 https://parl.ai/projects/recipes/ 24 • Who would you prefer to talk to for a long conversation? C OM B OT and M ED B OT. 4.2 Evaluati"
2021.nlpmc-1.3,P19-1534,0,0.0227839,"ialog context (all preceding dialog turns) and we exclude candidates with similarity score 0.8 or higher. After filtering, the top ranking candidate is selected and the associated follow-up question is output. 3.3 Ensemble Model (ComBot) Empathy Bot As the name suggests, the role of the E MPATHYB OT is to engage the user by showing empathy. For this bot, we use Roller et al. (2020) generative model which was pre-trained on a variant of Reddit discussion (Baumgartner et al., 2020) and finetuned on the ConvAI2 (Zhang et al., 2018), Wizard of Wikipedia (Dinan et al., 2019), Empathetic Dialogues (Rashkin et al., 2019), and Blended Skill Talk datasets (BST) (Smith et al., 2020) to opti6 MMR is a measure for quantifying the extent to which a new item is both dissimilar to those already selected and similar to the target (here a selected question). A λ value of 0.5 favors similarity and diversity equally, both matter equally. 7 https://github.com/connorbrinton/polyaimodels/releases/tag/v1.0 8 https://parl.ai/projects/recipes/ 24 • Who would you prefer to talk to for a long conversation? C OM B OT and M ED B OT. 4.2 Evaluation • If you had to say one of the speakers is interesting and one is boring, who would"
2021.tacl-1.6,W18-2706,1,0.923182,"ut a specific movie, it can be helpful to provide the model with more information about that movie so a more interesting dialog response could be produced. To incorporate knowledge, models often concatenate a knowledge source E such as Wikipedia to xi and use attention modules to identify the most relevant knowledge. However, this approach is computationally intensive when handling large quantities of information. Further, attention mechanisms have been found to operate poorly over long sequences, as the mechanism becomes blurry due to the softmax and struggles to make fine-grained decisions (Fan et al., 2018b). The same is true for hierarchical approaches, which lack scalability. We augment Transformer sequence to sequence (seq2seq) networks on the encoder side with KIF to improve generative dialog models. We experiment on two dialog tasks, Wizard of Wikipedia (Dinan et al., 2018) and Engaging ImageChat (Shuster et al., 2020). In both datasets, models must leverage information external to the dialog history alone—in Wizard of Wikipedia, the chat requires access to knowledgeable facts and in Engaging ImageChat, discussion about a specific image. As models must process multiple inputs and ground re"
2021.tacl-1.6,D19-1195,0,0.0143837,"nformation to be interpreted as each memory slot is an explicit fact that can be read as text, rather than a learned vector such as in Lample et al. (2019). Work has also focused on computationally efficient softmax operations (Mnih and Hinton, 2009; Grave et al., 2017a; Chen et al., 2016). Many approximate softmax techniques use KNNlike operations to form clusters, and the overall softmax operation is constrained by the slow calculation of the exponential. Our usage of KNN benefits from efficient and scalable libraries such as faiss and nmslib. model (Dinan et al., 2018; Weston et al., 2018; Cai et al., 2019; Zhu et al., 2020). Some of this work has specialized to use both types of models to generate conversations in an ensemble (Song et al., 2016) or to specifically improve consistency (Song et al., 2020). We extend these approaches by augmenting generative models with retrieval-like operations based on KNN search, allowing dialog models to flexibly incorporate various sources of external knowledge at the same time and scale to large quantities of retrieval candidates. 3 KNN-based Information Fetching Modules Broadly, the KIF module assumes an encoder model M can access inputs X = {x1 , x2 , . ."
2021.tacl-1.6,P17-1171,1,0.932681,"on times and availability (Bordes et al., 2017). In contrast, our work focuses on how to incorporate unstructured knowledge, such as free text found on the Web. Previous work has used architectures that attend over the available knowledge and identify relevant pieces of information, which scales poorly with large quantities of information (Dinan et al., 2018; Qin et al., 2019; Lian et al., 2019). We replace the use of attention over external information with the output of a KNN module. Other work has investigated incorporating information retrieval in language modeling and question answering (Chen et al., 2017; Fan et al., 2019; Seo et al., 2019; Guu et al., 2020), while we focus on dialog applications and flexibly incorporating knowledge from multiple, multimodal sources. On the modeling side, work has explored both generative (Serban et al. 2016a, 2016b) and retrieval based models (Zhang et al., 2018), which identify the best utterance from the training set to return as the dialog response. This often leverages self-attention or cross-attention mechanisms (Humeau et al., 2019). Further work has explored hybrid models, for example, using the output of a retrieval model as input for a generative 84"
2021.tacl-1.6,P16-1186,0,0.0166918,"be possible to store information implicitly during training time by memorizing common patterns present in text (Petroni et al., 2019). We focus on learning 83 to fetch relevant information from multiple explicit external multimodal knowledge sources and integrate them into one network. Further, our work allows the retrieved information to be interpreted as each memory slot is an explicit fact that can be read as text, rather than a learned vector such as in Lample et al. (2019). Work has also focused on computationally efficient softmax operations (Mnih and Hinton, 2009; Grave et al., 2017a; Chen et al., 2016). Many approximate softmax techniques use KNNlike operations to form clusters, and the overall softmax operation is constrained by the slow calculation of the exponential. Our usage of KNN benefits from efficient and scalable libraries such as faiss and nmslib. model (Dinan et al., 2018; Weston et al., 2018; Cai et al., 2019; Zhu et al., 2020). Some of this work has specialized to use both types of models to generate conversations in an ensemble (Song et al., 2016) or to specifically improve consistency (Song et al., 2020). We extend these approaches by augmenting generative models with retrie"
2021.tacl-1.6,D19-1250,0,0.337999,"rave et al., 2017b) simplify these to access previous memories with a dot product. Previous work has also studied how to read and write into these memory architectures (Rae et al., 2016; Graves et al., 2014; Joulin and Mikolov, 2015). In contrast, we focus on how to read large memories. Another line of research has focused on computational scalability for larger external memories to allow efficient access of information. For example, Chandar et al. (2016) propose a hierarchical memory network rather than a flat one and Rae et al. (2016) learn sparse operations to read and write. Lample et al. (2019) focus on learning memories of up to one million slots and how to efficiently access the slots using product keys. Khandelwal et al. (2019) use nearest neighbor operations to augment language models by performing retrieval at the token level—in contrast, we focus on multimodal retrieval of multiple pieces of knowledge based on an entire dialog context. Beyond explicit memory representations, it may be possible to store information implicitly during training time by memorizing common patterns present in text (Petroni et al., 2019). We focus on learning 83 to fetch relevant information from mult"
2021.tacl-1.6,P19-1539,0,0.345829,"case of generative dialog models. Previous work in dialog has leveraged knowledge as necessary information to accomplish the task. For example, airline and restaurant booking tasks often use API calls to access information about reservation times and availability (Bordes et al., 2017). In contrast, our work focuses on how to incorporate unstructured knowledge, such as free text found on the Web. Previous work has used architectures that attend over the available knowledge and identify relevant pieces of information, which scales poorly with large quantities of information (Dinan et al., 2018; Qin et al., 2019; Lian et al., 2019). We replace the use of attention over external information with the output of a KNN module. Other work has investigated incorporating information retrieval in language modeling and question answering (Chen et al., 2017; Fan et al., 2019; Seo et al., 2019; Guu et al., 2020), while we focus on dialog applications and flexibly incorporating knowledge from multiple, multimodal sources. On the modeling side, work has explored both generative (Serban et al. 2016a, 2016b) and retrieval based models (Zhang et al., 2018), which identify the best utterance from the training set to r"
2021.tacl-1.6,P16-1162,0,0.017807,"t al. (2020). then the turn number t and personality p are represented separately. As the personality is a word, we use the same Transformer to encode it. The concatenation of features used for KNN search is: M ′ (xi,last ), M ′ (xi,−last ), t, p. Knowledge Sources. Our model for Engaging ImageChat has access to two sources of external information, E1 and E2 : 5 Experimental Setup 5.1 Implementation Details Parameter Settings. We use parl.ai (Miller et al., 2017) to implement our models. The data for both datasets used is available for download from parl.ai as well. We use byte-pair encoding (Sennrich et al., 2016) to represent the text to better handle the rare word problem (Dinan et al., 2018; Fan et al., 2018a). Our generative Transformer models have 8 encoder layers and 8 decoder layers, with FFN size 2048, embedding dimension 512, and 4 attention heads. We optimize using Adam (Kingma and Ba) and the inverse square root learning schedule (Vaswani et al., 2017) with 10k warmup updates. The initial learning rate is 0.0001 and we optimize for model perplexity. We use a dropout of 0.5 and set gradient clipping to 0.1. We set k = 5 for all cases. For both datasets, we model a vocabulary size of 54,944 ba"
2021.tacl-1.6,2020.acl-main.219,1,0.667032,"et al. 2018), general topics are provided to crowdworkers, who are asked to have in-depth and specific conversations about these topics by referencing specific Wikipedia sentences as knowledge. In this scenario, external knowledge is retrieved from a pre-selected set of Wikipedia sentences associated with the current dialog topic. Retrieval aims to select the sentence that is most relevant at each step of the dialog and thereby to ground system responses in relevant world knowledge (e.g., by referring to Star Wars when talking about science fiction). In the other scenario, Engaging ImageChat (Shuster et al., 2020), crowdworkers are provided with images and asked to have a conversation Various machine learning tasks can benefit from access to external information of different modalities, such as text and images. Recent work has focused on learning architectures with large memories capable of storing this knowledge. We propose augmenting generative Transformer neural networks with KNNbased Information Fetching (KIF) modules. Each KIF module learns a read operation to access fixed external knowledge. We apply these modules to generative dialog modeling, a challenging task where information must be flexibl"
2021.tacl-1.6,W18-5713,0,0.320611,"llows the retrieved information to be interpreted as each memory slot is an explicit fact that can be read as text, rather than a learned vector such as in Lample et al. (2019). Work has also focused on computationally efficient softmax operations (Mnih and Hinton, 2009; Grave et al., 2017a; Chen et al., 2016). Many approximate softmax techniques use KNNlike operations to form clusters, and the overall softmax operation is constrained by the slow calculation of the exponential. Our usage of KNN benefits from efficient and scalable libraries such as faiss and nmslib. model (Dinan et al., 2018; Weston et al., 2018; Cai et al., 2019; Zhu et al., 2020). Some of this work has specialized to use both types of models to generate conversations in an ensemble (Song et al., 2016) or to specifically improve consistency (Song et al., 2020). We extend these approaches by augmenting generative models with retrieval-like operations based on KNN search, allowing dialog models to flexibly incorporate various sources of external knowledge at the same time and scale to large quantities of retrieval candidates. 3 KNN-based Information Fetching Modules Broadly, the KIF module assumes an encoder model M can access inputs"
2021.tacl-1.6,2020.acl-main.516,0,0.0122248,"ficient softmax operations (Mnih and Hinton, 2009; Grave et al., 2017a; Chen et al., 2016). Many approximate softmax techniques use KNNlike operations to form clusters, and the overall softmax operation is constrained by the slow calculation of the exponential. Our usage of KNN benefits from efficient and scalable libraries such as faiss and nmslib. model (Dinan et al., 2018; Weston et al., 2018; Cai et al., 2019; Zhu et al., 2020). Some of this work has specialized to use both types of models to generate conversations in an ensemble (Song et al., 2016) or to specifically improve consistency (Song et al., 2020). We extend these approaches by augmenting generative models with retrieval-like operations based on KNN search, allowing dialog models to flexibly incorporate various sources of external knowledge at the same time and scale to large quantities of retrieval candidates. 3 KNN-based Information Fetching Modules Broadly, the KIF module assumes an encoder model M can access inputs X = {x1 , x2 , . . . , xn }. For example, X can be a collection of sentences, and xi represents an individual sentence. In a setting without additional supporting information, the encoder will process an input xi and pro"
2021.tacl-1.6,P18-1205,0,0.407166,"poorly with large quantities of information (Dinan et al., 2018; Qin et al., 2019; Lian et al., 2019). We replace the use of attention over external information with the output of a KNN module. Other work has investigated incorporating information retrieval in language modeling and question answering (Chen et al., 2017; Fan et al., 2019; Seo et al., 2019; Guu et al., 2020), while we focus on dialog applications and flexibly incorporating knowledge from multiple, multimodal sources. On the modeling side, work has explored both generative (Serban et al. 2016a, 2016b) and retrieval based models (Zhang et al., 2018), which identify the best utterance from the training set to return as the dialog response. This often leverages self-attention or cross-attention mechanisms (Humeau et al., 2019). Further work has explored hybrid models, for example, using the output of a retrieval model as input for a generative 84 Figure 1: KIF modules fetch relevant information from multimodal external knowledge. External knowledge sources E1 and E2 are pre-encoded by encoder M (green). In the model, input xi is encoded by encoder M ′ (blue) to produce M ′ (xi ). KIF modules (orange) operate on M ′ (xi ) and identify the n"
amoia-gardent-2008-test,J92-3002,0,\N,Missing
amoia-gardent-2008-test,C04-1051,0,\N,Missing
amoia-gardent-2008-test,W06-1805,1,\N,Missing
amoia-gardent-2008-test,W07-1430,1,\N,Missing
bedaride-gardent-2010-syntactic,P03-1054,0,\N,Missing
bedaride-gardent-2010-syntactic,P06-1042,0,\N,Missing
bedaride-gardent-2010-syntactic,P07-2009,0,\N,Missing
bedaride-gardent-2010-syntactic,W05-1605,1,\N,Missing
C08-1032,E03-1030,1,0.939796,"by the unification of semantic indices associated with the FTAG elementary trees). Another more practical reason for the absence of large scale TAGs integrating a compositional semantics is the lack of available computational frameworks. Up to recently, there has been no available grammar writing environment and parser that would support the integration of compositional semantics into a TAG. One step in that direction is provided by the development of XMG (Duchier et al., 2004), a formalism which supports the specification of Feature-Based LTAGs equipped with a compositional semantics a` la (Gardent and Kallmeyer, 2003). In this paper, we report on the integration of a unification-based semantics into a Feature-Based LTAG for French which consists of around 6 000 trees. This integration is specified using XMG and we show how this formalism can be used to support a compact and principled encoding of the semantic information that needs to be associated with each of the 6 000 elementary trees. The article is structured as follows. We start (section 2) by presenting XMG and showing how it supports the specification of Feature-Based LTAGs equipped with a compositional semantics. We then present S EM F RAG, the FT"
C08-1032,P06-2032,1,0.934663,"ing disjunctions, conjunctions and inheritance of classes. As argued in (Crabb´e, 2005), classes disjunction supports the description of alternatives, for instance, to describe the alternative possible realisations of a subject (see below). As usual, conjunction and inheritance of classes permits combining the content of two classes2 . 2.3 Node naming and identification mechanisms In combining tree descriptions, the linguist often wants to identify nodes across descriptions. One distinguishing feature of XMG it that it supports a sophisticated treatment of node naming and node identification (Gardent and Parmentier, 2006). Node naming. In XMG, node names are by default local to a class. However explicit IMPORT and EXPORT declarations can be used to make names “visible” to children classes. An EXPORT declaration makes the exported name(s) visible to all children classes. Conversely restrictive IMPORT declarations can be used either to block or to rename exported variables that are visible through inheritance. Node identification. As we have just seen, IM PORT and EXPORT declarations can be used to make names “visible” to children classes and thereby idendify nodes from different classes. For instance, if class"
C08-1032,C88-2147,0,0.724986,"e case, X can be identified using the constraint C1 .X = C2 .X. This concludes our informal presentation of XMG . For a more precise definition of its syntax, semantic and compilation process, we refer the reader to (Duchier et al., 2004). 3 SemFraG To illustrate the expressive power of XMG, we now show how it can be used to specify S EM F RAG, a TAG for French which integrates a unification based compositional semantics. We start by presenting the grammar produced by the XMG specification. S EM F RAG is a unification based version of LTAG namely, Feature-based TAG. A Featurebased TAG (FTAG, (Vijay-Shanker and Joshi, 1988)) consists of a set of (auxiliary or initial) elementary trees and of two tree composition operations: substitution and adjunction. Initial trees are trees whose leaves are labelled with substitution nodes (marked with a downarrow) or terminal categories. Auxiliary trees are distinguished by a foot node (marked with a star) whose category must be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree while adjunction inserts an auxiliary tree into a tree. In an FTAG, the tree nodes are furthermore decorated with two feature structures (called"
C08-1032,W98-0143,0,0.0657078,"llowing for the specification of constraints on features that are “far apart from each other” within a tree. In this paper, we have argued that these features of XMG are effective in supporting an encoding of an FTAG with a unification based compositional semantics which is principled, transparent and compact. These features also markedly distinguish XMG from existing formalisms used to encode tree based grammars such as the nonmonotonic encoding of TAG proposed in (Evans et al., 1995) (in contrast, XMG is fully monotonic) and the tree descriptions based approaches proposed in (Candito, 1996; Xia et al., 1998) where in particular, tree descriptions can only be conjoined (not disjoined) and where identification across tree fragments is restricted to nodes. More in general, we believe that expressive formalisms are necessary to allow not only for the quick development of symbolic tree based grammars but also for their comparison and for the factoring of several grammars be they different wrt to the language they handle (as for instance in the HPSG Delphin or in the LFG Pargram project) or in the semantics they integrate e.g., a glue semantics as proposed in (Frank and van Genabith, 2001), a lambda-ba"
C08-1032,C96-1034,0,0.221717,"names thereby allowing for the specification of constraints on features that are “far apart from each other” within a tree. In this paper, we have argued that these features of XMG are effective in supporting an encoding of an FTAG with a unification based compositional semantics which is principled, transparent and compact. These features also markedly distinguish XMG from existing formalisms used to encode tree based grammars such as the nonmonotonic encoding of TAG proposed in (Evans et al., 1995) (in contrast, XMG is fully monotonic) and the tree descriptions based approaches proposed in (Candito, 1996; Xia et al., 1998) where in particular, tree descriptions can only be conjoined (not disjoined) and where identification across tree fragments is restricted to nodes. More in general, we believe that expressive formalisms are necessary to allow not only for the quick development of symbolic tree based grammars but also for their comparison and for the factoring of several grammars be they different wrt to the language they handle (as for instance in the HPSG Delphin or in the LFG Pargram project) or in the semantics they integrate e.g., a glue semantics as proposed in (Frank and van Genabith,"
C08-1032,P01-1019,0,0.205516,". We focus on verb semantics and show how factorisation can be used to support a compact and principled encoding of the semantic information that needs to be associated with each of the verbal elementary trees. The factorisation is made possible by the use of XMG, a high-level linguistic formalism designed to specify and compile computational grammars and in particular, grammars based on non-local trees or tree descriptions. 1 Introduction Whilst there exists large scale LFGs (Lexical Functional Grammar) and HPSGs (Head-Driven Phrase Structure Grammar) equipped with a compositional semantics (Copestake et al., 2001; Frank and van Genabith, 2001), available Tree Adjoining Grammars remain largely syntactic. One reason for this is that there has been, up to recently, much debate about how best to combine TAG with a compositional semantics. Should it be based on the derived or the derivation tree ? Should Feature-Based LTAG be used or should synchronous TAG? Many proposals have been put forward but only recently did sufficient consensus c 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reser"
C08-1032,P95-1011,0,0.165016,"ating tree nodes with one or two (for TAG) feature structures. Importantly, feature values can be assigned global names thereby allowing for the specification of constraints on features that are “far apart from each other” within a tree. In this paper, we have argued that these features of XMG are effective in supporting an encoding of an FTAG with a unification based compositional semantics which is principled, transparent and compact. These features also markedly distinguish XMG from existing formalisms used to encode tree based grammars such as the nonmonotonic encoding of TAG proposed in (Evans et al., 1995) (in contrast, XMG is fully monotonic) and the tree descriptions based approaches proposed in (Candito, 1996; Xia et al., 1998) where in particular, tree descriptions can only be conjoined (not disjoined) and where identification across tree fragments is restricted to nodes. More in general, we believe that expressive formalisms are necessary to allow not only for the quick development of symbolic tree based grammars but also for their comparison and for the factoring of several grammars be they different wrt to the language they handle (as for instance in the HPSG Delphin or in the LFG Pargra"
C08-1032,C92-1034,0,\N,Missing
C10-1042,W00-2004,0,0.580265,"0-100 102 Initial Search Space (ISS) size Figure 3: Performance of realisation approaches on the C OMPLEXITY benchmark, average unpacked chart size as a function of the ISS complexity. Much work has already been done on optimising surface realisation. Because surface realisation often draws on parsing techniques, work on parsing optimisation is also relevant. In this section, we briefly relate our proposal to another grammar converting approach (Koller and Striegnitz, 2002); to another chart based approach (Carroll and Oepen, 2005); and to approaches based on statistical pruning (White, 2004; Bangalore and Rambow, 2000). 5.1 straints. Interestingly, it also shows that the selective mode (RTG EN-selective) permits improving runtimes while achieving almost perfect disambiguation in that the average number of derivation trees (GF) produced is close to that produced when using all features. The differences between the two generation forests stems from packing. Using only a subset of features favors packing, thereby reducing the number of chart items built, but introduces over- generation. Graph 3 and Table 2 confirm the results obtained using the M ODIFIERS benchmark on a testset (C OMPLEXITY) where input comple"
C10-1042,C92-2092,0,0.243875,".perez@loria.fr Abstract Surface realisation with grammars integrating flat semantics is known to be NP complete. In this paper, we present a new algorithm for surface realisation based on Feature Based Tree Adjoining Grammar (FTAG) which draws on the observation that an FTAG can be translated into a Regular Tree Grammar describing its derivation trees. We carry out an extensive testing of several variants of this algorithm using an automatically produced testsuite and compare the results obtained with those obtained using GenI, another FTAG based surface realiser. 1 Introduction As shown in (Brew, 1992; Koller and Striegnitz, 2002), Surface Realisation is NP-complete. Various optimisation techniques have therefore been proposed to help improve practical runtimes. For instance, (Kay, 1996) proposes to reduce the number of constituents built during realisation by only considering for combination constituents with non overlapping semantics and compatible indices. (Kay, 1996; Carroll and Oepen, 2005; Gardent and Kow, 2007) propose various techniques to restrict the combinatorics induced by intersective modifiers all applying to the same structure. And (Koller and Striegnitz, 2002; Gardent and K"
C10-1042,I05-1015,0,0.500799,"g of several variants of this algorithm using an automatically produced testsuite and compare the results obtained with those obtained using GenI, another FTAG based surface realiser. 1 Introduction As shown in (Brew, 1992; Koller and Striegnitz, 2002), Surface Realisation is NP-complete. Various optimisation techniques have therefore been proposed to help improve practical runtimes. For instance, (Kay, 1996) proposes to reduce the number of constituents built during realisation by only considering for combination constituents with non overlapping semantics and compatible indices. (Kay, 1996; Carroll and Oepen, 2005; Gardent and Kow, 2007) propose various techniques to restrict the combinatorics induced by intersective modifiers all applying to the same structure. And (Koller and Striegnitz, 2002; Gardent and Kow, 2007) describe two alternative techniques for reducing the initial search space. In this paper, we focus on the optimisation mechanisms of two TAG based surface realisers namely, GENI (Gardent and Kow, 2007) and the algorithm we present in this paper namely, RTG EN (Perez-Beltrachini, 2009). GENI’s optimisation includes both a filtering process whose aim is to reduce the initial search space an"
C10-1042,C88-2147,0,0.642766,"ect to related work on surface realisation optimisation. 2 SemXTag The grammar (S EM XTAG) used by GENI and RTG EN is a Feature-Based Lexicalised Tree Adjoining Grammar (FTAG) augmented with a unification-based semantics as described in (Gardent and Kallmeyer, 2003). We briefly introduce each of these components and describe the grammar coverage. We then show how this FTAG can be converted to an RTG describing its derivation trees. 367 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 367–375, Beijing, August 2010 2.1 FTAG. A Feature-based TAG (Vijay-Shanker and Joshi, 1988) consists of a set of (auxiliary or initial) elementary trees and of two tree-composition operations: substitution and adjunction. Initial trees are trees whose leaves are labeled with substitution nodes (marked with a downarrow) or terminal categories. Auxiliary trees are distinguished by a foot node (marked with a star) whose category must be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree while adjunction inserts an auxiliary tree into a tree. In an FTAG, the tree nodes are furthermore decorated with two feature structures (called t"
C10-1042,E03-1030,1,0.92012,"n surface realisation optimisation. The paper is structured as follows. We first present the grammar used by both GENI and RTG EN, namely S EM XTAG (Section 2). We then describe the two surface realisation algorithms (Section 3). In Section 4, we describe the empirical evaluation carried out and present the results. Finally, Section 5 situates RTG EN with respect to related work on surface realisation optimisation. 2 SemXTag The grammar (S EM XTAG) used by GENI and RTG EN is a Feature-Based Lexicalised Tree Adjoining Grammar (FTAG) augmented with a unification-based semantics as described in (Gardent and Kallmeyer, 2003). We briefly introduce each of these components and describe the grammar coverage. We then show how this FTAG can be converted to an RTG describing its derivation trees. 367 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 367–375, Beijing, August 2010 2.1 FTAG. A Feature-based TAG (Vijay-Shanker and Joshi, 1988) consists of a set of (auxiliary or initial) elementary trees and of two tree-composition operations: substitution and adjunction. Initial trees are trees whose leaves are labeled with substitution nodes (marked with a downarrow) or ter"
C10-1042,P96-1027,0,0.574819,"eature Based Tree Adjoining Grammar (FTAG) which draws on the observation that an FTAG can be translated into a Regular Tree Grammar describing its derivation trees. We carry out an extensive testing of several variants of this algorithm using an automatically produced testsuite and compare the results obtained with those obtained using GenI, another FTAG based surface realiser. 1 Introduction As shown in (Brew, 1992; Koller and Striegnitz, 2002), Surface Realisation is NP-complete. Various optimisation techniques have therefore been proposed to help improve practical runtimes. For instance, (Kay, 1996) proposes to reduce the number of constituents built during realisation by only considering for combination constituents with non overlapping semantics and compatible indices. (Kay, 1996; Carroll and Oepen, 2005; Gardent and Kow, 2007) propose various techniques to restrict the combinatorics induced by intersective modifiers all applying to the same structure. And (Koller and Striegnitz, 2002; Gardent and Kow, 2007) describe two alternative techniques for reducing the initial search space. In this paper, we focus on the optimisation mechanisms of two TAG based surface realisers namely, GENI (G"
C10-1042,P02-1003,0,0.577725,".fr Abstract Surface realisation with grammars integrating flat semantics is known to be NP complete. In this paper, we present a new algorithm for surface realisation based on Feature Based Tree Adjoining Grammar (FTAG) which draws on the observation that an FTAG can be translated into a Regular Tree Grammar describing its derivation trees. We carry out an extensive testing of several variants of this algorithm using an automatically produced testsuite and compare the results obtained with those obtained using GenI, another FTAG based surface realiser. 1 Introduction As shown in (Brew, 1992; Koller and Striegnitz, 2002), Surface Realisation is NP-complete. Various optimisation techniques have therefore been proposed to help improve practical runtimes. For instance, (Kay, 1996) proposes to reduce the number of constituents built during realisation by only considering for combination constituents with non overlapping semantics and compatible indices. (Kay, 1996; Carroll and Oepen, 2005; Gardent and Kow, 2007) propose various techniques to restrict the combinatorics induced by intersective modifiers all applying to the same structure. And (Koller and Striegnitz, 2002; Gardent and Kow, 2007) describe two alterna"
C10-1042,W08-2319,0,0.255971,"Missing"
C10-1042,W07-2306,1,\N,Missing
C10-1042,J93-4001,0,\N,Missing
C10-2006,W07-1402,0,0.0271926,"r detailed error mining making it possible to identify the most likely causes of system errors. Additionally, the proposed methodology permits controlling over such benchmark parameters as the size of the data set, the balance between true and false entailments, the correlation between word overlap and entailment value and/or the specific syntactic phenomena involved. This is in contrast with the RTE data collection process where “the distribution of examples is arbitrary to a large extent, being determined by manual selection2 ” (Giampiccolo et al., 2007). As has been repeatedly pointed out (Burchardt et al., 2007; Garoufi, 2007), the RTE datasets are poorly balanced w.r.t., both the frequency and the coverage of the various phenomena interacting with textual inference. 3 smell:{n0Va1,active,relSubj,canAdj} give:{n0Vn2n1,active,canSubj,canObj,canIObj} H: The flowers are given to the woman give:{n0Vn1Pn2,shortPassive,canSubj,canIObj} Entailment: TRUE Figure 1: An SSI Benchmark item to construct a balanced data set for SSI evaluation. We now describe each of these processes in turn. Constructing a generation bank We use the term “generation bank” to refer to a dataset whose items are produced by a surfac"
C10-2006,W08-0506,0,0.0316303,"Missing"
C10-2006,W03-2806,0,0.0356613,"Missing"
C10-2006,W06-3907,0,0.248679,"old standard, the evaluation scheme presented here, permits evaluating them w.r.t. their ability to capture syntax based sentential inference. It is worth adding that, although the present paper focuses on entailments strictly based on syntax, the proposed methodology should straightforwardly extend to further types of entailment such as in particular, entailments involving lexical relations (synonymy, antonymy, etc.) or entailments involving more complex semantic phenomena such as the interplay between different classes of complement taking verbs, polarity and author commitment discussed in (Nairn et al., 2006). This is because as we shall see in section 3, our approach is based on an extensive, hand written grammar of English integrating syntax and semantics. By modifying the grammar, the lexicon and/or the semantics, data of varying linguistic type and complexity can be produced and used for evaluation. Arguably focusing on meaning entailing syntactic transformations is very weak. Indeed, one of the key conclusions at the second RTE Challenge Workshop was that entailment modeling requires vast knowledge resources that correspond to different types of entailment reasoning e.g., ontological and lexi"
C10-2006,W09-2609,0,0.022225,"Missing"
C10-2006,P06-1042,0,0.0540455,"Missing"
C10-2006,E03-1030,1,0.78923,"tion. We now describe each of these processes in turn. Constructing a generation bank We use the term “generation bank” to refer to a dataset whose items are produced by a surface realiser i.e., a sentence generator. A surface realiser in turn is a program which associates with a given semantic representation, the set of sentences verbalising the meaning encoded by that representation. To construct our generation bank, we use the GenI surface realiser (Gardent and Kow, 2007). This realiser uses a Feature based Tree Adjoining Grammar (FTAG) augmented with a unification sematics as proposed in (Gardent and Kallmeyer, 2003) to produce all the sentences associated by the grammar with a given semantic representation. Interestingly, the FTAG used has been compiled out of a factorised representation and as a result, each elementary grammar unit (i.e., elementary FTAG tree) and further each parse tree, is associated with a list of items indicating the syntactic construct(s) captured by that unit/tree3 . In short, GenI permits associating with a given semantics, a set of sentences and further for each of these sentences, a set of items indicating the syntactic construct(s) present in the syntactic tree of that sentenc"
C10-2006,P07-1042,1,0.914421,"n give:{n0Vn1Pn2,shortPassive,canSubj,canIObj} Entailment: TRUE Figure 1: An SSI Benchmark item to construct a balanced data set for SSI evaluation. We now describe each of these processes in turn. Constructing a generation bank We use the term “generation bank” to refer to a dataset whose items are produced by a surface realiser i.e., a sentence generator. A surface realiser in turn is a program which associates with a given semantic representation, the set of sentences verbalising the meaning encoded by that representation. To construct our generation bank, we use the GenI surface realiser (Gardent and Kow, 2007). This realiser uses a Feature based Tree Adjoining Grammar (FTAG) augmented with a unification sematics as proposed in (Gardent and Kallmeyer, 2003) to produce all the sentences associated by the grammar with a given semantic representation. Interestingly, the FTAG used has been compiled out of a factorised representation and as a result, each elementary grammar unit (i.e., elementary FTAG tree) and further each parse tree, is associated with a list of items indicating the syntactic construct(s) captured by that unit/tree3 . In short, GenI permits associating with a given semantics, a set of"
C10-2006,W07-1401,0,0.109074,"oman smell nice 1 http://www.pascal-network.org/ Challenges/RTE 45 Coling 2010: Poster Volume, pages 45–53, Beijing, August 2010 2 Motivations may be of very limited value. For semantically oriented tools such as SRL systems, it is important to also assess their results w.r.t. the task which they are meant support namely reasoning : Do the semantic representations built by SRL help in making the correct inferences ? Can they be used, for instance, to determine whether a given sentence answers a given question ? or whether the content of one sentence follow from that another ? As explained in (Giampiccolo et al., 2007), entailment recognition is a first, major step towards answering these questions. Accordingly, instead of comparing the representations produced by SRL systems against a gold standard, the evaluation scheme presented here, permits evaluating them w.r.t. their ability to capture syntax based sentential inference. It is worth adding that, although the present paper focuses on entailments strictly based on syntax, the proposed methodology should straightforwardly extend to further types of entailment such as in particular, entailments involving lexical relations (synonymy, antonymy, etc.) or ent"
C10-2006,W08-2123,0,0.0321702,"lting structures are rewritten into first order logic formulae. Like Nutcracker, Afazio checks entailment using first order automated reasoners namely, Equinox and Paradox 5 . System evaluation and comparison SRL and grammar based systems equipped with a compositional semantics are primary targets for an SSI evaluation. Indeed these systems aim to abstract away from syntactic differences by producing semantic representations of a text which capture predicate/argument relations independent of their syntactic realisation. We evaluated three such systems on the SSI benchmark namely, NutCracker, (Johansson and Nugues, 2008)’s Semantic Role Labeller and the Afazio RTE system. Nutcracker Nutcracker is a system for recognising textual entailment which uses deep semanSRL (Johansson and Nugues, 2008)’s semantic role labeller achieved the top score in the closed CoNLL 2008 challenge reaching a labeled semantic F1 of 81.65. To allow for comparison with Nutcracker and Afazio, we adapted the a clause or to the embedded verb if the sentence is a complex sentence. http://www.cs.chalmers.se/˜koen/ folkung/ 4.1 Systems 5 49 account often leads to incorrect results when the hypothesis (H) is short. Nutcracker, on the other ha"
C10-2006,C96-2120,0,0.0371245,"Missing"
C10-2039,C92-2092,0,0.107951,"ivations Previous work on benchmark construction for testing the performance of surface realisers falls into two camps depending on whether or not the realiser uses a reversible grammar, that is, a grammar that can be used for both parsing and generation. To test a surface realiser based on a large reversible Head-Driven Phrase Structure Grammar (HPSG), Carroll et al. (1999) use a small test set of two hand-constructed and 40 parsingderived cases to test the impact of intersective modifiers1 on generation performance. More recently, Carroll and Oepen (2005) present a perfor1 As first noted by Brew (1992) and Kay (1996), given a set of n modifiers all modifying the same structure, all possible intermediate structures will be constructed, i.e., 2n+1 . 338 Coling 2010: Poster Volume, pages 338–346, Beijing, August 2010 mance evaluation which uses as a benchmark the set of semantic representations produced by parsing 130 sentences from the Penn Treebank and manually selecting the correct semantic representations. Finally, White (2004) profiles a CCG2 based sentence realiser using two domain-focused reversible CCGs to produce two test suites of 549 and 276 h semantic formula, target sentence i pai"
C10-2039,I05-1015,0,0.167683,"realisers with respect to a GENSEM-produced benchmark. 2 Motivations Previous work on benchmark construction for testing the performance of surface realisers falls into two camps depending on whether or not the realiser uses a reversible grammar, that is, a grammar that can be used for both parsing and generation. To test a surface realiser based on a large reversible Head-Driven Phrase Structure Grammar (HPSG), Carroll et al. (1999) use a small test set of two hand-constructed and 40 parsingderived cases to test the impact of intersective modifiers1 on generation performance. More recently, Carroll and Oepen (2005) present a perfor1 As first noted by Brew (1992) and Kay (1996), given a set of n modifiers all modifying the same structure, all possible intermediate structures will be constructed, i.e., 2n+1 . 338 Coling 2010: Poster Volume, pages 338–346, Beijing, August 2010 mance evaluation which uses as a benchmark the set of semantic representations produced by parsing 130 sentences from the Penn Treebank and manually selecting the correct semantic representations. Finally, White (2004) profiles a CCG2 based sentence realiser using two domain-focused reversible CCGs to produce two test suites of 549 a"
C10-2039,C88-2147,0,0.745417,"ow how to automatically derive a DCG that describes the derivation trees of this grammar (section 3.2). Finally, we show how this DCG encoding permits generating formulae while enabling control over the set of semantic representations to be produced (section 3.3). 3.1 SemXTAG The S EM XTAG grammar used by GENSEM and by the two surface realisers is a Feature-Based Lexicalised Tree Adjoining Grammar augmented with a unification-based semantics as described by Gardent and Kallmeyer (2003). We briefly introduce each of these components and describe the grammar coverage. FTAG. A Feature-based TAG (Vijay-Shanker and Joshi, 1988) consists of a set of (auxiliary or initial) elementary trees and of two treecomposition operations: substitution and adjunction. Initial trees are trees whose leaves are labelled with substitution nodes (marked with a downarrow) or terminal categories. Auxiliary trees are distinguished by a foot node (marked with a star) whose category must be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree while adjunction inserts an auxiliary tree into a tree. In an FTAG, the tree nodes are furthermore decorated with two feature structures (called t"
C10-2039,E03-1030,1,0.924971,"algorithm for TAG. We first present the specific TAG used for traversal, namely S EM XTAG (Alahverdzhieva, 2008) (section 3.1). We then show how to automatically derive a DCG that describes the derivation trees of this grammar (section 3.2). Finally, we show how this DCG encoding permits generating formulae while enabling control over the set of semantic representations to be produced (section 3.3). 3.1 SemXTAG The S EM XTAG grammar used by GENSEM and by the two surface realisers is a Feature-Based Lexicalised Tree Adjoining Grammar augmented with a unification-based semantics as described by Gardent and Kallmeyer (2003). We briefly introduce each of these components and describe the grammar coverage. FTAG. A Feature-based TAG (Vijay-Shanker and Joshi, 1988) consists of a set of (auxiliary or initial) elementary trees and of two treecomposition operations: substitution and adjunction. Initial trees are trees whose leaves are labelled with substitution nodes (marked with a downarrow) or terminal categories. Auxiliary trees are distinguished by a foot node (marked with a star) whose category must be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree while"
C10-2039,W07-2306,1,0.845218,"Gottesman Universit´e Henri Poincar´e/LORIA acrolinx GmbH laura.perez@loria.fr ben.gottesman@acrolinx.com Abstract We present GENSEM, a tool for generating input semantic representations for two sentence generators based on the same reversible Tree Adjoining Grammar. We then show how GENSEM can be used to produced large and controlled benchmarks and test the relative performance of these generators. 1 Introduction Although computational grammars are mostly used for parsing, they can also be used to generate sentences. This has been done, for instance, to detect overgeneration by the grammar (Gardent and Kow, 2007). Sentences that are generated but are ungrammatical indicate flaws in the grammar. This has also been done to test a parser (Nederhof, 1996; Purdom, 1972). Using the sentences generated from the grammar ensures that the sentences given to the parser are in the language it defines. Hence a parse failure necessarily indicates a flaw in the parser’s design as opposed to a lack of coverage by the grammar. Here we investigate a third option, namely, the focused benchmarking of sentence realisers based on reversible grammars, i.e. on grammars that can be used both to produce sentences from a semant"
C10-2039,P96-1027,0,0.0852865,"s work on benchmark construction for testing the performance of surface realisers falls into two camps depending on whether or not the realiser uses a reversible grammar, that is, a grammar that can be used for both parsing and generation. To test a surface realiser based on a large reversible Head-Driven Phrase Structure Grammar (HPSG), Carroll et al. (1999) use a small test set of two hand-constructed and 40 parsingderived cases to test the impact of intersective modifiers1 on generation performance. More recently, Carroll and Oepen (2005) present a perfor1 As first noted by Brew (1992) and Kay (1996), given a set of n modifiers all modifying the same structure, all possible intermediate structures will be constructed, i.e., 2n+1 . 338 Coling 2010: Poster Volume, pages 338–346, Beijing, August 2010 mance evaluation which uses as a benchmark the set of semantic representations produced by parsing 130 sentences from the Penn Treebank and manually selecting the correct semantic representations. Finally, White (2004) profiles a CCG2 based sentence realiser using two domain-focused reversible CCGs to produce two test suites of 549 and 276 h semantic formula, target sentence i pairs, respectivel"
C10-2039,P02-1003,0,0.024342,"ematically tries to combine trees using substitution and adjunction. Third, the retrieval phase extracts the yields of the complete derived trees, thereby producing the generated sentence(s). There are also differences however. We now spell these out and indicate how they might impact the relative performance of the two surface realisers. Derived vs. derivation trees. While GENI constructs derived trees, RTG EN uses the RTG encoding of S EM XTAG sketched in the previous section to construct derivation trees. These are then unraveled into derived trees at the final retrieval stage. As noted by Koller and Striegnitz (2002), these trees are simpler than TAG elementary trees, which can favourably impact performance. Interleaving of feature constraint solving and syntactic analysis. GENI integrates in the tree combining phase a filtering step in which the initial search space is pruned by eliminating from it all combinations of TAG elementary trees that cover the input semantics but cannot possibly lead to a valid derived tree. This filtering eliminates all combinations of trees such that either the category of a substitution node cannot be cancelled out by that of the root node of a different tree, or a root node"
C10-2039,W02-2103,0,0.0380275,"ages 338–346, Beijing, August 2010 mance evaluation which uses as a benchmark the set of semantic representations produced by parsing 130 sentences from the Penn Treebank and manually selecting the correct semantic representations. Finally, White (2004) profiles a CCG2 based sentence realiser using two domain-focused reversible CCGs to produce two test suites of 549 and 276 h semantic formula, target sentence i pairs, respectively. For realisers that are not based on a reversible grammar, there are approaches which derive large sets of realiser input from the Penn Treebank (PTB). For example, Langkilde-Geary (2002) proposes to translate the PTB annotations into a format accepted by her sentence generator Halogen. The output of this generator can then be automatically compared with the PTB sentence from which the corresponding input was derived. Similarly, Callaway (2003) builds an evaluation benchmark by transforming PTB trees into a format suitable for the KPML realiser he uses. In all of the above cases, the data is derived from real world sentences, thereby exemplifying “real world complexity”. If the corpus is large enough (as in the case of the PTB), the data can furthermore be expected to cover a"
C10-2039,W08-2319,0,0.034896,"Missing"
C12-1123,W11-2832,0,0.0690707,"orms and whose leaf nodes represent the clusters of error mined data grouped according to the suspicious forms characterizing their elements. Like in a decision tree, each cluster in the suspicion tree is characterized by the set of attributes (suspicious forms) labelling its ancestors; and the tree itself represents a disjunction of mutually exclusive error cases. We illustrate the impact of our error mining algorithm on error analysis by applying it to detect and analyse the most likely sources of failure in a surface realiser developed to participate in the Surface Realisation Shared Task (Belz et al., 2011); and we show how this error mining algorithm permits improving the surface realiser. The paper is structured as follows. We start (Section 2) by introducing our error mining algorithm. In essence, this algorithm adapts (Quinlan, 1986)’s ID3 algorithm to build a suspicion tree such that the clusters obtained group together sets of input data that share similar sources of failure (called suspicious forms); and the attributes labelling these clusters are the suspicious forms indicating which are these most likely causes of failure. In Section 3, we show how this error mining algorithm helps impr"
C12-1123,W09-2609,0,0.0398769,"Missing"
C12-1123,W11-2929,0,0.0668978,"Missing"
C12-1123,P12-1062,1,0.575067,"i . . . w n is the ratio P(w i . . . w n ) = C(w i ...w n |OK) where C(w i . . . w n ) is the number of sentences in which the n-gram w i . . . w n occurs and C(w i ...w n ) C(w i . . . w n |OK), the number of sentences containing w i . . . w n which could be parsed. In other words, the parsability rate of an n-gram is the proportion of sentences in which this n-gram occurs and for which parsing succeeds. An n-gram then, is a suspicious form if it has a low parsability rate. (van Noord, 2004)’s approach was extended and refined in (Sagot and de la Clergerie, 2006), (de Kok et al., 2009) and (Gardent and Narayan, 2012) as follows. (Sagot and de la Clergerie, 2006) defines a suspicion rate for n-grams which takes into account the number of occurrences of a given word form and iteratively defines the suspicion rate of each word form in a sentence based on the suspicion rate of this word form in the corpus. Further, (de Kok et al., 2009) extends this iterative error mining to n-grams of words and POS tags of arbitrary length. And (Gardent and Narayan, 2012) extends (van Noord, 2004)’s approach to mine for suspicious subtrees rather than n-grams. An important limitation shared by all these error mining approach"
C12-1123,C12-1124,1,0.769309,"s on lexical and grammatical issues. Attributes The attributes used to partition the SR data are suspicious trees i.e., subtrees of the SR dependency trees whose frequency is above a given threshold. Following (Gardent and Narayan, 2012), we allow for various views on errors by mining for forms labelled with lemmas only (word); with parts of speech (POS); with dependency relations (dep); with lemmas and parts of speech (word/POS); and with dependency relations and parts of speech (dep-POS) (cf. Figure 3). Generation System The system to be tested is the symbolic Surface Realiser described in (Narayan and Gardent, 2012). We ran this surface realiser on the SR input data and separately stored the input dependency trees for which generation succeeded (PASS) and the input dependency trees for which generation failed (FAIL). We then removed from the failed data, those cases where generation failed either because a word was missing in the lexicon or because a grammar rule was missing but required by the lexicon and the input data. These cases can easily be detected using the generation system and thus do not need to be handled by error mining. Error Mining We iterate several times between error mining and perform"
C12-1123,W11-2836,0,0.0306671,"frontier indicates that the main distinct suspicious forms are, in that order: 1. Possessive NPs (POSS is the part of speech tag assigned to possessive ’s3 ) The suspicious form (POSS) points to a mismatch between the representation of genitive NPs (e.g., Oakland’s thief) in the SR Task data and in the grammar. While our generator expects the representation of ‘Oakland’s thief’ to be (thief/NN, (’s/POSS, (oakland/NNP))), the structure provided by the SR Task is (thief/NN, (oakland/NNP, (’s/POSS))). Hence whenever a possessive appears in the input data, generation fails. This is in line with (Rajkumar et al., 2011)’s finding that the logical 2 Iteration stops either when the results are perfect (perfect coverage and perfect BLEU score) or when the trees fail to be discriminative enough (low number of FAIL instances associated with the suspicion tree leaves). So far, the latter situation did not occur and we are still using the suspicion tree to identify the main sources of errors for the remaining error cases. 3 In fact, the part of speech tag assigned to possessive ’s in the SR data is POS not POSS. We renamed it to avoid confusion with POS as an abbreviation for part-of-speech. 2017 (POSS) yes no (NN)"
C12-1123,P06-1042,0,0.0513126,"Missing"
C12-1123,C96-2103,0,0.322685,"Missing"
C12-1123,P04-1057,0,0.0422848,"Missing"
C12-1124,J99-2004,0,0.0617305,"cores. To address the fact that there are n! ways to combine any n modifiers with a single constituent, (White, 2004) proposes to use a language model to prune the chart of identical edges representing different modifier permutations, e.g., to choose between fierce black cat and black fierce cat. Similarly, (Bangalore and Rambow, 2000) assumes a single derivation tree that encodes a word lattice (a {fierce black, black fierce} cat), and uses statistical knowledge to select the best linearisation. Recently, (Espinosa et al., 2008) adapted the supertagging techniques first proposed for parsing (Bangalore and Joshi, 1999) to surface realisation. Given a treebank in the appropriate format, this technique permits filtering the initial search space by using a model trained on that treebank. Supertagging was shown to improve the performance of symbolic parsers and generators significantly. However, it requires the existence of a treebank in a format appropriate to generate the supertagging model. In sum, various symbolic and statistical techniques have been developed to improve the efficiency of grammar-based surface realisation. However, statistical systems using supertagging require the existence of a treebank i"
C12-1124,W11-2832,0,0.285323,"tional optimisation techniques. From the lexicalist approach, it adapts two techniques designed to prune the search space, namely a so-called polarity filter on local input trees (Bonfante et al., 2004); and the use of a language model to prune competing intermediate substructures. In addition, the algorithm is parallelised to explore the possible completions of the top-down predictions simultaneously rather than sequentially. The algorithm was implemented using a Feature-Based Lexicalised Tree Adjoining Grammar for English and tested on the Generation Challenge Surface Realisation task data (Belz et al., 2011). We compare our algorithm with a baseline lexicalist approach which processes the input tree top 2028 down. The results show that the algorithm we propose drastically improves on the baseline, reducing generation time for sentences longer than 6 words w.r.t. this baseline. This paper is structured as follows. Section 2 situates our approach with respect to related work. Section 3 introduces the input data provided by the Generation Challenge Surface Realisation task and used for the evaluation. Section 4 introduces the tree adjoining grammar used by the algorithm. Section 5 presents the surfa"
C12-1124,W11-2835,0,0.0280494,"pertagging model. In sum, various symbolic and statistical techniques have been developed to improve the efficiency of grammar-based surface realisation. However, statistical systems using supertagging require the existence of a treebank in an appropriate format while the purely symbolic systems described in (Carroll and Oepen, 2005; Gardent and Kow, 2005; Koller and Striegnitz, 2002; Gardent and Perez-Beltrachini, 2010) have not been evaluated on large corpora of arbitrarily long sentences such as provided by the surface realisation (SR) task (Belz et al., 2011). Recently, (Guo et al., 2011; Bohnet et al., 2011; Stent, 2011) have developed statistical dependency realisers that do not make use of an explicit grammar but use cascaded classifiers and n-gram models to map in SR input data to sentences. They obtain the best results in the SR task partly because, for grammar based systems, converting the provided input into the format expected by the grammar proved to be extremely difficult. The algorithm we propose departs from these approaches in that it is a grammar-based approach; it is optimised by combining parallel processing, top-down prediction and local bottom-up polarity filtering; and it was e"
C12-1124,C04-1044,0,0.0169404,"oach. On the one hand, rule selection is guided, as in the lexicalist approach, by the elementary units present in the input rather than by its structure – In this way, the logical form equivalence issue is avoided. On the other hand, the structure of the input is used to provide top-down guidance for the search and thereby restrict the combinatorics. To further improve efficiency, the algorithm integrates three additional optimisation techniques. From the lexicalist approach, it adapts two techniques designed to prune the search space, namely a so-called polarity filter on local input trees (Bonfante et al., 2004); and the use of a language model to prune competing intermediate substructures. In addition, the algorithm is parallelised to explore the possible completions of the top-down predictions simultaneously rather than sequentially. The algorithm was implemented using a Feature-Based Lexicalised Tree Adjoining Grammar for English and tested on the Generation Challenge Surface Realisation task data (Belz et al., 2011). We compare our algorithm with a baseline lexicalist approach which processes the input tree top 2028 down. The results show that the algorithm we propose drastically improves on the"
C12-1124,I05-1015,0,0.670205,", a grammar will associate with natural language expressions only one of these logically equivalent formula. Hence a generator will be able to produce the natural language expression E only when given the formula φ associated by the grammar with E . For all other formulae logically equivalent to φ , it will fail. Since, the problem of computing logical equivalence for first order logic is undecidable, the problem is quite deep. For flat semantic representations such as MRSs (Minimal Recursion Semantics, (Copestake et al., 2001)) on the other hand, lexicalist approaches (Espinosa et al., 2010; Carroll and Oepen, 2005; Gardent and Kow, 2005) have extensively been used because (i) they impose few constraints on the grammar thereby making it easier to maintain bi-directional grammars that can be used both for parsing and for generation; and (ii) the approach eschews the logical form equivalence problem – Since the semantic representations are unstructured, there is no requirement on the generator to mirror a semantic structure. One known drawback of lexicalist approaches however is that they generally lack efficiency. Indeed, previous work has shown that the high combinatorics of lexicalist approaches stem f"
C12-1124,P01-1019,0,0.0285512,"distinct formulae. For instance p ∧ q is logically equivalent to q ∧ p. In general though, a grammar will associate with natural language expressions only one of these logically equivalent formula. Hence a generator will be able to produce the natural language expression E only when given the formula φ associated by the grammar with E . For all other formulae logically equivalent to φ , it will fail. Since, the problem of computing logical equivalence for first order logic is undecidable, the problem is quite deep. For flat semantic representations such as MRSs (Minimal Recursion Semantics, (Copestake et al., 2001)) on the other hand, lexicalist approaches (Espinosa et al., 2010; Carroll and Oepen, 2005; Gardent and Kow, 2005) have extensively been used because (i) they impose few constraints on the grammar thereby making it easier to maintain bi-directional grammars that can be used both for parsing and for generation; and (ii) the approach eschews the logical form equivalence problem – Since the semantic representations are unstructured, there is no requirement on the generator to mirror a semantic structure. One known drawback of lexicalist approaches however is that they generally lack efficiency. I"
C12-1124,D10-1055,0,0.161244,"trFкA dsr  sADArZ “ Upr s  nFc  ” pr Ert шNd - sE&gt;яt trFкo к  mкAbl  u(pAdn smy кo a(yEDк GVA  dtA h {। Keywords: Generation, Tree Adjoining Grammar, Surface Realization. Keywords in Hindi: u(pAdn , v&quot; - sV - &yAкrZ , sth spAdn. Proceedings of COLING 2012: Technical Papers, pages 2027–2042, COLING 2012, Mumbai, December 2012. 2027 1 Introduction Depending on the type of semantic representation encoded by the grammar, two main types of algorithms have been proposed for generating sentences with bi-directional, unification-based grammars such as CCG (Combinatory Categorial Grammar, (Espinosa et al., 2010)), HPSG (HeadDriven Phrase Structure Grammar, (Carroll et al., 1999)) and TAG (Tree Adjoining Grammar, (Gardent and Kow, 2005)). For recursive semantic representations such as first-order logic formulae, head-driven algorithms (Shieber et al., 1990) have been argued to be best because they restrict the combinatorics inherent to bottom-up search; they avoid non termination by using lexical items to guide the search ; and they allow for semantically nonmonotonic grammars (i.e., grammars where the semantics of a rule at the left hand side need not be subsumed by the semantics of the rule at the r"
C12-1124,P08-1022,0,0.0573499,"hite’s system (White, 2004), the best paraphrase is determined on the basis of n-gram scores. To address the fact that there are n! ways to combine any n modifiers with a single constituent, (White, 2004) proposes to use a language model to prune the chart of identical edges representing different modifier permutations, e.g., to choose between fierce black cat and black fierce cat. Similarly, (Bangalore and Rambow, 2000) assumes a single derivation tree that encodes a word lattice (a {fierce black, black fierce} cat), and uses statistical knowledge to select the best linearisation. Recently, (Espinosa et al., 2008) adapted the supertagging techniques first proposed for parsing (Bangalore and Joshi, 1999) to surface realisation. Given a treebank in the appropriate format, this technique permits filtering the initial search space by using a model trained on that treebank. Supertagging was shown to improve the performance of symbolic parsers and generators significantly. However, it requires the existence of a treebank in a format appropriate to generate the supertagging model. In sum, various symbolic and statistical techniques have been developed to improve the efficiency of grammar-based surface realisa"
C12-1124,W05-1605,1,0.440197,"neration, Tree Adjoining Grammar, Surface Realization. Keywords in Hindi: u(pAdn , v&quot; - sV - &yAкrZ , sth spAdn. Proceedings of COLING 2012: Technical Papers, pages 2027–2042, COLING 2012, Mumbai, December 2012. 2027 1 Introduction Depending on the type of semantic representation encoded by the grammar, two main types of algorithms have been proposed for generating sentences with bi-directional, unification-based grammars such as CCG (Combinatory Categorial Grammar, (Espinosa et al., 2010)), HPSG (HeadDriven Phrase Structure Grammar, (Carroll et al., 1999)) and TAG (Tree Adjoining Grammar, (Gardent and Kow, 2005)). For recursive semantic representations such as first-order logic formulae, head-driven algorithms (Shieber et al., 1990) have been argued to be best because they restrict the combinatorics inherent to bottom-up search; they avoid non termination by using lexical items to guide the search ; and they allow for semantically nonmonotonic grammars (i.e., grammars where the semantics of a rule at the left hand side need not be subsumed by the semantics of the rule at the right hand side). One main issue with this approach however is the so-called logical form equivalence problem (Shieber, 1993)."
C12-1124,P07-1042,1,0.960212,"realisation. For HPSG, (Carroll and Oepen, 2005) present a bottom-up, lexicalist, surface realiser which uses a chart based strategy, subsumption-based local ambiguity factoring and a procedure to selectively unpack the generation forest according to a probability distribution given by a conditional, discriminative model. The algorithm is evaluated on the hike treebank, a collection of 330 sentences of instructional text taken from Norwegian tourism brochures with an average length of 12.8 words. Practical generation times average below or around one second for outputs of 15 words. For TAG, (Gardent and Kow, 2007) propose a three step surface realisation algorithm for FB-LTAG (Feature-Based Lexicalised Tree-Adjoining Grammar) where first, a so-called polarity filter is used to prune the initial search space second, substitution is applied to combine trees together and third, adjunction is applied. In essence, polarity filtering filters out combinations of FB-LTAG elementary trees which cover the input semantics but cannot yield a valid parse tree either because a syntactic requirement cannot be satisfied or because a syntactic resource cannot be used. In this way, the exponential impact of lexical ambi"
C12-1124,C10-1042,1,0.696013,"se tree either because a syntactic requirement cannot be satisfied or because a syntactic resource cannot be used. In this way, the exponential impact of lexical ambiguity can be reduced. Furthermore applying substitution before adjunction means that first a skeleton sentence is built before modifiers are adjoined. This permits reducing the combinatorics introduced by intersective modifiers as the multiple intermediate structures they may license do not propagate to the rest of the sentence tree. In practice however, evaluation is restricted to short input and the algorithm fails to scale up (Gardent and Perez-Beltrachini, 2010). (Koller and Striegnitz, 2002) present a surface realisation algorithm where (i) the XTAG FB-LTAG grammar (The XTAG Research Group, 2001) is converted to a dependency grammar capturing the derivation trees of XTAG and (ii) a constraint-based dependency parser is used to construct derivation trees from semantic representations. The parser used was specifically developed for the efficient parsing of free word order languages and is shown to efficiently handle both the lexical ambiguity and the lack of order information in the input that are characteristic of surface realisation from a flat sema"
C12-1124,W11-2833,0,0.0609029,"Missing"
C12-1124,P02-1003,0,0.709703,"irement cannot be satisfied or because a syntactic resource cannot be used. In this way, the exponential impact of lexical ambiguity can be reduced. Furthermore applying substitution before adjunction means that first a skeleton sentence is built before modifiers are adjoined. This permits reducing the combinatorics introduced by intersective modifiers as the multiple intermediate structures they may license do not propagate to the rest of the sentence tree. In practice however, evaluation is restricted to short input and the algorithm fails to scale up (Gardent and Perez-Beltrachini, 2010). (Koller and Striegnitz, 2002) present a surface realisation algorithm where (i) the XTAG FB-LTAG grammar (The XTAG Research Group, 2001) is converted to a dependency grammar capturing the derivation trees of XTAG and (ii) a constraint-based dependency parser is used to construct derivation trees from semantic representations. The parser used was specifically developed for the efficient parsing of free word order languages and is shown to efficiently handle both the lexical ambiguity and the lack of order information in the input that are characteristic of surface realisation from a flat semantics. The evaluation however i"
C12-1124,C96-2103,0,0.530266,"Missing"
C12-1124,W08-2319,0,0.110621,"developed for the efficient parsing of free word order languages and is shown to efficiently handle both the lexical ambiguity and the lack of order information in the input that are characteristic of surface realisation from a flat semantics. The evaluation however is restricted to a few hand constructed example inputs; and the grammar conversion ignores feature structure information. To address these shortcomings, (Gardent and Perez-Beltrachini, 2010) present an approach which makes use of the procedure for converting an FB-LTAG to a Feature-Based Regular Tree Grammar (FB-RTG) described in (Schmitz and Roux, 2008). Like in (Koller and Striegnitz, 2002), the initial FB-LTAG is converted to a grammar of its derivation trees. However in this case, the grammar conversion and the resulting feature-based RTGs accurately translates the full range of unification 2029 mechanisms employed in the initial FB-LTAG. An Earley, bottom-up algorithm is developed and the approach is tested on a large benchmark of artificially constructed examples illustrating different levels of linguistic complexity (different input lengths, different numbers of clauses and of modifiers). The approach is shown to outperform the algorit"
C12-1124,J93-1008,0,0.276547,"t and Kow, 2005)). For recursive semantic representations such as first-order logic formulae, head-driven algorithms (Shieber et al., 1990) have been argued to be best because they restrict the combinatorics inherent to bottom-up search; they avoid non termination by using lexical items to guide the search ; and they allow for semantically nonmonotonic grammars (i.e., grammars where the semantics of a rule at the left hand side need not be subsumed by the semantics of the rule at the right hand side). One main issue with this approach however is the so-called logical form equivalence problem (Shieber, 1993). A logic formula may have several logically equivalent but syntactically distinct formulae. For instance p ∧ q is logically equivalent to q ∧ p. In general though, a grammar will associate with natural language expressions only one of these logically equivalent formula. Hence a generator will be able to produce the natural language expression E only when given the formula φ associated by the grammar with E . For all other formulae logically equivalent to φ , it will fail. Since, the problem of computing logical equivalence for first order logic is undecidable, the problem is quite deep. For f"
C12-1124,J90-1004,0,0.55773,"Missing"
C12-1124,W11-2834,0,0.0199333,"sum, various symbolic and statistical techniques have been developed to improve the efficiency of grammar-based surface realisation. However, statistical systems using supertagging require the existence of a treebank in an appropriate format while the purely symbolic systems described in (Carroll and Oepen, 2005; Gardent and Kow, 2005; Koller and Striegnitz, 2002; Gardent and Perez-Beltrachini, 2010) have not been evaluated on large corpora of arbitrarily long sentences such as provided by the surface realisation (SR) task (Belz et al., 2011). Recently, (Guo et al., 2011; Bohnet et al., 2011; Stent, 2011) have developed statistical dependency realisers that do not make use of an explicit grammar but use cascaded classifiers and n-gram models to map in SR input data to sentences. They obtain the best results in the SR task partly because, for grammar based systems, converting the provided input into the format expected by the grammar proved to be extremely difficult. The algorithm we propose departs from these approaches in that it is a grammar-based approach; it is optimised by combining parallel processing, top-down prediction and local bottom-up polarity filtering; and it was evaluated on a"
C12-1124,C88-2147,0,0.738259,"serts an auxiliary tree into a tree. Derivation in an FB-LTAG yields two trees: a derived tree which is, like for context free grammars, the tree produced by combining the grammar rules (here, the elementary trees) licensed by the input; and a derivation tree which indicates how 2031 the derived tree was built i.e., which elementary trees were used and how they were combined. Figure 3 show the derived and derivation trees associated by the grammar shown in Figure 2 with the sentence “Which fruit has John eaten?”. For a detailed presentation of the FB-LTAG formalism, the reader is referred to (Vijay-Shanker and Joshi, 1988). 4.2 FB-RTG As shown in (Koller and Striegnitz, 2002; Gardent and Perez-Beltrachini, 2010), processing the derivation trees of a given FB-LTAG rather than its derived trees is more efficient. Following (Gardent and Perez-Beltrachini, 2010), we therefore use not the initial FB-LTAG described in the previous section, but the FB-RTG grammar of derivation trees that can be derived from it. That is, the surface realisation algorithm first builds a derivation tree. The generated sentence is then extracted from the derived tree1 which can be reconstructed from this derivation tree using the original"
C12-1124,W00-2004,0,\N,Missing
C16-1141,H05-1042,0,0.0543381,"DBpedia properties that often co-occur are selected together. In contrast, (Lampouras and Androutsopoulos, 2013) assumes that the relevance scores are given. Moreover, while they focus on selecting content that leads to maximally aggregated content, we focus on selecting content that is discourse coherent. Like us, (Biran and McKeown, 2015) focus on DBpedia data and use bigram 1494 models. However their approach investigate discourse planning not content selection and relatedly, the basic units of their bigram models are discourse relations rather than triples. Our approach also differs from (Barzilay and Lapata, 2005) in that it is unsupervised and does not require an aligned data-text corpus. Finally, the work presented here is closely related to a simpler proposal we introduced in (Mohammed et al., 2016). It differs from it in that it defines the notions of chain, sibling and mixed models for ngrams of DBpedia properties; relate them to the notion of topic- and discourse-coherence; and provide a comparative evaluation of their impact on content selection. Integer Linear Programming and NLP. Finally, there has been much work in recent years on using ILP for natural language processing. In particular, (Kuz"
C16-1141,W11-2810,0,0.0183328,"n this way, the proposed approach determines both the order of the events and the discourse relation holding between them. (Lampouras and Androutsopoulos, 2013) present an Integer Linear Programming model of content selection, lexicalisation and aggregation for generating text from OWL ontologies. The objective function used in their ILP model maximises the total importance of selected facts and minimizes the number of distinct elements mentioned in each sentence thereby favouring aggregated sentences i.e., sentences where repeated elements are avoided through e.g., ellipsis or coordination. (Bouayad-Agha et al., 2011) introduces an ontology driven content selection procedure in which a base domain ontology is used to infer new facts. For instance, given the numerical scores of two teams playing in the same game, a result event will be inferred between the winner and the loser and a causal relation will be inferred between the number of goals of a given team and this result event. Content selection proceeds in three steps. First, a set of hand written rules is used to select a subset of the knowledge base. Second, relevance scores learned from a parallel data/text corpus are used to select the most relevant"
C16-1141,W08-1105,0,0.0381561,"to a simpler proposal we introduced in (Mohammed et al., 2016). It differs from it in that it defines the notions of chain, sibling and mixed models for ngrams of DBpedia properties; relate them to the notion of topic- and discourse-coherence; and provide a comparative evaluation of their impact on content selection. Integer Linear Programming and NLP. Finally, there has been much work in recent years on using ILP for natural language processing. In particular, (Kuznetsova et al., 2012) proposes an ILP formulation for the generation of natural image descriptions from visual and text data and (Filippova and Strube, 2008) uses ILP to model sentence compression. The ILP formulation of our content selection method is most similar to that proposed for sentence compression in (Filippova and Strube, 2008). One important difference though is both the application (content selection rather than sentence compression) and the way in which relevance is computed. While (Filippova and Strube, 2008) uses weights derived from a treebank to determine the relative importance of an edge, we use bigram models over DBpedia properties to estimate the relative importance of DBpedia triples. 3 Task and Method Given an entity e of ca"
C16-1141,P12-1038,0,0.0255346,"05) in that it is unsupervised and does not require an aligned data-text corpus. Finally, the work presented here is closely related to a simpler proposal we introduced in (Mohammed et al., 2016). It differs from it in that it defines the notions of chain, sibling and mixed models for ngrams of DBpedia properties; relate them to the notion of topic- and discourse-coherence; and provide a comparative evaluation of their impact on content selection. Integer Linear Programming and NLP. Finally, there has been much work in recent years on using ILP for natural language processing. In particular, (Kuznetsova et al., 2012) proposes an ILP formulation for the generation of natural image descriptions from visual and text data and (Filippova and Strube, 2008) uses ILP to model sentence compression. The ILP formulation of our content selection method is most similar to that proposed for sentence compression in (Filippova and Strube, 2008). One important difference though is both the application (content selection rather than sentence compression) and the way in which relevance is computed. While (Filippova and Strube, 2008) uses weights derived from a treebank to determine the relative importance of an edge, we use"
C16-1141,P13-2100,0,0.125699,"ith discourse relations. For instance, if two triples share the same predicate and object, an expansion relation is added between the two triples (e.g., “John has a ball. Mary also has a ball”). Discourse planning then consists in finding a path through the resulting multigraphs of potential relations between DBpedia triples using an bigram model over discourse relations. Good discourse plans are those which maximise the probability of a sequence of discourse relations. In this way, the proposed approach determines both the order of the events and the discourse relation holding between them. (Lampouras and Androutsopoulos, 2013) present an Integer Linear Programming model of content selection, lexicalisation and aggregation for generating text from OWL ontologies. The objective function used in their ILP model maximises the total importance of selected facts and minimizes the number of distinct elements mentioned in each sentence thereby favouring aggregated sentences i.e., sentences where repeated elements are avoided through e.g., ellipsis or coordination. (Bouayad-Agha et al., 2011) introduces an ontology driven content selection procedure in which a base domain ontology is used to infer new facts. For instance, g"
C16-1141,W16-6616,1,0.347676,"g content that leads to maximally aggregated content, we focus on selecting content that is discourse coherent. Like us, (Biran and McKeown, 2015) focus on DBpedia data and use bigram 1494 models. However their approach investigate discourse planning not content selection and relatedly, the basic units of their bigram models are discourse relations rather than triples. Our approach also differs from (Barzilay and Lapata, 2005) in that it is unsupervised and does not require an aligned data-text corpus. Finally, the work presented here is closely related to a simpler proposal we introduced in (Mohammed et al., 2016). It differs from it in that it defines the notions of chain, sibling and mixed models for ngrams of DBpedia properties; relate them to the notion of topic- and discourse-coherence; and provide a comparative evaluation of their impact on content selection. Integer Linear Programming and NLP. Finally, there has been much work in recent years on using ILP for natural language processing. In particular, (Kuznetsova et al., 2012) proposes an ILP formulation for the generation of natural image descriptions from visual and text data and (Filippova and Strube, 2008) uses ILP to model sentence compres"
C90-2022,C88-2128,0,0.140432,"Missing"
C90-2022,E89-1032,0,\N,Missing
C90-2022,P89-1034,1,\N,Missing
C90-2022,P89-1002,0,\N,Missing
C96-1073,P96-1001,1,0.50428,"Missing"
D13-1076,W11-2006,0,0.0598394,"data is better data) ; balanced (similar amount of data for each class targeted by the classifier) and varied (it should encompass the largest possible number of paraphrases and synonyms for the utterances of each class). In this paper, we explore different ways of improving and complementing the training data of a Related work Previous work on improving robustness of supervised dialog systems includes detecting and handling out of domain utterances for generating feedback (Lane et al., 2004) ; using domain-restricted lexical semantics (Hardy et al., 2004) ; and work on manual data expansion (DeVault et al., 2011). Our work follows up on this research but provides a systematic investigation of how data expansion, lemmatisation and synonym handling impacts the performance of a supervised QA engine. 3 Experimental Setup We run our experiments on a dialog engine developed for a serious game called Mission Plastechnologie. In this game, the player must interact with different virtual humans through a sequence of 12 subdialogs, each of them occurring in a different part of the virtual world. Training Data. The training corpus consists of around 1250 Human-Human dialogues which were manually annotated with d"
D13-1076,P04-1010,0,0.0210872,"d. In sum, the ideal training data should be large (more data is better data) ; balanced (similar amount of data for each class targeted by the classifier) and varied (it should encompass the largest possible number of paraphrases and synonyms for the utterances of each class). In this paper, we explore different ways of improving and complementing the training data of a Related work Previous work on improving robustness of supervised dialog systems includes detecting and handling out of domain utterances for generating feedback (Lane et al., 2004) ; using domain-restricted lexical semantics (Hardy et al., 2004) ; and work on manual data expansion (DeVault et al., 2011). Our work follows up on this research but provides a systematic investigation of how data expansion, lemmatisation and synonym handling impacts the performance of a supervised QA engine. 3 Experimental Setup We run our experiments on a dialog engine developed for a serious game called Mission Plastechnologie. In this game, the player must interact with different virtual humans through a sequence of 12 subdialogs, each of them occurring in a different part of the virtual world. Training Data. The training corpus consists of around 1250"
D13-1076,rojas-barahona-etal-2012-building,1,0.765532,"Training Data. The training corpus consists of around 1250 Human-Human dialogues which were manually annotated with dialog moves. As the following dialog excerpt illustrates, the dialogs are conducted in French and each dialog turn is manually annotated using a set of 28 dialog acts. For 808 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 808–813, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics a more detailed presentation of the training corpus and of the annotation scheme, the reader is referred to (Rojas-Barahona et al., 2012a) dialog : 01_dialogDirecteur-Tue Jun 14 11 :04 :23 2011 &gt;M.Jasper : Bonjour, je suis M.Jasper le directeur. ||greet (Hello, I am the director, Mr. Jasper.) &gt;M.Jasper : Qu’est-ce que je peux faire pour vous ? ||ask(task(X)) (What can I do for you ?) &gt;Lucas : je dois sauver mon oncle ||first_step (I must rescue my uncle) &gt;M.Jasper : Pour faire votre manette, il vous faut des plans. Allez voir dans le bureau d’études, ils devraient y être. ||inform(do(first_step)) (To build the joystick you will need the plans. You will find them in the Designing Office.) &gt;M.Jasper : Bonne Chance ! ||quit (Good"
D13-1076,W12-1602,1,0.850296,"ng Data. The training corpus consists of around 1250 Human-Human dialogues which were manually annotated with dialog moves. As the following dialog excerpt illustrates, the dialogs are conducted in French and each dialog turn is manually annotated using a set of 28 dialog acts. For 808 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 808–813, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics a more detailed presentation of the training corpus and of the annotation scheme, the reader is referred to (Rojas-Barahona et al., 2012a) dialog : 01_dialogDirecteur-Tue Jun 14 11 :04 :23 2011 &gt;M.Jasper : Bonjour, je suis M.Jasper le directeur. ||greet (Hello, I am the director, Mr. Jasper.) &gt;M.Jasper : Qu’est-ce que je peux faire pour vous ? ||ask(task(X)) (What can I do for you ?) &gt;Lucas : je dois sauver mon oncle ||first_step (I must rescue my uncle) &gt;M.Jasper : Pour faire votre manette, il vous faut des plans. Allez voir dans le bureau d’études, ils devraient y être. ||inform(do(first_step)) (To build the joystick you will need the plans. You will find them in the Designing Office.) &gt;M.Jasper : Bonne Chance ! ||quit (Good"
D13-1076,N09-2014,0,0.0211095,"odels for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode. 2 1 Introduction One strand of work in dialog research targets the rapid prototyping of virtual humans capable of conducting a conversation with humans in the context of a virtual world. In particular, question answering (QA) characters can respond to a restricted set of topics after training on a set of dialogs whose utterances are annotated with dialogue acts (Leuski and Traum, 2008). As argued in (Sagae et al., 2009), the size of the training corpus is a major factor in allowing QA characters that are both robust and accurate. In addition, the training corpus should arguably be of good quality in that (i) it should contain the various ways of expressing the same content (paraphrases) and (ii) the data should not be skewed. In sum, the ideal training data should be large (more data is better data) ; balanced (similar amount of data for each class targeted by the classifier) and varied (it should encompass the largest possible number of paraphrases and synonyms for the utterances of each class). In this pap"
D13-1076,sagot-2010-lefff,0,0.0128852,"ds are compared. We use the POS tag provided by TreeTagger. In this case, disambiguation is syntactic only. Or we pick the synonym with highest probability based on a trigram language model trained on the H-H corpus 9 . 5 Results and Discussion Table 2 summarises the results obtained in four main configurations : (i) with and without paraphrases ; (ii) with and without synonym handling ; (iii) with and without lemmatisation ; and (iv) when 5. A word is determined to be a well-formed French word if it occurs in the LEFFF dictionary, a large-scale morphological and syntactic lexicon for French (Sagot, 2010) 6. DICOSYN (http ://elsap1.unicaen.fr/dicosyn.html). 7. We also used distributional semantics from the Gigaword corpus but the results were poor probably because of the very different text genre and domains between the the Gigaword and the MP game. 8. Topics are Dialog acts while documents are utterances ; we used the S-Space Package http://code.google.com/p/ airhead-research/wiki/RandomIndexing 9. We used SRILM (http://www.speech.sri.com/ projects/srilm) 811 combining lemmatisation with synonym handling. We also compare the results obtained when evaluating using 10-fold cross validation on t"
D17-1064,C10-1037,0,0.0810355,"Missing"
D17-1064,D15-1042,0,0.0886682,"Missing"
D17-1064,P05-1074,0,0.0497637,"B, UK ‡ CNRS, LORIA, UMR 7503, Vandoeuvre-l`es-Nancy, F-54500, France shashi.narayan@ed.ac.uk claire.gardent@loria.fr scohen@inf.ed.ac.uk anastasia.shimorina@loria.fr Abstract Strube, 2008; Pitler, 2010; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sent"
D17-1064,W08-1105,0,0.143307,"Missing"
D17-1064,P01-1008,0,0.114122,"ton Street, Edinburgh EH8 9AB, UK ‡ CNRS, LORIA, UMR 7503, Vandoeuvre-l`es-Nancy, F-54500, France shashi.narayan@ed.ac.uk claire.gardent@loria.fr scohen@inf.ed.ac.uk anastasia.shimorina@loria.fr Abstract Strube, 2008; Pitler, 2010; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operatio"
D17-1064,D11-1108,0,0.0392016,"Missing"
D17-1064,P16-2055,0,0.0228674,"Missing"
D17-1064,E99-1042,0,0.232209,"(Rephr.) and meaning preserving (MPre.) operations (Y: yes, N: No, ?Y: should do but most existing approaches do not). ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel´ınek, 2014), semantic role labelers (Vickrey and Koller, 2008) and statistical machine translation (SMT) systems (Chandrasekar et al., 1996). In addition, because it allows the conversion of longer sentences into shorter ones, it should also be of use for people with reading disabilities (Inui et al., 2003) such as aphasia patients (Carroll et al., 1999), low-literacy readers (Watanabe et al., 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010). 2 Related Work We briefly review previous work on sentence splitting and rephrasing. Sentence Splitting. Of the four sentence rewriting tasks (paraphrasing, fusion, compression and simplification) mentioned above, only sentence simplification involves sentence splitting. Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the parallel dataset"
D17-1064,P17-1017,1,0.850809,"Missing"
D17-1064,C96-2183,0,0.729533,"kes the input complex sentence into account when generating while the other does not. Table 1: Similarities and differences between sentence rewriting tasks with respect to splitting (Split), deletion (Delete), rephrasing (Rephr.) and meaning preserving (MPre.) operations (Y: yes, N: No, ?Y: should do but most existing approaches do not). ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel´ınek, 2014), semantic role labelers (Vickrey and Koller, 2008) and statistical machine translation (SMT) systems (Chandrasekar et al., 1996). In addition, because it allows the conversion of longer sentences into shorter ones, it should also be of use for people with reading disabilities (Inui et al., 2003) such as aphasia patients (Carroll et al., 1999), low-literacy readers (Watanabe et al., 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010). 2 Related Work We briefly review previous work on sentence splitting and rephrasing. Sentence Splitting. Of the four sentence rewriting tasks (paraphrasing, fusion, compression and simplification) mentioned above, only sentence simplification involves sent"
D17-1064,W03-1602,0,0.291741,"itting (Split), deletion (Delete), rephrasing (Rephr.) and meaning preserving (MPre.) operations (Y: yes, N: No, ?Y: should do but most existing approaches do not). ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel´ınek, 2014), semantic role labelers (Vickrey and Koller, 2008) and statistical machine translation (SMT) systems (Chandrasekar et al., 1996). In addition, because it allows the conversion of longer sentences into shorter ones, it should also be of use for people with reading disabilities (Inui et al., 2003) such as aphasia patients (Carroll et al., 1999), low-literacy readers (Watanabe et al., 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010). 2 Related Work We briefly review previous work on sentence splitting and rephrasing. Sentence Splitting. Of the four sentence rewriting tasks (paraphrasing, fusion, compression and simplification) mentioned above, only sentence simplification involves sentence splitting. Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Naray"
D17-1064,C08-1018,0,0.0473474,"e and make available a benchmark consisting of 1,066,115 tuples mapping a single complex sentence to a sequence of sentences expressing the same meaning.1 Second, we propose five models (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task. 1 Introduction Several sentence rewriting operations have been extensively discussed in the literature: sentence compression, multi-sentence fusion, sentence paraphrasing and sentence simplification. Sentence compression rewrites an input sentence into a shorter paraphrase (Knight and Marcu, 2000; Cohn and Lapata, 2008; Filippova and 1 The Split-and-Rephrase dataset is available here: https://github.com/shashiongithub/ Split-and-Rephrase. 606 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 606–616 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics Compression Fusion Paraphrasing Simplification Split-and-Rephrase Split N N N Y Y Delete Y Y N Y N Rephr. ?Y Y Y Y Y MPre. N ?Y Y N Y ing. This allows for the learning of semanticallyinformed models (cf. Section 5). Our second contribution is to provide five models to understand"
D17-1064,jelinek-2014-improvements,0,0.112961,"Missing"
D17-1064,W11-1601,0,0.0946978,"Missing"
D17-1064,W04-1016,0,0.0257937,"Missing"
D17-1064,D15-1166,0,0.0302707,"Missing"
D17-1064,E17-1083,0,0.0153724,"-54500, France shashi.narayan@ed.ac.uk claire.gardent@loria.fr scohen@inf.ed.ac.uk anastasia.shimorina@loria.fr Abstract Strube, 2008; Pitler, 2010; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new"
D17-1064,N06-2009,0,0.107081,"Missing"
D17-1064,P14-5010,0,0.00544315,"Missing"
D17-1064,J11-1007,0,0.0187072,"les) of the complex sentence into smaller units and then generate a text for each RDF subset in that partition. One model is multi-source and takes the input complex sentence into account when generating while the other does not. Table 1: Similarities and differences between sentence rewriting tasks with respect to splitting (Split), deletion (Delete), rephrasing (Rephr.) and meaning preserving (MPre.) operations (Y: yes, N: No, ?Y: should do but most existing approaches do not). ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel´ınek, 2014), semantic role labelers (Vickrey and Koller, 2008) and statistical machine translation (SMT) systems (Chandrasekar et al., 1996). In addition, because it allows the conversion of longer sentences into shorter ones, it should also be of use for people with reading disabilities (Inui et al., 2003) such as aphasia patients (Carroll et al., 1999), low-literacy readers (Watanabe et al., 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010). 2 Related Work We briefly review previous work on sentence splitting and rephrasing. Sentence Splitting. Of th"
D17-1064,I13-1198,0,0.0149176,"i Narayan† Claire Gardent‡ Shay B. Cohen† Anastasia Shimorina‡ School of Informatics, University of Edinburgh, 10 Crichton Street, Edinburgh EH8 9AB, UK ‡ CNRS, LORIA, UMR 7503, Vandoeuvre-l`es-Nancy, F-54500, France shashi.narayan@ed.ac.uk claire.gardent@loria.fr scohen@inf.ed.ac.uk anastasia.shimorina@loria.fr Abstract Strube, 2008; Pitler, 2010; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all f"
D17-1064,N10-1044,0,0.0303032,"Missing"
D17-1064,P14-1041,1,0.893088,"consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences while preserving meaning. In that task, the emphasis is on sentence splitting"
D17-1064,W16-6620,1,0.862186,"with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences while preserving meaning. In that task, the emphasis is on sentence splitting and rephrasing. There is no deletion and no"
D17-1064,D16-1033,0,0.0899926,"Missing"
D17-1064,W16-6625,1,0.901333,"Missing"
D17-1064,P08-1040,0,0.140872,"text for each RDF subset in that partition. One model is multi-source and takes the input complex sentence into account when generating while the other does not. Table 1: Similarities and differences between sentence rewriting tasks with respect to splitting (Split), deletion (Delete), rephrasing (Rephr.) and meaning preserving (MPre.) operations (Y: yes, N: No, ?Y: should do but most existing approaches do not). ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel´ınek, 2014), semantic role labelers (Vickrey and Koller, 2008) and statistical machine translation (SMT) systems (Chandrasekar et al., 1996). In addition, because it allows the conversion of longer sentences into shorter ones, it should also be of use for people with reading disabilities (Inui et al., 2003) such as aphasia patients (Carroll et al., 1999), low-literacy readers (Watanabe et al., 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010). 2 Related Work We briefly review previous work on sentence splitting and rephrasing. Sentence Splitting. Of the four sentence rewriting tasks (paraphrasing, fusion, compression a"
D17-1064,P02-1040,0,0.0989634,"Missing"
D17-1064,W04-3219,0,0.196979,"Missing"
D17-1064,D11-1038,0,0.13372,", 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences while preserving meaning. In"
D17-1064,P02-1006,0,0.0227466,"Missing"
D17-1064,P12-1107,0,0.137343,"Missing"
D17-1064,D15-1044,0,0.0384958,"Missing"
D17-1064,W10-4223,0,0.0690832,"Missing"
D17-1064,P15-1152,0,0.0512972,"Missing"
D17-1064,Q15-1021,0,0.06186,"or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences while preserving meaning. In that task, the emphasis is on sentence splitting and rephrasing."
D17-1064,Q16-1029,0,0.184709,"Missing"
D17-1064,W10-4213,0,0.073206,"Missing"
D17-1064,W11-2802,0,0.0930787,"Missing"
D17-1064,D17-1062,0,0.0548473,"on content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences while preserving meaning. In that task, the emphasis is on sentence splitting and rephrasing. There is no deletion and no lexical or phrasal simpl"
D17-1064,E14-1076,0,0.254892,"Missing"
D17-1064,P08-1089,0,0.0467264,"Missing"
D17-1064,C04-1129,0,0.059261,"Strube, 2008; Pitler, 2010; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into sh"
D17-1064,C10-1152,0,0.335065,"; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details (McKeown et al., 2010; Filippova, 2010; Thadani and McKeown, 2013). Sentence paraphrasing aims to rewrite a sentence while preserving its meaning (Dras, 1999; Barzilay and McKeown, 2001; Bannard and Callison-Burch, 2005; Wubben et al., 2010; Mallinson et al., 2017). Finally, sentence (or text) simplification aims to produce a text that is easier to understand (Siddharthan et al., 2004; Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2015; Narayan and Gardent, 2016; Zhang and Lapata, 2017). Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion. We propose a new sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences wh"
D17-1064,N16-1004,0,0.034648,"Missing"
D17-1064,P07-2009,0,\N,Missing
D18-1113,P17-4012,0,0.0463322,"Missing"
D18-1113,P18-2114,0,0.0308242,"itional T2T and D2T models both in terms of linguistic adequacy (higher BLEU score) and in terms of diversity (higher number of distinct output per meaning, lower similarity between texts generated from the same meaning). The comparison with T2T generation is particularly striking as the training data is 3 to 5 times larger for the T2Tsyn model than for the TXsyn and the TRsyn model respectively. Similarly, it is noticable that although the T2Tsyn training corpus is 3 times larger than the D2Tsyn corpus, the T2Tsyn and the D2Tsyn models show similar results. This is in line with results from (Aharoni and Goldberg, 2018) which shows that rephrasing is a difficult task. Linguistic Adequacy. Overall the linguistic adequacy of the syntactically constrained models is high with a BLEU score with respect to a single reference ranging from 46.20 (D2Tsyn ) to 83.87 (TXsyn ). Moreover, the generated sentences show close similarity with the reference sentence realising the input constraint (BLEUsyn : from 48.16 to 89.32). 2∗match(S1,S2) formula sim(S1, S2) = len(S1)+len(S2) where a match is defined as the sum of Pthe length of the matching segments (match(S1, S2) = m∈overlap(S1,S2) len(m). 3 We use the sacrebleu script"
D18-1113,W03-1601,0,0.0678234,"show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based"
D18-1113,P14-1133,0,0.0418402,"tistical Machine Translation system (SMT) on three tasks, namely, correlation with human judgments of paraphrase quality; paraphrase and similarity detection; and sentence-level paraphrase generation. (Iyyer et al., 2018) also use backtranslation as a mean to provide training data. In addition, it uses syntax to control paraphrase generation. Given Introduction The ability to automatically generate paraphrases (alternative phrasings of the same content) has been shown to be useful in many areas of Natural Language Processing such as question answering (Riezler et al., 2007), semantic parsing (Berant and Liang, 2014)), machine translation (Kauchak and Barzilay, 2006; Zhou et al., 2006), sentence compression (Napoles et al., 2011) and sentence representation (Wieting et al., 2015). From a linguistic standpoint, the automatic generation of paraphrases is an important task in its own right as it demonstrates the capacity of NLP techniques to handle a key feature of natural language. In this paper, we focus on the automatic generation of syntactic paraphrases that is, texts which share the same meaning but differ in their syntax. Our work makes the following contributions. We show that conditioning text gener"
D18-1113,D08-1021,0,0.0315016,"of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on three datasets (PPDB, WikiAnswers, and MSCOCO). (Mallinson et al., 2017) introduces a neural model for multi-lingual, multi-pivot backtranslation and show th"
D18-1113,W07-0716,0,0.184771,"ta for each of these tasks from the WebNLG dataset and we show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that t"
D18-1113,ganitkevitch-callison-burch-2014-multilingual,0,0.014373,"or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on three datasets (PPDB, WikiAnswers, and MSCOCO). (Mallinson et al., 2017) introduces a neural model for multi-lingual, multi-pivot backtranslation and show that it outperforms a paraphrase model tr"
D18-1113,E17-1083,0,0.139884,"ree main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on three datasets (PPDB, WikiAnswers, and MSCOCO). (Mallinson et al., 2017) introduces a neural model for multi-lingual, multi-pivot backtranslation and show that it outperforms a paraphrase model trained with a commonly used Statistical Machine Translation system (SMT) on three tasks, namely, correlation with human judgments of paraphrase quality; paraphrase"
D18-1113,D11-1108,0,0.0328796,"Missing"
D18-1113,J83-1001,0,0.457207,"asks from the WebNLG dataset and we show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outp"
D18-1113,P17-1017,1,0.89368,"Missing"
D18-1113,W11-1610,0,0.0580736,"Missing"
D18-1113,S07-1091,0,0.0439985,"ebNLG dataset and we show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to s"
D18-1113,P02-1040,0,0.101097,"linguistic/syntactic adequacy of the generated texts and the diversity of the paraphrases being generated. Syntactic and Linguistic Adequacy (BLEU, Synt, BLEUsyn ). For the syntactically constrained models, given an input syntactic constraint k, the BLEU score3 is computed with respect to those references which satisfy k. In that way, the BLEU score indicates how close to the syntactic target the generated sentence is and therefore how well the model succeeds in generating the required syntactic constructs – as the number of references varies across inputs, we use BLEU at the sentence level (Papineni et al., 2002). In addition, we compute the proportion of output satisfying the input syntactic constraint (Synt) and the BLEU score for these output which satisfy the input syntactic constraint (BLEUsyn ). The number of output satisfying the input syntactic constraint is computed by first parsing the generated output and then applying the templates used for the automatic annotation of the training data. Diversity (Sim, #Txt/Mg). To measure the level of paraphrasing obtained, we group together inputs which share the same meaning (i.e., inputs that are linked in the W EB NLG dataset to the same set of RDF tr"
D18-1113,N18-1170,0,0.14162,"l LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on three datasets (PPDB, WikiAnswers, and MSCOCO). (Mallinson et al., 2017) introduces a neural model for multi-lingual, multi-pivot backtranslation and show that it outperforms a paraphrase model trained with a commonly used Statistical Machine Translation system (SMT) on three tasks, namely, correlation with human judgments of paraphrase quality; paraphrase and similarity detection; and sentence-level paraphrase generation. (Iyyer et al., 2018) also use backtranslation as a mean to provide training data. In addition, it uses syntax to control paraphrase generation. Given Introduction The ability to automatically generate paraphrases (alternative phrasings of the same content) has been shown to be useful in many areas of Natural Language Processing such as question answering (Riezler et al., 2007), semantic parsing (Berant and Liang, 2014)), machine translation (Kauchak and Barzilay, 2006; Zhou et al., 2006), sentence compression (Napoles et al., 2011) and sentence representation (Wieting et al., 2015). From a linguistic standpoint,"
D18-1113,W12-2017,1,0.811692,"Missing"
D18-1113,C16-1275,0,0.154061,"ainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on three datasets (PPDB, WikiAnswers, and MSCOCO). (Mallinson et al., 2017) introduces a neural model for multi-lingual, multi-pivot backtranslation and show that it outperforms a paraphrase model trained with a commonly used Statistical Machine Translation system (SMT) on three tasks, namely, correlation with human judgments of paraphrase quality; paraphrase and similarity detecti"
D18-1113,N06-1058,0,0.0949182,"ree tasks, namely, correlation with human judgments of paraphrase quality; paraphrase and similarity detection; and sentence-level paraphrase generation. (Iyyer et al., 2018) also use backtranslation as a mean to provide training data. In addition, it uses syntax to control paraphrase generation. Given Introduction The ability to automatically generate paraphrases (alternative phrasings of the same content) has been shown to be useful in many areas of Natural Language Processing such as question answering (Riezler et al., 2007), semantic parsing (Berant and Liang, 2014)), machine translation (Kauchak and Barzilay, 2006; Zhou et al., 2006), sentence compression (Napoles et al., 2011) and sentence representation (Wieting et al., 2015). From a linguistic standpoint, the automatic generation of paraphrases is an important task in its own right as it demonstrates the capacity of NLP techniques to handle a key feature of natural language. In this paper, we focus on the automatic generation of syntactic paraphrases that is, texts which share the same meaning but differ in their syntax. Our work makes the following contributions. We show that conditioning text generation on syntactic information permits generating"
D18-1113,W04-3219,0,0.109069,"ng generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directiona"
D18-1113,P07-1059,0,0.0352302,"se model trained with a commonly used Statistical Machine Translation system (SMT) on three tasks, namely, correlation with human judgments of paraphrase quality; paraphrase and similarity detection; and sentence-level paraphrase generation. (Iyyer et al., 2018) also use backtranslation as a mean to provide training data. In addition, it uses syntax to control paraphrase generation. Given Introduction The ability to automatically generate paraphrases (alternative phrasings of the same content) has been shown to be useful in many areas of Natural Language Processing such as question answering (Riezler et al., 2007), semantic parsing (Berant and Liang, 2014)), machine translation (Kauchak and Barzilay, 2006; Zhou et al., 2006), sentence compression (Napoles et al., 2011) and sentence representation (Wieting et al., 2015). From a linguistic standpoint, the automatic generation of paraphrases is an important task in its own right as it demonstrates the capacity of NLP techniques to handle a key feature of natural language. In this paper, we focus on the automatic generation of syntactic paraphrases that is, texts which share the same meaning but differ in their syntax. Our work makes the following contribu"
D18-1113,D17-1066,0,0.0319821,"ase of S which realises the input syntactic template T . Our approach is closest to (Iyyer et al., 2018) but differs from it in that instead of restricting paraphrase generation to a text rewriting problem, we explore how various sources of input impacts the number and the type of generated paraphrases. It also differs from the former two approaches (Prakash et al., 2016; Mallinson et al., 2017) in that we focus on syntactic paraphrases and condition generation on syntax. In that sense, our approach also shares similarities with recent models for controllable text generation (Hu et al., 2017; Semeniuta et al., 2017), which use variational autoencoders to model holistic properties of sentences such as style, topic and various other syntactic features. Our work is arguably conceptually simpler, focuses on syntactic paraphrases and introduces a new text production mode based on hybrid “data and text” input. 3 We derive training corpora for syntactically constrained generation from this dataset as follows. We enrich the W EB NLG texts with labels indicating syntactic structures that are realised by these texts by first, parsing1 these texts and then using syntactic templates to identify the target structures"
D18-1113,Q15-1025,0,0.0260859,"nce-level paraphrase generation. (Iyyer et al., 2018) also use backtranslation as a mean to provide training data. In addition, it uses syntax to control paraphrase generation. Given Introduction The ability to automatically generate paraphrases (alternative phrasings of the same content) has been shown to be useful in many areas of Natural Language Processing such as question answering (Riezler et al., 2007), semantic parsing (Berant and Liang, 2014)), machine translation (Kauchak and Barzilay, 2006; Zhou et al., 2006), sentence compression (Napoles et al., 2011) and sentence representation (Wieting et al., 2015). From a linguistic standpoint, the automatic generation of paraphrases is an important task in its own right as it demonstrates the capacity of NLP techniques to handle a key feature of natural language. In this paper, we focus on the automatic generation of syntactic paraphrases that is, texts which share the same meaning but differ in their syntax. Our work makes the following contributions. We show that conditioning text generation on syntactic information permits generating distinct syntactic paraphrases for the same input. We provide a systematic exploration of how different types of gen"
D18-1113,P08-1116,0,0.0335434,"tactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input. 1 2 Related Work Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016). (Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on thre"
D18-1113,W06-1610,0,0.0378896,"Missing"
D19-1305,W18-3604,0,0.146317,"ly in the English track. For word ordering, five teams chose an approach based on neural networks, two used a 3086 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, and one used an SMT system (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). Overall, neural components were dominant across all the participants. However, official scores of the teams that went neural greatly differ. Furthermore, two teams (Elder and Hokamp, 2018; Sobrevilla Cabezudo and Pardo, 2018) applied data augmentation, which makes their results not strictly comparable to others. One of the interesting findings of the shared task is reported by Elder and Hokamp (2018) who showed that applying standard neural"
D19-1305,P17-1183,0,0.0301799,"tep of our surface realisation pipeline. Example 2 shows some types of contractions. (2) French: “Le chat dort.” / “L’alouette chante.” (Elision for the definite article le before a vowel: Le → L’) Italian: *“In il mare.” → “Nel mare.” (Contraction of the preposition in and the article il: In il → Nel) Portuguese: *“Eis lo.” → “Ei-lo.” (Clitic pronoun attachment: Eis lo → Ei-lo) Morphological Realisation The morphological realisation (MR) module consists in producing inflected word forms based on lemmas coupled with morphological features. For that module, we used a model recently proposed by Aharoni and Goldberg (2017), which achieves state-of-the-art results on several morphological inflection datasets: the CELEX dataset (Baayen et al., 1993; Dreyer et al., 2008), the Wiktionary dataset (Durrett and DeNero, 2013) and the SIGMORPHON2016 dataset (Cotterell et al., 2016). Their model is based on a neural encoder-decoder architecture with hard monotonic attention and performs out-of-context morphologic realisation: given a lemma and a set of morpho-syntactic features, it produces a corresponding word form. We trained the model of Aharoni and Goldberg (2017) on (lemma+morpho-syntactic features4 , form) pairs ex"
D19-1305,N06-2001,0,0.217698,"identifier is assigned to the nodes. More generally, after linearisation through depth-first, left-to-right traversal of the input tree, each training instance captures the mapping between lemmas in the input tree and the same lemmas in the output sequence. For instance, given the example shown in Figure 1, delexicalisation will yield the training instance: Input: tkn2 tkn3 tkn4 tkn1 Output: tkn4 tkn1 tkn3 tkn2 where tkni is the factored representation (see below) of each delexicalised input node. Factored Sequence-to-Sequence Model. Following Elder and Hokamp (2018), we use a factored model (Alexandrescu and Kirchhoff, 2006) as a means of enriching the node representations input to the neural model. Each delexicalised tree node is modelled by a sequence of features. Separate embeddings are learned for each feature type and the feature embeddings of each input node are concatenated to create its dense representation. As exemplified in Figure 1, we model each input placeholder as a concatenation of four features: the node identifier, its POS tag, its dependency relation to the parent node and its parent identifier2 . Sequence-to-sequence model. We use the OpenNMT-py framework (Klein et al., 2017)3 to train factored"
D19-1305,W18-3609,0,0.164325,"h, however, they participated only in the English track. For word ordering, five teams chose an approach based on neural networks, two used a 3086 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, and one used an SMT system (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). Overall, neural components were dominant across all the participants. However, official scores of the teams that went neural greatly differ. Furthermore, two teams (Elder and Hokamp, 2018; Sobrevilla Cabezudo and Pardo, 2018) applied data augmentation, which makes their results not strictly comparable to others. One of the interesting findings of the shared task is reported by Elder and Hokamp (2018) who showed"
D19-1305,W11-2832,0,0.0976194,"s for an analysis of how well these models handle languages with different morphological and topological properties. The SR’18 shared task includes two tracks: a shallow track where the input is an unordered, lemmatised dependency tree and a deep track Related Work Early approaches for surface realisation adopted statistical methods, including both pipelined (Bohnet et al., 2010) and joint (Song et al., 2014; Puduppully et al., 2017) architecture for word ordering and morphological generation. Multilingual SR’18 was preceded by the SR’11 surface realisation task for the English language only (Belz et al., 2011). The submitted systems in 2011 had grammar-based and statistical nature, mostly relying on pipelined architecture. Recently, Marcheggiani and PerezBeltrachini (2018) proposed a neural end-to-end approach based on graph convolutional encoders for the SR’11 deep track. The SR’18 shallow track received submissions from eight teams with seven of them dividing the task into two subtasks: word ordering and inflection. Only Elder and Hokamp (2018) developed a joint approach, however, they participated only in the English track. For word ordering, five teams chose an approach based on neural networks"
D19-1305,C10-1012,0,0.0300132,"sentation, the SR’18 Surface Realisation shared task (Mille et al., 2018) allows for a detailed evaluation and comparison of surface realisation models. Moreover, as it provides training and test data for multiple languages, it also allows for an analysis of how well these models handle languages with different morphological and topological properties. The SR’18 shared task includes two tracks: a shallow track where the input is an unordered, lemmatised dependency tree and a deep track Related Work Early approaches for surface realisation adopted statistical methods, including both pipelined (Bohnet et al., 2010) and joint (Song et al., 2014; Puduppully et al., 2017) architecture for word ordering and morphological generation. Multilingual SR’18 was preceded by the SR’11 surface realisation task for the English language only (Belz et al., 2011). The submitted systems in 2011 had grammar-based and statistical nature, mostly relying on pipelined architecture. Recently, Marcheggiani and PerezBeltrachini (2018) proposed a neural end-to-end approach based on graph convolutional encoders for the SR’11 deep track. The SR’18 shallow track received submissions from eight teams with seven of them dividing the t"
D19-1305,Q17-1010,0,0.100026,"Missing"
D19-1305,D08-1113,0,0.106958,"Missing"
D19-1305,N13-1138,0,0.0288755,"lian: *“In il mare.” → “Nel mare.” (Contraction of the preposition in and the article il: In il → Nel) Portuguese: *“Eis lo.” → “Ei-lo.” (Clitic pronoun attachment: Eis lo → Ei-lo) Morphological Realisation The morphological realisation (MR) module consists in producing inflected word forms based on lemmas coupled with morphological features. For that module, we used a model recently proposed by Aharoni and Goldberg (2017), which achieves state-of-the-art results on several morphological inflection datasets: the CELEX dataset (Baayen et al., 1993; Dreyer et al., 2008), the Wiktionary dataset (Durrett and DeNero, 2013) and the SIGMORPHON2016 dataset (Cotterell et al., 2016). Their model is based on a neural encoder-decoder architecture with hard monotonic attention and performs out-of-context morphologic realisation: given a lemma and a set of morpho-syntactic features, it produces a corresponding word form. We trained the model of Aharoni and Goldberg (2017) on (lemma+morpho-syntactic features4 , form) pairs extracted from the SR’18 training data. We trained the model for 20 epochs with the default parameters provided in the implementation5 . In our pipeline architecture, morphological realisation is appli"
D19-1305,P15-1044,0,0.0340531,"Missing"
D19-1305,W18-3606,0,0.404733,"chitecture for word ordering and morphological generation. Multilingual SR’18 was preceded by the SR’11 surface realisation task for the English language only (Belz et al., 2011). The submitted systems in 2011 had grammar-based and statistical nature, mostly relying on pipelined architecture. Recently, Marcheggiani and PerezBeltrachini (2018) proposed a neural end-to-end approach based on graph convolutional encoders for the SR’11 deep track. The SR’18 shallow track received submissions from eight teams with seven of them dividing the task into two subtasks: word ordering and inflection. Only Elder and Hokamp (2018) developed a joint approach, however, they participated only in the English track. For word ordering, five teams chose an approach based on neural networks, two used a 3086 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, an"
D19-1305,W18-3605,0,0.726861,"e teams chose an approach based on neural networks, two used a 3086 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, and one used an SMT system (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). Overall, neural components were dominant across all the participants. However, official scores of the teams that went neural greatly differ. Furthermore, two teams (Elder and Hokamp, 2018; Sobrevilla Cabezudo and Pardo, 2018) applied data augmentation, which makes their results not strictly comparable to others. One of the interesting findings of the shared task is reported by Elder and Hokamp (2018) who showed that applying standard neural encoderdecoder models to jointly learn word o"
D19-1305,C18-1101,0,0.0156831,"model and an analysis of the differences in word ordering performance across languages. 1 Claire Gardent LORIA / CNRS claire.gardent@loria.fr Introduction 2 Surface realisation maps a meaning representation to a sentence. In data-to-text generation, it is part of a complex process aiming to select, compress and structure the input data into a text. In textto-text generation, it can be used as a mean to rephrase part or all of the input content. For instance, Takase et al. (2016) used surface realisation to generate a summary based on the meaning representations of multiple input documents and Liao et al. (2018) to improve neural machine translation. By providing parallel data of sentences and their meaning representation, the SR’18 Surface Realisation shared task (Mille et al., 2018) allows for a detailed evaluation and comparison of surface realisation models. Moreover, as it provides training and test data for multiple languages, it also allows for an analysis of how well these models handle languages with different morphological and topological properties. The SR’18 shared task includes two tracks: a shallow track where the input is an unordered, lemmatised dependency tree and a deep track Relate"
D19-1305,D15-1166,0,0.0264411,"ions input to the neural model. Each delexicalised tree node is modelled by a sequence of features. Separate embeddings are learned for each feature type and the feature embeddings of each input node are concatenated to create its dense representation. As exemplified in Figure 1, we model each input placeholder as a concatenation of four features: the node identifier, its POS tag, its dependency relation to the parent node and its parent identifier2 . Sequence-to-sequence model. We use the OpenNMT-py framework (Klein et al., 2017)3 to train factored sequence-to-sequence models with attention (Luong et al., 2015) and the copy and coverage mechanisms described in See et al. (2017). A single-layer LSTM is used for both encoder and decoder. We train using full vocabulary 2 The parent identifier of a root node is represented as 0. commit e61589d, https://github.com/ OpenNMT/OpenNMT-py 3088 3 and the maximal length in the source and target for both baseline and the proposed model. Models were trained for 20 epochs, with a mini-batch size of 64, a word embedding size of 300, and a hidden unit size of 450. They were optimised with SGD with a starting learning rate of 1.0. A learning rate is halved when perpl"
D19-1305,W18-3607,0,0.207116,"Missing"
D19-1305,W18-6501,0,0.0918934,"Missing"
D19-1305,P09-1039,0,0.0476323,"ration: one based on regular expressions (Creg ) and another based on a sequence-tosequence model (Cs2s ). The sequence-to-sequence model is trained on pairs of sentences without and with contractions. The sentence with contraction (S +c ) is the final sentence, i.e., the reference sentence in the SR’18 data. The sentence without contraction (S −c ) is the corresponding sequence of word forms extracted from the UD CoNLL data. The regular expression module is inspired by the decomposition of multi-word expressions, such as contractions, which is applied during the tokenisation step in parsing (Martins et al., 2009). We reversed the regular expressions given in the TurboParser6 for the surface realisation task, and also added our own to tackle, for example, elision in French. Cs2s and Creg modules were created for three languages: French, Italian, and Portuguese7 . 5 Evaluation We evaluate each component of our approach separately. We start by providing a detailed evaluation of how the model handles word ordering 6 https://github.com/andre-martins/ TurboParser/tree/master/python/tokenizer 7 Although contractions are also present in Spanish, we did not develop a module for it, since the UD Spanish AnCora"
D19-1305,W18-3601,0,0.220464,"n maps a meaning representation to a sentence. In data-to-text generation, it is part of a complex process aiming to select, compress and structure the input data into a text. In textto-text generation, it can be used as a mean to rephrase part or all of the input content. For instance, Takase et al. (2016) used surface realisation to generate a summary based on the meaning representations of multiple input documents and Liao et al. (2018) to improve neural machine translation. By providing parallel data of sentences and their meaning representation, the SR’18 Surface Realisation shared task (Mille et al., 2018) allows for a detailed evaluation and comparison of surface realisation models. Moreover, as it provides training and test data for multiple languages, it also allows for an analysis of how well these models handle languages with different morphological and topological properties. The SR’18 shared task includes two tracks: a shallow track where the input is an unordered, lemmatised dependency tree and a deep track Related Work Early approaches for surface realisation adopted statistical methods, including both pipelined (Bohnet et al., 2010) and joint (Song et al., 2014; Puduppully et al., 201"
D19-1305,E17-1061,0,0.0246551,"k (Mille et al., 2018) allows for a detailed evaluation and comparison of surface realisation models. Moreover, as it provides training and test data for multiple languages, it also allows for an analysis of how well these models handle languages with different morphological and topological properties. The SR’18 shared task includes two tracks: a shallow track where the input is an unordered, lemmatised dependency tree and a deep track Related Work Early approaches for surface realisation adopted statistical methods, including both pipelined (Bohnet et al., 2010) and joint (Song et al., 2014; Puduppully et al., 2017) architecture for word ordering and morphological generation. Multilingual SR’18 was preceded by the SR’11 surface realisation task for the English language only (Belz et al., 2011). The submitted systems in 2011 had grammar-based and statistical nature, mostly relying on pipelined architecture. Recently, Marcheggiani and PerezBeltrachini (2018) proposed a neural end-to-end approach based on graph convolutional encoders for the SR’11 deep track. The SR’18 shallow track received submissions from eight teams with seven of them dividing the task into two subtasks: word ordering and inflection. On"
D19-1305,W18-3602,0,0.680823,"tworks, two used a 3086 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, and one used an SMT system (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). Overall, neural components were dominant across all the participants. However, official scores of the teams that went neural greatly differ. Furthermore, two teams (Elder and Hokamp, 2018; Sobrevilla Cabezudo and Pardo, 2018) applied data augmentation, which makes their results not strictly comparable to others. One of the interesting findings of the shared task is reported by Elder and Hokamp (2018) who showed that applying standard neural encoderdecoder models to jointly learn word ordering and inflection is highly challenging; thei"
D19-1305,P17-1099,0,0.0225895,"ed by a sequence of features. Separate embeddings are learned for each feature type and the feature embeddings of each input node are concatenated to create its dense representation. As exemplified in Figure 1, we model each input placeholder as a concatenation of four features: the node identifier, its POS tag, its dependency relation to the parent node and its parent identifier2 . Sequence-to-sequence model. We use the OpenNMT-py framework (Klein et al., 2017)3 to train factored sequence-to-sequence models with attention (Luong et al., 2015) and the copy and coverage mechanisms described in See et al. (2017). A single-layer LSTM is used for both encoder and decoder. We train using full vocabulary 2 The parent identifier of a root node is represented as 0. commit e61589d, https://github.com/ OpenNMT/OpenNMT-py 3088 3 and the maximal length in the source and target for both baseline and the proposed model. Models were trained for 20 epochs, with a mini-batch size of 64, a word embedding size of 300, and a hidden unit size of 450. They were optimised with SGD with a starting learning rate of 1.0. A learning rate is halved when perplexity does not decrease on the development set. Preliminary experime"
D19-1305,P16-1162,0,0.0641373,"Missing"
D19-1305,W18-3603,0,0.114983,"eedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, and one used an SMT system (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). Overall, neural components were dominant across all the participants. However, official scores of the teams that went neural greatly differ. Furthermore, two teams (Elder and Hokamp, 2018; Sobrevilla Cabezudo and Pardo, 2018) applied data augmentation, which makes their results not strictly comparable to others. One of the interesting findings of the shared task is reported by Elder and Hokamp (2018) who showed that applying standard neural encoderdecoder models to jointly learn word ordering and inflection is highly challenging; their sequence-tosequenc"
D19-1305,W18-3608,0,0.0202835,"on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3086–3096, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics classifier, and one team resorted to a language model. As for the inflection subtask, five teams applied neural techniques, two used lexicon-based approaches, and one used an SMT system (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). Overall, neural components were dominant across all the participants. However, official scores of the teams that went neural greatly differ. Furthermore, two teams (Elder and Hokamp, 2018; Sobrevilla Cabezudo and Pardo, 2018) applied data augmentation, which makes their results not strictly comparable to others. One of the interesting findings of the shared task is reported by Elder and Hokamp (2018) who showed that applying standard neural encoderdecoder models to jointly learn word ordering and inflection is highly challenging; their sequence-tosequence baseline without data augmentation g"
D19-1305,D16-1112,0,0.0292618,"ed Task shallow track. We provide a detailed evaluation of how word order, morphological realisation and contractions are handled by the model and an analysis of the differences in word ordering performance across languages. 1 Claire Gardent LORIA / CNRS claire.gardent@loria.fr Introduction 2 Surface realisation maps a meaning representation to a sentence. In data-to-text generation, it is part of a complex process aiming to select, compress and structure the input data into a text. In textto-text generation, it can be used as a mean to rephrase part or all of the input content. For instance, Takase et al. (2016) used surface realisation to generate a summary based on the meaning representations of multiple input documents and Liao et al. (2018) to improve neural machine translation. By providing parallel data of sentences and their meaning representation, the SR’18 Surface Realisation shared task (Mille et al., 2018) allows for a detailed evaluation and comparison of surface realisation models. Moreover, as it provides training and test data for multiple languages, it also allows for an analysis of how well these models handle languages with different morphological and topological properties. The SR’"
D19-1305,D15-1199,0,0.116531,"Missing"
D19-1314,W13-2322,0,0.134002,"structural information contained in the AMR graph. The model learns parallel top-down and bottom-up representations of nodes capturing contrasting views of the graph. We also investigate the use of different node message passing strategies, employing different state-of-the-art graph encoders to compute node representations based on incoming and outgoing perspectives. In our experiments, we demonstrate that the dual graph representation leads to improvements in AMR-to-text generation, achieving state-ofthe-art results on two AMR datasets1 . 1 Introduction Abstract Meaning Representation (AMR; Banarescu et al. (2013)) is a linguistically-grounded semantic formalism that represents the meaning of a sentence as a rooted directed graph, where nodes are concepts and edges are semantic relations. As AMR abstracts away from surface word strings and syntactic structure producing a language neutral representation of meaning, its usage is beneficial in many semantic related NLP tasks, including text summarization (Liao et al., 2018) and machine translation (Song et al., 2019). The purpose of AMR-to-text generation is to produce a text which verbalises the meaning encoded by an input AMR graph. This is a challengin"
D19-1314,P18-1026,0,0.46298,"s capturing the complex structural information stored in graph-based data is not trivial, as these are non-Euclidean structures, which 1 Code is available at https://github.com/UKPLab/emnlp2019-dualgraph implies that properties such as global parametrization, vector space structure, or shift-invariance do not hold (Bronstein et al., 2017). Recently, Graph Neural Networks (GNNs) have emerged as a powerful class of methods for learning effective graph latent representations (Xu et al., 2019) and graph-to-sequence models have been applied to the task of AMR-to-text generation (Song et al., 2018; Beck et al., 2018; Damonte and Cohen, 2019; Guo et al., 2019). In this paper, we propose a novel graph-tosequence approach to AMR-to-text generation, which is inspired by pre-neural generation algorithms. These approaches explored alternative (top-down, bottom-up and mixed) traversals of the input graph and showed that a hybrid traversal combining both top-down (TD) and bottom-up (BU) information was best as this permits integrating both global constraints top-down from the input and local constraints bottom-up from the semantic heads (Shieber et al., 1990; Narayan and Gardent, 2012). Similarly, we present an"
D19-1314,W11-2832,0,0.0303653,"on and use graph encoders to represent nodes. Cao and Clark (2019) factor the generation process leveraging syntactic information to improve the performance. However, they linearize both AMR and constituency graphs, which implies that important parts of the graphs cannot well be represented (e.g., coreference). Several graph-to-sequence models have been proposed. Marcheggiani and Perez Beltrachini (2018) show that explicitly encoding the structure of the graph is beneficial with respect to sequential encoding. They evaluate their model on two tasks, WebNLG (Gardent et al., 2017) and SR11Deep (Belz et al., 2011), but do not apply it to AMR benchmarks. Song et al. (2018) and Beck et al. (2018) apply recurrent neural networks to directly encode AMR graphs. Song et al. (2018) use a graph LSTM as the graph encoder, whereas Beck et al. (2018) develop a model based on GRUs. We go a step further in that direction by developing parallel encodings of graphs which are able to highlight different graph properties. In a related task, Koncel-Kedziorski et al. (2019) propose an attention-based graph model that generates sentences from knowledge graphs. Schlichtkrull et al. (2018) use Graph Convolutional Networks ("
D19-1314,N19-1223,0,0.440619,"November 3–7, 2019. 2019 Association for Computational Linguistics nates the need for additional positional information (Beck et al., 2018) which is required when the same graph is used to encode both TD and BU information, thereby making the edges undirected. Our main contributions are the following: • We present a novel architecture for AMR-to-text generation which explicitly encodes two separate TD and BU views of the input graph. • We show that our approach outperforms recent AMR-to-text generation models on two datasets, including a model that leverages additional syntactic information (Cao and Clark, 2019). • We compare the performance of three graph encoders, which have not been studied so far for AMR-to-text generation. 2 Related Work Early works on AMR-to-text generation employ statistical methods (Flanigan et al., 2016b; Pourdamghani et al., 2016; Castro Ferreira et al., 2017) and apply linearization of the graph by means of a depth-first traversal. Recent neural approaches have exhibited success by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisati"
D19-1314,W17-3501,0,0.063384,"utions are the following: • We present a novel architecture for AMR-to-text generation which explicitly encodes two separate TD and BU views of the input graph. • We show that our approach outperforms recent AMR-to-text generation models on two datasets, including a model that leverages additional syntactic information (Cao and Clark, 2019). • We compare the performance of three graph encoders, which have not been studied so far for AMR-to-text generation. 2 Related Work Early works on AMR-to-text generation employ statistical methods (Flanigan et al., 2016b; Pourdamghani et al., 2016; Castro Ferreira et al., 2017) and apply linearization of the graph by means of a depth-first traversal. Recent neural approaches have exhibited success by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisation. Anonymisation requires an ad hoc procedure for each new corpus. The matching procedure needs to match a rare input item correctly (e.g., “United States of America”) with the corresponding part in the output text (e.g., “USA”) which may be challenging and may result in incorre"
D19-1314,D14-1179,0,0.0233632,"Missing"
D19-1314,N19-1366,0,0.344844,"plex structural information stored in graph-based data is not trivial, as these are non-Euclidean structures, which 1 Code is available at https://github.com/UKPLab/emnlp2019-dualgraph implies that properties such as global parametrization, vector space structure, or shift-invariance do not hold (Bronstein et al., 2017). Recently, Graph Neural Networks (GNNs) have emerged as a powerful class of methods for learning effective graph latent representations (Xu et al., 2019) and graph-to-sequence models have been applied to the task of AMR-to-text generation (Song et al., 2018; Beck et al., 2018; Damonte and Cohen, 2019; Guo et al., 2019). In this paper, we propose a novel graph-tosequence approach to AMR-to-text generation, which is inspired by pre-neural generation algorithms. These approaches explored alternative (top-down, bottom-up and mixed) traversals of the input graph and showed that a hybrid traversal combining both top-down (TD) and bottom-up (BU) information was best as this permits integrating both global constraints top-down from the input and local constraints bottom-up from the semantic heads (Shieber et al., 1990; Narayan and Gardent, 2012). Similarly, we present an approach where the input"
D19-1314,W14-3348,0,0.109133,"Missing"
D19-1314,N19-1423,0,0.0380882,"Missing"
D19-1314,P19-1213,1,0.867711,"Missing"
D19-1314,S16-1186,0,0.114335,"ion, thereby making the edges undirected. Our main contributions are the following: • We present a novel architecture for AMR-to-text generation which explicitly encodes two separate TD and BU views of the input graph. • We show that our approach outperforms recent AMR-to-text generation models on two datasets, including a model that leverages additional syntactic information (Cao and Clark, 2019). • We compare the performance of three graph encoders, which have not been studied so far for AMR-to-text generation. 2 Related Work Early works on AMR-to-text generation employ statistical methods (Flanigan et al., 2016b; Pourdamghani et al., 2016; Castro Ferreira et al., 2017) and apply linearization of the graph by means of a depth-first traversal. Recent neural approaches have exhibited success by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisation. Anonymisation requires an ad hoc procedure for each new corpus. The matching procedure needs to match a rare input item correctly (e.g., “United States of America”) with the corresponding part in the output text (e.g."
D19-1314,N16-1087,0,0.611973,"ion, thereby making the edges undirected. Our main contributions are the following: • We present a novel architecture for AMR-to-text generation which explicitly encodes two separate TD and BU views of the input graph. • We show that our approach outperforms recent AMR-to-text generation models on two datasets, including a model that leverages additional syntactic information (Cao and Clark, 2019). • We compare the performance of three graph encoders, which have not been studied so far for AMR-to-text generation. 2 Related Work Early works on AMR-to-text generation employ statistical methods (Flanigan et al., 2016b; Pourdamghani et al., 2016; Castro Ferreira et al., 2017) and apply linearization of the graph by means of a depth-first traversal. Recent neural approaches have exhibited success by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisation. Anonymisation requires an ad hoc procedure for each new corpus. The matching procedure needs to match a rare input item correctly (e.g., “United States of America”) with the corresponding part in the output text (e.g."
D19-1314,W17-3518,1,0.827968,"uild a dual TD/BU graph representation and use graph encoders to represent nodes. Cao and Clark (2019) factor the generation process leveraging syntactic information to improve the performance. However, they linearize both AMR and constituency graphs, which implies that important parts of the graphs cannot well be represented (e.g., coreference). Several graph-to-sequence models have been proposed. Marcheggiani and Perez Beltrachini (2018) show that explicitly encoding the structure of the graph is beneficial with respect to sequential encoding. They evaluate their model on two tasks, WebNLG (Gardent et al., 2017) and SR11Deep (Belz et al., 2011), but do not apply it to AMR benchmarks. Song et al. (2018) and Beck et al. (2018) apply recurrent neural networks to directly encode AMR graphs. Song et al. (2018) use a graph LSTM as the graph encoder, whereas Beck et al. (2018) develop a model based on GRUs. We go a step further in that direction by developing parallel encodings of graphs which are able to highlight different graph properties. In a related task, Koncel-Kedziorski et al. (2019) propose an attention-based graph model that generates sentences from knowledge graphs. Schlichtkrull et al. (2018) u"
D19-1314,Q19-1019,0,0.452769,"on stored in graph-based data is not trivial, as these are non-Euclidean structures, which 1 Code is available at https://github.com/UKPLab/emnlp2019-dualgraph implies that properties such as global parametrization, vector space structure, or shift-invariance do not hold (Bronstein et al., 2017). Recently, Graph Neural Networks (GNNs) have emerged as a powerful class of methods for learning effective graph latent representations (Xu et al., 2019) and graph-to-sequence models have been applied to the task of AMR-to-text generation (Song et al., 2018; Beck et al., 2018; Damonte and Cohen, 2019; Guo et al., 2019). In this paper, we propose a novel graph-tosequence approach to AMR-to-text generation, which is inspired by pre-neural generation algorithms. These approaches explored alternative (top-down, bottom-up and mixed) traversals of the input graph and showed that a hybrid traversal combining both top-down (TD) and bottom-up (BU) information was best as this permits integrating both global constraints top-down from the input and local constraints bottom-up from the semantic heads (Shieber et al., 1990; Narayan and Gardent, 2012). Similarly, we present an approach where the input graph is represente"
D19-1314,P07-2045,0,0.00610917,"ively. In contrast to their work, we do not rely on (i) leveraging supplementary syntactic information and (ii) we do not require an anonymization preprocessing step. G2S-GIN and G2S-GAT have comparable performance on both datasets. Interestingly, G2S-GGNN has better performance among our models. This suggests that graph encoders based on gating mechanisms are very effective in text generation models. We hypothesize that the gating mechanism can better capture longdistance dependencies between nodes far apart in the graph. 3 For BLEU, we use the multi-BLEU script from the MOSES decoder suite (Koehn et al., 2007). For METEOR, we use the original meteor-1.5.jar script (https://github.com/cmu-mtlab/meteor). 3188 Model biLSTM GEt + biLSTM GEb + biLSTM GEt + GEb + biLSTM BLEU METEOR 22.50 26.33 26.12 27.37 30.42 32.62 32.49 33.30 Size 57.6M 59.6M 59.6M 61.7M Model Table 4: Results of the ablation study on the LDC2017T10 development set. Additional Training Data Following previous works (Konstas et al., 2017; Song et al., 2018; Guo et al., 2019), we also evaluate our models employing additional data from English Gigaword corpus (Napoles et al., 2012). We sample 200K Gigaword sentences and use JAMR4 (Flanig"
D19-1314,N19-1238,0,0.0992376,"Missing"
D19-1314,P17-1014,0,0.199886,"eration models on two datasets, including a model that leverages additional syntactic information (Cao and Clark, 2019). • We compare the performance of three graph encoders, which have not been studied so far for AMR-to-text generation. 2 Related Work Early works on AMR-to-text generation employ statistical methods (Flanigan et al., 2016b; Pourdamghani et al., 2016; Castro Ferreira et al., 2017) and apply linearization of the graph by means of a depth-first traversal. Recent neural approaches have exhibited success by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisation. Anonymisation requires an ad hoc procedure for each new corpus. The matching procedure needs to match a rare input item correctly (e.g., “United States of America”) with the corresponding part in the output text (e.g., “USA”) which may be challenging and may result in incorrect or incomplete delexicalisations. In contrast, our approach omits anonymisation. Instead, we use a copy mechanism (See et al., 2017), a generic technique which is easy to integrate in the encoder-decoder framework and ca"
D19-1314,C18-1101,0,0.0600318,"graph representation leads to improvements in AMR-to-text generation, achieving state-ofthe-art results on two AMR datasets1 . 1 Introduction Abstract Meaning Representation (AMR; Banarescu et al. (2013)) is a linguistically-grounded semantic formalism that represents the meaning of a sentence as a rooted directed graph, where nodes are concepts and edges are semantic relations. As AMR abstracts away from surface word strings and syntactic structure producing a language neutral representation of meaning, its usage is beneficial in many semantic related NLP tasks, including text summarization (Liao et al., 2018) and machine translation (Song et al., 2019). The purpose of AMR-to-text generation is to produce a text which verbalises the meaning encoded by an input AMR graph. This is a challenging task as capturing the complex structural information stored in graph-based data is not trivial, as these are non-Euclidean structures, which 1 Code is available at https://github.com/UKPLab/emnlp2019-dualgraph implies that properties such as global parametrization, vector space structure, or shift-invariance do not hold (Bronstein et al., 2017). Recently, Graph Neural Networks (GNNs) have emerged as a powerful"
D19-1314,W18-6501,0,0.122099,"Missing"
D19-1314,W18-3601,0,0.0661719,"Missing"
D19-1314,W12-3018,0,0.0181848,"Missing"
D19-1314,C12-1124,1,0.816294,"text generation (Song et al., 2018; Beck et al., 2018; Damonte and Cohen, 2019; Guo et al., 2019). In this paper, we propose a novel graph-tosequence approach to AMR-to-text generation, which is inspired by pre-neural generation algorithms. These approaches explored alternative (top-down, bottom-up and mixed) traversals of the input graph and showed that a hybrid traversal combining both top-down (TD) and bottom-up (BU) information was best as this permits integrating both global constraints top-down from the input and local constraints bottom-up from the semantic heads (Shieber et al., 1990; Narayan and Gardent, 2012). Similarly, we present an approach where the input graph is represented by two separate structures, each representing a different view of the graph. The nodes of these two structures are encoded using separate graph encoders so that each concept and relation in the input graph is assigned both a TD and a BU representation. Our approach markedly differs from existing graph-to-sequence models for MR-to-Text generation (Marcheggiani and Perez Beltrachini, 2018; Beck et al., 2018; Damonte and Cohen, 2019) in that these approaches aggregate all the immediate neighborhood information of a node in a"
D19-1314,P02-1040,0,0.106388,"Missing"
D19-1314,D14-1162,0,0.0820871,"Missing"
D19-1314,W16-6603,0,0.366354,"edges undirected. Our main contributions are the following: • We present a novel architecture for AMR-to-text generation which explicitly encodes two separate TD and BU views of the input graph. • We show that our approach outperforms recent AMR-to-text generation models on two datasets, including a model that leverages additional syntactic information (Cao and Clark, 2019). • We compare the performance of three graph encoders, which have not been studied so far for AMR-to-text generation. 2 Related Work Early works on AMR-to-text generation employ statistical methods (Flanigan et al., 2016b; Pourdamghani et al., 2016; Castro Ferreira et al., 2017) and apply linearization of the graph by means of a depth-first traversal. Recent neural approaches have exhibited success by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisation. Anonymisation requires an ad hoc procedure for each new corpus. The matching procedure needs to match a rare input item correctly (e.g., “United States of America”) with the corresponding part in the output text (e.g., “USA”) which may be challe"
D19-1314,P17-1099,0,0.244136,"ccess by linearising the input graph and using a sequence-to-sequence architecture. Konstas et al. (2017) achieve promising results on this task. However, they strongly rely on named entities anonymisation. Anonymisation requires an ad hoc procedure for each new corpus. The matching procedure needs to match a rare input item correctly (e.g., “United States of America”) with the corresponding part in the output text (e.g., “USA”) which may be challenging and may result in incorrect or incomplete delexicalisations. In contrast, our approach omits anonymisation. Instead, we use a copy mechanism (See et al., 2017), a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. Our approach further differs from Konstas et al. (2017) in that we build a dual TD/BU graph representation and use graph encoders to represent nodes. Cao and Clark (2019) factor the generation process leveraging syntactic information to improve the performance. However, they linearize both AMR and constituency graphs, which implies that important parts of the graphs cannot well be represented (e.g., coreference). Several graph-to-sequence mod"
D19-1314,Q19-1002,0,0.0799941,"n AMR-to-text generation, achieving state-ofthe-art results on two AMR datasets1 . 1 Introduction Abstract Meaning Representation (AMR; Banarescu et al. (2013)) is a linguistically-grounded semantic formalism that represents the meaning of a sentence as a rooted directed graph, where nodes are concepts and edges are semantic relations. As AMR abstracts away from surface word strings and syntactic structure producing a language neutral representation of meaning, its usage is beneficial in many semantic related NLP tasks, including text summarization (Liao et al., 2018) and machine translation (Song et al., 2019). The purpose of AMR-to-text generation is to produce a text which verbalises the meaning encoded by an input AMR graph. This is a challenging task as capturing the complex structural information stored in graph-based data is not trivial, as these are non-Euclidean structures, which 1 Code is available at https://github.com/UKPLab/emnlp2019-dualgraph implies that properties such as global parametrization, vector space structure, or shift-invariance do not hold (Bronstein et al., 2017). Recently, Graph Neural Networks (GNNs) have emerged as a powerful class of methods for learning effective gra"
D19-1314,P18-1150,0,0.437341,"challenging task as capturing the complex structural information stored in graph-based data is not trivial, as these are non-Euclidean structures, which 1 Code is available at https://github.com/UKPLab/emnlp2019-dualgraph implies that properties such as global parametrization, vector space structure, or shift-invariance do not hold (Bronstein et al., 2017). Recently, Graph Neural Networks (GNNs) have emerged as a powerful class of methods for learning effective graph latent representations (Xu et al., 2019) and graph-to-sequence models have been applied to the task of AMR-to-text generation (Song et al., 2018; Beck et al., 2018; Damonte and Cohen, 2019; Guo et al., 2019). In this paper, we propose a novel graph-tosequence approach to AMR-to-text generation, which is inspired by pre-neural generation algorithms. These approaches explored alternative (top-down, bottom-up and mixed) traversals of the input graph and showed that a hybrid traversal combining both top-down (TD) and bottom-up (BU) information was best as this permits integrating both global constraints top-down from the input and local constraints bottom-up from the semantic heads (Shieber et al., 1990; Narayan and Gardent, 2012). Simila"
D19-1314,N18-1101,0,0.0386878,"Missing"
D19-1428,P11-1049,0,0.0331093,"require models to identify spans and can do so effectively on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument i"
D19-1428,P15-1153,0,0.0651403,"y on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument input, such as TriviaQA (Joshi et al., 2017). V"
D19-1428,P17-1171,1,0.834271,"and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument input, such as TriviaQA (Joshi et al., 2017). Various approaches have been proposed, including leveraging TF-IDF and bigram hashing with an RNN to find relevant information (Chen et al., 2017), models that score individual paragraphs for sub-selection (Clark and Gardner, 2017), and nearest neighbor search with paragraph re-ranking (Das et al., 2018a). However, these approaches have been applied to extractive question answering tasks that require span identification, rather than abstractive text generation in an information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in knowledge bases (Bordes et al., 2011) and improving these representations (Chen et al., 2013). Knowledge bases have been leveraged to improve perfo"
D19-1428,P14-1091,0,0.0241995,"ch with paragraph re-ranking (Das et al., 2018a). However, these approaches have been applied to extractive question answering tasks that require span identification, rather than abstractive text generation in an information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in knowledge bases (Bordes et al., 2011) and improving these representations (Chen et al., 2013). Knowledge bases have been leveraged to improve performance on various tasks, from coreference resolution (Ng and Cardie, 2002) and question answering (Zheng, 2003; Bao et al., 2014; Cui et al., 2017; Sun et al., 2018) to signal processing (B¨uckner et al., 2002). Various works convert text into Abstract Meaning Representations (Liu et al., 2018a) for domains such as news (Vossen et al., 2015; Rospocher et al., 2016) and link nodes to large knowledge bases such as DBPedia (Auer et al., 2007). Wities et al. (2017) combine open information extraction with coreference and lexical inference to build knowledge representations. They apply this to tweets and analyze the accuracy on various aspects of graph construction. Das et al. (2018b) construct graphs from procedural text t"
D19-1428,P99-1071,0,0.41211,"terest in generative sequence modeling has intensified due to recent improvements (Peters et al., 2018; Devlin et al., 2018; Radford et al., 2019), making the challenge of information synthesis more relevant. In contrast to extractive tasks which only require models to identify spans and can do so effectively on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on e"
D19-1428,P18-1026,0,0.044305,"en information extraction with coreference and lexical inference to build knowledge representations. They apply this to tweets and analyze the accuracy on various aspects of graph construction. Das et al. (2018b) construct graphs from procedural text to track entity position to answer when and if entities are created, destroyed, or moved. In contrast, we build graphs from substantially longer multi-document input and use them for multi-sentence text generation. Recently, many have explored neural architectures that can encode graph structured input (Bruna et al., 2013; Kipf and Welling, 2016; Beck et al., 2018; Zhou et al., 2018; Xu et al., 2018; Lai et al., 2019). These models often represent graphs as adjacency matrices to generalize architectures such as convolutional networks to graph inputs. Rather than encoding a static knowledge graph or leveraging external knowledge graphs, we build a local graph for each query and model these using standard Seq2Seq models. We leave the incorporation of graph networks for future work. 3 Graph Construction We describe how symbolic graph representations of knowledge can be constructed from text. Our approach assumes a multi-document input (such as web pages)"
D19-1428,D16-1245,0,0.0244464,"g them, the construction of the graph reduces redundancy. The size of the graph can be modified by controlling which triples are added using TF-IDF overlap (see Figure 2, step 4). TFIDF overlap of the triple with the question can be used to determine if the triple contains relevant information. This improves robustness to noisy web search input and helps filter entirely irrelevant portions, such as scraped HTML tags. document sentence used to produce the graph output. 4 Text to Triples to Graph Graph construction proceeds in several steps outlined in Figure 2. We apply Coreference Resolution (Clark and Manning, 2016a,b)1 and Open Information Extraction (Stanovsky et al., 2018)2 to convert sentences into a Triple of the form (subject, predicate, object). The sentence Albert Einstein, a German theoretical physicist, won the Nobel Prize would become (Albert Einstein, won, the Nobel Prize). A graph is constructed using the triples by representing subjects and objects as nodes connected by predicates as directed edges. For example, the triple would become Albert Einstein −−→ the Nowon bel Prize. Nodes and edges have a name property that is the text they represent. They also have a weight property that denotes"
D19-1428,P16-1061,0,0.0244566,"g them, the construction of the graph reduces redundancy. The size of the graph can be modified by controlling which triples are added using TF-IDF overlap (see Figure 2, step 4). TFIDF overlap of the triple with the question can be used to determine if the triple contains relevant information. This improves robustness to noisy web search input and helps filter entirely irrelevant portions, such as scraped HTML tags. document sentence used to produce the graph output. 4 Text to Triples to Graph Graph construction proceeds in several steps outlined in Figure 2. We apply Coreference Resolution (Clark and Manning, 2016a,b)1 and Open Information Extraction (Stanovsky et al., 2018)2 to convert sentences into a Triple of the form (subject, predicate, object). The sentence Albert Einstein, a German theoretical physicist, won the Nobel Prize would become (Albert Einstein, won, the Nobel Prize). A graph is constructed using the triples by representing subjects and objects as nodes connected by predicates as directed edges. For example, the triple would become Albert Einstein −−→ the Nowon bel Prize. Nodes and edges have a name property that is the text they represent. They also have a weight property that denotes"
D19-1428,P19-1285,0,0.0169835,"nearized graph) by computing an attention distribution between the question and the input, then selecting the top k positions with the most attention weight. Such a mechanism can be thought of as building a query-dependent representation of the most relevant knowledge, which is commonly done in question answering architectures like BiDAF (Seo et al., 2017). The top k 4189 operation limits the number of tokens, making the attention mechanism sharper. 4.3 Scaling to Encode the Graph Recent progress has improved the ability of language models to process longer sequences (Sukhbaatar et al., 2019; Dai et al., 2019), but models remain limited in their capacity to encode long documents. The multi-document results of query-based web search have hundreds of thousands of tokens, beyond the limit of current Seq2Seq models to handle. For example, the ELI5 dataset provides an average of 200K tokens of web search input. However, by compressing the web search results into a knowledge graph, we significantly reduce the number of tokens by an order of magnitude and make it possible for a model to access the entirety of the search information. To represent the full graph, models must scale to encode around 10K input"
D19-1428,P02-1057,0,0.294075,"Missing"
D19-1428,W14-4408,0,0.0556659,"Missing"
D19-1428,P19-1102,0,0.211346,"sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument input, such as TriviaQA (Joshi et al., 2017). Various approaches have been proposed, including leveraging TF-IDF and bigram h"
D19-1428,P19-1346,1,0.752719,"ectively encode the entire graph as a sequence and attend to the most relevant portions within this linearization. We demonstrate the effectiveness of this approach on two large4186 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 4186–4196, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics scale generative tasks with both long and noisy multi-document web input and paragraph length output: long-form question answering on the ELI5 dataset (Fan et al., 2019) and Wikipedia lead paragraph generation as a multi-document summarization problem (Liu et al., 2018b). 2 Related Work Interest in generative sequence modeling has intensified due to recent improvements (Peters et al., 2018; Devlin et al., 2018; Radford et al., 2019), making the challenge of information synthesis more relevant. In contrast to extractive tasks which only require models to identify spans and can do so effectively on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document inp"
D19-1428,P18-1082,1,0.829423,"rst document have QR embedding 1, and tokens from the second document have value 2. Models now have access to several different types of embeddings, but all embedding information contributes equally as there is no mechanism to distinguish between them. We introduce a Models learn a gating mechanism for the QR embedding in a similar manner. The full embedding the model receives is as follows: pos eword + et t 4.2 QR + [hGW t ; ht ] Hierarchical Attention One challenge in modeling long sequences is that attention mechanisms struggle to make sharp selections when softmax-ing over long sequences (Fan et al., 2018). When attention is blurry, there lacks a strong distinction between noise and relevant information. We assume that graphs are constructed from query-based web search input and thus leverage this query to learn a subselection operation using hierarchical top-k attention, depicted in Figure 4. The query is encoded with a Transformer encoder and the linearized graph with another Transformer encoder. We model the interaction between the query and the input sequence (e.g. web search results or linearized graph) by computing an attention distribution between the question and the input, then selecti"
D19-1428,C10-1039,0,0.0270448,"-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument input, such as TriviaQA (Joshi et al., 2017). Various approaches have been proposed, including leveraging TF-IDF and bigram hashing with an RNN to find relevant information (Chen et al., 2017), models that s"
D19-1428,W09-1802,0,0.0470465,"tractive tasks which only require models to identify spans and can do so effectively on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance o"
D19-1428,I08-2101,0,0.0197432,"8; Radford et al., 2019), making the challenge of information synthesis more relevant. In contrast to extractive tasks which only require models to identify spans and can do so effectively on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidoc"
D19-1428,P17-1147,0,0.0158502,"014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument input, such as TriviaQA (Joshi et al., 2017). Various approaches have been proposed, including leveraging TF-IDF and bigram hashing with an RNN to find relevant information (Chen et al., 2017), models that score individual paragraphs for sub-selection (Clark and Gardner, 2017), and nearest neighbor search with paragraph re-ranking (Das et al., 2018a). However, these approaches have been applied to extractive question answering tasks that require span identification, rather than abstractive text generation in an information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in"
D19-1428,P02-1014,0,0.158839,"ction (Clark and Gardner, 2017), and nearest neighbor search with paragraph re-ranking (Das et al., 2018a). However, these approaches have been applied to extractive question answering tasks that require span identification, rather than abstractive text generation in an information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in knowledge bases (Bordes et al., 2011) and improving these representations (Chen et al., 2013). Knowledge bases have been leveraged to improve performance on various tasks, from coreference resolution (Ng and Cardie, 2002) and question answering (Zheng, 2003; Bao et al., 2014; Cui et al., 2017; Sun et al., 2018) to signal processing (B¨uckner et al., 2002). Various works convert text into Abstract Meaning Representations (Liu et al., 2018a) for domains such as news (Vossen et al., 2015; Rospocher et al., 2016) and link nodes to large knowledge bases such as DBPedia (Auer et al., 2007). Wities et al. (2017) combine open information extraction with coreference and lexical inference to build knowledge representations. They apply this to tweets and analyze the accuracy on various aspects of graph construction. Das"
D19-1428,N19-4009,1,0.835948,"explore using MMR to select sentences from the web text to concatenate to form a support document. Input Length avg 850 avg 850 avg 850 850 avg 570 850 850 850 11K Table 1: Answer Generation on ELI5 using Seq2Seq models receiving the Question and a support Document (e.g. TF-IDF selection, Triples, Linearized Graph) to produce the Answer. * denotes results from (Fan et al., 2019). Training and Generation To reduce the vocabulary size of varied web document content, we apply byte-pair encoding (Sennrich et al., 2016) to generate 40K codes for each dataset. We implement our models in fairseqpy (Ott et al., 2019) using the Transformer Big architecture and training schedule described in (Vaswani et al., 2017). Detailed parameters are listed in the Appendix. For generation, we use beam search with beam size 5 and tune a minimum and maximum length on the validation set. 5.3 Model • Seq2Seq Multi-task Top 20 Triples: As an alternative to using graph construction to compress the full set of Open IE Triples, we explore using TF-IDF overlap with the query to find the most relevant information. We select the top 20 triples to concatenate as input. 6 Results We examine the performance of our proposed approach"
D19-1428,N18-1202,0,0.0116098,"mpirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 4186–4196, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics scale generative tasks with both long and noisy multi-document web input and paragraph length output: long-form question answering on the ELI5 dataset (Fan et al., 2019) and Wikipedia lead paragraph generation as a multi-document summarization problem (Liu et al., 2018b). 2 Related Work Interest in generative sequence modeling has intensified due to recent improvements (Peters et al., 2018; Devlin et al., 2018; Radford et al., 2019), making the challenge of information synthesis more relevant. In contrast to extractive tasks which only require models to identify spans and can do so effectively on long documents by looking at the paragraphs independently, generative sequence models must combine multiple pieces of evidence from long and noisy multi-document input to generate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find s"
D19-1428,P16-1162,0,0.0114035,"l relevance is an effective strategy for selecting relevant information while reducing redundancy. We explore using MMR to select sentences from the web text to concatenate to form a support document. Input Length avg 850 avg 850 avg 850 850 avg 570 850 850 850 11K Table 1: Answer Generation on ELI5 using Seq2Seq models receiving the Question and a support Document (e.g. TF-IDF selection, Triples, Linearized Graph) to produce the Answer. * denotes results from (Fan et al., 2019). Training and Generation To reduce the vocabulary size of varied web document content, we apply byte-pair encoding (Sennrich et al., 2016) to generate 40K codes for each dataset. We implement our models in fairseqpy (Ott et al., 2019) using the Transformer Big architecture and training schedule described in (Vaswani et al., 2017). Detailed parameters are listed in the Appendix. For generation, we use beam search with beam size 5 and tune a minimum and maximum length on the validation set. 5.3 Model • Seq2Seq Multi-task Top 20 Triples: As an alternative to using graph construction to compress the full set of Open IE Triples, we explore using TF-IDF overlap with the query to find the most relevant information. We select the top 20"
D19-1428,N18-1081,0,0.0493568,"size of the graph can be modified by controlling which triples are added using TF-IDF overlap (see Figure 2, step 4). TFIDF overlap of the triple with the question can be used to determine if the triple contains relevant information. This improves robustness to noisy web search input and helps filter entirely irrelevant portions, such as scraped HTML tags. document sentence used to produce the graph output. 4 Text to Triples to Graph Graph construction proceeds in several steps outlined in Figure 2. We apply Coreference Resolution (Clark and Manning, 2016a,b)1 and Open Information Extraction (Stanovsky et al., 2018)2 to convert sentences into a Triple of the form (subject, predicate, object). The sentence Albert Einstein, a German theoretical physicist, won the Nobel Prize would become (Albert Einstein, won, the Nobel Prize). A graph is constructed using the triples by representing subjects and objects as nodes connected by predicates as directed edges. For example, the triple would become Albert Einstein −−→ the Nowon bel Prize. Nodes and edges have a name property that is the text they represent. They also have a weight property that denotes the number of times that node or edge has appeared. For examp"
D19-1428,P19-1032,0,0.0173659,"web search results or linearized graph) by computing an attention distribution between the question and the input, then selecting the top k positions with the most attention weight. Such a mechanism can be thought of as building a query-dependent representation of the most relevant knowledge, which is commonly done in question answering architectures like BiDAF (Seo et al., 2017). The top k 4189 operation limits the number of tokens, making the attention mechanism sharper. 4.3 Scaling to Encode the Graph Recent progress has improved the ability of language models to process longer sequences (Sukhbaatar et al., 2019; Dai et al., 2019), but models remain limited in their capacity to encode long documents. The multi-document results of query-based web search have hundreds of thousands of tokens, beyond the limit of current Seq2Seq models to handle. For example, the ELI5 dataset provides an average of 200K tokens of web search input. However, by compressing the web search results into a knowledge graph, we significantly reduce the number of tokens by an order of magnitude and make it possible for a model to access the entirety of the search information. To represent the full graph, models must scale to enco"
D19-1428,D18-1455,0,0.02738,"al., 2018a). However, these approaches have been applied to extractive question answering tasks that require span identification, rather than abstractive text generation in an information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in knowledge bases (Bordes et al., 2011) and improving these representations (Chen et al., 2013). Knowledge bases have been leveraged to improve performance on various tasks, from coreference resolution (Ng and Cardie, 2002) and question answering (Zheng, 2003; Bao et al., 2014; Cui et al., 2017; Sun et al., 2018) to signal processing (B¨uckner et al., 2002). Various works convert text into Abstract Meaning Representations (Liu et al., 2018a) for domains such as news (Vossen et al., 2015; Rospocher et al., 2016) and link nodes to large knowledge bases such as DBPedia (Auer et al., 2007). Wities et al. (2017) combine open information extraction with coreference and lexical inference to build knowledge representations. They apply this to tweets and analyze the accuracy on various aspects of graph construction. Das et al. (2018b) construct graphs from procedural text to track entity position to answer whe"
D19-1428,W15-4507,0,0.0283838,"n information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in knowledge bases (Bordes et al., 2011) and improving these representations (Chen et al., 2013). Knowledge bases have been leveraged to improve performance on various tasks, from coreference resolution (Ng and Cardie, 2002) and question answering (Zheng, 2003; Bao et al., 2014; Cui et al., 2017; Sun et al., 2018) to signal processing (B¨uckner et al., 2002). Various works convert text into Abstract Meaning Representations (Liu et al., 2018a) for domains such as news (Vossen et al., 2015; Rospocher et al., 2016) and link nodes to large knowledge bases such as DBPedia (Auer et al., 2007). Wities et al. (2017) combine open information extraction with coreference and lexical inference to build knowledge representations. They apply this to tweets and analyze the accuracy on various aspects of graph construction. Das et al. (2018b) construct graphs from procedural text to track entity position to answer when and if entities are created, destroyed, or moved. In contrast, we build graphs from substantially longer multi-document input and use them for multi-sentence text generation."
D19-1428,W17-0902,0,0.0517259,"Missing"
D19-1428,K17-1045,0,0.0383308,"erate correct and convincing responses. 2.1 Multi-Document Input Previous work in multi-document summarization (Barzilay et al., 1999) applies various techniques to handle long input, including clustering to find similar information (Honarpisheh et al., 2008), extractive methods to select relevant sentences (Daum´e III and Marcu, 2002; Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Di Fabbrizio et al., 2014; Bing et al., 2015; Cao et al., 2017) including maximal marginal relevance (Fabbri et al., 2019), and incorporating queries (Baumel et al., 2018) and graphs (Ganesan et al., 2010; Yasunaga et al., 2017). However, there are few large scale multi-document summarization datasets and many approaches have focused on extractive selection or hybrid extractive-abstractive models. In this work, we use graph construction to re-structure multidocument input for abstractive generation. Advancements in question answering have examined performance on datasets with multidocument input, such as TriviaQA (Joshi et al., 2017). Various approaches have been proposed, including leveraging TF-IDF and bigram hashing with an RNN to find relevant information (Chen et al., 2017), models that score individual paragrap"
D19-1428,E03-2017,0,0.0762918,"neighbor search with paragraph re-ranking (Das et al., 2018a). However, these approaches have been applied to extractive question answering tasks that require span identification, rather than abstractive text generation in an information synthesis setting. 2.2 Using Knowledge Bases Previous work has explored various ways of representing information in knowledge bases (Bordes et al., 2011) and improving these representations (Chen et al., 2013). Knowledge bases have been leveraged to improve performance on various tasks, from coreference resolution (Ng and Cardie, 2002) and question answering (Zheng, 2003; Bao et al., 2014; Cui et al., 2017; Sun et al., 2018) to signal processing (B¨uckner et al., 2002). Various works convert text into Abstract Meaning Representations (Liu et al., 2018a) for domains such as news (Vossen et al., 2015; Rospocher et al., 2016) and link nodes to large knowledge bases such as DBPedia (Auer et al., 2007). Wities et al. (2017) combine open information extraction with coreference and lexical inference to build knowledge representations. They apply this to tweets and analyze the accuracy on various aspects of graph construction. Das et al. (2018b) construct graphs from"
D19-6312,W18-3606,0,0.131525,"duced. The input tree can be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with some slight modifications. This model, developed for the"
D19-6312,W18-3605,0,0.0351627,"n be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with some slight modifications. This model, developed for the SR’18 shared task data"
D19-6312,W18-3607,0,0.0433881,"Missing"
D19-6312,W18-3601,0,0.0836511,"ties and suggesting directions for future work. 1 Claire Gardent LORIA / CNRS claire.gardent@loria.fr 2 Data We used only the data provided by the organisers. If several corpora were available for a language, they were mixed to the one training and development dataset. We used original UD files for creating target files for training the word ordering component, i.e. we extracted a sequence of tokens (the field token in the CoNLL format) instead of using a reference sentence. Introduction SR’19 (Mille et al., 2019) is the second edition of the multilingual surface realisation task ran in 2018 (Mille et al., 2018). It aims at developing surface realisers in the multilingual setting. Given an input tree, a well-formed sentence should be produced. The input tree can be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, wher"
D19-6312,P17-1183,0,0.0613988,"Missing"
D19-6312,D19-6301,0,0.0507783,"ask. We provide a separate evaluation of each component of our pipeline, concluding on some difficulties and suggesting directions for future work. 1 Claire Gardent LORIA / CNRS claire.gardent@loria.fr 2 Data We used only the data provided by the organisers. If several corpora were available for a language, they were mixed to the one training and development dataset. We used original UD files for creating target files for training the word ordering component, i.e. we extracted a sequence of tokens (the field token in the CoNLL format) instead of using a reference sentence. Introduction SR’19 (Mille et al., 2019) is the second edition of the multilingual surface realisation task ran in 2018 (Mille et al., 2018). It aims at developing surface realisers in the multilingual setting. Given an input tree, a well-formed sentence should be produced. The input tree can be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most partic"
D19-6312,N06-2001,0,0.143277,"Missing"
D19-6312,W18-3609,0,0.0216653,"ven an input tree, a well-formed sentence should be produced. The input tree can be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with som"
D19-6312,W18-3602,0,0.0196362,"allow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with some slight modifications. This model, developed for the SR’18 shared task data, is a pipeline approach to the surface realisatio"
D19-6312,W11-2832,0,0.113128,"raining the word ordering component, i.e. we extracted a sequence of tokens (the field token in the CoNLL format) instead of using a reference sentence. Introduction SR’19 (Mille et al., 2019) is the second edition of the multilingual surface realisation task ran in 2018 (Mille et al., 2018). It aims at developing surface realisers in the multilingual setting. Given an input tree, a well-formed sentence should be produced. The input tree can be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview o"
D19-6312,D19-1305,1,0.777372,"l inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with some slight modifications. This model, developed for the SR’18 shared task data, is a pipeline approach to the surface realisation task, which has separate modules for word ordering, morphological inflection, and contraction generation. A brief outline is provided below; for more details about the model, we refer the reader to Shimorina and Gardent (2019). 3.1 Word Ordering (WO) Word ordering is modelled as a sequence-tosequence task, where an input tree is linearised. Linearisation differs from our previous approach in that it was augmented with information about the relative order of s"
D19-6312,W18-3604,0,0.0638174,"sentence should be produced. The input tree can be either an unordered dependency tree (shallow track), or a tree with a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with some slight modifications. This m"
D19-6312,W18-3603,0,0.0130442,"a predicate-argument structure (deep track). The predecessor of the task is SR’11 (Belz et al., 2011), which dealt with surface realisation for English using data from Penn Treebank. Then, most approaches were based on statistical and rulebased methods. In SR’18, most participants used neural-based components, however, most teams (7 out of 8) used a pipeline approach, where they dealt separately with word ordering and morphological inflection (Basile and Mazzei, 2018; Castro Ferreira et al., 2018; Elder and Hokamp, 2018; King and White, 2018; Madsack et al., 2018; Puzikov and Gurevych, 2018; Singh et al., 2018; Sobrevilla Cabezudo and Pardo, 2018). In this paper, we present a brief overview of the LORIA / Lorraine University system. We participated in the shallow track, and delivered solutions for all the languages proposed by the organisers. We also participated in generating output for all the types of corpora: in-domain, outof-domain, and predicted by syntax parsers. Re3 Model We made use of the model introduced in Shimorina and Gardent (2019) with some slight modifications. This model, developed for the SR’18 shared task data, is a pipeline approach to the surface realisation task, which has se"
denis-etal-2012-representation,C08-2017,0,\N,Missing
denis-etal-2012-representation,P07-1042,1,\N,Missing
E03-1030,W00-2001,0,0.0451495,"Missing"
E03-1030,P01-1019,0,0.247648,"e will compare our approach in work aiming at determining the correct rules and section 5. representations needed to build a representation of In this paper, we explore the idea of a semantic natural language meaning. In particular, compuconstruction method which is based on the TAG tational grammars were developed which by and derived tree and show how a Montague style (unilarge took on Montague's proposal, building sefication based) approach to semantic construction mantic representations in tandem with syntactic can be applied to Feature-Based Tree Adjoining structures. Thus for instance, (Copestake et al., 2001) Grammar (FTAG, (Vijay-Shanker and Joshi, 1988)). shows how to specify a Head Driven Phrase StrucWe relate our approach to existing proposals and ture Grammar (HPSG) which supports the parallel discuss two possibilities for implementation. construction of a phrase structure (or derived) tree 2 Hole semantics and of a semantic representation, (Zeevat et al., 1987) shows it for Unification Categorial GramWe start by introducing the semantic representamar (UCG) and (Dalrymple, 1999) for Lexical Function language we use. As mentioned above, Montional grammar (LFG). tague was using the lambda calcu"
E03-1030,W02-2218,1,0.867149,"first example can be captured as suggested in (Kallmeyer and Joshi, 2002) by ruling out multiple adjunctions (one VP modifier is adjoined to the other rather than both modifiers being applied to the verb) and treating ""usually"" as an ""opaque"" VP Ides to 10 : T(re j , PRO V P NP.V3 V hi), hi meet a 12 M(x2, 2 3) 10 : T(X1 ha), h1 &gt; 12,12 M(Xl, X3) FIG. 6 — Control verbs 5 Related work We now compare our approach with three related proposals: that of basing semantic construction on the TAG derivation tree as put forward in (Kallmeyer and Joshi, 2002); an extension of this proposal presented in (Kallmeyer, 2002b) and the 127 glue semantic approach proposed in (Frank and van Genabith, 2001). 5.1 Semantic construction and the derivation tree As can be seen there is no direct link between ""who"" and the verb introducing its scoping sentence, namely ""think"". Hence the scoping relation between ""who"" and ""does Paul think John said Bill likes"" cannot be captured. A third type of problems occur when several trees are adjoined to distinct nodes of the same tree. This typically occurs when raising verbs interact with long distance dependencies e.g., The LTAG derivation tree records how elementary trees are com"
E03-1030,C00-2087,0,0.0905448,"Missing"
E03-1030,C88-2147,0,0.833456,"ng at determining the correct rules and section 5. representations needed to build a representation of In this paper, we explore the idea of a semantic natural language meaning. In particular, compuconstruction method which is based on the TAG tational grammars were developed which by and derived tree and show how a Montague style (unilarge took on Montague's proposal, building sefication based) approach to semantic construction mantic representations in tandem with syntactic can be applied to Feature-Based Tree Adjoining structures. Thus for instance, (Copestake et al., 2001) Grammar (FTAG, (Vijay-Shanker and Joshi, 1988)). shows how to specify a Head Driven Phrase StrucWe relate our approach to existing proposals and ture Grammar (HPSG) which supports the parallel discuss two possibilities for implementation. construction of a phrase structure (or derived) tree 2 Hole semantics and of a semantic representation, (Zeevat et al., 1987) shows it for Unification Categorial GramWe start by introducing the semantic representamar (UCG) and (Dalrymple, 1999) for Lexical Function language we use. As mentioned above, Montional grammar (LFG). tague was using the lambda calculus. In compuOne grammatical framework for whic"
E14-1020,P13-1123,0,0.306837,"Missing"
E14-1020,C10-2116,0,0.0169514,"1 is an increment of qi . That is, qi+1 is derived from qi by adding, removing or substituting to qi a concept or a relation. The series were devised so as to encompass the whole range of possible operations at different points of the preceding query (e.g., at the last node/edge or on some node/edge occurring further to the left of the previous query); and include 14 revisions on 4 initial queries. For all queries, the word order of the best NL query produced by the generator was found to match the linearisation of the DL query. 5.3 Fluency and Clarity Following the so-called consensus model (Power and Third, 2010), the current, template based version of Quelo generates one clause per relation7 . Thus for instance, template-based Quelo will generate (5a) while our grammar based approach supports the generation of arguably more fluent sentences such as (5b). (5) a. I am looking for a car. Its make should be a Land Rover. The body style of the car should be an off-road car. The exterior color of the car should be beige. Figure 3: Online Evaluation. b. I am looking for car whose make is a Land Rover, whose body style is an off-road car and whose exterior color is beige. Comparing template- and grammar-base"
E14-1020,E09-1081,0,0.0230067,"formed by adding, deleting and revising the current query q at point p. The task of the generator is then to produce a natural language sentence for each new formal query q ′ ∈ rev(q) which results from this revision process. In other words, each time the user refines a query q to produce a new query q ′ , the system computes all revisions rev(q) of q ′ that are compatible with the underlying knowledge base using a reasoner. Each of these possible revisions is then input to the generator and the resulting revised NL queries are displayed to the user. In what follows, There is also much work (Schlangen and Skantze, 2009; Schlangen et al., 2009) in the domain of spoken dialog systems geared at modelling the incremental nature of dialog and in particular, at developing dialog systems where processing starts before the input is complete. In these approaches, the focus is on developing efficient architectures which support the timely interleaving of parsing and generation. Instead, our aim is to develop a principled approach to the incremental generation of a user query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maxi184 we assume that"
E14-1020,W09-3905,0,0.0264401,"nd revising the current query q at point p. The task of the generator is then to produce a natural language sentence for each new formal query q ′ ∈ rev(q) which results from this revision process. In other words, each time the user refines a query q to produce a new query q ′ , the system computes all revisions rev(q) of q ′ that are compatible with the underlying knowledge base using a reasoner. Each of these possible revisions is then input to the generator and the resulting revised NL queries are displayed to the user. In what follows, There is also much work (Schlangen and Skantze, 2009; Schlangen et al., 2009) in the domain of spoken dialog systems geared at modelling the incremental nature of dialog and in particular, at developing dialog systems where processing starts before the input is complete. In these approaches, the focus is on developing efficient architectures which support the timely interleaving of parsing and generation. Instead, our aim is to develop a principled approach to the incremental generation of a user query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maxi184 we assume that formal queries are repres"
E14-1020,P83-1023,0,0.77637,"urces, but also to support the final user in querying them, thus improving the usability of the integrated system. To support the wide access to these data sources, it is crucial to develop efficient and user-friendly ways to query them (Wache et al., 2001). In this paper, we present a Natural Language (NL) interface of an ontology-based query tool, called Quelo1 , which allows the end user to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1 Enrico Franconi Faculty of Computer Science Free University of Bozen-Bolzano Bozen-Bolzano, Italy 2 Related Work Our approach is related to two main strands of work: incremental generation and conceptual authoring. Incremental Generation (Oh and Rudnicky, 2000) used an n-gram language model to stochaskrdbapp.inf.unibz.it:8080/quelo 183 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183–191, c Gothenburg, Sweden, April 26-30 2014. 2014 Association"
E14-1020,C10-1042,1,0.395916,"j john), run(a,j), often(a). Sb c NPj John l1:john(j) NP↓ VPba Va runs VPx often VP*x lo:often(x) lv:run(a,j) l1:named(j john), lv:run(a,j), lv:often(a) Figure 2: Derivation and Semantics for “John often runs” Chart-Based Surface Realisation Given an FB-LTAG G of the type described above, sentences can be generated from semantic formulae by (i) selecting all trees in G whose semantics subsumes part of the input formula and (ii) combining 4 3 For a more detailed introduction to TAG and FB-LTAG, see (Vijay-Shanker and Joshi, 1988). 187 For more details on this algorithm, we refer the reader to (Gardent and Perez-Beltrachini, 2010). 5 The agenda is a book keeping device which stores all items that needs to be processed i.e., which need to be tried for combination with elements in the chart. 4.2.3 Referring Expression Generation The referring expression (RE) module takes as input the sequence of phrase structure trees output by the surface realiser and uses heuristics to decide for each NP whether it should be verbalised as a pronoun, a definite or an indefinite NP. These heuristics are based on the linear order and morpho-syntactic information contained in the phrase structure trees of the generated sentences. Beam Sear"
E14-1020,J07-1006,0,0.178483,"port the final user in querying them, thus improving the usability of the integrated system. To support the wide access to these data sources, it is crucial to develop efficient and user-friendly ways to query them (Wache et al., 2001). In this paper, we present a Natural Language (NL) interface of an ontology-based query tool, called Quelo1 , which allows the end user to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1 Enrico Franconi Faculty of Computer Science Free University of Bozen-Bolzano Bozen-Bolzano, Italy 2 Related Work Our approach is related to two main strands of work: incremental generation and conceptual authoring. Incremental Generation (Oh and Rudnicky, 2000) used an n-gram language model to stochaskrdbapp.inf.unibz.it:8080/quelo 183 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183–191, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Ling"
E14-1020,kow-belz-2012-lg,0,0.0137356,"uld be a Land Rover. The body style of the car should be an off-road car. The exterior color of the car should be beige. Figure 3: Online Evaluation. b. I am looking for car whose make is a Land Rover, whose body style is an off-road car and whose exterior color is beige. Comparing template- and grammar-based queries In this second experiment, we asked 10 persons (all proficient in the English language) to compare pairs of NL queries where one query is produced using templates and the other using our grammar-based generation algorithm. The evaluation was done online using the LG-Eval toolkit (Kow and Belz, 2012) and geared to collect relative quality judgements using visual analogue scales. After logging in, judges were given a description of the task. The sentence pairs were displayed as shown in Figure 3 with one sentence to the left and the other to the right. The judges were instructed to move the slider to the left to favor the sentence shown on the left side of the screen; and to the right to favor the sentence appearing to the right. Not moving the slider means that both sentences rank equally. To avoid creating a bias, We ran two experiments designed to assess how fluency impacts users. The f"
E14-1020,W00-0306,0,0.0648073,"uery tool, called Quelo1 , which allows the end user to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1 Enrico Franconi Faculty of Computer Science Free University of Bozen-Bolzano Bozen-Bolzano, Italy 2 Related Work Our approach is related to two main strands of work: incremental generation and conceptual authoring. Incremental Generation (Oh and Rudnicky, 2000) used an n-gram language model to stochaskrdbapp.inf.unibz.it:8080/quelo 183 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183–191, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics mally preserves the linear order of the query. tically generate system turns. The language model is trained on a dialog corpus manually annotated with word and utterance classes. The generation engine uses the appropriate language model for the utterance class and generates word sequences randomly according to"
E89-1034,E87-1029,0,\N,Missing
E93-1004,P86-1038,0,0.461447,"Missing"
E93-1004,T75-2001,0,0.312772,"Missing"
E93-1004,J91-2001,0,\N,Missing
E93-1018,C90-3018,0,0.0355142,"Missing"
E93-1018,J86-3001,0,0.0889706,"Missing"
E93-1018,P91-1008,0,0.0748867,"Missing"
E93-1018,J88-2004,0,0.0310952,"Missing"
E93-1018,P84-1085,0,0.0929146,"Missing"
E93-1018,J90-4001,0,\N,Missing
gardent-lorenzo-2010-identifying,messiant-etal-2008-lexschem,0,\N,Missing
gardent-lorenzo-2010-identifying,A97-1052,0,\N,Missing
gardent-lorenzo-2010-identifying,P08-3010,0,\N,Missing
gardent-lorenzo-2010-identifying,C04-1188,0,\N,Missing
gardent-lorenzo-2010-identifying,zeman-sarkar-2000-learning,0,\N,Missing
gardent-lorenzo-2010-identifying,abeille-barrier-2004-enriching,0,\N,Missing
gardent-lorenzo-2010-identifying,korhonen-etal-2006-large,0,\N,Missing
J13-3005,C96-1034,0,0.376661,"nsider a particular type of computational grammar, namely, tree-based grammars—that is, grammars where the basic units are trees (or tree descriptions) of arbitrary depth, such as Tree-Adjoining Grammar (TAG; Joshi, Levy, and Takahashi 1975), D-Tree Grammar (DTG; Rambow, Vijay-Shanker, and Weir 1995), Tree Description Grammars (TDG; Kallmeyer 1999) or Interaction Grammars (IG; Perrier 2000)— environments sharing all of the listed features are lacking. As we shall see in Section 7 of this article, there have been some proposals for grammar engineering environments for tree-based grammar (e.g., Candito 1996; Xia, Palmer, and Vijay-Shanker 1999, but these lack notational expressivity. This is partly due to the fact that tree-based formalisms offer an extended domain of locality where one can encode constraints between remote syntactic constituents. If one wants to define such constraints while giving a modular and incremental specification of the grammar, one needs a high level of notational expressivity, as we shall see throughout the article (and especially in Section 4). In this article, we present XMG (eXtensible MetaGrammar), a framework for specifying tree-based grammars. Focusing mostly on"
J13-3005,P03-1024,0,0.507858,"Missing"
J13-3005,C69-0101,0,0.536249,"Missing"
J13-3005,J11-1003,0,0.0149523,"s the criticisms leveled by Cohen-Sygal and Wintner (2007, 2009) against non-associative constraints on node unification do not apply. Briefly, in their work, Cohen-Sygal and Wintner (2007, 2009) showed that any polarity-based tree description formalism is not associative. In other words, when describing trees in terms of combinations of polarized structures, the order in which the structures are combined matters (i.e., the output structures depend on the combination order). This feature makes such formalisms not appropriate for a modular and collaborative grammar engineering, such as that of Cohen-Sygal and Wintner (2011) for Unification Grammar. In the XMG case, when using node colors, the tree description solver does not rely on any specific fragment combination order. It computes all possible combination orders. In this context, the grammar designer cannot think in terms of sequences of node identifications. This would lead to tree overgeneration. Again, it is important to remember that tree solving computes any valid tree model, independently of any specific sequence of node identifications (all valid node identifications are computed). In this context, non-associativity of color-based node identification"
J13-3005,copestake-flickinger-2000-open,0,0.0911674,"Missing"
J13-3005,P01-1019,0,0.109092,"Missing"
J13-3005,P95-1011,0,0.232963,"Missing"
J13-3005,W02-2233,1,0.737385,"Missing"
J13-3005,C08-1032,1,0.9499,"a modular account of the syntax/semantics interface in which linking constraints can be stipulated separately and reused to specify the various diatheses. In other words, the DYN feature structure allows us to extend the scope of some specific variables so that they can be unified with variables (or values) introduced in some other classes of the metagrammar. This concept of scope extension can be compared with that of hook in Copestake, Lascarides, and Flickinger (2001). 9 For more details on the interpretation of flat semantics and on its association with a grammar of natural language, see Gardent (2008). 601 Computational Linguistics Volume 39, Number 3 Control language. The linguistic units (named Content here) defined by the linguist can be abstracted and combined as follows: C ,...,C → Class ::= Namex11,...,xnk Content ::= SYN, SEM, DYN |Name |Content ∧ Content |Content ∨ Content Content The first clause states that the linguistic information encoded in Content is abstracted in a class named Name and that this class inherits classes C1 ,..., Ck and exports variables x1 ,..., xn . That is, XMG allows for abstraction, inheritance, and variable exports. By default, variables (referring to no"
J13-3005,P07-1042,1,0.873061,"Missing"
J13-3005,P07-2004,1,0.894592,"Missing"
J13-3005,J05-2003,0,0.0673111,"Missing"
J13-3005,kallmeyer-etal-2008-developing,1,0.809222,"roduce a TAG covering the following frames: intransitive (tree family N0V), transitive with a nominal complement (N0VN1), transitive with a clausal complement (N0VS1), transitive with modal complement (N0V0V1), ditransitive (N0VN1N2), ditransitive with a preposition (N0VN1ON2), ditransitive with a verbal complement (N0V0N1V1), ditransitive with an adjectival complement (N0VN1A), movement verbs with a nominal complement (N0V0V1N1), movement verbs with an adjectival complement (N0V0AV1), and movement ditransitive (N0V0N1V1N2). GerTT. Another XMG-based grammar corresponds to the German MC-TAG of Kallmeyer et al. (2008). This grammar, called GerTT, is in fact an MC-TAG with Tree Tuples (Lichte 2007). This variant of MCTAG has been designed to model free word order phenomena. This is done by imposing node sharing constraints on MCTAG derivations (Kallmeyer 2005). GerTT covers phenomena such as scrambling, coherent constructions, relative clauses, embedded questions, copula verbs, complementized sentences, verbs with various sub-categorization frames, nouns, prepositions, determiners, adjectives, and partly includes semantics. It is made of 103 tree tuples, compiled from 109 classes. 7. Related Work We now com"
J13-3005,W04-3325,0,0.0745752,"Missing"
J13-3005,W04-3321,0,0.0685973,"Missing"
J13-3005,W97-1508,0,0.235579,"he modeling of the tree fragment hierarchies required to specify tree-based grammars and of a syntax/semantics interface between semantic representations and syntactic trees. Finally, we briefly report on several grammars for French, English, and German that were implemented using XMG and compare XMG with other existing grammar specification frameworks for tree-based grammars. 1. Introduction In the late 1980s and early 1990s, many grammar engineering environments were developed to support the specification of large computational grammars for natural language. One may, for instance, cite XLE (Kaplan and Newman 1997) for specifying Lexical-Functional Grammars (LFG), LKB (Copestake and Flickinger 2000) for specifying Head-driven Phrase Structure Grammars (HPSG), and D OT CCG (Baldridge et al. 2007) for specifying Combinatory Categorial Grammars (CCG). Concretely, such environments usually rely on (i) a formal language used to describe a target computational grammar, and (ii) a processor for this language, which aims at generating the actual described grammar (and potentially at checking it, e.g., by feeding it to a parser). Although these environments were tailored for specific grammar formalisms, they sha"
J13-3005,C00-1065,0,0.042807,"c formula can be used to underspecify the meaning of the sentence “Every dog chases a cat”: l0 : ∀(x, h1 , h2 ) ∧ l1 ≤ h1 ∧ l3 : ∃(y, h3 , h4 ) ∧ ∧ l1 : Dog(x) l4 ≤ h3 ∧ ∧ l2 ≤ h2 l4 : Cat(y) ∧ ∧ l2 : Chase(x, y) l2 ≤ h4 (14) This formula denotes the following two first-order logic formulae, thereby describing the two possibles readings of this sentence.9 l0 : ∀(x, l1 , l3 ) ∧ l1 : Dog(x) ∧ l2 : Chase(x, y) ∧ l3 : ∃(y, l4 , l2 ) ∧ l4 : Cat(y) (15) l0 : ∀(x, l1 , l2 ) ∧ l1 : Dog(x) ∧ l2 : Chase(x, y) ∧ l3 : ∃(y, l4 , l0 ) ∧ l4 : Cat(y) (16) DYN. The DYN dimension generalizes Kinyon’s hypertag (Kinyon 2000) which is unified whenever two tree fragments are combined. Similarly, in XMG the DYN dimension is a feature structure that is unified whenever two XMG classes are combined through inheritance or through conjunction (see the discussion on XMG control language, subsequently). For instance, the following constraints ensure a coreference between the index I occurring in the syntactic dimension and the argument X occurring in the semantic dimension (indexsubject and arg1 are feature names, and E, I, X, and V local unification variables). C1 → Node [idx : I] ∧ indexsubject : I (17) C2 → L : P(E) ∧"
J13-3005,W06-1503,0,0.051829,"Missing"
J13-3005,C96-2120,0,0.331007,"Missing"
J13-3005,W98-0129,0,0.099141,"ations are usually called reified constraints. 610 Crabb´e et al. XMG: eXtensible MetaGrammar and if this is the case, we add to the input description a strict precedence constraint on these nodes according to their respective values of the property p:19 bn,m ∧ (pn < pm ) ⇒ n ≺+ m (26) bn,m ∧ (pm < pn ) ⇒ m ≺ n (27) + 5.3.3 Adding Color Constraints to Facilitate Grammar Writing. To further ease grammar development, XMG supports a node coloring mechanism that permits nameless node identification (Crabb´e and Duchier 2004), reminiscent of the polarity-based node identification first proposed by Muskens and Krahmer (1998) and later used by Duchier and Thater (1999) and Perrier (2000). Such a mechanism offers an alternative to explicit node identification using equations between node variables. The idea is to label node variables with a color property, whose value (either red, black, or white) can trigger node identifications. This mechanism is another parameter of the tree solver. When in use, the valid tree models must satisfy some color constraints, namely, they must only have red or black nodes (no remaining white nodes; these have to be identified with some black nodes). As shown in the following table, no"
J13-3005,C02-1153,0,0.164995,"le and second, the Passive meta-rule to the base tree. 596 Crabb´e et al. XMG: eXtensible MetaGrammar Passive meta-rule ⇒ Sr ?1 NP? Sr VP V []  mode Wh-Subject meta-rule 3  ?2 NP? VP ⎡ ⎣ ⎣ 3 ⎤ mode 2 passive 1 ⎡ V ?2NP? ↓  mode ?2 NP? ⇒ Sr  ?1 Sq  ?2NP? ↓  wh + NP↓NA ⎦ 1 + mode 2 ppart ?1  ⎤ passive Sr [] ⎦ PP [] P ?1 NP? by Figure 4 Simplified meta-rules for passive and wh-subject extraction. More generally a meta-rule is a procedural device that, given a tree instance, generates a new tree instance by adding, suppressing (hence possibly substituting) information in grammatical units. Prolo (2002) defines a set of meta-rules that can be used to specify a large FB-LTAG for English. Given an ordered set of meta-rules, however, there is no guarantee that the trees they derive are linguistically appropriate and that the derivation process terminates. Thus, to ensure termination and consistency, Prolo needs to additionally provide rule ordering schemes (expressed as automata). 3.2 XMG: Capturing Diathesis Using Disjunction XMG provides an alternative account for describing tree sets such as that of Figure 2 without lexical rules and without the related ordering constraints. In essence, the"
J13-3005,P95-1021,0,0.701406,"Missing"
J13-3005,P84-1075,0,0.45061,"rase Structure Grammars (HPSG), and D OT CCG (Baldridge et al. 2007) for specifying Combinatory Categorial Grammars (CCG). Concretely, such environments usually rely on (i) a formal language used to describe a target computational grammar, and (ii) a processor for this language, which aims at generating the actual described grammar (and potentially at checking it, e.g., by feeding it to a parser). Although these environments were tailored for specific grammar formalisms, they share a number of features. Firstly, they are expressive enough to characterize subsets of natural language. Following Shieber (1984), we call this feature weak completeness. Secondly, they are notationally expressive enough to relatively easily formalize important theoretical notions. Thirdly, they are rigorous, that is, the semantics of their underlying language is well defined and understood. Additionally, for an environment to be useful in practice, it should be simple to use (by a linguist), and make it possible to detect errors in the described target grammar. If we consider a particular type of computational grammar, namely, tree-based grammars—that is, grammars where the basic units are trees (or tree descriptions)"
J13-3005,C88-2147,0,0.90341,"be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree and adjunction inserts an auxiliary tree 593 Computational Linguistics Volume 39, Number 3 S N↓ N Marie Mary vu seen V V V V S N↓ N Jean John ∗ ⇒ N Marie Mary V V N V a vu has seen Jean John a has Figure 1 Sample derivation of Marie a vu Jean ‘Mary has seen John’ in a TAG. into a tree. Figure 1 shows a toy TAG generating the sentence Marie a vu Jean ‘Mary has seen John’ and sketches its derivation.1 Among existing variants of TAG, one commonly used in practice is Lexicalized FB-LTAG (Vijay-Shanker and Joshi 1988). A lexicalized TAG is such that each elementary tree has at least one leaf labeled with a lexical item (word), whereas in an FB-LTAG, tree nodes are additionally decorated with two feature structures (called top and bottom). These feature structures are unified during derivation as follows. On substitution, the top features of the substitution node are unified with the top features of the root node of the tree being substituted in. On adjunction, the top features of the root of the auxiliary tree are unified with the top features of the node where adjunction takes place; and the bottom featur"
J13-3005,C92-1034,0,0.421336,"ng Lexical Rules Following Flickinger (1987), redundancy among grammatical descriptions is often handled using two devices: an inheritance hierarchy and a set of lexical rules. Whereas the inheritance hierarchy permits us to encode the sharing of common substructures, lexical rules (sometimes called meta-rules) permit us to capture relationships between trees by deriving new trees from already specified ones. For instance, passive trees will be derived from active ones. Although Flickinger’s (1987) approach was developed for HPSGs, several similar approaches have been put forward for FB-LTAG (Vijay-Shanker and Schabes 1992; Becker 1993; Evans, Gazdar, and Weir 1995; XTAG Research Group 2001). One important drawback of these approaches, however, is that they are procedural in that the order in which lexical rules apply matters. For instance, consider again the set of trees given in Figure 2. In the meta-rule representation scheme adopted by Becker (1993), the base tree (a) would be specified in the inheritance hierarchy grouping all base trees, and the derived trees (b, c, d) would be generated by applying one or more meta-rules on this base tree. Figure 4 sketches these meta-rules. The left-hand side of the met"
J13-3005,W10-4414,0,0.427943,"Missing"
J13-3005,P06-2032,1,\N,Missing
J13-3005,J15-1003,1,\N,Missing
J13-3005,C00-2087,0,\N,Missing
J15-1003,W12-4613,0,0.0126653,"es were combined using which operations to yield that derivation. In this tree, each vertex is labeled with a tree name and each edge with a description of the operation (node address and operation type) used to combine the trees labeling its end vertices. As we shall see in Section 3.2, in TAG, each derivation tree specifies a unique parse tree, also called derived tree. In previous work, it has been argued that TAG derivation trees provide a good approximation of semantic dependencies between the words of a sentence (Kroch 1989; Rambow, Vijay-Shanker, and Weir 1995; Candito and Kahane 1998; Kallmeyer and Kuhlmann 2012). As shown by Schabes and Shieber (1994), however, there are several possible ways of defining TAG derivation trees, depending on how multiple adjunction of several auxiliary trees at the same tree node is handled. The standard notion of derivation proposed by Vijay-Shanker (1987) forbids multiple adjunction, thus enforcing dependent derivations. In contrast, the extended notion of derivation proposed by Schabes ∗ UMR 7503, Campus Scientifique, BP 239, F-54506 Vandoeuvre-l`es-Nancy Cedex, France. E-mail:{claire.gardent,shashi.narayan}@loria.fr. Submission received: 2 August 2013; revised versi"
J15-1003,P95-1021,0,0.870671,"Missing"
J15-1003,C92-2065,0,0.426241,"join to the tree selected by reminded. Thus, constraints placed by the verb on its modifiers must be passed through by modifier trees (here, the tree for yesterday) to also rule out sentences such as Example (2a). Propagating selective adjunction constraints in TAG would lead to a formalism for which derivation trees are no longer context-free (Schabes and Shieber 1994). The second motivation for independent adjunction stems from probabilistic approaches. Stochastic lexicalized TAG specifies the probability of an adjunction of a given auxiliary tree at a given node in another elementary tree (Resnik 1992; Schabes 1992). Thus, under the standard notion of derivation, the overall probability of the string roasted red pepper would be determined by the probability of red adjoining to pepper and the probability of roasted adjoining to red. In contrast, independent adjunction would result in a derivation such that the overall probability of the string roasted red pepper would be determined by the probability of both red and roasted adjoining to pepper. Schabes and Shieber (1994, page 97) argue that it is plausible that “the most important relationships to characterize statistically are those betwee"
J15-1003,1991.iwpt-1.4,0,0.339851,"Missing"
J15-1003,C92-2066,0,0.499547,"ree selected by reminded. Thus, constraints placed by the verb on its modifiers must be passed through by modifier trees (here, the tree for yesterday) to also rule out sentences such as Example (2a). Propagating selective adjunction constraints in TAG would lead to a formalism for which derivation trees are no longer context-free (Schabes and Shieber 1994). The second motivation for independent adjunction stems from probabilistic approaches. Stochastic lexicalized TAG specifies the probability of an adjunction of a given auxiliary tree at a given node in another elementary tree (Resnik 1992; Schabes 1992). Thus, under the standard notion of derivation, the overall probability of the string roasted red pepper would be determined by the probability of red adjoining to pepper and the probability of roasted adjoining to red. In contrast, independent adjunction would result in a derivation such that the overall probability of the string roasted red pepper would be determined by the probability of both red and roasted adjoining to pepper. Schabes and Shieber (1994, page 97) argue that it is plausible that “the most important relationships to characterize statistically are those between modifier and"
J15-1003,P88-1032,0,0.469864,"Missing"
J15-1003,P92-1022,0,0.367781,"Missing"
J15-1003,J94-1004,0,0.121632,"yield that derivation. In this tree, each vertex is labeled with a tree name and each edge with a description of the operation (node address and operation type) used to combine the trees labeling its end vertices. As we shall see in Section 3.2, in TAG, each derivation tree specifies a unique parse tree, also called derived tree. In previous work, it has been argued that TAG derivation trees provide a good approximation of semantic dependencies between the words of a sentence (Kroch 1989; Rambow, Vijay-Shanker, and Weir 1995; Candito and Kahane 1998; Kallmeyer and Kuhlmann 2012). As shown by Schabes and Shieber (1994), however, there are several possible ways of defining TAG derivation trees, depending on how multiple adjunction of several auxiliary trees at the same tree node is handled. The standard notion of derivation proposed by Vijay-Shanker (1987) forbids multiple adjunction, thus enforcing dependent derivations. In contrast, the extended notion of derivation proposed by Schabes ∗ UMR 7503, Campus Scientifique, BP 239, F-54506 Vandoeuvre-l`es-Nancy Cedex, France. E-mail:{claire.gardent,shashi.narayan}@loria.fr. Submission received: 2 August 2013; revised version received: 16 June 2014; accepted for"
J15-1003,W98-0106,0,0.0430327,"which elementary TAG trees were combined using which operations to yield that derivation. In this tree, each vertex is labeled with a tree name and each edge with a description of the operation (node address and operation type) used to combine the trees labeling its end vertices. As we shall see in Section 3.2, in TAG, each derivation tree specifies a unique parse tree, also called derived tree. In previous work, it has been argued that TAG derivation trees provide a good approximation of semantic dependencies between the words of a sentence (Kroch 1989; Rambow, Vijay-Shanker, and Weir 1995; Candito and Kahane 1998; Kallmeyer and Kuhlmann 2012). As shown by Schabes and Shieber (1994), however, there are several possible ways of defining TAG derivation trees, depending on how multiple adjunction of several auxiliary trees at the same tree node is handled. The standard notion of derivation proposed by Vijay-Shanker (1987) forbids multiple adjunction, thus enforcing dependent derivations. In contrast, the extended notion of derivation proposed by Schabes ∗ UMR 7503, Campus Scientifique, BP 239, F-54506 Vandoeuvre-l`es-Nancy Cedex, France. E-mail:{claire.gardent,shashi.narayan}@loria.fr. Submission received"
J15-1003,C08-1032,1,0.828088,"modifier auxiliary trees (Schabes and Shieber (1994), Section 3.1), they define a parsing algorithm that assigns dependent derivations to predicative auxiliary trees but independent derivations to multiple modifier auxiliary trees adjoining to the same node. In case both predicative and modifier auxiliary trees adjoin to the same node, their parsing algorithm ensures that predicative trees appear above the modifier trees in the derived tree. This parsing algorithm is defined for featureless variants of TAG. In contrast, in implemented TAGs (e.g., XTAG [The XTAG Research Group 2001], SemXTAG [Gardent 2008], or XXTAG1 [Alahverdzhieva 2008]) feature structures and feature unification are central. They are used to minimize the size of the grammar; to model linguistic phenomena such as verb/subject agreement; and to encode a unification-based syntax/semantics interface (e.g., Gardent and Kallmeyer 2003). In this article, we extend Schabes and Shieber’s proposal to Feature-Based TAG (FB-TAG); and we show that the resulting parsing algorithm naturally accounts for the interplay of dependent vs. independent derivation structures with syntactic constraints, linear ordering, and scopal vs. nonscopal se"
J15-1003,E03-1030,1,0.799083,"and modifier auxiliary trees adjoin to the same node, their parsing algorithm ensures that predicative trees appear above the modifier trees in the derived tree. This parsing algorithm is defined for featureless variants of TAG. In contrast, in implemented TAGs (e.g., XTAG [The XTAG Research Group 2001], SemXTAG [Gardent 2008], or XXTAG1 [Alahverdzhieva 2008]) feature structures and feature unification are central. They are used to minimize the size of the grammar; to model linguistic phenomena such as verb/subject agreement; and to encode a unification-based syntax/semantics interface (e.g., Gardent and Kallmeyer 2003). In this article, we extend Schabes and Shieber’s proposal to Feature-Based TAG (FB-TAG); and we show that the resulting parsing algorithm naturally accounts for the interplay of dependent vs. independent derivation structures with syntactic constraints, linear ordering, and scopal vs. nonscopal semantic dependencies. The article is organized as follows. In Section 2, we recap the motivations for independent derivations put forward by Schabes and Shieber (1994) and we briefly discuss the interactions that may arise between dependent and independent derivations. Section 3 summarizes their appr"
J15-1003,W00-2015,0,0.0297186,"needs to be adjoined above a predicative adjunction. Figure 15 shows the complete recognition algorithm modified to rule out spurious parses in the case of multiple scopal auxiliary trees and intersective modifier auxiliary trees. 5.3.4 Weak Generative Equivalence. The weak-generative equivalence refers to the set of strings characterized by the formal system. In contrast, the strong-generative equivalence relates to the set of structural descriptions (such as derivation trees, dags, proof trees, etc.) assigned by a formal system to the strings that it specifies (Vijay-Shankar and Joshi 1985; Joshi 2000). Using an argument similar to that put forward by Schabes and Shieber (1994), we can prove the weak-generative equivalence of TAGs under the dependent and our independent derivations. We call the set of languages generated by the standard derivation in TAG, TALstd ; the set of languages generated by Schabes and Shieber’s extended derivation in TAG, TALextss ; the set of languages generated with our modifications for FB-TAG, TALext ; and the set of languages generated by the LIG, LIL. Our derivation allows both dependent and independent derivations; therefore, our derivation will recognize all"
J15-1003,P85-1011,0,0.730448,"node prediction (the tree dominated by the foot of the auxiliary tree has been recognized), the Type 5 completor rule unifies the bottom feature structure of the foot of the auxiliary tree with the bottom feature structure of the adjunction site. Finally, the Type 6 completor unifies the top feature structure of a substitution node with the top feature structure of the root of the tree being substituted. r Scanner: hb[..η] → Γ • w∆, i, j, k, li , hb[..η] → Γw • ∆, i, j, k, l + 1i w = wl+1 , ∅ 5 The indices hi, j, k, li have been used in previous parsing algorithms for tree-adjoining grammars (Vijay-Shankar and Joshi 1985; Schabes and Joshi 1988; Schabes 1991). They deliver the same functionality here. 58 Gardent and Narayan Multiple Adjunction in Feature-Based Tree Adjoining Grammar If w (a terminal symbol) occurs at position l+1, the scanner rule creates a new item whose span extends to l+1. r Predictor: hN[..η] → Γ • N′ [µ]∆, i, j, k, li , hN′ [µ] → •Θ, l, −, −, li ∅ Predictor rules are produced for all types of production rules. N and N′ are LIG variables taking the value t or b. Γ, ∆, and Θ are the sequences of LIG nonterminals associated with stacks of node indices. µ is a sequence of node indices. r Typ"
J15-1003,C88-2147,0,0.90548,"djunction of the modifier auxiliary tree with the root node ηr , the following LIG production rule is generated. b[..η] → t[..ηηr ] Figure 5 LIG variant of TAG for Schabes and Shieber’s Extended derivation and associated production rules. The top and bottom components of the nodes are presented by •. Type 4(a) transitions support dependent derivations, and Type 4(b) transitions support independent derivations. 4.1 Feature-Based Tree Adjoining Grammar We start by a brief description of FB-TAG and of the unifications performed during derivation. FB-TAG was introduced by Vijay-Shanker (1987) and Vijay-Shanker and Joshi (1988, 1991) to support the use of feature structures in TAG. Figure 6 shows a toy FB-TAG for illustration. An FB-TAG differs from a TAG in that tree nodes are decorated with feature structures. Nonterminal and foot nodes are decorated with two feature structures called top (T) and bottom (B), and substitution nodes are decorated with a single top feature structure. During derivation, feature structure unification constrains tree combination, as illustrated in Figure 7. Substitution unifies the top feature structure of a substitution node with the top feature structure of the root node of the tree"
J15-1003,J93-4002,0,0.364846,"Missing"
J15-1003,P88-1034,0,0.418365,"e associated with a stack of symbols, called indices. A LIG rule can thus be represented as follows: N[..µ] → N1 [µ1 ] . . . Ni−1 [µi−1 ]Ni [..µi ]Ni+1 [µi+1 ] . . . Nn [µn ] (8) N and Ni are nonterminals whereas µ and µi are strings of stack symbols. The symbol .. stands for the remainder of the stack symbols. Note that the remainder of the stack symbols associated with the left-hand side is associated with only one of the nonterminal (namely, Ni ) on the right-hand side. 46 Gardent and Narayan Multiple Adjunction in Feature-Based Tree Adjoining Grammar LIGs have been used in the literature (Weir and Joshi 1988; Vijay-Shanker and Weir 1991) to provide a common framework for the extensions of context-free grammars. In particular, Vijay-Shanker and Weir (1991, 1993) showed a weak equivalence between LIGs, TAGs, and combinatory categorial grammars (Steedman 2000) and proposed a LIG-based polynomial-time CYK recognition algorithm for TAGs and combinatory categorical grammars. In what follows, we show how Schabes and Shieber (1994) use a LIG variant of TAGs to license both dependent and independent derivations. 3.4 TAG to LIG Compilation The TAG-to-LIG compilation proposed by Vijay-Shanker and Weir (1991"
J15-1003,J13-3005,1,\N,Missing
J15-1003,H86-1020,0,\N,Missing
J17-1001,D10-1049,0,0.074276,"Missing"
J17-1001,W13-2322,0,0.0278067,"re interested in exploring how our approach could be applied to more complex text and more complex data and, in particular, how it could be extended to handle the interactions between discourse connectives and microplanning. Indeed, the approach we have described here is currently restricted to simple data (conjunctive tree shape queries) and relatively simple text (limited discourse structure). In the future, we intend to investigate whether a similar hybrid approach could be used to generate structured discourse from more complex data such as, for instance, Abstract Meaning Representations (Banarescu et al. 2013), and representations produced by machine reading tools such as FRED (Draicchio et al. 2013) or the Discourse Representations Structures derived by Boxer (Bos 2008). Appendix A. List of TAG Trees and Syntactic Classes Used by the Hypertagger Table A1 shows the list of TAG trees and abstract syntactic classes used in the annotation of the training corpus. The tree names follow the naming conventions of TAG. Uppercase letters indicate anchors. Phrasal projections are postfixed with the “x” symbol and integers indicate semantic role (e.g., 0 for the first argument of a relation, 1 for the second)"
J17-1001,J99-2004,0,0.388706,"erestingly, this also allows for the training of a “high level hypertagger” whose categories are not lexical or syntactic categories but general, more abstract, syntactic classes describing the surface realization of, for instance, a verb argument. This contrasts both with approaches to data-to-text generation that map meaning representations to sentences without assuming an intervening syntax (Konstas and Lapata 2012b, 2012a; Lu, Ng, and Lee 2009; Dethlefs et al. 2013), and with traditional supertagging approaches that operate on lexical categories, thereby requiring a large training corpus (Bangalore and Joshi 1999; Espinosa, White, and Mehay 2008). Another important feature of our approach is that it is domain-independent and can be applied to any knowledge base independent of its domain. As we shall show in Section 4.3, because it relies on a generic grammar, an automatically induced lexicon, and a hypertagger trained on a small data-to-text corpus, our approach can be applied to any knowledge base independent of the domain it covers. In sum, the main features of our approach to query generation are that: r it jointly models sentence segmentation, aggregation, and surface realization (cf. Sections 5 a"
J17-1001,W08-2222,0,0.0185494,"etween discourse connectives and microplanning. Indeed, the approach we have described here is currently restricted to simple data (conjunctive tree shape queries) and relatively simple text (limited discourse structure). In the future, we intend to investigate whether a similar hybrid approach could be used to generate structured discourse from more complex data such as, for instance, Abstract Meaning Representations (Banarescu et al. 2013), and representations produced by machine reading tools such as FRED (Draicchio et al. 2013) or the Discourse Representations Structures derived by Boxer (Bos 2008). Appendix A. List of TAG Trees and Syntactic Classes Used by the Hypertagger Table A1 shows the list of TAG trees and abstract syntactic classes used in the annotation of the training corpus. The tree names follow the naming conventions of TAG. Uppercase letters indicate anchors. Phrasal projections are postfixed with the “x” symbol and integers indicate semantic role (e.g., 0 for the first argument of a relation, 1 for the second). A beta prefix indicates an auxiliary tree. The W prefix indicates a wh-NP extraction. Thus for instance, W0nx0VVVnx1 indicates a subject relative tree (W0nx0) wit"
J17-1001,C04-1041,0,0.0514778,"(Car ⊓ Coupe) b. PRO0VVnx1 nx betanxPUnx PRO0VVnx1 nx betanxBEnx c. sell(a, d, c), car(c), coupe(c) 3.3.4 Hypertagging. Supertagging and hypertagging (Espinosa, White, and Mehay 2008) are preprocessing steps to parsing and surface realization that assign likely categories to the input based on contextual information. Supertagging was first introduced by Bangalore and Joshi (1999) to assign likely categories to words before parsing begins, thereby reducing the initial search space. They showed that supertagging speeds up parsing times considerably. Likewise, Curran, Clark, and Vadas (2006) and Clark and Curran (2004) showed that supertagging leads to extremely efficient Combinatory Categorial Grammar parsing and Espinosa, White, and Mehay (2008) showed that hypertagging can achieve substantial improvements in realization speed with superior realization quality. Similarly, we use hypertagging to improve efficiency. Importantly however, we also use hypertagging to monitor several of the choices that need to be made during the microplanning stage of generation. Contrary to parsing, where supertagging aims to identify a single correct sequence of PoS tags for the input string, in surface realization there may"
J17-1001,P06-1088,0,0.266667,"Missing"
J17-1001,E87-1001,0,0.330504,"at were correctly accounted for by our approach. Section 7 concludes with pointers for further research. 2. Related Work Earlier rule-based work on microplanning NLGs has explored various ways of combining lexicalization, surface realization, and aggregation in architectures ranging from integrated systems where all decisions are made simultaneously (Appelt 1982) to strictly sequential pipelines (Reiter, Dale, and Feng 2000). Although the sequential approach is easier to develop and to maintain, it cannot easily account for the interactions that are known to exist between the various modules (Danlos 1987). A sequential approach can in fact induce a “generation gap” (Meteer 1990) whereby generation fails because a choice made earlier in the pipeline conflicts with the constraints of a module occurring further down the pipeline. Moreover, taking individual decisions at different sub-tasks in a sequential manner might lead to suboptimal solutions (Marciniak and Strube 2005). On the other hand, symbolic joint approaches to microplanning lack in robustness and efficiency. They also require much time and expertise to develop the various linguistic resources (grammar, lexicon, text plans, etc.) they"
J17-1001,P13-1123,0,0.0493188,"Missing"
J17-1001,W13-0108,0,0.0371889,"Missing"
J17-1001,P08-1022,0,0.14449,"Missing"
J17-1001,P07-1042,1,0.737068,"o verbalize these relation identifiers (see Trevisan [2010] for more details on this evaluation). Thus, in general, the lexicon extraction method proposed by Trevisan (2010) provides a generic procedure for automatically lexicalizing ontological data. Although more sophisticated methods could be used to improve both coverage and output quality, we focus here on the interactions between surface realization, sentence segmentation, and aggregation (rather than lexicalization) and leave the question of a better and more complete lexicalization method for further research. 3.3.2 Grammar. Following Gardent and Kow (2007), we use a Feature-Based Lexicalized Tree Adjoining Grammar (FB-LTAG) augmented with a unification based semantics for generation. For a precise definition of FB-LTAG, we refer the reader to Vijay-Shanker and Joshi (1988). In essence, a FB-LTAG is a set of elementary trees whose nodes are decorated with feature structures and that can be combined using either substitution or adjunction to produce phrase structure trees (also called derived trees). Substitution of tree γ1 at node n of the derived tree γ2 rewrites n in γ2 with γ1 . n must be a substitution node (marked with a down arrow). Adjunc"
J17-1001,C10-1042,1,0.772304,"e union of their semantics modulo unification. Figure 3 shows an example toy FB-LTAG with unification semantics. The dotted arrows indicate possible tree combinations (substitution for car, adjunction for coup´e). As the trees are combined, the semantics is the union of their semantics modulo unification. Thus, given the grammar and the derivation shown, the semantics of It sells a car, a coup´e. is as shown—namely, sell(a,d,c),car(c),coupe(c) or equivalently ∃ sell.(Car ⊓ Coupe). 3.3.3 Chart-Based Surface Realization. For surface realization, we combine the chart-based algorithm described in Gardent and Perez-Beltrachini (2010) and Perez-Beltrachini, Gardent, and Franconi (2014) with a hypertagger filtering the initial search space. This algorithm proceeds in five main steps as follows. r Given the input linearized query, hypertagging predicts n best sequences of grammar units. These grammar units are either FB-LTAG trees from the grammar or more abstract syntactic classes such as subject relative (SubjRel). r Lexical Selection retrieves from the grammar all lexical entries whose semantics subsumes the input semantics and that are consistent with the hypertagger filter. The grammar trees selected by these lexical en"
J17-1001,P13-1138,0,0.0362459,"Missing"
J17-1001,P12-1039,0,0.0285115,"Missing"
J17-1001,N12-1093,0,0.0962009,"Missing"
J17-1001,P13-2100,0,0.0713877,"enerally, whereas our grammar systematically encodes the various ways in which a proposition can be verbalized (e.g., using a relative clause or an elided clause) and uses these to support aggregation, Zarrieß and Kuhn use a limited set of learned transformations to map deep to shallow syntax. Empirically, another difference with our work is that whereas Zarrieß and Kuhn focus on the interactions between referring expressions, syntax, and 5 Computational Linguistics Volume 43, Number 1 word order, we work on the interactions between surface realization, aggregation, and sentence segmentation. Lampouras and Androutsopoulos (2013) present a joint model for content selection, surface realization, and aggregation. Using Integer Linear Programming, they specify constraints designed to maximize the importance and the number of the selected facts so as to enhance informativeness while minimizing the number of selected entities to favor aggregation. They apply their approach to the task of verbalizing sets of OWL axioms and show that, in comparison to a handcrafted NLG system, their approach provides more compact text with no deterioration in text quality. This approach is similar to ours in that it focuses on modeling the i"
J17-1001,D09-1042,0,0.0703006,"Missing"
J17-1001,W05-0618,0,0.0577871,"1982) to strictly sequential pipelines (Reiter, Dale, and Feng 2000). Although the sequential approach is easier to develop and to maintain, it cannot easily account for the interactions that are known to exist between the various modules (Danlos 1987). A sequential approach can in fact induce a “generation gap” (Meteer 1990) whereby generation fails because a choice made earlier in the pipeline conflicts with the constraints of a module occurring further down the pipeline. Moreover, taking individual decisions at different sub-tasks in a sequential manner might lead to suboptimal solutions (Marciniak and Strube 2005). On the other hand, symbolic joint approaches to microplanning lack in robustness and efficiency. They also require much time and expertise to develop the various linguistic resources (grammar, lexicon, text plans, etc.) they are based upon. In previous work on sentence planning, Walker, Rambow, and Rogati (2001) therefore proposed a trainable sentence planner (called SPoT) that addresses the interactions occurring between content ordering, lexicalization, and aggregation. SPoT is part of a dialog system in the travel domain, which was later on extended to provide restaurant information (SPaR"
J17-1001,P02-1040,0,0.0979217,"Missing"
J17-1001,E14-1020,1,0.908141,"Missing"
J17-1001,C88-2147,0,0.246504,"tically lexicalizing ontological data. Although more sophisticated methods could be used to improve both coverage and output quality, we focus here on the interactions between surface realization, sentence segmentation, and aggregation (rather than lexicalization) and leave the question of a better and more complete lexicalization method for further research. 3.3.2 Grammar. Following Gardent and Kow (2007), we use a Feature-Based Lexicalized Tree Adjoining Grammar (FB-LTAG) augmented with a unification based semantics for generation. For a precise definition of FB-LTAG, we refer the reader to Vijay-Shanker and Joshi (1988). In essence, a FB-LTAG is a set of elementary trees whose nodes are decorated with feature structures and that can be combined using either substitution or adjunction to produce phrase structure trees (also called derived trees). Substitution of tree γ1 at node n of the derived tree γ2 rewrites n in γ2 with γ1 . n must be a substitution node (marked with a down arrow). Adjunction of the tree β at node n of the derived tree γ2 inserts β into γ2 at n (n is spliced to “make room” for β). The adjoined tree must be an auxiliary tree, that is, a tree with a foot node (marked with a star) and such t"
J17-1001,N01-1003,0,0.570154,"Missing"
J17-1001,N07-1022,0,0.034107,"akeOfModel.LandRoverDiscovery ⊓ ∃isMakeOf.DemonstrationCar I am looking for a car make located in a country. The car make should be the make of a land rover discovery and should be the make of a demonstration car. b. Car ⊓ ∃producedby.CarMake ⊓ ∃soldBy.(CarDealer ⊓ ∃locatedInCountry.Country ⊓ ∃equippedWith.NavigationSystem ⊓ ∃equippedWith.Abs ⊓ ∃equippedWith.GasolineEngine) I am looking for a car produced by a car make and sold by a car dealer located in a country. It should be equipped with a navigation system, an abs and a gasoline engine. 7. Conclusion Recent statistical approaches to NLG (Wong and Mooney 2007; Angeli, Liang, and Klein 2010; Konstas and Lapata 2012b, 2012a) have typically relied on sizable training corpora to train models that directly map meaning representations to strings. In contrast, we developed a hybrid model that integrates a statistical hypertagger in a grammar-based generation system. This has several advantages. First, because the grammar used is generic and the hypertagger trained to learn syntactic units (rather than, e.g., domain-dependent semantic ones), the approach is domain-independent and can be applied to any knowledge base. Applying the approach to a new knowled"
J17-1001,P13-1152,0,0.0618099,"Missing"
J17-1001,J13-3005,1,\N,Missing
N18-6002,C10-1128,0,0.0697397,"Missing"
N18-6002,N16-1015,0,0.0416556,"Missing"
N18-6002,D15-1199,0,0.0770728,"Missing"
P01-1028,E89-1001,0,0.0914324,"Missing"
P01-1028,C92-2092,0,0.262711,"hrases) built when gener ating a phrase with  intersective modifiers is ÿ in the case where the grammar imposes a single linear ordering of these modifiers. For instance, when generating “The fierce little black cat”, a naive constructive approach will also build the subphrases (1) only to find that these cannot be part of the output as they do not exhaust the input semantics. (1) The fierce black cat, The fierce little cat, The little black cat, The black cat, The fierce cat, The little cat, The cat. To remedy this shortcoming, various heuristics and parsing strategies have been proposed. (Brew, 1992) combines a constraint-propagation mechanism with a shift-reduce generator, propagating constraints after every reduction step. (Carroll et al., 1999) advocate a two-step generation algorithm in which first, the basic structure of the sentence is generated and second, intersective modifiers are adjoined in. And (Poznanski et al., 1995) make use of a tree reconstruction method which incrementally improves the syntactic tree until it is accepted by the grammar. In effect, the constraint-based encoding of the axiomatic view of generation proposed here takes advantage of Brew’s observation that co"
P01-1028,P96-1027,0,0.211938,"asic linguistic units are trees rather than categories and (iii) it assumes a flat semantics. In what follows we show that this combination of features results in a generator which integrates the positive aspects of both top-down and bottom-up generators. In this sense, it is not unlike (Shieber et al., 1990)’s semantic-head-driven generation. As will become clear in the following section however, it differs from it in that it integrates stronger lexicalist (i.e. bottom-up) information. 5.1 Bottom-Up Generation Bottom-up or “lexically-driven” generators (e.g., (Shieber, 1988; Whitelock, 1992; Kay, 1996; Carroll et al., 1999)) start from a bag of lexical items with instantiated semantics and generates a syntactic tree by applying grammar rules whose right hand side matches a sequence of phrases in the current input. There are two known disadvantages to bottomup generators. On the one hand, they require that the grammar be semantically monotonic that is, that the semantics of each daughter in a rule subsumes some portion of the mother semantics. On the other hand, they are often overly nondeterministic (though see (Carroll et al., 1999) for an exception). We now show how these problems are de"
P01-1028,C00-2087,0,0.0211279,"d bottom-up generators, Section 6 reports on a proof-of-concept implementation and Section 7 concludes with pointers for further research. 2 Description Grammars There is a range of grammar formalisms which depart from Tree Adjoining Grammar (TAG) by taking as basic building blocks tree descriptions rather than trees. D-Tree Grammar (DTG) is proposed in (Rambow et al., 1995) to remedy some empirical and theoretical shortcomings of TAG; Tree Description Grammar (TDG) is introduced in (Kallmeyer, 1999) to support syntactic and semantic underspecification and Interaction Grammar is presented in (Perrier, 2000) as an alternative way of formulating linear logic grammars. Like all these frameworks, DG uses tree descriptions and thereby benefits first, from the extended domain of locality which makes TAG particularly suitable for generation (cf. (Joshi, 1987)) and second, from the monotonicity which differentiates descriptions from trees with respect to adjunction (cf. (Vijay-Shanker, 1992)). DG differs from DTG and TDG however in that it adopts an axiomatic rather than a generative view of grammar: whereas in DTG and TDG, derived trees are constructed through a sequence of rewriting steps, in DG deriv"
P01-1028,P95-1035,0,0.0189947,"f the output as they do not exhaust the input semantics. (1) The fierce black cat, The fierce little cat, The little black cat, The black cat, The fierce cat, The little cat, The cat. To remedy this shortcoming, various heuristics and parsing strategies have been proposed. (Brew, 1992) combines a constraint-propagation mechanism with a shift-reduce generator, propagating constraints after every reduction step. (Carroll et al., 1999) advocate a two-step generation algorithm in which first, the basic structure of the sentence is generated and second, intersective modifiers are adjoined in. And (Poznanski et al., 1995) make use of a tree reconstruction method which incrementally improves the syntactic tree until it is accepted by the grammar. In effect, the constraint-based encoding of the axiomatic view of generation proposed here takes advantage of Brew’s observation that constraint propagation can be very effective in pruning the search space involved in the generation process. In constraint programming, the solutions to a constraint satisfaction problem (CSP) are found by alternating propagation with distribution steps. Propagation is a process of deterministic inference which fills out the consequences"
P01-1028,P95-1021,0,0.162754,"for generation, a model generator can be used to enumerate the models satisfying the bag of lexical items selected by the lexical look up phase on the basis of the input semantics. How can we design model generators which work efficiently on natural language input i.e. on the type of information delivered by logic based grammars? (Duchier and Gardent, 1999) shows that constraint programming can be used to implement a model generator for tree logic (Backofen et al., 1995). Further, (Duchier and Thater, 1999) shows that this model generator can be used to parse with descriptions based grammars (Rambow et al., 1995; Kallmeyer, 1999) that is, on logic based grammars where lexical entries are descriptions of trees expressed in some tree logic. In this paper, we build on (Duchier and Thater, 1999) and show that modulo some minor modifications, the same model generator can be used to generate with description based grammars. We describe the workings of the algorithm and compare it with standard existing top-down and bottom-up generation algorithms. In specific, we argue that the change of perspective offered by the constraint-based, axiomatic approach to processing presents some interesting differences with"
P01-1028,J90-1004,0,0.259668,"Missing"
P01-1028,C88-2128,0,0.658731,")) nor with a grammar allowing for trace anchored lexical entries. The mirror restriction for generation is that each lexical entry must be associated with exactly one semantic proposition. The resulting shortcomings are that the generator can deal neither with a lexical entry having an empty semantics nor with a lexical entry having a multipropositional semantics. We first show that these restrictions are too strong. We then show how to adapt the generator so as to lift them. Empty Semantics. Arguably there are words such as “that” or infinitival “to” whose semantic contribution is void. As (Shieber, 1988) showed, the problem with such words is that they cannot be selected on the basis of the input semantics. To circumvent this problem, we take advantage of the TAG extended domain of locality to avoid having such entries in the grammar. For instance, complementizer “that” does not anchor a tree description by itself but occurs in all lexical tree descriptions providing an appropriate syntactic context for it, e.g. in the tree description for “say”. Multiple Propositions. Lexical entries with a multi-propositional semantics are also very common. For instance, a neo-Davidsonian semantics would as"
P01-1028,P97-1026,0,0.225213,"P:  z{ — John saw Mary S: &lt; S op G( ""#34X. ( UV$5$'& &lt;'(Y?W(G . 0 S X , ', fragments (fully specified subtrees) are always positive; except for the anchor, all leaves of fragments are negative, and internal node variables are neutral. This guarantees that in a saturated model, tree fragments that belong to the denotation of distinct tree descriptions do not overlap. Second, we require that every lexical tree description has a single minimal free model, which essentially means that the lexical descriptions must be tree shaped. Semantic representation. Following (Stone and Doran, 1997), we represent meaning using a flat semantic representation, i.e. as multisets, or conjunctions, of non-recursive propositions. This treatment offers a simple syntax-semantics interface in that the meaning of a tree is just the conjunction of meanings of the lexical tree descriptions used to derive it once the free variables occurring in the propositions are instantiated. A free variable is instantiated as follows: each free variable labels a syntactic node variable  and is unified with the label of any node variable identified with  . For the purpose of this paper, a simple semantic represe"
P01-1028,J92-4004,0,0.0460004,"to remedy some empirical and theoretical shortcomings of TAG; Tree Description Grammar (TDG) is introduced in (Kallmeyer, 1999) to support syntactic and semantic underspecification and Interaction Grammar is presented in (Perrier, 2000) as an alternative way of formulating linear logic grammars. Like all these frameworks, DG uses tree descriptions and thereby benefits first, from the extended domain of locality which makes TAG particularly suitable for generation (cf. (Joshi, 1987)) and second, from the monotonicity which differentiates descriptions from trees with respect to adjunction (cf. (Vijay-Shanker, 1992)). DG differs from DTG and TDG however in that it adopts an axiomatic rather than a generative view of grammar: whereas in DTG and TDG, derived trees are constructed through a sequence of rewriting steps, in DG derived trees are models satisfying a conjunction of elementary tree descriptions. Moreover, DG differs from Interaction Grammars in that it uses a flat rather than a Montague style recursive semantics thereby permitting a simple syntax/semantics interface (see below). A Description Grammar is a set of lexical entries of the form   where  is a tree description and  is the sema"
P01-1028,C92-2117,0,0.15025,"ar in which the basic linguistic units are trees rather than categories and (iii) it assumes a flat semantics. In what follows we show that this combination of features results in a generator which integrates the positive aspects of both top-down and bottom-up generators. In this sense, it is not unlike (Shieber et al., 1990)’s semantic-head-driven generation. As will become clear in the following section however, it differs from it in that it integrates stronger lexicalist (i.e. bottom-up) information. 5.1 Bottom-Up Generation Bottom-up or “lexically-driven” generators (e.g., (Shieber, 1988; Whitelock, 1992; Kay, 1996; Carroll et al., 1999)) start from a bag of lexical items with instantiated semantics and generates a syntactic tree by applying grammar rules whose right hand side matches a sequence of phrases in the current input. There are two known disadvantages to bottomup generators. On the one hand, they require that the grammar be semantically monotonic that is, that the semantics of each daughter in a rule subsumes some portion of the mother semantics. On the other hand, they are often overly nondeterministic (though see (Carroll et al., 1999) for an exception). We now show how these prob"
P02-1013,P97-1027,0,0.554148,"s that, starting from the set of objects to be described and from the properties known to hold of these objects by both the speaker and the hearer, a definite description must be constructed which allows the user 1 The other well-known function of a definite is to inform the hearer of some specific attributes the referent of the NP has. to unambiguously identify the objects being talked about. While the task of constructing singular definite descriptions on the basis of positive properties has received much attention in the generation literature (Dale and Haddock, 1991; Dale and Reiter, 1995; Horacek, 1997; Krahmer et al., 2001), for a long time, a more general statement of the task at hand remained outstanding. Recently however, several papers made a step in that direction. (van Deemter, 2001) showed how to extend the basic Dale and Reiter Algorithm (Dale and Reiter, 1995) to generate plural definite descriptions using not just conjunctions of positive properties but also negative and disjunctive properties; (Stone, 1998) integrates the D&R algorithm into the surface realisation process and (Stone, 2000) extends it to deal with collective and distributive plural NPs. Notably, in all three case"
P02-1013,W01-0805,0,0.151736,"Missing"
P02-1013,W98-1419,0,0.0524229,"indicated in Figure 8. That is, the algorithm looks for a tuple of sets such »ÇKÇKÇ]» -jÈ is the target set - and that their union -ÆV such that for each set -jÉ in that tuple there is a basic   . The resulting description is the disjunctive ÇKÇKÇ description  ^ n n© ]Ê where each   is a DD conjunctive description. As before solutions are searched for in increasing order of size (i.e., number of literals occurring in the description) by distributing over the cardinality of the resulting description. 5 Discussion and comparison with related work Integration with surface realisation As (Stone and Webber, 1998) clearly shows, the two-step strategy which consists in first computing a DD and second, generating a definite NP realising that DD, does not do language justice. This is because, as the following example from (Stone and Webber, 1998) illustrates, the information used to uniquely identify some object need not be localised to a definite description. (2) Remove the rabbit from the hat. In a context where there are several rabbits and several hats but only one rabbit in a hat (and only one hat containing a rabbit), the sentence in (2) is sufficient to identify the rabbit that is in the hat. In th"
P02-1013,W00-1416,0,0.242514,"ch attention in the generation literature (Dale and Haddock, 1991; Dale and Reiter, 1995; Horacek, 1997; Krahmer et al., 2001), for a long time, a more general statement of the task at hand remained outstanding. Recently however, several papers made a step in that direction. (van Deemter, 2001) showed how to extend the basic Dale and Reiter Algorithm (Dale and Reiter, 1995) to generate plural definite descriptions using not just conjunctions of positive properties but also negative and disjunctive properties; (Stone, 1998) integrates the D&R algorithm into the surface realisation process and (Stone, 2000) extends it to deal with collective and distributive plural NPs. Notably, in all three cases, the incremental structure of the D&R’s algorithm is preserved: the algorithm increments a set of properties till this set uniquely identifies the target set i.e., the set of objects to be described. As (Garey and Johnson, 1979) shows, such an incremental algorithm while being polynomial (and this, together with certain psycholinguistic observations, was one of the primary motivation for privileging this incremental strategy) is not guaranteed to find the minimal solution i.e., the description which un"
P02-1013,J02-1003,0,\N,Missing
P06-2032,P95-1011,0,0.72133,"based grammars is well supported by the design of formalisms such as PATR-II, Ale or TDL (Krieger and Schafer, 1994), the situation is less well established for Tree-Based Grammars such as Tree Adjoining Grammars (Joshi and Schabes, 1997), Tree Description Grammars (Kallmeyer, 1996) or Interaction Grammars (Perrier, 2003). Roughly, two main types of specification formalism for Tree-Based Grammars can be distinguished: formalisms based on tree fragments and non monotonic inheritance and formalisms based on tree descriptions and monotonic inheritance. The tree fragment approach is advocated in (Evans et al., 1995) which proposes to encode lexicalised TAGs using the DATR representation language1 . In this approach, tree fragments are combined within a non monotonic inheritance hierarchy. Furthermore, new fragments can be derived from existing ones by means of lexical rules. This first approach suffers from the procedural character of non-monotonic inheritance. In specifying the grammar, the grammar writer must keep 1 A tree based approach is also used in(Becker, 2000) but this time in combination with metarules. In that particular approach, procedural aspects also come into play as the order in which me"
P06-2032,W02-2233,0,0.277069,"me into play as the order in which metarules apply affect the results. 247 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 247–254, c Sydney, July 2006. 2006 Association for Computational Linguistics modularity as the grammar writer must remember which names were used where and with which interpretation. As we shall see below, it also has the undesirable effect that the same tree fragment cannot be used twice in a given tree description. Nevertheless, this is the option that is adopted in most grammar formalisms and grammar compilers (Candito, 1996; Xia et al., 1999; Gaiffe et al., 2002). In this paper, we present an approach which remedies these shortcomings by combining monotonic inheritance of tree descriptions with an explicit management of identifier scope and identifiers equality2 . The proposed approach thus eschews both the inconvenients induced by a non monotonic framework (by using tree descriptions rather than trees) and those resulting from a global treatment of identifiers (by providing greater expressivity wrt identifiers). Specifically, we show that the proposed approach supports several ways of identifying (node or feature) values, we motivate this multiplicit"
P06-2032,E03-1030,1,0.888984,"tically well defined hierarchies. In a case where the objects containing the two identifiers to be identified are different, these will belong to distinct part of the inheritance hierarchy hence identifier export is not a good option. Node colouring is another possibility but as the name indicates, it only works for nodes, not for feature values. In such a situation then, interfaces come in handy. This is the case for instance, when combining a semantic representation with a tree. The semantic formula and the tree are distinct objects but in the approach to semantic construction described in (Gardent and Kallmeyer, 2003), they share some semantic indices. For instance, the subject node in the tree is labelled with an index feature whose value must be (in an active form tree) that of the first argument occurring in the semantic representation. The encoding of the required coreference can be sketched as follows: • to further constrain colour based identification (when the feature information present in the nodes does not suffice to force identification of the appropriate nodes) • to model general principles that apply to several subtrees in a given hierarchy The second point is illustrated by Subject/Verb agree"
P06-2032,2006.jeptalnrecital-long.12,1,0.862125,". . ?X . . . }∗ = [n1 = ?X] { . . . ?Y . . . }∗ = [n1 = ?Y] In A (resp. B), the local identifier ?X (resp. ?Y) is associated with an interface feature named n1. If these two classes are combined either by conjunction or by inheritance, their interfaces are unified and as a result, the local identifiers ?X and ?Y are unified. In the case of a disjunction, the interface of the current class (C here) is non deterministically unified with that of A or B. In practice, interface-based identification of values is particularly useful when two distinct features need to be assigned the same value. In (Gardent, 2006) for instance, it is used to identify the semantic index associated with e.g., the subject node of a verbal tree and the corresponding semantic index in the semantic representation associated with that tree. lustrate this by demonstrating that the following tree can be obtained in four different ways: s n Figure 1: A tree that can be derived in four ways In section 4, we will show that these four ways of identifying nodes and/or features values support both explicitness and economy thereby reducing the risks of specification errors. 3.1 Using explicit identification The most basic way to ident"
P06-2032,C94-2144,0,0.043848,"constraint and thereby permit overgeneration (the description will be satisfied by more trees than intended). The second option greatly degrades We claim that existing specification languages for tree based grammars fail to adequately support identifier managment. We then show that XMG (eXtensible MetaGrammar) provides a sophisticated treatment of identifiers which is effective in supporting a linguist-friendly grammar design. 1 Specifying tree-based grammars Whilst the development of standard unificationbased grammars is well supported by the design of formalisms such as PATR-II, Ale or TDL (Krieger and Schafer, 1994), the situation is less well established for Tree-Based Grammars such as Tree Adjoining Grammars (Joshi and Schabes, 1997), Tree Description Grammars (Kallmeyer, 1996) or Interaction Grammars (Perrier, 2003). Roughly, two main types of specification formalism for Tree-Based Grammars can be distinguished: formalisms based on tree fragments and non monotonic inheritance and formalisms based on tree descriptions and monotonic inheritance. The tree fragment approach is advocated in (Evans et al., 1995) which proposes to encode lexicalised TAGs using the DATR representation language1 . In this appr"
P06-2032,W98-0129,0,0.29528,"n C using the dot operator. • a convenient way of managing identifier scope based on import/export declarations inspired from standard Object Oriented Programming techniques (section 2.3.1); Disjunction: if classes A and B are disjoined inside a class C, then all the identifiers exported by A or B are visible within C using the dot operator. However in this case, both A and B have to be associated with the same local identifier. • an alternative means of identifying feature values based on the use of unification • polarity- (here called colour-) based node identification as first proposed in (Muskens and Krahmer, 1998) and later used in (Duchier and Thater, 1999; Perrier, 2000). In sum, export/import declarations permit extending/restricting the scope of an identifier within a branch of the inheritance hierarchy whilst the dot operator allows explicit access to an inherited identifier in case the inheriting class either displays multiple inheritance or is combined by conjunction or disjunction with other classes. More specifically, inheritance allows implicit coreference (the use of an imported name ensures coreference with the object referred to when declaring this name) and the dot operator explicit coref"
P06-2032,C00-2087,0,0.348671,"ope based on import/export declarations inspired from standard Object Oriented Programming techniques (section 2.3.1); Disjunction: if classes A and B are disjoined inside a class C, then all the identifiers exported by A or B are visible within C using the dot operator. However in this case, both A and B have to be associated with the same local identifier. • an alternative means of identifying feature values based on the use of unification • polarity- (here called colour-) based node identification as first proposed in (Muskens and Krahmer, 1998) and later used in (Duchier and Thater, 1999; Perrier, 2000). In sum, export/import declarations permit extending/restricting the scope of an identifier within a branch of the inheritance hierarchy whilst the dot operator allows explicit access to an inherited identifier in case the inheriting class either displays multiple inheritance or is combined by conjunction or disjunction with other classes. More specifically, inheritance allows implicit coreference (the use of an imported name ensures coreference with the object referred to when declaring this name) and the dot operator explicit coreference (through an explicit equality statement e.g., ?A.?X ="
P06-2032,C96-1034,0,0.896097,"rence handling in XMG Yannick Parmentier Claire Gardent INRIA Lorraine CNRS/LORIA 615, rue du jardin botanique, B.P. 101 615, rue du jardin botanique, B.P. 101 54602 Villers l`es Nancy CEDEX 54602 Villers l`es Nancy CEDEX France France Yannick.Parmentier@loria.fr Claire.Gardent@loria.fr Abstract in mind the order in which non-monotonic statements have been made so as to be able to predict how explicit statements interact with defaults and non-monotonic inheritance in determining the final output. When developing a large coverage grammar, this rapidly become extremely cumbersome. Moreover, as (Candito, 1996) remarks, nonmonotonicity may result in an information loss which makes it impossible to express the relation existing for instance between an active object and the corresponding passive subject. The approach based on tree descriptions (often called, the metagrammar approach) obviates the procedural character of the non-monotonic approach by taking tree descriptions rather than trees to be the basic units (Candito, 1996; Xia et al., 1999; Vijay-Shanker and Schabes, 1992). In essence, tree fragments are described using tree descriptions and tree descriptions are combined through conjunction or"
P06-2032,C92-1034,0,0.867562,"inheritance in determining the final output. When developing a large coverage grammar, this rapidly become extremely cumbersome. Moreover, as (Candito, 1996) remarks, nonmonotonicity may result in an information loss which makes it impossible to express the relation existing for instance between an active object and the corresponding passive subject. The approach based on tree descriptions (often called, the metagrammar approach) obviates the procedural character of the non-monotonic approach by taking tree descriptions rather than trees to be the basic units (Candito, 1996; Xia et al., 1999; Vijay-Shanker and Schabes, 1992). In essence, tree fragments are described using tree descriptions and tree descriptions are combined through conjunction or inheritance. The idea is that the minimal models satisfying the resulting descriptions are TAG elementary trees. In some cases, lexical rules are also used to derive new trees from existing ones. One main drawback with this second type of approach concerns the management of node identifiers. Either nodes are represented by nameless variables and node identification is forced by well-formedness constraints e.g., wff-constraints on trees and wff-constraints given by the in"
P07-1042,E03-1030,1,0.873566,"bottom) which are unified during derivation as follows. On substitution, the top of the substitution node is unified with the top of the root node of the tree being substituted in. On adjunction, the top of the root of the auxiliary tree is unified with the top of the node where adjunction takes place; and the bottom features of the foot node are unified with the bottom features of this node. At the end of a derivation, the top and bottom of all nodes in the derived tree are unified. To associate semantic representations with natural language expressions, the FTAG is modified as proposed in (Gardent and Kallmeyer, 2003). S s NP↓ NPj John VPr V runs VPx often VP* often(x) name(j,john) run(r,s) ⇒ name(j,john), run(r,j), often(r) Figure 1: Flat Semantics for “John often runs” Each elementary tree is associated with a flat semantic representation. For instance, in Figure 1,2 the trees for John, runs and often are associated with the semantics name(j,john), run(r,s) and often(x) respectively. Importantly, the arguments of a semantic functor are represented by unification variables which occur both in the semantic representation of this functor and on some nodes of the associated syntactic tree. For instance in Fi"
P07-1042,W05-1605,1,0.949621,"rt, in both cases, the well formedness of the input can be checked with respect to some criteria (e.g., well formedness of a deep syntactic structure in MTT, well formedness of a FD in SURGE) but this well formedness does not guarantee satisfiability. Nonetheless this basic well formedness check is important as it provides some guidance as to what an acceptable input to the realiser should look like. We adopt a similar strategy and resort to the notion of polarity neutral input to control the well formedness of the enriched input. The proposal draws on ideas from (Koller and Striegnitz, 2002; Gardent and Kow, 2005) and aims to determine whether for a given input (a set of TAG elementary trees whose semantics equate the input semantics), syntactic requirements and resources cancel out. More specifically, the aim is to determine whether given the input set of elementary trees, each substitution and each adjunction requirement is satisfied by exactly one elementary tree of the appropriate syntactic category and semantic index. Roughly,5 the technique consists in (automatically) associating with each elementary tree a polarity signature reflecting its substitution/adjunction requirements and resources and i"
P07-1042,2006.jeptalnrecital-long.12,1,0.86039,"Missing"
P07-1042,P96-1027,0,0.172401,"and for each of these frames, the set of argument redistributions (active, passive, middle, neuter, reflexivisation, impersonal, passive impersonal) and of argument realisations (cliticisation, extraction, omission, permutations, etc.) possible for this frame. As a result, it captures most grammatical paraphrases that is, paraphrases due to diverging argument realisations or to different meaning preserving alternation (e.g., active/passive or clefted/non-clefted sentence). 3 The surface realiser, GenI The basic surface realisation algorithm used is a bottom up, tabular realisation algorithm (Kay, 1996) optimised for TAGs. It follows a three step strategy which can be summarised as follows. Given an empty agenda, an empty chart and an input semantics φ: Lexical selection. Select all elementary trees whose semantics subsumes (part of) φ. Store these trees in the agenda. Auxiliary trees devoid of substitution nodes are stored in a separate agenda called the auxiliary agenda. Substitution phase. Retrieve a tree from the agenda, add it to the chart and try to combine it by substitution with trees present in the chart. Add any resulting derived tree to the agenda. Stop when the agenda is empty. A"
P07-1042,P02-1003,0,0.448756,"to the lexical level. In short, in both cases, the well formedness of the input can be checked with respect to some criteria (e.g., well formedness of a deep syntactic structure in MTT, well formedness of a FD in SURGE) but this well formedness does not guarantee satisfiability. Nonetheless this basic well formedness check is important as it provides some guidance as to what an acceptable input to the realiser should look like. We adopt a similar strategy and resort to the notion of polarity neutral input to control the well formedness of the enriched input. The proposal draws on ideas from (Koller and Striegnitz, 2002; Gardent and Kow, 2005) and aims to determine whether for a given input (a set of TAG elementary trees whose semantics equate the input semantics), syntactic requirements and resources cancel out. More specifically, the aim is to determine whether given the input set of elementary trees, each substitution and each adjunction requirement is satisfied by exactly one elementary tree of the appropriate syntactic category and semantic index. Roughly,5 the technique consists in (automatically) associating with each elementary tree a polarity signature reflecting its substitution/adjunction requirem"
P07-1042,W02-2103,0,0.0422845,"Missing"
P07-1042,W06-1661,0,0.0731225,"Missing"
P07-1042,C88-2147,0,0.786203,"the trees for John, runs and often are associated with the semantics name(j,john), run(r,s) and often(x) respectively. Importantly, the arguments of a semantic functor are represented by unification variables which occur both in the semantic representation of this functor and on some nodes of the associated syntactic tree. For instance in Figure 1, the semantic index s occurring in the semantic representation of runs also occurs on the subject substitution node of the associated elementary tree. We use a unification based version of LTAG namely, Feature-based TAG. A Feature-based TAG (FTAG, (Vijay-Shanker and Joshi, 1988)) consists of a set 2 x of (auxiliary or initial) elementary trees and of two C /Cx abbreviate a node with category C and a top/bottom feature structure including the feature-value pair { index : x}. tree composition operations: substitution and ad329 The value of semantic arguments is determined by the unifications resulting from adjunction and substitution. For instance, the semantic index s in the tree for runs is unified during substitution with the semantic indices labelling the root nodes of the tree for John. As a result, the semantics of John often runs is (1) {name(j,john),run(r,j),of"
P07-1042,I05-1015,0,\N,Missing
P07-2004,C04-1180,0,0.0123217,"onal linguistics were extended to support semantic construction (i.e., the computation of a meaning representation from syntax and word meanings). Thus, the HPSG ERG grammar for English was extended to output minimal recursive structures as semantic representations for sentences (Copestake and Flickinger, 2000); the LFG (Lexical Functional Grammar) grammars to output lambda terms (Dalrymple, 1999); and Clark and Curran’s CCG (Combinatory Categorial Grammar) based statistical parser was linked to a semantic construction module allowing for the derivation of Discourse Representation Structures (Bos et al., 2004). For Tree Adjoining Grammar (TAG) on the other hand, there exists to date no computational framework which supports semantic construction. In this demo, we present S EM TAG, a free and open software architecture that supports TAG based semantic construction. 13 Yannick Parmentier INRIA / LORIA - Nancy Universit´e Campus scientifique - BP 259 54 506 Vandœuvre-L`es-Nancy CEDEX France Yannick.Parmentier@loria.fr The structure of the paper is as follows. First, we briefly introduce the syntactic and semantic formalisms that are being handled (section 2). Second, we situate our approach with respe"
P07-2004,copestake-flickinger-2000-open,0,0.0625159,"egrating a compositional semantics. S EM TAG differs from XTAG in two main ways. First, it provides an expressive grammar formalism and compiler for factorising and specifying TAGs. Second, it supports semantic construction. 1 Introduction Over the last decade, many of the main grammatical frameworks used in computational linguistics were extended to support semantic construction (i.e., the computation of a meaning representation from syntax and word meanings). Thus, the HPSG ERG grammar for English was extended to output minimal recursive structures as semantic representations for sentences (Copestake and Flickinger, 2000); the LFG (Lexical Functional Grammar) grammars to output lambda terms (Dalrymple, 1999); and Clark and Curran’s CCG (Combinatory Categorial Grammar) based statistical parser was linked to a semantic construction module allowing for the derivation of Discourse Representation Structures (Bos et al., 2004). For Tree Adjoining Grammar (TAG) on the other hand, there exists to date no computational framework which supports semantic construction. In this demo, we present S EM TAG, a free and open software architecture that supports TAG based semantic construction. 13 Yannick Parmentier INRIA / LORIA"
P07-2004,E03-1030,1,0.903429,"associating each word with a semantic representation and from a set of semantic rules specifying how syntactic combinations relate to semantic composition. This is the approach adopted for instance, in the LFG glue semantic framework, in the CCG approach and in the approaches to TAGbased semantic construction that are based on the TAG derivation tree. S EM TAG implements a hybrid approach to semantic construction where (i) semantic construction proceeds after derivation and (ii) the semantic lexicon is extracted from a TAG which simultaneously specifies syntax and semantics. In this approach (Gardent and Kallmeyer, 2003), the TAG used integrates syntactic and semantic information as follows. Each elementary tree is associated with a formula of LU representing its meaning. Importantly, the meaning representations of semantic functors include unification variables that are shared with specific feature values occurring in the associated elementary trees. For instance in figure 1, the variables x and y appear both in the semantic representation associated with the tree for aime (love) and in the tree itself. Given such a TAG, the semantics of a tree t derived from combining the elementary trees t1 , . . . , tn is"
P07-2004,W98-0143,0,\N,Missing
P07-2004,C92-1034,0,\N,Missing
P12-1062,W11-2832,0,0.0681279,"results on parsing output and shown to help improve the large scale symbolic grammars and lexicons used by the parser. However the techniques they use (e.g., suffix arrays) to enumerate and count n-grams builds on the sequential nature of a text corpus and cannot easily extend to structured data. There are some NLP applications though where the processed data is structured data such as trees or graphs and which would benefit from error mining. For instance, when generating sentences from dependency trees, as was proposed recently in the Generation Challenge Surface Realisation Task (SR Task, (Belz et al., 2011)), it would be useful to be able to apply error mining on the input trees to find the most likely causes of generation failure. In this paper, we address this issue and propose an approach that supports error mining on trees. We adapt an existing algorithm for tree mining which we then use to mine the Generation Challenge dependency trees and identify the most likely causes of generation failure. We show in particular, that this tree mining algorithm permits identifying not only errors in the grammar and the lexicon used by generation but also a few idiosyncrasies/error in the input data as we"
P12-1062,W09-2609,0,0.485183,"Missing"
P12-1062,C10-1042,1,0.850978,"nodes and word forms was provided by the organisers. The surface realiser used is a system based on a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG) for English extended with a unification based compositional semantics. Both the grammars and the lexicon were developed in view of the Generation Challenge and the data provided by this challenge was used as a means to debug and extend the system. Unknown words are assigned a default TAG family/tree based on the part of speech they are associated with in the SR data. The surface realisation algorithm extends the algorithm proposed in (Gardent and Perez-Beltrachini, 2010) and adapts it to work on the SR dependency input rather than on flat semantic representations. using different minimal support thresholds, different display modes (sorted first by size and second by suspicion rate vs sorted by suspicion rate) and different labels (part of speech, words and part of speech, dependency, dependency and part of speech). 4.2 Mining on a single label permits (i) assessing the relative impact of each category in a given label category and (ii) identifying different sources of errors depending on the type of label considered (POS tag, dependency or word form). Experim"
P12-1062,C10-2039,1,0.506587,"from incorrect items using surface realisation and targets the most likely sources of errors rather than the absolute ones. More generally, our approach is the first to our knowledge, which mines a surface realiser for undergeneration. Indeed, apart from (Gardent and Kow, 2007), most previous work on surface realisation evaluation has focused on evaluating the performance and the coverage of surface realisers. Approaches based on reversible grammars (Carroll et al., 1999) have used the semantic formulae output by parsing to evaluate the coverage and performance of their realiser; similarly, (Gardent et al., 2010) developed a tool called GenSem which traverses the grammar to produce flat semantic representations and thereby provide a benchmark for performance and coverage evaluation. In both cases however, because it is produced using the grammar exploited by the surface realiser, the input produced can only be used to test for overgeneration (and performance) . (Callaway, 2003) avoids this shortcoming by converting the Penn Treebank to the format expected by his realiser. However, this involves manually identifying the mismatches between two formats much like symbolic systems did in the Generation Cha"
P12-1062,W07-2416,0,0.0259542,"allows us to process e.g., all NP chunks of size 4 and 6 present in the SR data (roughly 60 000 trees) in roughly 20 minutes on a PC. 4 Experiment and Results Using the input data provided by the Generation Challenge SR Task, we applied the error mining algorithm described in the preceding Section to debug and extend a symbolic surface realiser developed for this task. 4.1 Input Data and Surface Realisation System The shallow input data provided by the SR Task was obtained from the Penn Treebank using the LTH Constituent-to-Dependency Conversion Tool for Penn-style Treebanks (Pennconverter, (Johansson and Nugues, 2007)). It consists of a set of unordered labelled syntactic dependency trees whose nodes are labelled with word forms, part of speech categories, partial morphosyntactic information such as tense and number and, in some cases, a sense tag identifier. The edges are labelled with the syntactic labels provided by the Pennconverter. All words (including punctuation) of the original sen4 ETM needs to store all (n-1)-node trees in queues before producing n-node trees. tence are represented by a node in the tree and the alignment between nodes and word forms was provided by the organisers. The surface re"
P12-1062,W11-2836,0,0.0630859,"dicate that there are unresolved issues with, in decreasing order of suspicion rate, cardinal numbers (CD), proper names (NNP), nouns (NN), prepositions (IN) and determiners (DT). The highest ranking category (POS5 ) points to a mismatch between the representation of genitive NPs (e.g., John’s father) in the SR Task data and in the grammar. While our generator expects the representation of ‘John’s father’ to be FA THER (“ S ”( JOHN )), the structure provided by the SR Task is FATHER ( JOHN (“ S ”)). Hence whenever a possessive appears in the input data, generation fails. This is in line with (Rajkumar et al., 2011)’s finding that the logical forms expected by their system for possessives differed from the shared task inputs. 5 In the Penn Treebank, the POS tag is the category assigned to possessive ’s. POS POS CC CD NNP NN IN DT Sus 0.99 0.99 0.39 0.35 0.30 0.30 0.09 Sup 0.38 0.21 0.16 0.32 0.81 0.16 0.12 Fail 3237 1774 1419 2749 6798 1355 1079 Pass 1 9 2148 5014 15663 3128 10254 Table 1: Error Mining on POS tags with frequency cutoff 0.1 and displaying only trees of size 1 sorted by decreasing suspicion rate (Sus) The second highest ranked category is CC for coordinations. In this case, error mining un"
P12-1062,P06-1042,0,0.472439,"red data. In this paper, we propose an algorithm for mining trees and apply it to detect the most likely sources of generation failure. We show that this tree mining algorithm permits identifying not only errors in the generation system (grammar, lexicon) but also mismatches between the structures contained in the input and the input structures expected by our generator as well as a few idiosyncrasies/error in the input data. 1 Introduction In recent years, error mining techniques have been developed to help identify the most likely sources of parsing failure (van Noord, 2004; Sagot and de la Clergerie, 2006; de Kok et al., 2009). First, the input data (text) is separated into two subcorpora, a corpus of sentences that could be parsed (PASS) and a corpus of sentences that failed to be parsed (FAIL). For each n-gram of words (and/or part of speech tag) occurring in the corpus to be parsed, a suspicion rate is then computed which, in essence, captures the likelihood that this n-gram causes parsing to fail. These error mining techniques have been applied with good results on parsing output and shown to help improve the large scale symbolic grammars and lexicons used by the parser. However the techni"
P12-1062,P04-1057,0,0.155782,"Missing"
P12-1062,W07-2306,1,\N,Missing
P12-1090,W02-1016,0,0.131921,"Missing"
P12-1090,P02-1027,0,0.0975523,"ic and/or semantic generalisations about verbs (Levin, 1993; Kipper Schuler, 2006). From a practical perspective, they support factorisation and have been shown to be effective in various NLP (Natural language Processing) tasks such as semantic role labelling (Swier and Stevenson, 2005) or word sense disambiguation (Dang, 2004). While there has been much work on automatically acquiring verb classes for English (Sun et al., 2010) and to a lesser extent for German (Brew and Schulte im Walde, 2002; Schulte im Walde, 2003; Schulte im Walde, 2006), Japanese (Oishi and Matsumoto, 1997) and Italian (Merlo et al., 2002), few studies have been conducted on the automatic classification of French verbs. Recently however, two proposals have been put forward. On the other hand, Falk and Gardent (2011) present a classification approach for French verbs based on the use of Formal Concept Analysis (FCA). FCA (Barbut and Monjardet, 1970) is a symbolic classification technique which permits creating classes associating sets of objects (eg. French verbs) with sets of features (eg. syntactic frames). Falk and Gardent (2011) provide no evaluation for their results however, only a qualitative analysis. In this paper, we d"
P12-1090,P08-3010,0,0.0834951,"s. 2 Lexical Resources Used Our aim is to accquire a classification which covers the core verbs of French, could be used to support semantic role labelling and is similar in spirit to the English Verbnet. In this first experiment, we therefore favoured extracting the features used for clustering, not from a large corpus parsed automatically, but from manually validated resources1 . These lexical resources are (i) a syntactic lexicon produced by merging three existing lexicons for French and (ii) the English Verbnet. Among the many syntactic lexicons available for French (Nicolas et al., 2008; Messiant, 2008; Kup´sc´ and Abeill´e, 2008; van den Eynde and Mertens, 2003; Gross, 1975), we selected and merged three lexicons built or validated manually namely, Dicovalence, TreeLex and the LADL tables. The resulting lexicon contains 5918 verbs, 20433 lexical entries (i.e., verb/frame pairs) and 345 subcategorisation frames. It also contains more detailed syntactic and semantic features such as lexical preferences (e.g., locative argument, concrete object) or thematic role information (e.g., symmetric arguments, asset role) which we make use of for clustering. We use the English Verbnet as a resource fo"
P12-1090,C08-1080,0,0.0223429,"ed. Section 6 concludes. 2 Lexical Resources Used Our aim is to accquire a classification which covers the core verbs of French, could be used to support semantic role labelling and is similar in spirit to the English Verbnet. In this first experiment, we therefore favoured extracting the features used for clustering, not from a large corpus parsed automatically, but from manually validated resources1 . These lexical resources are (i) a syntactic lexicon produced by merging three existing lexicons for French and (ii) the English Verbnet. Among the many syntactic lexicons available for French (Nicolas et al., 2008; Messiant, 2008; Kup´sc´ and Abeill´e, 2008; van den Eynde and Mertens, 2003; Gross, 1975), we selected and merged three lexicons built or validated manually namely, Dicovalence, TreeLex and the LADL tables. The resulting lexicon contains 5918 verbs, 20433 lexical entries (i.e., verb/frame pairs) and 345 subcategorisation frames. It also contains more detailed syntactic and semantic features such as lexical preferences (e.g., locative argument, concrete object) or thematic role information (e.g., symmetric arguments, asset role) which we make use of for clustering. We use the English Verbnet"
P12-1090,J06-2001,0,0.271936,"e. From the theoretical viewpoint, they permit capturing syntactic and/or semantic generalisations about verbs (Levin, 1993; Kipper Schuler, 2006). From a practical perspective, they support factorisation and have been shown to be effective in various NLP (Natural language Processing) tasks such as semantic role labelling (Swier and Stevenson, 2005) or word sense disambiguation (Dang, 2004). While there has been much work on automatically acquiring verb classes for English (Sun et al., 2010) and to a lesser extent for German (Brew and Schulte im Walde, 2002; Schulte im Walde, 2003; Schulte im Walde, 2006), Japanese (Oishi and Matsumoto, 1997) and Italian (Merlo et al., 2002), few studies have been conducted on the automatic classification of French verbs. Recently however, two proposals have been put forward. On the other hand, Falk and Gardent (2011) present a classification approach for French verbs based on the use of Formal Concept Analysis (FCA). FCA (Barbut and Monjardet, 1970) is a symbolic classification technique which permits creating classes associating sets of objects (eg. French verbs) with sets of features (eg. syntactic frames). Falk and Gardent (2011) provide no evaluation for"
P12-1090,C10-1119,0,0.326282,"Missing"
P12-1090,H05-1111,0,0.150888,"mantic lexical resources. We evaluate our approach on an established test set and show that it outperforms previous related work with an Fmeasure of 0.70. 1 Introduction Verb classifications have been shown to be useful both from a theoretical and from a practical perspective. From the theoretical viewpoint, they permit capturing syntactic and/or semantic generalisations about verbs (Levin, 1993; Kipper Schuler, 2006). From a practical perspective, they support factorisation and have been shown to be effective in various NLP (Natural language Processing) tasks such as semantic role labelling (Swier and Stevenson, 2005) or word sense disambiguation (Dang, 2004). While there has been much work on automatically acquiring verb classes for English (Sun et al., 2010) and to a lesser extent for German (Brew and Schulte im Walde, 2002; Schulte im Walde, 2003; Schulte im Walde, 2006), Japanese (Oishi and Matsumoto, 1997) and Italian (Merlo et al., 2002), few studies have been conducted on the automatic classification of French verbs. Recently however, two proposals have been put forward. On the other hand, Falk and Gardent (2011) present a classification approach for French verbs based on the use of Formal Concept A"
P14-1040,D10-1049,0,0.24015,"ions and drastically reducing the search space. Although conceptually related to (Lu and Ng, 2011), our approach extracts a unification based grammar rather than one with lambda terms. The extraction process and the generation algorithms are also fundamentally different. We use a simple mainly symbolic approach whereas they use a generative approach for grammar induction and a discriminative approach for sentence generation. dom Field to generate from the same meaning representations. Finally, more recent papers propose approaches which perform both surface realisation and content selection. (Angeli et al., 2010) proposes a log linear model which decomposes into a sequence of discriminative local decisions. The first classifier determines which records to mention; the second, which fields of these records to select; and the third, which words to use to verbalise the selected fields. (Kim and Mooney, 2010) uses a generative model for content selection and verbalises the selected input using WASP−1 , an existing generator. Finally, (Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) develop a joint optimisation approach for content selection and surface realisation using a generic, domain independent"
P14-1040,W12-1526,1,0.856558,"roduction In this paper we present a grammar based approach for generating from knowledge bases (KB) which is linguistically principled and conceptually simple. A key feature of this approach is that grammar induction is driven by the extended domain of locality principle of TAG (Tree Adjoining Grammar) and takes into account both syntactic and semantic information. The resulting extracted TAGs include a unification based semantics and can be used by an existing surface realiser to generate sentences from KB data. To evaluate our approach, we use the benchmark provided by the KBGen challenge (Banik et al., 2012; Banik et al., 2013), a challenge designed to evaluate generation from knowledge bases; where the input is a KB subset; and where the expected output is a complex sentence conveying the meaning represented by the input. When compared with two other systems having taken part in the KBGen challenge, our system outperforms a data-driven, generate-and-rank approach 424 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 424–434, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics strand of work maps each axiom in t"
P14-1040,W13-2111,1,0.925959,"per we present a grammar based approach for generating from knowledge bases (KB) which is linguistically principled and conceptually simple. A key feature of this approach is that grammar induction is driven by the extended domain of locality principle of TAG (Tree Adjoining Grammar) and takes into account both syntactic and semantic information. The resulting extracted TAGs include a unification based semantics and can be used by an existing surface realiser to generate sentences from KB data. To evaluate our approach, we use the benchmark provided by the KBGen challenge (Banik et al., 2012; Banik et al., 2013), a challenge designed to evaluate generation from knowledge bases; where the input is a KB subset; and where the expected output is a complex sentence conveying the meaning represented by the input. When compared with two other systems having taken part in the KBGen challenge, our system outperforms a data-driven, generate-and-rank approach 424 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 424–434, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics strand of work maps each axiom in the knowledge base to"
P14-1040,E03-1030,1,0.814193,"o-property relations. AURA uses a frame-based knowledge representation and reasoning system called Knowledge Machine (Clark and Porter, 1997) which was translated into first-order logic with equality and from there, into multiple different formats including SILK (Grosof, 2012) and OWL2 (Motik et al., 2009). It is available for download in various formats including OWL2 . 4 Generating from the KBGen Knowledge-Base To generate from the KBGen data, we induce a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG, (Vijay-Shanker and Joshi, 1988)) augmented with a unification-based semantics (Gardent and Kallmeyer, 2003) from the training data. We then use this grammar and an existing surface realiser to generate from the test data. 4.1 Feature-Based Lexicalised Tree Adjoining Grammar In an FB-LTAG augmented with a unificationbased semantics, each tree is associated with a semantics i.e., a set of literals whose arguments may be constants or unification variables. The semantics of a derived tree is the union of the semantics of the tree contributing to its derivation modulo unification. Importantly, semantic variables are shared with syntactic variables (i.e., variables occurring in the feature structures dec"
P14-1040,P07-1042,1,0.886043,"Missing"
P14-1040,P96-1027,0,0.0611148,"uation on the KBGen data shows that our model outperforms a data-driven generate-and-rank approach based on an automatically induced probabilistic grammar; and is comparable with a handcrafted symbolic approach. 2 Related Work Our work is related to work on concept to text generation. Earlier work on concept to text generation mainly focuses on generation from logical forms using rule-based methods. (Wang, 1980) uses hand-written rules to generate sentences from an extended predicate logic formalism; (Shieber et al., 1990) introduces a head-driven algorithm for generating from logical forms; (Kay, 1996) defines a chart based algorithm which enhances efficiency by minimising the number of semantically incomplete phrases being built; and (Shemtov, 1996) presents an extension of the chart based generation algorithm presented in (Kay, 1996) which supports the generation of multiple paraphrases from underspecified semantic input. In all these approaches, grammar and lexicon are developed manually and it is assumed that the lexicon associates semantic sub-formulae with natural language expressions. Our approach is similar to these approaches in that it assumes a grammar encoding a compositional se"
P14-1040,P00-1058,0,0.391072,"ation and a noun to a concept). In constrast, we propose an approach which can generate complex sentences from KB data; where the grammar is acquired from the data; and where no assumption is made about the mapping between semantics and NL expressions. Recent work has focused on data-driven generation from frames, lambda terms and data base entries. (DeVault et al., 2008) describes an approach for generating from the frames produced by a dialog system. They induce a probabilistic Tree Adjoining Grammar from a training set aligning frames and sentences using the grammar induction technique of (Chiang, 2000) and use a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. To generate more complex output from KB data, several alternative approaches have been proposed. The MIAKT project (Bontcheva and Wilks., 2004) and the ONTOGENERATION project (Aguado et al., 1998) use symbolic NLG techniques to produce textual descriptions from some semantic information contained in a knowledge base. Both systems require some manual input (lexicons and domain schemas). More sophisticated NLG systems such as TAILOR (Paris, 1988), MIGRAINE (Mittal et al."
P14-1040,H94-1010,0,0.129555,"nchronous context-free grammar. They introduce a novel synchronous context free grammar formalism for generating from lambda terms; induce such a synchronous grammar using a generative model; and extract the best output sentence from the generated forest using a log linear model. (Wong and Mooney, 2007; Lu et al., 2009) focuses on generating from variable-free treestructured representations such as the CLANG formal language used in the ROBOCUP competition and the database entries collected by (Liang et al., 2009) for weather forecast generation and for the air travel domain (ATIS dataset) by (Dahl et al., 1994). (Wong and Mooney, 2007) uses synchronous grammars to transform a variable free tree structured meaning representation into sentences. (Lu et al., 2009) uses a Conditional RanThe SWAT project has focused on producing descriptions of ontologies that are both coherent 425 The function of a gated channel is to release particles from the endoplasmic reticulum :TRIPLES ( (|Release-Of-Calcium646 ||object ||Particle-In-Motion64582|) (|Release-Of-Calcium646 ||base ||Endoplasmic-Reticulum64603|) (|Gated-Channel64605 ||has-function||Release-Of-Calcium646|) (|Release-Of-Calcium646 ||agent ||Gated-Channe"
P14-1040,W08-0130,0,0.194274,"rally, the sentences generated by ontology verbalisers cover a limited set of linguistics constructions; the grammar used is manually defined; and the mapping between semantics and strings is assumed to be deterministic (e.g., a verb maps to a relation and a noun to a concept). In constrast, we propose an approach which can generate complex sentences from KB data; where the grammar is acquired from the data; and where no assumption is made about the mapping between semantics and NL expressions. Recent work has focused on data-driven generation from frames, lambda terms and data base entries. (DeVault et al., 2008) describes an approach for generating from the frames produced by a dialog system. They induce a probabilistic Tree Adjoining Grammar from a training set aligning frames and sentences using the grammar induction technique of (Chiang, 2000) and use a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. To generate more complex output from KB data, several alternative approaches have been proposed. The MIAKT project (Bontcheva and Wilks., 2004) and the ONTOGENERATION project (Aguado et al., 1998) use symbolic NLG techniques to produc"
P14-1040,E09-2005,0,0.019411,"hniques to produce textual descriptions from some semantic information contained in a knowledge base. Both systems require some manual input (lexicons and domain schemas). More sophisticated NLG systems such as TAILOR (Paris, 1988), MIGRAINE (Mittal et al., 1994), and STOP (Reiter et al., 2003) offer tailored output based on user/patient models. While offering more flexibility and expressiveness, these systems are difficult to adapt by non-NLG experts because they require the user to understand the architecture of the NLG systems (Bontcheva and Wilks., 2004). Similarly, the NaturalOWL system (Galanis et al., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. This approach however relies on extensive manual annotation of the input data. (Lu and Ng, 2011) focuses on generating natural language sentences from logical form (i.e., lambda terms) using a synchronous context-free grammar. They introduce a novel synchronous context free grammar formalism for generating from lambda terms; induce such a synchronous grammar using a generative model; and extract the best output sentence from the generated forest using a log linear model. (Wong and Mooney, 2007; Lu et al"
P14-1040,P12-1039,0,0.174653,"ate from the same meaning representations. Finally, more recent papers propose approaches which perform both surface realisation and content selection. (Angeli et al., 2010) proposes a log linear model which decomposes into a sequence of discriminative local decisions. The first classifier determines which records to mention; the second, which fields of these records to select; and the third, which words to use to verbalise the selected fields. (Kim and Mooney, 2010) uses a generative model for content selection and verbalises the selected input using WASP−1 , an existing generator. Finally, (Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) develop a joint optimisation approach for content selection and surface realisation using a generic, domain independent probabilistic grammar which captures the structure of the database and the mapping from fields to strings. They intersect the grammar with a language model to improve fluency; use a weighted hypergraph to pack the derivations; and find the best derivation tree using Viterbi algorithm. Our approach differs from the approaches which assume variable free tree structured representations (Wong and Mooney, 2007; Lu et al., 2009) and data-based entries"
P14-1040,N12-1093,0,0.0443055,"ate from the same meaning representations. Finally, more recent papers propose approaches which perform both surface realisation and content selection. (Angeli et al., 2010) proposes a log linear model which decomposes into a sequence of discriminative local decisions. The first classifier determines which records to mention; the second, which fields of these records to select; and the third, which words to use to verbalise the selected fields. (Kim and Mooney, 2010) uses a generative model for content selection and verbalises the selected input using WASP−1 , an existing generator. Finally, (Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) develop a joint optimisation approach for content selection and surface realisation using a generic, domain independent probabilistic grammar which captures the structure of the database and the mapping from fields to strings. They intersect the grammar with a language model to improve fluency; use a weighted hypergraph to pack the derivations; and find the best derivation tree using Viterbi algorithm. Our approach differs from the approaches which assume variable free tree structured representations (Wong and Mooney, 2007; Lu et al., 2009) and data-based entries"
P14-1040,kow-belz-2012-lg,0,0.0242104,"Missing"
P14-1040,P09-1011,0,0.0520869,"1) focuses on generating natural language sentences from logical form (i.e., lambda terms) using a synchronous context-free grammar. They introduce a novel synchronous context free grammar formalism for generating from lambda terms; induce such a synchronous grammar using a generative model; and extract the best output sentence from the generated forest using a log linear model. (Wong and Mooney, 2007; Lu et al., 2009) focuses on generating from variable-free treestructured representations such as the CLANG formal language used in the ROBOCUP competition and the database entries collected by (Liang et al., 2009) for weather forecast generation and for the air travel domain (ATIS dataset) by (Dahl et al., 1994). (Wong and Mooney, 2007) uses synchronous grammars to transform a variable free tree structured meaning representation into sentences. (Lu et al., 2009) uses a Conditional RanThe SWAT project has focused on producing descriptions of ontologies that are both coherent 425 The function of a gated channel is to release particles from the endoplasmic reticulum :TRIPLES ( (|Release-Of-Calcium646 ||object ||Particle-In-Motion64582|) (|Release-Of-Calcium646 ||base ||Endoplasmic-Reticulum64603|) (|Gated"
P14-1040,D11-1149,0,0.70045,"G systems such as TAILOR (Paris, 1988), MIGRAINE (Mittal et al., 1994), and STOP (Reiter et al., 2003) offer tailored output based on user/patient models. While offering more flexibility and expressiveness, these systems are difficult to adapt by non-NLG experts because they require the user to understand the architecture of the NLG systems (Bontcheva and Wilks., 2004). Similarly, the NaturalOWL system (Galanis et al., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. This approach however relies on extensive manual annotation of the input data. (Lu and Ng, 2011) focuses on generating natural language sentences from logical form (i.e., lambda terms) using a synchronous context-free grammar. They introduce a novel synchronous context free grammar formalism for generating from lambda terms; induce such a synchronous grammar using a generative model; and extract the best output sentence from the generated forest using a log linear model. (Wong and Mooney, 2007; Lu et al., 2009) focuses on generating from variable-free treestructured representations such as the CLANG formal language used in the ROBOCUP competition and the database entries collected by (Li"
P14-1040,D09-1042,0,0.0730763,"., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. This approach however relies on extensive manual annotation of the input data. (Lu and Ng, 2011) focuses on generating natural language sentences from logical form (i.e., lambda terms) using a synchronous context-free grammar. They introduce a novel synchronous context free grammar formalism for generating from lambda terms; induce such a synchronous grammar using a generative model; and extract the best output sentence from the generated forest using a log linear model. (Wong and Mooney, 2007; Lu et al., 2009) focuses on generating from variable-free treestructured representations such as the CLANG formal language used in the ROBOCUP competition and the database entries collected by (Liang et al., 2009) for weather forecast generation and for the air travel domain (ATIS dataset) by (Dahl et al., 1994). (Wong and Mooney, 2007) uses synchronous grammars to transform a variable free tree structured meaning representation into sentences. (Lu et al., 2009) uses a Conditional RanThe SWAT project has focused on producing descriptions of ontologies that are both coherent 425 The function of a gated channel"
P14-1040,J90-1004,0,0.173721,"Missing"
P14-1040,W06-1661,0,0.0799344,"Missing"
P14-1040,C88-2147,0,0.33002,"eature structure of the node being adjoined to. event-to-property and entity-to-property relations. AURA uses a frame-based knowledge representation and reasoning system called Knowledge Machine (Clark and Porter, 1997) which was translated into first-order logic with equality and from there, into multiple different formats including SILK (Grosof, 2012) and OWL2 (Motik et al., 2009). It is available for download in various formats including OWL2 . 4 Generating from the KBGen Knowledge-Base To generate from the KBGen data, we induce a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG, (Vijay-Shanker and Joshi, 1988)) augmented with a unification-based semantics (Gardent and Kallmeyer, 2003) from the training data. We then use this grammar and an existing surface realiser to generate from the test data. 4.1 Feature-Based Lexicalised Tree Adjoining Grammar In an FB-LTAG augmented with a unificationbased semantics, each tree is associated with a semantics i.e., a set of literals whose arguments may be constants or unification variables. The semantics of a derived tree is the union of the semantics of the tree contributing to its derivation modulo unification. Importantly, semantic variables are shared with"
P14-1040,C80-1061,0,0.427396,"c and semantic information. The resulting extracted TAG includes a unification based semantics and can be used by an existing surface realiser to generate sentences from KB data. Experimental evaluation on the KBGen data shows that our model outperforms a data-driven generate-and-rank approach based on an automatically induced probabilistic grammar; and is comparable with a handcrafted symbolic approach. 2 Related Work Our work is related to work on concept to text generation. Earlier work on concept to text generation mainly focuses on generation from logical forms using rule-based methods. (Wang, 1980) uses hand-written rules to generate sentences from an extended predicate logic formalism; (Shieber et al., 1990) introduces a head-driven algorithm for generating from logical forms; (Kay, 1996) defines a chart based algorithm which enhances efficiency by minimising the number of semantically incomplete phrases being built; and (Shemtov, 1996) presents an extension of the chart based generation algorithm presented in (Kay, 1996) which supports the generation of multiple paraphrases from underspecified semantic input. In all these approaches, grammar and lexicon are developed manually and it i"
P14-1040,D09-1043,0,0.0610653,"Missing"
P14-1040,P02-1040,0,0.0923627,"gure 5: an S tree corresponding to the sentence The function of a gated channel is to release particles and an auxiliary PP tree corresponding to the phrase from the endoplasmic reticulum. Similarly in the above example, a PP tree corresponding to the phrase ”through hydrophilic channels.” will be extracted. As with the base grammar, missing grammar entries are guessed from the expanded grammar. However we do this only in cases where a correct grammar entry cannot be guessed from the base grammar. 5.3 Metrics. We evaluate system output automatically, using the BLEU-4 modified precision score (Papineni et al., 2002) with the human written sentences as reference. We also report results from a human based evaluation. In this evaluation, participants were asked to rate sentences along three dimensions: fluency (Is the text easy to read?), grammaticality and meaning similarity or adequacy (Does the meaning conveyed by the generated sentence correspond to the meaning conveyed by the reference sentence?). The evaluation was done on line using the LG-Eval toolkit (Kow and Belz, 2012), subjects used a sliding scale from -50 to +50 and a Latin Square Experimental Design was used to ensure that each evaluator sees"
P14-1040,J88-3006,0,0.539238,"induction technique of (Chiang, 2000) and use a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. To generate more complex output from KB data, several alternative approaches have been proposed. The MIAKT project (Bontcheva and Wilks., 2004) and the ONTOGENERATION project (Aguado et al., 1998) use symbolic NLG techniques to produce textual descriptions from some semantic information contained in a knowledge base. Both systems require some manual input (lexicons and domain schemas). More sophisticated NLG systems such as TAILOR (Paris, 1988), MIGRAINE (Mittal et al., 1994), and STOP (Reiter et al., 2003) offer tailored output based on user/patient models. While offering more flexibility and expressiveness, these systems are difficult to adapt by non-NLG experts because they require the user to understand the architecture of the NLG systems (Bontcheva and Wilks., 2004). Similarly, the NaturalOWL system (Galanis et al., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. This approach however relies on extensive manual annotation of the input data. (Lu and Ng, 2011) focuses on generating"
P14-1040,C10-2116,0,0.128045,", our system outperforms a data-driven, generate-and-rank approach 424 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 424–434, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics strand of work maps each axiom in the knowledge base to a clause. Thus the OWL verbaliser integrated in the Prot´eg´e tool (Kaljurand and Fuchs, 2007) provides a verbalisation of every axiom present in the ontology under consideration and (Wilcock, 2003) describes an ontology verbaliser using XML-based generation. As discussed in (Power and Third, 2010), one important limitation of these approaches is that they assume a simple deterministic mapping between knowledge representation languages and some controlled natural language (CNL). Specifically, the assumption is that each atomic term (individual, class, property) maps to a word and each axiom maps to a sentence. As a result, the verbalisation of larger ontology parts can produce very unnatural text such as, Every cat is an animal. Every dog is an animal. Every horse is an animal. Every rabbit is an animal. More generally, the CNL based approaches to ontology verbalisation generate clauses"
P14-1040,C96-2155,0,0.0658984,"grammar; and is comparable with a handcrafted symbolic approach. 2 Related Work Our work is related to work on concept to text generation. Earlier work on concept to text generation mainly focuses on generation from logical forms using rule-based methods. (Wang, 1980) uses hand-written rules to generate sentences from an extended predicate logic formalism; (Shieber et al., 1990) introduces a head-driven algorithm for generating from logical forms; (Kay, 1996) defines a chart based algorithm which enhances efficiency by minimising the number of semantically incomplete phrases being built; and (Shemtov, 1996) presents an extension of the chart based generation algorithm presented in (Kay, 1996) which supports the generation of multiple paraphrases from underspecified semantic input. In all these approaches, grammar and lexicon are developed manually and it is assumed that the lexicon associates semantic sub-formulae with natural language expressions. Our approach is similar to these approaches in that it assumes a grammar encoding a compositional semantics. It differs from them however in that, in our approach, grammar and lexicon are automatically acquired from the data. With the development of t"
P14-1040,W10-4222,0,0.0257426,"aps to a word and each axiom maps to a sentence. As a result, the verbalisation of larger ontology parts can produce very unnatural text such as, Every cat is an animal. Every dog is an animal. Every horse is an animal. Every rabbit is an animal. More generally, the CNL based approaches to ontology verbalisation generate clauses (one per axiom) rather than complex sentences and thus cannot adequately handle the verbalisation of more complex input such as the KBGen data where the KB input often requires the generation of a complex sentence rather than a sequence of base clauses. and efficient (Williams and Power, 2010). For instance, instead of the above output, the SWAT system would generate the sentence: The following are kinds of animals: cats, dogs, horses and rabbits. . In this approach too however, the verbaliser output is strongly constrained by a simple Definite Clause Grammar covering simple clauses and sentences verbalising aggregation patterns such as the above. More generally, the sentences generated by ontology verbalisers cover a limited set of linguistics constructions; the grammar used is manually defined; and the mapping between semantics and strings is assumed to be deterministic (e.g., a"
P14-1040,N07-1022,0,0.720231,"L system (Galanis et al., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. This approach however relies on extensive manual annotation of the input data. (Lu and Ng, 2011) focuses on generating natural language sentences from logical form (i.e., lambda terms) using a synchronous context-free grammar. They introduce a novel synchronous context free grammar formalism for generating from lambda terms; induce such a synchronous grammar using a generative model; and extract the best output sentence from the generated forest using a log linear model. (Wong and Mooney, 2007; Lu et al., 2009) focuses on generating from variable-free treestructured representations such as the CLANG formal language used in the ROBOCUP competition and the database entries collected by (Liang et al., 2009) for weather forecast generation and for the air travel domain (ATIS dataset) by (Dahl et al., 1994). (Wong and Mooney, 2007) uses synchronous grammars to transform a variable free tree structured meaning representation into sentences. (Lu et al., 2009) uses a Conditional RanThe SWAT project has focused on producing descriptions of ontologies that are both coherent 425 The function"
P14-1040,N09-2058,0,\N,Missing
P14-1040,N01-1001,0,\N,Missing
P14-1040,C10-2062,0,\N,Missing
P14-1040,N06-1056,0,\N,Missing
P14-1040,P11-1101,0,\N,Missing
P14-1040,W13-2130,0,\N,Missing
P14-1040,C12-2127,0,\N,Missing
P14-1040,P15-1129,0,\N,Missing
P14-1041,P05-1074,0,0.0389166,"d and Lapata (2011) will often fail to appropriately reconstruct the shared phrase and introduce agreement mismatches because the alignment or rules they learn are based on syntax alone. For instance, in example (2), Zhu et al. (2010) fails to copy the shared argument “The judge” to the second clause whereas Woodsend and Lapata (2011) learns a synchronous rule matching (VP and VP) to (VP. NP(It) VP) thereby failing to produce the correct subject pronoun (“he” or “she”) for the antecedent “The judge”. Substitution and Reordering SMT based approaches to paraphrasing (Barzilay and Elhadad, 2003; Bannard and Callison-Burch, 2005) and to sentence simplification (Wubben et al., 2012) have shown that by utilising knowledge about alignment and translation probabilities, SMT systems can account for the substitutions and the reorderings occurring in sentence simplification. Following on these approaches, we therefore rely on phrase based SMT to learn substitutions and reordering. In addition, the language model we integrate in the SMT module helps ensuring better fluency and grammaticality. 3.1 An Example Figure 1 shows how our approach simplifies (4C) into (4S). (4) C. In 1964 Peter Higgs published his second paper in Phys"
P14-1041,W03-1004,0,0.0185815,"hu et al. (2010) and Woodsend and Lapata (2011) will often fail to appropriately reconstruct the shared phrase and introduce agreement mismatches because the alignment or rules they learn are based on syntax alone. For instance, in example (2), Zhu et al. (2010) fails to copy the shared argument “The judge” to the second clause whereas Woodsend and Lapata (2011) learns a synchronous rule matching (VP and VP) to (VP. NP(It) VP) thereby failing to produce the correct subject pronoun (“he” or “she”) for the antecedent “The judge”. Substitution and Reordering SMT based approaches to paraphrasing (Barzilay and Elhadad, 2003; Bannard and Callison-Burch, 2005) and to sentence simplification (Wubben et al., 2012) have shown that by utilising knowledge about alignment and translation probabilities, SMT systems can account for the substitutions and the reorderings occurring in sentence simplification. Following on these approaches, we therefore rely on phrase based SMT to learn substitutions and reordering. In addition, the language model we integrate in the SMT module helps ensuring better fluency and grammaticality. 3.1 An Example Figure 1 shows how our approach simplifies (4C) into (4S). (4) C. In 1964 Peter Higgs"
P14-1041,bott-etal-2012-text,0,0.134071,"Missing"
P14-1041,E99-1042,0,0.864244,"Missing"
P14-1041,C96-2183,0,0.631146,"has been much work recently on developing computational frameworks for sentence simplification. Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence (Dras, 1999; Woodsend and Lapata, 2011). Machine Translation systems have been adapted to translate complex sentences into simple ones (Zhu et al., 2010; Wubben et al., 2012; Coster and Kauchak, 2011). And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996). In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways. First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which handles reordering and substitution. In this way, we exploit the ability of statistical machine translation (SMT) systems to capture phrasal/lexical substitution and reordering while relying on a dedicated probabilistic module to capture the splitting and deletion operations which are less well (deletion) or not at all (splitting) captured"
P14-1041,W11-1601,0,0.672279,"application as a reading aid for people with aphasis (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). There has been much work recently on developing computational frameworks for sentence simplification. Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence (Dras, 1999; Woodsend and Lapata, 2011). Machine Translation systems have been adapted to translate complex sentences into simple ones (Zhu et al., 2010; Wubben et al., 2012; Coster and Kauchak, 2011). And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996). In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways. First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which handles reordering and substitution. In this way, we exploit the ability of statistical machine translation (SMT) systems to capture phrasal/lexical substitutio"
P14-1041,P07-2009,0,0.20616,"his way, we exploit the ability of statistical machine translation (SMT) systems to capture phrasal/lexical substitution and reordering while relying on a dedicated probabilistic module to capture the splitting and deletion operations which are less well (deletion) or not at all (splitting) captured by SMT approaches. Second, our approach is semantic based. While previous simplification approaches starts from either the input sentence or its parse tree, our model takes as input a deep semantic representation namely, the Discourse Representation Structure (DRS, (Kamp, 1981)) assigned by Boxer (Curran et al., 2007) to the input complex sentence. As we We present a hybrid approach to sentence simplification which combines deep semantics and monolingual machine translation to derive simple sentences from complex ones. The approach differs from previous work in two main ways. First, it is semantic based in that it takes as input a deep semantic representation rather than e.g., a sentence or a parse tree. Second, it combines a simplification model for splitting and deletion with a monolingual translation model for phrase substitution and reordering. When compared against current state of the art methods, ou"
P14-1041,W08-1105,0,0.285564,"or apposition); and fewer modifiers (e.g., He slept vs. He also slept). In practice, simplification is thus often modeled using four main operations: splitting a complex sentence into several simpler sentences; dropping and reordering phrases or constituents; substituting words/phrases with simpler ones. As has been argued in previous work, sentence simplification has many potential applications. It is useful as a preprocessing step for a variety of NLP systems such as parsers and machine translation systems (Chandrasekar et al., 1996), summarisation (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008) and semantic 435 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 435–445, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics pler ones by greedily selecting the output sentence with highest probability. Using both the PWKP corpus developed by Zhu et al. (2010) and the edit history of Simple Wikipedia, Woodsend and Lapata (2011) learn a quasi synchronous grammar (Smith and Eisner, 2006) describing a loose alignment between parse trees of complex and of simple sentences. Following Dras (1999), they then gene"
P14-1041,kow-belz-2012-lg,0,0.0255635,"Missing"
P14-1041,C04-1129,0,0.156259,"on native speakers (Siddharthan, 2002). There has been much work recently on developing computational frameworks for sentence simplification. Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence (Dras, 1999; Woodsend and Lapata, 2011). Machine Translation systems have been adapted to translate complex sentences into simple ones (Zhu et al., 2010; Wubben et al., 2012; Coster and Kauchak, 2011). And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996). In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways. First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which handles reordering and substitution. In this way, we exploit the ability of statistical machine translation (SMT) systems to capture phrasal/lexical substitution and reordering while relying on a dedicated probabilistic module to capture the splitting and deletion operations which are less well"
P14-1041,W10-4213,0,0.0931557,"eleting obligatory arguments. When compared against current state of the art methods (Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012), our model yields significantly simpler output that is both grammatical and meaning preserving. 2 Related Work Earlier work on sentence simplification relied on handcrafted rules to capture syntactic simplification e.g., to split coordinated and subordinated sentences into several, simpler clauses or to model active/passive transformations (Siddharthan, 2002; Chandrasekar and Srinivas, 1997; Bott et al., 2012; Canning, 2002; Siddharthan, 2011; Siddharthan, 2010). While these handcrafted approaches can encode precise and linguistically well-informed syntactic transformation (using e.g., detailed morphological and syntactic information), they are limited in scope to purely syntactic rules and do not account for lexical simplifications and their interaction with the sentential context. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedia (EWKP)2 , more recent work has focused on developing machine learning approaches to sentence simplification. Zhu et al. (2010) constructed a parallel corpus (PWKP) of 1"
P14-1041,W11-2802,0,0.221329,"rthan, 2002). There has been much work recently on developing computational frameworks for sentence simplification. Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence (Dras, 1999; Woodsend and Lapata, 2011). Machine Translation systems have been adapted to translate complex sentences into simple ones (Zhu et al., 2010; Wubben et al., 2012; Coster and Kauchak, 2011). And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996). In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways. First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which handles reordering and substitution. In this way, we exploit the ability of statistical machine translation (SMT) systems to capture phrasal/lexical substitution and reordering while relying on a dedicated probabilistic module to capture the splitting and deletion operations which are less well (deletion) or not"
P14-1041,W06-3104,0,0.020902,"and machine translation systems (Chandrasekar et al., 1996), summarisation (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008) and semantic 435 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 435–445, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics pler ones by greedily selecting the output sentence with highest probability. Using both the PWKP corpus developed by Zhu et al. (2010) and the edit history of Simple Wikipedia, Woodsend and Lapata (2011) learn a quasi synchronous grammar (Smith and Eisner, 2006) describing a loose alignment between parse trees of complex and of simple sentences. Following Dras (1999), they then generate all possible rewrites for a source tree and use integer linear programming to select the most appropriate simplification. They evaluate their model on the same dataset used by Zhu et al. (2010) namely, an aligned corpus of 100/131 EWKP/SWKP sentences and show that they achieve better BLEU score. They also conducted a human evaluation on 64 of the 100 test sentences and showed again a better performance in terms of simplicity, grammaticality and meaning preservation. I"
P14-1041,P08-1040,0,0.34684,"Missing"
P14-1041,D11-1038,0,0.459744,"503 Vandoeuvre-l`es-Nancy, F-54500, France claire.gardent@loria.fr Abstract role labelling (Vickrey and Koller, 2008). It also has wide ranging potential societal application as a reading aid for people with aphasis (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). There has been much work recently on developing computational frameworks for sentence simplification. Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence (Dras, 1999; Woodsend and Lapata, 2011). Machine Translation systems have been adapted to translate complex sentences into simple ones (Zhu et al., 2010; Wubben et al., 2012; Coster and Kauchak, 2011). And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996). In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways. First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which"
P14-1041,P12-1107,0,0.599521,"Missing"
P14-1041,P01-1067,0,0.0961322,"mited in scope to purely syntactic rules and do not account for lexical simplifications and their interaction with the sentential context. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedia (EWKP)2 , more recent work has focused on developing machine learning approaches to sentence simplification. Zhu et al. (2010) constructed a parallel corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001). Their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sentences namely, substitution, reordering, splitting and deletion. It is combined with a language model to improve grammaticality and the decoder translates sentences into sim3 Simplification Framework We start by motivating our approach and explaining how it relates to previous proposals w.r.t., the four main operations involved in simplification namely, splitting, deletion, substitution and reordering. We then introduce our framework. 1 SWKP (http://simple.wikipedia.org) is a c"
P14-1041,C10-1152,0,0.116745,"lso has wide ranging potential societal application as a reading aid for people with aphasis (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). There has been much work recently on developing computational frameworks for sentence simplification. Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence (Dras, 1999; Woodsend and Lapata, 2011). Machine Translation systems have been adapted to translate complex sentences into simple ones (Zhu et al., 2010; Wubben et al., 2012; Coster and Kauchak, 2011). And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996). In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways. First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which handles reordering and substitution. In this way, we exploit the ability of statistical machine translation (SMT"
P16-1127,P14-1133,0,0.0637,"lying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNNbased sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques for our task. However we o"
P16-1127,D13-1160,0,0.263199,"relative to the underlying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNNbased sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques f"
P16-1127,D14-1067,0,0.0510377,"ques. Reddy et al. (2014) exploits a weak supervision signal to learn a mapping between the logical form associated by a CCG based semantic parser with the input question and the appropriate logical form in Freebase (Bollacker et al., 2008). Paraphrase-based approaches (Fader et al., 2013; Berant and Liang, 2014) generate variants of the input question using a simple hand-written grammar and then rank these using a paraphrase model. That is, in their setting, the logical form assigned to the input question is that of the generated sentence which is most similar to the input question. Finally, Bordes et al. (2014b; 2014a) learn a similarity function between a natural language question and the knowledge base formula encoding its answer. We depart from these approaches in that we learn a direct mapping between natural language questions and their corresponding logical form or equivalently, their corresponding derivation and canonical form. This simple, very direct approach to semantic parsing eschews the need for complex feature engineering and large external resources required by such paraphrase-based approaches as (Fader et al., 2013; Berant and Liang, 2014). It is conceptually simpler than the two st"
P16-1127,P13-1158,0,0.012785,"gation. 5 Related Work and Discussion In recent work on developing semantic parsers for open-domain and domain-specific question answering, various methods have been proposed to handle the mismatch between natural language questions and knowledge base representations including, graph matching, paraphrasing and embeddings techniques. Reddy et al. (2014) exploits a weak supervision signal to learn a mapping between the logical form associated by a CCG based semantic parser with the input question and the appropriate logical form in Freebase (Bollacker et al., 2008). Paraphrase-based approaches (Fader et al., 2013; Berant and Liang, 2014) generate variants of the input question using a simple hand-written grammar and then rank these using a paraphrase model. That is, in their setting, the logical form assigned to the input question is that of the generated sentence which is most similar to the input question. Finally, Bordes et al. (2014b; 2014a) learn a similarity function between a natural language question and the knowledge base formula encoding its answer. We depart from these approaches in that we learn a direct mapping between natural language questions and their corresponding logical form or equ"
P16-1127,N13-1092,0,0.019418,"Missing"
P16-1127,P82-1020,0,0.855865,"Missing"
P16-1127,D13-1161,0,0.121238,"sting of derivation steps relative to the underlying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNNbased sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit"
P16-1127,P15-1142,0,0.0761773,"esults for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques for our task. However we observe that, contrary to those applications which try to predict intrinsically sequential objects (texts), our task involves producing a structured object, namely a logical form that is tree-like by nature and"
P16-1127,Q14-1030,0,0.0438488,"al knowledge, DSP-CL = Derivation Sequence using a loss function constrained by grammatical knowledge. gives small probability to ungrammatical choices, a property not shared by DSP-CL. However, a more complete understanding of the difference will need more investigation. 5 Related Work and Discussion In recent work on developing semantic parsers for open-domain and domain-specific question answering, various methods have been proposed to handle the mismatch between natural language questions and knowledge base representations including, graph matching, paraphrasing and embeddings techniques. Reddy et al. (2014) exploits a weak supervision signal to learn a mapping between the logical form associated by a CCG based semantic parser with the input question and the appropriate logical form in Freebase (Bollacker et al., 2008). Paraphrase-based approaches (Fader et al., 2013; Berant and Liang, 2014) generate variants of the input question using a simple hand-written grammar and then rank these using a paraphrase model. That is, in their setting, the logical form assigned to the input question is that of the generated sentence which is most similar to the input question. Finally, Bordes et al. (2014b; 201"
P16-1127,P15-1129,0,0.0862307,"Missing"
P16-1127,D15-1199,0,0.00681658,"ng systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques for our task. However we observe that, contrary to those applications which try to predict intrinsically sequential objects (texts), our task involves producing a structured object, namely a logical form that is tree-like by nature and also has to respect certain a priori constraints in order to be interpretable against the knowledge base. In our case, building on the work “Building a Semantic Parser Overnight” (Wang et al., 2015), which we will refer to as SPO, the LFs are generated by a grammar which is known a priori, and it is this grammar that makes"
P16-1127,P16-1004,0,\N,Missing
P16-1127,P14-2105,0,\N,Missing
P16-1127,P14-1129,0,\N,Missing
P17-1017,W13-2111,1,0.858118,"Several domain specific data-text corpora have been built by researchers to train and evaluate NLG systems. In the sports domain, Chen and Mooney (2008) constructed a dataset mapping soccer games events to text which consists of 1,539 data-text pairs and a vocabulary of 214 words. For weather forecast generation, the dataset of Liang et al. (2009) includes 29,528 data-text pairs with a vocabulary of 345 words. For the air travel domain, Ratnaparkhi (2000) created a dataset consisting of 5,426 datatext pairs with a richer vocabulary (927 words) and in the biology domain, the KBGen shared task (Banik et al., 2013) made available 284 data-text pairs where the data was extracted from an existing knowledge base and the text was authored by biology experts. An important limitation of these datasets is that, because they are domain specific, systems learned from them are restricted to generating domain specific, often strongly stereotyped text (e.g., weather forecast or soccer game commentator reports). Arguably, training corpora for NLG should support the learning of more generic systems capable of handling a much wider range of linguistic interactions than is present in stereotyped texts. By nature howeve"
P17-1017,C16-1105,0,0.104502,"ecently, data-to-text benchmarks have also been created by associating data units with text using crowdsourcing. Wen et al. (2016) first created data by enumerating all possible combinations of 14 dialog act types (e.g., request, inform) and attribute-value pairs present in four small-size, hand-written ontologies about TVs, laptops, restaurants and hotels. They then use crowdsourcing to associate each data unit with a text. The resulting dataset is both large and varied (4 domains) and was successfully exploited to train neural and imitation learning data-to-text generator (Wen et al., 2016; Lampouras and Vlachos, 2016). Similarly, Novikova and Rieser (2016) described a framework for collecting data-text pairs using automatic quality control measures and evaluating how the type of the input representations (text vs pictures) impacts the quality of crowdsourced text. The crowdsourcing approach to creating inputtext corpora has several advantages. First, it is low cost in that the data is produced automatically and the text is authored by a crowdworker. This is in stark contrast with the previous approach where expert linguists are required to align text with data. Benchmarks constructed from “expert” linguist"
P17-1017,D16-1128,0,0.130034,"an ours, it is less diverse both in terms of input and in terms of text. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in micro-planning between lexicalisation, aggregation, surface realisation, referring expression generation and sentence segmentation. To encourage researchers to take up this challenge, we recently made available a dataset created using this framework in the context of the W EB NLG shared task. 1 1 We ignore here (Lebret et al., 2016)’s dataset which was created fully automatically from Wikipedia by associating infoboxes with text because this dataset fails to ensure an adequate match between data and text. We manually examined 50 input/output pairs randomly extracted from this dataset and did not find a single example where data and text matched. As such, this dataset is ill-suited for training microplanners. Moreover, since its texts contain both missing and additional information, it cannot be used to train joint models for content selection and micro-planning either. Introduction To train Natural Language Generation (N"
P17-1017,P09-1011,0,0.0280802,"than on the existing ones. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of generating complex texts from KB data. 2 NLG Benchmarks Domain specific benchmarks. Several domain specific data-text corpora have been built by researchers to train and evaluate NLG systems. In the sports domain, Chen and Mooney (2008) constructed a dataset mapping soccer games events to text which consists of 1,539 data-text pairs and a vocabulary of 214 words. For weather forecast generation, the dataset of Liang et al. (2009) includes 29,528 data-text pairs with a vocabulary of 345 words. For the air travel domain, Ratnaparkhi (2000) created a dataset consisting of 5,426 datatext pairs with a richer vocabulary (927 words) and in the biology domain, the KBGen shared task (Banik et al., 2013) made available 284 data-text pairs where the data was extracted from an existing knowledge base and the text was authored by biology experts. An important limitation of these datasets is that, because they are domain specific, systems learned from them are restricted to generating domain specific, often strongly stereotyped tex"
P17-1017,P14-5010,0,0.00200382,"a Bachelor of Science degree at the University of Texas at Austin in 1955 and was chosen by NASA in 1963. 10 Recall from section 3 that input patterns are inputs where subjects and objects have been remove thus, in essence, an input pattern is the set of all the attributes occurring in a given input. 185 As illustrated by the contrast between Examples (6) and (7) above, text length (number of tokens per text) and the number of sentences per text are strong indicators of the complexity of the generation task. We use the Stanford Part-Of-Speech Tagger and Parser version 3.5.2 (dated 2015-0420, Manning et al. 2014) to tokenize and to perform sentence segmentation on text. As shown in Table 4, W EB NLG’s texts are longer both in terms of tokens and in terms of number of sentences per text. Another difference between the two datasets is that W EB NLG contains a higher number of text per input thereby providing a better basis for learning paraphrases. Nb. Text / Input Text Length (avg/median/min/max) Nb. Sentence / Text (avg/median/min/max) Nb. Tokens Nb. Types Lexical Sophistication CTTR W EB NLG 2.63 24.36/23/4/80 RNNLG 1.38 18.37/19/1/76 1.45/1/1/6 1.25/1/1/6 290479 2992 0.69 3.93 531871 3524 0.54 3.42"
P17-1017,mendes-etal-2012-dbpedia,0,0.0189715,"using the SRILM toolkit (Stolcke, 2002): one model (S-Model) for bigrams occurring in sibling triples (triples with a shared subject); one model (C-Model) for bigrams occurring in chained triples (the object of one triple is the subject of the other); and one model (M-Model) which is a linear interpolation of the sibling and the chain model. The intuition is that these sibDBPedia To illustrate the functioning of our benchmark creation framework, we apply it to DBPedia. DBPedia is a multilingual knowledge base that was built from various kinds of structured information contained in Wikipedia (Mendes et al., 2012). This data is stored as RDF (Resource Description Format) triples of the form (subject, property, object) where the subject is a URI (Uniform Resource Identifier), the property is a binary relation and the object is either a URI or a literal value such as a string, a date or a number. We use an English version of the DBPedia knowledge base which encompasses 6.2M entities, 739 classes, 1,099 properties with reference values and 1,596 properties 6 http://wiki.dbpedia.org/ dbpedia-dataset-version-2015-10 7 An entity graph for some entity e is a graph obtained by traversing the DBPedia graph star"
P17-1017,W16-6627,0,0.0281422,"o been created by associating data units with text using crowdsourcing. Wen et al. (2016) first created data by enumerating all possible combinations of 14 dialog act types (e.g., request, inform) and attribute-value pairs present in four small-size, hand-written ontologies about TVs, laptops, restaurants and hotels. They then use crowdsourcing to associate each data unit with a text. The resulting dataset is both large and varied (4 domains) and was successfully exploited to train neural and imitation learning data-to-text generator (Wen et al., 2016; Lampouras and Vlachos, 2016). Similarly, Novikova and Rieser (2016) described a framework for collecting data-text pairs using automatic quality control measures and evaluating how the type of the input representations (text vs pictures) impacts the quality of crowdsourced text. The crowdsourcing approach to creating inputtext corpora has several advantages. First, it is low cost in that the data is produced automatically and the text is authored by a crowdworker. This is in stark contrast with the previous approach where expert linguists are required to align text with data. Benchmarks constructed from “expert” linguistic annotations. NLG benchmarks have als"
P17-1017,P02-1040,0,0.118522,"Missing"
P17-1017,C16-1141,1,0.547657,"ercising the main subtasks of microplanning. For instance, in Example (1) above, given the input shown in (1a), generating (1b) involves lexicalising the occupation property as the phrase worked as (lexicalisation); using PP coordination (born in San Antonio on 1942-08-26) to avoid repeating the word born (aggregation); and verbalising the three triples using a single complex sentence including an apposition, a PP coordination and a transitive verb construction (sentence segmentation and surface realisation). 3.1 3.2 Selecting Content To create data units, we adapted the procedure outlined by Perez-Beltrachini et al. (2016) and sketched in Figure 2. This method can be summarised as follows. First, DBPedia category graphs are extracted from DBPedia by retrieving up to 500 entity graphs for entities of the same category.7 For example, we build a category graph for the Astronaut category by collecting, graphs of depth five for 500 entities of types astronaut. Next, category graphs are used to learn bi-gram models of DBPedia properties which specify the probability of two properties co-occuring together. Three types of bi-gram models are extracted from category graphs using the SRILM toolkit (Stolcke, 2002): one mod"
P17-1017,A00-2026,0,0.102559,"enging data sets from which NLG models can be learned which are capable of generating complex texts from KB data. 2 NLG Benchmarks Domain specific benchmarks. Several domain specific data-text corpora have been built by researchers to train and evaluate NLG systems. In the sports domain, Chen and Mooney (2008) constructed a dataset mapping soccer games events to text which consists of 1,539 data-text pairs and a vocabulary of 214 words. For weather forecast generation, the dataset of Liang et al. (2009) includes 29,528 data-text pairs with a vocabulary of 345 words. For the air travel domain, Ratnaparkhi (2000) created a dataset consisting of 5,426 datatext pairs with a richer vocabulary (927 words) and in the biology domain, the KBGen shared task (Banik et al., 2013) made available 284 data-text pairs where the data was extracted from an existing knowledge base and the text was authored by biology experts. An important limitation of these datasets is that, because they are domain specific, systems learned from them are restricted to generating domain specific, often strongly stereotyped text (e.g., weather forecast or soccer game commentator reports). Arguably, training corpora for NLG should suppo"
P17-1017,N16-1015,0,0.0437239,"Missing"
P17-1017,W11-2832,0,\N,Missing
P89-1034,E89-1034,1,0.876906,"Missing"
P89-1034,P87-1012,0,0.0557738,"tically equivalent. 3. THE PARSER Because the subcategorisation information is represented as a set rather than as a list, there is no constraint on the order in which each valency is consumed. This raises a problem with respect to parsing which is that for any triplet X,Y,Z where Y is a verb and X and Z are arguments to this verb, there will often be two possible derivations i.e., (XY)Z and xo'z). The problem of spurious parses is a well-known one in extensions of pure categorial grammar. It derives either from using other rules or combinators for derivation than just functional application (Pareschi and Steedman 1987, Wittenburg 1987, Moortgat 1987, Morrill 1988) or from having anordered set valencies (Karttunen 1986), the latter case being that of FG. Various solutions have been proposed in relation to this problem. Karttunen's solution is to check that for any potential edge, no equivalent analysis is already In (5) 3E can be paraphrasedas ""Thereexistsan event"". 282 stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL' need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternativel"
P89-1034,P87-1011,0,0.150829,"ARSER Because the subcategorisation information is represented as a set rather than as a list, there is no constraint on the order in which each valency is consumed. This raises a problem with respect to parsing which is that for any triplet X,Y,Z where Y is a verb and X and Z are arguments to this verb, there will often be two possible derivations i.e., (XY)Z and xo'z). The problem of spurious parses is a well-known one in extensions of pure categorial grammar. It derives either from using other rules or combinators for derivation than just functional application (Pareschi and Steedman 1987, Wittenburg 1987, Moortgat 1987, Morrill 1988) or from having anordered set valencies (Karttunen 1986), the latter case being that of FG. Various solutions have been proposed in relation to this problem. Karttunen's solution is to check that for any potential edge, no equivalent analysis is already In (5) 3E can be paraphrasedas ""Thereexistsan event"". 282 stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL' need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternatively reducing one to"
P96-1001,C96-1073,1,0.575994,"neral theory for modeling the interface between the interpretation process and other sources of linguistic, non semantic information. In particular, it provides the general theory for the Primary Occurrence Restriction which (Dalrymple et al., 1991)&apos;s analysis called for. 1 Introduction It is well known that Higher-Order Unification (HOU) can be used to construct the semantics of Natural Language: (Dalrymple et al., 1991) - henceforth, DSP - show that it allows a treatment of VPEllipsis which successfully captures the interaction of VPE with quantification and nominal anaphora; (Pulman, 1995; Gardent and Kohlhase, 1996) use HOU to model the interpretation of focus and its interaction with focus sensitive operators, adverbial quantifiers and second occurrence expressions; (Gardent et al., 1996) shows that HOU yields a simple but precise treatment of corrections; Finally, (Pinkal, 1995) uses linear HOU to reconstruct underspecified semantic representations. However, it is also well known that the HOU approach to NL semantics systematically overgenerates and that some general theory of the interface between the interpretation process and other sources of linguistic information is needed in order to avoid this."
P99-1007,C96-1073,1,0.833181,"n Equation I S A R(T1, • • •, Tn) R(S1,..., Sn) = S I S is the semantic representation of the source, $ 1 , . . . , Sn and T1,... ,Tn are the semantic representations of the parallel elements in the source and target respectively and R represents the relation to be recovered. The equation is solved using Higher-Order Unification (HOU): Given any solvable equation M = N, HOU yields a substitution of terms for free variables 1As (Dalrymple et al., 1991) themselves observe, HOU also yields other, linguistically invalid, solutions. For a proposal on how to solve this over-generation problem, see (Gardent and Kohlhase, 1996b; Gardent et al., 1999). 49 In this paper, I start (section 2) by clarifying the relationship between DSP&apos;s proposal and the semantic representation of discourse anaphors. In section 3 and 4, I then show that the HOU-treatment of ellipsis naturally extends to provide: Furthermore, although DSP only apply their analysis to VP-ellipsis, they have in mind a much broader range of applications: [...] many other elliptical phenomena and related phenomena subject to multiple readings akin to the strict and sloppy readings discussed here may be analysed using the same techniques (Dalrymple et al., 19"
P99-1007,P96-1001,1,0.838447,"n Equation I S A R(T1, • • •, Tn) R(S1,..., Sn) = S I S is the semantic representation of the source, $ 1 , . . . , Sn and T1,... ,Tn are the semantic representations of the parallel elements in the source and target respectively and R represents the relation to be recovered. The equation is solved using Higher-Order Unification (HOU): Given any solvable equation M = N, HOU yields a substitution of terms for free variables 1As (Dalrymple et al., 1991) themselves observe, HOU also yields other, linguistically invalid, solutions. For a proposal on how to solve this over-generation problem, see (Gardent and Kohlhase, 1996b; Gardent et al., 1999). 49 In this paper, I start (section 2) by clarifying the relationship between DSP&apos;s proposal and the semantic representation of discourse anaphors. In section 3 and 4, I then show that the HOU-treatment of ellipsis naturally extends to provide: Furthermore, although DSP only apply their analysis to VP-ellipsis, they have in mind a much broader range of applications: [...] many other elliptical phenomena and related phenomena subject to multiple readings akin to the strict and sloppy readings discussed here may be analysed using the same techniques (Dalrymple et al., 19"
P99-1007,P97-1051,0,0.173961,"raint on deaccenting still holds but it plays no role in determining these particular quantification domains. lowing equalitiesZ: 4 Resolution of the first equation yields AR.wt(you, R(i, you)) --+ R(i, you) as a possible value for C and consequently, the value for C(k) is: C(h) = wt(you, h(i, you)) -+ h(i, you) C(k) = P(you) --+ k(i, you) Sloppy i d e n t i t y As we saw in section 2, an important property of DSP&apos;s analysis is that it predicts sloppy/strict ambiguity for VP-Ellipsis whereby the multiple solutions generated by HOU capture the multiple readings allowed by natural language. As (Hobbs and Kehler, 1997; Hardt, 1996) have shown however, sloppy identity is not necessarily linked to VP-ellipsis. Essentially, it can occur whenever, in a parallel configuration, the antecedent of an anaphor/ellipsis itself contains an anaphor/ellipsis whose antecedent is a parallel element. Here are some examples. (14) (15) (16) C(k) = wt(you, k(i, you)) -+ k(i, ou) Therefore a possible substitution for P is: {P +-- x.wt(x,k(i,x))} and the V P E occurring in the target can indeed be assigned the sloppy interpretation x want me to kiss x. Now consider example (15). The pronoun it occurring in the second clause has"
P99-1007,P97-1053,0,0.0289811,"Missing"
R09-1015,W06-3814,0,0.0686424,"Missing"
R09-1015,P01-1008,0,0.107095,"Missing"
R09-1015,P90-1034,0,0.496133,"Missing"
R09-1015,W03-1610,0,0.0440522,"Missing"
rojas-barahona-etal-2012-building,bunt-etal-2010-towards,0,\N,Missing
rojas-barahona-etal-2012-building,W03-0705,0,\N,Missing
rojas-barahona-etal-2012-building,W11-2044,0,\N,Missing
S16-2019,D11-1142,0,0.182196,"nalyze the benefit of adding a regularizer favoring the embeddings of entities to be orthogonal to those of relations. The main motivation comes from the observation that modifying the embeddings using prior knowledge often helps performance. The experiments show that incorporating the regularizer yields better results on a challenging question answering benchmark. 1 Introduction Having a system which is able to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al."
S16-2019,P13-1158,0,0.353924,"y, France 1 chunyang.xiao, marc.dymetman@xerox.com 2 g.bouchard@cs.ucl.ac.uk 3 claire.gardent@loria.fr Abstract called logical form. This logical form is then used to query the knowledge base and retrieve the answer. IR-based approaches try to identify the best possible match between the knowledge base and the question (Bordes et al., 2014a; Bordes et al., 2014b; Yao and Van Durme, 2014; Dong et al., 2015). In this work, we focus on the second approach, using embedding models, mainly because it is robust to invalid syntax and can exploit information of the answer. We focus on the Wikianswers (Fader et al., 2013) dataset constructed for Reverb. On Wikianswers, the underlying semantics is very simple (just one single triple). However, the task remains challenging due to the large variety of lexicalizations for the same semantics. We follow the approach of Bordes et .al (2014b) which learns the embeddings of words and KB elements. They model the semantics of natural language sentences and KB triples as the sum of the embeddings of the associated words and KB elements respectively. Despite its simplicity, this model performs surprisingly well in practice. Something even more interesting (Bordes et al., 2"
S16-2019,P14-1133,0,0.0138794,"nts show that incorporating the regularizer yields better results on a challenging question answering benchmark. 1 Introduction Having a system which is able to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pag"
S16-2019,D13-1160,0,0.0126868,"ing the regularizer yields better results on a challenging question answering benchmark. 1 Introduction Having a system which is able to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pages 142–147, Berlin, G"
S16-2019,D14-1067,0,0.123779,"er et al., 2013) dataset constructed for Reverb. On Wikianswers, the underlying semantics is very simple (just one single triple). However, the task remains challenging due to the large variety of lexicalizations for the same semantics. We follow the approach of Bordes et .al (2014b) which learns the embeddings of words and KB elements. They model the semantics of natural language sentences and KB triples as the sum of the embeddings of the associated words and KB elements respectively. Despite its simplicity, this model performs surprisingly well in practice. Something even more interesting (Bordes et al., 2014b) is that the system can have a good performance even without using a paraphrase corpus. This makes the system very attractive in practice because in many specific domains, we might have a KB but there may be no paraphrase corpus as in Wikianswers. In our work, we push the results further when learning a QA system based only on the KB. Our contribution is to introduce a new orthogonality regularizer which distinguishes entities and relations. We also investigate the tradeoff captured by the orthogonality constraints. With a synthetic example, we show that if entities and relations are indepen"
S16-2019,Q14-1030,0,0.0139472,"of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pages 142–147, Berlin, Germany, August 11-12, 2016. most no linguistic features such as POS tagging, parsing, etc. 2 The idea of distinguishing entities and relations in question answering can also be found in (Yih et al., 2014). However, they base their work by supposing that we can cut the sentence into “entity part” and “relation part” and then calculate the matching score. Our model does not need this cut and"
S16-2019,P15-1026,0,0.0879141,"er for question answering Chunyang Xiao1 , Guillaume Bouchard2 , Marc Dymetman1 ,Claire Gardent3 1 Xerox Research Centre Europe, Grenoble, France 2 University College London, United Kingdom 3 CNRS, LORIA, Nancy, France 1 chunyang.xiao, marc.dymetman@xerox.com 2 g.bouchard@cs.ucl.ac.uk 3 claire.gardent@loria.fr Abstract called logical form. This logical form is then used to query the knowledge base and retrieve the answer. IR-based approaches try to identify the best possible match between the knowledge base and the question (Bordes et al., 2014a; Bordes et al., 2014b; Yao and Van Durme, 2014; Dong et al., 2015). In this work, we focus on the second approach, using embedding models, mainly because it is robust to invalid syntax and can exploit information of the answer. We focus on the Wikianswers (Fader et al., 2013) dataset constructed for Reverb. On Wikianswers, the underlying semantics is very simple (just one single triple). However, the task remains challenging due to the large variety of lexicalizations for the same semantics. We follow the approach of Bordes et .al (2014b) which learns the embeddings of words and KB elements. They model the semantics of natural language sentences and KB tripl"
S16-2019,P14-2105,0,0.0156772,"ble to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pages 142–147, Berlin, Germany, August 11-12, 2016. most no linguistic features such as POS tagging, parsing, etc. 2 The idea of distinguishing entitie"
S16-2019,P14-1090,0,\N,Missing
S16-2027,P05-1074,0,0.0405105,"Missing"
S16-2027,D11-1142,0,0.0865546,"y names while systematically checking for semantic relatedness. 2 Relation Extraction Earlier Information Extraction (IE) systems learned an extractor for each target relation from labelled training examples (Riloff, 1996; Soderland, 1999). For instance, (Riloff, 1996) first extract relation mention patterns from the corpus then rank these based on the number of time a relation pattern occurs in a text labelled with the target relation. More recent work on Open IE has focused on building large scale knowledge bases such as Reverb by extracting arbitrary relations from text (Wu and Weld, 2010; Fader et al., 2011; Mohamed et al., 2011; Nakashole et al., 2012). While relation extraction can be viewed as the mirror task of relation lexicalisation, there are important differences. Our lexicalisation task differs from domain specific IE in that it is unsupervised (we do not have access to annotated data). It also differs from open IE in that the set of properties to be lexicalised is predefined whereas, by definition, in open IE, the set of relations to be extracted is unrestricted. That is, while we aim to find the possible lexicalisations of a given set of relations (here DBPedia properties), open IE se"
S16-2027,P13-1158,0,0.0537503,"Missing"
S16-2027,D11-1134,0,0.0323015,"atically checking for semantic relatedness. 2 Relation Extraction Earlier Information Extraction (IE) systems learned an extractor for each target relation from labelled training examples (Riloff, 1996; Soderland, 1999). For instance, (Riloff, 1996) first extract relation mention patterns from the corpus then rank these based on the number of time a relation pattern occurs in a text labelled with the target relation. More recent work on Open IE has focused on building large scale knowledge bases such as Reverb by extracting arbitrary relations from text (Wu and Weld, 2010; Fader et al., 2011; Mohamed et al., 2011; Nakashole et al., 2012). While relation extraction can be viewed as the mirror task of relation lexicalisation, there are important differences. Our lexicalisation task differs from domain specific IE in that it is unsupervised (we do not have access to annotated data). It also differs from open IE in that the set of properties to be lexicalised is predefined whereas, by definition, in open IE, the set of relations to be extracted is unrestricted. That is, while we aim to find the possible lexicalisations of a given set of relations (here DBPedia properties), open IE seeks to extract an unre"
S16-2027,D14-1162,0,0.092881,"(tj , si )] (5) 223 where (ti , si ) is a positive triple/sentence example and (tj , si ) a negative one. Similarly, when training on paraphrase data, the ranking loss function to minimise is: ∀i, j, l, ∀[1 − Sp (pi , pj ) + Sp (pi , pl )] (6) where (pi , pj ) is a positive example from the paraphrase corpus P and (pi , pl ) a negative one. 4 Implementation The model is implemented in Python using the Keras(Chollet, 2015) library with Theano backend. We initialise the W matrix with pre-trained vectors which already provide a rich representation for words. We use the publicly available GloVe (Pennington et al., 2014) vectors2 of length 100. These vectors were trained on 6 billions words from Wikipedia and the English Gigaword. We set the dimension d of the K and W matrices to 100. For K we use uniform initialisation. The size of the vocabulary for the W matrix, the nw dimension, is 130970 words. This is considering all words appearing in the T and P sets. The size of the K matrix, the nk dimension, is 43797 counting both KB entities and relations. The training for both similarity functions St/s and Sp is performed with Stochastic Gradient Descent. The learning rate is set to 0.1 and the number of epochs t"
S16-2027,P10-1013,0,0.0181538,"th types of property names while systematically checking for semantic relatedness. 2 Relation Extraction Earlier Information Extraction (IE) systems learned an extractor for each target relation from labelled training examples (Riloff, 1996; Soderland, 1999). For instance, (Riloff, 1996) first extract relation mention patterns from the corpus then rank these based on the number of time a relation pattern occurs in a text labelled with the target relation. More recent work on Open IE has focused on building large scale knowledge bases such as Reverb by extracting arbitrary relations from text (Wu and Weld, 2010; Fader et al., 2011; Mohamed et al., 2011; Nakashole et al., 2012). While relation extraction can be viewed as the mirror task of relation lexicalisation, there are important differences. Our lexicalisation task differs from domain specific IE in that it is unsupervised (we do not have access to annotated data). It also differs from open IE in that the set of properties to be lexicalised is predefined whereas, by definition, in open IE, the set of relations to be extracted is unrestricted. That is, while we aim to find the possible lexicalisations of a given set of relations (here DBPedia pro"
W03-2410,P98-1013,0,0.0309738,"where the implicit bridging relation “comes from”: is it a lexical relation (e.g., meronymy, hyponymy, synonymy) whose encoding is part of tools such as WordNet? Is it given by world knowledge? etc. In this paper, we focus on identifying the set of relations that can hold between a bridging definite description and its antecedent. Starting from the literature, we propose a typology for these relations which we then validate on a medium size corpus (9500 definite descriptions of which roughly 400 are bridging definite descriptions). Further, we investigate WordNet (Miller, 1995) and FrameNet (Baker et al., 1998) and quantify the number of cases where these resources actually contain the relation used between the ontological types of the antecedent/anaphor pair. We conclude with some indications of which types of lexical resources are needed in order to interpret and/or generate bridging definite descriptions as well as pointers for further research. 2 A typology of bridging relations In this section, we start by summarising the bridging relations identified in the literature. We then explains why it cannot be used directly as a basis for annotation and go on to propose a taxonomy of bridging relation"
W03-2410,W01-1612,0,0.0193389,"a collaboration between ATILF and the LORIA research unit. 3. This part of the work was carried out by Eric Kow. F IG . 2 – The MMAX annotation tool these two NPs twice in its output, if three are embedded, it gives it three times, etc..). – writing a filter to adapt the output format of Gsearch to the input format of MMAX, i.e. XML text, tagged word by word and with all the definite description phrases tagged as markables to be highlighted in the MMAX window. 3.2 Annotating definite descriptions To annotate definite descriptions and their relation to their antecedent, we used the MMAX tool (Mueller and Strube, 2001). Designed to support the annotation of anaphoric and bridging relations in written text, MMAX takes as input XML encoded text corpora whereby the structure of each of the XML element types is described by a DTD (Document Type Definition). The XML elements representing markables (i.e., antecedent, coreferential and bridging NPs) have a closed set of fixed system attributes which can be complemented with user defined attributes as required by the annotation scheme. The system is equiped with a graphical interface which allows the annotator to select the values of user or predefined system attri"
W03-2410,J98-2001,0,0.222441,"Missing"
W03-2410,A97-1014,0,0.0587804,"Missing"
W03-2410,C98-1013,0,\N,Missing
W04-0910,N03-1003,0,0.043162,"ed research interest in paraphrases as IE and QA systems typically need to be able to recognise various verbalisations of the content. Because of the large, open domain corpora these systems deal with, coverage and robustness are key issues and much on the work on paraphrases in that domain is based on automatic learning techniques. For instance, (Lin and Pantel, 2001) acquire two-argument templates (inference rules) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning. Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al., 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source. And (Glickman and Dagan, 2003) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts. Such machine learning approaches have known pros and cons. On the one hand, they produce large scale resources at little man labour cost. On the other hand, the degree of descriptive abstraction offered by the list of inference or paraphrase rules they output is low. We chose to investigat"
W04-0910,H91-1060,0,0.0584646,"etrable This tool is parameterisable. Cet outil peut eˆ tre param´etr´e This tool can be parameterised. 3 Developing a paraphrase testsuite Based on the above typology, we can systematically construct a testsuite for developing and evaluating a paraphrastic grammar. Indeed, when developing a grammar, it is necessary to have some means of assessing both the coverage of the grammar (does it generate all the sentences of the described language?) and its degree of overgeneration (does it generate only the sentences of the described language?) While corpus driven efforts along the PAR SEVAL lines (Black et al., 1991) are good at giving some measure of a grammar coverage, they are not suitable for finer grained analysis and in particular, for progress evaluation, regression testing and comparative report generation. Another known method consists in developing and using a test suite that is, a set of negative and positive items against which the grammar can be systematically tested. For english, there is for instance the 15 year old HewlettPackard test suite, a simple text file listing test sentences and grouping them according to linguistics phenomena (Flickinger et al., 1987); and more recently, the much"
W04-0910,copestake-flickinger-2000-open,0,0.0339822,"family, we attempt to find examples with distinct aspectual categories (state, accomplishment and process). Finally, given a WN family and an aspectual category, items will vary with respect to the arity of the main predicate and the types of their arguments e.g., predicates of arity one (run, cost, sleep), of arity two with non propositional arguments (eat, hit, dug), of arity two with a propositional argument (say, promise etc.), etc. 4 A paraphrastic grammar “Semantic grammars” already exist which describe not only the syntax but also the semantics of natural language. Thus for instance, (Copestake and Flickinger, 2000; Copestake et al., 2001) describes a Head Driven Phrase Structure Grammar (HPSG) which supports the parallel construction of a phrase structure (or derived) tree and of a semantic representation and (Dalrymple, 1999) show how to equip Lexical Functional grammar (LFG) with a glue semantics. These grammars are both efficient and large scale in that they cover an important fragment of the natural language they describe and can be processed by parsers and generators in almost real time. For instance, the LFG grammar parses sentences from the Wall Street Journal and the ERG HPSG grammar will produ"
W04-0910,P01-1019,0,0.200677,"ples with distinct aspectual categories (state, accomplishment and process). Finally, given a WN family and an aspectual category, items will vary with respect to the arity of the main predicate and the types of their arguments e.g., predicates of arity one (run, cost, sleep), of arity two with non propositional arguments (eat, hit, dug), of arity two with a propositional argument (say, promise etc.), etc. 4 A paraphrastic grammar “Semantic grammars” already exist which describe not only the syntax but also the semantics of natural language. Thus for instance, (Copestake and Flickinger, 2000; Copestake et al., 2001) describes a Head Driven Phrase Structure Grammar (HPSG) which supports the parallel construction of a phrase structure (or derived) tree and of a semantic representation and (Dalrymple, 1999) show how to equip Lexical Functional grammar (LFG) with a glue semantics. These grammars are both efficient and large scale in that they cover an important fragment of the natural language they describe and can be processed by parsers and generators in almost real time. For instance, the LFG grammar parses sentences from the Wall Street Journal and the ERG HPSG grammar will produce semantic representatio"
W04-0910,E03-1030,1,0.84779,"n fine grained semantic distinctions, the underspecification and the description of the scope relations permitted by these semantics will here be largely ignored and flat semantics will be principally used as a convenient way of describing predicate/arguments and modifiers/modified relationships. Thus the semantic representations we assume are simply set of literals of the form P n (x1 , . . . , xn ) where P n is a predicate of arity n and xi is either a constant or a unification variable whose value will be instantiated during processing. Semantic construction proceeds from the derived tree (Gardent and Kallmeyer, 2003) rather than – as is more common in TAG – from the derivation tree. This is done by associating each elementary tree with a semantic representation and by decorating relevant tree nodes with unification variables and constants occuring in associated semantic representation. The association between tree nodes and unification variables encodes the syntax/semantics interface – it specifies which node in the tree provides the value for which variable in the final semantic representation. As trees combine during derivation, (i) variables are unified – both in the tree and in the associated semantic"
W04-0910,P98-2127,0,0.118736,"ed by a paraphrastic link be it parallel, shuffling or definitional) is more or less easy as resources for that specific means may or may not be readily available. Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available (Ploux, 1997). Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries. For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity (Pereira et al., 1993; Lin, 1998). techniques. For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related. Lexical semantics information still need to be included. Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, french alternatio"
W04-0910,P93-1024,0,0.0417096,"ll lexical items related by a paraphrastic link be it parallel, shuffling or definitional) is more or less easy as resources for that specific means may or may not be readily available. Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available (Ploux, 1997). Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries. For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity (Pereira et al., 1993; Lin, 1998). techniques. For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related. Lexical semantics information still need to be included. Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, frenc"
W04-0910,C98-2122,0,\N,Missing
W05-1605,W00-2004,0,0.134797,"Missing"
W05-1605,C92-2092,0,0.138778,"Missing"
W05-1605,P01-1019,0,0.111881,"Missing"
W05-1605,C04-1044,0,0.0962076,"Missing"
W05-1605,E03-1030,1,0.879784,"Missing"
W05-1605,P91-1011,0,0.161268,"Missing"
W05-1605,P96-1027,0,0.54719,"Missing"
W05-1605,C00-1065,0,0.0193604,"Missing"
W05-1605,P02-1003,0,0.754984,"Missing"
W06-1513,C92-2092,0,0.101366,"Missing"
W06-1513,P96-1027,0,0.11174,"Missing"
W06-1513,P02-1003,0,0.234141,"Missing"
W06-1516,2006.jeptalnrecital-long.12,1,0.824703,"Missing"
W06-1516,C96-2120,0,0.0893914,"Missing"
W06-1516,2000.iwpt-1.17,0,0.0511936,", the resulting framework supports a very high degree of factorisation. For instance, a first core grammar (F RAG) for French comprising 4 200 trees was produced from roughly 300 XMG classes. In this paper we introduce a toolbox that allows for both parsing and generation with TAG. This toolbox combines existing software and aims at facilitating grammar development, More precisely, this toolbox includes1 : • XMG: a grammar compiler which supports the generation of a TAG from a factorised TAG (Crabb´e and Duchier, 2004), • LLP2 and DyALog: two chart parsers, one with a friendly user interface (Lopez, 2000) and the other optimised for efficient parsing (Villemonte de la Clergerie, 2005)2 Integrating semantic information. In XMG, classes can be multi-dimensional. That is, they can be used to describe several levels of linguistic knowledge such as for instance, syntax, semantics or prosody. At present, XMG supports classes including both a syntactic and a semantic dimension. As mentioned above, the syntactic dimen• GenI: a chart generator which has been tested on a middle size grammar for French (Gardent and Kow, 2005) 1 All these tools are freely available, more information and links at http://tr"
W06-1516,I05-1015,0,0.0717824,"Missing"
W06-1516,E03-1030,1,0.847949,"Missing"
W06-1516,W05-1605,1,0.926795,"Duchier, 2004), • LLP2 and DyALog: two chart parsers, one with a friendly user interface (Lopez, 2000) and the other optimised for efficient parsing (Villemonte de la Clergerie, 2005)2 Integrating semantic information. In XMG, classes can be multi-dimensional. That is, they can be used to describe several levels of linguistic knowledge such as for instance, syntax, semantics or prosody. At present, XMG supports classes including both a syntactic and a semantic dimension. As mentioned above, the syntactic dimen• GenI: a chart generator which has been tested on a middle size grammar for French (Gardent and Kow, 2005) 1 All these tools are freely available, more information and links at http://trac.loria.fr/˜semtag. 2 Note that DyALog refers in fact to a logic programming language, and a tabular compiler for this language. The DyALog system is well-adapted to the compilation of efficient tabular parsers. 3 Although in this paper we only mention TAG, the XMG framework is also used to develop so called Interaction Grammars i.e., grammars whose basic units are tree descriptions rather than trees (Parmentier and Le Roux, 2005). 115 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Rel"
W06-1805,peters-peters-2000-treatment,0,0.299067,"Missing"
W06-1805,C96-2120,0,\N,Missing
W07-1430,W06-1805,1,0.41137,"uping together adjectives which intuitively denote functions from properties to properties, i.e. second order objects. We present a compositional semantics for adjectives which both (i) defines a first order representation and (ii) integrates interactions with other sources of linguistic information such as lexical semantics and morpho-derivational relations. We then show that the proposed semantics correctly predicts the inferential patterns observed to hold of the various adjective subclasses identified in the literature (Chierchia and Connell-Ginet, 1990; Kamp, 1975; Kamp and Partee, 1995; Amoia and Gardent, 2006). This paper is structured as follows. We start by presenting a classification of adjectives which is motivated by the different inferential patterns observed. We then propose a compositional semantics for each class and show that it correctly predicts their inferential behaviour. We conclude with a brief discussion of related work and pointers for further research. 2 Inferential patterns and adjective classes In the literature (Chierchia and Connell-Ginet, 1990; Kamp, 1975; Kamp and Partee, 1995; Amoia and 185 Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 185–192,"
W07-1430,P85-1008,0,0.693515,"y of these classes are often described using second order constructs. In this paper, we adopt Hobbs’s ontologically promiscuous approach and present a first order treatment of adjective semantics which opens the way for a sophisticated treatment of adjectival inference. The approach was implemented and tested using first order automated reasoners. 1 Introduction As has often been observed, not all of natural language meaning can be represented by first order logic. There are expressions such as, most, former, I didn’t whose meaning intuitively involve higherorder constructs. Nevertheless, as (Hobbs, 1985) and others have argued, semantic representations for natural language need not be higher-order in that ontological promiscuity can solve the problem. That is, by reifying all objects that can be predicated of, it is possible to retain a semantic representation scheme for NL that is first-order. This observation is crucial for computational applications for two reasons. First, logics that goes beyond first order are highly undecidable. Second and more importantly, there is no off the shelf higher orClaire gardent CNRS/Loria Campus Scientifique BP 239 54506 Vandoeuvre-les-Nancy, France claire.g"
W07-2306,E03-1030,1,0.943453,"Missing"
W07-2306,W05-1605,1,0.88274,"Missing"
W07-2306,P96-1027,0,0.60969,"Missing"
W07-2306,C88-2147,0,0.833029,"Missing"
W09-3744,W07-1403,0,0.0267342,"Missing"
W09-3744,W05-0620,0,0.154422,"Missing"
W09-3744,W07-1408,0,0.037254,"Missing"
W09-3744,de-marneffe-etal-2006-generating,0,0.0612035,"Missing"
W09-3744,D07-1024,0,0.0292971,"Missing"
W09-3744,W03-2401,0,0.0831195,"Missing"
W09-3744,P03-1054,0,0.00757407,"Missing"
W09-3744,W07-1402,0,0.0570999,"Missing"
W09-3744,W08-2121,0,0.0227445,"Missing"
W09-3744,W08-1301,0,\N,Missing
W09-3744,W07-1400,0,\N,Missing
W12-1507,W11-2832,0,0.0184375,"reby the suspicion rate of an item indicates how likely a given item is to cause parsing to fail. Error mining was shown to successfully help detect errors in the lexicon and to a lesser degree in the grammar. Debugging Grammars using Generation Most of the work on treebank-based evaluation and error mining target undergeneration using parsing. Recently however, some work has been done which exploits generation and more specifically, surface realisation to detect both under- and over-generation. Both (Callaway, 2003) and the Surface Realisation (SR) task organised by the Generation Challenge (Belz et al., 2011) evaluate the output of surface realisers on a set of inputs derived from the Penn Treebank. As with parsing, these approaches permit detecting under-generation in that an input for which the surface realiser fails to produce a sentence points to shortcomings either in the surface realisation algorithm or in the grammar/lexicon. The approach also permits detecting overgeneration in that a low BLEU score points to these inputs for which the realiser produced a sentence that is markedly different from the expected answer. Error mining approaches have also been developed using generation. (Garden"
W12-1507,H91-1060,0,0.405811,"rammar incompleteness (i.e., rules that do not lead to a complete derivation) and (ii) to identify overgeneration and analyse linguistic coverage. Section 6 concludes. 2 Related Work Two main approaches have so far been used to improve grammars: treebank-based evaluation and error mining techniques. We briefly review this work focusing first, on approaches that are based on parsing and second, on those that exploit generation. Debugging Grammars using Parsing Over the last two decades, Treebank-Based evaluation has become the standard way of evaluating parsers and grammars. In this framework (Black et al., 1991), the output of a parser is evaluated on a set of sentences that have been manually annotated with their syntactic parses. Whenever the parse tree produced by the parser differs from the manual annotation, the difference can be traced back to the parser (timeout, disambiguation component), the grammar and/or to the lexicon. Conversely, if the parser fails to return an output, undergeneration can be traced back to missing or erroneous information in the grammar or/and in the lexicon. While it has supported the development of robust, large coverage parsers, treebank based evaluation is limited t"
W12-1507,P01-1019,0,0.0485429,"FBLTAGs equipped with a unification-based compositional semantics. We start by describing the grammar used (S EM TAG), we then summarise the implementation of G RA D E for FB-LTAG. 4.1 SemTAG For our experiments, we use the FB-LTAG described in (Crabb´e, 2005; Gardent, 2008). This grammar, called S EM TAG, integrates a unification-based semantics and can be used both for parsing and for generation. It covers the core constructs for non verbal constituents and most of the verbal constructions for French. The semantic representations built are MRSs (Minimal Recursion Semantic representations, (Copestake et al., 2001)). More specifically, a tree adjoining grammar (TAG) is a tuple hΣ, N, I, A, Si with Σ a set of terminals, N a set of non-terminals, I a finite set of initial trees, A a finite set of auxiliary trees, and S a distinguished non-terminal (S ∈ N ). Initial trees are trees whose leaves are labeled with substitution nodes (marked with a downarrow) or terminal categories3 . Auxiliary trees are distinguished by a foot node (marked with a star) whose category must be the same as that of the root node. 2 The rules whose semantics is not checked during derivation are specified as a parameter of the syst"
W12-1507,W09-2609,0,0.0290111,"Missing"
W12-1507,P12-1062,1,0.670394,"veloped using generation. (Gardent and Kow, 2007) is similar in spirit to the error mining approaches developed for parsing. Starting from a set of manually defined semantic representations, the approach consists in running a surface realiser on these representations; manually sorting the generated sentences as correct or incorrect; and using the resulting two datasets to detect grammatical structures that systematically occur in the incorrect dataset. The approach however is only partially automatised since both the input and the output need to be manually produced/annotated. More recently, (Gardent and Narayan, 2012) has shown how the fully automatic error mining techniques used for parsing could be adapted to mine for errors in the output of a surface realiser tested on the SR input data. In essence, they present an algorithm which enumerate the subtrees in the input data that frequently occur in surface realisation failure (the surface realiser fails to generate a sentence) and rarely occur in surface realisation success. In this way, they can identify subtrees in the input that are predominantly associated with generation failure. In sum, tree-bank based evaluation permits detecting over- and under-gen"
W12-1507,C08-1032,1,0.829933,"} is contained in, and therefore will generate, the flat semantics for the sentences The man runs, The man ran, A man runs, A man ran, This man runs, My man runs, etc.. 4 Implementation In the previous section, we provided an abstract description of the G RA D E algorithm. We now describe an implementation of that algorithm tailored for FBLTAGs equipped with a unification-based compositional semantics. We start by describing the grammar used (S EM TAG), we then summarise the implementation of G RA D E for FB-LTAG. 4.1 SemTAG For our experiments, we use the FB-LTAG described in (Crabb´e, 2005; Gardent, 2008). This grammar, called S EM TAG, integrates a unification-based semantics and can be used both for parsing and for generation. It covers the core constructs for non verbal constituents and most of the verbal constructions for French. The semantic representations built are MRSs (Minimal Recursion Semantic representations, (Copestake et al., 2001)). More specifically, a tree adjoining grammar (TAG) is a tuple hΣ, N, I, A, Si with Σ a set of terminals, N a set of non-terminals, I a finite set of initial trees, A a finite set of auxiliary trees, and S a distinguished non-terminal (S ∈ N ). Initial"
W12-1507,P04-1057,0,0.0464267,"Missing"
W12-1507,C88-2147,0,0.386111,"Missing"
W12-1507,C10-2039,1,\N,Missing
W12-1507,W07-2306,1,\N,Missing
W12-1507,P06-1042,0,\N,Missing
W12-1526,I05-1015,0,0.059409,"Missing"
W12-1526,P07-1042,1,0.936808,"Missing"
W12-1526,P02-1003,0,0.103318,"Missing"
W12-1526,P02-1040,0,0.0852589,"Missing"
W12-1526,W06-1403,0,0.0513501,"Missing"
W12-1602,W03-0705,0,0.0170547,"re-interpretation fails. Instead of re-interpreting the player’s (Julie) input as a request for the next goal, it outputs a request for information about the staff thereby yielding an incoherent exchange. Samir: D’ autres questions ? Other questions? Julie: oui qu’est-ce que je peux faire avec ces bouts de papier ? yes, what can I do with these pieces of paper ? Samir: Et bien sachez qu’il y a de plus en plus des femmes dans cette industrie ... you should know there are more and more women in this industry ... The Dialog Manager We designed a plan for each dialog strategy and extended Midiki (Burke et al., 2003) to support the OAA architecture and access the relational database specifying the configurations of the different dialogs in the game. Each time a new dialog is launched, the information state is loaded with the corresponding dialog-context (e.g., speakers, list of goals to be discussed) and the plan modeling the corresponding dialog strategy. To support dialog management, we implemented a set of update and selection rules for integrating players’ moves, handling the information-state and for preparing the agenda according to the plan. More specifically, the following rules are executed at ru"
W12-1602,J97-1002,0,0.102653,"contains 3609 player utterances consisting of 31613 word tokens and 2969 word types, with approximately 100 conversations for each dialog in the game. Turns were annotated with dialog moves (Traum and Larsson, 2003) capturing both domain knowledge (e.g., about the goals set by the game) and the set of core communicative acts. 2.3 Dialog Strategies We identified four main dialog strategies underlying the 12 MP dialogs and used these to define the plans guiding the rule-based discourse management in the hybrid system. These strategies can be seen as transactions made up of conversational games (Carletta et al., 1997). Strategy 1. This strategy is used in the first dialog only and consists of a single Address Request move by the VC followed by the player’s answer: Lucas requests Ben to find the address of the Plastic Enterprise that must be hidden somewhere in the lab. Ben can accept, reject or ask for help. Lucas answers accordingly and ends the conversation. Strategy 2. Nine dialogues follow this strategy. They include several (up to 5) requests for information and the corresponding system/player’s exchange. Appendix A shows an example dialog following this strategy. Strategy 3: This is a confirmation st"
W12-1602,I11-1150,0,0.0382486,"Missing"
W12-1602,W06-1303,0,0.0319384,"orenzo Universit´e de Lorraine LORIA, UMR 7503 Vandoeuvre-l`es-Nancy F-54500, France Claire Gardent CNRS, LORIA, UMR 7503 Vandoeuvre-l`es-Nancy F-54500, France claire.gardent@loria.fr alejandra.lorenzo@loria.fr Abstract first system (H) is a hybrid approach that combines an information-state dialogue manager (Larsson and Traum, 2000) with a classifier for interpreting the players’ phrases. The second system (QA) is a question/answering character model which predicts the system dialog move given a player’s utterance (Leuski and Traum, 2008). Both systems use a generation-by-selection strategy (Leuski et al., 2006; Gandhe and Traum, 2007) where the system’s utterances are selected from a corpus of possible outputs based on the dialog manager output. While previous work focuses on relatively short dialogs in a static setting, in our systems we consider long interactions in which dialogs occur in a setting that dynamically evolves as the game unfolds. We present and evaluate two state-of-the art dialogue systems developed to support dialog with French speaking virtual characters in the context of a serious game: one hybrid statistical/symbolic and one purely statistical. We conducted a quantitative evalu"
W12-1602,rojas-barahona-etal-2012-building,1,0.492699,"e game goals and the contextual parameters (player’s role, location in the virtual world, VCs present) associated with each dialog. 2.2 Dialog Data and Annotation To train both classifiers, the one used by the hybrid and the one used by the QA system, we collected Human-Machine dialog data using a Wizard-of-Oz setting and manually annotated each turn with a dialog move. The resulting corpus (called Emospeech Corpus) and the annotation scheme (as well as the inter-annotator agreement) used are described in de1 The MP game was created by Artefacto, http://www. artefacto.fr/index_ok.htm 11 tail (Rojas-Barahona et al., 2012). Briefly, the Emospeech Corpus comprises 1249 dialogs, 10454 utterances and 168509 words. It contains 3609 player utterances consisting of 31613 word tokens and 2969 word types, with approximately 100 conversations for each dialog in the game. Turns were annotated with dialog moves (Traum and Larsson, 2003) capturing both domain knowledge (e.g., about the goals set by the game) and the set of core communicative acts. 2.3 Dialog Strategies We identified four main dialog strategies underlying the 12 MP dialogs and used these to define the plans guiding the rule-based discourse management in the"
W12-1602,2007.sigdial-1.15,0,0.0189752,"d evaluation where we examine such criteria as dialog coherence, dialog success, interpretation and generation errors in the corpus of Human-System interactions collected during the user-based evaluation. We show that although the statistical approach is slightly more robust, the hybrid strategy seems to be better at guiding the player through the game. 1 Introduction In recent years, there has been much research on creating situated conversational characters i.e., virtual characters (VCs) that look and act like humans but inhabit a virtual environment (Gratch et al., 2002; Hofs et al., 2010; Traum et al., 2007; Johnson et al., 2005; Traum et al., 2008; DeVault et al., 2011). In this paper, we focus on French speaking, situated conversational agents who interact with virtual characters in the context of a serious game designed to promote careers in the plastic industry (The Mission Plastechnologie game or MP). We present and compare two state-of-the art dialogue systems. The We evaluate the two dialog systems in the context of the 3D game they were developed for and seek to determine the degree to which a dialog system is operational. To answer this question, we analyse both systems with respect not"
W12-1602,W11-2002,0,\N,Missing
W12-2017,W05-0201,0,0.0527675,"Missing"
W12-2017,P06-4001,0,0.120442,"neff, 2007). Mostly, this work targets the automatic generation of so-called objective test items i.e., test items such as multiple choice questions, fill in the blank and cloze exercise items, whose answer is strongly constrained and can therefore be predicted and checked with high accuracy. These approaches use large corpora and machine learning techniques to automatically generate the stems (exercise sentences), the keys (correct an148 swers) and the distractors (incorrect answers) that are required by such test items. Among these approaches, some proposals target grammar exercises. Thus, (Chen et al., 2006) describes a system called FAST which supports the semi-automatic generation of Multiple-Choice and Error Detection exercises while (Aldabe et al., 2006) presents the ArikiTurri automatic question generator for constructing Fill-in-the-Blank, Word Formation, Multiple Choice and Error Detection exercises. These approaches are similar to the approach we propose. First, a bank of sentences is built which are automatically annotated with syntactic and morphosyntactic information. Second, sentences are retrieved from this bank based on their annotation and on the linguistic phenomena the exercise i"
W12-2017,W12-1507,1,0.373825,"un}}, {”lemma”: ”doux”, ”lemma-features”: {num:sg,gen:f,flexion:irreg,cat:adj}, ”trace”: {Epith,EpithPost}} Constructing a Generation bank The generation bank is a database associating sentences with a representation of their semantic content and a detailed description of their syntactic and morphosyntactic properties. In other words, a gen149 eration bank is a set of (Si , Li , σi ) tuples where Si is a sentence, Li is a set of linguistic properties true of that sentence and σi is its semantic representation. To produce these tuples, we use the GraDe grammar traversal algorithm described in (Gardent and Kruszewski, 2012). Given a grammar and a set of user-defined constraints, this algorithm generates sentences licensed by this grammar. The userdefined constraints are either parameters designed to constrain the search space and guarantee termination (e.g., upper-bound on the number and type of recursive rules used or upper-bound on the depth of the tree build by GraDe); or linguistic parameters which permit constraining the output (e.g., by specifying a core semantics the output must verbalise or by requiring the main verb to be of a certain type). Here we use GraDe both to generate from manually specified sem"
W12-2017,W06-1416,0,0.0723948,"Missing"
W12-2017,W05-0210,0,0.0338167,"(Section 2). In Section 3, we present the framework we developed to generate grammar exercises. Section 4 describes the experimental setup we used to generate exercise items. Section 5 reports on an evaluation of the exercise items produced and on the results obtained. Section 6 concludes. 2 Related Work A prominent strand of research in Computer Aided Language Learning (CALL) addresses the automation of exercise specifications relying on Natural Language Processing (NLP) techniques (Mitkov et al., 2006; Heilman and Eskenazi, 2007; Karamanis et al., 2006; Chao-Lin et al., 2005; Coniam, 1997; Sumita et al., 2005; Simon Smith, 2010; Lin et al., 2007; Lee and Seneff, 2007). Mostly, this work targets the automatic generation of so-called objective test items i.e., test items such as multiple choice questions, fill in the blank and cloze exercise items, whose answer is strongly constrained and can therefore be predicted and checked with high accuracy. These approaches use large corpora and machine learning techniques to automatically generate the stems (exercise sentences), the keys (correct an148 swers) and the distractors (incorrect answers) that are required by such test items. Among these approaches,"
W12-2017,W07-2309,0,\N,Missing
W12-4614,P06-4001,0,0.0294718,"sentences are “real life sentences” extracted from an existing corpus. In contrast, we aim at generating textbook style exercices i.e., exercices whose syntax and lexicon are controlled to match the linguistic content already acquired by the learner. Moreover, in computer aided language learning (CALL), much of the work towards generating exercices has focused on so-called objective test items i.e., test items such as multiple choice questions, fill in the blank and cloze exercise items, whose answer is strongly constrained and can therefore be predicted and checked with high accuracy. Thus, (Chen et al., 2006) describes a system called FAST which supports the semiautomatic generation of Multiple-Choice and Error Detection exercises while (Aldabe et al., 2006) presents the ArikiTurri automatic question generator for constructing Fill-in-the-Blank, Word Formation, Multiple Choice and Error Detection exercises. Few studies, however, have been conducted on the generation of transformation based exercices such as illustrated in Figure 1. In this paper, we present an approach for generating transformation exercices such as (1), where the query (Q) is a sentence and the solution (S) is related to the quer"
W12-4614,E03-1030,1,0.791485,"... } β1 -la:{defDet} Figure 3: Derived (top) and Derivation (bottom) Trees for the active voiced sentence C’est Tex qui a fait la tarte (It is Tex who baked the pie) and its passive variant transformationally related sentences. Finally, we present the derivation tree filters used to identify pairs of transformationally related sentences. 3.1 Grammar The grammar used by the surface realiser is called SemTAG. It is a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG, (Vijay-Shanker and Joshi, 1988)) for French augmented with a unification-based compositional semantics as described in (Gardent and Kallmeyer, 2003). Figure 2 shows an example FB-LTAG grammar and the derivation tree associated with the sentence C’est Tammy qui fait la tarte (It is Tammy who bakes a pie). The basic elements of FB-LTAG are called elementary trees. Each elementary tree is labelled with feature structures and is associated with at least one lexical item called the anchor of that tree. Elementary trees are of two types: auxiliary (to model recursion) and initial (to capture predicate/argument dependencies). They are combined using two operations, substitution and adjunction. The result of combining elementary trees together is"
W12-4614,W12-1507,1,0.842027,"s. In contrast, we make use of the derivation trees produced by the GraDe algorithm. Third, while their work is limited to sentences containing relative clauses, we consider a wider range of transformations. Fourth, their approach targets the automatic acquisition of simplification rules while we manually define those. 3 Generating Transformation-related sentences To generate pairs of sentences that are related by a transformation, we proceed in two main steps. First, we construct a generation bank by generating sentences from underspecified semantic representations using the GraDe algorithm (Gardent and Kruszewski, 2012). This generation bank stores sentences that have been generated using GraDe together with the detailed linguistic information associated by this algorithm with each sentence in particular, its derivation tree. Second, filters are used to retrieve from the generation bank sentence pairs that provide the query and the solution to a given transformation type exercise. These filters are defined on derivation trees and make use of the rich linguistic information associated by our generator with those derivation trees. In what follows, we start by describing the grammar used and the information con"
W12-4614,W12-2017,1,0.818856,"exas.edu/tex/ is an online pedagogical reference grammar which is arranged like many other traditional reference grammars with the parts of speech (nouns, verbs, etc.) used to categorize specific grammar items (gender of nouns, irregular verbs). Individual grammar items are explained in English, exemplified in a dialogue, and finally tested in self-correcting, fill-in-the-blank exercises. Laura Perez-Beltrachini Universit´e de Lorraine/LORIA Nancy, France Laura.Perez@loria.fr learner with exercises made up of short sentences involving a simple syntax and a restricted vocabulary. As argued in (Perez-Beltrachini et al., 2012), most existing work on the generation of grammar exercises has concentrated on the automatic creation of exercises whose source sentences are “real life sentences” extracted from an existing corpus. In contrast, we aim at generating textbook style exercices i.e., exercices whose syntax and lexicon are controlled to match the linguistic content already acquired by the learner. Moreover, in computer aided language learning (CALL), much of the work towards generating exercices has focused on so-called objective test items i.e., test items such as multiple choice questions, fill in the blank and"
W12-4614,W10-4213,0,0.0996714,"ransformations (Harris, 1957; Chomsky, 1957) model recurrent linguistic relations between sentence pairs. For instance, a transformation can be used to define the relation between the active and the passive voice version of the same sentence. Formally, transformations were stated as tree-transducers on phrase structure trees and they defined either structure changing or structure building (generalised transformation) operations. In computational linguistics, transformations and more generally, structure changing and structure building rules have been used in such tasks as text simplification (Siddharthan, 2010), text summarising (Cohn and Lapata, 2009) and question generation (Piwek and Boyer, 2012). In these approaches however, the transformation relation is not necessarily defined on phrase structure trees. For instance, for the question generation task, (Yao et al., 2012) has argued that Assertion/WHQuestion transformations are best defined on semantic representations. Conversely, for text simplification, (Siddharthan, 2010) has convincingly shown that dependency trees are better suited as a representation on which to define text simplification rules than both phrase structure trees and semantic"
W12-4614,W11-2802,0,0.0226528,"(Cohn and Lapata, 2009) and question generation (Piwek and Boyer, 2012). In these approaches however, the transformation relation is not necessarily defined on phrase structure trees. For instance, for the question generation task, (Yao et al., 2012) has argued that Assertion/WHQuestion transformations are best defined on semantic representations. Conversely, for text simplification, (Siddharthan, 2010) has convincingly shown that dependency trees are better suited as a representation on which to define text simplification rules than both phrase structure trees and semantic representations. (Siddharthan, 2011) presents a user evaluation comparing different re-generation approaches for sentence simplification. He notes in particular that annotators preferred those transformations that are closer in syntax to the original sentence. To achieve this, rules for word ordering are either added to the transform rules or coded as constraints within the input to a generator. In contrast, in our approach, syntactic similarity can be deduced by tree comparison using the rich linguistic information associated by the generator with the FB-LTAG derivation trees. (Chandrasekar and Srinivas, 1997) describes an algo"
W12-4614,C88-2147,0,0.567956,"V e´ t´e faite α2 -faire:{Passive,CleftAgent,CanSubj} α1 -tex:{ ... } β1 -la:{defDet} α5 -avoir:{TenseAux} α3 -tarte:{ ... } β1 -la:{defDet} Figure 3: Derived (top) and Derivation (bottom) Trees for the active voiced sentence C’est Tex qui a fait la tarte (It is Tex who baked the pie) and its passive variant transformationally related sentences. Finally, we present the derivation tree filters used to identify pairs of transformationally related sentences. 3.1 Grammar The grammar used by the surface realiser is called SemTAG. It is a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG, (Vijay-Shanker and Joshi, 1988)) for French augmented with a unification-based compositional semantics as described in (Gardent and Kallmeyer, 2003). Figure 2 shows an example FB-LTAG grammar and the derivation tree associated with the sentence C’est Tammy qui fait la tarte (It is Tammy who bakes a pie). The basic elements of FB-LTAG are called elementary trees. Each elementary tree is labelled with feature structures and is associated with at least one lexical item called the anchor of that tree. Elementary trees are of two types: auxiliary (to model recursion) and initial (to capture predicate/argument dependencies). They"
W13-2105,W04-3315,0,0.0851368,"Missing"
W13-2105,W11-2832,0,0.157824,"Missing"
W13-2105,P06-1130,0,0.060315,"Missing"
W13-2105,I05-1015,0,0.0675771,"Missing"
W13-2105,cmejrek-etal-2004-prague,0,0.030845,"Missing"
W13-2105,W09-0624,0,0.0167668,"tion, right node raising, gapping and stripping and uses dependency trees connected by rhetorical relations as input. Before these trees are mapped to sentences, repeated elements are deleted and their antecedent (thesource element) is related by a SUBORROWED relation to their governor in the elliptic clause and a SUIDENTICAL relation to their governor in the antecedent clause. This is then interpreted by the surface realiser to mean that the repeated element should be realised in the source clause, elided in the target clause and that it licenses the same syntactic structure in both clauses. Harbusch and Kempen (2009) have proposed a module called Elleipo which takes as input unreduced, non-elliptic, syntactic structures annotated with lexical identity and coreference relationships Analysing the remaining failure cases. To better assess the extent to which rewriting and the FBLTAG generation system succeed in generating elliptic coordinations, we performed error mining on the elliptic data using our error miner described in (Narayan and Gardent, 2012a). This method permits highlighting the most likely sources of error given two datasets: a set of successful cases and a set of failure cases. In this case, t"
W13-2105,W07-2416,0,0.0212058,"using functions. For instance, if the remnant is parallel to the source subject, it will be labelled GAP - SBJ (cf. Figure 3). commission SBJ COORD OBJ 4 Rewriting the SR Data He The SR Task 2011 made available two types of data for surface realisers to be tested on: shallow dependency trees and deep dependency graphs. Here we focus on the shallow dependency trees i.e., on syntactic structures. The input data provided by the SR Task were obtained from the Penn Treebank. They were derived indirectly from the LTH Constituent-toDependency Conversion Tool for Penn-style Treebanks (Pennconverter, (Johansson and Nugues, 2007)) by post-processing the CoNLL data to reand fearsome contemporary score CONJ splendidly interpret Figure 4: Subject Sharing and RNR in the SR data. “[He]j ǫj commissions ǫi and ǫj splendidly interprets ǫi [fearsome contemporary scores]i .” For right-node raising and shared subjects, the coindexation present in the PTB is dropped in the SR data. As a result, the SR representation under42 specifies the relation between the object and the coordinated verbs in RNR constructions: the object could be shared as in He commissions ǫi and splendidly interprets ǫi [fearsome contemporary scores]i . (Figu"
W13-2105,daum-etal-2004-automatic,0,0.0162925,"sed here because they can be handled by the generator by having the appropriate categories in the grammar and the lexicon e.g., in a Tree Adjoining Grammar, an auxiliary anchoring a verb phrase for VP ellipsis and question words anchoring a sentence for sluicing. Figure 2: Penn Treebank annotation for gapping “Mary [likes]i potatoes and Bill ǫi ostriches.” In dependency treebanks, headless elliptic constructs such as gapping additionally raise the is41 sue of how to represent the daughters of an empty head. Three main types of approaches have been proposed. In dependency treebanks for German (Daum et al., 2004; Hajiˇc et al., 2009) and in ˇ the Czech treebank (Cmejrek et al., 2004; Hajiˇc et al., 2009), one of the dependents of the headless phrase is declared to be the head. This is a rather undesirable solution because it hides the fact that there the clause lacks a head. In contrast, the Hungarian dependency treebank (Vincze et al., 2010) explicitly represents the elided elements in the trees by introducing phonetically empty elements that serve as attachment points to other tokens. This is the cleanest solution from a linguistic point of view. Similarly, Seeker and Kuhn (2012) present a conversi"
W13-2105,W11-2912,0,0.0407452,"Missing"
W13-2105,W02-2103,0,0.13379,"Missing"
W13-2105,W12-3624,0,0.0376725,"Missing"
W13-2105,W08-1105,0,0.0731873,"Missing"
W13-2105,A94-1002,0,0.239077,"elated work Previous work on generating elliptic sentences has mostly focused on identifying material that could be elided and on defining procedures capable of producing input structures for surface realisation that support the generation of elliptic sentences. Shaw (1998) developed a sentence planner which generates elliptic sentences in 3 steps. First, input data are grouped according to their similarities. Second, repeated elements are marked. Third, constraints are used to determine which occurrences of a marked element should be deleted. The approach is integrated in the PLANDoc system (McKeown et al., 1994) and shown to generate a wide range of elliptic constructs including RNR, VPE and NCC using FUF/SURGE (Elhadad, 1993), a realisation component based on Functional Unification Grammar. Theune et al. (2006) describe how elliptic sentences are generated in a story generation system. The approach covers conjunction reduction, right node raising, gapping and stripping and uses dependency trees connected by rhetorical relations as input. Before these trees are mapped to sentences, repeated elements are deleted and their antecedent (thesource element) is related by a SUBORROWED relation to their gove"
W13-2105,C12-1123,1,0.543286,"to map sounds onto their corresponding meanings, break down. For instance, in the sentence John eats apples and Mary pear, the Subject-Verb-Object structure which can be used in English to express a binary relation is present in the source clause but not in the elided one. In practice, the syntax of elliptical sentences often leads to a duplication of the grammatical system, one system allowing for non elliptical sentences and the other for their elided counterpart. 5 Generating Elliptic Coordination 5.1 The Surface Realiser To generate sentences from the SR data, we use our surface realiser (Narayan and Gardent, 2012b), a grammar-based generator based on a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG) for English. This generator first selects the elementary FB-LTAG trees associated in the lexicon with the lemmas and part of speech tags associated with each node in the input dependency tree. It then attempts to combine the selected trees bottom-up taking into account the structure of the input tree (only trees that are selected by nodes belonging to the same local input tree are tried for combination). A language model is used to implement a beam search letting through only the n most likely p"
W13-2105,W09-1201,0,0.0499899,"Missing"
W13-2105,C12-1124,1,0.929044,"to map sounds onto their corresponding meanings, break down. For instance, in the sentence John eats apples and Mary pear, the Subject-Verb-Object structure which can be used in English to express a binary relation is present in the source clause but not in the elided one. In practice, the syntax of elliptical sentences often leads to a duplication of the grammatical system, one system allowing for non elliptical sentences and the other for their elided counterpart. 5 Generating Elliptic Coordination 5.1 The Surface Realiser To generate sentences from the SR data, we use our surface realiser (Narayan and Gardent, 2012b), a grammar-based generator based on a Feature-Based Lexicalised Tree Adjoining Grammar (FB-LTAG) for English. This generator first selects the elementary FB-LTAG trees associated in the lexicon with the lemmas and part of speech tags associated with each node in the input dependency tree. It then attempts to combine the selected trees bottom-up taking into account the structure of the input tree (only trees that are selected by nodes belonging to the same local input tree are tried for combination). A language model is used to implement a beam search letting through only the n most likely p"
W13-2105,C96-2103,0,0.282891,"Missing"
W13-2105,W08-2311,0,0.0156757,"he structure of the input tree (only trees that are selected by nodes belonging to the same local input tree are tried for combination). A language model is used to implement a beam search letting through only the n most likely phrases at each bottom up combination step. In this experiment, we set n to 5. The generator thus outputs at most 5 sentences for each input. For parsing with TAG, two main methods have been proposed for processing elliptical sentences. (Sarkar and Joshi, 1996) introduces an additional operation for combining TAG trees which yields derivation graphs rather than trees. (Seddah, 2008) uses Multi-Component TAG and proposes to associate each elementary verb tree with an elliptic tree with different pairs representing different types of ellipses. We could use either of these approaches for generation. The first approach however has the drawback that it leads to a non standard notion of derivation (the derivation trees become derivation graphs). The second on the other hand, induces a proliferation of trees in the grammar and impacts efficiency. Instead, we show that, given an input enriched with empty categories as proposed in the previous section, neither the grammar nor the"
W13-2105,seeker-kuhn-2012-making,0,0.0154984,"y treebanks for German (Daum et al., 2004; Hajiˇc et al., 2009) and in ˇ the Czech treebank (Cmejrek et al., 2004; Hajiˇc et al., 2009), one of the dependents of the headless phrase is declared to be the head. This is a rather undesirable solution because it hides the fact that there the clause lacks a head. In contrast, the Hungarian dependency treebank (Vincze et al., 2010) explicitly represents the elided elements in the trees by introducing phonetically empty elements that serve as attachment points to other tokens. This is the cleanest solution from a linguistic point of view. Similarly, Seeker and Kuhn (2012) present a conversion of the German Tiger treebank which introduces empty nodes for verb ellipses if a phrase normally headed by a verb is lacking a head. They compare the performance of two statistical dependency parsers on the canonical version and the CoNLL 2009 Shared Task data and show that the converted dependency treebank they propose yields better parsing results than the treebank not containing empty heads. In sum, while some linguists have argued for an approach where ellipsis has no syntactic representation, many have provided strong empirical evidence for positing empty nodes as pl"
W13-2105,P98-2199,0,0.0462157,"overall increase of 0.09 points on the set of elliptic sentences. Moreover, the consistent improvement in terms of BLEU score for generated sentences (COV column) shows that rewriting simultaneously improves both coverage and precision that is, that for those sentences that are generated, rewriting consistently improves precision. 6 Related work Previous work on generating elliptic sentences has mostly focused on identifying material that could be elided and on defining procedures capable of producing input structures for surface realisation that support the generation of elliptic sentences. Shaw (1998) developed a sentence planner which generates elliptic sentences in 3 steps. First, input data are grouped according to their similarities. Second, repeated elements are marked. Third, constraints are used to determine which occurrences of a marked element should be deleted. The approach is integrated in the PLANDoc system (McKeown et al., 1994) and shown to generate a wide range of elliptic constructs including RNR, VPE and NCC using FUF/SURGE (Elhadad, 1993), a realisation component based on Functional Unification Grammar. Theune et al. (2006) describe how elliptic sentences are generated in"
W13-2105,vincze-etal-2010-hungarian,0,0.0661275,"Missing"
W13-2105,D09-1043,0,0.0645666,"Missing"
W13-2105,J03-4003,0,\N,Missing
W13-2105,C98-2194,0,\N,Missing
W13-2105,W04-3316,0,\N,Missing
W13-2111,W12-1526,1,0.785567,"1). As part of the encoding process, concepts in CLIB are specialized and/or combined to encode biology-specific information. AURA is organized into a set of concept maps, where each concept map corresponds to a biological entity or process. The KB was encoded by biology teachers and contains around 5,000 concept maps. It is available for download for academic purposes in various formats including OWL2 . The KBGen 2013 natural language generation challenge1 was intended to survey and compare the performance of various systems which perform tasks in the content realization stage of generation (Banik et al., 2012). Given a set of relations which form a coherent unit, the task is to generate complex sentences which are grammatical and fluent in English. The relations for this year’s challenge were selected from the AURA knowledge base (KB) (Gunning et al., 2010). In this paper we give an overview of the KB, describe our methodology for selecting sets of relations from the KB to provide input-output pairs for the challenge, and give details of the development and test data set that was provided to participating teams. Three teams have submitted system outputs for this year’s challenge. In this paper we s"
W13-2131,C08-1032,1,\N,Missing
W13-4056,W12-2017,1,0.799126,"tion Q X. S defines the system, and P the learner. 4 In the guided dialogue system, the dialogue paths contained in the training corpus are used to decide on the next dialogue move. In a first step, learner’s moves are labelled with the meaning representation associated to them by the grammar underlying the natural language generator used to produce IFLEG grammar exercises. Given a sequence S/L contained in the training corpus with S, a system turn and L the corresponding learner’s turn, the system then constructs the exercise providing the learner’s answer using the methodology described in (Perez-Beltrachini et al., 2012). First, a sentence is generated from the meaning representation of the learner answer. Next, the linguistic information (syntactic tree, morpho-syntactic information, lemmas) associated by the generator with the generated sentence is used to build a shuffle, a fill-in-the-blank or a transformation exercise. Here is an example interaction produced by the system : Sample Dialogue In this demo, the user will be able to interact with both dialogue systems, situated in the kitchen of a virtual world, and where the tutor prompts the learner with questions about meals, drinks, and various kitchen re"
W13-4056,rojas-barahona-etal-2012-building,1,0.880286,"Missing"
W13-4056,W12-1602,1,0.925658,"wer is guided only by the preceding dialog exchanges ; and a “guided dialog system” which restricts the set of permissible answers by providing the learner with an exercise whose solution provides a possible answer given the current dialog context. 3.1 Data collection To provide the training data necessary to train the free dialog system, we conducted a Wizardof-Oz experiment where language learners were invited to engage in a conversation with the wizard, a French tutor. In these experiments, we followed the methodology and used the tools for data collection and annotation presented in (RojasBarahona et al., 2012a). Given an FSA specifiying a set of 5 questions the learner had to answer, the wizard guided the learner through the dialog using this FSA. The resulting corpus consists of 52 dialogues and 1906 sentences. 3.2 Free answer Dialogue System The free answer dialogue system simulates the behavior of the wizard tutor by means of a Logistic-Regression classifier, the FSA and a generation-by-selection algorithm. The system first uses the FSA to determine the next question to be asked. Then for each question, the LogisticRegression classifier is used to map the learner answer to a system dialog act."
W15-4703,A97-1052,0,0.0304937,"pping between syntactic and semantic arguments. That is, probabilities are used to determine which event argument fills which syntactic function (e.g., subject, object) in the produced verbalisation. We start by giving a brief overview of the content and the structure of KB B IO 101(Section 3.1). We then describe the steps involved in building our generation system. Related to the work discussed in this paper is the task of learning subcategorization information from textual corpora. Automatic methods for subcategorization frame acquisition have been proposed from general text corpora, e.g., (Briscoe and Carroll, 1997), (Korhonen, 2002), (Sarkar and Zeman, 2000) and specific biomedical domain corpora as well (Rimell et al., 2013). Such works are limited to the extraction of syntactic frames representing subcategorization information. Instead, we focus on relating the syntactic and semantic frame and, in particular, on the linking between syntactic and semantic arguments. Another trend of work relevant to this paper is generation from databases using parallel corpora of data and text. (Angeli et al., 2010) train a sequence of discriminative models to predict data selection, ordering and realisation. (Wong an"
W15-4703,W13-2132,0,0.017323,"ject1 has focused on pro1 http://crc.open.ac.uk/Projects/SWAT Proceedings of the 15th European Workshop on Natural Language Generation (ENLG), pages 18–27, c Brighton, September 2015. 2015 Association for Computational Linguistics 18 ducing descriptions of ontologies that are both coherent and efficient (Williams and Power, 2010). In these approaches, the mapping between relations and verbs is determined either manually or through string matching and KB relations are assumed to map to binary verbs. and of the associated text. Various systems from the KBG EN shared task (Banik et al., 2013) – (Butler et al., 2013), (Gyawali and Gardent, 2013) and (Zarrieβ and Richardson, 2013) perform generation from the same input data source as ours’ and use parallel text for supervision. Our approach differs from all these approaches in that it does not require parallel text/data corpora. Also in contrast to the template extraction approaches described in (Kondadadi et al., 2013), (Ell and Harth, 2014) and (Duma and Klein, 2013), we do not succeed in directly matching the input data to surface text in the sentences obtained from non-parallel biomedical texts. Instead, we must extract the subcategorization frame and"
W15-4703,H94-1010,0,0.145493,"ons, provide a qualitative and quantitative analysis of the results obtained and discuss possible directions for further work. 1 Introduction While earlier work on data-to-text generation heavily relied on handcrafted linguistic resources, more recent data-driven approaches have focused on learning a generation system from parallel corpora of data and text. Thus, (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) trained and developed data-to-text generators on datasets from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). In both cases, considerable time and expertise must be spent on developing the required linguistic resources. In the handcrafted, symbolic approach, appropriate grammars and lexicons must be specified while in the parallel corpus based learning approach, an aligned data-text corpus must be built for each new domain. Here, we explore an alternative approach using non-parallel corpora for surface realisation from knowledge bases that can be used for any knowledge base for which there exists large text"
W15-4703,W13-0108,0,0.0315483,"either manually or through string matching and KB relations are assumed to map to binary verbs. and of the associated text. Various systems from the KBG EN shared task (Banik et al., 2013) – (Butler et al., 2013), (Gyawali and Gardent, 2013) and (Zarrieβ and Richardson, 2013) perform generation from the same input data source as ours’ and use parallel text for supervision. Our approach differs from all these approaches in that it does not require parallel text/data corpora. Also in contrast to the template extraction approaches described in (Kondadadi et al., 2013), (Ell and Harth, 2014) and (Duma and Klein, 2013), we do not succeed in directly matching the input data to surface text in the sentences obtained from non-parallel biomedical texts. Instead, we must extract the subcategorization frame and learn the linking between semantic and syntactic arguments. More complex NLG systems have also been developed to generate text (rather than simple sentences) from knowledge bases. Thus, the MIAKT project (Bontcheva and Wilks., 2004) and the ONTOGENERATION project (Aguado et al., 1998) use symbolic NLG techniques to produce textual descriptions from some semantic information contained in a knowledge base. B"
W15-4703,E09-2005,0,0.0322802,"hniques to produce textual descriptions from some semantic information contained in a knowledge base. Both systems require some manual input (lexicons and domain schemas). More sophisticated NLG systems such as TAILOR (Paris, 1988), MIGRAINE (Mittal et al., 1994), and STOP (Reiter et al., 2003) offer tailored output based on user/patient models. While offering more flexibility and expressiveness, these systems are difficult to adapt by non-NLG experts because they require the user to understand the architecture of the NLG systems (Bontcheva and Wilks., 2004). Similarly, the NaturalOWL system (Galanis et al., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. These approaches however rely on extensive manual annotation of the input data. 3 Methodology Our goal is to automatically generate natural language verbalisations of the biological event descriptions encoded in KB B IO 101 (Chaudhri et al., 2013) whereby an event description is assumed to consist of an event, its arguments and the roles relating each argument to the event. In the KB B IO 101 knowledge base, events are concepts of type E VENT (e.g., R ELEASE), arguments are concepts of type E NTITY (e.g"
W15-4703,J88-3006,0,0.529233,"biomedical texts. Instead, we must extract the subcategorization frame and learn the linking between semantic and syntactic arguments. More complex NLG systems have also been developed to generate text (rather than simple sentences) from knowledge bases. Thus, the MIAKT project (Bontcheva and Wilks., 2004) and the ONTOGENERATION project (Aguado et al., 1998) use symbolic NLG techniques to produce textual descriptions from some semantic information contained in a knowledge base. Both systems require some manual input (lexicons and domain schemas). More sophisticated NLG systems such as TAILOR (Paris, 1988), MIGRAINE (Mittal et al., 1994), and STOP (Reiter et al., 2003) offer tailored output based on user/patient models. While offering more flexibility and expressiveness, these systems are difficult to adapt by non-NLG experts because they require the user to understand the architecture of the NLG systems (Bontcheva and Wilks., 2004). Similarly, the NaturalOWL system (Galanis et al., 2009) has been proposed to generate fluent descriptions of museum exhibits from an OWL ontology. These approaches however rely on extensive manual annotation of the input data. 3 Methodology Our goal is to automatic"
W15-4703,W13-2131,1,0.822638,"o1 http://crc.open.ac.uk/Projects/SWAT Proceedings of the 15th European Workshop on Natural Language Generation (ENLG), pages 18–27, c Brighton, September 2015. 2015 Association for Computational Linguistics 18 ducing descriptions of ontologies that are both coherent and efficient (Williams and Power, 2010). In these approaches, the mapping between relations and verbs is determined either manually or through string matching and KB relations are assumed to map to binary verbs. and of the associated text. Various systems from the KBG EN shared task (Banik et al., 2013) – (Butler et al., 2013), (Gyawali and Gardent, 2013) and (Zarrieβ and Richardson, 2013) perform generation from the same input data source as ours’ and use parallel text for supervision. Our approach differs from all these approaches in that it does not require parallel text/data corpora. Also in contrast to the template extraction approaches described in (Kondadadi et al., 2013), (Ell and Harth, 2014) and (Duma and Klein, 2013), we do not succeed in directly matching the input data to surface text in the sentences obtained from non-parallel biomedical texts. Instead, we must extract the subcategorization frame and learn the linking between sem"
W15-4703,C00-2100,0,0.0304221,"That is, probabilities are used to determine which event argument fills which syntactic function (e.g., subject, object) in the produced verbalisation. We start by giving a brief overview of the content and the structure of KB B IO 101(Section 3.1). We then describe the steps involved in building our generation system. Related to the work discussed in this paper is the task of learning subcategorization information from textual corpora. Automatic methods for subcategorization frame acquisition have been proposed from general text corpora, e.g., (Briscoe and Carroll, 1997), (Korhonen, 2002), (Sarkar and Zeman, 2000) and specific biomedical domain corpora as well (Rimell et al., 2013). Such works are limited to the extraction of syntactic frames representing subcategorization information. Instead, we focus on relating the syntactic and semantic frame and, in particular, on the linking between syntactic and semantic arguments. Another trend of work relevant to this paper is generation from databases using parallel corpora of data and text. (Angeli et al., 2010) train a sequence of discriminative models to predict data selection, ordering and realisation. (Wong and Mooney, 2007) uses techniques from statist"
W15-4703,P13-1138,0,0.0129198,"e mapping between relations and verbs is determined either manually or through string matching and KB relations are assumed to map to binary verbs. and of the associated text. Various systems from the KBG EN shared task (Banik et al., 2013) – (Butler et al., 2013), (Gyawali and Gardent, 2013) and (Zarrieβ and Richardson, 2013) perform generation from the same input data source as ours’ and use parallel text for supervision. Our approach differs from all these approaches in that it does not require parallel text/data corpora. Also in contrast to the template extraction approaches described in (Kondadadi et al., 2013), (Ell and Harth, 2014) and (Duma and Klein, 2013), we do not succeed in directly matching the input data to surface text in the sentences obtained from non-parallel biomedical texts. Instead, we must extract the subcategorization frame and learn the linking between semantic and syntactic arguments. More complex NLG systems have also been developed to generate text (rather than simple sentences) from knowledge bases. Thus, the MIAKT project (Bontcheva and Wilks., 2004) and the ONTOGENERATION project (Aguado et al., 1998) use symbolic NLG techniques to produce textual descriptions from some sem"
W15-4703,P12-1039,0,0.065062,"for automatically generating descriptions of biological events encoded in the KB B IO 101 Knowledge base. We evaluate our approach on a corpus of 336 event descriptions, provide a qualitative and quantitative analysis of the results obtained and discuss possible directions for further work. 1 Introduction While earlier work on data-to-text generation heavily relied on handcrafted linguistic resources, more recent data-driven approaches have focused on learning a generation system from parallel corpora of data and text. Thus, (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) trained and developed data-to-text generators on datasets from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). In both cases, considerable time and expertise must be spent on developing the required linguistic resources. In the handcrafted, symbolic approach, appropriate grammars and lexicons must be specified while in the parallel corpus based learning approach, an aligned data-text corpus must be built for each new domain. Here, we explore an altern"
W15-4703,N12-1093,0,0.0912774,"for automatically generating descriptions of biological events encoded in the KB B IO 101 Knowledge base. We evaluate our approach on a corpus of 336 event descriptions, provide a qualitative and quantitative analysis of the results obtained and discuss possible directions for further work. 1 Introduction While earlier work on data-to-text generation heavily relied on handcrafted linguistic resources, more recent data-driven approaches have focused on learning a generation system from parallel corpora of data and text. Thus, (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) trained and developed data-to-text generators on datasets from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). In both cases, considerable time and expertise must be spent on developing the required linguistic resources. In the handcrafted, symbolic approach, appropriate grammars and lexicons must be specified while in the parallel corpus based learning approach, an aligned data-text corpus must be built for each new domain. Here, we explore an altern"
W15-4703,W10-4222,0,0.0221397,"the Prot´eg´e tool is a CNL based generation tool, (Kaljurand and Fuchs, 2007) which provides a verbalisation of every axiom present in the ontology under consideration. Similarly, (Wilcock, 2003) describes an ontology verbaliser using XML-based generation. Finally, recent work by the SWAT project1 has focused on pro1 http://crc.open.ac.uk/Projects/SWAT Proceedings of the 15th European Workshop on Natural Language Generation (ENLG), pages 18–27, c Brighton, September 2015. 2015 Association for Computational Linguistics 18 ducing descriptions of ontologies that are both coherent and efficient (Williams and Power, 2010). In these approaches, the mapping between relations and verbs is determined either manually or through string matching and KB relations are assumed to map to binary verbs. and of the associated text. Various systems from the KBG EN shared task (Banik et al., 2013) – (Butler et al., 2013), (Gyawali and Gardent, 2013) and (Zarrieβ and Richardson, 2013) perform generation from the same input data source as ours’ and use parallel text for supervision. Our approach differs from all these approaches in that it does not require parallel text/data corpora. Also in contrast to the template extraction"
W15-4703,W02-0907,0,0.0237317,"emantic arguments. That is, probabilities are used to determine which event argument fills which syntactic function (e.g., subject, object) in the produced verbalisation. We start by giving a brief overview of the content and the structure of KB B IO 101(Section 3.1). We then describe the steps involved in building our generation system. Related to the work discussed in this paper is the task of learning subcategorization information from textual corpora. Automatic methods for subcategorization frame acquisition have been proposed from general text corpora, e.g., (Briscoe and Carroll, 1997), (Korhonen, 2002), (Sarkar and Zeman, 2000) and specific biomedical domain corpora as well (Rimell et al., 2013). Such works are limited to the extraction of syntactic frames representing subcategorization information. Instead, we focus on relating the syntactic and semantic frame and, in particular, on the linking between syntactic and semantic arguments. Another trend of work relevant to this paper is generation from databases using parallel corpora of data and text. (Angeli et al., 2010) train a sequence of discriminative models to predict data selection, ordering and realisation. (Wong and Mooney, 2007) us"
W15-4703,N07-1022,0,0.232815,"es. We present a method for automatically generating descriptions of biological events encoded in the KB B IO 101 Knowledge base. We evaluate our approach on a corpus of 336 event descriptions, provide a qualitative and quantitative analysis of the results obtained and discuss possible directions for further work. 1 Introduction While earlier work on data-to-text generation heavily relied on handcrafted linguistic resources, more recent data-driven approaches have focused on learning a generation system from parallel corpora of data and text. Thus, (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) trained and developed data-to-text generators on datasets from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). In both cases, considerable time and expertise must be spent on developing the required linguistic resources. In the handcrafted, symbolic approach, appropriate grammars and lexicons must be specified while in the parallel corpus based learning approach, an aligned data-text corpus must be built for each new domain."
W15-4703,P09-1011,0,0.0378529,"tive analysis of the results obtained and discuss possible directions for further work. 1 Introduction While earlier work on data-to-text generation heavily relied on handcrafted linguistic resources, more recent data-driven approaches have focused on learning a generation system from parallel corpora of data and text. Thus, (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) trained and developed data-to-text generators on datasets from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). In both cases, considerable time and expertise must be spent on developing the required linguistic resources. In the handcrafted, symbolic approach, appropriate grammars and lexicons must be specified while in the parallel corpus based learning approach, an aligned data-text corpus must be built for each new domain. Here, we explore an alternative approach using non-parallel corpora for surface realisation from knowledge bases that can be used for any knowledge base for which there exists large textual corpora. A more specific, linguisti"
W15-4703,W13-2130,0,0.0236692,"s/SWAT Proceedings of the 15th European Workshop on Natural Language Generation (ENLG), pages 18–27, c Brighton, September 2015. 2015 Association for Computational Linguistics 18 ducing descriptions of ontologies that are both coherent and efficient (Williams and Power, 2010). In these approaches, the mapping between relations and verbs is determined either manually or through string matching and KB relations are assumed to map to binary verbs. and of the associated text. Various systems from the KBG EN shared task (Banik et al., 2013) – (Butler et al., 2013), (Gyawali and Gardent, 2013) and (Zarrieβ and Richardson, 2013) perform generation from the same input data source as ours’ and use parallel text for supervision. Our approach differs from all these approaches in that it does not require parallel text/data corpora. Also in contrast to the template extraction approaches described in (Kondadadi et al., 2013), (Ell and Harth, 2014) and (Duma and Klein, 2013), we do not succeed in directly matching the input data to surface text in the sentences obtained from non-parallel biomedical texts. Instead, we must extract the subcategorization frame and learn the linking between semantic and syntactic arguments. More"
W15-4703,W13-2111,1,\N,Missing
W15-4703,D10-1049,0,\N,Missing
W16-3505,D15-1219,0,0.0231411,"sentence mapping to check whether it was appropriate for identifying important information. The results obtained good performance, thus indicating that we can rely on the 2 Related Work Abstractive summarisation is one of the most challenging issues to address automatically, since it both requires deep language understanding and generation with a strong semantic component. For tackling this task, approaches usually need to define an internal representation of the text, that can be in the form of SVO triples (Genest and Lapalme, 2011), basic semantic units consisting of actor-action-receiver (Li, 2015), or using predarg structures (Khan et al., 2015). In this latter work, pred-arg structures extracted from different related documents are compared, so that common or redundant information can be grouped into clusters. For computing a similarity matrix, Wordnet1 based similarity metrics are used, mainly relying on the semantic distance between concepts, given Wordnets’ hierarchy. On the other hand, previous works on linguistic structure mapping can be related to paraphrase identification (Fernando and Stevenson, 2008; Xu et al., 2015), as well as to pred-arg alignment (Wolfe et al., 2015; Roth"
W16-3505,W04-1013,0,0.00549554,"e consists of more than one element, we will compute the final vector as the composition of the WEs of each of the elements it contains. This is a common strategy that has been previously adopted, in which the addition or product normally lead to the best results (Mitchell and Lapata, 2008; Blacoe and Lapata, 2012; K˚ageb¨ack et al., 2014). Finally, the aim of the third stage is to define a similarity metric between the vectors obtained in the second stage. 4 5 Evaluation and Discussion We addressed the validation of the source document-abstract pairs mapping as an extrinsic task using ROUGE (Lin, 2004). ROUGE is a wellknown tool employed for summarisation evaluation, which computes the n-gram overlapping between an automatic and a reference summary in terms of n-grams (unigrams - ROUGE 1; bigrams - ROUGE 2, etc.). Our assumption behind this type of evaluation was that considering the Dataset and Approach Configuration The English training collection of documents and abstracts from the Single document Summarization task (MSS)4 of the MultiLing2015 was used as corpus. It consisted of 30 Wikipedia documents from heterogeneous topics (e.g., history of Texas University, fauna of Australia, or Ma"
W16-3505,P08-1028,0,0.160377,"Missing"
W16-3505,D14-1162,0,0.0753165,"Missing"
W16-3505,D12-1050,0,0.0756165,"Missing"
W16-3505,J15-4003,0,0.0223514,"015), or using predarg structures (Khan et al., 2015). In this latter work, pred-arg structures extracted from different related documents are compared, so that common or redundant information can be grouped into clusters. For computing a similarity matrix, Wordnet1 based similarity metrics are used, mainly relying on the semantic distance between concepts, given Wordnets’ hierarchy. On the other hand, previous works on linguistic structure mapping can be related to paraphrase identification (Fernando and Stevenson, 2008; Xu et al., 2015), as well as to pred-arg alignment (Wolfe et al., 2015; Roth and Frank, 2015). However, these works only use semantic similarity metrics based on WordNet or other semantic resources, such as ConceptNet2 or FrameNet3 . 1 https://wordnet.princeton.edu/ http://conceptnet5.media.mit.edu/ 3 https://framenet.icsi.berkeley.edu/fndrupal/ 2 Proceedings of the 2nd International Workshop on Natural Language Generation and the Semantic Web (WebNLG), pages 25–28, c Edinburgh, Scotland, September 6th, 2016. 2016 Association for Computational Linguistics 25 The use of continuous semantic representation, and in particular the learning or use of Word Embeddings (WE) has been shown to b"
W16-3505,P10-1040,0,0.0231691,"t2 or FrameNet3 . 1 https://wordnet.princeton.edu/ http://conceptnet5.media.mit.edu/ 3 https://framenet.icsi.berkeley.edu/fndrupal/ 2 Proceedings of the 2nd International Workshop on Natural Language Generation and the Semantic Web (WebNLG), pages 25–28, c Edinburgh, Scotland, September 6th, 2016. 2016 Association for Computational Linguistics 25 The use of continuous semantic representation, and in particular the learning or use of Word Embeddings (WE) has been shown to be more appropriate and powerful approach for representing linguistic elements (words, sentences, paragraphs or documents) (Turian et al., 2010; Dai et al., 2015). Given its good performance, they have been recently applied to many natural language generation tasks (Collobert et al., 2011; K˚ageb¨ack et al., 2014). The work presented in (Perez-Beltrachini and Gardent, 2016) proposes a method to learn embeddings to lexicalise RDF properties, showing also the potential of using this type of representation for the Semantic Web. 3 page. Documents were rather long, having 3,972 words on average (the longest document had 8,348 words and the shortest 2,091), whereas abstracts were 274 words on average (the maximum value was 305 words and th"
W16-3505,N15-1002,0,0.0500655,"Missing"
W16-3505,W11-1608,0,0.0267479,"embeddings. Our approach was tested and validated in the context of document-abstract sentence mapping to check whether it was appropriate for identifying important information. The results obtained good performance, thus indicating that we can rely on the 2 Related Work Abstractive summarisation is one of the most challenging issues to address automatically, since it both requires deep language understanding and generation with a strong semantic component. For tackling this task, approaches usually need to define an internal representation of the text, that can be in the form of SVO triples (Genest and Lapalme, 2011), basic semantic units consisting of actor-action-receiver (Li, 2015), or using predarg structures (Khan et al., 2015). In this latter work, pred-arg structures extracted from different related documents are compared, so that common or redundant information can be grouped into clusters. For computing a similarity matrix, Wordnet1 based similarity metrics are used, mainly relying on the semantic distance between concepts, given Wordnets’ hierarchy. On the other hand, previous works on linguistic structure mapping can be related to paraphrase identification (Fernando and Stevenson, 2008; Xu et a"
W16-3505,S15-2001,0,0.0326421,"Missing"
W16-3505,S16-2027,1,\N,Missing
W16-3505,W14-1504,0,\N,Missing
W16-3506,H94-1010,0,0.119742,"ted a version of the SumTime-Meteo corpus which is restricted to wind data. The resulting corpus consists of 2,123 instances for a total of 22,985 words and was used by other researchers working on NLG and semantic parsing (Angeli et al., 2012). Other data-to-text corpora were proposed for training and testing generation systems, including WeatherGov (Liang et al., 2009), the ATIS dataset, the Restaurant Corpus (Wen et al., 2015) and the BAGEL dataset (Mairesse et al., 2010). WeatherGov consists of 29,528 weather scenarios for 3,753 major US cities. In the air travel domain, the ATIS dataset (Dahl et al., 1994) consists of 5,426 scenarios. These are transcriptions of spontaneous utterances of users interacting with a hypothetical online flight-booking system. The RESTAURANTS corpus contains utterances that a spoken dialogue system might produce in an interaction with a human user together with the corresponding dialog act. Similarly, the BAGEL dataset is concerned with restaurant information in a dialog setting. Related Work In all these approaches, datasets are created using heuristics often involving extensive manual labour and/or programming. The data is Many studies tackled the construction of d"
W16-3506,D16-1128,0,0.022582,"ate the data-to-text corpora that are required for learning and testing. Two main such strategies can be identified. One strategy consists in creating a small, domain-specific corpus where data and text are manually aligned by a small group of experts (often the researchers who work on developing the NLG system). Typically, such corpora are domain specific and of relatively small size while their linguistic variability is often restricted. A second strategy consists in automatically building a large data-to-text corpus in which the alignment between data and text is much looser. For instance, Lebret et al. (2016) extracted a corpus consisting of 728,321 biography articles from English Wikipedia and created a data-to-text corpus by simply associating the infobox of each article with its introduction section. The resulting dataset has a vocabulary of 403k words but there is no guarantee that the text actually matches the content of the infobox. In this paper, we explore a middle-ground approach and introduce a new methodology for semi-automatically building large, high quality data-to-text corpora. More precisely, our approach relies on a semantic sentence simplification method which allows transforming"
W16-3506,P09-1011,0,0.0318601,"nt human forecasters, and each instance in the corpus consists of three numerical data files produced by three different weather simulators, and the weather forecast file written by the forecaster. To train a sentence generator, (Belz, 2008) created a version of the SumTime-Meteo corpus which is restricted to wind data. The resulting corpus consists of 2,123 instances for a total of 22,985 words and was used by other researchers working on NLG and semantic parsing (Angeli et al., 2012). Other data-to-text corpora were proposed for training and testing generation systems, including WeatherGov (Liang et al., 2009), the ATIS dataset, the Restaurant Corpus (Wen et al., 2015) and the BAGEL dataset (Mairesse et al., 2010). WeatherGov consists of 29,528 weather scenarios for 3,753 major US cities. In the air travel domain, the ATIS dataset (Dahl et al., 1994) consists of 5,426 scenarios. These are transcriptions of spontaneous utterances of users interacting with a hypothetical online flight-booking system. The RESTAURANTS corpus contains utterances that a spoken dialogue system might produce in an interaction with a human user together with the corresponding dialog act. Similarly, the BAGEL dataset is conc"
W16-3506,P10-1157,0,0.0605466,"Missing"
W16-3506,N12-1049,0,0.0128106,"pus was created by the SumTime project (Sripada et al., 2002). The corpus was collected from the commercial output of five different human forecasters, and each instance in the corpus consists of three numerical data files produced by three different weather simulators, and the weather forecast file written by the forecaster. To train a sentence generator, (Belz, 2008) created a version of the SumTime-Meteo corpus which is restricted to wind data. The resulting corpus consists of 2,123 instances for a total of 22,985 words and was used by other researchers working on NLG and semantic parsing (Angeli et al., 2012). Other data-to-text corpora were proposed for training and testing generation systems, including WeatherGov (Liang et al., 2009), the ATIS dataset, the Restaurant Corpus (Wen et al., 2015) and the BAGEL dataset (Mairesse et al., 2010). WeatherGov consists of 29,528 weather scenarios for 3,753 major US cities. In the air travel domain, the ATIS dataset (Dahl et al., 1994) consists of 5,426 scenarios. These are transcriptions of spontaneous utterances of users interacting with a hypothetical online flight-booking system. The RESTAURANTS corpus contains utterances that a spoken dialogue system m"
W16-3506,W13-2111,1,0.845935,"in 2011 to compare and evaluate sentence generators (Belz et al., 2011). The dataset prepared by the organisers was derived from the PennTreebank and associates sentences with both a shallow representation (dependency trees) and a deep representation where edges are labelled with semantic roles (e.g., agent, patient) and the structure is a graph rather than a tree. While the data-to-text corpus that was made available from this shared task was very large, the representation associated with each sentence is a linguistic representation and is not related to a data schema. The KBGen shared task (Banik et al., 2013) followed a different approach and focused on generating sentences from knowledge bases. For this task, knowledge base fragments were extracted semi-automatically from an existing biology knowledge base (namely, BioKB101 (Chaudhri et al., 2013)) and expert biologists were asked to associate each KB fragments with a sentence verbalising their meaning. The resulting dataset was small (207 data-text instances for training, 70 for testing) and the creation process relied heavily on domain experts, thereby limiting its portability. In sum, there exists so far no standard methodology for rapidly cre"
W16-3506,W11-2832,0,0.0485912,"generation systems on expressing sets of triples in the same sentence; enabling the production of more fluent texts. mostly created artificially from sensor or web data rather than extracted from some existing knowledge base. As the data are often domain specific, the vocabulary size and the linguistic variability of the target text are often restricted. Other approaches tackled the benchmarking of NLG systems and provided the constructed dataset as a publicly available resource. For instance, a Surface Realisation shared task was organised in 2011 to compare and evaluate sentence generators (Belz et al., 2011). The dataset prepared by the organisers was derived from the PennTreebank and associates sentences with both a shallow representation (dependency trees) and a deep representation where edges are labelled with semantic roles (e.g., agent, patient) and the structure is a graph rather than a tree. While the data-to-text corpus that was made available from this shared task was very large, the representation associated with each sentence is a linguistic representation and is not related to a data schema. The KBGen shared task (Banik et al., 2013) followed a different approach and focused on genera"
W16-3506,D15-1199,0,0.0175166,"of three numerical data files produced by three different weather simulators, and the weather forecast file written by the forecaster. To train a sentence generator, (Belz, 2008) created a version of the SumTime-Meteo corpus which is restricted to wind data. The resulting corpus consists of 2,123 instances for a total of 22,985 words and was used by other researchers working on NLG and semantic parsing (Angeli et al., 2012). Other data-to-text corpora were proposed for training and testing generation systems, including WeatherGov (Liang et al., 2009), the ATIS dataset, the Restaurant Corpus (Wen et al., 2015) and the BAGEL dataset (Mairesse et al., 2010). WeatherGov consists of 29,528 weather scenarios for 3,753 major US cities. In the air travel domain, the ATIS dataset (Dahl et al., 1994) consists of 5,426 scenarios. These are transcriptions of spontaneous utterances of users interacting with a hypothetical online flight-booking system. The RESTAURANTS corpus contains utterances that a spoken dialogue system might produce in an interaction with a human user together with the corresponding dialog act. Similarly, the BAGEL dataset is concerned with restaurant information in a dialog setting. Relat"
W16-3508,P14-1023,0,0.0520295,"ncepts (relations) to expand the current query. These candidates are computed using reasoning operations on the query build so far and the underlying ontology. As discussed in Section 1, the lack of axioms in the ontology will enable the inference and the selection of incoherent candidate content such as (Song, Rectangular) and ( Song, marriedTo, Person). To filter out incoherent suggestions made by the add operations we propose the following models2 . 4 Experimental setup Both models use the best performing word vectors available at http://clic.cimec.unitn. it/composes/semantic-vectors.html (Baroni et al., 2014). DIS C OMP dataset. This dataset consists of compatible and incompatible example pairs. We extract them in the following way. We combine a set of manually annotated pairs with a set of automatically extracted ones. As manually annotated examples, we use the dataset of (Kruszewski and Baroni, 2015) plus additional examples extracted from the results of difConcept compatibility model (DIS C OMP ). As explained in (Kruszewski and Baroni, 2015), distributional semantic representations provide models for semantic relatedness and have shown good performance in many lexical semantic tasks (Baroni et"
W16-3508,S15-1004,0,0.0314443,"Bandyopadhyay CNRS/LORIA CNRS/LORIA I.U.T. Blagnac IIEST Nancy (France) laura.perez@loria.fr 1 Nancy (France) Toulouse (France) claire.gardent@loria.fr anselme.revuz@gmail.com Introduction Shibpur (India) saptarashmicse@gmail.com space models can help to improve the coherence of automatically formulated KB queries. These models are learnt from large corpora and provide general shared common semantic knowledge. Such models have been proposed for related tasks. For example, (Freitas et al., 2014) proposes a distributional semantic approach for the exploration of paths in a knowledge graph and (Corman et al., 2015) uses distributional semantics for spotting common sense inconsistencies in large KBs. Our approach draws on the fact that natural language is used to name elements, i.e. concepts and relations, in ontologies (Mellish and Sun, 2006). Hence, the idea is to exploit lexical semantics to detect incoherent query expansions during the automatic query formulation process. Following ideas from the work in (Kruszewski and Baroni, 2015; Van de Cruys, 2014), our approach uses word vector representations as lexical semantic resources. We train two semantic “compatibility” models, namely DIS C OMP and DR C"
W16-3508,D14-1004,0,0.0627022,"Missing"
W16-3508,N15-1097,0,0.128738,"dels have been proposed for related tasks. For example, (Freitas et al., 2014) proposes a distributional semantic approach for the exploration of paths in a knowledge graph and (Corman et al., 2015) uses distributional semantics for spotting common sense inconsistencies in large KBs. Our approach draws on the fact that natural language is used to name elements, i.e. concepts and relations, in ontologies (Mellish and Sun, 2006). Hence, the idea is to exploit lexical semantics to detect incoherent query expansions during the automatic query formulation process. Following ideas from the work in (Kruszewski and Baroni, 2015; Van de Cruys, 2014), our approach uses word vector representations as lexical semantic resources. We train two semantic “compatibility” models, namely DIS C OMP and DR C OMP . The first one will model incompatibility between concepts in a candidate query expansion and the second incompatibility between concepts and candidate properties. Natural Language (NL) based access to information contained in Knowledge Bases (KBs) has been tackled by approaches following different paradigms. One strand of research deals with the task of ontology-based data access and data exploration (Franconi et al.,"
W16-3508,D14-1162,0,0.0782407,"we evaluate with the ukWaCKy.SP testing set we get an accuracy of 0.86 which is similar to the results reported in (Van de Cruys, 2014). We also asses the performance of the models on the task of meaningful query generation. We run the random query generation process over 5 ontologies of different domains, namely cars, travel, wines, conferences and human disabilities. At each query expansion operation, we apply the models to the sets of candidate concepts or relations. We compare the DIS C OMP and DR C OMP models with a baseline cosine similarity (C OS ) score5 . For this score we use GloVe (Pennington et al., 2014) word embeddings and simple addition for composing multiword concept and relation names. We use a threshold of 0.3 that was determined empirically6 . During the query generation process, we registered the candidate sets as well as 5 For the case of add candidate relations, the C OS model checks for semantic relatedness between a subject concept and the relation and between the subject concept and the object concept, i.e. (s,p) and (s,o) 6 We compare the C OS baseline plus a threshold of 0.3 43 P R F S A addRelation C OS DR C OMP 0.51 0.67 0.30 0.33 0.38 0.44 0.79 0.88 0.59 0.65 [Add compatible"
W16-3511,P14-1129,0,0.0398277,"y (France) amin.sleimi@gmail.com Abstract Recent deep learning approaches to Natural Language Generation mostly rely on sequence-to-sequence models. In these approaches, the input is treated as a sequence whereas in most cases, input to generation usually is either a tree or a graph. In this paper, we describe an experiment showing how enriching a sequential input with structural information improves results and help support the generation of paraphrases. 1 Introduction Following work by (Karpathy and Fei-Fei, 2015; Kiros et al., 2014; Vinyals et al., 2015; Fang et al., 2015; Xu et al., 2015; Devlin et al., 2014; Sutskever et al., 2011; Bahdanau et al., 2014; Luong et al., 2014), there has been much work recently on using deep learning techniques to generate text from data. (Wen et al., 2015) uses recurrent neural network to generate text from dialog speech acts. Using biography articles and infoboxes from the WikiProject Biography, (Lebret et al., 2016) learns a conditional neural language model to generate text from infoboxes. etc. A basic feature of these approaches is that both the input and the output data is represented as a sequence so that generation can then be modeled using a Long Short Ter"
W16-3511,P07-1042,1,0.712603,"a RDF triples consist of (subject property object) tuples such as (Alan Bean occupation Test pilot). As illustrated in Figure 1, RDF data can be represented by a graph in which edges are labelled with properties and vertices with subject and object resources. To construct a corpus of RDF data units which can serve as input for NLG, we retrieve sets of RDF triples from DBPedia SPARQL endpoint. Text To associate data with text, we build lexical entries for DBPedia properties and use a small handwritten grammar to automatically generate text from sets of DBPedia triples using the GenI generator (Gardent and Kow, 2007). Lexicon. The lexicon is constructed semiautomatically by tokenizing the RDF triples and creating a lexical entry for each RDF resource. Subject and Object RDF resources trigger the automatic creation of a noun phrase where the string is simply the name of the corresponding resource (e.g., John E Blaha, San Antonio, ...). For properties, we manually create verb entries and assign each property a given lexicalisation. For instance, the property birthDate is mapped to the lexicalisation was born on. Grammar. We use a simple Feature-Based Lexicalised Tree Adjoining Grammar which captures canonic"
W16-3511,D16-1128,0,0.0207596,"a sequential input with structural information improves results and help support the generation of paraphrases. 1 Introduction Following work by (Karpathy and Fei-Fei, 2015; Kiros et al., 2014; Vinyals et al., 2015; Fang et al., 2015; Xu et al., 2015; Devlin et al., 2014; Sutskever et al., 2011; Bahdanau et al., 2014; Luong et al., 2014), there has been much work recently on using deep learning techniques to generate text from data. (Wen et al., 2015) uses recurrent neural network to generate text from dialog speech acts. Using biography articles and infoboxes from the WikiProject Biography, (Lebret et al., 2016) learns a conditional neural language model to generate text from infoboxes. etc. A basic feature of these approaches is that both the input and the output data is represented as a sequence so that generation can then be modeled using a Long Short Term Memory Model (LSTM) or a conditional language model. Mostly however, the data taken as input by natural language generation systems is tree or graph structured, not linear. In this paper, we investigate a constrained generation approach where the input is enriched with constraints on the syntactic shape of the sentence to be generated. As illust"
W16-3511,D15-1199,0,0.0754284,"Missing"
W16-6616,D10-1049,0,0.0260576,"we are currently investigating concerns the creation of a benchmark for Natural Language Generation. Most existing work on data-to-text generation rely on a parallel or comparable data-to-text corpus. To generate from the frames produced by a dialog system, (DeVault et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). Creating such data-to-text corpora is however difficult, time consuming and non generic. Contrary to parsing where resources such as the Penn Treebank succeeded in boosting research, natural language generation still suffers from a lack of common reference on which to train and"
W16-6616,H94-1010,0,0.478235,"es produced by a dialog system, (DeVault et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). Creating such data-to-text corpora is however difficult, time consuming and non generic. Contrary to parsing where resources such as the Penn Treebank succeeded in boosting research, natural language generation still suffers from a lack of common reference on which to train and evaluate parsers. Using crowdsourcing and the content selection method presented here, we plan to construct a large benchmark on which data-to-text generators can be trained and tested. 5 Acknowledgments We thank the French N"
W16-6616,W08-0130,0,0.0264602,"he description of the Deam Man’s Plack’s monument. More generally, bi- and 3-grams mostly seem to trigger the selection of 2- and 3-grams that are directly related to the target entity rather than chains of triples. We are currently investigating whether the use of interpolated models could help resolve this issue. Another important point we are currently investigating concerns the creation of a benchmark for Natural Language Generation. Most existing work on data-to-text generation rely on a parallel or comparable data-to-text corpus. To generate from the frames produced by a dialog system, (DeVault et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2"
W16-6616,P12-1039,0,0.0145133,"for Natural Language Generation. Most existing work on data-to-text generation rely on a parallel or comparable data-to-text corpus. To generate from the frames produced by a dialog system, (DeVault et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). Creating such data-to-text corpora is however difficult, time consuming and non generic. Contrary to parsing where resources such as the Penn Treebank succeeded in boosting research, natural language generation still suffers from a lack of common reference on which to train and evaluate parsers. Using crowdsourcing and the content selection method p"
W16-6616,N12-1093,0,0.0146997,"for Natural Language Generation. Most existing work on data-to-text generation rely on a parallel or comparable data-to-text corpus. To generate from the frames produced by a dialog system, (DeVault et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). Creating such data-to-text corpora is however difficult, time consuming and non generic. Contrary to parsing where resources such as the Penn Treebank succeeded in boosting research, natural language generation still suffers from a lack of common reference on which to train and evaluate parsers. Using crowdsourcing and the content selection method p"
W16-6616,P09-1011,0,0.0338986,"t et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). Creating such data-to-text corpora is however difficult, time consuming and non generic. Contrary to parsing where resources such as the Penn Treebank succeeded in boosting research, natural language generation still suffers from a lack of common reference on which to train and evaluate parsers. Using crowdsourcing and the content selection method presented here, we plan to construct a large benchmark on which data-to-text generators can be trained and tested. 5 Acknowledgments We thank the French National Research Agency for funding the"
W16-6616,N07-1022,0,0.022599,"creation of a benchmark for Natural Language Generation. Most existing work on data-to-text generation rely on a parallel or comparable data-to-text corpus. To generate from the frames produced by a dialog system, (DeVault et al., 2008) describes an approach in which a probabilistic Tree Adjoining Grammar is 97 induced from a training set aligning frames and sentences and used to generate using a beam search that uses weighted features learned from the training data to rank alternative expansions at each step. More recently, data-to-text generators (Angeli et al., 2010; Chen and Mooney, 2008; Wong and Mooney, 2007; Konstas and Lapata, 2012b; Konstas and Lapata, 2012a) were trained and developed on data-to-text corpora from various domains including the air travel domain (Dahl et al., 1994), weather forecasts (Liang et al., 2009; Belz, 2008) and sportscasting (Chen and Mooney, 2008). Creating such data-to-text corpora is however difficult, time consuming and non generic. Contrary to parsing where resources such as the Penn Treebank succeeded in boosting research, natural language generation still suffers from a lack of common reference on which to train and evaluate parsers. Using crowdsourcing and the"
W16-6620,P11-2087,0,0.513673,"Physical Review Letters explaining Higgs mechanism which predicted a new massive elementary particle for the first time. S2 (Split). In 1964 Peter Higgs wrote his second paper in Physical Review Letters explaining Higgs mechanism. Higgs mechanism predicted a new massive elementary particle for the first time. S (Deletion). In 1964 Peter Higgs wrote his paper explaining Higgs mechanism. Higgs mechanism predicted a new elementary particle. First, the input (1C) is rewritten as (1S1 ) by replacing standard words with simpler ones using the context aware lexical simplification method proposed in (Biran et al., 2011). Splitting is then applied to the semantic representation of (1S1 ). Following Narayan and Gardent (2014), we use Boxer 3 (Curran et al., 2007) to map the output sentence from the lexical simplification step (here S1 ) to a Discourse Representation Structure (DRS, (Kamp, 1981)). The DRS for 3 http://svn.ask.it.usyd.edu.au/trac/ candc, Version 1.00 In 1964 Peter Higgs published his second paper in Physical Review Letters describing Higgs mechanism which predicted a new massive spin-zero w boson for the first time . w w wLex Simpl.  In 1964 Peter Higgs wrote his second paper in Physical Review"
W16-6620,E99-1042,0,0.442378,"Work 1 Introduction Sentence simplification maps a sentence to a simpler, more readable one approximating its content. As has been argued in (Shardlow, 2014), sentence simplification has many potential applications. It is useful as a preprocessing step for a variety of NLP systems such as parsers and machine translation systems (Chandrasekar et al., 1996), summarisation (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008) and semantic role labelling (Vickrey and Koller, 2008). It also has wide ranging potential societal applications as a reading aid for people with aphasia (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). In this paper, we present a novel approach to sentence simplification which departs from previous work in two main ways. First, it requires neither hand written rules nor a training corpus of aligned standard and simplified sentences. Instead, we exploit non aligned Simple and English Wikipedia to learn the probability of lexical simplifications, of the semantics of simple sentences and of optional phrases i.e., phrase which may be Earlier work on sentence simplification relied on handcrafted ru"
W16-6620,C96-2183,0,0.82716,"es on deep semantic structure. We show (i) that the unsupervised framework we propose is competitive with four state-of-the-art supervised systems and (ii) that our semantic based approach allows for a principled and effective handling of sentence splitting. 2 Related Work 1 Introduction Sentence simplification maps a sentence to a simpler, more readable one approximating its content. As has been argued in (Shardlow, 2014), sentence simplification has many potential applications. It is useful as a preprocessing step for a variety of NLP systems such as parsers and machine translation systems (Chandrasekar et al., 1996), summarisation (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008) and semantic role labelling (Vickrey and Koller, 2008). It also has wide ranging potential societal applications as a reading aid for people with aphasia (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). In this paper, we present a novel approach to sentence simplification which departs from previous work in two main ways. First, it requires neither hand written rules nor a training corpus of aligned standard and simplified sentences. In"
W16-6620,W11-1601,0,0.247902,"probability. Using both the PWKP corpus developed by Zhu et al. (2010) and the edit history of simple Wikipedia, Woodsend and Lapata (2011) learn a quasi synchronous grammar (Smith and Eisner, 2006) describing a loose alignment between parse trees of complex and of simple sentences. Following Dras (1999), they then generate all possible rewrites for a source tree and use integer linear programming to select the most appropriate simplification. They evaluate their model on the same dataset used by Zhu et al. (2010) namely, an aligned corpus of 100/131 EWKP/SWKP sentences. Wubben et al. (2012), Coster and Kauchak (2011) and Xu et al. (2016) saw simplification as a monolingual translation task where the complex sentence is the source and the simpler one is the target. To account for deletions, reordering and substitution, Coster and Kauchak (2011) trained a phrase based machine translation system on the PWKP corpus while modifying the word alignment output by GIZA++ in Moses to allow for null phrasal alignments. In this way, they allow for phrases to be deleted during translation. Similarly, Wubben et al. (2012) used Moses and the PWKP data to train a phrase based machine translation system augmented with a p"
W16-6620,P07-2009,0,0.0477558,"ter Higgs wrote his second paper in Physical Review Letters explaining Higgs mechanism. Higgs mechanism predicted a new massive elementary particle for the first time. S (Deletion). In 1964 Peter Higgs wrote his paper explaining Higgs mechanism. Higgs mechanism predicted a new elementary particle. First, the input (1C) is rewritten as (1S1 ) by replacing standard words with simpler ones using the context aware lexical simplification method proposed in (Biran et al., 2011). Splitting is then applied to the semantic representation of (1S1 ). Following Narayan and Gardent (2014), we use Boxer 3 (Curran et al., 2007) to map the output sentence from the lexical simplification step (here S1 ) to a Discourse Representation Structure (DRS, (Kamp, 1981)). The DRS for 3 http://svn.ask.it.usyd.edu.au/trac/ candc, Version 1.00 In 1964 Peter Higgs published his second paper in Physical Review Letters describing Higgs mechanism which predicted a new massive spin-zero w boson for the first time . w w wLex Simpl.  In 1964 Peter Higgs wrote his second paper in Physical Review Letters explaining Higgs mechanism which predicted a new massive elementary particle for the first time . X2 X0 X1 (( named(X0 , higgs, per) ∧("
W16-6620,W08-1105,0,0.510671,"is competitive with four state-of-the-art supervised systems and (ii) that our semantic based approach allows for a principled and effective handling of sentence splitting. 2 Related Work 1 Introduction Sentence simplification maps a sentence to a simpler, more readable one approximating its content. As has been argued in (Shardlow, 2014), sentence simplification has many potential applications. It is useful as a preprocessing step for a variety of NLP systems such as parsers and machine translation systems (Chandrasekar et al., 1996), summarisation (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008) and semantic role labelling (Vickrey and Koller, 2008). It also has wide ranging potential societal applications as a reading aid for people with aphasia (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). In this paper, we present a novel approach to sentence simplification which departs from previous work in two main ways. First, it requires neither hand written rules nor a training corpus of aligned standard and simplified sentences. Instead, we exploit non aligned Simple and English Wikipedia to learn the probability of"
W16-6620,kow-belz-2012-lg,0,0.0130013,"us: the corresponding simple (Gold) 9 Moses support tools: multi-bleu http://www. statmt.org/moses/?n=Moses.SupportTools. 116 sentence from Zhu’s test corpus, the output of our system (UNSUP) and the output of the other four systems (Zhu, Woodsend, Narayan and Wubben) which were provided to us by the system authors10 . We collected ratings from 18 participants. All were either native speakers or proficient in English, having taken part in a Master taught in English or lived in an English speaking country for an extended period of time. The evaluation was done online using the LG-Eval toolkit (Kow and Belz, 2012)11 and a Latin Square Experimental Design (LSED) was used to ensure a fair distribution of the systems and the data across raters. Systems GOLD Zhu Woodsend Wubben Narayan UNSUP Simplicity 3.62 2.62 1.69 1.52 2.30 2.83 Fluency 4.69 2.56 3.15 3.05 3.03 3.56 Adequacy 3.80 2.47 3.15 3.38 3.35 2.83 Table 4: Average Human Ratings for simplicity, fluency and adequacy. Table 4 shows the average ratings of the human evaluation on a scale from 0 to 5. Pairwise comparisons between all models and their statistical significance were carried out using a one-way ANOVA with post-hoc Tukey HSD tests. 10 We up"
W16-6620,P14-1041,1,0.246458,"or phrases to be deleted during translation. Similarly, Wubben et al. (2012) used Moses and the PWKP data to train a phrase based machine translation system augmented with a post-hoc reranking procedure designed to rank the output based on their dissimilarity from the source sentence. Unlinke Wubben et al. (2012) and Coster and Kauchak (2011) who used machine translation as a black box, Xu et al. (2016) proposed to modify the optimization function of SMT systems by tuning them for the sentence simplification task. However, in their work they primarily focus on lexical simplification. Finally, Narayan and Gardent (2014) present a hybrid approach combining a probabilistic model for sentence splitting and deletion with a statistical machine translation system trained on PWKP for substitution and reordering. Our proposal differs from all these approaches in that it does not use the parallel PWKP corpus for training. Nor do we use hand-written rules. Another difference is that we use a deep semantic 112 representation as input for simplification. While a similar approach was proposed in (Narayan and Gardent, 2014), the probabilistic models differ in that we determine splitting points based on the maximum likelih"
W16-6620,E14-1076,0,0.794255,"ptional phrases i.e., phrase which may be Earlier work on sentence simplification relied on handcrafted rules to capture syntactic simplification e.g., to split coordinated and subordinated sentences into several, simpler clauses or to model e.g., active/passive transformations (Siddharthan, 2002; Chandrasekar and Srinivas, 1997; Canning, 2002; Siddharthan, 2011; Siddharthan, 2010). While these hand-crafted approaches can encode precise and linguistically well-informed syntactic transformations, they do not account for lexical simplifications and their interaction with the sentential context. Siddharthan and Mandya (2014) therefore propose an approach where hand-crafted syntactic simplification rules are combined with lexical simplification rules extracted from aligned English and simple English sentences, and revision histories of Simple Wikipedia. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedia (EWKP)2 , further work has focused on developing machine learning approaches to sentence simplification. Zhu et al. (2010) constructed a parallel Wikipedia corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used"
W16-6620,W10-4213,0,0.0787579,"rules nor a training corpus of aligned standard and simplified sentences. Instead, we exploit non aligned Simple and English Wikipedia to learn the probability of lexical simplifications, of the semantics of simple sentences and of optional phrases i.e., phrase which may be Earlier work on sentence simplification relied on handcrafted rules to capture syntactic simplification e.g., to split coordinated and subordinated sentences into several, simpler clauses or to model e.g., active/passive transformations (Siddharthan, 2002; Chandrasekar and Srinivas, 1997; Canning, 2002; Siddharthan, 2011; Siddharthan, 2010). While these hand-crafted approaches can encode precise and linguistically well-informed syntactic transformations, they do not account for lexical simplifications and their interaction with the sentential context. Siddharthan and Mandya (2014) therefore propose an approach where hand-crafted syntactic simplification rules are combined with lexical simplification rules extracted from aligned English and simple English sentences, and revision histories of Simple Wikipedia. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedia (EWKP)2 , further"
W16-6620,W11-2802,0,0.243619,"either hand written rules nor a training corpus of aligned standard and simplified sentences. Instead, we exploit non aligned Simple and English Wikipedia to learn the probability of lexical simplifications, of the semantics of simple sentences and of optional phrases i.e., phrase which may be Earlier work on sentence simplification relied on handcrafted rules to capture syntactic simplification e.g., to split coordinated and subordinated sentences into several, simpler clauses or to model e.g., active/passive transformations (Siddharthan, 2002; Chandrasekar and Srinivas, 1997; Canning, 2002; Siddharthan, 2011; Siddharthan, 2010). While these hand-crafted approaches can encode precise and linguistically well-informed syntactic transformations, they do not account for lexical simplifications and their interaction with the sentential context. Siddharthan and Mandya (2014) therefore propose an approach where hand-crafted syntactic simplification rules are combined with lexical simplification rules extracted from aligned English and simple English sentences, and revision histories of Simple Wikipedia. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedi"
W16-6620,W06-3104,0,0.156549,"ia.org 111 Proceedings of The 9th International Natural Language Generation conference, pages 111–120, c Edinburgh, UK, September 5-8 2016. 2016 Association for Computational Linguistics tences namely, substitution, reordering, splitting and deletion. It is combined with a language model to improve grammaticality and the decoder translates sentences into simpler ones by greedily selecting the output sentence with highest probability. Using both the PWKP corpus developed by Zhu et al. (2010) and the edit history of simple Wikipedia, Woodsend and Lapata (2011) learn a quasi synchronous grammar (Smith and Eisner, 2006) describing a loose alignment between parse trees of complex and of simple sentences. Following Dras (1999), they then generate all possible rewrites for a source tree and use integer linear programming to select the most appropriate simplification. They evaluate their model on the same dataset used by Zhu et al. (2010) namely, an aligned corpus of 100/131 EWKP/SWKP sentences. Wubben et al. (2012), Coster and Kauchak (2011) and Xu et al. (2016) saw simplification as a monolingual translation task where the complex sentence is the source and the simpler one is the target. To account for deletio"
W16-6620,P08-1040,0,0.175511,"tems and (ii) that our semantic based approach allows for a principled and effective handling of sentence splitting. 2 Related Work 1 Introduction Sentence simplification maps a sentence to a simpler, more readable one approximating its content. As has been argued in (Shardlow, 2014), sentence simplification has many potential applications. It is useful as a preprocessing step for a variety of NLP systems such as parsers and machine translation systems (Chandrasekar et al., 1996), summarisation (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008) and semantic role labelling (Vickrey and Koller, 2008). It also has wide ranging potential societal applications as a reading aid for people with aphasia (Carroll et al., 1999), for low literacy readers (Watanabe et al., 2009) and for non native speakers (Siddharthan, 2002). In this paper, we present a novel approach to sentence simplification which departs from previous work in two main ways. First, it requires neither hand written rules nor a training corpus of aligned standard and simplified sentences. Instead, we exploit non aligned Simple and English Wikipedia to learn the probability of lexical simplifications, of the semantics of simple se"
W16-6620,D11-1038,0,0.892011,"an input sen1 2 http://simple.wikipedia.org http://en.wikipedia.org 111 Proceedings of The 9th International Natural Language Generation conference, pages 111–120, c Edinburgh, UK, September 5-8 2016. 2016 Association for Computational Linguistics tences namely, substitution, reordering, splitting and deletion. It is combined with a language model to improve grammaticality and the decoder translates sentences into simpler ones by greedily selecting the output sentence with highest probability. Using both the PWKP corpus developed by Zhu et al. (2010) and the edit history of simple Wikipedia, Woodsend and Lapata (2011) learn a quasi synchronous grammar (Smith and Eisner, 2006) describing a loose alignment between parse trees of complex and of simple sentences. Following Dras (1999), they then generate all possible rewrites for a source tree and use integer linear programming to select the most appropriate simplification. They evaluate their model on the same dataset used by Zhu et al. (2010) namely, an aligned corpus of 100/131 EWKP/SWKP sentences. Wubben et al. (2012), Coster and Kauchak (2011) and Xu et al. (2016) saw simplification as a monolingual translation task where the complex sentence is the sourc"
W16-6620,P12-1107,0,0.429341,"Missing"
W16-6620,P01-1067,0,0.0233067,"exical simplification rules extracted from aligned English and simple English sentences, and revision histories of Simple Wikipedia. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedia (EWKP)2 , further work has focused on developing machine learning approaches to sentence simplification. Zhu et al. (2010) constructed a parallel Wikipedia corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001). Their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sen1 2 http://simple.wikipedia.org http://en.wikipedia.org 111 Proceedings of The 9th International Natural Language Generation conference, pages 111–120, c Edinburgh, UK, September 5-8 2016. 2016 Association for Computational Linguistics tences namely, substitution, reordering, splitting and deletion. It is combined with a language model to improve grammaticality and the decoder translates sentences into simpler ones by greedily selecting the output sentence with highest probabil"
W16-6620,C10-1152,0,0.560218,"ed syntactic transformations, they do not account for lexical simplifications and their interaction with the sentential context. Siddharthan and Mandya (2014) therefore propose an approach where hand-crafted syntactic simplification rules are combined with lexical simplification rules extracted from aligned English and simple English sentences, and revision histories of Simple Wikipedia. Using the parallel dataset formed by Simple English Wikipedia (SWKP)1 and traditional English Wikipedia (EWKP)2 , further work has focused on developing machine learning approaches to sentence simplification. Zhu et al. (2010) constructed a parallel Wikipedia corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001). Their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sen1 2 http://simple.wikipedia.org http://en.wikipedia.org 111 Proceedings of The 9th International Natural Language Generation conference, pages 111–120, c Edinburgh, UK, September 5-8 2016. 2016 Association for Computa"
W16-6620,bott-etal-2012-text,0,\N,Missing
W16-6626,W11-2832,0,0.0220477,"cusing on different categories. Moreover, the set of relations on both KBs pose different challenges for generation, while the AURA KB contains n-ary relations DBPedia contains relations names challenging for the lexicalisation subtask. A last difference with our task is the content selection method. Our method is completely automatic and thus permits the inexpensive generation of a large benchmark. Moreover, it can be used to select content ranging from a single triple to several triples and with different shapes. The Surface Realisation Shared Task (SR’11). The major goal of the SR’11 task (Belz et al., 2011) was to provide a common ground for the comparison of surface realisers on the task of regenerating sentences in a treebank. Two different tracks are considered with different input representations. The ’shallow’ input provides a dependency tree of the sentence to be generated and the ’deep’ input provides a graph representation where syntactic dependencies have been replaced by semantic roles and some function words have been removed. The focus of the SR’11 task was on the linguistic realisation subtask and the broad coverage of linguistic phenomena. The task we propose here starts from non-l"
W16-6626,W13-2102,0,0.0271306,"Missing"
W16-6626,W13-0108,0,0.0608974,"from DBPedia Data Emilie Colin1 Claire Gardent1 Yassine M’rabet2 Shashi Narayan3 Laura Perez-Beltrachini1 1 CNRS/LORIA and Universit´e de Lorraine, Nancy, France {emilie.colin,claire.gardent,laura.perez}@loria.fr 2 National Library of Medicine, Bethesda, USA yassine.m’rabet@nih.gov 3 School of Informatics, University of Edinburgh, UK snaraya2@inf.ed.ac.uk 1 Introduction With the emergence of the linked data initiative and the rapid development of RDF (Resource Description Format) datasets, several approaches have recently been proposed for generating text from RDF data (Sun and Mellish, 2006; Duma and Klein, 2013; Bontcheva and Wilks, 2004; Cimiano et al., 2013; Lebret et al., 2016). To support the evaluation and comparison of such systems, we propose a shared task on generating text from DBPedia data. The training data will consist of Data/Text pairs where the data is a set of triples extracted from DBPedia and the text is a verbalisation of these triples. In essence, the task consists in mapping data to text. Specific subtasks include sentence segmentation (how to chunk the input data into sentences), lexicalisation (of the DBPedia properties), aggregation (how to avoid repetitions) and surface real"
W16-6626,W08-1131,0,0.0189634,"function words have been removed. The focus of the SR’11 task was on the linguistic realisation subtask and the broad coverage of linguistic phenomena. The task we propose here starts from non-linguistic KB data and puts forward other NLG subtasks. Generating Referring Expressions (GRE). The GRE shared tasks pioneered the proposed NLG challenges. The first shared task has only focused on the selection of distinguishing attributes (Belz and Gatt, 2007) while subsequent tasks have considered the referring expression realisation subtask proposing a complete referring expression generation task (Gatt et al., 2008; Gatt et al., 2009). This tasks aimed at the unique identification of the referent and brevity of the referring expression. Slightly different, the GREC challenges (Belz et al., 2008; Belz et al., 2009; Belz et al., 2010) propose the generation of referring expressions in a discourse context. The GREC tasks use a corpus created from Wikipedia abstracts on geographic entities and people and with two referring expression annotation schemes, reference type and word strings. Rather than generating from data input these tasks consist in labelling underspecified referring expressions in a given tex"
W16-6626,W09-0629,0,0.0763856,"e been removed. The focus of the SR’11 task was on the linguistic realisation subtask and the broad coverage of linguistic phenomena. The task we propose here starts from non-linguistic KB data and puts forward other NLG subtasks. Generating Referring Expressions (GRE). The GRE shared tasks pioneered the proposed NLG challenges. The first shared task has only focused on the selection of distinguishing attributes (Belz and Gatt, 2007) while subsequent tasks have considered the referring expression realisation subtask proposing a complete referring expression generation task (Gatt et al., 2008; Gatt et al., 2009). This tasks aimed at the unique identification of the referent and brevity of the referring expression. Slightly different, the GREC challenges (Belz et al., 2008; Belz et al., 2009; Belz et al., 2010) propose the generation of referring expressions in a discourse context. The GREC tasks use a corpus created from Wikipedia abstracts on geographic entities and people and with two referring expression annotation schemes, reference type and word strings. Rather than generating from data input these tasks consist in labelling underspecified referring expressions in a given text. Our task concerns"
W16-6626,D16-1128,0,0.0549581,"Missing"
W16-6626,mendes-etal-2012-dbpedia,0,0.0200225,"Missing"
W16-6626,W16-6616,1,0.65506,"trast, our proposal targets all generation subtasks involved in content realisation. 4 Data As illustrated in Example 1 above, the training corpus consists of (D, T ) pairs such that D is a set of DBPedia triples and T is an English text (possibly consisting of a single sentence). This corpus will be constructed in two steps by first, extracting from DBPedia content units that are both coherent and diverse and second, associating these content units with English text verbalising their content. Data To extract content units from DBPedia, we will use the content selection procedure sketched in (Mohammed et al., 2016). This procedure consists of two steps. First, bigram models of DBPedia properties specific to a given DBPedia category (e.g., Astronaut) are learned from the DBPedia graphs associated with entities of that category. Second, an 165 ILP program is used to extract from DBPedia, subtrees that maximise bigram probability. In effect, the extracted DBPedia trees are coherent entity descriptions in that the property bigram they contain often cooccur together in the DBPedia graphs associated with entities of a given DBPedia category. The method can be parameterised to produce content units for differe"
W16-6626,W16-3506,1,0.809821,"contained in the Lemon English Lexicon for DBPedia7 (Walter et al., 2013; Walter et al., 2014a; Walter et al., 2014b) and by manually filtering the lexicalisations produced by the lexicalisation method described in (PerezBeltrachini and Gardent, 2016) and by the relation extraction and clustering method described in (c.f. (Nakashole et al., 2012))8 . We will then ask crowdsourcers to verbalise sets of DBPEdia triples in which properties have already been lexicalised (e.g., C REW 1U P will be lexicalised as commander of ). Second, we will exploit the data-to-text alignment method presented in (Mrabet et al., 2016) to semiautomatically align Wikipedia text with sets of DBPedia triples. The method consists in (i) automatically annotating phrases with DBPedia entities, (ii) associating sentences with DBPedia triples relating entities annotating these sentences and (iii) using crowdsourcing to align sentences with triples. In the third step, annotators are asked to “align” triples and sentences that is, to remove from the sentence all material that is irrelevant to express the associated triples and vice versa, to remove any triples that is not expressed by the sentence. Statistics, Schedule and Funding Th"
W16-6626,S16-2027,1,0.87081,"Missing"
W16-6626,D15-1199,0,0.0380916,"Missing"
W16-6626,2007.mtsummit-ucnlg.14,0,\N,Missing
W16-6626,W13-2111,1,\N,Missing
W17-3518,W13-2111,1,0.909881,"Missing"
W17-3518,2007.mtsummit-ucnlg.14,0,0.0931338,"Missing"
W17-3518,W09-2817,0,0.0289064,"ur evaluation methodology, analyse participant results and provide a brief description of the participating systems. (1) a. Data: (J OHN E B LAHA BIRTH DATE 1942 08 26) (J OHN E B LAHA S AN A NTONIO ) (J OHN E B LAHA OCCUPATION F IGHTER PILOT ) b. Text: John E Blaha, born in San Antonio on 194208-26, worked as a fighter pilot 2 1 BIRTH P LACE Introduction Previous Natural Language Generation (NLG) challenges have focused on surface realisation (Banik et al., 2013; Belz et al., 2011), referring expression generation (Belz and Gatt, 2007; Gatt et al., 2008; Gatt et al., 2009; Belz et al., 2008; Belz et al., 2009; Belz et al., 2010) and content selection (BouayadAgha et al., 2013). In contrast, the WebNLG challenge focuses on microplanning, that subtask of NLG which consists in mapping a given content to a text verbalising this content. Microplanning is a complex choice problem involving several subtasks referred to in the literature as referring expression generation, aggregation, lexicalisation, surface realisation and sentence segmentation. For instance, given the WebNLG data unit shown in (1a), generating the text in (1b) involves choosing to lexicalise the JOHN E BLAHA Data As illustrated by the"
W17-3518,W11-2832,0,0.104147,"Missing"
W17-3518,W13-2112,0,0.0508518,"Missing"
W17-3518,P16-1054,0,0.0250493,"UT ILBURG -SMT Tilburg University UIT-VNU-HCM University of Information Technology UPF-FORG E Universitat Pompeu Fabra SMT Systems UT ILBURG -SMT Tilburg University NMT Systems ADAPTC ENTRE ADAPT Centre, Ireland UM ELBOURNE University of Melbourne UT ILBURG -NMT Tilburg University PKUW RITER Peking University BASELINE Table 2: Categorisation of participating systems. from, UT ILBURG -P IPELINE first ordered triples to maintain discourse order. Extracted rules were then applied to generate a delexicalised text. Missing entities were added using a referring expression generation module (Castro Ferreira et al., 2016). Finally, a 6-gram language model trained on the Gigaword corpus was used to rank the system output. UIT-VNU-HCM did not resort to delexicalisation in their rules. Instead of using the text to extract templates, it used the typed-dependency structure of the text to facilitate rule extraction from the training data. In addition, at run time, WordNet was used to estimate similarity between predicates in the test and train sets. UPF-FORG E mostly focused on sentence planning with predicate-argument (PredArg) templates. For each of the DBPedia properties found in the training and evaluation data,"
W17-3518,W14-3348,0,0.0163047,"Missing"
W17-3518,P17-1017,1,0.291717,"o in the literature as referring expression generation, aggregation, lexicalisation, surface realisation and sentence segmentation. For instance, given the WebNLG data unit shown in (1a), generating the text in (1b) involves choosing to lexicalise the JOHN E BLAHA Data As illustrated by the above example, the WebNLG dataset was designed to exercise the ability of NLG systems to handle the whole range of microplanning operations and their interactions. It was created using a content selection procedure specifically designed to enhance data and text variety (Perez-Beltrachini et al., 2016). In (Gardent et al., 2017), we compared a dataset created using the WebNLG process with existing benchmarks in particular, (Wen et al., 2016)’s dataset (RNNLG) which was produced using a similar process. In what follows, we give various statistics about the WebNLG dataset using the RNNLG dataset as a reference point. Size. The WebNLG dataset consists of 25,298 (data,text) pairs and 9,674 distinct data units. The data units are sets of RDF triples extracted from DBPedia and the texts are sequences of one or more sentences verbalising these data units. 124 Proceedings of The 10th International Natural Language Generation"
W17-3518,W08-1131,0,0.151063,"Missing"
W17-3518,W09-0629,0,0.0265947,"describe data preparation, introduce our evaluation methodology, analyse participant results and provide a brief description of the participating systems. (1) a. Data: (J OHN E B LAHA BIRTH DATE 1942 08 26) (J OHN E B LAHA S AN A NTONIO ) (J OHN E B LAHA OCCUPATION F IGHTER PILOT ) b. Text: John E Blaha, born in San Antonio on 194208-26, worked as a fighter pilot 2 1 BIRTH P LACE Introduction Previous Natural Language Generation (NLG) challenges have focused on surface realisation (Banik et al., 2013; Belz et al., 2011), referring expression generation (Belz and Gatt, 2007; Gatt et al., 2008; Gatt et al., 2009; Belz et al., 2008; Belz et al., 2009; Belz et al., 2010) and content selection (BouayadAgha et al., 2013). In contrast, the WebNLG challenge focuses on microplanning, that subtask of NLG which consists in mapping a given content to a text verbalising this content. Microplanning is a complex choice problem involving several subtasks referred to in the literature as referring expression generation, aggregation, lexicalisation, surface realisation and sentence segmentation. For instance, given the WebNLG data unit shown in (1a), generating the text in (1b) involves choosing to lexicalise the JO"
W17-3518,P17-4012,0,0.00506614,"extracted from seen categories. (4) a. Set of triples: (I NDONESIA J USUF K ALLA ) (BAKSO LEADER NAME INGREDIENT N OODLE ) (BAKSO COUNTRY I NDONESIA ) b. Text: Bakso is a food containing noodles; it is found in Indonesia where Jusuf Kalla is the leader. (5) a. Source: (COUNTRY LEADER NAME LEADERNAME) (FOOD INGREDIENT INGREDIENT) (FOOD COUNTRY COUNTRY) b. Target: FOOD is a food containing noodles ; it is found in COUNTRY where LEADERNAME is the leader . On this delexicalised data-to-text corpus, we trained a vanilla sequence-to-sequence model with attention mechanism using the OpenNMT toolkit (Klein et al., 2017) with default parameters for training and decoding. The network consists of a twolayered bidirectional encoder-decoder model with LSTM units. We use a batch size of 64 and a starting learning rate of 1.0. The size of the hidden layers is 500. The network was trained for 13 epochs with a stochastic gradient descent optimisation method and a dropout probability of 0.3. We used the entire vocabulary for the baseline due to its rather small size. Source Target Total Original 2703 5374 8077 Delexicalised 1300 5013 6313 Table 4: Vocabulary size in tokens. After training we relexicalised sentences wi"
W17-3518,W06-3114,0,0.0350981,"resented in this paper. The results of the humanbased evaluation will be provided on the WebNLG website2 in October 2017. 2 http://talc1.loria.fr/webnlg/stories/ challenge.html 4.1 Automatic Evaluation test set, but not in the training and development set. Three automatic metrics were used to evaluate the participating systems: • BLEU-43 (Papineni et al., 2002). BLEU scores were computed using up to three references. • METEOR (v1.5)4 (Denkowski and Lavie, 2014); Prop. Obj. • TER5 (Snover et al., 2006). For statistical significance testing, we followed the bootstrapping algorithm described in (Koehn and Monz, 2006). To assess the ability of the participating systems to generalise to out of domain data, the test dataset consists of two sets of roughly equal size: a test set containing inputs created for entities belonging to DBpedia categories that were seen in the training data (Astronaut, University, Monument, Building, ComicsCharacter, Food, Airport, SportsTeam, City, and WrittenWork), and a test set containing inputs extracted for entities belonging to 5 unseen categories (Athlete, Artist, MeanOfTransportation, CelestialBody, Politician). We call the first type of data seen categories, the second, un"
W17-3518,S17-2158,0,0.041301,"cipating systems and our baseline (BASELINE) system. These can be grouped into three categories: pipeline systems, statistical machine translation (SMT) and neural machine translation (NMT) systems. Table 3 shows the system categorisations. Pipeline Systems. Three submissions used a template or grammar-based pipeline framework with some NLG module: UT ILBURG -P IPELINE, UITVNU-HCM and UPF-FORG E. The first two systems, UT ILBURG -P IPELINE and UIT-VNU-HCM, extracted rules or templates from the training data for surface realisation, whereas the third system, UPF-FORG E, used the FORGe grammar (Mille et al., 2017). UT ILBURG -P IPELINE extracted rules mapping a triple (or a triple set) to a text observed in the training data; both the triple and the associated text were delexicalised. Given a RDF triple set to generate 126 System ID Institution P IPELINE Systems UT ILBURG -SMT Tilburg University UIT-VNU-HCM University of Information Technology UPF-FORG E Universitat Pompeu Fabra SMT Systems UT ILBURG -SMT Tilburg University NMT Systems ADAPTC ENTRE ADAPT Centre, Ireland UM ELBOURNE University of Melbourne UT ILBURG -NMT Tilburg University PKUW RITER Peking University BASELINE Table 2: Categorisation of"
W17-3518,D17-1064,1,0.810278,"aset consisting of 40,049 (data, text) pairs, 15,095 distinct data input and 15 DBpedia categories is also available. Both datasets are under the creative common licence “CC Attribution-Noncommercial-Share Alike 4.0 International license”. We hope that these resources will enable a long and fruitful strand of research on microplanning. The usefulness of the WebNLG dataset reaches far beyond the WebNLG challenge. It can be used for instance to train a semantic parser which would convert a sentence into a set of RDF triples. It can also be used to derive new datasets for related tasks. Thus in (Narayan et al., 2017), we show how to derive from the WebNLG dataset, a dataset for sentence simplification which we call the Split-andRephrase dataset. In this dataset, each pair consists of (i) a single, complex sentence with its meaning representation in terms of RDF triples and (ii) a sequence of at least two sentences and their corresponding sets of RDF triples whereby these sets form a partition on the set of RDF triples associated with the input complex sentence. In other words, the Split-and-Rephrase dataset associates a complex sentence with a sequence of at least two sentences whose meaning is the same a"
W17-3518,P02-1040,0,0.113293,"Missing"
W17-3518,W17-3537,1,0.797882,"e naturally give rise to object relative clauses or participials. Another factor impacting syntactic variation is the set of properties (input patterns) cooccuring in a given input. This is illustrated by the examples in (3) where two inputs of the same length (3 triples hence 3 properties) result in text with different syntax. That is, a larger number of input patterns is more likely to induce texts with greater syntactic variety. By extracting data units from a large number of distinct domains (DBPedia categories), we seeked to produce a large number of distinct input patterns. 1 Following (Perez-Beltrachini and Gardent, 2017), we use (Lu, 2008)’s system to compute the CTTR (Carroll, 1964). 125 (3) a. C A participated in C operated B mission A SIBLING operator B mission n (2) X TITLE Y ⇒ X served as Y Verb X NATIONALITY Y ⇒ X’s nationality is Y Relational noun X COUNTRY Y ⇒ X is in Y Preposition X NATIONALITY USA ⇒ X is American Adjective To promote diverse lexicalisation patterns, we extracted data from 15 DBPedia categories (Astronaut, University, Monument, Building, ComicsCharacter, Food, Airport, SportsTeam, WrittenWork, Athlete, Artist, City, MeanOfTransportation, CelestialBody, Politician) resulting in a set"
W17-3518,C16-1141,1,0.698605,"involving several subtasks referred to in the literature as referring expression generation, aggregation, lexicalisation, surface realisation and sentence segmentation. For instance, given the WebNLG data unit shown in (1a), generating the text in (1b) involves choosing to lexicalise the JOHN E BLAHA Data As illustrated by the above example, the WebNLG dataset was designed to exercise the ability of NLG systems to handle the whole range of microplanning operations and their interactions. It was created using a content selection procedure specifically designed to enhance data and text variety (Perez-Beltrachini et al., 2016). In (Gardent et al., 2017), we compared a dataset created using the WebNLG process with existing benchmarks in particular, (Wen et al., 2016)’s dataset (RNNLG) which was produced using a similar process. In what follows, we give various statistics about the WebNLG dataset using the RNNLG dataset as a reference point. Size. The WebNLG dataset consists of 25,298 (data,text) pairs and 9,674 distinct data units. The data units are sets of RDF triples extracted from DBPedia and the texts are sequences of one or more sentences verbalising these data units. 124 Proceedings of The 10th International"
W17-3518,E17-3017,0,0.0162677,"s were tuned using 60batch MIRA with BLEU as the evaluation metric. Similar to UT ILBURG -P IPELINE, the system used a 6-gram language model trained on the Gigaword corpus using KenLM. NMT Systems. Four systems (ADAPTC ENTRE, UM ELBOURNE, UT ILBURG -NMT and PKUW RITER) build upon the attention-based encoder-decoder architecture proposed in (Bahdanau et al., 2014). Most of them make use of existing NMT frameworks. There are however important differences among systems with respect to both the concrete architecture and the sequence representations they use. ADAPTC ENTRE makes use of the Nematus (Sennrich et al., 2017) system. They opt for subword representations rather than delexicalisation to deal with rare words and sparsity. They linearise the input sequence and insert tuple separation special tokens. 127 UM ELBOURNE does a combined delexicalisation procedure and enrichment of the input sequence. Entities are delexicalised using an entity identifier (ENTITY- ID). When available, the DBPedia type of the entity is appended. An n-gram search is used to assure the most accurate target sequence delexicalisation. They use a standard encoder-decoder with attention model. UT ILBURG -NMT is based on the Edinburg"
W17-3518,2006.amta-papers.25,0,0.128663,"Missing"
W17-3518,N16-1015,0,0.00976834,"Missing"
W17-3518,P07-2045,0,\N,Missing
W17-3537,basile-etal-2012-developing,0,0.0257319,"er datasets (W IKI B IO16317 ) and one which is domain specific in that all biographies are about astronauts (W IKI B IOA STRO). The other two datasets were created manually with humans providing text for dialogue acts in the case of (Wen et al., 2015b; Wen et al., 2016)’s RNNLG datasets (laptop, TV, hotel, restaurant) and image descriptions in the case of (Novikova and Rieser, 2016)’s dataset (I MAGE D ESC). We also include a text-only corpus for comparison with the texts contained in our three datasets. This corpus (GMB) consists of the texts from the Groningen Meaning Bank (Version 1.0.0, (Basile et al., 2012)) and covers different genres (e.g., news, jokes, fables). Linguistic and Computational Diversity. Table 2 gives the descriptive statistics for each of these three datasets. It shows marked differences in terms of size ( W IKI B IO16317 being the largest and I MAGE D ESC the smallest), number of distinct relations (from 16 for I MAGE D ESC to 2367 for W IKI B IO16317 ) and average number of paraphrases (15.11 for I MAGE D ESC against 1 to 3.72 for the other two datasets). The number of distinct data inputs (semantic variability) also varies widely (from 77 distinct data inputs for the I M AGE"
W17-3537,W11-2832,0,0.0482233,"his methodology to three existing benchmarks and we elicite a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators. 1 Claire Gardent CNRS, LORIA, UMR 7503 Vanoeuvre-l`es-Nancy, F-54506 France 2 Introduction In some scenarios, generation datasets provide linguistic descriptions of a specific domain and application (e.g. (Reiter et al., 2005)). However, in other scenarios generation datasets aim at broader syntactic (e.g. the surface realisation shared-task (Belz et al., 2011)) or domain (Wen et al., 2015a) coverage. Recently, several datasets have been created to train data-to-text generators (Wen et al., 2015a; Liang et al., 2009; Lebret et al., 2016; Novikova et al., 2016; Chen and Mooney, 2008). It is unclear however to what extent the generation task exercised by these datasets is linguistically challenging. Do these datasets provide enough variety to support the development of high-quality data-to-text generators ? In this paper, we propose a methodology for characterising the variety and complexity of these datasets. We exemplify its use by applying it to th"
W17-3537,D16-1128,0,0.133446,"Missing"
W17-3537,P09-1011,0,0.0593008,"development, evaluation and comparison of linguistically sophisticated data-to-text generators. 1 Claire Gardent CNRS, LORIA, UMR 7503 Vanoeuvre-l`es-Nancy, F-54506 France 2 Introduction In some scenarios, generation datasets provide linguistic descriptions of a specific domain and application (e.g. (Reiter et al., 2005)). However, in other scenarios generation datasets aim at broader syntactic (e.g. the surface realisation shared-task (Belz et al., 2011)) or domain (Wen et al., 2015a) coverage. Recently, several datasets have been created to train data-to-text generators (Wen et al., 2015a; Liang et al., 2009; Lebret et al., 2016; Novikova et al., 2016; Chen and Mooney, 2008). It is unclear however to what extent the generation task exercised by these datasets is linguistically challenging. Do these datasets provide enough variety to support the development of high-quality data-to-text generators ? In this paper, we propose a methodology for characterising the variety and complexity of these datasets. We exemplify its use by applying it to three existing training corpora for NLG and we conclude by eliciting a set of criteria for the creation of data-to-text Approach Our classification aims to asse"
W17-3537,W16-6627,0,0.0113318,"that this is the case through manual examination of a random subset of the dataset. A data/text pair will be considered an “Exact” match if all data is verbalised by the text. It will be labelled as “Missing” if part of the data is not present in the text (content selection) and as “Additional” if the text contains information not present in the input data. 3 Case Study To illustrate the usage of the evaluation grid proposed in the preceding section, we apply it to three datasets recently proposed for data-to-text generation by (Lebret et al., 2016), (Wen et al., 2015b; Wen et al., 2016) and (Novikova and Rieser, 2016). (Lebret et al., 2016)’s dataset (W IKI B IO) focuses on biographies and associates Wikipedia infoboxes with the first sentence of the corresponding article in Wikipedia. As the dataset is much larger than the other datasets and is not domain specific, we extract two subsets of it for better comparison: one whose size is similar to the other datasets (W IKI B IO16317 ) and one which is domain specific in that all biographies are about astronauts (W IKI B IOA STRO). The other two datasets were created manually with humans providing text for dialogue acts in the case of (Wen et al., 2015b; Wen"
W17-3537,W16-6644,0,0.0290539,"f linguistically sophisticated data-to-text generators. 1 Claire Gardent CNRS, LORIA, UMR 7503 Vanoeuvre-l`es-Nancy, F-54506 France 2 Introduction In some scenarios, generation datasets provide linguistic descriptions of a specific domain and application (e.g. (Reiter et al., 2005)). However, in other scenarios generation datasets aim at broader syntactic (e.g. the surface realisation shared-task (Belz et al., 2011)) or domain (Wen et al., 2015a) coverage. Recently, several datasets have been created to train data-to-text generators (Wen et al., 2015a; Liang et al., 2009; Lebret et al., 2016; Novikova et al., 2016; Chen and Mooney, 2008). It is unclear however to what extent the generation task exercised by these datasets is linguistically challenging. Do these datasets provide enough variety to support the development of high-quality data-to-text generators ? In this paper, we propose a methodology for characterising the variety and complexity of these datasets. We exemplify its use by applying it to three existing training corpora for NLG and we conclude by eliciting a set of criteria for the creation of data-to-text Approach Our classification aims to assess to what extent a data-to-text corpus will"
W17-3537,D15-1199,0,0.473775,"ng benchmarks and we elicite a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators. 1 Claire Gardent CNRS, LORIA, UMR 7503 Vanoeuvre-l`es-Nancy, F-54506 France 2 Introduction In some scenarios, generation datasets provide linguistic descriptions of a specific domain and application (e.g. (Reiter et al., 2005)). However, in other scenarios generation datasets aim at broader syntactic (e.g. the surface realisation shared-task (Belz et al., 2011)) or domain (Wen et al., 2015a) coverage. Recently, several datasets have been created to train data-to-text generators (Wen et al., 2015a; Liang et al., 2009; Lebret et al., 2016; Novikova et al., 2016; Chen and Mooney, 2008). It is unclear however to what extent the generation task exercised by these datasets is linguistically challenging. Do these datasets provide enough variety to support the development of high-quality data-to-text generators ? In this paper, we propose a methodology for characterising the variety and complexity of these datasets. We exemplify its use by applying it to three existing training corpora"
W17-3537,N16-1015,0,0.0476213,"re important to verify that this is the case through manual examination of a random subset of the dataset. A data/text pair will be considered an “Exact” match if all data is verbalised by the text. It will be labelled as “Missing” if part of the data is not present in the text (content selection) and as “Additional” if the text contains information not present in the input data. 3 Case Study To illustrate the usage of the evaluation grid proposed in the preceding section, we apply it to three datasets recently proposed for data-to-text generation by (Lebret et al., 2016), (Wen et al., 2015b; Wen et al., 2016) and (Novikova and Rieser, 2016). (Lebret et al., 2016)’s dataset (W IKI B IO) focuses on biographies and associates Wikipedia infoboxes with the first sentence of the corresponding article in Wikipedia. As the dataset is much larger than the other datasets and is not domain specific, we extract two subsets of it for better comparison: one whose size is similar to the other datasets (W IKI B IO16317 ) and one which is domain specific in that all biographies are about astronauts (W IKI B IOA STRO). The other two datasets were created manually with humans providing text for dialogue acts in the"
W18-6543,P15-1044,0,0.036371,"Missing"
W18-6543,W17-5519,0,0.0685366,"the dataset is constructed and on how it is split into train, dev and test1 . 1 Introduction The input to data-to-text generation often contains rare items, i.e. low frequency items such as names, locations and dates. This makes it difficult for neural models to predict their verbalisation. To address these issues, neural approaches to datato-text generation typically resort either to delexicalisation (Wen et al., 2015; Duˇsek and Jurcicek, 2015; Trisedya et al., 2018; Chen et al., 2018) or to a copy mechanism (Chen, 2018; Elder et al., 2018; Gehrmann et al., 2018). Character-based encodings (Agarwal and Dymetman, 2017; Deriu and Cieliebak, 2018) and byte pair encodings have also been used (Elder, 2017; Zhang et al., 2018). However, when applying a character-based approach within a standard sequence-to-sequence model to the WebNLG and E2E datasets, the results were low. Hence we chose not to discuss them. 1 All the data, scripts and evaluation results used in this study can be found at https://gitlab.com/ shimorina/inlg-2018. 360 Proceedings of The 11th International Natural Language Generation Conference, pages 360–370, c Tilburg, The Netherlands, November 5-8, 2018. 2018 Association for Computational Ling"
W18-6543,P18-2114,0,0.0683607,") and WebNLG (second row) datasets with and without delexicalisation. 2.2 Delexicalising Datasets We derive delexicalised datasets from the original E2E and WebNLG datasets as follows. For each dataset, we replicated the delexicalisation procedure which was applied to the baseline systems developed for the E2E (Novikova et al., 2017) and for the WebNLG challenge (Gardent et al., 2017b) respectively5 . As shown in Table 1, both input data and output text were delexicalised. In E2E, only the name and near slots were delexicalised (because contrary to the other slots, spired by a recent paper by Aharoni and Goldberg (2018), which shows that the train/dev/test split may have a strong impact on how much the model learns to generalise and how much it memorises. Our study suggests the following. • Rare items strongly impact the performance of Data-to-Text generation. • Combining delexicalisation and copying yields the strongest improvements. • Copying underperforms for items not, or rarely, seen in the training data. • The content (e.g., distribution and number of named entities) and the partitioning (constraints on the test set) of the training data strongly affect the impact of both copying and delexicalisation."
W18-6543,W18-6556,0,0.378992,"hat the impact of these two mechanisms greatly varies depending on how the dataset is constructed and on how it is split into train, dev and test1 . 1 Introduction The input to data-to-text generation often contains rare items, i.e. low frequency items such as names, locations and dates. This makes it difficult for neural models to predict their verbalisation. To address these issues, neural approaches to datato-text generation typically resort either to delexicalisation (Wen et al., 2015; Duˇsek and Jurcicek, 2015; Trisedya et al., 2018; Chen et al., 2018) or to a copy mechanism (Chen, 2018; Elder et al., 2018; Gehrmann et al., 2018). Character-based encodings (Agarwal and Dymetman, 2017; Deriu and Cieliebak, 2018) and byte pair encodings have also been used (Elder, 2017; Zhang et al., 2018). However, when applying a character-based approach within a standard sequence-to-sequence model to the WebNLG and E2E datasets, the results were low. Hence we chose not to discuss them. 1 All the data, scripts and evaluation results used in this study can be found at https://gitlab.com/ shimorina/inlg-2018. 360 Proceedings of The 11th International Natural Language Generation Conference, pages 360–370, c Tilbur"
W18-6543,P17-1017,1,0.876096,"ta-to-text generation (Gehrmann et al., 2018; Chen et al., 2018) is a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. In this paper, we investigate the impact of copying and delexicalisation on the quality of generated texts using two sequence-to-sequence models with attention: one using the copy and coverage mechanism of See et al. (2017), the other using delexicalisation. We evaluate their respective output on two data-to-text datasets, namely the E2E (Novikova et al., 2017) and the WebNLG (Gardent et al., 2017a) datasets. We also compare the two methods in two different settings: the original train/dev/test partition produced by the E2E and by the WebNLG challenge vs. a more constrained train/dev/test split which aims to further minimise the amount of redundancy between train, dev and test data. This latter experimental setting is inNeural approaches to data-to-text generation generally handle rare input items using either delexicalisation or a copy mechanism. We investigate the relative impact of these two methods on two datasets (E2E and WebNLG) and using two evaluation settings. We show (i) that"
W18-6543,W17-3518,1,0.903581,"ta-to-text generation (Gehrmann et al., 2018; Chen et al., 2018) is a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. In this paper, we investigate the impact of copying and delexicalisation on the quality of generated texts using two sequence-to-sequence models with attention: one using the copy and coverage mechanism of See et al. (2017), the other using delexicalisation. We evaluate their respective output on two data-to-text datasets, namely the E2E (Novikova et al., 2017) and the WebNLG (Gardent et al., 2017a) datasets. We also compare the two methods in two different settings: the original train/dev/test partition produced by the E2E and by the WebNLG challenge vs. a more constrained train/dev/test split which aims to further minimise the amount of redundancy between train, dev and test data. This latter experimental setting is inNeural approaches to data-to-text generation generally handle rare input items using either delexicalisation or a copy mechanism. We investigate the relative impact of these two methods on two datasets (E2E and WebNLG) and using two evaluation settings. We show (i) that"
W18-6543,P16-1046,0,0.193831,"ssing. While this method is often used, it has several drawbacks. It requires an additional pre- and post-processing step. These processing steps must be re-implemented for each new data-to-text application. The matching procedure needed to correctly match a rare input item (e.g., Barack Obama) with the corresponding part in the output text (e.g., the former President of the United States) may be quite complex which may result in incorrect or incomplete delexicalisations. In contrast, the copy mechanisms standardly used in neural approaches to summarisation (See et al., 2017; Gu et al., 2016; Cheng and Lapata, 2016), paraphrasing (Cao et al., 2017), answer generation (He et al., 2017) and data-to-text generation (Gehrmann et al., 2018; Chen et al., 2018) is a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. In this paper, we investigate the impact of copying and delexicalisation on the quality of generated texts using two sequence-to-sequence models with attention: one using the copy and coverage mechanism of See et al. (2017), the other using delexicalisation. We evaluate their respective output on two d"
W18-6543,P16-1154,0,0.214896,"t during preprocessing. While this method is often used, it has several drawbacks. It requires an additional pre- and post-processing step. These processing steps must be re-implemented for each new data-to-text application. The matching procedure needed to correctly match a rare input item (e.g., Barack Obama) with the corresponding part in the output text (e.g., the former President of the United States) may be quite complex which may result in incorrect or incomplete delexicalisations. In contrast, the copy mechanisms standardly used in neural approaches to summarisation (See et al., 2017; Gu et al., 2016; Cheng and Lapata, 2016), paraphrasing (Cao et al., 2017), answer generation (He et al., 2017) and data-to-text generation (Gehrmann et al., 2018; Chen et al., 2018) is a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. In this paper, we investigate the impact of copying and delexicalisation on the quality of generated texts using two sequence-to-sequence models with attention: one using the copy and coverage mechanism of See et al. (2017), the other using delexicalisation. We evaluate their r"
W18-6543,W14-3348,0,0.0162746,"Missing"
W18-6543,P17-1019,0,0.289458,"an additional pre- and post-processing step. These processing steps must be re-implemented for each new data-to-text application. The matching procedure needed to correctly match a rare input item (e.g., Barack Obama) with the corresponding part in the output text (e.g., the former President of the United States) may be quite complex which may result in incorrect or incomplete delexicalisations. In contrast, the copy mechanisms standardly used in neural approaches to summarisation (See et al., 2017; Gu et al., 2016; Cheng and Lapata, 2016), paraphrasing (Cao et al., 2017), answer generation (He et al., 2017) and data-to-text generation (Gehrmann et al., 2018; Chen et al., 2018) is a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. In this paper, we investigate the impact of copying and delexicalisation on the quality of generated texts using two sequence-to-sequence models with attention: one using the copy and coverage mechanism of See et al. (2017), the other using delexicalisation. We evaluate their respective output on two data-to-text datasets, namely the E2E (Novikova et al., 2017) and the W"
W18-6543,N18-1014,0,0.0681969,"Missing"
W18-6543,P17-4012,0,0.0342123,"Cotto is a family-friendly pub with a high customer rating. Cotto {wrong}, family-friendly {added}, pub {right}, high customer rating {right}, near Burger King {missed} A Wizard of Mars – author – Diane Duane A Wizard of Mars was written in the United States in 1995. A Wizard of Mars {right}, was written {right}, in the United States {wrong}, in 1995 {added}. Table 4: Manual annotation of text predictions for E2E and WebNLG data. Annotations are between curly braces. of an LSTM encoder-decoder model with attention (Luong et al., 2015) from the OpenNMT-py toolkit6 , a PyTorch port of OpenNMT (Klein et al., 2017). The default parameters of OpenNMT-py were used for training and decoding. The encoder and decoder both have two layers. Models were trained for 13 epochs, with a mini-batch size of 64, a dropout rate of 0.3, and a word embedding size of 500. They were optimised with SGD with a starting learning rate of 1.0. Data was not lowercased, nor was it truncated (the maximal sequence length was used in the source and target). Special options available in OpenNMT-py were used to augment the standard model with the copy and the coverage mechanisms. The OpenNMTpy implementation of training additional cop"
W18-6543,D15-1199,0,0.102403,"Missing"
W18-6543,W04-1013,0,0.0135662,"tion was finished, the human annotator confirmed that, except for one system (see Section 3), all system outputs demonstrated fluent and grammatical English sentences. Once presented with an input and a corresponding prediction text, a human judge was asked to evaluate semantic information present in the prediction. A minimal unit of analysis was a slotvalue pair in E2E and an RDF triple element (subEvaluation Automatic Evaluation Systems were evaluated using four automatic corpus-based metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Denkowski and Lavie, 2014), ROUGEL (Lin, 2004). We made use of the scripts used for the E2E Challenge evaluation7 . The first three metrics were originally developed for machine translation, the last one for summarisation. Roughly speaking, BLEU calculates the n-gram precision; NIST is based on BLEU, but adds more weight to rarer n-grams; METEOR computes the harmonic mean of precision and recall, featuring also stem and synonymy matching; ROUGEL calculates recall for common longest subsequences in a reference and candidate text. Given our task— handling rare items (or named entities in the corpora in question)—we also applied the slot-err"
W18-6543,D15-1166,0,0.0651032,"annotation name[Cocum], eatType[pub], customer rating[high], near[Burger King] Cotto is a family-friendly pub with a high customer rating. Cotto {wrong}, family-friendly {added}, pub {right}, high customer rating {right}, near Burger King {missed} A Wizard of Mars – author – Diane Duane A Wizard of Mars was written in the United States in 1995. A Wizard of Mars {right}, was written {right}, in the United States {wrong}, in 1995 {added}. Table 4: Manual annotation of text predictions for E2E and WebNLG data. Annotations are between curly braces. of an LSTM encoder-decoder model with attention (Luong et al., 2015) from the OpenNMT-py toolkit6 , a PyTorch port of OpenNMT (Klein et al., 2017). The default parameters of OpenNMT-py were used for training and decoding. The encoder and decoder both have two layers. Models were trained for 13 epochs, with a mini-batch size of 64, a dropout rate of 0.3, and a word embedding size of 500. They were optimised with SGD with a starting learning rate of 1.0. Data was not lowercased, nor was it truncated (the maximal sequence length was used in the source and target). Special options available in OpenNMT-py were used to augment the standard model with the copy and th"
W18-6543,W17-5525,0,0.049199,"Missing"
W18-6543,P02-1040,0,0.100645,"Missing"
W18-6543,W18-6557,0,0.0347859,"Missing"
W18-6543,P17-1099,0,0.576805,"nitial values built during preprocessing. While this method is often used, it has several drawbacks. It requires an additional pre- and post-processing step. These processing steps must be re-implemented for each new data-to-text application. The matching procedure needed to correctly match a rare input item (e.g., Barack Obama) with the corresponding part in the output text (e.g., the former President of the United States) may be quite complex which may result in incorrect or incomplete delexicalisations. In contrast, the copy mechanisms standardly used in neural approaches to summarisation (See et al., 2017; Gu et al., 2016; Cheng and Lapata, 2016), paraphrasing (Cao et al., 2017), answer generation (He et al., 2017) and data-to-text generation (Gehrmann et al., 2018; Chen et al., 2018) is a generic technique which is easy to integrate in the encoder-decoder framework and can be used independently of the particular domain and application. In this paper, we investigate the impact of copying and delexicalisation on the quality of generated texts using two sequence-to-sequence models with attention: one using the copy and coverage mechanism of See et al. (2017), the other using delexicalisation. We"
W18-6543,P18-1151,0,0.394954,"ovement; (iii) that copying underperforms for rare and unseen items and (iv) that the impact of these two mechanisms greatly varies depending on how the dataset is constructed and on how it is split into train, dev and test1 . 1 Introduction The input to data-to-text generation often contains rare items, i.e. low frequency items such as names, locations and dates. This makes it difficult for neural models to predict their verbalisation. To address these issues, neural approaches to datato-text generation typically resort either to delexicalisation (Wen et al., 2015; Duˇsek and Jurcicek, 2015; Trisedya et al., 2018; Chen et al., 2018) or to a copy mechanism (Chen, 2018; Elder et al., 2018; Gehrmann et al., 2018). Character-based encodings (Agarwal and Dymetman, 2017; Deriu and Cieliebak, 2018) and byte pair encodings have also been used (Elder, 2017; Zhang et al., 2018). However, when applying a character-based approach within a standard sequence-to-sequence model to the WebNLG and E2E datasets, the results were low. Hence we chose not to discuss them. 1 All the data, scripts and evaluation results used in this study can be found at https://gitlab.com/ shimorina/inlg-2018. 360 Proceedings of The 11th In"
W18-6543,P16-1008,0,0.0521317,"Missing"
W19-3706,W18-6521,0,0.0220354,". See, for instance, Popovi´c (2018) who provides an overview of different approaches to error classification. We also got some ideas from studies focused on errors made by language learners and non-experienced translators in the Russian-English and English-Russian translation directions (Kunilovskaya, 2013; Rakhilina et al., 2016; Komalova, 2017). That allowed us to extend the classification with some phenomena typical for Russian. Lastly, the classification Creating a Russian Version of the WebNLG Dataset 4.1 Manual Post-Editing and Error Analysis Neural Machine Translation Following Castro Ferreira et al. (2018), who created a silver-standard German version of WebNLG, we translated the WebNLG English texts into Russian using the English-Russian NMT system developed by the University of Edinburgh for the WMT17 translation shared task (Sennrich et al., 2017).2 This system ranks first for the English-Russian News translation task both in 2 http://data.statmt.org/wmt17_systems/ Specifically, we use their ensemble model consisting of four left-to-right models. 3 http://matrix.statmt.org/matrix/ systems_list/1875 45 Category Grammar Vocabulary Structure Subcategory Case marking Copula Verbal aspect Preposi"
W19-3706,P17-1017,1,0.844625,"Missing"
W19-3706,W18-6467,0,0.0309881,"Missing"
W19-3706,P17-4012,0,0.0752987,"Missing"
W19-3706,P02-1040,0,0.104041,"hmidhuber, 1997) is used for both encoder and decoder. We trained using full vocabulary and the maximal length in the source and target; all the hyperparameters were tuned on the development set. The APE model was trained with a mini-batch size of 32, a word embedding size of 512, and a hidden unit size of 512. It was optimised with Adam with a starting learning rate of 0.0005. We used early stopping based on BLEU on the development set, as a result of that, the model was trained for 23 epochs. Decoding was done using beam search with a beam size of 5. As an evaluation metric, we used BLEU-4 (Papineni et al., 2002) calculated between our model predictions and RPE. BLEU and statistical significance were calculated on tokenised texts using COMPARE - MT tool (Neubig et al., 2019), which, in turn, uses the NLTK implementation of BLEU. Results are shown in Table 5. The APE model performance reached parity with the baseline on dev and test data. The difference between scores was not statistically significant via the bootstrap resampling (1000 samples, p < 0.05). On the training data, the model yielded 94 BLEU, which indicates a possible overfitting. based on the errors found during manual annotation and a neu"
W19-3706,W16-6509,0,0.0452022,"Missing"
W19-3706,W16-2361,0,0.0820221,"Missing"
W19-3706,D15-1166,0,0.11133,"Missing"
W19-3706,D17-1064,1,0.832156,"aracter category, its Russian translation (MT), and postedited translation (PE) along with error annotation. Errors are highlighted in blue. Links are RDF triples of the form <English entity, sameAs, Russian entity&gt;. However, such links are not available for all entities in DBpedia. automatic metrics3 and human assessment (Bojar et al., 2017). It is learned using Nematus, an encoder-decoder with attention, based on subword units (byte pair encoding). Since the Edinburgh model was trained on sentence-to-sentence data, we split WebNLG texts into sentences using the WebSplit sentence annotation (Narayan et al., 2017), input each sentence to the NMT system, and then concatenated translations to reconstruct the target texts. sets of (one to seven) RDF triples of the form <subject, property, object&gt;. Textual descriptions are in English, and due to the nature of the knowledge graphs, they have an abundance of named entities. The first two lines of Table 1 show an example of a WebNLG instance. WebNLG provides textual descriptions for entities in fifteen DBpedia categories (Airport, Artist, Astronaut, Athlete, Building, CelestialBody, City, ComicsCharacter, Food, MeanOfTransportation, Monument, Politician, Spor"
W19-3706,L18-1004,0,0.0821628,"Missing"
W19-3706,N19-4007,0,0.0142177,"uned on the development set. The APE model was trained with a mini-batch size of 32, a word embedding size of 512, and a hidden unit size of 512. It was optimised with Adam with a starting learning rate of 0.0005. We used early stopping based on BLEU on the development set, as a result of that, the model was trained for 23 epochs. Decoding was done using beam search with a beam size of 5. As an evaluation metric, we used BLEU-4 (Papineni et al., 2002) calculated between our model predictions and RPE. BLEU and statistical significance were calculated on tokenised texts using COMPARE - MT tool (Neubig et al., 2019), which, in turn, uses the NLTK implementation of BLEU. Results are shown in Table 5. The APE model performance reached parity with the baseline on dev and test data. The difference between scores was not statistically significant via the bootstrap resampling (1000 samples, p < 0.05). On the training data, the model yielded 94 BLEU, which indicates a possible overfitting. based on the errors found during manual annotation and a neural approach. 5.1 Rule Based Post-Editing Based on the manual corrections applied to the 1-triple data (WebNLG instances where the input graph consists of a single t"
W19-3706,P16-2046,0,0.0429933,"Missing"
W19-8614,N06-2001,0,0.14471,"Missing"
W19-8614,F12-5001,0,0.0280058,"Missing"
W19-8614,W13-2322,0,0.0433651,"tches a reference using BLEU as evaluation criteria. In this paper, we additionally consider the model’s ability to reintroduce the function words that are absent from the deep input meaning representations. We show that our approach increases both BLEU score and the scores used to assess function words generation. 1 2 SR Corpora Various datasets have been introduced to support the learning of surface realisers. The 2017 AMR SemEval generation shared task (May and Priyadarshi, 2017) provides a parallel corpus where the input semantic representations are AMRs (Abstract Meaning Representation, (Banarescu et al., 2013)) and the task is to generate a sentence verbalising that AMR. Mille et al. (2018) derived multilingual MR-toText datasets from the UD (Universal Dependencies) treebanks2 creating two types of input, shallow and deep. In the shallow input, the nodes of the UD dependency tree are scrambled to remove word order information and words are replaced by their lemmas. The generation task consists in ordering and inflecting the lemmas decorating the input tree. The deep input is closer to an applicative context. It abstracts away from the surface form by removing additional information from the UD tree"
W19-8614,N19-1238,0,0.0341916,"Missing"
W19-8614,P18-1026,0,0.0364782,"Missing"
W19-8614,P17-1014,0,0.0274774,"Gautier wanted to impress Belles-Isle by some revelations) 113 SR Models. Using the parallel MR-to-text corpora just described, various SR models have been proposed. We focus here on SR from deep meaning representations (AMRs and SR’18 deep track MRs) as this is closest to our proposal. Early work on MR-to-text generation linearise the input graph and use various statistical methods to generate text (Flanigan et al., 2016; Song et al., 2017; Pourdamghani et al., 2016; Bohnet et al., 2010). Similarly, early neural approaches linearise the input graph and use a sequence-to-sequence (S2S) model. Konstas et al. (2017) achieve strong results on the AMR-to-text task by using data expansion and anonymising data entities while Cao and Clark (2019) additionally leverages syntactic information to improve performance. On the deep SR data, (Elder and Hokamp, 2018) uses data expansion and a factored S2S model. Graph-to-sequence models have also been proposed using various graph encoders and testing on different datasets Marcheggiani and PerezBeltrachini (2018); Song et al. (2018); Beck et al. (2018); Koncel-Kedziorski et al. (2019); Veliˇckovi´c et al. (2018). Our approach is closest to the S2S model used by Elder"
W19-8614,W18-6501,0,0.0621791,"Missing"
W19-8614,S17-2090,0,0.021742,"to generalise by abstracting away from lexical content. Most current work on natural language generation focuses on generating text that matches a reference using BLEU as evaluation criteria. In this paper, we additionally consider the model’s ability to reintroduce the function words that are absent from the deep input meaning representations. We show that our approach increases both BLEU score and the scores used to assess function words generation. 1 2 SR Corpora Various datasets have been introduced to support the learning of surface realisers. The 2017 AMR SemEval generation shared task (May and Priyadarshi, 2017) provides a parallel corpus where the input semantic representations are AMRs (Abstract Meaning Representation, (Banarescu et al., 2013)) and the task is to generate a sentence verbalising that AMR. Mille et al. (2018) derived multilingual MR-toText datasets from the UD (Universal Dependencies) treebanks2 creating two types of input, shallow and deep. In the shallow input, the nodes of the UD dependency tree are scrambled to remove word order information and words are replaced by their lemmas. The generation task consists in ordering and inflecting the lemmas decorating the input tree. The dee"
W19-8614,W18-3601,0,0.0198288,"nsider the model’s ability to reintroduce the function words that are absent from the deep input meaning representations. We show that our approach increases both BLEU score and the scores used to assess function words generation. 1 2 SR Corpora Various datasets have been introduced to support the learning of surface realisers. The 2017 AMR SemEval generation shared task (May and Priyadarshi, 2017) provides a parallel corpus where the input semantic representations are AMRs (Abstract Meaning Representation, (Banarescu et al., 2013)) and the task is to generate a sentence verbalising that AMR. Mille et al. (2018) derived multilingual MR-toText datasets from the UD (Universal Dependencies) treebanks2 creating two types of input, shallow and deep. In the shallow input, the nodes of the UD dependency tree are scrambled to remove word order information and words are replaced by their lemmas. The generation task consists in ordering and inflecting the lemmas decorating the input tree. The deep input is closer to an applicative context. It abstracts away from the surface form by removing additional information from the UD tree and replacing syntactic edge labels with ProbBank/NomBank labels. Finally, (Novik"
W19-8614,W17-5525,0,0.025125,"2018) derived multilingual MR-toText datasets from the UD (Universal Dependencies) treebanks2 creating two types of input, shallow and deep. In the shallow input, the nodes of the UD dependency tree are scrambled to remove word order information and words are replaced by their lemmas. The generation task consists in ordering and inflecting the lemmas decorating the input tree. The deep input is closer to an applicative context. It abstracts away from the surface form by removing additional information from the UD tree and replacing syntactic edge labels with ProbBank/NomBank labels. Finally, (Novikova et al., 2017) introduce a dataset where the input MRs are dialog moves. All these datasets were expensive to build as they require extensive human intervention. The AMR datasets were built by manually annotating sentences with AMRs, the SR datasets were derived from hand-annotated treebanks and (Novikova et al., 2017)’s dialog moves were associated with text using crowdsourcing. Moreover, except for the SR task, these datasets all focus on English. In short, we depart from previous work in that we introduce a new dataset for French which is automatically derived from text using parsers. Introduction Surfac"
W19-8614,W18-6319,0,0.0272429,"Missing"
W19-8614,W16-6603,0,0.019446,"guistics Figure 1: Example Input Meaning Representation and Linearizations for the sentence Gautier voulut impressionner Belles-Isle par des révélations (Gautier wanted to impress Belles-Isle by some revelations) 113 SR Models. Using the parallel MR-to-text corpora just described, various SR models have been proposed. We focus here on SR from deep meaning representations (AMRs and SR’18 deep track MRs) as this is closest to our proposal. Early work on MR-to-text generation linearise the input graph and use various statistical methods to generate text (Flanigan et al., 2016; Song et al., 2017; Pourdamghani et al., 2016; Bohnet et al., 2010). Similarly, early neural approaches linearise the input graph and use a sequence-to-sequence (S2S) model. Konstas et al. (2017) achieve strong results on the AMR-to-text task by using data expansion and anonymising data entities while Cao and Clark (2019) additionally leverages syntactic information to improve performance. On the deep SR data, (Elder and Hokamp, 2018) uses data expansion and a factored S2S model. Graph-to-sequence models have also been proposed using various graph encoders and testing on different datasets Marcheggiani and PerezBeltrachini (2018); Song e"
W19-8614,P17-2002,0,0.0202345,"r Computational Linguistics Figure 1: Example Input Meaning Representation and Linearizations for the sentence Gautier voulut impressionner Belles-Isle par des révélations (Gautier wanted to impress Belles-Isle by some revelations) 113 SR Models. Using the parallel MR-to-text corpora just described, various SR models have been proposed. We focus here on SR from deep meaning representations (AMRs and SR’18 deep track MRs) as this is closest to our proposal. Early work on MR-to-text generation linearise the input graph and use various statistical methods to generate text (Flanigan et al., 2016; Song et al., 2017; Pourdamghani et al., 2016; Bohnet et al., 2010). Similarly, early neural approaches linearise the input graph and use a sequence-to-sequence (S2S) model. Konstas et al. (2017) achieve strong results on the AMR-to-text task by using data expansion and anonymising data entities while Cao and Clark (2019) additionally leverages syntactic information to improve performance. On the deep SR data, (Elder and Hokamp, 2018) uses data expansion and a factored S2S model. Graph-to-sequence models have also been proposed using various graph encoders and testing on different datasets Marcheggiani and Pere"
W19-8614,P18-1150,0,0.0363154,"Missing"
W19-8614,D15-1199,0,0.130374,"Missing"
W19-8635,W18-3606,0,0.230378,"inlin 268 Proceedings of The 12th International Conference on Natural Language Generation, pages 268–278, c Tokyo, Japan, 28 Oct - 1 Nov, 2019. 2019 Association for Computational Linguistics Data split Train Dev Test ar cs en es 6,016 897 676 66,485 9,016 9,876 12,375 1,978 2,061 14,289 1,651 1,719 Language fi fr 12,030 1,336 1,525 14,529 1,473 416 it nl pt ru 12,796 562 480 12,318 720 685 8,325 559 476 48,119 6,441 6,366 Table 1: Number of sentences in SR’18 datasets (Mille et al., 2018). 2 Task Description techniques performing more global input-output mapping (Castro Ferreira et al., 2018; Elder and Hokamp, 2018). The former approaches traverse the input tree, encode nodes using sparse manually defined feature sets as input representations and generate a sentence by extending a candidate hypothesis with an input word that has the highest score among other input words that have not yet been processed. These approaches rely on the observation that natural language production has a preference for shorter dependencies (Gibson, 2000; White and Rajkumar, 2012; King and White, 2018), which facilitates building sentences incrementally. The NLP community organized two Surface Realization Shared Tasks (in 2011"
W19-8635,P17-1183,0,0.167773,"-resource scenario: Table 1 shows that the treebanks are rather small, which poses a challenge for training complex neural models. 3 Related Work The two best-performing approaches in the task of generating sentences from dependency trees have been feature-based incremental text generation (Bohnet et al., 2010; Liu et al., 2015; Puduppully et al., 2016; King and White, 2018) and 2 http://universaldependencies.org/ 269 Property Data efficiency Rich context representation Interpretability Language coverage form much better than similar systems which learn the alignment information from scratch (Aharoni and Goldberg, 2017). The success of the encoder-decoder paradigm has given birth to a prominent research trend of finding various ways of utilizing the abundant data on the web. While looking for ways to acquire more data for training even larger models is a promising research topic, an orthogonal direction is pursuing the question of how to design and train more data-efficient models. Our work focuses on this latter point and attempts to address it via data analysis and algorithm design. Taking this into consideration, we build upon the work done by Puzikov and Gurevych (2018), and attempt to improve their meth"
W19-8635,W17-3518,1,0.855413,"of encoderdecoder (Cho et al., 2014) and sequence-tosequence (seq2seq) (Sutskever et al., 2014) neural architectures, this line of work has gained a lot of popularity due to the method’s simplicity: the input string is encoded into a dense vector and a sentence is being generated token-by-token from the encoded input representation. From an NLP perspective, one of the main research problems in this paradigm has become the choice of the graph encoding strategy. The most popular method is linearizing it into a sequence of tokens and encoding using a variant of a recurrent neural network (RNN) (Gardent et al., 2017; Castro Ferreira et al., 2017; Konstas et al., 2017). Another prominent approach is using graph-to-text neural networks (Song et al., 2018; Trisedya et al., 2018). These methods have shown good results across various tasks, but in the context of surface realization they produced somewhat mixed results: the former ones were successfully used only when being trained on large amounts of data (Elder and Hokamp, 2018), while the latter ones have been only evaluated on the SR’11 Deep Track data and, while performing better than RNN-type encoders, fell short behind feature-based methods (MarchegShal"
W19-8635,W11-2832,0,0.0990045,"ering and morphological inflection steps of the surface linearization process. From a research perspective, this offers greater control over the problem-solving procedure. Introduction Natural Language Generation (NLG) is the task of generating natural language utterances from various data representations. In this work we consider lemmatized dependency trees as input and focus on the process of transforming a dependency tree into a linearly-ordered grammatical string of morphologically inflected words – the setup which is most commonly known as surface realization (SR) (Langkilde-Geary, 2002; Belz et al., 2011). Most surface realization approaches fall into two main groups: feature-based incremental generation pipelines and end-to-end neural approaches. To predict a correct token sequence, In this work we extend B IN L IN along two orthogonal directions. First, we propose a way to enrich the training data, which largely compensates for the small size of the datasets used in the task. Second, we propose a new input encoding strategy which incorporates both local and global prediction contexts. These modifications bridge the performance gap between B IN L IN and endto-end black-box approaches, while r"
W19-8635,W18-3605,0,0.359997,"Mille et al., 2018). 2 Task Description techniques performing more global input-output mapping (Castro Ferreira et al., 2018; Elder and Hokamp, 2018). The former approaches traverse the input tree, encode nodes using sparse manually defined feature sets as input representations and generate a sentence by extending a candidate hypothesis with an input word that has the highest score among other input words that have not yet been processed. These approaches rely on the observation that natural language production has a preference for shorter dependencies (Gibson, 2000; White and Rajkumar, 2012; King and White, 2018), which facilitates building sentences incrementally. The NLP community organized two Surface Realization Shared Tasks (in 2011 and 2018) which aimed at developing a common representation that could be used by a variety of NLG systems as input (Belz et al., 2011). They used almost identical task definitions, but different datasets. We focus on the latest task (SR’18 (Mille et al., 2018)), because the former was confined to using English data only, while the latter included Arabic, Czech, Dutch, English, Finnish, French, Italian, Portuguese, Russian and Spanish Universal Dependencies (UD, versi"
W19-8635,C10-1012,0,0.0214058,"on labels. We focus on the Shallow Track, because it covers more languages than the Deep Track (only three), and is therefore more interesting to study the problem of word ordering and morphological inflection as two steps of the surface realization process. The task can be considered as operating under low-resource scenario: Table 1 shows that the treebanks are rather small, which poses a challenge for training complex neural models. 3 Related Work The two best-performing approaches in the task of generating sentences from dependency trees have been feature-based incremental text generation (Bohnet et al., 2010; Liu et al., 2015; Puduppully et al., 2016; King and White, 2018) and 2 http://universaldependencies.org/ 269 Property Data efficiency Rich context representation Interpretability Language coverage form much better than similar systems which learn the alignment information from scratch (Aharoni and Goldberg, 2017). The success of the encoder-decoder paradigm has given birth to a prominent research trend of finding various ways of utilizing the abundant data on the web. While looking for ways to acquire more data for training even larger models is a promising research topic, an orthogonal dire"
W19-8635,W17-3204,0,0.0302366,"f the workshop. The authors identified the lack of sufficient training data as the major obstacle to training highperforming neural models and mentioned that the system trained only on the original dataset failed to deliver sensible outputs. These results are supported by the work done in other NLP fields. For example, in the machine translation community researchers have found that neural models have a much slower learning curve with respect to the amount of training data, which usually manifests itself as worse quality in low-resource settings, but better performance in high-resource cases (Koehn and Knowles, 2017). In morphological inflection, when trained on small datasets, seq2seq models with additional external (noisy) alignments per4 Approach Description Before explaining our work, we briefly recap how B IN L IN works. It is a pipeline system which generates a sentence from a dependency tree in two stages: 1. Syntactic ordering: convert dependency tree into a binary tree, then traverse the latter to obtain a sequence of lemmas. 2. Morphological inflection: conjugate each lemma into a surface form. Figure 1 shows a schematic view of the first stage. It relies on the procedure which first runs a brea"
W19-8635,W17-3501,0,0.0131435,"., 2014) and sequence-tosequence (seq2seq) (Sutskever et al., 2014) neural architectures, this line of work has gained a lot of popularity due to the method’s simplicity: the input string is encoded into a dense vector and a sentence is being generated token-by-token from the encoded input representation. From an NLP perspective, one of the main research problems in this paradigm has become the choice of the graph encoding strategy. The most popular method is linearizing it into a sequence of tokens and encoding using a variant of a recurrent neural network (RNN) (Gardent et al., 2017; Castro Ferreira et al., 2017; Konstas et al., 2017). Another prominent approach is using graph-to-text neural networks (Song et al., 2018; Trisedya et al., 2018). These methods have shown good results across various tasks, but in the context of surface realization they produced somewhat mixed results: the former ones were successfully used only when being trained on large amounts of data (Elder and Hokamp, 2018), while the latter ones have been only evaluated on the SR’11 Deep Track data and, while performing better than RNN-type encoders, fell short behind feature-based methods (MarchegShallow Track: unordered dependenc"
W19-8635,P17-1014,0,0.0227524,"osequence (seq2seq) (Sutskever et al., 2014) neural architectures, this line of work has gained a lot of popularity due to the method’s simplicity: the input string is encoded into a dense vector and a sentence is being generated token-by-token from the encoded input representation. From an NLP perspective, one of the main research problems in this paradigm has become the choice of the graph encoding strategy. The most popular method is linearizing it into a sequence of tokens and encoding using a variant of a recurrent neural network (RNN) (Gardent et al., 2017; Castro Ferreira et al., 2017; Konstas et al., 2017). Another prominent approach is using graph-to-text neural networks (Song et al., 2018; Trisedya et al., 2018). These methods have shown good results across various tasks, but in the context of surface realization they produced somewhat mixed results: the former ones were successfully used only when being trained on large amounts of data (Elder and Hokamp, 2018), while the latter ones have been only evaluated on the SR’11 Deep Track data and, while performing better than RNN-type encoders, fell short behind feature-based methods (MarchegShallow Track: unordered dependency trees consisting of l"
W19-8635,W18-3604,0,0.0995046,"/ inlg2019-revisiting-binlin 268 Proceedings of The 12th International Conference on Natural Language Generation, pages 268–278, c Tokyo, Japan, 28 Oct - 1 Nov, 2019. 2019 Association for Computational Linguistics Data split Train Dev Test ar cs en es 6,016 897 676 66,485 9,016 9,876 12,375 1,978 2,061 14,289 1,651 1,719 Language fi fr 12,030 1,336 1,525 14,529 1,473 416 it nl pt ru 12,796 562 480 12,318 720 685 8,325 559 476 48,119 6,441 6,366 Table 1: Number of sentences in SR’18 datasets (Mille et al., 2018). 2 Task Description techniques performing more global input-output mapping (Castro Ferreira et al., 2018; Elder and Hokamp, 2018). The former approaches traverse the input tree, encode nodes using sparse manually defined feature sets as input representations and generate a sentence by extending a candidate hypothesis with an input word that has the highest score among other input words that have not yet been processed. These approaches rely on the observation that natural language production has a preference for shorter dependencies (Gibson, 2000; White and Rajkumar, 2012; King and White, 2018), which facilitates building sentences incrementally. The NLP community organized two Surface Realizati"
W19-8635,W02-2103,0,0.075576,"is of the syntactic ordering and morphological inflection steps of the surface linearization process. From a research perspective, this offers greater control over the problem-solving procedure. Introduction Natural Language Generation (NLG) is the task of generating natural language utterances from various data representations. In this work we consider lemmatized dependency trees as input and focus on the process of transforming a dependency tree into a linearly-ordered grammatical string of morphologically inflected words – the setup which is most commonly known as surface realization (SR) (Langkilde-Geary, 2002; Belz et al., 2011). Most surface realization approaches fall into two main groups: feature-based incremental generation pipelines and end-to-end neural approaches. To predict a correct token sequence, In this work we extend B IN L IN along two orthogonal directions. First, we propose a way to enrich the training data, which largely compensates for the small size of the datasets used in the task. Second, we propose a new input encoding strategy which incorporates both local and global prediction contexts. These modifications bridge the performance gap between B IN L IN and endto-end black-box"
W19-8635,D14-1179,0,0.0113457,"Missing"
W19-8635,N15-1012,0,0.105683,"n the Shallow Track, because it covers more languages than the Deep Track (only three), and is therefore more interesting to study the problem of word ordering and morphological inflection as two steps of the surface realization process. The task can be considered as operating under low-resource scenario: Table 1 shows that the treebanks are rather small, which poses a challenge for training complex neural models. 3 Related Work The two best-performing approaches in the task of generating sentences from dependency trees have been feature-based incremental text generation (Bohnet et al., 2010; Liu et al., 2015; Puduppully et al., 2016; King and White, 2018) and 2 http://universaldependencies.org/ 269 Property Data efficiency Rich context representation Interpretability Language coverage form much better than similar systems which learn the alignment information from scratch (Aharoni and Goldberg, 2017). The success of the encoder-decoder paradigm has given birth to a prominent research trend of finding various ways of utilizing the abundant data on the web. While looking for ways to acquire more data for training even larger models is a promising research topic, an orthogonal direction is pursuing"
W19-8635,D12-1023,0,0.0173889,"tences in SR’18 datasets (Mille et al., 2018). 2 Task Description techniques performing more global input-output mapping (Castro Ferreira et al., 2018; Elder and Hokamp, 2018). The former approaches traverse the input tree, encode nodes using sparse manually defined feature sets as input representations and generate a sentence by extending a candidate hypothesis with an input word that has the highest score among other input words that have not yet been processed. These approaches rely on the observation that natural language production has a preference for shorter dependencies (Gibson, 2000; White and Rajkumar, 2012; King and White, 2018), which facilitates building sentences incrementally. The NLP community organized two Surface Realization Shared Tasks (in 2011 and 2018) which aimed at developing a common representation that could be used by a variety of NLG systems as input (Belz et al., 2011). They used almost identical task definitions, but different datasets. We focus on the latest task (SR’18 (Mille et al., 2018)), because the former was confined to using English data only, while the latter included Arabic, Czech, Dutch, English, Finnish, French, Italian, Portuguese, Russian and Spanish Universal"
W19-8635,W18-6501,0,0.0361472,"Missing"
W19-8635,W18-3601,0,0.0156982,"-end black-box approaches, while retaining its interpretability advantages. 1 https://github.com/UKPLab/ inlg2019-revisiting-binlin 268 Proceedings of The 12th International Conference on Natural Language Generation, pages 268–278, c Tokyo, Japan, 28 Oct - 1 Nov, 2019. 2019 Association for Computational Linguistics Data split Train Dev Test ar cs en es 6,016 897 676 66,485 9,016 9,876 12,375 1,978 2,061 14,289 1,651 1,719 Language fi fr 12,030 1,336 1,525 14,529 1,473 416 it nl pt ru 12,796 562 480 12,318 720 685 8,325 559 476 48,119 6,441 6,366 Table 1: Number of sentences in SR’18 datasets (Mille et al., 2018). 2 Task Description techniques performing more global input-output mapping (Castro Ferreira et al., 2018; Elder and Hokamp, 2018). The former approaches traverse the input tree, encode nodes using sparse manually defined feature sets as input representations and generate a sentence by extending a candidate hypothesis with an input word that has the highest score among other input words that have not yet been processed. These approaches rely on the observation that natural language production has a preference for shorter dependencies (Gibson, 2000; White and Rajkumar, 2012; King and White, 201"
W19-8635,P02-1040,0,0.104067,"85.6 92.85 85.56 Table 3: The distribution of left/right labels in the training data and the accuracy of predicting a node’s relative position with the binary classifier. Two cases are considered: predicting the position of a dependent w.r.t. its head (head-dep), and a sibling (dep-dep). BLEU EDIST NIST B IN L IN + data enrichment + new encoder + new features 24.92 48.47 50.67 51.15 35.91 62.04 64.05 64.78 9.55 10.72 10.82 10.82 Upper bound 65.31 85.52 11.38 dency locality hypothesis. We trained the syntactic ordering component and performed its automatic metric evaluation by computing BLEU (Papineni et al., 2002)3 , NIST (Doddington, 2002) and normalized string edit distance (EDIST) scores between the references and system outputs. Note that system outputs contain ordered lemmas, not surface forms, while the references are correctly ordered sequences of inflected surface forms given in the CONLL file. Table 4 shows the contribution of each of the modifications that we propose in this work; the results are computed on the English SR’18 development set. We also show the maximum metric scores that an ideal syntactic ordering component would get, i.e. an upper bound on its performance. We computed it by r"
W19-8635,N16-1058,0,0.0166486,"k, because it covers more languages than the Deep Track (only three), and is therefore more interesting to study the problem of word ordering and morphological inflection as two steps of the surface realization process. The task can be considered as operating under low-resource scenario: Table 1 shows that the treebanks are rather small, which poses a challenge for training complex neural models. 3 Related Work The two best-performing approaches in the task of generating sentences from dependency trees have been feature-based incremental text generation (Bohnet et al., 2010; Liu et al., 2015; Puduppully et al., 2016; King and White, 2018) and 2 http://universaldependencies.org/ 269 Property Data efficiency Rich context representation Interpretability Language coverage form much better than similar systems which learn the alignment information from scratch (Aharoni and Goldberg, 2017). The success of the encoder-decoder paradigm has given birth to a prominent research trend of finding various ways of utilizing the abundant data on the web. While looking for ways to acquire more data for training even larger models is a promising research topic, an orthogonal direction is pursuing the question of how to de"
W19-8635,W18-3602,1,0.824118,"ediction accuracy. We show how enriching the training data to better capture word order constraints almost doubles the performance of the system. We further demonstrate that encoding both local and global prediction contexts yields another considerable performance boost. With the proposed modifications, the system which ranked low in the latest shared task on multilingual surface realization now achieves best results in five out of ten languages, while being on par with the state-of-the-art approaches in others. 1 1 This work builds upon B IN L IN, a binary linearization technique proposed by Puzikov and Gurevych (2018). It is a hybrid approach which uses a feature-based neural word ordering module and a sequence-to-sequence morphological inflection component. In terms of prediction accuracy, B IN L IN falls short compared to end-to-end neural approaches, but has an advantage of being more intuitive and interpretable. It also supports separate analysis of the syntactic ordering and morphological inflection steps of the surface linearization process. From a research perspective, this offers greater control over the problem-solving procedure. Introduction Natural Language Generation (NLG) is the task of genera"
W19-8635,P18-1150,0,0.0204681,"ained a lot of popularity due to the method’s simplicity: the input string is encoded into a dense vector and a sentence is being generated token-by-token from the encoded input representation. From an NLP perspective, one of the main research problems in this paradigm has become the choice of the graph encoding strategy. The most popular method is linearizing it into a sequence of tokens and encoding using a variant of a recurrent neural network (RNN) (Gardent et al., 2017; Castro Ferreira et al., 2017; Konstas et al., 2017). Another prominent approach is using graph-to-text neural networks (Song et al., 2018; Trisedya et al., 2018). These methods have shown good results across various tasks, but in the context of surface realization they produced somewhat mixed results: the former ones were successfully used only when being trained on large amounts of data (Elder and Hokamp, 2018), while the latter ones have been only evaluated on the SR’11 Deep Track data and, while performing better than RNN-type encoders, fell short behind feature-based methods (MarchegShallow Track: unordered dependency trees consisting of lemmatized nodes with part-ofspeech (POS) tags and morphological information, as found"
W19-8635,P18-1151,0,0.0157503,"larity due to the method’s simplicity: the input string is encoded into a dense vector and a sentence is being generated token-by-token from the encoded input representation. From an NLP perspective, one of the main research problems in this paradigm has become the choice of the graph encoding strategy. The most popular method is linearizing it into a sequence of tokens and encoding using a variant of a recurrent neural network (RNN) (Gardent et al., 2017; Castro Ferreira et al., 2017; Konstas et al., 2017). Another prominent approach is using graph-to-text neural networks (Song et al., 2018; Trisedya et al., 2018). These methods have shown good results across various tasks, but in the context of surface realization they produced somewhat mixed results: the former ones were successfully used only when being trained on large amounts of data (Elder and Hokamp, 2018), while the latter ones have been only evaluated on the SR’11 Deep Track data and, while performing better than RNN-type encoders, fell short behind feature-based methods (MarchegShallow Track: unordered dependency trees consisting of lemmatized nodes with part-ofspeech (POS) tags and morphological information, as found in the UD annotations. D"
W98-0113,P83-1020,0,0.432737,"one that is preferred. For example, in plan recognition (identifying the structure of goals and subgoals that give rise to what is usually taken to be a sequence of observed actions), Kautz (Kautz, 1990) suggested a ""goal minimization"" bias that preferred a tree with the fewest goals (non-terminal nodes) able to ""explain"" the sequence of actions. Where goal minimization is known to produce the wrong explanation, some other bias is needed to yield the one that is preferred (Gertner and Webber, I 996). Similarly, in associating a preferred reading with a compact underspecified representation, (Marcus et al., 1983) proposed a bias towards a tree that minimised the dominance relation . That is, if two node names stand in a dominance relation, they are taken to refer to one and the same node, provided nothing rules it out. Ofcourse, such a ""min.dom"" bias might yield several trees, each of which are equally minimal. Typically, this is true of global ambiguities as in (6) above, where dominance can be minimised by identifying node 5 either with node 4 or with node 6, each .move resulting in an equally minimal tree. An alternative bias combines ""min.dom"" with ""right-association"" (Frazier, 1995; Chen and Vija"
W98-0113,J92-4004,0,0.478545,"tational Linguistics University of the Saarland Saarbrücken, Gerrnany claire@coli.uni-sb.de Bonnie Webber Computer and Information Science University of Pennsylvania Philadelphia PA 19104-6389 USA bonnie@central.cis.upenn.edu Descriptions. In recent years, both formal and computational linguistics have been exploiting descriptions of structures where previously the structures themselves were used. Tue practice started with (Marcus et al., 1983), who demonstrated the value of (syntactic) tree descriptions for near-deterministic incremental parsing. Vijay-Shankar (Vijay-Shankar and Joshi, 1988; Vijay-Shankar, 1992) used descriptions to maintain the monotonicity of syntactic derivations in the framework ofFeature-Based Tree Adjoining Grammar. In semantics, both (Muskens, 1997) and (Egg et al., 1997) have shown the value of descriptions as an underspecified representation of scope ambiguities. Tue current paper further extends the use of descriptions, from individual sentences to discourse, showing their benefit for incremental, near-detenninistic discourse processing. In particular, we show that using descriptions to desc~be the semantic representation of discourse penn1ts: (1) a monotone treatment of lo"
W98-0113,W98-0315,1,0.794915,"ntity from possible alternatives. We believe it is worth exploring what bias best models the preferences people have in discourse interpretation, and how it resembles their preference at the sentence level. thank Mark Steedman and Aravind Joshi for comments and suggestions. An early draft of this paper was presented at the Workshop on Underspecification, Bad Teinach, Germany, May 1998. Claire Gardent is grateful to the Deutsche Forschungsgesellschaft for financial support within the SFB 378, Comparison with related work. A related approach to discourse structure and semantics is presented in (Webber and Joshi, 1998), where Lexicalised Tree Adjoining Grammar (LTAG) is used to construct the compositional semantics of discourse. Although the basic structures used here are different, we foresee no difficulty in modifiying them in order to integrate the additional information included in the LTAG discourse trees. Essentially, the atomic labels representing the relations should be mapped into the feature structures used in (Webber and Joshi, 1998) and this information used to labe! not the root node of a local tree but its anchor. Second, the LTAG approach has focussed on describing the compositional semantics"
