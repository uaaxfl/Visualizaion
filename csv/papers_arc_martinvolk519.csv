2020.readi-1.7,Benchmarking Data-driven Automatic Text Simplification for {G}erman,2020,-1,-1,3,0,3152,andreas sauberli,Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI),0,"Automatic text simplification is an active research area, and there are first systems for English, Spanish, Portuguese, and Italian. For German, no data-driven approach exists to this date, due to a lack of training data. In this paper, we present a parallel corpus of news items in German with corresponding simplifications on two complexity levels. The simplifications have been produced according to a well-documented set of guidelines. We then report on experiments in automatically simplifying the German news items using state-of-the-art neural machine translation techniques. We demonstrate that despite our small parallel corpus, our neural models were able to learn essential features of simplified language, such as lexical substitutions, deletion of less relevant words and phrases, and sentence shortening."
2020.lrec-1.436,How Much Data Do You Need? About the Creation of a Ground Truth for Black Letter and the Effectiveness of Neural {OCR},2020,-1,-1,3,0,16862,phillip strobel,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Recent advances in Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) have led to more accurate textrecognition of historical documents. The Digital Humanities heavily profit from these developments, but they still struggle whenchoosing from the plethora of OCR systems available on the one hand and when defining workflows for their projects on the other hand.In this work, we present our approach to build a ground truth for a historical German-language newspaper published in black letter. Wealso report how we used it to systematically evaluate the performance of different OCR engines. Additionally, we used this ground truthto make an informed estimate as to how much data is necessary to achieve high-quality OCR results. The outcomes of our experimentsshow that HTR architectures can successfully recognise black letter text and that a ground truth size of 50 newspaper pages suffices toachieve good OCR accuracy. Moreover, our models perform equally well on data they have not seen during training, which means thatadditional manual correction for diverging data is superfluous."
W19-9003,Geotagging a Diachronic Corpus of Alpine Texts: Comparing Distinct Approaches to Toponym Recognition,2019,0,0,6,0,3150,tannon kew,Proceedings of the Workshop on Language Technology for Digital Historical Archives,0,"Geotagging historic and cultural texts provides valuable access to heritage data, enabling location-based searching and new geographically related discoveries. In this paper, we describe two distinct approaches to geotagging a variety of fine-grained toponyms in a diachronic corpus of alpine texts. By applying a traditional gazetteer-based approach, aided by a few simple heuristics, we attain strong high-precision annotations. Using the output of this earlier system, we adopt a state-of-the-art neural approach in order to facilitate the detection of new toponyms on the basis of context. Additionally, we present the results of preliminary experiments on integrating a small amount of crowdsourced annotations to improve overall performance of toponym recognition in our heritage corpus."
W19-6626,Post-editing Productivity with Neural Machine Translation: An Empirical Assessment of Speed and Quality in the Banking and Finance Domain,2019,24,0,6,1,20844,samuel laubli,Proceedings of Machine Translation Summit XVII: Research Track,0,"Neural machine translation (NMT) has set new quality standards in automatic translation, yet its effect on post-editing productivity is still pending thorough investigation. We empirically test how the inclusion of NMT, in addition to domain-specific translation memories and termbases, impacts speed and quality in professional translation of financial texts. We find that even with language pairs that have received little attention in research settings and small amounts of in-domain data for system adaptation, NMT post-editing allows for substantial time savings and leads to equal or slightly better quality."
D18-1512,Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation,2018,14,16,3,1,20844,samuel laubli,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Recent research suggests that neural machine translation achieves parity with professional human translation on the WMT Chinese{--}English news translation task. We empirically test this claim with alternative evaluation protocols, contrasting the evaluation of single sentences and entire documents. In a pairwise ranking experiment, human raters assessing adequacy and fluency show a stronger preference for human over machine translation when evaluating documents as compared to isolated sentences. Our findings emphasise the need to shift towards document-level evaluation as machine translation improves to the degree that errors which are hard or impossible to spot at the sentence-level become decisive in discriminating quality of different translation outputs."
W17-0231,Multilingwis{\\mbox{$^2$}} {--} Explore Your Parallel Corpus,2017,0,0,3,0,16678,johannes graen,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
L16-1155,Crowdsourcing an {OCR} Gold Standard for a {G}erman and {F}rench Heritage Corpus,2016,0,1,3,0.277778,1321,simon clematide,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Crowdsourcing approaches for post-correction of OCR output (Optical Character Recognition) have been successfully applied to several historic text collections. We report on our crowd-correction platform Kokos, which we built to improve the OCR quality of the digitized yearbooks of the Swiss Alpine Club (SAC) from the 19th century. This multilingual heritage corpus consists of Alpine texts mainly written in German and French, all typeset in Antiqua font. Finding and engaging volunteers for correcting large amounts of pages into high quality text requires a carefully designed user interface, an easy-to-use workflow, and continuous efforts for keeping the participants motivated. More than 180,000 characters on about 21,000 pages were corrected by volunteers in about 7 month, achieving an OCR gold standard with a systematically evaluated accuracy of 99.7{\%} on the word level. The crowdsourced OCR gold standard and the corresponding original OCR recognition results from Abby FineReader 7 for each page are available as a resource. Additionally, the scanned images (300dpi) of all pages are included in order to facilitate tests with other OCR software."
W15-4926,Pre-reordering for Statistical Machine Translation of Non-fictional Subtitles,2015,9,0,4,0,36558,magdalena plamadua,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"This paper describes the challenges of building a Statistical Machine Translation (SMT) system for non-fictional subtitles. Since our experiments focus on a difficult translation direction (i.e. French-German), we investigate several methods to improve the translation performance. We also compare our in-house SMT systems (including domain adaptation and pre-reordering techniques) to other SMT services and show that pre-reordering alone significantly improves the baseline systems."
W15-2506,Detecting Document-level Context Triggers to Resolve Translation Ambiguity,2015,12,0,3,0,8570,laura mascarell,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"Most current machine translation systems translate each sentence independently, ignoring the context from previous sentences. This discourse unawareness can lead to incorrect translation of words or phrases that are ambiguous in the sentence. For example, the German term Typen in the phrase diese Typen can be translated either into English types or guys. However, knowing that it co-refers to the compound Kxc2xa8 (xe2x80x9cbody typesxe2x80x9d) in the previous sentence helps to disambiguate the term and translate it into types. We propose a method of automatically detecting document-level trigger words (like Kxc2xa8 orpertypen), whose presence helps to disambiguate translations of ambiguous terms. In this preliminary study we analyze the method and its limitations, and outline future work directions."
P15-3002,Leveraging Compounds to Improve Noun Phrase Translation from {C}hinese and {G}erman,2015,20,2,6,0,28965,xiao pu,Proceedings of the {ACL}-{IJCNLP} 2015 Student Research Workshop,0,"This paper presents a method to improve the translation of polysemous nouns, when a previous occurrence of the noun as the head of a compound noun phrase is available in a text. The occurrences are identified through pattern matching rules, which detect XY compounds followed closely by a potentially coreferent occurrence of Y , such as xe2x80x9cNordwand ... Wandxe2x80x9d. Two strategies are proposed to improve the translation of the second occurrence of Y : re-using the cached translation of Y from the XY compound, or post-editing the translation of Y using the head of the translation of XY . Experiments are performed on Chinese-toEnglish and German-to-French statistical machine translation, over the WIT3 and TextBerg corpora respectively, with 261 XY/Y pairs each. The results suggest that while the overall BLEU scores increase only slightly, the translations of the targeted polysemous nouns are significantly improved."
2015.eamt-1.27,Pre-reordering for Statistical Machine Translation of Non-fictional Subtitles,2015,9,0,4,0,38034,magdalena plamada,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"This paper describes the challenges of building a Statistical Machine Translation (SMT) system for non-fictional subtitles. Since our experiments focus on a difficult translation direction (i.e. French-German), we investigate several methods to improve the translation performance. We also compare our in-house SMT systems (including domain adaptation and pre-reordering techniques) to other SMT services and show that pre-reordering alone significantly improves the baseline systems."
W14-3903,Detecting Code-Switching in a Multilingual Alpine Heritage Corpus,2014,12,4,1,1,15670,martin volk,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"This paper describes experiments in detecting and annotating code-switching in a large multilingual diachronic corpus of Swiss Alpine texts. The texts are in English, French, German, Italian, Romansh and Swiss German. Because of the multilingual authors (mountaineers, scientists) and the assumed multilingual readers, the texts contain numerous code-switching elements. When building and annotating the corpus, we faced issues of language identification on the sentence and sub-sentential level. We present our strategy for language identification and for the annotation of foreign language fragments within sentences. We report 78% precision on detecting a subset of code-switches with correct language labels and 92% unlabeled precision."
etchegoyhen-etal-2014-machine,Machine Translation for Subtitling: A Large-Scale Evaluation,2014,8,5,10,0,17606,thierry etchegoyhen,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This article describes a large-scale evaluation of the use of Statistical Machine Translation for professional subtitling. The work was carried out within the FP7 EU-funded project SUMAT and involved two rounds of evaluation: a quality evaluation and a measure of productivity gain/loss. We present the SMT systems built for the project and the corpora they were trained on, which combine professionally created and crowd-sourced data. Evaluation goals, methodology and results are presented for the eleven translation pairs that were evaluated by professional subtitlers. Overall, a majority of the machine translated subtitles received good quality ratings. The results were also positive in terms of productivity, with a global gain approaching 40{\%}. We also evaluated the impact of applying quality estimation and filtering of poor MT output, which resulted in higher productivity gains for filtered files as opposed to fully machine-translated files. Finally, we present and discuss feedback from the subtitlers who participated in the evaluation, a key aspect for any eventual adoption of machine translation technology in professional subtitling."
volk-etal-2014-innovations,Innovations in Parallel Corpus Search Tools,2014,15,6,1,1,15670,martin volk,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Recent years have seen an increased interest in and availability of parallel corpora. Large corpora from international organizations (e.g. European Union, United Nations, European Patent Office), or from multilingual Internet sites (e.g. OpenSubtitles) are now easily available and are used for statistical machine translation but also for online search by different user groups. This paper gives an overview of different usages and different types of search systems. In the past, parallel corpus search systems were based on sentence-aligned corpora. We argue that automatic word alignment allows for major innovations in searching parallel corpora. Some online query systems already employ word alignment for sorting translation variants, but none supports the full query functionality that has been developed for parallel treebanks. We propose to develop such a system for efficiently searching large parallel corpora with a powerful query language."
W13-5630,Combining Statistical Machine Translation and Translation Memories with Domain Adaptation,2013,19,5,3,1,20844,samuel laubli,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"Since the emergence of translation memory software, translation companies and freelance translators have been accumulating translated text for various languages and domains. This data has the potential of being used for training domain-specific machine translation systems for corporate or even personal use. But while the resulting systems usually perform well in translating domain-specific language, their out-of-domain vocabulary coverage is often insufficient due to the limited size of the translation memories. In this paper, we demonstrate that small in-domain translation memories can be successfully complemented with freely available general-domain parallel corpora such that (a) the number of out-of-vocabulary words (OOV) is reduced while (b) the in-domain terminology is preserved. In our experiments, a Germanxe2x80x93French and a Germanxe2x80x93Italian statistical machine translation system geared to marketing texts of the automobile industry has been significantly improved using Europarl and OpenSubtitles data, both in terms of automatic evaluation metrics and human judgement."
W13-2902,Building a {G}erman/Simple {G}erman Parallel Corpus for Automatic Text Simplification,2013,21,9,3,0,40897,david klaper,Proceedings of the Second Workshop on Predicting and Improving Text Readability for Target Reader Populations,0,In this paper we report our experiments in creating a parallel corpus using German/Simple German documents from the web. We require parallel data to build a statistical machine translation (SMT) system that translates from German into Simple German. Parallel data for SMT systems needs to be aligned at the sentence level. We applied an existing monolingual sentence alignment algorithm. We show the limits of the algorithm with respect to the language and domain of our data and suggest ways of circumventing them.
W13-2514,Mining for Domain-specific Parallel Text from {W}ikipedia,2013,18,8,2,0,36558,magdalena plamadua,Proceedings of the Sixth Workshop on Building and Using Comparable Corpora,0,"Previous attempts in extracting parallel data from Wikipedia were restricted by the monotonicity constraint of the alignment algorithm used for matching possible candidates. This paper proposes a method for exploiting Wikipedia articles without worrying about the position of the sentences in the text. The algorithm ranks the candidate sentence pairs by means of a customized metric, which combines different similarity criteria. Moreover, we limit the search space to a specific topical domain, since our final goal is to use the extracted data in a domain-specific Statistical Machine Translation (SMT) setting. The precision estimates show that the extracted sentence pairs are clearly semantically equivalent. The SMT experiments, however, show that the extracted data is not refined enough to improve a strong in-domain SMT system. Nevertheless, it is good enough to boost the performance of an out-of-domain system trained on sizable amounts of data."
R13-1079,"Exploiting Synergies Between Open Resources for {G}erman Dependency Parsing, {POS}-tagging, and Morphological Analysis",2013,18,22,2,0.47619,2690,rico sennrich,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"We report on the recent development of ParZu, a German dependency parser. We discuss the effect of POS tagging and morphological analysis on parsing performance, and present novel ways of improving performance of the components, including the use of morphological features for POS-tagging, the use of syntactic information to select good POS sequences from an n-best list, and using parsed text as training data for POS tagging and statistical parsing. We also describe our efforts towards reducing the dependency on restrictively licensed and closed-source NLP resources."
2013.mtsummit-wptp.10,Assessing post-editing efficiency in a realistic translation environment,2013,12,19,5,1,20844,samuel laubli,Proceedings of the 2nd Workshop on Post-editing Technology and Practice,0,"In many experimental studies on assessing post-editing efficiency, idiosyncratic user interfaces isolate translators from translation aids that are available to them in their daily work. In contrast, our experimental design allows translators to use a well-known translator workbench for both conventional translation and post-editing. We find that post-editing reduces translation time significantly, although considerably less than reported in isolated experiments, and argue that overall assessments of post-editing efficiency should be based on a realistic translation environment."
2013.mtsummit-posters.9,Statistical Machine Translation for Automobile Marketing Texts,2013,20,2,4,1,20844,samuel laubli,Proceedings of Machine Translation Summit XIV: Posters,0,"We describe a project on introducing an in-house statistical machine translation system for marketing texts from the automobile industry with the final aim of replacing manual translation with post-editing, based on the translation system. The focus of the paper is the suitability of such texts for SMT; we present experiments in domain adaptation and decompounding that improve the baseline translation systems, the results of which are evaluated using automatic metrics as well as manual evaluation."
petukhova-etal-2012-sumat,{SUMAT}: Data Collection and Parallel Corpus Compilation for Machine Translation of Subtitles,2012,12,6,9,0,16746,volha petukhova,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Subtitling and audiovisual translation have been recognized as areas that could greatly benefit from the introduction of Statistical Machine Translation (SMT) followed by post-editing, in order to increase efficiency of subtitle production process. The FP7 European project SUMAT (An Online Service for SUbtitling by MAchine Translation: http://www.sumat-project.eu) aims to develop an online subtitle translation service for nine European languages, combined into 14 different language pairs, in order to semi-automate the subtitle translation processes of both freelance translators and subtitling companies on a large scale. In this paper we discuss the data collection and parallel corpus compilation for training SMT systems, which includes several procedures such as data partition, conversion, formatting, normalization and alignment. We discuss in detail each data pre-processing step using various approaches. Apart from the quantity (around 1 million subtitles per language pair), the SUMAT corpus has a number of very important characteristics. First of all, high quality both in terms of translation and in terms of high-precision alignment of parallel documents and their contents has been achieved. Secondly, the contents are provided in one consistent format and encoding. Finally, additional information such as type of content in terms of genres and domain is available."
2012.eamt-1.2,From Subtitles to Parallel Corpora,2012,5,3,6,0.708333,13955,mark fishel,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,We describe the preparation of parallel corpora based on professional quality subtitles in seven European language pairs. The main focus is the effect of the processing steps on the size and quality of the final corpora.
W11-4624,"Iterative, {MT}-based Sentence Alignment of Parallel Texts",2011,16,21,2,0.666667,2690,rico sennrich,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,"Recent research has shown that MT-based sentence alignment is a robust approach for noisy parallel texts. However, using Machine Translation for sentence alignment causes a chicken-and-egg problem: to train a corpus-based MT system, we need sentence-aligned data, and MT-based sentence alignment depends on an MT system. We describe a bootstrapping approach to sentence alignment that resolves this circular dependency by computing an initial alignment with length-based methods. Our evaluation shows that iterative MT-based sentence alignment significantly outperforms widespread alignment approaches on our evaluation set, without requiring any linguistic resources other than the to-be-aligned bitext."
W11-4633,Disambiguation of {E}nglish Contractions for Machine Translation of {TV} Subtitles,2011,12,0,1,1,15670,martin volk,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,This paper presents a disambiguation method for English apostrophes contractions. They occur frequently in subtitles and pose special difficulties for Machine Translation. We propose to disambiguate these contractions in a pre-processing step and show that this leads to improved translation quality.
W11-4115,Reducing {OCR} Errors in {G}othic-Script Documents,2011,7,7,2,0.714286,14588,lenz furrer,Proceedings of the Workshop on Language Technologies for Digital Humanities and Cultural Heritage,0,"In order to improve OCR quality in texts originally typeset in Gothic script, we have built an automated correction system which is highly specialized for the given text. Our approach includes external dictionary resources as well as information derived from the text itself. The focus lies on testing and improving different methods for classifying words as correct or erroneous. Also, different techniques are applied to find and rate correction candidates. In addition, we are working on a web application that enables users to read and edit the digitized text online."
2011.jeptalnrecital-court.17,Le corpus {T}ext+{B}erg Une ressource parall{\\`e}le alpin fran{\\c{c}}ais-allemand (The {T}ext+{B}erg Corpus An Alpine {F}rench-{G}erman Parallel Resource),2011,-1,-1,2,0,2735,anne gohring,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Cet article pr{\'e}sente un corpus parall{\`e}le fran{\c{c}}ais-allemand de plus de 4 millions de mots issu de la num{\'e}risation d{'}un corpus alpin multilingue. Ce corpus est une pr{\'e}cieuse ressource pour de nombreuses {\'e}tudes de linguistique compar{\'e}e et du patrimoine culturel ainsi que pour le d{\'e}veloppement d{'}un syst{\`e}me statistique de traduction automatique dans un domaine sp{\'e}cifique. Nous avons annot{\'e} un {\'e}chantillon de ce corpus parall{\`e}le et align{\'e} les structures arbor{\'e}es au niveau des mots, des constituants et des phrases. Cet {``}alpine treebank{''} est le premier corpus arbor{\'e} parall{\`e}le fran{\c{c}}ais-allemand de haute qualit{\'e} (manuellement contr{\^o}l{\'e}), de libre acc{\`e}s et dans un domaine et un genre nouveau : le r{\'e}cit d{'}alpinisme."
2011.eamt-1.29,Combining Semantic and Syntactic Generalization in Example-Based Machine Translation,2011,21,3,3,0.714286,3154,sarah ebling,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"In this paper, we report our experiments in combining two EBMT systems that rely on generalized templates, Marclator and CMU-EBMT, on an Englishxe2x80x90German translation task. Our goal was to see whether a statistically significant improvement could be achieved over the individual performances of these two systems. We observed that this was not the case. However, our system consistently outperformed a lexical EBMT baseline system."
W10-1830,Combining Parallel Treebanks and Geo-Tagging,2010,17,2,1,1,15670,martin volk,Proceedings of the Fourth Linguistic Annotation Workshop,0,"This paper describes a new kind of semantic annotation in parallel treebanks. We build French-German parallel treebanks of mountaineering reports, a text genre that abounds with geographical names which we classify and ground with reference to a large gazetteer of Swiss toponyms. We discuss the challenges in obtaining a high recall and precision in automatic grounding, and sketch how we represent the grounding information in our treebank."
volk-etal-2010-challenges,Challenges in Building a Multilingual Alpine Heritage Corpus,2010,10,16,1,1,15670,martin volk,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes our efforts to build a multilingual heritage corpus of alpine texts. Currently we digitize the yearbooks of the Swiss Alpine Club which contain articles in French, German, Italian and Romansch. Articles comprise mountaineering reports from all corners of the earth, but also scientific topics such as topography, geology or glacierology as well as occasional poetry and lyrics. We have already scanned close to 70,000 pages which has resulted in a corpus of 25 million words, 10{\%} of which is a parallel French-German corpus. We have solved a number of challenges in automatic language identification and text structure recognition. Our next goal is to identify the great variety of toponyms (e.g. names of mountains and valleys, glaciers and rivers, trails and cabins) in this corpus, and we sketch how a large gazetteer of Swiss topographical names can be exploited for this purpose. Despite the size of the resource, exact matching leads to a low recall because of spelling variations, language mixtures and partial repetitions."
2010.jec-1.7,Machine Translation of {TV} Subtitles for Large Scale Production,2010,13,11,1,1,15670,martin volk,Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry,0,"This paper describes our work on building and employing Statistical Machine Translation systems for TV subtitles in Scandinavia. We have built translation systems for Danish, English, Norwegian and Swedish. They are used in daily subtitle production and translate large volumes. As an example we report on our evaluation results for three TV genres. We discuss our lessons learned in the system development process which shed interesting light on the practical use of Machine Translation technology."
2010.amta-papers.14,{MT}-based Sentence Alignment for {OCR}-generated Parallel Texts,2010,18,25,2,0.666667,2690,rico sennrich,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"The performance of current sentence alignment tools varies according to the to-be-aligned texts. We have found existing tools unsuitable for hard-to-align parallel texts and describe an alternative alignment algorithm. The basic idea is to use machine translations of a text and BLEU as a similarity score to find reliable alignments which are used as anchor points. The gaps between these anchor points are then filled using BLEU-based and length-based heuristics. We show that this approach outperforms state-of-the-art algorithms in our alignment task, and that this improvement in alignment quality translates into better SMT performance. Furthermore, we show that even length-based alignment algorithms profit from having a machine translation as a point of comparison."
W09-4610,Using Linguistic Annotations in Statistical Machine Translation of Film Subtitles,2009,12,8,2,0,670,christian hardmeier,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"Statistical Machine Translation (SMT) has been successfully employed to support translation of film subtitles. We explore the integration of Constraint Grammar corpus annotations into a Swedishxe2x80x90Danish subtitle SMT system in the framework of factored SMT. While the usefulness of the annotations is limited with large amounts of parallel data, we show that linguistic annotations can increase the gains in translation quality when monolingual data in the target language is added to an SMT system based on a small parallel corpus."
W08-1208,Human Judgements in Parallel Treebank Alignment,2008,12,2,1,1,15670,martin volk,Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics,0,"We have built a parallel treebank that includes word and phrase alignment. The alignment information was manually checked using a graphical tool that allows the annotator to view a pair of trees from parallel sentences. We found the compilation of clear alignment guidelines to be a difficult task. However, experiments with a group of students have shown that we are on the right track with up to 89% overlap between the student annotation and our own. At the same time these experiments have helped us to pin-point the weaknesses in the guidelines, many of which concerned unclear rules related to differences in grammatical forms between the languages."
W07-2427,"Comparing {F}rench {PP}-attachment to {E}nglish, {G}erman and {S}wedish",2007,9,1,1,1,15670,martin volk,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,"The correct attachment of prepositional phrases (PPs) is a central disambiguation problem when parsing natural languages. This paper compares the baseline situation for French as exemplified in the Le Monde treebank with earlier findings for English, German and Swedish. We perform uniform treebank queries and show that the noun attachment rate for French prepositions is strongly influenced by the preposition de which is by far the most frequent preposition and has a strong tendency for noun attachment. We therefore also compute the noun attachment rate for the other prepositions separately as well as for the many complex prepositions that are explicitly marked in this treebank."
W07-1514,A Search Tool for Parallel Treebanks,2007,10,11,1,1,15670,martin volk,Proceedings of the Linguistic Annotation Workshop,0,This paper describes a tool for aligning and searching parallel treebanks. Such treebanks are a new type of parallel corpora that come with syntactic annotation on both languages plus sub-sentential alignment. Our tool allows the visualization of tree pairs and the comfortable annotation of word and phrase alignments. It also allows monolingual and bilingual searches including the specification of alignment constraints. We show that the TIGER-Search query language can easily be combined with such alignment constraints to obtain a powerful cross-lingual query language.
2007.mtsummit-papers.66,Evaluating {MT} with translations or translators: what is the difference?,2007,4,11,1,1,15670,martin volk,Proceedings of Machine Translation Summit XI: Papers,0,"This paper describes a project on building a Machine Translation system for television and film subtitles. We report on the specific properties of the text genre, the language pair Swedish-Danish, and the large training corpus. n We focus on the evaluation of the system output against independent and post-edited translations. We show that n evaluation results against post-edited translations are higher by a margin of up to 19 points BLEU score."
W06-2717,{XML}-based Phrase Alignment in Parallel Treebanks,2006,5,16,1,1,15670,martin volk,Proceedings of the 5th Workshop on {NLP} and {XML} ({NLPXML}-2006): Multi-Dimensional Markup in Natural Language Processing,0,This paper describes the usage of XML for representing cross-language phrase alignments in parallel treebanks. We have developed a TreeAligner as a tool for interactively inserting and correcting such alignments as an independent level of treebank annotation.
W06-2112,"How Bad is the Problem of {PP}-Attachment? A Comparison of {E}nglish, {G}erman and {S}wedish",2006,11,10,1,1,15670,martin volk,Proceedings of the Third {ACL}-{SIGSEM} Workshop on Prepositions,0,"The correct attachment of prepositional phrases (PPs) is a central disambiguation problem in parsing natural languages. This paper compares the baseline situation in English, German and Swedish based on manual PP attachments in various treebanks for these languages. We argue that cross-language comparisons of the disambiguation results in previous research is impossible because of the different selection procedures when building the training and test sets. We perform uniform tree-bank queries and show that English has the highest noun attachment rate followed by Swedish and German. We also show that the high rate in English is dominated by the preposition of. From our study we derive a list of criteria for profiling data sets for PP attachment experiments."
W04-1910,Bootstrapping Parallel Treebanks,2004,-1,-1,1,1,15670,martin volk,Proceedings of the 5th International Workshop on Linguistically Interpreted Corpora,0,None
buitelaar-etal-2004-evaluation,Evaluation Resources for Concept-based Cross-Lingual Information Retrieval in the Medical Domain,2004,7,9,3,0.75,6276,paul buitelaar,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The paper describes evaluation resources for concept-based, cross-lingual information retrieval in the medical domain. All resources were constructed in the context of the MuchMore project and are freely available through the project website. Available resources include: a bilingual, parallel document collection of German and English medical scientific abstracts, a set of queries and corresponding relevance assessments, two manually disambiguated test sets for semantic annotation (sense disambiguation), two evaluation lists for German morphological decomposition of medical terms."
E03-2012,A Cross Language Document Retrieval System Based on Semantic Annotation,2003,3,8,3,0,42996,bogdan sacaleanu,Demonstrations,0,"The paper describes a cross-lingual document retrieval system in the medical domain that employs a controlled vocabulary (UMLS1) in constructing an XML-based intermediary representation into which queries as well as documents are mapped. The system assists in the retrieval of English and German medical scientific abstracts relevant to a German query document (electronic patient record). The modularity of the system allows for deployment in other domains, given appropriate linguistic and semantic resources."
C02-1004,Combining Unsupervised and Supervised Methods for {PP} Attachment Disambiguation,2002,9,22,1,1,15670,martin volk,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Statistical methods for PP attachment fall into two classes according to the training material used: first, unsupervised methods trained on raw text corpora and second, supervised methods trained on manually disambiguated examples. Usually supervised methods win over unsupervised methods with regard to attachment accuracy. But what if only small sets of manually disambiguated material are available? We show that in this case it is advantageous to intertwine unsupervised and supervised methods into one disambiguation algorithm that outperforms both methods used alone."
bohan-etal-2000-evaluating,Evaluating Translation Quality as Input to Product Development,2000,1,6,3,0,54469,niamh bohan,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"In this paper we present a corpus-based method to evaluate the translation quality of machine translation (MT) systems. We start with a shallow analysis of a large corpus and gradually focus the attention on the translation problems. The method constitutes an efficient way to identify the most important grammatical and lexical weaknesses of an MT system and to guide development towards improved translation quality. The evaluation described in the paper was carried out as a cooperation between an MT technology developer, Sail Labs, and the Computational Linguistics group at the University of Zurich. 1. Different types of evaluation for different purposes Sail Labs does various types of translation quality (TQ) evaluations (absolute, comparative, text and sentence-based) and uses different methods (glass-box, black-box evaluations, preand postrelease, using linguistic test suites and real text corpora). Most of the evaluations are from a developer's rather than a userxe2x80x99s point of view. Please note that these evaluations were carried out with earlier product versions and the results were used in the development of Sail Labs' current MT technology. For this reason, the concrete results included in this paper (statistics and phenomena) do not reflect the current status of Sail Labs' technology. Before designing an evaluation method it is crucial to answer the following questions (King, 1997): xe2x80xa2 What is the purpose of the evaluation? xe2x80xa2 What exactly is being evaluated? In this paper we focus on a TQ evaluation to answer the question: In which linguistic areas does the evaluated MT system have the most problems? Thus, the purpose of our evaluation is to identify the most costly grammatical and lexical weaknesses so that by concentrating development on these areas, we can most effectively improve the TQ of our systems. We did not want to evaluate the overall TQ of our systems, but rather the problems encountered by the worst translations. 2. Our Evaluation method xe2x80x99Survival of the Weakestxe2x80x99 We chose a corpus-based approach as we wanted to measure the performance of the MT system with minimal user involvement (e.g., no prior adaptation of bad texts nor lexical coding of unknown words). This means that we checked the xe2x80x98performancexe2x80x99 rather than the xe2x80x98competencexe2x80x99 of the system (Falkedahl, 1998). We were not merely interested in determining which linguistic problems the system could handle and to which degree, but rather in which areas the system encounters the most severe problems when translating real texts. To achieve a realistic distribution of linguistic phenomena, it is best to use a collection of test sentences covering various linguistic phenomena proportional to their frequency of occurrence in corpus texts. However, this is very difficult if not impossible to obtain. Constructed test suites for linguistic phenomena for which the real occurrence frequency is unknown would also be of little use to us. For these reasons, we selected texts from the Internet and from a corpus CD and considered all phenomena occurring in the test corpus. To this end, the corpus must be big enough to yield representative frequencies of linguistic phenomena. Another advantage of real texts is that they also contain interactions between various linguistic phenomena, which is another important aspect in evaluating the performance of a system. The evaluation method described here adopts, on the whole, a black-box approach. The advantage is that the evaluation can be outsourced to an institution not involved with the system development. This ensures a more objective evaluation. After the final step of the black-box evaluation, the external evaluators from the University of Zurich passed the results to Sail Labs system developers who carried out the more time-consuming glass-box evaluation using standard methods (e.g., by isolating the suspected phenomenon, tracing the grammar rules etc.). In the black-box evaluation we applied a 4-step filtering mechanism, where each step involved narrowing down the set of sentences for the next step according to certain criteria. This allowed us to start the evaluation with an extensive data set while continually reducing the data set for the more costly subsequent steps. Each metric and its rating scale was defined in written form, where possible also with reference to quantitative assignment criteria (e.g., the sentence is bad if more than half is not understandable). From our experience with other evaluation projects and as reported by Sparck-Jones and Galliers (1995), it is crucial to define the evaluation criteria and the values for the text and sentence ratings in as much detail as possible. Among the evaluators, crosschecking and regular discussions helped to ensure that the metrics were applied consistently and subjectivity of ratings was kept to a minimum. The final result of the evaluation is a list of grammatical and lexical errors with their respective frequencies within the set of worst translations. This list documents the causes of the most frequent and severe translation problems with the corpus of real texts. 2.1. Selection of test material For each language direction, we selected between 100 and 140 texts totaling approximately 5500 to 6000 sentences (translation units), mainly from the Internet, some from the ACL/ECI Multilingual Corpus CD1. We chose texts from various subject areas but with little specialised terminology, a) to ensure a good general understanding of the topics by the evaluators, and b) because we develop general-purpose MT technology. The texts were short in order to get a broad variety for a given corpus size and contained sentences of varying linguistic style (simple and complex, short and long sentences, listings and other non-sentence structures). Texts were taken from different domains to suit the purposes of the particular evaluation. We used general texts as well as texts from data processing, car industry, economics, medicine, biology, geography & geology, recreation & sports, linguistics and art & literature. Where available, the texts were translated using the systemsxe2x80x98 relevant terminology lexica. In order to capture different linguistic styles pertinent to particular domains we selected texts that served various functions (newspaper, manual, internet, dialog). Due to the fact that we used the texts as we found them and no pre-evaluation changes were made, we decided to exclude texts with severe and multiple spelling errors or slang as we were not interested in evaluating the robustness of the MT system when facing bad input, but rather its performance with relatively wellformed texts. 2.2. Step 1: Evaluate TL texts after translation with the MT system After translation with our MT system, the TL texts were evaluated to identify bad translations. The SL sentences were not taken into consideration in this step as we wanted an evaluation of the generated TL as a standalone text. The texts were evaluated according to the following three parameters: xe2x80xa2 understandability (the amount of information that is understood by the reader). xe2x80xa2 grammaticality (syntactically ill-formed sentences and incorrect morphology). xe2x80xa2 lexical correctness (number of unknown, i.e. untranslated words and suitability of chosen words in the given context, not with regard to the SL sentence). These three parameters were chosen to capture the various purposes a machine translation may serve (information translation or input for postediting). Each criterion was rated on a 3-point value scale: 1. Bad 2. Neither bad nor good 3. Good The rating for the three parameters was done paragraph-wise to ensure each paragraph contributed equally to the overall score. The average was then computed for the whole text and this introduced decimal scores. Each text was evaluated by three persons to reduce subjectivity. All texts evaluated as generally not good 1 TL = target language; SL = source language (average point value below 2) progressed to evaluation step 2. The results were documented extensively including valuable additional information on the overall quality of the translated texts in various subject areas. We documented the grades for the 3 criteria for each text and computed the average across subject areas. Presuming that even texts that are translated well will contain their share of badly translated sentences, by excluding these texts, we are decreasing our set of badly translated sentences for subsequent steps. For more accurate data on the frequency of problematic phenomenon, we could have skipped this step and evaluated all sentences immediately. However we designed this step to exclude understandable texts with many well translated sentences in order to maximise the relevance of problems contained in the remaining sentences. This also has the advantage of excluding texts from certain genres that are generally translated well. 2.3. Step 2: Evaluate individual sentences In step 2, the goal was to identify within the xe2x80x98badxe2x80x98 texts those sentences that are translated the worst. This time, the SL sentences were taken into account for the assessment of the TL sentences to enable a more informed evaluation. This step was carried out for approx. 3500 xe2x80x93 4000 translation units per language direction. We used two metrics which were rated on a 10 pt scale xe2x80xa2 Preservation of meaning: Is the meaning of the TL sentence the same as the meaning of the SL sentence? 7 xe2x80x93 10 points (Good): meaning of SL and TL sentence is about the same. Almost no post-editing with respect to meaning is necessary. Example: SL: Cxe2x80x99est sur le terrain social que le changement est le"
W97-1515,Experiences with the {GTU} grammar development environment,1997,5,0,1,1,15670,martin volk,Computational Environments for Grammar Development and Linguistic Engineering,0,"In this paper we describe our experiences with a tool for the development and testing of natural language grammars called GTU (German: Grammatik-Testumgebumg; grammar test environment). GTU supports four grammar formalisms under a window-oriented user interface. Additionally, it contains a set of German test sentences covering various syntactic phenomena as well as three types of German lexicons that can be attached to a grammar via an integrated lexicon interface. What follows is a description of the experiences we gained when we used GTU as a tutoring tool for students and as an experimental tool for CL researchers. From these we will derive the features necessary for a future grammar workbench."
P97-1015,Probing the Lexicon in Evaluating Commercial {MT} Systems,1997,7,2,1,1,15670,martin volk,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,In the past the evaluation of machine translation systems has focused on single system evaluations because there were only few systems available. But now there are several commercial systems for the same language pair. This requires new methods of comparative evaluation. In the paper we propose a black-box method for comparing the lexical coverage of MT systems. The method is based on lists of words from different frequency classes. It is shown how these word lists can be compiled and used for testing. We also present the results of using our method on 6 MT systems that translate between English and German.
A92-1046,The Role of Testing in Grammar Engineering,1992,2,3,1,1,15670,martin volk,Third Conference on Applied Natural Language Processing,0,"In the past grammars have been developed either with an art approach (building up a coherent system; prescriptive grammars like the Latin g r ammars of the Middle Ages) or with a science approach (describing the laws of nature; descriptive and contrastive grammars) . We propose to regard g rammar development in Computat ional Linguistics as an engineering task analogous to software engineerkig: one that requires analysis, specification, implementation, testing, integration and maintenance. The different phases in the software development process correspond to phases in g r am m ar development in the following way:"
J91-3010,The Logical Structure of {E}nglish: Computing Semantic Content,1991,2,1,1,1,15670,martin volk,Computational Linguistics,0,None
