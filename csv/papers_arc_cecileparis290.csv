2021.emnlp-main.233,Lifelong Explainer for Lifelong Learners,2021,-1,-1,4,0,9123,xuelin situ,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Lifelong Learning (LL) black-box models are dynamic in that they keep learning from new tasks and constantly update their parameters. Owing to the need to utilize information from previously seen tasks, and capture commonalities in potentially diverse data, it is hard for automatic explanation methods to explain the outcomes of these models. In addition, existing explanation methods, e.g., LIME, which are computationally expensive when explaining a static black-box model, are even more inefficient in the LL setting. In this paper, we propose a novel Lifelong Explanation (LLE) approach that continuously trains a student explainer under the supervision of a teacher {--} an arbitrary explanation algorithm {--} on different tasks undertaken in LL. We also leverage the Experience Replay (ER) mechanism to prevent catastrophic forgetting in the student explainer. Our experiments comparing LLE to three baselines on text classification tasks show that LLE can enhance the stability of the explanations for all seen tasks and maintain the same level of faithfulness to the black-box model as the teacher, while being up to 10{\^{}}2 times faster at test time. Our ablation study shows that the ER mechanism in our LLE approach enhances the learning capabilities of the student explainer. Our code is available at https://github.com/situsnow/LLE."
2021.clpsych-1.5,Demonstrating the Reliability of Self-Annotated Emotion Data,2021,-1,-1,2,0,11571,anton malko,Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access,0,"Vent is a specialised iOS/Android social media platform with the stated goal to encourage people to post about their feelings and explicitly label them. In this paper, we study a snapshot of more than 100 million messages obtained from the developers of Vent, together with the labels assigned by the authors of the messages. We establish the quality of the self-annotated data by conducting a qualitative analysis, a vocabulary based analysis, and by training and testing an emotion classifier. We conclude that the self-annotated labels of our corpus are indeed indicative of the emotional contents expressed in the text and thus can support more detailed analyses of emotion expression on social media, such as emotion trajectories and factors influencing them."
2021.acl-long.415,Learning to Explain: Generating Stable Explanations Fast,2021,-1,-1,3,0,9123,xuelin situ,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"The importance of explaining the outcome of a machine learning model, especially a black-box model, is widely acknowledged. Recent approaches explain an outcome by identifying the contributions of input features to this outcome. In environments involving large black-box models or complex inputs, this leads to computationally demanding algorithms. Further, these algorithms often suffer from low stability, with explanations varying significantly across similar examples. In this paper, we propose a Learning to Explain (L2E) approach that learns the behaviour of an underlying explanation algorithm simultaneously from all training examples. Once the explanation algorithm is distilled into an explainer network, it can be used to explain new instances. Our experiments on three classification tasks, which compare our approach to six explanation algorithms, show that L2E is between 5 and 7.5{\mbox{$\times$}}10{\^{}}4 times faster than these algorithms, while generating more stable explanations, and having comparable faithfulness to the black-box model."
2020.findings-emnlp.151,Cost-effective Selection of Pretraining Data: A Case Study of Pretraining {BERT} on Social Media,2020,-1,-1,4,1,7126,xiang dai,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Recent studies on domain-specific BERT models show that effectiveness on downstream tasks can be improved when models are pretrained on in-domain data. Often, the pretraining data used in these models are selected based on their subject matter, e.g., biology or computer science. Given the range of applications using social media text, and its unique language variety, we pretrain two models on tweets and forum text respectively, and empirically demonstrate the effectiveness of these two resources. In addition, we investigate how similarity measures can be used to nominate in-domain pretraining data. We publicly release our pretrained models at https://bit.ly/35RpTf0."
2020.coling-industry.14,Assessing Social License to Operate from the Public Discourse on Social Media,2020,-1,-1,2,1,7330,chang xu,Proceedings of the 28th International Conference on Computational Linguistics: Industry Track,0,"Organisations are monitoring their Social License to Operate (SLO) with increasing regularity. SLO, the level of support organisations gain from the public, is typically assessed through surveys or focus groups, which require expensive manual efforts and yield quickly-outdated results. In this paper, we present SIRTA (Social Insight via Real-Time Text Analytics), a novel real-time text analytics system for assessing and monitoring organisations{'} SLO levels by analysing the public discourse from social posts. To assess SLO levels, our insight is to extract and transform peoples{'} stances towards an organisation into SLO levels. SIRTA achieves this by performing a chain of three text classification tasks, where it identifies task-relevant social posts, discovers key SLO risks discussed in the posts, and infers stances specific to the SLO risks. We leverage recent language understanding techniques (e.g., BERT) for building our classifiers. To monitor SLO levels over time, SIRTA employs quality control mechanisms to reliably identify SLO trends and variations of multiple organisations in a market. These are derived from the smoothed time series of their SLO levels based on exponentially-weighted moving average (EWMA) calculation. Our experimental results show that SIRTA is highly effective in distilling stances from social posts for SLO level assessment, and that the continuous monitoring of SLO levels afforded by SIRTA enables the early detection of critical SLO changes."
2020.alta-1.10,Benchmarking of Transformer-Based Pre-Trained Models on Social Media Text Classification Datasets,2020,-1,-1,5,0,1171,yuting guo,Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association,0,"Free text data from social media is now widely used in natural language processing research, and one of the most common machine learning tasks performed on this data is classification. Generally speaking, performances of supervised classification algorithms on social media datasets are lower than those on texts from other sources, but recently-proposed transformer-based models have considerably improved upon legacy state-of-the-art systems. Currently, there is no study that compares the performances of different variants of transformer-based models on a wide range of social media text classification datasets. In this paper, we benchmark the performances of transformer-based pre-trained models on 25 social media text classification datasets, 6 of which are health-related. We compare three pre-trained language models, RoBERTa-base, BERTweet and ClinicalBioBERT in terms of classification accuracy. Our experiments show that RoBERTa-base and BERTweet perform comparably on most datasets, and considerably better than ClinicalBioBERT, even on health-related datasets."
2020.acl-main.520,An Effective Transition-based Model for Discontinuous {NER},2020,41,0,4,1,7126,xiang dai,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Unlike widely used Named Entity Recognition (NER) data sets in generic domains, biomedical NER data sets often contain mentions consisting of discontinuous spans. Conventional sequence tagging techniques encode Markov assumptions that are efficient but preclude recovery of these mentions. We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER. Through extensive experiments on three biomedical data sets, we show that our model can effectively recognize discontinuous mentions without sacrificing the accuracy on continuous mentions."
W19-5015,A Comparison of Word-based and Context-based Representations for Classification Problems in Health Informatics,2019,28,0,4,0.219291,17882,aditya joshi,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"Distributed representations of text can be used as features when training a statistical classifier. These representations may be created as a composition of word vectors or as context-based sentence vectors. We compare the two kinds of representations (word versus context) for three classification problems: influenza infection classification, drug usage classification and personal health mention classification. For statistical classifiers trained for each of these problems, context-based representations based on ELMo, Universal Sentence Encoder, Neural-Net Language Model and FLAIR are better than Word2Vec, GloVe and the two adapted using the MESH ontology. There is an improvement of 2-4{\%} in the accuracy when these context-based representations are used instead of word-based representations."
U19-1020,Does Multi-Task Learning Always Help?: An Evaluation on Health Informatics,2019,0,0,4,0.219291,17882,aditya joshi,Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association,0,"Multi-Task Learning (MTL) has been an attractive approach to deal with limited labeled datasets or leverage related tasks, for a variety of NLP problems. We examine the benefit of MTL for three specific pairs of health informatics tasks that deal with: (a) overlapping symptoms for the same classification problem (personal health mention classification for influenza and for a set of symptoms); (b) overlapping medical concepts for related classification problems (vaccine usage and drug usage detection); and, (c) related classification problems (vaccination intent and vaccination relevance detection). We experiment with a simple neural architecture: a shared layer followed by task-specific dense layers. The novelty of this work is that it compares alternatives for shared layers for these pairs of tasks. While our observations agree with the promise of MTL as compared to single-task learning, for health informatics, we show that the benefit also comes with caveats in terms of the choice of shared layers and the relatedness between the participating tasks."
P19-1108,Figurative Usage Detection of Symptom Words to Improve Personal Health Mention Detection,2019,18,0,5,0,25614,adith iyer,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Personal health mention detection deals with predicting whether or not a given sentence is a report of a health condition. Past work mentions errors in this prediction when symptom words, i.e., names of symptoms of interest, are used in a figurative sense. Therefore, we combine a state-of-the-art figurative usage detection with CNN-based personal health mention detection. To do so, we present two methods: a pipeline-based approach and a feature augmentation-based approach. The introduction of figurative usage detection results in an average improvement of 2.21{\%} F-score of personal health mention detection, in the case of the feature augmentation-based approach. This paper demonstrates the promise of using figurative usage detection to improve personal health mention detection."
P19-1460,Recognising Agreement and Disagreement between Stances with Reason Comparing Networks,2019,41,0,2,1,7330,chang xu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"We identify agreement and disagreement between utterances that express stances towards a topic of discussion. Existing methods focus mainly on conversational settings, where dialogic features are used for (dis)agreement inference. We extend this scope and seek to detect stance (dis)agreement in a broader setting, where independent stance-bearing utterances, which prevail in many stance corpora and real-world scenarios, are compared. To cope with such non-dialogic utterances, we find that the reasons uttered to back up a specific stance can help predict stance (dis)agreements. We propose a reason comparing network (RCN) to leverage reason information for stance comparison. Empirical results on a well-known stance corpus show that our method can discover useful reason information, enabling it to outperform several baselines in stance (dis)agreement detection."
P19-1510,{NNE}: A Dataset for Nested Named Entity Recognition in {E}nglish Newswire,2019,25,0,5,0,25855,nicky ringland,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Named entity recognition (NER) is widely used in natural language processing applications and downstream tasks. However, most NER tools target flat annotation from popular datasets, eschewing the semantic information available in nested entity mentions. We describe NNE{---}a fine-grained, nested named entity dataset over the full Wall Street Journal portion of the Penn Treebank (PTB). Our annotation comprises 279,795 mentions of 114 entity types with up to 6 layers of nesting. We hope the public release of this large dataset for English newswire will encourage development of new techniques for nested NER."
N19-1149,Using Similarity Measures to Select Pretraining Data for {NER},2019,0,5,4,1,7126,xiang dai,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Word vectors and Language Models (LMs) pretrained on a large amount of unlabelled data can dramatically improve various Natural Language Processing (NLP) tasks. However, the measure and impact of similarity between pretraining data and target task data are left to intuition. We propose three cost-effective measures to quantify different aspects of similarity between source pretraining and target task data. We demonstrate that these measures are good predictors of the usefulness of pretrained models for Named Entity Recognition (NER) over 30 data pairs. Results also suggest that pretrained LMs are more effective and more predictable than pretrained word vectors, but pretrained word vectors are better when pretraining data is dissimilar."
D19-6124,Reevaluating Argument Component Extraction in Low Resource Settings,2019,0,0,4,1,19853,anirudh joshi,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,"Argument component extraction is a challenging and complex high-level semantic extraction task. As such, it is both expensive to annotate (meaning training data is limited and low-resource by nature), and hard for current-generation deep learning methods to model. In this paper, we reevaluate the performance of state-of-the-art approaches in both single- and multi-task learning settings using combinations of character-level, GloVe, ELMo, and BERT encodings using standard BiLSTM-CRF encoders. We use evaluation metrics that are more consistent with evaluation practice in named entity recognition to understand how well current baselines address this challenge and compare their performance to lower-level semantic tasks such as CoNLL named entity recognition. We find that performance utilizing various pre-trained representations and training methodologies often leaves a lot to be desired as it currently stands, and suggest future pathways for improvement."
W18-5911,Shot Or Not: Comparison of {NLP} Approaches for Vaccination Behaviour Detection,2018,0,1,5,0.219291,17882,aditya joshi,Proceedings of the 2018 {EMNLP} Workshop {SMM}4{H}: The 3rd Social Media Mining for Health Applications Workshop {\\&} Shared Task,0,"Vaccination behaviour detection deals with predicting whether or not a person received/was about to receive a vaccine. We present our submission for vaccination behaviour detection shared task at the SMM4H workshop. Our findings are based on three prevalent text classification approaches: rule-based, statistical and deep learning-based. Our final submissions are: (1) an ensemble of statistical classifiers with task-specific features derived using lexicons, language processing tools and word embeddings; and, (2) a LSTM classifier with pre-trained language models."
S18-1190,"{U}ni{M}elb at {S}em{E}val-2018 Task 12: Generative Implication using {LSTM}s, {S}iamese Networks and Semantic Representations with Synonym Fuzzing",2018,0,0,4,1,19853,anirudh joshi,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes a warrant classification system for SemEval 2018 Task 12, that attempts to learn semantic representations of reasons, claims and warrants. The system consists of 3 stacked LSTMs: one for the reason, one for the claim, and one shared Siamese Network for the 2 candidate warrants. Our main contribution is to force the embeddings into a shared feature space using vector operations, semantic similarity classification, Siamese networks, and multi-task learning. In doing so, we learn a form of generative implication, in encoding implication interrelationships between reasons, claims, and the associated correct and incorrect warrants. We augment the limited data in the task further by utilizing WordNet synonym {``}fuzzing{''}. When applied to SemEval 2018 Task 12, our system performs well on the development data, and officially ranked 8th among 21 teams."
P18-2123,Cross-Target Stance Classification with Self-Attention Networks,2018,0,7,2,1,7330,chang xu,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In stance classification, the target on which the stance is made defines the boundary of the task, and a classifier is usually trained for prediction on the same target. In this work, we explore the potential for generalizing classifiers between different targets, and propose a neural model that can apply what has been learned from a source target to a destination target. We show that our model can find useful information shared between relevant targets which improves generalization in certain scenarios."
U17-1009,Medication and Adverse Event Extraction from Noisy Text,2017,0,3,3,1,7126,xiang dai,Proceedings of the Australasian Language Technology Association Workshop 2017,0,None
P17-2075,Demographic Inference on {T}witter using Recursive Neural Networks,2017,21,10,5,1,32577,sunghwan kim,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In social media, demographic inference is a critical task in order to gain a better understanding of a cohort and to facilitate interacting with one{'}s audience. Most previous work has made independence assumptions over topological, textual and label information on social networks. In this work, we employ recursive neural networks to break down these independence assumptions to obtain inference about demographic characteristics on Twitter. We show that our model performs better than existing models including the state-of-the-art."
W16-6206,Detecting Social Roles in {T}witter,2016,12,3,3,1,32577,sunghwan kim,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,None
W16-5611,The Effects of Data Collection Methods in {T}witter,2016,0,2,3,1,32577,sunghwan kim,Proceedings of the First Workshop on {NLP} and Computational Social Science,0,None
W16-0313,{D}ata61-{CSIRO} systems at the {CLP}sych 2016 Shared Task,2016,8,10,4,1,32577,sunghwan kim,Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology,0,This paper describes the Data61-CSIRO text classification systems submitted as part of the CLPsych 2016 shared task. The aim of the shared task is to develop automated systems that can help mental health professionals with the process of triaging posts with ideations of depression and/or self-harm. We structured our participation in the CLPsych 2016 shared task in order to focus on different facets of modelling online forum discussions: (i) vector space representations; (ii) different text granularities; and (iii) fine- versus coarse-grained labels indicating concern. We achieved an F1score of 0.42 using an ensemble classification approach that predicts fine-grained labels of concern. This was the best score obtained by any submitted system in the 2016 shared task.
U16-1010,The Role of Features and Context on Suicide Ideation Detection,2016,-1,-1,3,0,10656,yufei wang,Proceedings of the Australasian Language Technology Association Workshop 2016,0,None
C16-2008,{M}u{TUAL}: A Controlled Authoring Support System Enabling Contextual Machine Translation,2016,3,0,4,1,10715,rei miyata,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"The paper introduces a web-based authoring support system, MuTUAL, which aims to help writers create multilingual texts. The highlighted feature of the system is that it enables machine translation (MT) to generate outputs appropriate to their functional context within the target document. Our system is operational online, implementing core mechanisms for document structuring and controlled writing. These include a topic template and a controlled language authoring assistant, linked to our statistical MT system."
W15-3707,Ranking election issues through the lens of social media,2015,-1,-1,2,1,3122,stephen wan,"Proceedings of the 9th {SIGHUM} Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities ({L}a{T}e{CH})",0,None
2015.mtsummit-papers.8,{J}apanese controlled language rules to improve machine translatability of municipal documents,2015,-1,-1,3,1,10715,rei miyata,Proceedings of Machine Translation Summit XV: Papers,0,None
U13-1009,A Study: From Electronic Laboratory Notebooks to Generated Queries for Literature Recommendation,2013,19,0,2,0,41179,oldooz dianat,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"Relating onexe2x80x99s research to the vast body of scientific knowledge is a difficult task; the sheer volume of literature makes it difficult to keep up-to-date with scientific developments. Particularly when research is on-going, keeping track of related work is especially important to avoid an unintended duplication of effort. We outline a novel approach to this problem that uses the text in an Electronic Laboratory Notebook (ELN) as a representation of an experimental context in the field of Chemistry. The contribution of this work is to situate the literature recommendation task within the context of the userxe2x80x99s experimental information needs. We find that our approach to transform the ELN text into queries for use with PubMed is able to recover a subset of user bibliographies. We find that alternative methods for query generation that capture both scientific terminology and salient terms in the ELN complement each other."
I13-1084,Automatic Prediction of Evidence-based Recommendations via Sentence-level Polarity Classification,2013,26,3,3,1,1157,abeed sarker,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We propose a supervised classification approach for automatically determining the polarities of medical sentences. Our polarity classification approach is contextsensitive, meaning that the same sentence may have differing polarities depending on the context. Using a set of carefully selected features, we achieve 84.7% accuracy, which is significantly better than current state-of-the-art for the polarity classification task. Our analyses and experiments on a specialised corpus indicate that automatic polarity classification of key sentences can be utilised to generate evidence-based recommendations."
W12-3710,Unifying Local and Global Agreement and Disagreement Classification in Online Debates,2012,16,14,4,0,37733,jie yin,Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis,0,"Online debate forums provide a powerful communication platform for individual users to share information, exchange ideas and express opinions on a variety of topics. Understanding people's opinions in such forums is an important task as its results can be used in many ways. It is, however, a challenging task because of the informal language use and the dynamic nature of online conversations. In this paper, we propose a new method for identifying participants' agreement or disagreement on an issue by exploiting information contained in each of the posts. Our proposed method first regards each post in its local context, then aggregates posts to estimate a participant's overall position. We have explored the use of sentiment, emotional and durational features to improve the accuracy of automatic agreement and disagreement classification. Our experimental results have shown that aggregating local positions over posts yields better performance than non-aggregation baselines when identifying users' global positions on an issue."
U12-1011,Towards Two-step Multi-document Summarisation for Evidence Based Medicine: A Quantitative Analysis,2012,22,3,3,1,1157,abeed sarker,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"We perform a quantitative analysis of data in a corpus that specialises on summarisation for Evidence Based Medicine (EBM). The intent of the analysis is to discover possible directions for performing automatic evidence-based summarisation. Our analysis attempts to ascertain the extent to which good, evidence-based, multidocument summaries can be obtained from individual single-document summaries of the source texts. We define a set of scores, which we call coverage scores, to estimate the degree of information overlap between the multi-document summaries and source texts of various granularities. Based on our analysis, using several variants of the coverage scores, and the results of a simple task oriented evaluation, we argue that approaches for the automatic generation of evidence-based, bottom-line, multi-document summaries may benefit by utilising a two-step approach: in the first step, content-rich, singledocument, query-focused summaries are generated; followed by a step to synthesise the information from the individual summaries."
U11-1014,Outcome Polarity Identification of Medical Papers,2011,29,11,3,1,1157,abeed sarker,Proceedings of the Australasian Language Technology Association Workshop 2011,0,"A medical publication may or may not present an outcome. When an outcome is present, its polarity may be positive, negative or neutral. Information about the polarity of an outcome is a vital one, particularly for practitioners who use the outcome information for decision making. We model the problem of automatic outcome polarity identification as a three-way document classification problem and attempt to solve it via supervised machine learning. We combine domain knowledge and linguistic features of medical text, and apply natural language processing to extract features for the chosen classifiers. We introduce two novel features xe2x80x94 Relative Average Negation Count and Sentence Signature xe2x80x94 and show that they are effective in improving classification accuracy. We also include features, such as n-grams and semantic orientation of terms, that have been used for similar text classification problems in other domains. Using these features, we obtain a maximum accuracy of 74.9% for the classification problem. Our experiments suggest that through careful feature selection, machine learning can be used to solve this problem."
N10-1142,Detecting Emails Containing Requests for Action,2010,27,31,3,1,45825,andrew lampert,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Automatically finding email messages that contain requests for action can provide valuable assistance to users who otherwise struggle to give appropriate attention to the actionable tasks in their inbox. As a speech act classification task, however, automatically recognising requests in free text is particularly challenging. The problem is compounded by the fact that typical emails contain extraneous material that makes it difficult to isolate the content that is directed to the recipient of the email message. In this paper, we report on an email classification system which identifies messages containing requests; we then show how, by segmenting the content of email messages into different functional zones and then considering only content in a small number of message zones when detecting requests, we can improve the accuracy of message-level automated request classification to 83.76%, a relative increase of 15.9%. This represents an error reduction of 41% compared with the same request classifier deployed without email zoning."
W09-3606,Designing a Citation-Sensitive Research Tool: An Initial Study of Browsing-Specific Information Needs,2009,-1,-1,2,1,3122,stephen wan,Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries ({NLPIR}4{DL}),0,None
E09-1097,Improving Grammaticality in Statistical Sentence Generation: Introducing a Dependency Spanning Tree Algorithm with an Argument Satisfaction Model,2009,22,28,4,1,3122,stephen wan,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Abstract-like text summarisation requires a means of producing novel summary sentences. In order to improve the grammaticality of the generated sentence, we model a global (sentence) level syntactic structure. We couch statistical sentence generation as a spanning tree problem in order to search for the best dependency tree spanning a set of chosen words. We also introduce a new search algorithm for this task that models argument satisfaction to improve the linguistic validity of the generated tree. We treat the allocation of modifiers to heads as a weighted bipartite graph matching (or assignment) problem, a well studied problem in graph theory. Using BLEU to measure performance on a string regeneration task, we found an improvement, illustrating the benefit of the spanning tree approach armed with an argument satisfaction model."
D09-1096,Segmenting Email Message Text into Zones,2009,11,18,3,1,45825,andrew lampert,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"In the early days of email, widely-used conventions for indicating quoted reply content and email signatures made it easy to segment email messages into their functional parts. Today, the explosion of different email formats and styles, coupled with the ad hoc ways in which people vary the structure and layout of their messages, means that simple techniques for identifying quoted replies that used to yield 95% accuracy now find less than 10% of such content. In this paper, we describe Zebra, an SVM-based system for segmenting the body text of email messages into nine zone types based on graphic, orthographic and lexical cues. Zebra performs this task with an accuracy of 87.01%; when the number of zones is abstracted to two or three zone classes, this increases to 93.60% and 91.53% respectively."
U08-1009,Requests and Commitments in Email are More Complex Than You Think: Eight Reasons to be Cautious,2008,-1,-1,3,1,45825,andrew lampert,Proceedings of the Australasian Language Technology Association Workshop 2008,0,None
U08-1017,Fit it in but say it well!,2008,14,2,1,1,9124,cecile paris,Proceedings of the Australasian Language Technology Association Workshop 2008,0,"Reasoning about how much content to generate when space is limited presents an increasingly important challenge for generation systems, as the diversity of potential delivery channels continues to grow. The problem is multi-facetted: the generated text must fit into the allocated space, the space available must be well utilised, and the resulting text must convey its intended message, and be coherent, well structured and balanced. To address this problem, we use a discourse planning approach. Our system reasons about the discourse structure to decide how much content to realise. In this paper, we present two algorithms that perform this reasoning and analyse their effectiveness."
P08-2033,In-Browser Summarisation: Generating Elaborative Summaries Biased Towards the Reading Context,2008,3,10,2,1,3122,stephen wan,"Proceedings of ACL-08: HLT, Short Papers",0,"We investigate elaborative summarisation, where the aim is to identify supplementary information that expands upon a key fact. We envisage such summaries being useful when browsing certain kinds of (hyper-)linked document sets, such as Wikipedia articles or repositories of publications linked by citations. For these collections, an elaborative summary is intended to provide additional information on the linking anchor text. Our contribution in this paper focuses on identifying and exploring a real task in which summarisation is situated, realised as an In-Browser tool. We also introduce a neighbourhood scoring heuristic as a means of scoring matches to relevant passages of the document. In a preliminary evaluation using this method, our summarisation system scores above our baselines and achieves a recall of 57% annotated gold standard sentences."
D08-1057,Seed and Grow: {A}ugmenting Statistically Generated Summary Sentences using Schematic Word Patterns,2008,21,7,4,1,3122,stephen wan,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"We examine the problem of content selection in statistical novel sentence generation. Our approach models the processes performed by professional editors when incorporating material from additional sentences to support some initially chosen key summary sentence, a process we refer to as Sentence Augmentation. We propose and evaluate a method called Seed and Grow for selecting such auxiliary information. Additionally, we argue that this can be performed using schemata, as represented by word-pair co-occurrences, and demonstrate its use in statistical summary sentence generation. Evaluation results are supportive, indicating that a schemata model significantly improves over the baseline."
C08-2020,Generation under Space Constraints,2008,5,4,1,1,9124,cecile paris,Coling 2008: Companion volume: Posters,0,"Reasoning about how much to generate when space is limited is a challenge for generation systems. This paper presents two algorithms that exploit the discourse structure to decide which content to drop when there are space restrictions, in the context of producing documents from pre-authored text fragments. We analyse the effectiveness of both algorithms and show that the second is near optimal."
W06-1419,Evaluations of {NLG} Systems: Common Corpus and Tasks or Common Dimensions and Metrics?,2006,7,6,1,1,9124,cecile paris,Proceedings of the Fourth International Natural Language Generation Conference,0,"In this position paper, we argue that a common task and corpus are not the only ways to evaluate Natural Language Generation (NLG) systems. It might be, in fact, too narrow a view on evaluation and thus not be the best way to evaluate these systems. The aim of a common task and corpus is to allow for a comparative evaluation of systems, looking at the systems' performances. It is thus a system-oriented view of evaluation. We argue here that, if we are to take a system oriented view of evaluation, the community might be better served by enlarging the view of evaluation, defining common dimensions and metrics to evaluate systems and approaches. We also argue that end-user (or usability) evaluations form another important aspect of a system's evaluation and should not be forgotten."
U06-1007,Classifying Speech Acts using Verbal Response Modes,2006,24,21,3,1,45825,andrew lampert,Proceedings of the Australasian Language Technology Workshop 2006,0,"The driving vision for our work is to provide intelligent, automated assistance to users in understanding the status of their email conversations. Our approach is to create tools that enable the detection and connection of speech acts across email messages. We thus require a mechanism for tagging email utterances with some indication of their dialogic function. However, existing dialog act taxonomies as used in computational linguistics tend to be too taskor application-specific for the wide range of acts we find represented in email conversation. The Verbal Response Modes (VRM) taxonomy of speech acts, widely applied for discourse analysis in linguistics and psychology, is distinguished from other speech act taxonomies by its construction from crosscutting principles of classification, which ensure universal applicability across any domain of discourse. The taxonomy categorises on two dimensions, characterised as literal meaning and pragmatic meaning. In this paper, we describe a statistical classifier that automatically identifies the literal meaning category of utterances using the VRM classification. We achieve an accuracy of 60.8% using linguistic features derived from VRMxe2x80x99s human annotation guidelines. Accuracy is improved to 79.8% using additional features."
U06-1013,Pseudo Relevance Feedback Using Named Entities for Question Answering,2006,14,22,3,0,47728,luiz pizzato,Proceedings of the Australasian Language Technology Workshop 2006,0,"Relevance feedback has already proven its usefulness in probabilistic information retrieval (IR). In this research we explore whether a pseudo relevance feedback technique on IR can improve the Question Answering task (QA). The basis of our exploration is the use of relevant named entities from the top retrieved documents as clues of relevance. We discuss two interesting findings from these experiments: the reasons the results were not improved, and the fact that todayxe2x80x99s metrics of IR evaluation on QA do not reflect the results obtained by a QA system."
U06-1019,Using Dependency-Based Features to Take the {'}Para-farce{'} out of Paraphrase,2006,19,103,4,1,3122,stephen wan,Proceedings of the Australasian Language Technology Workshop 2006,0,"As research in text-to-text paraphrase generation progresses, it has the potential to improve the quality of generated text. However, the use of paraphrase generation methods creates a secondary problem. We must ensure that generated novel sentences are not inconsistent with the text from which it was generated. We propose a machine learning approach be used to filter out inconsistent novel sentences, or False Paraphrases. To train such a filter, we use the Microsoft Research Paraphrase corpus and investigate whether features based on syntactic dependencies can aid us in this task. Like Finch et al. (2005), we obtain a classification accuracy of 75.6%, the best known performance for this corpus. We also examine the strengths and weaknesses of dependency based features and conclude that they may be useful in more accurately classifying cases of False Paraphrase."
I05-5012,Towards Statistical Paraphrase Generation: Preliminary Evaluations of Grammaticality,2005,11,7,4,1,3122,stephen wan,Proceedings of the Third International Workshop on Paraphrasing ({IWP}2005),0,"Summary sentences are often paraphrases of existing sentences. They may be made up of recycled fragments of text taken from important sentences in an input document. We investigate the use of a statistical sentence generation technique that recombines words probabilistically in order to create new sentences. Given a set of event-related sentences, we use an extended version of the Viterbi algorithm which employs dependency relation and bigram probabilities to find the most probable summary sentence. Using precision and recall metrics for verb arguments as a measure of grammaticality, we find that our system performs better than a bigram baseline, producing fewer spurious verb arguments."
U04-1005,An Evaluation on Query-biased Summarisation for the Question Answering Task,2004,0,1,3,0,51718,mingfang wu,Proceedings of the Australasian Language Technology Workshop 2004,0,None
U04-1009,Information Assembly for Automatic Content Adaptation,2004,0,0,2,1,45825,andrew lampert,Proceedings of the Australasian Language Technology Workshop 2004,0,None
U04-1012,Intelligent Multi Media Presentation of information in a semi-immersive Command and Control environment,2004,18,1,1,1,9124,cecile paris,Proceedings of the Australasian Language Technology Workshop 2004,0,"We describe the framework for an intelligent multimedia presentation system we designed to be part of the FOCAL laboratory, a semi-immersive environment for Command and Control Environment. FOCAL comprises a number of input devices and output media, animated virtual conversational characters, a spoken dialogue system, and sophisticated visual displays. These need to be coordinated to provide a useful and effective presentation to the user. In this paper, we describe the principles which underlie intelligent multimedia presentation (IMMP) systems and the design of such a system within the FOCAL multiagent architecture."
W03-1202,Using Thematic Information in Statistical Headline Generation,2003,21,17,3,1,3122,stephen wan,Proceedings of the {ACL} 2003 Workshop on Multilingual Summarization and Question Answering,0,"We explore the problem of single sentence summarisation. In the news domain, such a summary might resemble a headline. The headline generation system we present uses Singular Value Decomposition (SVD) to guide the generation of a headline towards the theme that best represents the document to be summarised. In doing so, the intuition is that the generated summary will more accurately reflect the content of the source document. This paper presents SVD as an alternative method to determine if a word is a suitable candidate for inclusion in the headline. The results of a recall based evaluation comparing three different strategies to word selection, indicate that thematic information does help improve recall."
U03-1012,Straight to the point: Discovering themes for summary generation,2003,19,3,3,1,3122,stephen wan,Proceedings of the Australasian Language Technology Workshop 2003,0,"This paper presents our approach to the problem of single sentence summarisation. We investigate the use of Singular Value Decomposition (SVD) to guide the generation of a summary towards the theme that is the focus of the document to be summarised. In doing so, the intuition is that the generated summary will more accurately reflect the content of the source document. Currently, we operate in the news domain and at present, our summaries are modelled on headlines. This paper presents SVD as an alternative method to determine if a word is a suitable candidate for inclusion in the headline. The results of a recall based evaluation comparing three different strategies to word selection, indicate that thematic information does help improve recall."
W02-2117,An Evaluation of Procedural Instructional Text,2002,19,14,2,0,17625,nathalie colineau,Proceedings of the International Natural Language Generation Conference,0,"This paper presents an evaluation of the instructional text generated by Isolde, an authoring tool for technical writers that automates the production of procedural on-line help. The evaluation compares the effectiveness of the instructional text produced by Isolde with that of professionally authored instructions, such as MS Word Help. The results suggest that the documentation produced by Isolde is of comparable quality to similar texts found in commercial manuals."
W96-0504,{DRAFTER},1996,-1,-1,1,1,9124,cecile paris,Eighth International Natural Language Generation Workshop (Posters and Demonstrations),0,None
P96-1026,Two Sources of Control Over the Generation of Software Instructions,1996,22,8,2,1,32117,anthony hartley,34th Annual Meeting of the Association for Computational Linguistics,1,None
C96-2124,Building Knowledge Bases for the Generation of Software Documentation,1996,8,7,1,1,9124,cecile paris,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"Automated text generation requires a underlying knowledge base from which to generate, which is often difficult to produce. Software documentation is one domain in which parts of this knowledge base may be derived automatically. In this paper, we describe DRAFTER, an authoring support tool for generating usercentred software documentation, and in particular, we describe how parts of its required knowledge base can be obtained automatically."
W94-0306,"Intentions, Structure and Expression in Multi-Lingual Instructions",1994,0,2,1,1,9124,cecile paris,Proceedings of the Seventh International Workshop on Natural Language Generation,0,None
W94-0308,Expressing Procedural Relationships in Multilingual Instructions,1994,8,55,3,0,53166,judy delin,Proceedings of the Seventh International Workshop on Natural Language Generation,0,"In this paper we discuss a study of the expression of procedural relations in multilingual user instructions, in particular the relations of Generation and Enablement. These procedural relations are defined in terms of a plan representation model, and applied in a corpus study of English, French, and Portuguese instructions. The results of our analysis indicate specific guidelines for the tactical realisation of expressions of these relations in multilingual instructional text."
W93-0224,On the Necessity of Intentions and the Usefulness of Rhetorical Relations: A Position Paper,1993,-1,-1,2,0,49203,vibhu mittal,Intentionality and Structure in Discourse Relations,0,None
J93-4004,Planning Text for Advisory Dialogues: Capturing Intentional and Rhetorical Information,1993,53,302,2,0.740741,28333,johanna moore,Computational Linguistics,0,"To participate in a dialogue a system must be capable of reasoning about its own previous utterances. Follow-up questions must be interpreted in the context of the ongoing conversation, and the system's previous contributions form part of this context. Furthermore, if a system is to be able to clarify misunderstood explanations or to elaborate on prior explanations, it must understand what it has conveyed in prior explanations. Previous approaches to generating multisentential texts have relied solely on rhetorical structuring techniques. In this paper, we argue that, to handle explanation dialogues successfully, a discourse model must include information about the intended effect of individual parts of the text on the hearer, as well as how the parts relate to one another rhetorically. We present a text planner that records this information and show how the resulting structure is used to respond appropriately to a follow-up question."
P89-1025,Planning Text for Advisory Dialogues,1989,24,172,2,0.740741,28333,johanna moore,27th Annual Meeting of the Association for Computational Linguistics,1,"Explanation is an interactive process requiring a dialogue between advice-giver and advice-seeker. In this paper, we argue that in order to participate in a dialogue with its users, a generation system must be capable of reasoning about its own utterances and therefore must maintain a rich representation of the responses it produces. We present a text planner that constructs a detailed text plan, containing the intentional, attentional, and rhetorical structures of the text it generates."
J88-3006,Tailoring Object Descriptions to a User{'}s Level of Expertise,1988,29,175,1,1,9124,cecile paris,Computational Linguistics,0,"A question answering program providing access to a large amount of data will be most useful if it can tailor its answers to each individual user. In particular, a user's level of knowledge about the domain of discourse is an important factor in this tailoring if the answer provided is to be both informative and understandable to the user. In this research, we address the issue of how the user's domain knowledge can affect an answer. By studying texts, we found that the user's level of domain knowledge affected the kind of information provided and not just the amount of information, as was previously assumed. Depending on the user's assumed domain knowledge, a description can be either parts-oriented or process-oriented. Thus the user's level of expertise in a domain can guide a system in choosing the appropriate facts from the knowledge base to include in an answer. We propose two distinct descriptive strategies that can be used in a question answering program, and show how they can be mixed to include the appropriate information from the knowledge base, given the user's domain knowledge. We have implemented these strategies in TAILOR, a computer system that generates descriptions of devices. TAILOR uses one of the two discourse strategies identified in texts to construct a description for either a novice or an expert. It can merge the strategies automatically to produce a wide range of different descriptions to users who fall between the extremes of novice or expert, without requiring an a priori set of user stereotypes."
P87-1014,Functional Unification Grammar Revisited,1987,12,21,2,0,895,kathleen mckeown,25th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we show that one benefit of FUG, the ability to state global constraints on choice separately from syntactic rules, is difficult in generation systems based on augmented context free grammars (e.g., Definite Clause Grammars). They require that such constraints be expressed locally as part of syntactic rules and therefore, duplicated in the grammar. Finally, we discuss a reimplementation of FUG that achieves the similar levels of efficiency as Rubinoff's adaptation of MUMBLE, a deterministic language generator."
P85-1029,Description Strategies for Naive and Expert Users,1985,10,34,1,1,9124,cecile paris,23rd Annual Meeting of the Association for Computational Linguistics,1,"It is widely recognized that a question-answering system should be able to tailor its answers to the user. One of the dimensions along which this tailoring can occur is with respect to the level of knowledge of a user about a domain. In particular, responses should be different depending on whether they are addressed to naive or expert users. To understand what those differences should be, we analyzed texts from adult and junior encyclopedias. We found that two different strategies were used in describing complex physical objects to juniors and adults. We show how these strategies have been implemented on a test database."
