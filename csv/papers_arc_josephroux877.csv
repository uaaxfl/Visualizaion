2021.iwpt-1.11,Strength in Numbers: Averaging and Clustering Effects in Mixture of Experts for Graph-Based Dependency Parsing,2021,-1,-1,2,0,5823,xudong zhang,Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021),0,"We review two features of mixture of experts (MoE) models which we call averaging and clustering effects in the context of graph-based dependency parsers learned in a supervised probabilistic framework. Averaging corresponds to the ensemble combination of parsers and is responsible for variance reduction which helps stabilizing and improving parsing accuracy. Clustering describes the capacity of MoE models to give more credit to experts believed to be more accurate given an input. Although promising, this is difficult to achieve, especially without additional data. We design an experimental set-up to study the impact of these effects. Whereas averaging is always beneficial, clustering requires good initialization and stabilization techniques, but its advantages over mere averaging seem to eventually vanish when enough experts are present. As a by product, we show how this leads to state-of-the-art results on the PTB and the CoNLL09 Chinese treebank, with low variance across experiments."
2021.insights-1.19,Challenging the Semi-Supervised {VAE} Framework for Text Classification,2021,-1,-1,2,0,5901,ghazi felhi,Proceedings of the Second Workshop on Insights from Negative Results in NLP,0,"Semi-Supervised Variational Autoencoders (SSVAEs) are widely used models for data efficient learning. In this paper, we question the adequacy of the standard design of sequence SSVAEs for the task of text classification as we exhibit two sources of overcomplexity for which we provide simplifications. These simplifications to SSVAEs preserve their theoretical soundness while providing a number of practical advantages in the semi-supervised setup where the result of training is a text classifier. These simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unobserved latent variable from its probabilistic model. These changes relieve users from choosing a prior for their latent variables, make the model smaller and faster, and allow for a better flow of information into the latent variables. We compare the simplified versions to standard SSVAEs on 4 text classification tasks. On top of the above-mentioned simplification, experiments show a speed-up of 26{\%}, while keeping equivalent classification scores. The code to reproduce our experiments is public."
2020.jeptalnrecital-deft.2,Calcul de similarit{\\'e} entre phrases : quelles mesures et quels descripteurs ? (Sentence Similarity : a study on similarity metrics with words and character strings ),2020,-1,-1,4,0,18793,davide buscaldi,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Atelier D{\\'E}fi Fouille de Textes",0,Cet article pr{\'e}sente notre participation {\`a} l{'}{\'e}dition 2020 du D{\'e}fi Fouille de Textes DEFT 2020 et plus pr{\'e}cis{\'e}ment aux deux t{\^a}ches ayant trait {\`a} la similarit{\'e} entre phrases. Dans notre travail nous nous sommes int{\'e}ress{\'e} {\`a} deux questions : celle du choix de la mesure du similarit{\'e} d{'}une part et celle du choix des op{\'e}randes sur lesquelles se porte la mesure de similarit{\'e}. Nous avons notamment {\'e}tudi{\'e} la question de savoir s{'}il fallait utiliser des mots ou des cha{\^\i}nes de caract{\`e}res (mots ou non-mots). Nous montrons d{'}une part que la similarit{\'e} de Bray-Curtis peut {\^e}tre plus efficace et surtout plus stable que la similarit{\'e} cosinus et d{'}autre part que le calcul de similarit{\'e} sur des cha{\^\i}nes de caract{\`e}res est plus efficace que le m{\^e}me calcul sur des mots.
2020.coling-main.225,Multitask Easy-First Dependency Parsing: Exploiting Complementarities of Different Dependency Representations,2020,-1,-1,2,0,4825,yash kankanampati,Proceedings of the 28th International Conference on Computational Linguistics,0,"In this paper we present a parsing model for projective dependency trees which takes advantage of the existence of complementary dependency annotations which is the case in Arabic, with the availability of CATiB and UD treebanks. Our system performs syntactic parsing according to both annotation types jointly as a sequence of arc-creating operations, and partially created trees for one annotation are also available to the other as features for the score function. This method gives error reduction of 9.9{\%} on CATiB and 6.1{\%} on UD compared to a strong baseline, and ablation tests show that the main contribution of this reduction is given by sharing tree representation between tasks, and not simply sharing BiLSTM layers as is often performed in NLP multitask systems."
K19-1023,Representation Learning and Dynamic Programming for Arc-Hybrid Parsing,2019,0,0,1,1,5824,joseph roux,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"We present a new method for transition-based parsing where a solution is a pair made of a dependency tree and a derivation graph describing the construction of the former. From this representation we are able to derive an efficient parsing algorithm and design a neural network that learns vertex representations and arc scores. Experimentally, although we only train via local classifiers, our approach improves over previous arc-hybrid systems and reach state-of-the-art parsing accuracy."
2019.jeptalnrecital-deft.5,Indexation et appariements de documents cliniques pour le Deft 2019 (Indexing and pairing texts of the medical domain ),2019,-1,-1,3,0,18793,davide buscaldi,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. D{\\'e}fi Fouille de Textes (atelier TALN-RECITAL),0,"Dans cet article, nous pr{\'e}sentons nos m{\'e}thodes pour les t{\^a}ches d{'}indexation et d{'}appariements du D{\'e}fi Fouile de Textes (Deft) 2019. Pour la ta{\^c}he d{'}indexation nous avons test{\'e} deux m{\'e}thodes, une fond{\'e}e sur l{'}appariemetn pr{\'e}alable des documents du jeu de tset avec les documents du jeu d{'}entra{\^\i}nement et une autre m{\'e}thode fond{\'e}e sur l{'}annotation terminologique. Ces m{\'e}thodes ont malheureusement offert des r{\'e}sultats assez faible. Pour la t{\^a}che d{'}appariement, nous avons d{\'e}vellop{\'e} une m{\'e}thode sans apprentissage fond{\'e}e sur des similarit{\'e}s de cha{\^\i}nes de caract{\`e}res ainsi qu{'}une m{\'e}thode exploitant des r{\'e}seaux siamois. L{\`a} encore les r{\'e}sultats ont {\'e}t{\'e} plut{\^o}t d{\'e}cevant m{\^e}me si la m{\'e}thode non supervis{\'e}e atteint un score plut{\^o}t honorable pour une m{\'e}thode non-supervis{\'e}e : 62{\%} ."
2018.jeptalnrecital-deft.4,Mod{\\`e}les en Caract{\\`e}res pour la D{\\'e}tection de Polarit{\\'e} dans les Tweets (Character-level Models for Polarity Detection in Tweets ),2018,-1,-1,2,0,18793,davide buscaldi,"Actes de la Conf{\\'e}rence TALN. Volume 2 - D{\\'e}monstrations, articles des Rencontres Jeunes Chercheurs, ateliers DeFT",0,"Dans cet article, nous pr{\'e}sentons notre contribution au D{\'e}fi Fouille de Textes 2018 au travers de trois m{\'e}thodes originales pour la classification th{\'e}matique et la d{\'e}tection de polarit{\'e} dans des tweets en fran{\c{c}}ais. Nous y avons ajout{\'e} un syst{\`e}me de vote. Notre premi{\`e}re m{\'e}thode est fond{\'e}e sur des lexiques (mots et emojis), les n-grammes de caract{\`e}res et un classificateur {\`a} vaste marge (ou SVM). tandis que les deux autres sont des m{\'e}thodes endog{\`e}nes fond{\'e}es sur l{'}extraction de caract{\'e}ristiques au grain caract{\`e}res : un mod{\`e}le {\`a} m{\'e}moire {\`a} court-terme persistante (ou BiLSTM pour Bidirectionnal Long Short-Term Memory) et perceptron multi-couche d{'}une part et un mod{\`e}le de s{\'e}quences de caract{\`e}res ferm{\'e}es fr{\'e}quentes et classificateur SVM d{'}autre part. Le BiLSTM a produit de loin les meilleurs r{\'e}sultats puisqu{'}il a obtenu la premi{\`e}re place sur la t{\^a}che 1, classification binaire de tweets selon qu{'}ils traitent ou non des transports, et la troisi{\`e}me place sur la t{\^a}che 2, classification de la polarit{\'e} en 4 classes. Ce r{\'e}sultat est d{'}autant plus int{\'e}ressant que la m{\'e}thode propos{\'e}e est faiblement param{\'e}trique, totalement endog{\`e}ne et qu{'}elle n{'}implique aucun pr{\'e}-traitement."
W17-6212,Transforming Dependency Structures to {LTAG} Derivation Trees,2017,14,0,2,1,5586,caio corro,Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms,0,"We propose a new algorithm for parsing Lexicalized Tree Adjoining Grammars (LTAGs) which uses pre-assigned bilexi-cal dependency relations as a filter. That is, given a sentence and its corresponding well-formed dependency structure, the parser assigns elementary trees to words of the sentence and return attachment sites compatible with these elementary trees and predefined dependencies. Moreover, we prove that this algorithm has a linear-time complexity in the input length. This algorithm returns all compatible derivation trees as a packed forest. This result is of practical interest to the development of efficient weighted LTAG parsers based on derivation tree decoding."
D17-1172,Efficient Discontinuous Phrase-Structure Parsing via the Generalized Maximum Spanning Arborescence,2017,0,4,2,1,5586,caio corro,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We present a new method for the joint task of tagging and non-projective dependency parsing. We demonstrate its usefulness with an application to discontinuous phrase-structure parsing where decoding lexicalized spines and syntactic derivations is performed jointly. The main contributions of this paper are (1) a reduction from joint tagging and non-projective dependency parsing to the Generalized Maximum Spanning Arborescence problem, and (2) a novel decoding algorithm for this problem through Lagrangian relaxation. We evaluate this model and obtain state-of-the-art results despite strong independence assumptions."
P16-1034,Dependency Parsing with Bounded Block Degree and Well-nestedness via {L}agrangian Relaxation and Branch-and-Bound,2016,42,3,2,1,5586,caio corro,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a novel dependency parsing method which enforces two structural properties on dependency trees: bounded block degree and well-nestedness. These properties are useful to better represent the set of admissible dependency structures in treebanks and connect dependency parsing to context-sensitive grammatical formalisms. We cast this problem as an Integer Linear Program that we solve with Lagrangian Relaxation from which we derive a heuristic and an exact method based on a Branch-and-Bound search. Experimentally, we see that these methods are efficient and competitive compared to a baseline unconstrained parser, while enforcing structural properties in all cases."
N16-1127,Deep Lexical Segmentation and Syntactic Parsing in the Easy-First Dependency Framework,2016,16,2,2,0,23668,matthieu constant,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We explore the consequences of representing token segmentations as hierarchical structures (trees) for the task of Multiword Expression (MWE) recognition, in isolation or in combination with dependency parsing. We propose a novel representation of token segmentation as trees on tokens, resembling dependency trees. Given this new representation, we present and evaluate two different architectures to combine MWE recognition and dependency parsing in the easy-first framework: a pipeline and a joint system, both taking advantage of lexical and syntactic dimensions. We experimentally validate that MWE recognition significantly helps syntactic parsing."
D15-1157,{F}oreebank: Syntactic Analysis of Customer Support Forums,2015,25,8,6,0,27769,rasoul kaljahi,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We present a new treebank of English and French technical forum content which has been annotated for grammatical errors and phrase structure. This double annotation allows us to empirically measure the effect of errors on parsing performance. While it is slightly easier to parse the corrected versions of the forum sentences, the errors are not the main factor in making this kind of text hard to parse."
W14-3614,A Pipeline Approach to Supervised Error Correction for the {QALB}-2014 Shared Task,2014,31,4,4,0,21324,nadi tomeh,Proceedings of the {EMNLP} 2014 Workshop on {A}rabic Natural Language Processing ({ANLP}),0,"This paper describes our submission to the ANLP-2014 shared task on automatic Arabic error correction. We present a pipeline approach integrating an error detection model, a combination of character- and word-level translation models, a reranking model and a punctuation insertion model. We achieve an F1 score of 62.8% on the development set of the QALB corpus, and 58.6% on the official test set."
S14-2069,{LIPN}: Introducing a new Geographical Context Similarity Measure and a Statistical Similarity Measure based on the Bhattacharyya coefficient,2014,11,2,3,0.790923,18793,davide buscaldi,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper describes the system used by the LIPN team in the task 10, Multilingual Semantic Textual Similarity, at SemEval 2014, in both the English and Spanish sub-tasks. The system uses a support vector regression model, combining different text similarity measures as features. With respect to our 2013 participation, we included a new feature to take into account the geographical context and a new semantic distance based on the Bhattacharyya distance calculated on co-occurrence distributions derived from the Spanish Google Books n-grams dataset."
C14-1177,Syntactic Parsing and Compound Recognition via Dual Decomposition: Application to {F}rench,2014,19,8,1,1,5824,joseph roux,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In this paper we show how the task of syntactic parsing of non-segmented texts, including compound recognition, can be represented as constraints between phrase-structure parsers and CRF sequence labellers. In order to build a joint system we use dual decomposition, a way to combine several elementary systems which has proven successful in various NLP tasks. We evaluate this proposition on the French SPMRL corpus. This method compares favorably with pipeline architectures and improves state-of-the-art results."
S13-1023,"{LIPN}-{CORE}: Semantic Text Similarity using n-grams, {W}ord{N}et, Syntactic Analysis, {ESA} and Information Retrieval based Features",2013,17,21,2,0.790923,18793,davide buscaldi,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"This paper describes the system used by the LIPN team in the Semantic Textual Similarity task at SemEval 2013. It uses a support vector regression model, combining different text similarity measures that constitute the features. These measures include simple distances like Levenshtein edit distance, cosine, Named Entities overlap and more complex distances like Explicit Semantic Analysis, WordNet-based similarity, IR-based similarity, and a similarity measure based on syntactic dependencies."
J13-3005,{XMG}: e{X}tensible {M}eta{G}rammar,2013,59,28,4,0,5601,benoit crabbe,Computational Linguistics,0,"In this article, we introduce eXtensible MetaGrammar (xmg), a framework for specifying tree-based grammars such as Feature-Based Lexicalised Tree-Adjoining Grammars (FB-LTAG) and Interaction Grammars (IG). We argue that xmg displays three features which facilitate both grammar writing and a fast prototyping of tree-based grammars. Firstly, xmg is fully declarative. For instance, it permits a declarative treatment of diathesis that markedly departs from the procedural lexical rules often used to specify tree-based grammars. Secondly, the xmg language has a high notational expressivity in that it supports multiple linguistic dimensions, inheritance and a sophisticated treatment of identifiers. Thirdly, xmg is extensible in that its computational architecture facilitates the extension to other linguistic formalisms. We explain how this architecture naturally supports the design of three linguistic formalisms namely, FB-LTAG, IG, and Multi-Component Tree-Adjoining Grammar (MC-TAG). We further show how it permits a straightforward integration of additional mechanisms such as linguistic and formal principles. To further illustrate the declarativity, notational expressivity and extensibility of xmg , we describe the methodology used to specify an FB-LTAG for French augmented with a unification-based compositional semantics. This illustrates both how xmg facilitates the modelling of the tree fragment hierarchies required to specify tree-based grammars and of a syntax/semantics interface between semantic representations and syntactic trees. Finally, we briefly report on several grammars for French, English and German that were implemented using xmg and compare xmg to other existing grammar specification frameworks for tree-based grammars."
D13-1116,Combining {PCFG}-{LA} Models with Dual Decomposition: A Case Study with Function Labels and Binarization,2013,35,4,1,1,5824,joseph roux,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"It has recently been shown that different NLP models can be effectively combined using dual decomposition. In this paper we demon-strate that PCFG-LA parsing models are suit-able for combination in this way. We exper-iment with the different models which result from alternative methods of extracting a gram-mar from a treebank (retaining or discarding function labels, left binarization versus right binarization) and achieve a labeled Parseval F-score of 92.4 on Wall Street Journal Sec-tion 23 xe2x80x93 this represents an absolute improve-ment of 0.7 and an error reduction rate of 7% over a strong PCFG-LA product-model base-line. Although we experiment only with bina-rization and function labels in this study, there is much scope for applying this approach to other grammar extraction strategies."
W12-3408,Statistical Parsing of {S}panish and Data Driven Lemmatization,2012,15,5,1,1,5824,joseph roux,Proceedings of the {ACL} 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,0,"Although parsing performances have greatly improved in the last years, grammar inference from treebanks for morphologically rich lan- guages, especially from small treebanks, is still a challenging task. In this paper we in- vestigate how state-of-the-art parsing perfor- mances can be achieved on Spanish, a lan- guage with a rich verbal morphology, with a non-lexicalized parser trained on a treebank containing only around 2,800 trees. We rely on accurate part-of-speech tagging and data- driven lemmatization in order to cope with lexical data sparseness. Providing state-of- the-art results on Spanish, our methodology is applicable to other languages."
W12-3412,Generative Constituent Parsing and Discriminative Dependency Reranking: Experiments on {E}nglish and {F}rench,2012,26,3,1,1,5824,joseph roux,Proceedings of the {ACL} 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,0,We present an architecture for parsing in two steps. A phrase-structure parser builds for each sentence ann-best list of analyses which are converted to dependency trees. These dependency structures are then rescored by a discriminative reranker. Our method is language agnostic and enables the incorporation of additional information which are useful for the choice of the best parse candidate. We test our approach on the the Penn Treebank and the French Treebank. Evaluation shows a significative improvement on different parse metrics.
P12-1082,Semi-supervised Dependency Parsing using Lexical Affinities,2012,28,7,3,0,35499,seyed mirroshandel,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Treebanks are not large enough to reliably model precise lexical phenomena. This deficiency provokes attachment errors in the parsers trained on such data. We propose in this paper to compute lexical affinities, on large corpora, for specific lexico-syntactic configurations that are hard to disambiguate and introduce the new information in a parser. Experiments on the French Treebank showed a relative decrease of the error rate of 7.1% Labeled Accuracy Score yielding the best parsing results on this treebank."
P11-4015,{MACAON} An {NLP} Tool Suite for Processing Word Lattices,2011,17,30,5,0.317466,5812,alexis nasr,Proceedings of the {ACL}-{HLT} 2011 System Demonstrations,0,"MACAON is a tool suite for standard NLP tasks developed for French. MACAON has been designed to process both human-produced text and highly ambiguous word-lattices produced by NLP tools. MACAON is made of several native modules for common tasks such as a tokenization, a part-of-speech tagging or syntactic parsing, all communicating with each other through XML files. In addition, exchange protocols with external tools are easily definable. MACAON is a fast, modular and open tool, distributed under GNU Public License."
I11-1100,From News to Comment: Resources and Benchmarks for Parsing the Language of Web 2.0,2011,28,58,4,0.555556,819,jennifer foster,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We investigate the problem of parsing the noisy language of social media. We evaluate four Wall-Street-Journal-trained statistical parsers (Berkeley, Brown, Malt and MST) on a new dataset containing 1,000 phrase structure trees for sentences from microblogs (tweets) and discussion forum posts. We compare the four parsers on their ability to produce Stanford dependencies for these Web 2.0 sentences. We find that the parsers have a particular problem with tweets and that a substantial part of this problem is related to POS tagging accuracy. We attempt three retraining experiments involving Malt, Brown and an in-house Berkeley-style parser and obtain a statistically significant improvement for all three parsers."
2011.jeptalnrecital-long.26,Mod{\\`e}les g{\\'e}n{\\'e}ratif et discriminant en analyse syntaxique : exp{\\'e}riences sur le corpus arbor{\\'e} de {P}aris 7 (Generative and discriminative models in parsing: experiments on the {P}aris 7 Treebank),2011,-1,-1,1,1,5824,joseph roux,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous pr{\'e}sentons une architecture pour l{'}analyse syntaxique en deux {\'e}tapes. Dans un premier temps un analyseur syntagmatique construit, pour chaque phrase, une liste d{'}analyses qui sont converties en arbres de d{\'e}pendances. Ces arbres sont ensuite r{\'e}{\'e}valu{\'e}s par un r{\'e}ordonnanceur discriminant. Cette m{\'e}thode permet de prendre en compte des informations auxquelles l{'}analyseur n{'}a pas acc{\`e}s, en particulier des annotations fonctionnelles. Nous validons notre approche par une {\'e}valuation sur le corpus arbor{\'e} de Paris 7. La seconde {\'e}tape permet d{'}am{\'e}liorer significativement la qualit{\'e} des analyses retourn{\'e}es, quelle que soit la m{\'e}trique utilis{\'e}e."
W10-1408,"Handling Unknown Words in Statistical Latent-Variable Parsing Models for {A}rabic, {E}nglish and {F}rench",2010,21,43,4,0,24071,mohammed attia,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper presents a study of the impact of using simple and complex morphological clues to improve the classification of rare and unknown words for parsing. We compare this approach to a language-independent technique often used in parsers which is based solely on word frequencies. This study is applied to three languages that exhibit different levels of morphological expressiveness: Arabic, French and English. We integrate information about Arabic affixes and morphotactics into a PCFG-LA parser and obtain state-of-the-art accuracy. We also show that these morphological clues can be learnt automatically from an annotated corpus."
W09-3809,Deductive Parsing in Interaction Grammars,2009,8,0,1,1,5824,joseph roux,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We present a parsing algorithm for Interaction Grammars using the deductive parsing framework. This approach brings new perspectives to this problem, departing from previous methods which rely on constraint-solving techniques."
2009.jeptalnrecital-long.2,Analyse d{\\'e}ductive pour les grammaires d{'}interaction,2009,-1,-1,1,1,5824,joseph roux,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous proposons un algorithme d{'}analyse pour les grammaires d{'}interaction qui utilise le cadre formel de l{'}analyse d{\'e}ductive. Cette approche donne un point de vue nouveau sur ce probl{\`e}me puisque les m{\'e}thodes pr{\'e}c{\'e}dentes r{\'e}duisaient ce dernier {\`a} la r{\'e}{\'e}criture de graphes et utilisaient des techniques de r{\'e}solution de contraintes. D{'}autre part, cette pr{\'e}sentation permet de d{\'e}crire le processus de mani{\`e}re standard et d{'}exhiber les sources d{'}ind{\'e}terminisme qui rendent ce probl{\`e}me difficile."
W08-2319,Feature Unification in {TAG} Derivation Trees,2008,21,10,2,0,44028,sylvain schmitz,Proceedings of the Ninth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+9),0,"The derivation trees of a tree adjoining grammar provide a first insight into the sentence semantics, and are thus prime targets for generation systems. We define a formalism, feature-based regular tree grammars, and a translation from feature based tree adjoining grammars into this new formalism. The translation preserves the derivation structures of the original grammar, and accounts for feature unification."
C08-3003,A Toolchain for Grammarians,2008,12,3,2,0,5831,bruno guillaume,Coling 2008: Companion volume: Demonstrations,0,"We present a chain of tools used by grammarians and computer scientists to develop grammatical and lexical resources from linguistic knowledge, for various natural languages. The developed resources are intended to be used in Natural Language Processing (NLP) systems."
2008.jeptalnrecital-court.2,Calculs d{'}unification sur les arbres de d{\\'e}rivation {TAG},2008,-1,-1,2,0,44028,sylvain schmitz,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Nous d{\'e}finissons un formalisme, les grammaires rationnelles d{'}arbres avec traits, et une traduction des grammaires d{'}arbres adjoints avec traits vers ce nouveau formalisme. Cette traduction pr{\'e}serve les structures de d{\'e}rivation de la grammaire d{'}origine en tenant compte de l{'}unification de traits. La construction peut {\^e}tre appliqu{\'e}e aux r{\'e}alisateurs de surface qui se fondent sur les arbres de d{\'e}rivation."
W06-1502,A Constraint Driven Metagrammar,2006,11,2,1,1,5824,joseph roux,Proceedings of the Eighth International Workshop on Tree Adjoining Grammar and Related Formalisms,0,"We present an operational framework allowing to express a large scale Tree Adjoining Grammar (tag) by using higher level operational constraints on tree descriptions. These constraints first meant to guarantee the well formedness of the grammatical units may also be viewed as a way to put model theoretic syntax at work through an efficient offline grammatical compilation process. Our strategy preserves tag formal properties, hence ensures a reasonable processing efficiency."
E06-2005,{XMG} - An Expressive Formalism for Describing Tree-Based Grammars,2006,11,2,2,0,30986,yannick parmentier,Demonstrations,0,"In this paper we introduce eXtensible MetaGrammar, a system that facilitates the development of tree based grammars. This system includes both (1) a formal language adapted to the description of linguistic information and (2) a compiler for this language. It applies techniques of logic programming (e.g. Warren's Abstract Machine), thus providing an efficient and theoretically motivated framework for the processing of linguistic meta-descriptions."
2005.jeptalnrecital-long.2,{XMG} : un Compilateur de M{\\'e}ta-Grammaires Extensible,2005,9,5,2,0,30985,denys duchier,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous pr{\'e}sentons un outil permettant de produire automatiquement des ressources linguistiques, en l{'}occurence des grammaires. Cet outil se caract{\'e}rise par son extensibilit{\'e}, tant du point de vue des formalismes grammaticaux support{\'e}s (grammaires d{'}arbres adjoints et grammaires d{'}interaction {\`a} l{'}heure actuelle), que de son architecture modulaire, qui facilite l{'}int{\'e}gration de nouveaux modules ayant pour but de v{\'e}rifier la validit{\'e} des structures produites. En outre, cet outil offre un support adapt{\'e} au d{\'e}veloppement de grammaires {\`a} port{\'e}e s{\'e}mantique."
